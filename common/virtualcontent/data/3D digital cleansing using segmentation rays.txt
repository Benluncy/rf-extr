
 3D Digital Cleansing Using Segmentation Rays  Copyright and Reprint Permission: Abstracting is permitted 
with credit to the source. Libraries are permitted to photocopy beyond the limit of U.S. copyright law 
for private use of patrons those articles in this volume that carry a code at the bottom of the first 
page, provided the per-copy fee indicated in the code is paid through Copyright Clearance Center, 222 
Rosewood Drive, Danvers, MA 01923. For other copying, reprint or republication permission, write to IEEE 
Copyrights Manager, IEEE Service Center, 445 Hoes Lane, P.O. Box 1331, Piscataway, NJ 08855-1331. All 
rights reserved. Copyright 2001 by the Institute of Electrical and Electronics Engineers, Inc. All rights 
reserved.Copyright 2001 IEEE. Personal use of this material is permitted. However, permission to reprint/republish 
this material for advertising or promotional purposes or for creating new collective works for resale 
or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works 
must be obtained from the IEEE. Sarang Lakare, Ming Wan, Mie Sato, and Arie Kaufman Center for Visual 
Computing (CVC) and Department of Computer Science State University of New York at Stony Brook Stony 
Brook, NY 11790-4400 Abstract We propose a novel approach for segmentation and digital cleans­ing of 
endoscopic organs. Our method can be used for a variety of segmentation needs with little or no modi.cation. 
It aims at ful.lling the dual and often con.icting requirements of a fast and accurate segmentation and 
also eliminates the undesirable partial volume effect which contemporary approaches cannot. For segmen­tation 
and digital cleansing, we use the peculiar characteristics ex­hibited by the intersection of any two 
distinct-intensity regions. To detect these intersections we cast rays through the volume, which we call 
the segmentation rays as they assist in the segmentation. We then associate a certain task of reconstruction 
and classi.cation with each intersection the ray detects. We further use volumetric contrast enhancement 
to reconstruct surface lost by segmentation (if any), which aids in improving the quality of the volume 
render­ing. Keywords: Volume Segmentation, Segmentation Rays, Partial Volume Voxels, Volume Rendering, 
Virtual Endoscopy, Virtual Colonoscopy 1 Introduction Over the last decade, volume rendering techniques 
have grown rapidly, and currently are able to generate accurate results at in­teractive frame rates. 
As a result of this, a lot of research today focuses on using these rendering techniques for virtual 
screening of organs in the human body [7]. Often these organs have complex structures which require careful 
segmentation before they are .t to be screened. Thus, for accurate diagnosis of a patient, segmenta­tion 
plays a very important role. In addition, a speedy diagnosis could be crucial for these virtual techniques 
to be able to replace the contemporary techniques some day. Segmentation needs for the virtual screening 
techniques could range from simple thresholding to careful removal of unwanted ma­terial. Segmentation 
could also get complicated due to partial vol­ume effect, which can cause unwanted and non-existing surfaces 
to pop up during rendering. With our method, we eliminate this par­tial volume effect by detecting and 
eliminating all partial volume voxels. Our approach is a .exible one, and can be used for a variety of 
segmentation needs with little or no modi.cation. It combines the contemporary thresholding and .ood-.ll 
techniques with two new techniques, namely, segmentation rays and volumetric contrast enhancement. lsarang, 
mwan, mie, ari}@cs.sunysb.edu  We explain our segmentation algorithm using an example ap­plication of 
an upcoming virtual screening technique, Virtual Colonoscopy [3][4][9], which is being developed at the 
State Uni­versity of New York (SUNY) at Stony Brook. We now brie.y out­line the segmentation requirements 
of the virtual colonoscopy sys­tem and previous solutions before explaning our solution using our new 
method. 2 The Experiment The aim of virtual colonoscopy is to detect potentially cancerous growths in 
the colon, called polyps, by letting the doctor virtu­ally .y through the colon. This eliminates the 
need for the painful and highly uncomfortable optical colonoscopy exam that the pa­tient would otherwise 
have to go through. Early detection of polyps is important because their removal, before they get malignant, 
can completely cure the patient [8]. Polyps with a diameter of more than 5 mm are considered potentially 
malignant and need to be re­moved. Thus, the virtual colonoscopy aims at detecting the smallest of polyps. 
One problem with all current colonoscopy techniques is that they require a clean colon lumen for accurate 
detection of polyps. Resid­ual material inside the colon could be falsely interpreted as part of the 
colon in virtual colonoscopy, and in optical colonoscopy, it could hinder the movement of the camera 
and/or the doctor s view of the colon, with the chance that some polyps might remain unde­tected. Thus, 
as preparation for the colonoscopy, the patient under­goes a physical colon cleansing. This includes 
either washing the colon with large amounts of liquids or administrating medications and enemas to induce 
bowel movements. This colon preparation is often more uncomfortable and unpleasant than the colonoscopy 
examination itself. To make the virtual colonoscopy system even more friendly to the patient, it is necessary 
to bypass the physical cleansing of the colon. Thus, there is a need for segmenting the residual material 
out of the colon, giving a clean colon to the rendering algorithm. As a .rst step to accomplish this 
segmentation, a new bowel preparation scheme was developed at SUNY Stony Brook [5][10]. This helps segmentation 
by enhancing the stool and .uid (the residual material in the colon) densities. A CT scan of the patient 
s abdomen is then taken and recon­structed into a 3D dataset. The dataset obtained is much more com­plex 
than the one obtained with a pre-cleansed colon. The complex­ity arises because of the large amount of 
.uid and stool residing in­side the colon (Figure 1). Although these unwanted residues have been enhanced, 
they do not have a clear boundary due to partial volume effect. The situation is even worsened by the 
.nite resolu­tion and low contrast of the CT scanner. We now brie.y summerise the shortcomings of contemporary 
segmentation algorithms for this problem. Segmentation by thresholding The simplest segmentation approach 
is thresholding. The human Figure 1: Part of a colon as seen from a traverse slice. 200 150 Intensity 
100 50 0 Voxels Along Vertical Scan line Figure 2: Intensity pro.le at the boundary of air and .uid. 
 abdomen consists mainly of three distinct density regions: air, soft­tissue, and high density materials 
(which include the bone). A CT scan assigns different intensities to these materials and we classify 
them based on these intensities. For a physically cleansed colon, thresholding would be enough to accurately 
segment the colon for rendering in virtual colonoscopy [3][4]. However, with the new bowel preparation 
scheme, bones are not the only high density material present in the abdomen. Residual .uid and stool, 
which are enhanced with barium, also have CT image intensities similar to those of bone, thus complicating 
the segmentation. Although thresholding gives the fastest results, it has many disadvantages which we 
list below. First, thresholding does not remove partial volume voxels. Fig­ure 2 shows the intensity 
pro.le along a vertical line from top to bottom as shown in Figure 1. We observe that at the boundary 
of two regions with different intensities lie voxels, whose intensities do not match either of the two 
regions. We name these voxels the Partial Volume Effect (PVE) voxels. These voxels are undesirable since 
they are incorrectly classi.ed when thresholding is used. For example, in Figure 2, the voxels between 
the .uid and the air lie in the soft-tissue range. Hence, they are marked as soft-tissue voxels and would 
not be removed. The adverse effect on segmentation is immediately evident and is shown in Figure 3. Although 
the high density .uid/stool has been removed, a thin soft-tissue-like bound­ary still exists, which is 
not present in reality. Second, the thresholds for each range of intensities are very sen­sitive. A slight 
change to these thresholds could lead to a change in the outcome of the segmentation, especially the 
contour of the inner surface of the colon. Third, thresholding also gives rise to aliasing effects at 
the inner   Figure 5: A normal colonic mucosal surface without .uid or stool attached to it. colon 
boundary. It is immediately evident when we take a closer look at the segmented volume (Figure 4). The 
intensity values move sharply from soft-tissue range to air-range. This is undesirable from the point 
of view of the volume rendering. A sharp boundary also means the absence of colonic mucosa (a thin soft-tissue 
layer) that is present on the inner surface of the colon. Colonic mucosa is key to the detection of the 
polyps and hence its removal is undesirable. For comparison, we also show an example interior surface 
of the mucosa of the colon with no residual stool attached (Figure 5). Segmentation by morphological 
operations A succession of morphological operations, such as dilates and erodes, could also be used for 
segmentation [2]. For example, we could perform a .ood-.ll on all the .uid and stool regions, and then 
use a sequence of dilates and erodes to remove the PVE vox­els. However it is well known that dilates 
followed by erodes can H.ll in holes, and erodes followed by dilates can remove noise [2]. Thus, they 
could affect the inner contour of the colon, as it is highly twisted. This method would also require 
seed points to be placed in each and every region .lled with .uid or stool for performing the .ood­.ll. 
This could be a cumbersome task considering the large number of such regions. In addition, it may require 
a lot of human interven­tion. This could also slow down the entire process of segmentation and may result 
in some .uid/stool regions being neglected. Other segmentation approaches Recently, Liang et al. [6][10] 
reported three approaches to colon segmentation. The .rst two are very slow (3 hours and 30 minutes respectively 
on a Pentium II), which limit their clinical application. The third approach, which takes 6 minutes on 
a PC platform, gen­erates feature vectors for each voxel and then applies thresholding. Thus, the result 
may be dependent on strict thresholds, which is undesirable. Their approach also removes some colon mucosa 
vox­els which may result in the incorrect detection of polyps. Wyatt et al. [11] described another fully 
automatic segmentation, but their method does not aim at accuracy and is very slow (60-65 minutes on 
an SGI onyx). We now outline our algorithm for segmentation and digital cleansing. We then descibe at 
length how we use it to success­fully tackle the problems we described above for digital cleansing of 
the colon and how it can be applied to any situation with similar demands for segmentation. 3 Our Algorithm 
 The crux of our algorithm is based on the unique characteristic property at the interesection of two 
distinct-intensity regions. This unique characteristic is the intensity pro.le as we move in a direc­tion 
approximately normal to the intersecting surfaces. The main constituents of our algorithm are the use 
of segmenta­tion rays. These are named so because they assist in segmentation. When these rays traverse 
through the volume, they compare their intensity pro.le with some pre-de.ned ones. If the ray crosses 
an intersection between two regions in an approximately normal di­rection, it .nds a match and then performs 
certain tasks of classi­.cation and reconstruction at the intersection. Depending on the application, 
the rays can be programmed to detect certain speci.c intersections and perform certain speci.c tasks. 
This leads to a very fast and effective segmentation approach which can successfully get rid of the partial 
volume effect. The following is a brief description of the steps involved in our algorithm. We leave 
the implementational details to the next sec­tion where we show the application of our algorithm to solve 
the segmentation problems in virtual colonoscopy. The next section also describes how we automated each 
of these steps for the given application. Approximate intensity based classi.cation In this step, we 
approximately classify the intensity values in the histogram of the dataset into distinct regions. The 
classi.cation depends on the number and type of distict regions present in the dataset. An important 
point to note is that the region boundaries in the histogram are de.ned by approximate thresholds which 
are .exible. The unique intensity pro.les at different intersections are then studied and stored. Region 
growing The algorithm then takes a seed point lying inside a region which the user wants to segment. 
From this seed point, we use the naive region growing to mark all the voxels that belong to the selected 
region and which are connected to the start voxel, untill we reach voxels that no longer belong to the 
selected region. 6000000 4000000 Number of Occurrences 2000000 0 Intensity A I R PV1 TTAIR high ST low 
(ST) PV2 T highST F S B T lowFSB Figure 6: Histogram of the CT dataset. Selecting starting points for 
segmentation rays Before we go on to cast segmentation rays, we need to select vox­els from which these 
rays emanate. The selection of these voxels is critical to the overall speed of the algorithm. The fewer 
the vox­els, the faster the algorithm. Also, the nearer these voxels are to the intersection of different 
regions, the faster the rays detect inter­sections. The simplest and fastest strategy would be to assign 
the boundary voxels of the selected region as the starting points. Detecting intersections using segmentation 
rays After the starting points are selected, they are queued in. One by one these points are removed 
from the queue and from each point, segmentation rays are cast in all possible directions. The rays are 
alwaysdirectedinoneofthe26-connected-neighbordirections. We check which of the neighboring voxels does 
not belong to the se­lected region and cast a segmentation ray in that direction. Once a ray detects 
an intersection, it performs its given task and quits. The rays which do not .nd any intersection after 
traversing a certain distance are stopped and ignored. Volumetric contrast enhancement In the .nal step, 
the unwanted materials are removed from the vol­ume by applying a programmed transfer function. This 
process is similar to contrast enhancement in image processing. Using a smooth transfer function, we 
get unaliased boundaries which im­prove the quality of volume rendering signi.cantly. 4 Digital Colon 
Cleansing In this section we explain an example application of our algorithm. We use our algorithm for 
digitally cleansing the colon for virtual colonoscopy. We now show how we implemented each step of our 
algorithm and how we automated each of those steps to get a fully automatic segmentation. 4.1 Approximate 
intensity-based classi.cation A closer look at the histogram obtained from the dataset immedi­ately reveals 
two distinct-intensity regions (Figure 6). Region 1, which we call the AIR region, is on the lower end 
of the histogram. Voxels with intensities lying in this region are those that belong to air (from a prior 
knowledge of the CT intensities). This region can be characterized by just one threshold, T AR h i .. 
Region 2 includes intensities that make up the center of the histogram. We name this region the ST (for 
Soft Tissue) region. This region is characterized by two thresholds, TTTS Tloand TTTS T h i. The voxels 
with these intensities belong to the soft-tissue. Along with soft­tissue, this region also has some PVE 
voxels (some voxels at the intersection of the AIR and high intensity regions belong to this re­gion). 
There is also a third region, Region 3, which makes up the  Figure 7: Automatic location of seed points. 
 higher end of the histogram, and includes voxels which belong to .uid, stool and bones. We name this 
region FSB (for Fluid, Stool and Bone) and characterize it by a single threshold level, TTTTS Blo. Thus, 
we choose to broadly classify the volume into three main re­gions. We name the two regions which lie 
in between the three re­gions de.ned in the above classi.cation as PV1 and PV2 (for Partial Volume voxels). 
PV1 is characterized by two thresholds, TTAAT h i and TTS Tlo. It includes the colon mucosa voxels (mucosa 
is the thin layer on the interior side of the colon) and some PVE vox­els. Similarly, PV2 is characterized 
by two thresholds TTTS T h i .andTTTTS Blo. This region includes PVE voxels along with some stool voxels 
whose intensities are lowered because of the neighboring lower intensity voxels. The thresholds described 
above are automatically calculated from the histogram. The .rst two peaks in the histogram consti­tute 
the AIR voxels and hence we set T A. T h i .to the right of the second peak. The next two peaks are the 
ST voxels and we set TTSloand TTSh iaround them. Due to the lack of a peak in the histogram for FSB voxel 
intensities, we use prior knowledge of the contrast enhancing .uid and its intensity and assign it to 
TTTTS Blo. Since our algorithm does not depend on exact threshold values, the choice of above thresholds 
is .exible. 4.2 Region growing and start points for segmen­tation rays To detect and mark the interior 
AIR region of the colon, we need seed points that are de.nitely inside the colon. We have devised a simple 
strategy to automatically and accurately locate seed points. The basic idea is to look for an FSB region 
voxel and check if there is AIR immediately above it. If this condition is satis.ed, one of the AIR voxels 
is stored as a seed point. This strategy works accu­rately because the .uid, which is inside the colon, 
forms a smooth horizontal surface due to gravity (Figure 7). Hence, there is air on top of the .uid, 
and this air is de.nitely inside the colon. Any point inside this air can be the seed point for our algorithm. 
The only other high intensity material which is outside the colon, the bone, is surrounded by soft-tissues 
and the above condition will fail. The above strategy is implemented by going through each verti­cal 
scan-line and checking for the above condition. If a seed point is found, it is stored in an array. In 
the end, we have all possible seed points in the array. Next, we use some of these seed points to mark 
the interior of the colon by region growing. We now use region growing to get the boundary of the AIR 
re­gion. We use the naive dilate-and strategy to do the region growing. AIR Figure 8: AIR boundary detected 
by region growing. Figure 9: Four different types of intersections. To make this computationally ef.cient, 
we use a queue to store the voxels whose neighbors have not been explored. We start the region growing 
by placing the seed point in the queue. Now we explain the naive dilate-and strategy we use. In each 
iteration, the .rst voxel in the queue is removed and its neighbors are inspected. If a non-masked AIR 
voxel is found, it is inserted into the queue; if a masked AIR voxel is found, it is ignored; and if 
a non-AIR voxel is found, then the current voxel is marked as a boundary voxel and is stored in a boundary 
voxel (BV) queue. After all the neighbors are inspected, the current voxel is removed from the queue 
and is masked to indicate that it is processed. The iterations end when there are no more voxels left 
in the queue. We use the voxels in the BV queue as the starting point for segmentation rays. This gives 
the best results because the intersection of AIR with other regions is in the immediate neighborhood 
of these voxels. We use a 6-connection for detecting a neighboring, non-masked, AIR voxel, but a 26-connection 
for checking the boundary condi­tion. A 6-connection gives smaller queue lengths and is thus more ef.cient. 
A 26-connection for boundary detection increases the ac­curacy of our algorithm (Section 4.3). 4.3 Detecting 
intersections using segmentation rays Our next step exploits the peculiar characteristics at the intersection 
between AIR and the other regions, namely, ST and FSB. It is at these intersections that most of the 
PVE voxels occur and this step aims at removing them. This is an important step as it removes all the 
thin stool deposits and gives an improved contour to the colon, which is critical to the detection of 
the polyps. From the previous step (Section 4.2) we get all the voxels lying on therough contour of the 
colon (Figure 8) in the form of the BV hqueue. All the voxels which surround this AIR region belong to 
one of the following three types of intersections (Figure 9) : 1. AIR -ST intersection. 2. AIR -Fluid 
intersection. 3. AIR -Stool intersection.  We now differentiate between Fluid and Stool for two reasons. 
Firstly, since bone is not in the picture anymore, we cannot refer to the intersection as AIR -FSB. Secondly, 
a thin layer of stool is attached to the colonic mucosa at many places (Figure 9) and we choose to refer 
to such intersections as the AIR -Stool intersection. By Fluid we refer to relatively large high-intensity 
deposits which are mainly .uid (Figure 9). Characterizing the intersections We now need to characterize 
these intersections in order to dis­tinguish between them. The characteristic properties were formed 
from a careful study of the intensity pro.les at each intersection as we moved in a direction normal 
to the intersection. We show here the general intensity pro.les at each of the intersections and note 
their characteristics. The AIR -ST intersection 80 j S T 60 Intensity 40 20 0 Voxels  Figure 10: Intensity 
pro.le at AIR -ST intersection. In Figure 10 we show the intensity pro.le at the AIR -ST inter­section. 
From a careful analysis of this intensity pro.le we charac­terized the AIR -ST intersection by the following 
properties :  A gradual increase in the gradient as the intensities move from AIR to PV1 to ST and possibly 
to PV2.  After the .rst zero or negative gradient, the intensity value is still in the ST region. The 
intensities never reach the FSB region.  No more than one PV2 region voxel is present before the neg­ative 
or zero gradient. The AIR -Fluid intersection  A sharp rise in the gradient as the intensity values 
go from AIR to FSB.  An FSB voxel is reached within 3 voxels after the last AIR voxel. 150 100 Intensity 
50 0 Voxels The .rst negative or zero gradient does not bring the intensity value below the FSB range. 
The AIR -Stool intersection 100 80 60 Intensity 40 20 0 Voxels  From Figure 12 we characterize this 
intersection by the follow­ing properties : The intensity values sharply increase from AIR to PV2 or 
FSB. After the .rst negative or zero gradient the intensity value lies in PV2. An intersection is said 
to be found, when all the properties which characterize it are satis.ed. Our next step uses these characteristics 
to detect intersections. Casting segmentation rays We castsegmentation rays from each of the AIR boundary 
voxel (stored in the BV queue), outwards, in search of a matching char­acteristics. If the ray detects 
an intersection based on the above properties, then we perform a certain task that is associated with 
each type of intersection, or else the ray is simply ignored. To determine the direction of each segmentation 
ray originating from a voxel, we examine all its 26-connected neighbors. The ones that are marked as 
AIR are ignored and we cast rays in the direction of all other neighbors. For simplicity, we show this 
in 2-D (Fig­ure 13). The voxels marked A are the AIR voxels and those marked B are the AIR boundary voxels. 
We show rays sent from only one boundary voxel for clarity. Among all the rays, the ones that are most 
perpendicular to the intersection will most de.nitely detect it; others will be simply ignored. In Section 
4.2 we mentioned that we use 26-connection for checking if the AIR voxel is on the AIR boundary. By doing 
so, we avoid holes that would otherwise appear due to the lack of rays in some parts. To understand this, 
consider the dashed rays in Fig­ure 13. The voxels from which they originate will not be marked as the 
boundary voxels if we use 6-connection boundary checking, thus leaving holes. We now discuss the tasks 
we perform when a ray detects an in­tersection. The tasks mainly involve classifying the voxels into 
one of the three main regions (Section 4.1) and altering the intensity values to what they would have 
been in the absence of the residual .uid and stool. 80 60 Intensity 40 20 0 R A Y Figure 14: Classi.cation 
of voxels on the AIR -ST intersection. The AIR -ST intersection In this case we mark the last two voxels 
of the ray as the colon wall voxels and mark the voxels preceding them as the mucosa voxels (Figure 14). 
Colonic mucosa lies on the interior of the colon wall and hence we use such a classi.cation. An important 
point to note here is that we are not aiming at an accurate distinction between the colon wall and mucosa. 
We are only interested in an accurate inner contour of the colon which shows the polyps. The AIR -Fluid 
intersection Since our goal is removal of all Fluid voxels, we remove all the voxels on this intersection, 
thus eliminating all partial volume vox­els that resulted from the intersection. We remove the voxels 
by marking them as AIR voxels and assigning them an intensity value of TA.h i o(Figure 15). The removal 
of the remaining .uid vox­els is fairly simple because their intensities are in the FSB region and will 
be dealt with in the last step of our algorithm. The AIR -Stool intersection Due to the presence of high-intensity 
stool voxels, the thickness of the colonic mucosa increases. To overcome this problem and reconstruct 
the mucosa, we carefully remove the stool voxels along the ray and move the mucosa voxels ahead to their 
correct position. We show one example of the reconstruction in Figure 16. 150 100 Intensity 50 0  100 
80 Intensity 60 40 20 R A Y  By the end of this step of our algorithm, we have successfully removed 
all partial volume voxels that were in the PV1 region and some that were in the PV2 region. We are now 
left with all the high­intensity voxels of FSB range and the partial volume voxels on the Fluid -ST intersection. 
The .nal step handles these voxels. 4.4 Using volumetric contrast enhancement to re­construct mucosa 
and remove .uid 60 40 Reconstructed Intensity 20 0 607080906-. 666100110120Original Intensity  In the 
.nal step of our algorithm, we reconstruct the mucosa at the Fluid -ST intersection and remove the hight-intensity 
FSB vox­els that are still remaining in the dataset. We use a technique similar to the Contrast Enhancement 
used in image processing[1]. Since we extend it to a volume, we call it the Volumetric Contrast En­hancement. 
We show the contrast enhancing reconstruction graph . in Figure 17. The key idea behind this graph is 
that if a voxel on the Fluid -ST intersection has an intensity closer to the FSB region, then the probability 
of that voxel being an FSB voxel is very high. The lower intensity of the probable FSB voxel is attributed 
to the effect of the surrounding low intensity voxels. Thus, the closer the voxel intensity is to the 
FSB region, the lower the reconstructed intensity will be (since we are aiming to remove the FSB voxels). 
Simi­larly, a voxel with an intensity closer to the ST region will have a reconstructed intensity closer 
to the average ST intensity. This reconstruction graph can be implemented by a simple lookup table taking 
just one pass through the dataset. Thus, this step is extremely fast. We prefer the curve over a straight 
line to increase the contrast between the two regions without aliasing effects. This results in smoother 
and more accurate images from volume rendering.  5 Results Our segmentation algorithm was tested for 
the virtual colonoscopy system and now, is an integral part of its preprocessing pipeline. By doing automatic 
histogram classi.cation and seed point detec­tion, the algorithm gave a fully automatic solution to segmentation 
and digital colon cleansing. We tested the algorithm on a variety of datasets. We use one of the datasets 
of size 512x512x411 to demon­strate the results. Since the patient did not undergo any physical colon-cleansing 
prior to the scan, there was a signi.cant amount of residual .uid inside the colon. A thin layer of stool 
was found to be attached to the colonic mucosa in many places. Our algorithm removed all the .uid and 
stool voxels accurately (Figures 19 and 20). Our method was able to detect and remove stool deposits 
as thin as one voxel thick which is about 0.7 mm. We were also able to unearth all the mucosa voxels 
lying below the .uid at the intersection of .uid with the colon wall. Due to the mucosa voxels, there 
was no aliasing effect at the newly detected interior surface of the colon (Figure 18). Since the crux 
of our algorithm -characterizing the intersections -is done by our cognitive skills, we claim that our 
algorithm gives just as accurate a result as a manual segmentation. In fact, since we do not miss even 
a single intersection, our algorithm could be better than manual segmentation. The total time for the 
whole segmentation process for the se­lected dataset was 58 seconds on an SGI Onyx2 (R10000, 195MHz) 
and 35 seconds on a Linux PC (AMD Athelon, 750 MHz). This is the fastest time reported for colon segmentation 
which also includes digital cleansing. This paper showed the application of our segmentation algorithm 
for virtual colonoscopy. The algorithm, or its parts, could be used for any application requiring a similar 
complex segmentation. It will be especially useful when there are partial volume effect con­cerns. 6 
Conclusion and Future Work In this paper we have described an algorithm for fast and accurate segmentation 
with the ability to remove the partial volume effect. This algorithm is a very general algorithm which 
can be used by any application with segmentation requirements similar to those of virtual colonoscopy. 
In the future work, we plan to build an interactive segmentation system based on our algorithm in which 
the user can interactively con.gure all the parameters required by the algorithm. This will include the 
ability to pick intersection characteristics using a mouse and assigning classi.cation/reconstruction 
tasks to the rays that .nd a perticular intersection. Since the algorithm is extremely fast, we also 
plan to add visual feedback by rendering and displaying the segmented dataset after each operation by 
the user.  Acknowledgements This work has been supported by grants from NIH #CA79180, ONR #N000149710402, 
and Viatronix Inc. The patient s datasets were provided by the University Hospital of the State University 
of New York at Stony Brook. Special thanks to Klaus Mueller and Kevin Kreeger for the encouraging discussions. 
We thank Frank Dachille and Kathleen McConnell for their helpful comments on the draft of this paper. 
 References <RefA>[1] <SinRef><author>R. Gonzales</author> and <author>R. Woods</author>, Digital Image Processing, Addison-Wesley 1992</SinRef>. [2] <SinRef><author>K.H. Hohne </author>
and <author>W. Hanson</author>. <title>Interactive 3D Segmentation of MRI and CT Volumes using Morphological Operations</title>, <journal>Jour­nal 
of Computer Assisted Tomography</journal>, <volume>16(2)</volume>:<pages>285 294</pages>, <date>March 1992</date></SinRef>. [3] <SinRef><author>L. Hong</author>,<author> A. Kaufman</author>, <author>Y. Wei</author>, <author>A. Viswambharan</author>, 
<author>M. Wax</author>, and <author>Z. Liang</author>, <title>3D Virtual Colonoscopy </title><booktitle>Proc. Symposium on Biomedical Visualization</booktitle>, pp. <pages>26 32</pages>, 
<date>1995</date></SinRef>. [4] <SinRef><author>L. Hong</author>,<author> S. Muraki</author>, <author>A. Kaufman</author>, <author>D. Bartz</author>,<author> T. He</author>, <title>Virtual Voyage: Interactive Navigation in 
the Human Colon</title>, <booktitle>Proc. SIGGRAPH </booktitle><volume>97</volume>, pp. <pages>27 34</pages>, <date>1997</date></SinRef>. [5] <SinRef><author>Z. Liang</author>, <author>F. Yang</author>, <author>M. Wax</author>, <author>J. Li</author>, <author>J. You</author>, <author>A. 
Kaufman</author>, <author>L. Hong</author>, <author>H. Li</author>, and <author>A. Viswambharan</author>, <title>Inclusion of A Priori Informa­tion in Segmentation of Colon 
Lumen for Virtual Colonoscopy</title>, <journal>Conf Record </journal><publisher>IEEE NSSS-MIC</publisher>, CD-ROM, <date>1997</date></SinRef>. [6] <SinRef><author>Z. Liang</author>, <author>D. Chen</author>, <author>R. Chiou</author>, 
<author>B. Li</author>, <author>A. Kaufman</author>, and <author>M. Wax</author>, <title>On Segmentation of Colon Lumen for Virtual Colonoscopy</title>,<booktitle> Proc. SPIE Medical 
Imaging</booktitle>, <date>1999</date></SinRef>. [7] <SinRef><author>W. Lorensen</author>, <author>F. Jolesz</author>, and <author>R. Kikinis</author>, <title>The Exploration of Cross-Sectional Data with 
a Virtual Endoscope, Interactive Technology and the New Medical Paradigm for Health Care</title>, eds. <editor>R. Satava </editor>
and <editor>K. Morgan</editor>, pp. <pages>221 230</pages>, <date>1995</date></SinRef>. [8] <SinRef><author>J. Mandel</author>, <author>J. Bond</author>, <author>J. Church</author>, and <author>D. Snover</author>, <title>Reducing Mor­tality 
from Colon Cancer Control Study</title>, <journal>New England J Med </journal><volume>328</volume>, pp. <pages>1365 1371</pages>, <date>1993</date></SinRef>. [9] <SinRef><author>M. Wan</author>, <author>Q. Tang</author>,<author> A. 
Kaufman</author>, <author>Z. Liang</author>, and <author>M. Wax</author>, <title>Vol­umeRendering Based Interactive Navigation Within The Hu­ u man Colon</title>, 
<booktitle>Proc. IEEE Visualization </booktitle><volume>99</volume>, pp. <pages>397 400</pages>, <date>1999</date></SinRef>. [10] <SinRef><author>M. Wax</author>, <author>Z. Liang</author>, <author>D. Chen</author>, <author>B. Li</author>, <author>R. Chiou</author>, <author>A. Kaufman</author>, 
and <author>A. Viswambharan</author>, <title>Electronic Colon Cleansing for Vir­tual Colonoscopy</title>, <journal>1Ss Intl Conference on Virtual 
Colonoscopy</journal>, <location>Boston, MA</location>, <date>October 1998</date></SinRef>. [11] <SinRef><author>C.L. Wyatt</author>, <author>Y. Ge</author>, and <author>D.J. Vining</author>, <title>Automatic Segmentation 
of the Colon</title>, <booktitle>Proc. SPIE Medical Imaging</booktitle>, <date>1999</date></SinRef></RefA>. (a) (b) Figure 19: A cross-section of the CT data showing 
colon (a) before segmentation, and (b) after segmentation.  (a) (b) Figure 20: Volume rendered images 
showing (a) presence of .uid before segmentation, and (b) .uid removed after segmentation.  
			
