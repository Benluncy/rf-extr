
 Algorithms for Compile-Time Memory Optimization Jordan Gergov Max-Planck Institute for Computer Science 
 Abstract Given a program P in a structured programming language, we propose the first polynomial-time 
algorithm for compile- time memory allocation for the source objects of P (eg ar- rays, C structures) 
with a performance guarantee. Further, we present a new and simple O(n log n) time bapproxima- tion algorithm 
for (off-line) Dynamic Storage Allocation and, thus, improve the best previous approximation ratio of 
5. 1 Problem Motivation and Definition Consider the following simple fragment of a C function: foo(int 
i) { char A[40]; intB[lO];if(i){...}else{... } }. The dots in the i !=O (resp. i==O) branch of the if 
statement denote a C block without read or write access to the array B (resp. array A), ie either only 
A or only B is needed at run time. Assume that an int (char) is represented by 4 (1) bytes. Now, let 
us slightly simplify the compile-time memory allocation task and ask: how much storage does the compiler 
need to allocate for the arrays A and B ? First, the compiler can use two non-overlapping storage areas 
for A and B, ie 40 + 10.4 = 80 bytes. Alternatively, the compiler could find out that A and B will never 
exist at the same time when the program is running. Hence, a storage area of 40 bytes is sufficient for 
both arrays, and the first solution can be improved by a factor of 2. In general, given a source program 
.the compiler can use control-flow analysis and similar techniques to determine pairs of (source-code) 
objects such that the compiler is allowed to map the objects in each pair to overlapping memory regions. 
Now, assume that we have derived the following information from a program in a structured programming 
language: (1) the set of all (source-code) objects and their memory requirements; (2) a set of pairs 
of objects such that the objects in a pair cannot interfere with each other at run time and, hence, can 
share memory; (3) the associated control-flow graph, and, for any object, the vertices of the control-flow 
graph (ie source-code statements) at which the object is accessed as well as the associated access type 
information. Then, the Compile-time Memory Max-Planck Institut ftir Informatik, Im Stadtwald, 66 123 
Saarbriicken, Germany; E-Mail: gergov@mpi-sb.mpg.de AZlocation problem (CMA) is to compute a mapping 
from objects to memory regions such that: (1 ) the size of the memory region that is allocated to an 
object equals the memory requirement of that object; (2 ) if two memory regions overlap, then the associated 
object pair is in the set of object pairs that are allowed by (2) to share memory; and (3 ) the memory 
usage is minimized. The trend towards more complex embedded systems increases the interest in memory 
optimization tools, and CMA algorithms are also potentially useful in optimization of software with a 
high memory demand. The performance of all previous heuristics for this NP-hard task can deviate significantly 
from optimality, cf [l]. In Section 3, we discuss a novel approach to fast CMA algorithms with a performance 
guarantee. Fabri [l] gives a more detailed treatment of the CMA definition as well as an account of previous 
research. One special case of CMA with an independent research history as well as with numerous applications 
is the off-line Dynamic Storage Allocation (DSA). Assume that we are given a straight-line program, ie 
its source code does not contain branch or loop statements and, for ease of presentation, no function 
calls. It turns out that in this case CMA has a nice geometric interpretation. A DSA input I consists 
of n triples of numbers, ie I= {(Sl,~l,C1)7-.-, (sn,m,c,.,)}. Each triple (s~,Q,c~) can be interpreted 
as an axis-parallel rectangle with a projection (ri,ci) on the z-axis and a projection of length si on 
the y-axis. We are only allowed to slide the rectangles along the y-axis while the s-projections of all 
rectangles stay fixed as in the input I. The objective is to pack all rectangles in a horizontal strip 
of minimum height. Intuitively speaking, (Si, Ti) Ci) is associated with a source-code object that is 
used only between the rith and the c&#38;h statement and requires Si contiguous memory cells. The previous 
research on fast DSA algorithms with a performance guarantee was based on on-line coloring, and results 
were obtained independently by Woodall, Kierstead, Chrobak, and Slusarek, cf [2] for references. The 
best approximation ratio of 5 for this NP-hard problem is based on a different approach and is due to 
Gergov [2]. In the remaining sections, we give a rather condensed presentation of our results. 5908 
2 Dynamic Storage Allocation Given a DSA instance I={(sl,rl~cl):. . :(sn,r,:cn)}, a solution to I is 
a mapping Q from I to the nonneg-ative reals o:I--tRz, such that if (ri; ci)n(rj, cj)#O, then either 
i=j or o((s~,T~:c~))+s~~Q((s~:T~:c~)) or a((Sj; Tj, Cj))+Sj_<cY((S,: Ti, Ci)). The cost of Q is defined 
as maxk(o((sk:rk,cI;))+sI;:r. Geometrically speaking, o maps each rectangle to the y-coordinate of its 
lower side. The algorithm described below is based on the concept of 2-allocation, cf [2]. It first constructs 
an infeasible mapping cy that is then transformed into a feasible so lution cr to I. Incremental 2-Allocation 
Construction (MC): Initially, we set: J to the input I; H (an auxiliary set of triples) to { (0, mini 
ri7 mmj cj)}; and CX (a mapping from a set of triples to RIO) to the empty-domain mapping. while(J # 
0) { pick ( w,zr,zr) E H such that w is minimal among all triples in H and delete it from H; if ( there 
exists (s: r, c) E J s.t. (r, c) n (zl, q) # 0 and, for all (w ,zi,z;) E H. (T,c) n (z;,z:) = 0) { pick 
and delete from J the (s,r,c) in the if test; set a ((s,r,c)) to w; insert (w + s, max(zl,r), min(c, 
2,)) into H; if (2r < r) { insert (w,z~,r) into H; > if (c < 2,) { insert (w,c,zr) into H; 3 3 //if 
 3 //while At this point, we have constructed a mapping a from I to RX. Now, define G(V,E) by V=I and 
E={(vi,vj)l i # 7, (Ti,Ci) fl (Tj,Cj) $ 0 # (Ol (Vi)yQ (Vi) + Si) n (o (Vj),aC (Vj) + Sj)} where vk denotes 
(sk,rk,ck)EI-Order (s,r, C)EV in the same order as they have been deleted from J, and construct a coloring 
f:V+{O, 1,. . .) of G by means of First Fit. Finally, output cu:l-+$e where a(ui)=o (vi)+f(vi) mtij(o 
(uj) + sj). // end Our C++ implementation of IAC has O(n logn) running time and handles a few thousand 
triples in less than one second on a SUN SPARC 4. THEOREM 2.1. Given a DSA instance I, the IAC algo-rithm 
builds a solution Q to I of cost not exceeding 3 times the optimum cost in O(nlogn) time. 3 Compile-Time 
Memory Allocation In this and the next sections, the definitions of the notions in Sans Serif are standard 
and can be found in the technical literature, cf [l] and [2]. Let us also point out that the control-flow 
analysis is not part of CMA: poor analysis wiIl produce a CMA instance with a short list of objects allowed 
to share memory, and, hence, there will be less opportunities for memory optimization. Now, assume that 
F(I) is the control-flow graph of a CM.4 instance I. As it is shown in [l], each (source-code) object 
is associated with some of the vertices of F. Intuitively speaking, if an object is not associated with 
a specific vertex: then it does not need to be maintained at this vertex. We modify the instance 1 so 
that the following property holds: (con) the vertices each object is associated with induce a connected 
component in the undirected graph corresponding to F(1). The property (con) is crucial to Theorems 3.1 
and 3.2. The conflict graph G(1) of the ChlA instance .I is the graph whose vertices are the (source-code) 
objects, and there is an edge between two objects iff there is a vertex v of the control- flow graph 
F(I) such that both objects are associated with v. We can view the control-flow graph F(I) of a program 
in a structured programming language as a series parallel (S.-P.) graph by introducing dummy vertices 
and doing some edge reversals. Note that the CMA definition assumes a program in a structured programming 
language. The nesting depth d(S) of a single vertex S.-P. graph S is I by definition. If an S.-P. graph 
S is the series (parallel) composition of two s-p. graphs Sr and &#38; , then its nesting depth d(S) 
is defined as m=4d(Sd,d(Sd) (m=(Wd, d(W) + 1). THEOREM 3.1. Let I be an instance of CMA. Given any weighting 
of the vertices of G(I), a maximum weighted clique of G(I) can be built in polynomial time. We obtain 
the next result using decomposition tech- niques and a procedure closely related to IAC. THEOREM 3.2. 
Let F be the control-flow graph of a CMA instance I. A solution to I of cost at most 3-d(F) times the 
optimum can be computed in polynomial time. 4 Conclusion We can view Theorems 2.1 and 3.2 as positive 
results about the approximability of the NP-hard interval col-oring problem of two classes of intersection 
graphs, ie of interval graphs and of intersection graphs related to CMA. Our approximation results are 
based on the con-struction of suitable infeasible solutions, cf 2-allocations in [2], and on coloring 
of specific intersection graphs. As the next result shows, our approach can be used to de- signapproximation 
algorithms for different intersection graph classes as well. THEOREM 4.1. Given a weighted unit-disk 
graph, an interval coloring of cost at most 7 times the optimum can be constructed in linear time. References 
3.<RefA> <SinRef><author>Fabri</author>, <title>Automatic storage optimization</title>, <journal>ACM SIG- 111 PLAN Notices</journal>, <volume>14 (8), </volume><date>1979</date>, pp. <pages>83-91</pages></SinRef>. <SinRef><author>J. Gergov</author>, 
<title>Approximation algorithms for dynamic stor- PI age allocation, European Symposium on Algorithms (ESA 96), 
</title><publisher>Springer</publisher>, <journal>LNCS </journal><volume>1136</volume>, <date>1996</date>, pp. <pages>52-61</pages>. 
</SinRef></RefA>			
