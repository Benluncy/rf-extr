
 Tighter Lower Bounds for Nearest Neighbor Search and Related Problems in the Cell Probe Model Omer 
Barkol* Yuval Rabanit Abstract We prove new lower bounds for nearest neighbor search in the Hamming cube. 
Our lower bounds are for ran- domized, two-sided error, algorithms in Yao's cell probe model. Our bounds 
are in the form of a tradeoff among the number of cells, the size of a cell, and the search time. For 
example, suppose we are searching among n points in the d dimensional cube, we use poly(n, d) cells, 
each containing poly(d, log n) bits. We get a lower bound of ~2(d/log n) on the search time, a significant 
im- provement over the recent bound of ft(log d) of Borodin et al. This should be contrasted with the 
upper bound of O(loglogd) for approximate search (and O(1) for a decision version of the problem; our 
lower bounds hold in that case). By previous results, the bounds for the cube imply similar bounds for 
nearest neighbor search in high dimensional Euclidean space, and for other ge- ometric problems. *Computer 
Science Department, Technion --IIT, Haifa 32000, Israel. Work .partially supported by the Milton and 
Lillian Ed- wards Fellowship. Emaih omerbOcs, techns-on, ac. 5.1. t Computer Science Department, Technion 
-- IIT, Haifa 32000, Israel. This work was supported by grant number 386/99-1 of the Israel Science Foundation 
founded by the Israeli Academy of Sciences and Humanities, by the N. Haar and R. Zinn Research Fund, 
and by the Fund for the Promotion of Research at the Technion. Emaih rabani~cs.technien.ac.il. Permission 
to make digital or hard copies of all or part of this work for personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage mid that copies 
bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on 
servers or to redistribute to lists, requires prior specific permission and/or a fee. STOC 2000 Portland 
Oregon USA  1 Introduction Problem definition and motivation. This paper is con- cerned with nearest 
neighbor search (NNS), a funda-mental problem in computational geometry, with ap-plications to a variety 
of areas [16, 21, 18, 34, 17, 23, 15, 33, 20, 24, 35, 9, 22]. The problem is defined as follows: In some 
vector space endowed with a distance function (typically a d-dimensional Euclidean space), we are given 
a set of n points (called the database). Given any other point (called a query), we must find the clos- 
est point to it in the database. We have to pre-process the database efficiently and create a data structure 
that will support efficient search. More specifically, the triv- ial data structure storing the unprocessed 
list of points allows us to search spending O(nd) arithmetic opera-tions. A challenging goal is to design 
a similar sized data structure reducing the search time to poly(d, log n) (or, in fact, to anything polynomial 
in d and sub-linear in n). The problem (in Euclidean space) is a special case of point location in an 
arrangement of hyperplanes. As such, it has been studied extensively, especially in low dimension, where 
good solutions are known (see, for ex- ample [10]). However, the combinatorial complexity of arrangements 
grows exponentially with the dimension, rendering the problem seemingly intractable. Indeed, following 
a long list of contributions [19, 13, 37, 29, 1, 30], currently the best algorithms can find a nearest 
neighbor in time poly(d, logn), but they need exponen- tial (n O(d)) storage. On the other hand, there 
is little evidence in the form of concrete lower bounds to sup- port the curse of dimensionality conjecture 
[14]; i.e., the belief that in high dimension the problem is indeed intractable (see below for more details). 
Our results. We present here significant improvements over recently discovered lower bounds for nearest 
neigh- bor search [11]. Specifically, our main concern is nearest neighbor search in the d-dimensional 
Hamming cube. As previously observed [11], lower bounds for the cube imply lower bounds for geometric 
settings, such as gd (JR d with distances measured by the L p norm) for all 1 < p < co, as well as for 
related geometric problems. We prove lower bounds in Yao's cell probe model [36]. In this model, the 
database is pre-processed into s cells, each containing b bits. A search algorithm sequentially (and 
possibly adaptively) reads the contents of at most t cells to get the correct answer. In [11] it is proven 
that ~a randomized two-sided error cell probe algorithm that is restricted to use poly(n, d) cells of 
size poly(d, log n) each, must probe at least gt(logd) cells. Here, we im- prove this bound to f~(d/logn). 
In fact, as in [11], we actually show tradeoffs among the three parameters s, b, and t, as follows. 
Theorem 1. Assuming d E w(logn) A n°(1), ~ for any cell probe algorithm for NNS in the d-dimensional 
Ham- ming cube that uses s cells of size b each, and probes at most t cells, the following holds: either 
s = 2f~(d/t); or, b = na(1)/t. We note that similar bounds were shown in [11] for de-terministic algorithms. 
Our results are best contrasted with the bounds for approximate nearest neighbor search in the cube. 
In this version of the problem, the search algorithm is required to find a database point whose distance 
to the query is within a factor of 1 + ~ of the distance to a nearest neighbor, where e > 0 is a predefined 
value. The best available (randomized) algorithm, fol- lowing a long line of work [5, 14, 6, 27, 26, 
28], uses (for an arbitrary constant e, when stated in terms of the cell probe model) poly(n, d) cells 
of size O(d) each, and searches probing O(loglogd) cells. This random- ized upper bound nearly matches 
a recent determinis- tic lower bound of f~(log log d~ log log log d) [12], which holds even for very 
poor approximation. It is worth noting that better upper bounds hold for approximate A-neighbor (AN), 
a decision version of nearest neighbor search. In this problem, the search algorithm should an- swer 
"yes" iff there is a database point within distance at most A from the query. In the approximate version, 
if the nearest neighbor is at distance in (A, (1 + ~)A), then the algorithm may answer either "yes" or 
"no," and otherwise it should behave as in the exact ver-sion. The above-mentioned upper bounds for approx- 
imate nearest neighbor search work by reduction to al- gorithms for approximate A-neighbor that probe 
O(1) cells. Our lower bounds (like those in [11]) are proven for A-neighbor. Thus, we exhibit a very 
sharp con-trast of f~(d/logn) versus O(1) between the search time complexity of randomized, two-sided 
error, algorithms for exact A-neighbor versus approximate A-neighbor, re- spectively. We further note 
that by probabilistic argu- ments one can show the existence of a data structure with p01y(n, d) cells, 
each with poly(d, logn) bits, that allows us to find an approximate nearest neighbor de- terministically 
in poly(d, log n) probes [28, 25]. 1Notice that if d is outside this range, the problem in the cube becomes 
trivial. Unlike the randomized lower bound in [11], our re- sults do not hold for exact partial match. 
In this prob- lem queries may contain "don't care" bits (marked by *) that match both a zero and a one. 
A search should find a database point that precisely matches the query. There is an easy reduction from 
exact partial match to NNS (but not necessarily the other way around). We are able, however, to extend 
our results to partial match A-neighbor. In this problem the search should find whether or not there 
is a database point within distance A of a partial match query. Obviously, a lower bound for AN implies 
a lower bound for this problem, because queries may be void of don't cares. We show that our lower bounds 
hold even if the number of ex- posed bits k (i.e., bits # *) is fixed to any value in ft(d). We get Theorem 
2. For every constant p, 0 <p _< 1, as-suming d E w(log n) N n °(1) and k = pd, there exists A such that 
for any cell probe algorithm for partial match A-neighbor that can handle queries with exactly d -k don't 
cares, which uses s cells of size b each, and probes at most t cells, the following holds: either s = 
2f~(d/t); or, b = na(1)/t. The hidden constants in the lower bound decrease as k decreases. Indeed, notice 
that a solution the prob- lem with k = p]d can be reduced to the problem with k = p2d, for Pl _< P2 (the 
reduction is similar to the re- duction from exact partial match to NNS). Due to lack of space, the proof 
of Theorem 2 is omitted from this extended abstract (see [7] and the full version of the paper for a 
proof). Our methods. We prove our cell probe lower bounds via lower bounds in the asymmetric communication 
com- plexity model. In this model the input is split between two communicating parties, Alice and Bob. 
Alice gets the query, and Bob gets the database. Their goal is to compute a function of the entire input, 
the result of AN in our case. To do that, they may exchange bits. The complexity measure is the total 
number of bits commu- nicated by each side. A protocol where Alice sends a bits and Bob sends b bits 
is called an [a, b]-protocol. In a randomized protocol, Alice and Bob have access to a source of random 
bits, which may affect the protocol. The connection between the communication com-plexity model and the 
cell probe model is given by the following lemma due to Miltersen [31]: Lemma 3 (Miltersen [31]). For 
any function, if there is a (randomized) solution in the cell probe model with parameters s, b and t, 
then there is a (randomized) [t [log s], tb]-protocol for the communication problem. Thus, in order to 
prove lower bounds in the cell probe model, we exhibit lower bounds for the communication complexity 
of AN. For that, we appeal to the richness technique of [32]. It calls for showing that while a large 
389 fraction of the possible inputs produce a one value, ev- ery large sub-matrix of the communication 
matrix con- tains many zero values. As previously observed, the communication matrix for AN contains 
many large one- monochromatic sub-matrices, regardless of the value of A. However, we show that for a 
judicious choice of A, this is not the case for the complement function. The main idea underlying the 
proof is that if we take two query points that are about d/2 apart (in Hamming distance), then for a 
random database point the two dis- tributions of the distances to the query points behave somewhat independently. 
(The precise bound, as well as the details of the richness technique, appear below in Section 2.) We 
note that our cell probe time lower bounds are asymptotically the best possible to derive using communication 
complexity. (Yet our communica- tion complexity lower bounds could still be improved on the database 
side.) As observed in [32], proving stronger lower bounds in the cell probe model would imply non- linear 
lower bounds for Boolean branching programs. The converse is not necessarily true; and, to the best of 
our knowledge, recent breakthroughs in branching programs lower bounds [8, 2, 3] do not seem to apply 
directly to our problem. Additional remarks. For a more comprehensive sur-vey of the relevant literature, 
including previous lower bounds in algebraic and other concrete settings, as well as previous results 
on the cell probe model, see [11] and the references therein. Preliminaries Let Cd denote the d-dimensional 
binary cube {0, 1} ~. For p, q E Cd, let H(p, q) denote the Hamming dis- tance between p and q (i.e., 
the number of coordinates in which they differ). Definition. Let A E [0, d]. Let p, q ECd. We say that 
q is a A-neighbor of p (and vice-versa) iff H(p, q) <_ A. Let D C Cal. We say that q is a A-neighbor 
of D iff there exists p E D such that q is a A-neighbor of p. For q E Cd, we denote by B~ (q) the set 
of all A-neighbors of q. A two-party boolean (asymmetric) communication problem is specified by two input 
sets X and Y, and a boolean function f : X × Y --* {0, 1}. Informally, one party (Alice) gets an element 
x E X, and the other party (Bob) get an element y E Y. Their goal is to compute f(x, y) by exchanging 
as few bits as possible according to a specified protocol. The communication complex-ity of the problem 
is the number of bits transmitted by each side. In a probabilistic protocol, the sides can use random 
bits to determine the protocol. For every input, the output is correct with a certain probability. A 
two sided error protocol returns the correct output with probability at least 2/3. An [a, b]-protocol 
for the communication problem is a sequence of bit transmis- sions alternating between Alice and Bob, 
where the total number of bits Alice sends is at most a and the total number of bits Bob sends is at 
most b. It is convenient to specify a communication problem by its communi-cation matrix. The rows of 
the matrix are labeled by the elements of X, and the columns are labeled by the elements of Y. An entry 
labeled (x, y) has value f(x, y). We are interested in the A-neighbor problem (AN), where X = Cd, Y 
is the set of all n-tuples (yl, y2,..., yn) E C~, 2 and forx E X, yE Y, f(x,y) = 1 iffxis aA-neighbor 
of y. We call an element of X a query, and an element of Y a database. Abusing notation, we denote the 
function f by AN. We denote the complement of AN by nAN (again, abusing notation, this is both a problem 
and a function). Notice that for two sided error proto- cols, lower bounding the communication complexity 
of a problem is equivalent to lower bounding the communi- cation complexity of the complement problem. 
In order to derive asymptotic bounds, we consider an infinite se- quence of such problems, for increasing 
values of n and d = d(n). We assume that d E w(log n) N n °(1). In order to derive our lower bounds, 
we use the fol- lowing definition and lemma due to Miltersen et al. [32]. Definition. A communication 
problem f : X x Y --~ {0, 1} is a-dense if I{(x,y) E X × Y;f(x,y) = 1}1 > a. I x × Yt The following 
lemma presents the richness technique of Miltersen et al. for two sided error protocols. Lemma 4 (Miltersen 
et al. [32]). Let a, ~ > 0. Let f : X ×Y--* {0,1} be an a-dense problem. If f has a randomized two sided 
error [a, b]-protocol, then the communication matrix for f contains a sub-matrix M of dimension at least 
  IXl IYl --X -- 2o(a) 20(a+b) ' such that the fraction of zero entries in M is at most ~. (The hidden 
constants depend only on a and j3.) []  3 Lower Bounds for A-Neighbor The purpose of this section is 
to prove the following lower bound on the communication complexity of nAN. This, in turn, implies Theorem 
1 giving time/space trade- offs for nearest neighbor search. In what follows we de- note'y = ~ ~ 2.885, 
and put A = d_cv/-dT~gn, where C ~ ~ is defined below. 2We allow multiple copies of the same point in 
order to simplify the analysis. Our results hold without substantial changes if the n points must be 
distinct. Theorem 5. For every e > 0 there exists 5 > 0 such that the following holds. If there is a 
two sided error [a, b]-protocol for nAN;then, either a > ~d or b >_ n 6. (As c goes down to 0, 5 goes 
up to ~.) The rest of this section is devoted to the proof of this theorem. We begin with some properties 
of balls and intersections of balls in the cube. Claim 6. Let q E Cd. Then, n-('Y+v)C22d < ]Bx(q)] < 
n-(n-v)C22d, v = u(n) is monotonically decreasing in n, and moreover limn-.o~ u(n) = 0. For intuition, 
consider a uniform distribution over Cd. If p is a random point from this distribution, then the expected 
distance H(p, q) is d. Hence, by the Cher- noff bound (see, e.g., [4]), Pr[H(p,q)_< A] = Pr H(p,q) <_ 
~-C < e-(O lov'r~)' _C 2 < n , and therefore IB~(q)l <_ n-°22 e. Proving the tighter bounds stated in 
the claim requires estimating the bi- nomial distribution directly (using Stirling's formula): Proof. 
We first prove the lower bound. A i=0 Recall that by Stirling's formula v/'~'-k(k/e) k < k! < (1 + 1/4k)~(k/e) 
k. Thus we have -A~ (d -A)~ >-  ¢~ + 6/¢~/~. ¢~(~- ~)(~ + 4(~-~_~ )¢~/~-~ 2(d+1/2) log d-(A+I/2) log 
A-(d-A+1/2) log (d-A) 2(d+1/2) logd- (A+l/2) log A-(d-A-l-l/2) log (d-A)-4 (1) We now explore the exponent. 
Because A --d C v.d.i..~g n, 2 Using the Taylor expansion for ln(1 -x) we have --O where the last term 
follows from the fact that d E w(log n). Similarly, log(d-A) =log( d + C dlv/-d]-o--~) = and Assigning 
into the exponent in (1) we get log ~TwW 7 7tJ 7 +°  1 (d) (d) = d log d + ~ log d - d log -log - 3,G 
'2 log n + o(log n) = 1 d - 7C 2 log n -~ log d + o(log n). Because d E n °(1), there exists u > 0, 
where u --+ 0 as n ~ c~, such that 1 log d - o(log n) < uC 2 log n Hence, the term in (1) is at least 
2~/-9'C 2 log n-(1/2) log d+o(log n) ~_ 2d-('V+u)C ~ log n Hence, IBA(q)I _> n-(~'+~')O22d. On the other 
hand a similar argument gives the upper bound. In this case, we use i=0 By the Stirling formula, :~ = 
~:~ (d -~)! d <- -2 (_D . ~_ 21og(d/2)2(d+l/2) logd-(A+i/2) logA-(d-A+l/2) log (d-A) Using similar arguments 
as for the lower bound, and the fact that we can set u so that 1 log d + o(log n) _< uC 2 log n, we get, 
.~(d) ~_2d_(.r_u)C21ogn. Hence, [] Lemma 7. Let 0 < u < V. For all sufficiently large n there exists 
C, 1/v/~ + u < C < 1/~, for which 2din <_ IB~(q)I < 2d+l/n. (Recall that A depends on C.) Proof. By Claim 
6, for C = 1 ~/7-u' n-(7+~)/('r-")2 d < IB~(q)l < n-12d; and for C -1 n-12 d < IBA(q)I <_ n-(~-~)/(~+')2 
d. If we could claim for continuity of the size of B~ (q) we could claim that there is a C for which 
the size is exactly n-12 d. Instead, we show that by increasing the radius of a ball by one, the volume 
will not increase by more than twice, and from that the lemma follows. We show that if we increase the 
radius by one to be x, with x = o(d), the volume of the ball at most oubles, as To see this, notice that 
 >(d+x+O(d+x+2 ), as d 2 d2 o(d 2) > +o(d 2) y-_~- for sufficiently large d. Thus, 1 + (~+x+l) (~+x+2) 
 1 > -- -1)' which completes the proof. [] In what follows we set C to the value guaranteed by Lemma 
7, thus setting the value of )~ = d _ C dvfd]-~ n. 2 d We denote the size of BA(q) as ~-~-, where 1 < 
~ < 2. Notice that, although C is not constant, for all n large enough, because u ~ 0, we have C ~ 1/v~ 
~ 0.5887. Definition. Let e > 0, and let ql, q2 E Cd. We say that ql and q2 are e-close iff g(q 1, q2) 
< (½ _ v/~) d. Otherwise, we say that ql and q2 are e-far. Lemma 8. For every e, ~6 > e > 0, 3 there 
exists 5 > 0 such that the following holds for all n sufficiently large. If ql, q2 c Cd are e-far, then 
 IB;~(q 1) N B;,(q2)] <_ nJ~lCd[. Proof. Consider a uniform probability distribution over Cd, and let 
p be a random point from this distribu- tion. We show that Pr[p E BA(q 2) [p E BA(ql)] _< n -~. As Pr[p 
E BA(ql)] = ~n' the claim follows. 3The upper bound 3-~ is a somewhat arbitrary constant that can be 
improved. To see that, notice that choosing p uniformly at ran- dom in B~(q 1) is equivalent to the following 
experi- ment: Choose a distance r, 0 < r < A, with proba- bility ~. Then, for a given r, choose sequentially, 
uniformly, without replacement, a set of r coordinates I = {i1,i2,... ,i~}. Finally, putpj = 1 -q~ for 
allj E I, and pj = qj1 otherwise. Define pt by pjt = 1-qj1 for all j E {il,i2,..,it}, and pit = qjl 
otherwise. (Thus p0 = ql and pr = p.) For a fixed r, we define the following sequence of random variables: 
Xt = E[g(p, q2)lpt ]. As Xt -E[Xt+l]pt[, the sequence is a martingale, in which X~ = H(plq'Z). As for 
the value of X0, from linearity of expectation Xo = E[H(p, q2)] _- r r a (d- S(ql, q2)) q- (1- ~) U(qi,q 
2) = d ~+(1-d)(2H(ql,q2)-d)> where the last inequality follows from the fact that H(q 1, q=) > d/2 -dv% 
We consider two cases, according to the value of r. Case 1: d2 -3C dv/di-~n < r < -~d _ Cv/dlog n = 
A. (The constant 3 could be reduced to be close to V/~, yielding a wider range for e.) In this case, 
(1 d -(2ave) > We have Pr[H(p, q2) < A] = Pr [Xr < A] = Pr Xr<_-~-C = Pr [X~<~ d 6C~-SC dlv/d~] 1 
for some 0 < S < I (recall that e < ~). We need the following Fact 9. The martingale {Xt} satisfies the 
Lipschitz condition IXt -Xt+ll _< 2, for all 0 < t < r -1. Proof. Consider an arbitrary step t of the 
process of choosing coordinates. Let Wt denote the set of coordi- nates that have not been chosen by 
step t. Let Vt C_ Wt be the subset where ql and q2 agree, and let Ut C Wt be the subset where ql and 
q2 differ. Let vt =-[Vtl, and let ut = ]Ut]. Let Pt denote the probability of a coordinate in Wt to be 
chosen in step t + 1. (I.e., Pt = (r -t)/(d -t).) Finally, denote by X~'+l the value of Xt+l in case 
we choose in step t + 1 out of Vt, and denote by X~+ 1 the value of Xt+l in case we choose in step t 
+ 1 out of Ut. Notice that the expected distance after step t is Xt = d -H(ql,q 2) -vt + ut + Ptvt -Ptut. 
 Also X~+ 1 = d-H(q 1, q2)-(vt-1)+ut+ &#38;+l (Vt-i)-Pt+lu. and X~+ 1 = d- H(q 1, q2) _ vt + ut - 1 + 
Pt+lvt -Pt+l (ut - 1). Therefore X~+ 1 -X~t+l = 2(1 -Pt+l) <_ 2. (2) Obviously, = vt X v ~_tX~+ 1 Xt 
d-t t+a + _ (Notice that vt + ut = d -t.) Hence, in case we choose in step t + 1 from Vt, vt XV [Xt 
-X~+I[ = I(1 -d -t )(X~+I -t+l)[, and by (2), [Xt -X~+ll < 2. The case where we choose in step t + 1 
from Ut can be analyzed similarly. [] We proceed to get Pr[H(p, q2) -< -< Pr [Xr _< X0- SC leaS ]  
 = Pr[Xr X0 _< Pr[Xr_< X0-SC ][1 1 = Pr X~ < -~Xo -~SC < e-lS2C21og n = 2-1S2C2logelogn --A $2C 2 n 
87 where the first inequality follows from Xo >_ d/2 -6Cv/Td-Fg n, the second inequality follows from 
r < d, and the third inequality follows from applying Azuma's Inequality to the martingale {½Xt}. Case 
2: r<~ d _ 3C~n. In this case we use Lemma 6 to bound IBm(q1)[ < n-('~-')9C22d, and [B~(ql)l > n-(X+~)C22d. 
Therefore, Pr r < ~ -3C < n -8~C2+10"C2 ~ n -7, for all sufficiently large n. Summing up the two cases, 
we get Pr[H(p,q 2) < A] < n -~s2C2 +n -7 _< n -~, for all sufficiently large n, and for every 6 which 
is slightly smaller than "~S2C2/8. [] 1 Notice, as e --~ 0, S --~ 1, and as n --* c~, C --* ~. So, we 
get d ~ ~. For sufficiently large n, we can set 6 as a function of e alone. In what follows 6 = 6(e) 
denotes the 6 guaranteed by Lemma 8. Consider the graph G~ with node set Cd, and edges connecting pairs 
of points which are e-close. Our next goal is to establish some simple properties of this graph. Claim 
10. For every q E Cd, the degree of q in G¢ (i.e., the number of points which are e-close to q) is strictly 
less than led[ 2 -ed. Proof. By standard Chernoff bounds (see, e.g., [4]), the probability that a point 
q~ chosen uniformly at ran- dom in Cd has H(q, q') < d _ dv~ is at most e -ed. [] Definition. Let I C_ 
Cd. We say that I is e-apart iff I is an independent set in G~ (i.e., iff all the pairs ql, q2 E I, ql 
~ q2, are e-far). Claim 11. Let R C_ Cd, [R] >_ 2na[Cd[2 -~d. Then, assuming n is sufficiently large, 
there exists I C_ R, ]II = 2n 6, such that I is e-apart. Proof. Let A be the maximum degree of a node 
in Ge. By Claim 10, A + 1 _< [Cd[2 -~d. The claim follows because R must contain an independent set of 
size at least IR__~ > 2n 6, ~ A+I - for n sufficiently large. (The greedy algorithm will out- put such 
a set.) [] We are now ready for Lemma 12. Let R C Cd, [R[ = 4nS[Cdl2 -~d. Then there exist disjoint 
e-apart subsets Ii,I2,...,Iz C_ R whose union contains at least half of the points in R, such that the 
cardinality of each subset is 2n 6, and the number of subsets z E 2 n'O) Proof. Repeatedly apply Claim 
II to get an e-apart subset of the remainder of R. This can be done as long as the remaining set has 
cardinality at least 2nS[Cd[2 -ed. The number of subsets z is clearly up- per bounded by IR[/2n ~ = 2[Cdl2 
-~d. As we assume that d E n °(1), the bound on z follows. [] Lemma 13. Let I C C d be an e-apart set, 
II[> n 6. Let p be chosen uniformly at random in C d. Then, Pr[p is a A-neighbor of I] > ~. Proof. Assume 
III= n 6. (Otherwise, take a subset of I of cardinality n6.) Using Claims 7 and 8, and the Bonferroni 
Inequalities, Pr[pisaA-neighborofI] > [I] (~)-,([~[) ~ nl+5 ~n6(n ~ I) - nl-6 2n1+6 > - 2n1_6 [] We 
are now ready for bounding the communication complexity of nAN. Lemma 14. nAN is a-dense for some constant 
a. Proof. We show that in each row of the communi- cation matrix of nAN at least a constant fraction 
of the entries are 1. Fix q c Cal. Choose a database D uni-formly at random in C~. If p E Cd is chosen 
uniformly at random, then Pr[H(p, q) < A] n Thus, Pr[/(q, D) = 1] = Pr[Vp e D; g(p, q) > A] = for some 
constant ~ > ~. [] Claim 15. Let I C Cd, such that II[ = 2n 6 and I is e- apart. Then the number of databases 
in C~ that mach a fraction of less than 2A6 of the queries in I is at most 2nd-na/32. Proof. Consider 
a database chosen uniformly at random in C~. We think of the database as being cho- sen point by point. 
Let xl, x2,..., xn be the (random) points of the database, in the order they are chosen. Let Di = {Xinl-~+l,...,x(i+l)nl-~}, 
for 0 < i < n 6 - 1. Let M0,/1//1,/1//2,..., Mn~ be the following (random) subsets of I: M0 =~ { MiU{q} 
3q I\M~_l, qisa Mi+l = A-neighbor of Di; Mi otherwise. (If more than one such q exists, pick one of 
them ar-bitrarily.) Denote Z = [M~s[. (Notice that this is a random variable.) Define a sequence of random 
vari- ables X0, X1,..., X~, as follows. X~ = E[Z I Md. 2 nd-nS/33 has a fraction of at least ~h~t ~ 
of zero en- tries. Applying Lemma 4, we get it there is an [a, b]-protocol for nAN, then, either Ica_ 
_[ < icdr2_ + n , 20(a) or lc P 20(a+b------< IC~12-n~/33. ~ As Xi = E[Xi+l I Mi], the sequence is 
a martingale. Notice that [Xi -Xi-l[ __( 1 and that Xna = Z. Fur-thermore, for every i, [I \ Mi[ > n 
a. Therefore, by Lemma 13, the probability that a random database point is a A-neighbor of I \ Mi is 
at least ~. Hence the probability that none of the points of/3i are A-neighbors of I \ Mi is at most 
?~I --8 (1 2n~_a) <_e-{/2<e-'/2. Therefore, by linearityofexpectation, Xo >_ (1-e-1/2)n6. We use Azuma's 
Inequality to get Pr[X~8 < 2n6/20] _< Pr[X~8 < (1 - e -1/2 --1/4)n ~1 _< Pr[Xn8 < Xo -(1/4)nS/2nS/2] 
< e -n8/32. [] Now, we can show that there are no large nearly monochromatic sub-matrices in the communication 
ma- trix of nAN. Lemma 16. For all sufficiently large n, in any n62 0-E)d+2 x 2 nd-na/33 sub-matrix of 
the communica- tion matrix of nAN a fraction of at least 1 of the entries are zeros. Proof. Consider 
a sub-matrix A x B of the spec- ified dimensions. Partition at least half of A into sets Ii,I2,...,I~, 
as in Lemma 12. By Claim 15, for every Ij, 1 < j < z, the number of databases D B such that less than 
~ of the points in Ij are A-neighbors of D is at most 2 nd-ns/32. Hence, the number of databases D B 
such that there exists j for which less than 1__ 20of the points in Ij are A-neighbors of D is at most 
 Z" 2 nd-n~/32 ~ 2 nd-nS/32+n°O) ~ 2 nd-n~/33-1, for n sufficiently large. Therefore, since at least 
half of the databases in B have at least ~ of the points in any Ij as A-neighbors (i.e., at least half 
of the databases in B have as A-neighbors at least 1 of the points in A), the fraction of zero entries 
in A x B is at least sA6. [] We are now ready to prove Theorem 5, using the Miltersen et al. richness 
technique. Proof of Theorem 5: By Lemma 14, nAN is a-dense. By Lemma 16, every sub-matrix of size n52 
(1-e)d+2 × The first inequality implies that a E ft(ed -51ogn) = f~(d) (as d w(logn)). The second inequality 
implies that a + b = ft(n6). Assuming that a o(d), this gives b (as d [] References [1] P.K. Agarwal 
and J. Matou~ek. Ray shooting and parametric search. In Proc. of 24th STOC, pp. 517-526, 1992. [2] M. 
Ajtai. Determinism versus non-determinism for linear-time RAMs. In Proc. of 31st STOC, pp. 632-641, 1999. 
[3] M. Ajtai. A non-linear time lower bound for Boolean branching programs. Preprint, April 1999. [4] 
N. Alon and J. Spencer. The Probabilistic Method. Wiley, 1992. [5] S. Arya and D. Mount. Approximate 
nearest neighbor searching. In Proc. of 4th SODA, pp. 271-280, 1993. [6] S. Arya, D. Mount, N. Netanyahu, 
R. Silver- man, and A. Wu. An optimal algorithm for ap- proximate nearest neighbor searching in fixed 
dimensions. In Proc. of 5th SODA, pp. 573- 582, 1994. [7] O. Barkol. Tighter Lower Bounds for Nearest 
Neighbor Search and Related Problems in the Cell Probe Model. Master Thesis, Computer Science Dept., 
Technion, Israel, February 2000. [8] P. Beame, M. Saks, and J.S. Thathachar. Time-space tradeoffs for 
branching programs. In Proc. of 39th FOCS, pp. 254-263, 1998. [9] J.S. Beis and D.G. Lowe. Shape indexing 
using approximate nearest-neighbor search in high-dimensional spaces. In Proc. IEEE Conf. Comp. Vision 
Patt. Recog., pp. 1000-1006, 1997. [10] M. de Berg, M. van Kreveld, M. Overmars, O. Schwarzkopf. Computational 
Geometry, Al- gorithms and Applications. Springer, 1997. [11] A. Borodin , R. Ostrovsky, and Y. Rabani. 
Lower bounds for high dimensional nearest neighbor search and related problems. In Proc. of 31th STOC, 
pp. 312-321, 1999. [12] A. Chakrabarti, B. Chazelle, B. Gum, A. Lvov. A good neighbor is hard to find. 
In Proc. of 31st STOC, pp. 305-311, 1999. [13] K. Clarkson. A randomized algorithm for closest-point 
queries. SIAM J. Comput., 17:830-847, 1988. [14] K. Clarkson. An algorithm for approximate closest-point 
queries. In Proc. of lOth SCG, pp. 160-164, 1994. [15] S. Cost and S. Salzberg. A weighted nearest neighbor 
algorithm for learning with symbolic features. Machine Learning, 10:57-67, 1993. [16] T.M. Cover and 
P.E. Hart. Nearest neigh-bor pattern classification. IEEE-IT, 13:21-27, 1967. [17] S. Deerwester, S.T. 
Dumais, G.W. Furnas, T.K. Landauer, and R. Harshman. Indexing by latent semantic analysis. J. Amer. Soc. 
Info. Sei., 41(6):391-407, 1990. [18] L. Devroye and T.J. Wagner. Nearest neigh- bor methods in discrimination. 
In Handbook of Statistics, Vol. 2, P.R. Krishnaiah and L.N. Kanal eds. North Holland, 1982. [19] D. Dobkin 
and R. Lipton. Multidimensional search problems. SIAM J. Comput., 5:181-186, 1976. [20] M. Flickner, 
H. Sawhney, W. Niblack, J. Ash- ley, Q. Huang, B. Dom, M. Gorkani, J. Hafner, D. Lee, D. Petkovic, D. 
Steele, and P.Yanker. Query by image and video content: the QBIC system. IEEE Computer, 28:23-32, 1995. 
[21] R.O. Duda and P.E. Hart. Pattern Classifica- tion and Scene Analysis. Wiley, 1973. [22] R. Fagin. 
Fuzzy queries in multimedia database systems. In Proc. of PODS, 1998. [23] A. Gersho and R.M. Gray. Vector 
Quantization and Signal Compression. Kluwer Academic, 1991. [24] T. Hastie and R. Tibshirani. Discriminant 
adaptive nearest neighbor classification. In 1st International Conf. on Knowledge Discovery and Data 
Mining, 1995. [25] P. Indyk. Dimensionality reduction techniques for proximity problems. Manuscript, 
August 1999. To appear in SODA 2000. [26] P. Indyk and R. Motwani. Approximate near-est neighbors: Towards 
removing the curse of dimensionality. In Proc. of 30th STOC, pp. 604-613, 1998. [27] J. Kleinberg. Two 
algorithms for nearest-neighbor search in high dimensions. In Proc. of 29th STOC, pp. 599-608, 1997. 
[28] E. Kushilevitz, R. Ostrovsky, and Y. Rabani. Efficient search for approximate nearest neigh- bor 
in high dimensional spaces. In Proc. of 30th STOC, pp. 614-623, 1998. [29] J. Matou~ek. Reporting points 
in halfspaces. In Proc. of 32nd FOCS, pp. 207-215, 1991. [30] S. Meiser. Point location in arrangements 
of hyperplanes. Information and Computation, 106(2):286-303, 1993. [31] P.B. Miltersen. Lower bounds 
for union-split- find related problems on random access ma-chines. In Proc. of 26th STOC, pp. 625-634, 
1994. [32] P.B. Miltersen, N. Nisan, S. Safra, and A. Widgerson. On data-structures and asym- metric 
communication complexity. In Proc. of 27th STOC, pp. 103-111, 1995. [33] A. Pentland, R.W. Picard, and 
S. Sclaroff. Photobook: tools for content-based manipula- tion of image databases. In Proc. SPIE Conf. 
on Storage and Retrieval of Image and Video Databases II, 1994. [34] G. Salton. Automatic Text Processing. 
Addison-Wesley, 1989. [35] A.W.M. Smeulders and R. Jain (eds). Proc. 1st Workshop on Image Databases 
and Multi- Media Search, 1996. [36] A.C. Yao. Should tables be sorted? J. Ass. Comp. Mach., 28:615-628, 
1981. [37] A.C. Yao and F.F. Yao. A general approach to d-dimension geometric queries. In Proc. of 17th 
STOC, pp. 163-168, 1985.   
			