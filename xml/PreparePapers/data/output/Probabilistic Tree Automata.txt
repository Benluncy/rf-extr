
 PROBABILISTIC TREE AUTOMATA Clarence A. Ellis Bell Telephone Laboratories, Incorporated Whippany, New 
Jersey 07981 Introduction The purpose of this paper is meant to be three-fold. First it will introduce 
the reader to the concepts of Probabilistic Languages and Prob- abilistic Grammars. Second, it indicates 
that previous definitions of probabilistie finite au- tomaton have always been restricted to 1 of 8 classes 
of automaton and shows that other classes are useful. Third, the probabilistic concept is extended from 
finite automata to higher level automata (such as probabilistic PDAs and probabil- istic Turing automata). 
 A specific application of this theory is given in the development of Probabilistic Tree Automata. Theorems 
concerning these automata and operations on them are presented. It is indicated that this type of automaton 
is relevant because it characterizes Probabilistic Context Free Lan- guages. The results are taken from 
the author's PhD Thesis.4 l. Basic Definitions and Concepts Definition : A Probabilistic Language (P 
language) over a set T of terminal symbols is a system L = (L,~) where L is a class t of words formed 
from T and ~ is a measure on the set L. If ~ is a probability measure, then L is a Normalized Probabilistic 
Language (NP language). Definition: A Probabilistic Grammar (P grammar) over T is a system ~ = (N,P,A) 
where N is a finite set of nonterminals, Ai,A2,...,A n, A is an n-dimensional vector, (gl,62,...,6n) 
with ~i being the probability that A. is chosen as 1 the initial nonterminal, and P is a finite set 
of probabilistic The work contained herein describes part of the author's Ph.D. Thesis and was done 
while the author was a student and research assistant in the Department of Computer Science, University 
of lllinois, Urbana, Iii. It was supported in part by grant U.S. AEC AT(ii-i) 1469. Some classes under 
consideration for L are T + = all finite nonempty strings of symbols of T; T w = all infinite sequences 
over T; T O = all finite trees over T; and T ~ = all infinite trees over T. productions, ~i ~ ~j' with 
 ~i 6 (NqJT) +, ~j e(Nt.3T) +, and Pij 6R(Pij#0)" If A is stochastic,~_~ if 0 < Pij <- l, and if __2~Pi 
j = 1 J for every generatrix ~'i contained in productions of P, then G is a Normalized Probabilistic 
Grammar (NP grammar ). If all productions of G are of the form A Pl aB or A PP a, AeN, BeN, a~T, then 
6 is called a left linear P grammar. If all produc- tions of G are of the form (A P, I~), AgN, e(N~_JT) 
+, then G is called a context free P 5rammar. The probability of a derivation of ~n k k i from ~0 is 
defined as pr(~0~n ) = ~ ~ Pij i=l j=l where k is the number of derivations of ~n from ~, k. is the 
number of derivation steps, 1 Pij ~i,j-1 " ~i,j used in the i th derivation, and Pij is the probability 
associated with the jth step of the i th derivation. The derived probability of a terminal string x e 
T + with respect to a left n linear grammar G is ~(x)= ~ (~iPr(Ai---~x)) i=l where N = {Ai,A 2 ..... 
An}, A = (~i,~2 .....6n). The P language generated by G is L = (T+,w) where ~(x) = the derived probability 
of x. An admissi- ble P grammar (see Greibach [8]) is a grammar in which there exists a derivation of 
some x 6T + from each A6 N. A generalized admissible P grammar is one in which there exists a production 
with A in the generatrix for each A6 N. An example NP grammar is A 1/31 aA, A 2/31taB B 1/3 bB, B 
2/31~b which generates the NP language = { (ab,4/9), (aab,4/27), (abb,4/27) .... } where T = {a,b}, 
N = {A,B}, A = (i,0), and the class L = T +. Note that some strings of T + such -198- as bb have zero 
probability associated with them in this P language. Typical of the theorems which can be proven using 
these definitions is the following. Theorem: Every normalized left linear admissible P grammar, G, generates 
a normalized P language. Proof: Define an (n+l)×(n+l) matrix U = [uij] as follows: u.. = E pr( ), i 
< n,j < n ij a ~ T Ai÷aAj --- (Ai÷aA j ) E P U.. = pr(Ai÷b) , i ! n, j=n+l E 1j b E T (Ai÷b)E p 
 u.. = 0, i=n+l, j ~ n 13 Un+l,n+ I = i Ui,n+ I is by definition the total probability of a derivation 
from A. of a terminal string of length 1 1. Considering powers of the matrlx U, U~,n+ 1 gives the 
total probability of derivation from A. i of a string of length ~ k. If D k is pre- multiplied by the 
row vector A augmented by zero, A' = (61,~ 2 ..... 6n,0) then the (n+l)st element in the resulting vector 
represents the sum of the derived probabilities of all x E T + such that (length of x) ~ k. Finally, 
 E+ ~(x) = lim E W(x) = lim (A'.Uk)n+l . x eT k-~ o xCT + k÷~  ~(x)<_k  Since @ is normalized, U is 
a stochastic matrix; and since G is admissible, 3kelBu k. > 0 for l, n+l i=l,2,...,n+l. Thus, using 
the theory of Markov = " ' n+l 1  Chains 5 , uk (t~,t2,..k tk where each row vector t. k approaches 
a steady state vector t as k 1  approaches infinity, tk = (0,0,. 0,1)Vk el n+l " " ' implies t = (0,0.... 
,0,i) and lim (A'.U k) = A'.lim (U k) = A'.(t,t ..... t). k÷~ k÷~ Thus, the (n+l) st element is n+l 
A'-(t,t,...,t) n+l = ~ ~i = i. QED i=l  A P language which is generated by a left linear P grammar 
is called a regular P language, and similarly a P language which is generated by a context free P grammar 
is called a context free P language. The corresponding theorem for context free P grammars will later 
be proved using Prob- abilistic Tree Automata. These concepts of probabilistic languages and grammars 
when applied to automata theory lead to the following enrichment of the existing theory of probabilistic 
finite automata and pave the way for definitions of probabilistic higher level automata. 2. Probabilistic 
Automata  The basic idea of a probabilistic finite automaton which was introduced by Rabin 13 is that 
if the automaton is in some state q and receives an input a, then it can move into any state and the 
probability of moving into state q' is p(q,a,q'). Rabin requires that L p(q,a,q')=l q'6 Q (called type 
1 normalization in this paper) for all q in the set of states Q, and for all aET. Practical motivation 
for this requirement is that these automata can model sequential circuits which are intended to be deterministic, 
but which exhibit stochastic behavior because of random mal- functioning of components. Thus p(q,a,q') 
is interpreted as the conditional probability of q' given q and a, pr(q'lq ,a), so by the theorem of 
 total probability, ~ pr(q'lq,a) = 1. Other q'E Q interpretations may give rise to other normaliza- tions. 
For example, in performing the state iden- tification experiment with a probabilistlc auto- maton, one 
might interpret p(q,a,q') as pr(q,q'la). This implies a normalization by summing over all possible q, 
values I, I, p(q,a,q'l: 1 q E Q q'E Q In fact, eight different classes of probabilistic automata can 
be defined by the various interpreta- tions listed in the following table. Kleene's theorem, the Chomsky-Schutzenberger 
theorem, and the Landweber-Kuroda theorem all state that there exists a correspondence between a certain 
type of grammar and a certain type of automaton. Analogous problems for probabilistic h grammars and 
automata are investigated elsewhere-. The generalized definition of probabilistic automaton which we 
will use is the following. Definition: A Probabilistic Automaton (P automaton) over T is a system = 
(Q,M,S,E) ~here Q is a finite set of states, S is a finite set of stor- age tape symbols, ~ is an initial 
state vector and M is a function, called a prob~bilistic transition function, which has associated with 
it a second function p. The specific nature of these functions determines the type of P automaton defined. 
If E is a stochastic vector and if A is  -199- Normalizations for Probabilistic Finite Automata input 
a transition probability p(q,a,q') P CLASS INTERPRETATION NORMALIZATION i pr(q' lq,a) E q' £Q p(q,a,q' 
= iVqEQ, acT 2 pr(qla,q' ) E q6Q p(q,a,q' = iVq' , Va 3 pr(alq,q' ) ~ acT p (q,a,q' = iVq, Vq' 4 pr(q' 
,alq) E a£T ~ q'E Q p(q,a,q' = iVq 5 pr(q'alq' ) E aeT E qEQ p(q,a,q' = iVq' 6 pr(q'q' la) E q EQ E q'e 
Q p(q,a,q' = iVa 7 pr(q'a'q' I ) E q E a E q' p(q,a,q' =.i 0 pr( lq,a,q' ) p(q,a,q' = 1 Vq, a, q' constrained 
to some normalization 5. Probabilistic Tree Automaton type, then A is a Normalized Probabil- Norm: Type 
istic Automaton (NP automaton). RD: D(M) = QxT, R(M)~P(Q*) Cases in which S = ~ will be simpli- fied 
to A = (Q,M,E). Particular 6. Probabilistic Pushdown Store Antomaton classes of automata are obtained 
by Norm: Type h attaching constraints to the general RD: P(M) = Q×S×T, definition. The following table 
R(M)(,P(Q×S)U {~} lists some of the automata definable, and their range (R(M)) and domain Notes: P(E) 
for any set E denotes the power set (D(M)) constraints on the mapping M, of E. A mapping M(q,a) = ¢ has 
probability zero and their normalization constraints. associated with it, and designates that a transi- 
tion out of the state q under input a is dis- ~pes of Automata allowed. M(q,a) = k is used to designate 
termination. 1. Deterministic Finite Automaton Norm Constraints: Type 1 In the next section, an example 
of a proba-  MP Constraints: D(M) = Q×T, R(M) qQ bilistic automaton will be given. The definition will 
be specialized to a probabilistic tree  2. Nondeterministic Finite Automaton automaton (FTA); the characteristics 
of this Norm: Type 0 automaton will be explained and several operations ~P: P(M) = Q×T, R(M) CP(Q) on 
these automata will be defined. The PTA was chosen because automata over strings can be con-  3. Probabilistic 
Rabin Automaton sidered as a special case of these automata, and Norm: Type 1 because  RD: D(M) = Q×T, 
R(M) q P(Q) 1. for every context free P grammar G, there is a PTA which accepts exactly the P lan-  
4. Probabilistic Ellis Automaton guage generated by G, and Norm: Type 4 2. for every PTA A, there is 
a context free RP: P(M) Q×T, P grammar which generates exactly the P  R(M)~_ P(Q)L9 {X} language accepted 
by A. -200- 3. Probabilistic Tree Automata  Definition: A tree is a set D ~ I* where I* is the set of 
all finite strings of positive integers and where D satis- fies the following three require- ments: 
Let d = (n I n 2 ... nk) , n ieI, then dn = (n I n 2 ... n k n), nEI.  i. drieD, n > l,~d(n-l) CD 2. 
dnCD, n = l,~deD 3. If set {nldnCD, max (n) <-. dn CD nCI} # ~, then Note: (n I ... u k) in the case 
k = 0 is the empty string A which is considered as the root of the tree. Each dCD is a node of the tree 
and if + + n = max (n) then node d goes down into n dnCD other nodes dl,d2,... ,dn +, from left to right: 
 d dl ~dn +  + If {nldncD} = ¢, then n + is defined as n = O. In this case, d is a terminal node of 
D. Definition: A valued tree over a finite alphabet T is a pair (v,D) where D is a tree, and v is a 
function, v:D-~T. Valued tree will sometimes be abbreviated to tree when there is no possibility of confusion 
with the previous defi- nition of tree. Define £(n I n 2 ... rh ) = k. The length of a tree is sup 
£(d). Define the m th level of a d e D tree to be the set {deDl£(d) = m}. If (3meI)(Vd6D)[~(d) < m], 
then (v,D) is called a finite valued tree. Define a subtree of (v,D) to be (v',D') where D'C_D is itself 
a tree, and the function v' is v on the restricted domain D', v' = vlD. The set of all finite valued 
trees over T is denoted by T O . If deD ~dleD, then (v,D) is a full infinite valued tree. T ~ denotes 
the set of all full infinite valued trees over T. Definition: A Probabilistic Tree Automaton (PTA) over 
T is a triple (Q,M,H) where Q is a finite set of states, H is the initial state distribution vector, 
and M is the next state function, M: QxT ÷ P(Q*). Associated with each qCQ, aCT is a function Pq,a V(pq,a) 
= M(q,a), R(pq, a) = R. (Transition probability.)  An elementary transition T k is a change con- sistent 
with M. from state q under input a to a sequence of states % = qkl,qk2 ..... qkn" (Con- sistent with 
M means Qk c M(q,a).) Thus a transi- tion out of any state may go into many states rather than into 
a single next state. The nonzero probability of this elementary event is p(T k) = Pq,a(Qk ). A probabilistic 
tree automaton is normalized (NPTA) iff for all states q, the total probability of leaving q is one (i.e., 
 Pq,a(%) = 1), 0 < Pq,a(%) l, aCT %e M(q,a) and ~ is a stochastic vector (i.e., ~ {(q) = 1 q e Q where 
~ is a function: Q÷R which assigns to each state q, its proper probability value from the vector H). 
 Definition: A PTA is complete iff  (v qc Q)( 3be T)[M(q,b)#~].. Thus, complete means there is always 
a positive probability of exiting from any state q.  Definition: A PTA A is strictly nonterminable if 
 (1) A is complete.  (2) (V q EQ)(V aCT)[l~M(q,a)].   Any complete PTA can be altered to form a strictly 
nonterminable PTA by adding a new state qt if there are elementary transitions ~E M(q,a), and replacing 
these by elementary transitions qt EM(q,a) with probabilities equal to that of the omitted transitions. 
Next add a new blank symbol b to the alphabet and the transition M(qt,b) = {qt ), pqt,b(qt ) = 1. It 
is useful and convenient to represent these tree automata using a modification of the directed graphs 
usually used for state diagrams. A context free state diagram consists of a set of vertices, represented 
by small circles, each of which may be connected to others by incoming arcs (lined with arrowheads) 
and outgoing cables (heavy lines). The vertices denote states, and cables denote possible elementary 
transitions. Each cable splits into one or more arcs each of which goes to a state. The initial states 
(all q 9 ~(q)#O) are designated by incoming labelled arcs with no source states, and no inputs. In the 
case of a terminal transition, ~CM(q,a), the automaton literally goes into no state (it stops). In drawing 
state diagrams, this can be repre- sented by drawing an arc from the vertex q to a dead-end vertex qt 
which has no cables out of it and which does not correspond to any state in Q. -201- This is a state 
diagram of the automaton Q = {qA,qB }, = QC(qA),C(qB )) = (i,0), M(qA,a) = {qA,qAqB }, M(qB,b) = {qB,qAqB 
}, PqA,a(qA ) = Pa' PqA,a(qAqB ) = Pa' PqB,b(qB ) = Pb' PqB,D(qAqB ) = Pb' This automaton over T = 
{a,b} "accepts" among others the following trees: Tree i Tree 2  a a I /a/k "b, a a b b , ,/\\\ 
a I ! .... O @ @ @  D 1 = {inI n ~ 0} D 2=DILJ{I n 2 imln, m ~ 0} Vl(d ) = aVdeD I v2(d) = a if 
diD I v2(d) = b otherwise. Example  Definition: A run of A on a tree, denoted r(v,D), is a function 
r: D~QgV dED, (r(dl).... r(dn+))e M(r(d),v(d)) where (a) (r(A)) # 0 and (b) if n + = 0 then eS(r(d),v(d)). 
If condition (b) is omitted in the case £(d) = length of the tree (v,D) < ~, then r(v,D) is a ,re~. The 
set of all runs on (v,D) is denoted by Rn(v,D).  A transition t is defined as the sequence of elementary 
transitions used in a run to go from some level n of a tree to level n+l. The proba- bility of this 
event is p(t) = H P(Tk)" The T k E t sequence of transitions used in a run is denoted by t(r). The response'function 
of a run (or pre- run) r is defined as the product of the proba- bilities associated with transitions 
used in the run (or pre-run) and the initial state probability -rr rf(r) = ~(r(A)) H p(t). tEt(r) Definition: 
A k- r~of a tree (iv,D) is the subtree (Vk,Dk) where D k = {xEDl£(x) ~k} and v k = vID k. In defining 
acceptance of trees, it is desirable to accept a prefix as part of a longer tree without requir- ing 
the machine to terminate. Thus pre-runs on prefixes ~e necessary, and likewise the following defini- 
tions: An elementary pre-transition T out of state q under input a is the set of all elementary transitions 
from state q under a. The proba- bility of this event is p(T) = ~eM~(q,a) Pq,a(Qk). If M(q,a) = ¢, then 
p(T) = 0. The final transition t of a pre-run on (Vk,D k) is the sequence of elementary pre- transitions 
used to leave the kth level. The probability of this event is p(t) = Tk~Et P(Tk)'  Definition: The 
behavior of A is the set of all trees (v,D) over T B 3 at least one run of A on (v,O), B(A) = {(v,D)[Rn(v,D):~¢}. 
The k-behavior of ~, Bk(R), is the set of all k-prefixes (Vk,D k) over T.  Definition: The probability 
of acceptance of a tree, ~(v,D), is the sum of the re- sponse functions of all runs on (v,D), W(v,D) 
= L rf(r). r E Rn(v,D)  Define the k-probability of a tree as ~k(V,D) = ~(Vk,Dk) = ~ rf(r) where r 
£ Rn'(VkD k) Rn'(Vk,D k) is the set of all pre-runs on (Vk,Dk). Two trees over T are defined to be 
k-equivalent, = i = D k (vi,D l) k (v2,D 2) iff D k 2 and v~ = v~. k . Theorem: = is an equivalence 
relation. Proof: It is easy to verify that k-equivalence is reflexive, sy~nnetric~, and transitive. 
 Theorem: (vl,D I) ~ (v2,D2)~k(vl,Dl) = = Wk(V2,D 2) over T. 1 2 1 2 then Proof: Let D k = D k = Dk, 
and v k = v k = Vk, Wk(VI,D I ) 1 i = ~(vk,m k) = ~1(Vk,D k) = = k(v2,D2).  -202- Theorem: If A is 
a normalized PTA, then ~(Vk,Dk) = i, k=0,1,2 (Vk,D Bk(A)  Proof: Let Zrf(r k) denote rf(r) = r E Rn(Vk,D 
k) (Vk,Dk)e Bk(A) The proof is = ~ ~(Vk,Dk). (Vk,D k) e Bk(A) by induction on k.  (1) Case k=0: 
For each pre-run, there is only a single transition which is a final transition consisting of one elementary 
pre-transition because the 0 th level of a tree is only one node, A. Given any q EQ, suppose 3m inputs 
acT ~M(q,a i) # ¢. Then 3m prefixes al,a2,...,amwhich each have a pre-run of the form r:A-~q, and for 
the tree a., the re- 1  sponse function is ~(q) ~ P~ a (QJ)"  Qj E M(q,a i) ~' i The probability 
of these m response functions is Pq,a%/ which a i e T Qj e M(q,ai) " by normalization of A reduces 
to ~(q). Finally, st!mining over all states q, we get qeQ ai~T QjE a i) " = ~ ~(q) = 1 by normalization 
criteria. q e Q (2) Case k>O: Assume IJ(V k l,Dk 1 ) = 1. The  (Vk_l,Dk_ 1 ) E Bk_i(A) -- set of (k-l)-prefixes 
of trees in B(A) parti- tions the set of k-prefixes via the equiva- k-i  lence relation = . This is 
indeed a parti- tion because each (Vk,Dk) has some (Vk_l,Dk_ 1) as prefix, so U E i includes i=l all 
prefixes (Vk,D k) where E i is an equiva- lence class of k-prefixes all having the same (k-l) prefix. 
Z is the number of equivalence k-1 classes created by --. Furthermore,  E i f'~ Ej = ¢ because each 
(Vk,D k) has a unique (k-1)-prefix. For every class E~ , all mem- bers have the same (k-1)-probability 
by pre- vious theorem. For a particular pre-run of some _ k) e El, the transition from level _(Vk,D 
 k-1 to level k of the tree yields a sequence of States, qi'''''qn" All possible transi- tions emanating 
from this set of states to possible k+l level trees have a sum proba- bility of ~ mlk~= k~= " "" Pk 
 "" Pkl Pk2 n n where m i : ~ IM(qi,a) I and each value of a£T Pk. is associated with one of the transitions 
i out of state qi" Thus summing over all pre- runs of all k-prefixes the result is grf(rk) = ~(rf(rk_l)) 
. . . . °,~ . The inner sums can be written Pk ( " ( Pk )''" ) = 1 since kl=l i ~ Pk2"" n n by normalization 
the total probability of m. leaving state qi = ~ Pk i = 1. Thus k.=l l  ~(Vk,D k) = ~rf(rk) = Zrf(rk_ 
l) (Vk,Dk)E Bk(A) = ~ ~ D(Vk_l,Dk_l) and by (Vk_l,Dk_l) e B~_i(A) the induction hypothesis ~(Vk_l,Dk_ 
I) = i, so (Vk_l,Dk_ l) e Bk_l(A) ~(Vk,Dk) = i (Vk,D k) C Bk(A) The P language accepted by the (strictly 
nonterminable) probabilistic tree automaton ~ is defined as (T~,w) where W is determined by the measures 
Wk of ~ on B(~), and W is defined as the zero function on T~-B(A). Then using the machinery developed 
in this section, we can prove the following. Theorem: Every normalized strictly nonterminable PTA accepts 
a P language which is normalized. The proof of this theorem involves a proof that B(~) forms a consistent 
probability space and , 1  relies upon Kolmogorov s theorem . Since there iE a correspondence between 
probabilistic context free grammars and PTA's, the previous theorem implies that every context free NP 
grammar gener- ates a P language which is normalized. -203- 4. Operations on Probabilistic Tree Automata 
Definition: The direct w-sum of the PTA's Al'~2 .....An' where ~i = (Qi'Mi'Ri) ' Definition: The union 
with wei6htins vector w of is the PTA A = ~ Ai = (Q,M,H) where the P languages fLi = (T~'~i)'  i=l 
.... ,n is L = (T~,u) where n n Q = Lj Qi (assuming without loss of i=l wi~ i generality that all Qi 
('~QJ = ¢ if i # J), M(q,a) = Mi(q,a ) and Theorem: The union with weighting vector ~ of P = i for 
all qEQi ( i Pq,a Pq,a ' Pq,a is  languages £1,~2,... ,in forms a P lan- the probability associated 
with M i) guage; furthermore, if fL. is norma-  l and C(qi ) = wi~i(qi ). limed, i=l,...,n, and ~ 
is a stochastic n Theorem: If Ai,A2 .... 'An are normalized PTA's, vector, then the union f~ = L_J w.L. 
is then A = @ Ai is ]~ormallzed. i=l i i normali zed.  Definition: The direct b-product of Ai,A2,...,~n, 
 If (Vl,D1) and (v2,D2) are trees, then ao b ET, where Ai is the PTA, ((Vl,Dl),(v2,D 2)) is a tree whose 
root has value a ~ = (Q ,M ,~ ), is i _~ i i and with two branches going out to (Vl,Dl) and = ~Ai = 
(Q,M,E) where (v2,D2) respectively. n Q = ~ Qiqj {q0} with q0 ~ Qi' and i=l Qi~Qj = ¢, i,J=l ..... n, 
i W J. ~(qo ) = i, ~(q) = 0 if q # qo"  The generalization of this operation is formalized. M(q,a) 
= Mi(q,a) i ( (Pq,a(Qk) = Pq,a Qk )) if qeQi;  Definition: The concatenation under b of P lan- M(q0,a) 
= ¢ if a # b; for all possible guages Li = (T ,U ), i=l,...,n, is combinations ql,q2,...,q n such that 
 = (TO,w), defined as follows: for each combination of qieQi and {i(qi ) > O, (vl'D1) ~ L1 ..... (vn,Dn) 
c in, define a ql,q2,...,qn ¢ M(qo,b) and tree (v,D). D = {A}L_J 1DLJ... LinDn n where kD k means all 
strings in D k Pqo,b(ql ..... qn) = IT {i(qi )" i--1  prefixed by kEI; and define v(A) = b, v(kd) = 
vk(d) where dED k, k EI. Theorem: If Ai,A2,...,An are normalized PTA's, then A =~Ai is normalized. 
~k(v,O ) = ~n i i Define ~k_l (v ,Di), i=l  Theorem: 3 an operator homomorphism h from the k=l,2, ....n 
and W0(v,D) = i. Also set of strictly nonterminating PTA's over T into the set of P languages of  define 
~k((V,D) + (vl,Dl)) = the form (T®,~) under the operations Wk(V,D) + ~k(vl,D1), provided (~, ~)and (~, 
~b ) where (v,D) # (vl,Dl). This guarantees that means union with weighting vector  ~k is finitely 
additive. By simply and (0~ means concatenation under b. omitting the definitions for Wk' con-  catenation 
under bean be defined for Proofs of these theorems can be found in the nonprobahilistic languages. author's 
Thesis. Theorem: The concatenation under b of P lan-5. Summary and Conclusions guages il,i2.... ,in 
, forms a P General definitions have been given of the language for any beT. Furthermore,  concepts 
of Probabilistic Language, Probabilistic if i i is normalized, i=l,... ,n, then  Grammar, and Probabilistic 
Automaton. The set of the concatenation £ = b0(iI .... ,in) is context free probabilistic languages can 
be com- normali ned. pletely characterized in terms of -204- (i) probabilistic tree automata, and (2) 
proba-[4] Ellis, C. A., Probabilistic Languages and bilistic context free gra~nars. The motivation Automata, 
University of Illinois, Ph.D. for this work is to take a first step toward de-Thesis, September 1969. 
veloping a quantitative tool for analyzing pro- grAmm~ng languages and their translators. We [5] Feller, 
W., An Introduction to Probability would like to conclude by mentioning some applica-Theory and Its Applications, 
Vol. l, Wiley tions of and problems related to the present and Sons, Inc., New York, New York, 1957. 
investigations. [6] Ginsburg, S., A16ebraic Theory of Context In the area of compiler writing for program-Free 
Languages, McGraw-Hill, New York, New ming languages, there are various syntax oriented York, 1966. methods 
available which effectively derive code from the grammar which specifies the language. By [7] Greibach, 
S. A., "A New Normal Form Theorem keeping a frequency count of the amount of usage for Context-Free Phrase 
Structure Grammars," of the various "sentences" of the language, where JACM, 1._2(1), pp. 42-52, January 
1965. the sentences in this case are programs, a proba- bilistic language can be defined and it can be 
[8] Kleene, S. C., "Representation of Events in determined which of several probabilistic grammars Nerve 
Nets and Finite Automata," Automata generates a better approximation language. Fur-Studies, Princeton 
University Press, thermore, it can be speculated that an adaptive Princeton, New Jersey, pp. 3-41, 1956. 
compiler (i.e., a learning compiler) which modi- fies itself to translate high frequency sentences [9] 
McNaughton, R., "Testing and Generating Inf. best may be obtainable by improving the approxi-Sequences 
by a Finite Automaton," Inf. and mating grammar as more and more frequency data is Cont., ~, pp. 521-530, 
1966. obtained. [10] Muller,'D. E., "Infinite Sequences and One of the interesting areas related to 
sets Finite Machines," AIEE Proceedings 4th of trees concerns decidability questions. An ef-Annual Symposium 
of Sw. Circuit Theory and fective procedure can be given for checking equal-Logic Design, pp. 3-16, 1963. 
ity of two tree automata. This implies that it is always decidable whether the sets of trees gener-[ll] 
Paz, A., "Some Aspects of Probabilistic ated by two context free grammars are the same or Automata," 
Inf. and Cont., ~ (1), pp. not. If the sets of trees generated by two con-223-246, 1968. text free grs~mnars 
are not the same, this does not imply that the sets of strings generated by the [12] Paz, A., "Fuzzy 
Star Functions, Probabilis- grammars are not the same; similarly, if the two tic Automata, and Their 
Approximation by sets of strings generated are identical, this does Nonprobabilistic Automata," Journal 
on not imply that the sets of trees generated are the Computer System Sciences, i (4), pp. 371-390, same. 
Indeed, this question is known to be un-1967. decidable for context free sets of strings. Thus, the degrees 
of unsolvability of these two ques-[13] Rabin, M. 0., "Probabilistic Automata," Inf. tions are incomparable. 
and Cont., ~, pp. 230-245, 1963. This investigation does not consider how one [14] Rabin, M. 0., "Decidability 
of Second Order would find the "best" grammar or automaton for a Theories and Automata on Infinite Trees," 
language, or how to improve a given grammar. IBM Research Report RC-2012, February 1968. Indeed, the 
meaning of "best" is open to many" interpretations. The related idea of finding good [15] Rounds, W., 
"Context Free Grammars on Trees," approximation grammars for languages is also unex-1st Annual ACM Symposium 
on Theory of plored. It is hoped that the tools developed here Computing Proceedings, pp. 143-148, May 
1969. will lead to quantitative analysis in these and other areas. [16] Solomonoff, R. J., "A Progress 
Report on Machines to Learn to Translate Languages and Bibliography Retrieve Information," Advances in 
Documen- tation and Library Science, ~ (2), 1961. [1] Ash, R. B., Math. 468 Classnotes (Proba-bility 
Theory), University of Illinois, [17] Turakainen, P., "On Stochastic Languages,"Urbana, Illinois, September 
1967. Inf. and Cont., 1._2(4), 1968. [2] Brainerd, W. S., Tree Generating Systems and [18] Zadeh, A., 
"Fuzzy Sets," Inf. and Cont., Tree Automata, Purdue University, Ph.D. (3), pp. 338-353, July 1965. Thesis, 
June 1967. [3] Chomsky, N. and Schutzenberger, M., "Algebraic Theory of CF Languages," Computer Pro~rammin6 
and Formal Systems, North Amsterdam Publishing Company, pp. ll8-161, 1963. -205- 
			