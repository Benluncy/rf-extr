
 THE MACRO MODEL FOR DATA COMPRESSION * Extended Abstract James A. Storer and Thomas G. Szymanski Princeton 
University Dept. of Electrical Engineering and Computer Science rrlnceton,N.j. ABSTRACT: A ~eneral model 
for data compression is presented whlch includes most data compression sys- tems in the literature as 
special cases. All macro schemes are based on the principle of finding redundant strings or patterns 
and replacing them b~ pointers to a common copy. Different varieties or macro schemes may be defined 
by varying the in- terpretation of pointers, for instance, a pointer may indicate a substring of the 
compressed string, a substring of the original striag~ or a substrlng of some other string such as an 
external diction- ary. Other varieties of macros schemes may be de- fined by restricting the type of 
overlapping or re- cursion that may be used. Trade-offs between dif- ferent varieties of macro schemes, 
exact lower bounds on the amount of compression obtainable, and the complexity of encoding and decoding 
are dis- cussed as well as how the work of other authors (such as Lempel-Ziv) relates to this model. 
 On-line secondary storage space is one of the most restricting resources in many modern computer installations, 
particularly in those employing multi-user tlme-sharing systems. Fast algorithms for compressing and 
restoring data files can do much to alleviate this problem. Some of the more popular data compression 
schemes described in the literature include ~$atlstical encodln~ techniques such as Huffman codes (Huffman 
[1952]), which typi- cally encode a block of source data as a variable length string of bits determined 
by various sta- tistical properties of the source data, incremental encodinK methods (e.g. Visvalingam 
[1976]), which typically compress a file of fixed length records by recording only the difference between 
successive records, and textual substitution or macro encoding schemes (Storer [1977b], Rubin [1976], 
Mayne and James [1975], Hahn [1974], Wagner [1973], McCarthy [1973], Hagamen st al. [1972], Ruth and 
Kreutzer [1972], Lesk [1970], Matron and DeMaine [1967], and others) whleh factor out duplicate occurrences 
of #Research supported in part by NSF grant MCS 74-21939. data, replacing the repeated elements with 
some sort of special marker identifying the data to be replaced at that point. In addition, many ad-hoc 
methods for handling data with certain known characteristics appear in the literature. This abstract 
is devoted exclusively to the pro- perties of the macro model for data compression. We shall study two 
major types of macro schemes, the types being differentiated by the location where the factored-out text 
is stored. Section contains a discussion of our model along with some basic definitions, Sections 3 and 
4 present our results for the two major types of schemes con- sidered, and Section 5 examines the relative 
per- form~,ce of the various compression schemes intro- duced in the preceding sections. The proofs of 
the results reported in this abstract may be found in Storer [1977], and Storer and Szymanski [1977]. 
 THE~DELA~C DEFINITIONS We shall treat the source data as a finite string over some alphabet. With external 
macro scheme~, a source string is encoded as a pair of strings, a dictionary and a skeleton. The skeleton 
contains characters of the input alphabet inter- spersed with pointers to substrlngs of the diction- 
ary. The dictionary is also allowed to contain pointers to substrings of the dictionary. The source string 
is recovered by substituting diction- ary strings for pointers. With internal macro seheme~, a string 
is compressed by replacing dupll- cate instances of substrings with pointers to other occurrences of 
the same substrings. The result is a single string of characters and pointers. -30 - Throughout this 
abstract let p~1 denote the im- plementation dependent size of a pointer S . If x is a string containing 
pointers, the length of x, denoted ~xl, is defined to be the number of charac- ters in x plus p times 
the number of pointers in x. We shall treat a pointer as an indivisible object which, in some unspecified 
fashion, uniquely and unambiguously identifies some string which is re- ferred to as the target of that 
pointer. The way a pointer is written is not important; the only as- sumption we make is that it is always 
possible to determine by inspection of the pointer the length of the string that it represents $$. For 
simplici- ty, we shall write pointers as a pair (n,m) where n indicates the position of the first character 
in the string pointed to, m indicates the length of that string, and l(n,m)~ is the pointer size p. 
Without loss of generality, it will always be as- sumed that m>p. As an example of these ideas, let 
p=1 and con- sider the string w : aaBccDaacEaccFacac which might be encoded under the external macro 
model as x : aace#(I,2)B(3,2)D(I,3)E(2,3)F(2,2)(2,2) where # separates the dictionary from the skeleton 
$$$. The compression achieved by the string x (i.e., the ratio ~xl/lw~) is 14/18. Using the internal 
macro model, w could be encoded as y = aaBccD(1,2)cEa(4,2)Fae(13,2) achieving a compression of 15/18. 
 Implementation considerations motivate us to describe a number of variations on our basic models. A 
scheme is recursive if a macro body (i.e. a string that is a target of a pointer) is allowed to itself 
contain pointers. Overlapnin~ occurs whenever some position within a compressed string is part of two 
or more distinct macro bodies (e.g. the dictionary abc viewed as containing macro bodies ab and bc). 
Whether overlapping is permit- ted in the external model depends highly on the im- plementation chosen 
for the dictionary $#$~. An $We shall assume that all pointers within a given string have a uniform 
size. ~Vari~ble length poln~ers are considered in Storer [1977].) We shall assume p to be an integer, 
although our results generalize to non-integral pointer sizes. {#It is not always necessary to make this 
assump- tlon and, _in fact, it can be useful to remove it. See Storer [1977] for a discussion of this. 
 I$$ For convenience, we assume I#Z:O. $$$Certain implementation considerations can lead to the placement 
of various restrictions on the kinds of overlapping permitted. Some of these res- ori~inal pointer is 
one which denotes a substring of the original source string whereas a compressed pointer denotes a substring 
of the compressed representation itself. The string y of the previ- ous example contains compressed pointers. 
Using original pointers we could encode w as z = aaBccD(1,2)cEa(4,2)F(8,2)(8,2) achieving a compression 
of 14/18. Original pointers are more natural for one-pass decoding. Compressed pointers allow the recovery 
of portions of the source string without requiring the implicit decompression of the entire string. A 
left (or right) pointer is one which denotes a substrlng oc- curring earlier (respectively, later) in 
the string. Considering the strings x, y, and z presented above, only x uses overlapping, only z uses 
recursion, and none of these strings use right ~ointers. ~h~ above discussion leads us to formally define 
tour basic macro smhemes and three~ Which may be placed on any of these Scb~ee. Throughout this abstract, 
~ will denote the under- lying alphabet from which the data in question is constructed. DEFINITION !: 
A compressed form of a string s using the EpM (external pointer macro) scheme is any string t : So#S 
I satisfying: (I) s O and s I consist of characters from and pointers indicating substrings of s 0. 
 (2) s can be obtained from s I by performing the following two steps:  A: Replace each pointer in 
s I by its corresponding str ~g. B: Repeat step A until s I contains no pointers. | DEFINITION ~: A 
compressed form of a string s for pointer size p using the CPM (compressed pointer macro) scheme is any 
string t satisfying: (I) t consists of characters from ~ and pointers indicating substrings of t.  
(2) s can be obtained from t by forming the string t#q (where q is a pointer indicat- ing the string 
t) and then decoding as in the EPM scheme. |  DEFINITION ~: A compressed form of a string s using the 
OPM (original pointer macro) scheme is any string t satisfying: t-fictiOns are described in Storer[1977]. 
 (I) t consists of characters from ~ and pointers indicating substrings of s.  (2) s can be obtained 
from t by performing the following three steps:  A: Attach to each ~ character in t the index of its 
position within the ori- ginal string s. This can be done dur- ing a single left to right sweep over 
 t because each pointer within t speci- fies the length of the string it represents. B: Find a pointer 
(n,m) and a string r, both in t, for which the characters of r are tagged with the indices n, n+1, ..., 
n+m-1 and replace this pointer with a copy of r. C: Repeat steps A and B until t contains no pointers. 
 DEFINITION ~: A comnresse~ form of a string s using the OEPM (original external pointer macro) scheme 
is any string t=so#s I satisfying: (I) t consists of characters from 2 and pointers.  (2) s O may be 
decoded using the OPM scheme to produce a string r. Furthermore, pointers in s I indicate substrings 
of r.  (3) s may be obtained from s I by replacing each pointer by its corresponding String in r.  
 A contraction of a string s for pointer size p according to a given scheme is a shortest compressed 
form of s. A contraction of a string s will be denoted byA(s) $. We shall refer to any substring that 
is pointed to by a pointer as a factor and the process of replacing a string r by a pointer as factorin~ 
out r. DEFINITION ~: A macro scheme using compressed (original) pointers is restricted to no recursion 
if no factor (compressed form of a factor) may con- tain a pointer or part of a pointer $$. DEFINITION 
~: A macro scheme is restricted to no overlanoiruz if no two distinct strings that are both targets of 
a pointer are allowed to share a %A string may have more than one minimal length compressed form. For 
formal discussions, we can always insure that,s) is unique by assuming a lexicographic orderlng. $$This 
happens only with original pointers.. For example, consider the string aaaababusing polnter size p=l. 
Osing the OFM scheme, this string could be written as aa(1,2)b(4,2). Here. the pointer (4,2) points 
to "part of" the pointer (1,2). common substring. DEFINITION I: A macro scheme is restricted to unidil~ectional 
Pointers if all pointers must point in the same direction (of course, with the EPM and OEPM schemes, 
this only applies to the external dictionary). As a special case of this, we can restrict a macro scheme 
to have only left or ri=ht pointers. The different combinations of the four basic macro schemes we 
have defined and the recursion, overlapping, and pointer direction restrictions provide us with a large 
number of data compression methods. The combinations are sufficiently general to cover virtually all 
of the text substitution schemes proposed in the literature. Discussion of the utility and appropriateness 
of various restric- tions to the models are deferred until later in the abstract. One aspect of the 
macro model that we have not discussed in this abstract is the concept of adding arguments to pointers 
which allow the specification of modifications to be made on a factor before it is substituted. Macro 
schemes with argt, nents gen- erally have more power than ones without. Also, a few data compression 
methods presented in the llterature require a macro scheme with arguments to model them, for example, 
the subsequence and su- persequence compression methods discussed in Maier [1976, 1977]. Macro schemes 
with arguments will not be discussed in this abstract but it is impor- tant to realize that the macro 
model allows this generality. THE EXTE~C~O MODEL The external macro model views the collection of macro 
bodies as residing outside the remainder of the compressed string. Because of this, there are several 
reasons why it is more natural to treat all pointers as compressed pointers when discussing this model. 
First, this allows us to to compress collections of strings using a common dictionary. Second, it allows 
us to to decompress arbitrary portions of the data without first having to pro- duce the entire string 
containing the desired por- tion. Third, compressed pointers can often require less space than original 
pointers. For these rea- sons, we shall concentrate our attention in this section on the EPM model and 
then indicate how our results can be extended to the OEPM model. As we shall see in the next section, 
there are some ad-vantages to using original pointers over compressed pointers that Justify consideration 
of the OEPM model. In many cases the extension of results to the OEPM scheme is trivial since if recursion 
is forbidden, original and compressed pointers become equivalent in power. Similarly, if overlapping 
is forbidden, unidirectional and bidirectional pointers become equivalent. THEOREM I: For all s, both 
'~ qs)' 'LJEPM ~ ' and V~OEPM(S) [ are: (A) Z MIN{prlog2(lsZ/i)l+p+i: p<I/2P}. (B) > MIN{3pFlogB([S[/2ij)l+21p+J: 
0/1/2 &#38; p<l<~p} when overlapping is forbidden. (C) > ,r2(pls[)l/2~, when recursion is forbid-den. 
 (D) > F2(pSsZ)1/21 when beth overlapping and re~ursion are forbidden. (E) A through D hold even if 
pointers are re-quired to be unidirectional.  Furthermore, these bounds are tight; that is, each is 
attained for infinitely many strings s. PROOF : Since ' ' ,/~OEPM(S) ,J~,~EPM(S) , it is suffi- cient 
to show that the OEPH scheme satisfies these bounds and the EPM scheme can attain them infinite- ly often. 
First, let us consider (A). We can assume that ' ' '~ (a[S~)s i s = a 's' (for some a~) because "=JOEPM 
 I I ,/~OEPM (s), . It is easy to show that for some p<ki2p and n, n /~OEPM(S) = aki=~lqlOqn+ 1 where 
ql' 1~l<n, points to the string represented by everything to the left of it and qn+1 points to some substring 
of the dictionary. Thus we have: [~OEPM(S)[ = k+np+p > k+p,rlog2( [ s[/k)~+p 2 MIN{p,rlog2( Is[/l)l+p+i: 
p<i/2p} For any p<ti2p and n, this bound is achieved with the EPM scheme on the string: s = a i2n We 
now consider (B). Again we can assume that s I I = a 's' . Due to the fact that overlapping is for- 
bidden, it is possible to divide the pointers of ~OEPM(S) into a sequence of sets $I,...,$ k such that 
pointers in Si, 1<i~k, point to strings whose compressed representation consists of the pointers in 
Si_ I. We can also assume that Si, 1~i~k, con- tains at most 3 pointers. This is true because for any 
n>3, there is an i and j such that i+J_~n.~213 j and so we can replace a set S i of ~ or more pointers 
by a sequence of sets having at most 3 pointers. Given this, it is not hard to show that for some p<Ki~p, 
O<+L!2, and n,/~0EFM(S) is of the form: aK(q~)L(q~)L_l n (~2q~)#q~+l where qo points to aK; ql points 
to q~; q2 points to a K, q~,- or q~- depending on whether L is O, 1, or 2~; and for 3~t/n+1, qi points 
to q~-l" Note that we are not asserting that every string can be so represented, but that the above represents 
a worst-case situation. Thus we have: ~/~OEPM(S) S = Z+Snp+2Lp Z K+3pFlog3( Is]/2KL)~+2Lp Z MIN { 3P 
Plog 3 ( ~s 1121J )I +2ip+J :  O!il2 &#38; p<j/4p} For any O!!/2, p<1<4, and n, this bound is achieved 
using the EPM scheme with no overlapping on the string: s = a j2i3n  The proofs for (C) and (D) appear 
in Storer [1977]. All of the proofs of (A) through (D) make use of left pointers only and so (E) follows. 
| Theorem I says just what one would expect; there is an ~(log 2' lal') lower bound on the size of a 
compressed string when recursion is allowed and an ~(~s~ I/2) lower bound when recursion is no~ al- 
 lowed. However, much of the utility of Theorem I comes from the fact that it provides exact bounds which 
are needed in several of our NP- completeness ~ proofs. The next theorem considers encoding algorithms 
for the EPM model. Wagner [1973] presents a poly- nomial time algorithm for compressing a string as-sumlng 
that the dlotlonary of macro bodies is given as input to the encoding algorithm. However, no mention 
is made as to how the selection of the best possible dictionary is accomplished. Several heuristic methods 
for constructing dictionaries %For any string s and integer r~O, sn denotes the empty string. $%For 
a definition of NP-completeness and _related terms, see Aho, Hopcroft, and Ullman [1976]. For historical_interest, 
~he reader may also refer to Cook [1971] and Karp [1972]. have been presented in Hayne and James [1975] 
and Rubin [1976]. Neither of these guarantees optimal compression or even provides bounds on the compres- 
Sion that is obtainable. The reason for this gap in the literature is the NP-completeness of finding 
 ~pM(S). THEOREM ~: Given a string s and an integer K, it is NP-compiete to determine whether I~EpH(s)I~K 
in any of the following situations: (A) Both recursion and overlapping allowed.  (B) Recursion allowed, 
overlapping forbidden.  (C) Recursion forbidden, overlapping allowed.  (D) Both rec~rsion and overlapping 
forbidden.  (E) Unidirectional pointers and any of A  through D. Furthermore, the above are true regardless 
if p is part of the problem input or is constrained to be a fixed integer greater than I. PROOF: The 
proof of each of the parts of the theorem requires a separate argument because no one part directly implies 
any other. The reductions employed include the node cover problem (Karp [1972]), the restricted node 
cover problem (Haler and Storer [1977]), the K_-node cover nroblem (Stor- er [1977]), and the superstring 
problem (Major and Storer [1977]). In Storer [1977], case D of Theorem 2 is strengthened to apply when 
p=1. Moreover, it seems likely that all of the results of Theorem 2 can be so strengthened, however, 
the proof for case D is very technical and this discouraged further inves- tigation into the case p:1. 
In Storer [1977], it is also shown that cases B through E of Theorem 2 hold for the EOPM scheme. Case 
A is shown for the problem of compressing collections but the single string problem remains open at the 
time of the writing of this abstract. Throughout this abstract, we assume that the al- phabets over 
which strings are written are unbound- ed in size. However, results concerning lower bounds on encoding 
complexity are stronger if they apply to the case where all strings are assumed to be written over some 
fixed size alphabet and, although unbounded size alphabets model many prac- tical situations (such as 
when entries in a system dictionary are taken to be the basic characters), there are certainly many situations 
in which it is more realistic to consider strings to be written over some fixed finite alphabet. Thus, 
it is worthwhile to consider the complexity of compress- ing strings when it is assumed that all strings 
are written over a fixed size alphabet. Since our motiwLtion for doing this is to model practical si- 
tuations, when discussing fixed size alphabets, we also require that pointers of a given size can only 
encode a finite amount of information. This re- quirement is met by stipulating that the pointer size 
p be dependent on the string being processed. Because complexity results concerning fixed size alphabets 
are more technical, we shall only state a few sample theorems to indicate the flavor of these results 
and only for the case when both recursion and overlapping are forbidden. Suppose we require pointers 
to be able to indicate any substring of the source. Then a pointer's length must be some implementation 
dependent multiple of the logarithm of the string length. THEOREM ~: If recursion and overlapping are 
for- bidden, then, given a string s over any alphabet with at least three symbols, an integer K, and 
a real h>O, it is NP-complete to determine whether s has an EPM compressed form t satisfying It~<__K 
when the pc inter size p is Fhlog2~sl]. Two other natural ways to determine pointer size are to either 
require that the information content of a pointer be sufficient to distinguish all the pointers in an 
encoding or else require that a pointer be able to identify any substring of the dictionary. To this 
end, if t is an encoding of some string using the EPM scheme, let 6(t) be the number of distinct pointers 
in t and let d(t) be the dictionary portion of t. TH___EOREM ~: If recursion and overlapping are for- 
bidden, then, given a string s over any alphabet with at least three symbols, an integer K, and a real 
hZ1, it is NP-complete to determine whether s has an EPM compressed form t satisfying ',t,~K ' in the 
following situations: (A) When p is Fhlog26(t)].  (B) When p is Fhlog21d(t) I~.  In Storer [1977], 
results similar to the above are shown for other combinations of restrictions. Although Theorems 3 and 
4 apply only for alphabets of size 3 or greater, we conjecture that these results can be strengthened 
to apply for two symbol alphabets.  The proofs of the last two theorems involve an extra level of complexity 
over the corresponding proofs for the unbounded alphabet cases because when one attempts to embed, say, 
an NP-complete graph problem in a data compression problem, one is forced to encode nodes of the graph 
as strings. Care must be taken to insure that the integrity of these strings is maintained during compression. 
 As was indicated at the start of this section, external macro schemes are also useful for compressing 
collections of strings. Many of the NP-completeness results of this section can be strengthened when 
applied to collections. For ex- ample, some results concerning bounded size alpha- bets, when extended 
to collections, apply for two symbol alphabets. Storer [1977] also contains results concerning limitations 
on the size of strings in a collection and factors in compressed forms. SECTION 4 THE INTE~--~C~0 MODEL 
In the internal macro model, it is rather unna- tural to forbid the use of recursion or overlap- ping. 
We shall therefore concentrate on the four combinations provided by choosing between compressed and original 
pointers and choosing between unidirectional and bidirectional pointers. As done in the last section, 
we first start with some performance bounds. THEOREM ~: For all strings s, both ~pM(s): and ~OPM(S)~ 
are greater than or equal to SIN{p[log2(~s~/i)]+i: p<i<2p} regardless of whether unidirectional or bidirec- 
 tional pointers are used. Furthermore, this bound is tight; that is, it may be obtained for infinite- 
ly many strings s. PROOF: The proof is very similar to that of Theorem I. | The next theorem deals with 
the relative power of compressed and original pointers. THEOREM ~: (A) For any string s, l~OPM(S)Z ~ 
~CPM(S)~  independent of whether unidirectional or bidirectional pointers are used.  (B) For any real 
h>O, there exist infinitely many s such that   '~OPM(S)' ~h I~CpM(S) I < . Furthermore, this applies 
for both uni-directional and bidirectional pointers. PROOF: The proof of (A) follows from the fact that 
a compressed pointer may be converted to an original pointer. Let us now consider (B). For n a multiple 
of p define s n = anbnn~(aiPbn-ip+1). i=I Using the OPM scheme, s n can be represented by the compressed 
form n/ t ~(n-ip,n+1) i=I where t is the best compressed representation of anb n. Since ~tl = O(plog2n), 
we have ~AOPM(Sn) l p(n/p)+O(plog2n) = n+O(plog2n). On the other hand, if we attempt to factor s n using 
the CPM scheme, the shortest compressed form is n n n/p a b ~(n-ip,n+1) i=I that is, the leading factor 
of anb n is preserved intact. Thus ~pM(Sn)~=3n. Hence, for any real h>O, we have for sufficiently large 
n: l~DPM(Sn) I n+O(plog~n) l~pM(s n) I = 3n ! 3 Th We do not yet know whether the bound in (B) is the 
best possible. Also, it should be noted that I I! although ,~OPM(S),~,~pM(s)~, in principle, it is 
possible for a compressed pointer to require less space than its corresponding original pointer, since 
for a given string s, compressed pointers may point to smaller strings. The next theorem addresses the 
question of UN (unidirectional) pointers versus BD (bidirectional) pointers. THEOREM [: For any string 
s, using either the CPM or OPM scheme, 1 l~D(S) I < l~D(S) I ! 1 and these bounds are tight; that is, 
they may be approached arbitrarily close for infinitely many strings. We now turn our attention to the 
co:~lexity of optimally compressing strings using the internal macro model. Unfortunately, like the EPM 
scheme, optimal encoding for the CPM scheme is intractable. THEOREM ~: Given a string s and a integer 
K, it is NP-complete to determine whether ',~CPM(S),' ~ K  even when any combination of the restrictions 
to unidirectional pointers, no recursion, and no over- lapping is made. Furthermore, this is true regard- 
less of whether the pointer size p is part of the problem input or is constrained to be a fixed in- teger 
greater than I. I The situation for the OPM scheme, however, is much better. Although, at the time of 
the writing of this abstract, the status of the encoding com- plexity of the OPM scheme with bidirectional 
pointers remains open, the unidirectional case can be done in linear time S . Lempel and Ziv [1976] (and 
Ziv and Lempel [1977]) have developed a data compression algorithm that falls within the frame- work 
of our OPM scheme with left pointers. (As we shall see from the proof of Theorem 10, a linear time encoding 
algorithm for left pointers implies a linear time encoding algorithm for unidirectional pointers.) Rodeh, 
Pratt, and Even [1976] have presented a linear time implementation of the Lempel-Ziv algorithm. Their 
implementation can best be described as a one-pass greedy algorithm. At each step, the longest possible 
prefix of the remaining input that matches some substring of the previously read input is removed from 
the input and replaced with a pointer. For example, if we have already processed ababc and the rest of 
the input is abcd, then we would output the pointer (3,3) and delete the next three characters of the 
input. The Lempel-Ziv algorithm is asymptotically optimal for ergodic sources as the length of the source 
string tends to infinity, however, for individual finite strings the compression achieved can be far 
from optimal. We write OPM/L to denote the OPM scheme restricted to left pointers. THEOREM ~: Let LZ(s) 
denote the compressed form of s obtained by applying the Lempel-Ziv algorithm. Then for any string s: 
 if p=1, then ~LZ(s)I = V~OPM/L(S)~ l~OpM/L(S)l if p>1, then~L-T < |LZ(s}; ~ I Furthermore, for any 
real number h>O, it is possi- ble to construct a string s over a two symbol al- phabet such that ~OPL/L(S)X/~LZ(S)~ 
~h- CNote that as with the CPM scheme, encoding for the OPM scheme with either or both of the recursion 
and overlapping restrictions (with unidirectional or bidirectional pointers) is NP-complete. A proof 
of this may be round in Storer[1977]. PROOF: Without loss of generality, we can assume that in any minimal 
length compressed form, any substring that is represented by a pointer to an earlier occurrence is as 
long as possible; that is, if Sm...s n is represented by a pointer, then Sm...Sn+ I is not a substring 
of Sl...Sm_ I. Let s be any string and consider t~pL/L(S) and U~LZ(S). Form the finest partition of 
t and u into segments t=tl...t m and U=Ul...u m such that for l!J~m,, tj and uj represent the same substring 
of s. In order to establish the bounds quoted in this theorem, it is sufficient to show that: :t I} 
: ~u1: : I p~_1 < ~ ,~j, --< I for J>1  It is easy to see that, for each i, one of the fol- lowing 
cases holds: (I) tj and uj both consist of a single char- acter.  (2) tj and uj both consist of a single 
pointer (which represent identical strings by the optimality principle stat- ed at the beginning of the 
proof).  (3) tj begins with a character and uj begins   with a pointer. In the first two cases, ~tj~ 
: luj~ : I and their ratio falls within the desired bounds. We must therefore establish the bounds for 
case 3. Let us write tj : Xlqlx2q2...XnqnXn+ I uj = rlYlr2Y2...rmYm  where each of the xi's and Yi'S 
is a string of zero or more characters and the qi's and ri's are pointers. A crucial observation is 
that any substring of s that is represented by characters (as opposed to pointers) in either tj or uj 
must be represented by a pointer in the other. This is true because of our definition of tj and uj in 
terms of a finest possible partition of t and u. The"figure below suggests the structure of that portion 
of s represented by tj and uj.  tj: IXll ql Ix l Ix31 ... uj: I"rl F'I r2 ,,lY21" .... I"" Notlce that 
for each i, 1~i~n, qi represents at least the last character represented by ri, all of Yi' and at least 
the first character represented by 36 - ri+ I. For 2~i<m, r i represents at least the last character 
represented by qi-1, all of xi, and at least the first character represented by qi" Some immediate consequences 
are that: (I) Either m=n or else m=n+1.  (2) For 1<i<n+1, ~xi~/p , or else we could re-  place x i 
with a pointer to some earlier oc- currence in s, thus reducing the length of t by at least one in contradiction 
to our definition of t as a compressed form of minimal length.  (3) for 1<i<m, ~yi~<_p-1, or else the 
Lempel-Ziv algorithm would have used a pointer instead  of Yi"  (4) ~ym~ <_9. A number of cases now 
arise. Case 1: Suppose that n=m. Since tj contains ex- actly n pointers and at least one character from 
x I we have ~tj~ >_ np+1. Now consider uj which also has exactly n pointers. Since each of the Yi (ex- 
cept possibly yn ) has no more than p-1 characters, lujl < np+(n-1)(p-1)+p : n(2p-1)+1. Thus,  I t 
 I nv+l ~Z n(2p-1)+1A p~l~-1" Case 2: Suppose that m=n+1 and Xn+ I is the empty string. Thus both tj 
and uj end in a pointer. It is not hard to see that Ym-1 must also be empty, or else the Lempel-Ziv algorithm 
would have replaced the string represented by Ym-lrm by a single pointer. Thus uj contains exactly n+1 
pointers, lykl!P-1 for 1<k_<n-1, and lyn~ = lYn+11 = O. Hence lujl = (n+1)p+(n-1)(p-1) = (2p-1)n+1. 
Once again we have, I I nn+1 lUjl --> n(2p-1)+1 > ~" Case ~: Suppose that m=n+l and that Xn+ 1 is 
not empty. By our definition of t and u in ter~s of a finest possible partition, it must be the case 
that Yn+1 is the empty string. Also, since the string represented by qn extends at least (p+1)-~Xp+11 
characters past Yn' it must be that lynZ<IXn+11 ; otherwise, the presence of qn implies that the Lempel-Ziv 
algorithm must place a pointer directly after r n (i.e., lynZ=O). Thus we have: It.l np+~ x11+i ~+I 
no+1 ~ nC2p-1)++yn:+1 > n(2p-1)+1 >-- In all of the above cases we have shown ~tjl/~uj~ ]5 p/(2p-1). 
Since we are using left pointers, it must be that t I and u I contain no pointers (and so ItiI=~u;~). 
Thus, It~=~ul for p=1 and Itl/~u~ > p/(2p-1) for p>1. For any p>1, using only a two symbol alphabet, 
we can approach the lower bound of p/(2p-1) as fol- lows: For k~O, let n = (p+1)2k-1 and s = abn+labn+ln~]P(abn-iabn-i) 
i=O It is easy to check that: ~oP L (s): (k+2n+l) + (n-v)(v+l) ,AL(~, . ,L.LZ~j, = (k+2p+1) + (n-p)2p 
n(p+1) + O(plog2(n)) = n(2p) + O(plog2(n)) _> ~!p as n-~co For p=1, p/(2p-1)=(p+1)/2p=1, and as p gets 
large, both quanities converge to I/2. Nevertheless, for p>1, p/(2p-1) is strictly less that (p+1)/2p 
and so we are left with a small "gap". At the time of the writing of this abstract, this gap has not 
been resolved, i Although the Lempel-Ziv algorithm is not optimal for p>1, our next theorem shows that 
a linear time algorithm does exist for optimally compressing strings using the OPM scheme restricted 
to uni- directional pointers of any size. In view of the number of NP-completeness results presented 
thus far, this is a pleasing result, especially since the OPM scheme has many practical applications. 
 In what follows, if s and t are strings, let MIN{s,t} denote the string with the shorter length. THEOREM 
I0: For any string s, _/%OPM/UD(S) can be constructed in linear time (on a RAM). PROOF: Given a string 
S:Sl...Sn, /]OPL/L(S) may be computed by performing the following steps (note that SHORT[] and MATCH[] 
are arrays of strings): A: Let MATCH[k], l!k_~<n, be the longest string si...s j such that j<k and 
si...s j = Sk...Sk+j_ i. Also, let qk denote a pointer to MATCH[k]. B: SHORT[n]=s n C: DO i=n-1 TO 
I BY -I; SHORT[i]=MIN{siSHORT[i+I], qiSHORT[i+~MATCH[i]I-I]} D: A OPL/L(S) = SHORT[I] The algorithm 
is a dynamic programming algorithm which utilizes the optimality principle stated at the beginning of 
the proof of Theorem 9. Each string SHORT[I] computed by the algorithm is the  shortest compressed 
form for si...s n given that Sl...si_ I is available as a "dictionary". By using the appropriate data 
structures, step A can be per- formed in linear time using the algorithm described in Rodeh, Pratt, and 
Even [1976]. To perform step C in linear time, we note that the array SHORT can  be represented by storing 
at SHORT[i] s i (or qi ) followed by a pointer to SHORT[i+I] (or SHOHT[i+~MATCH[i]I-I]). In step D, we 
can easily write out SHORT[I] in linear time by following the sequence of pointers through the array 
SHORT. Hence, the entire algorithm to compute~OPL/L(S) is in linear time. To compute~oPM/UD(S) , we 
can compute ~OPM/R(s) using the above algorithm on the reverse of s and then~oPM/UD(S) = MIN{~oPL/L(S),~OPM/R(s)]. 
I It should be noted that the Lempel-Ziv scheme uses the same decoding algorithm as any other uni- directional 
OPM scheme, and so the decoding com- plexity of our method is the same as that of Lempel-Ziv. RELATIVE~~CE 
BOUNDS Although a number of bounds have already been given on the relative performance of various pairs 
of compression methods, we have yet to compare the effectiveness of the external schemes to the inter- 
nal schemes. We shall now present a few results of this kind. In order to avoid trivial comparisons, 
we shall require that both schemes under comparison allow recursion if either does (otherwise the rela- 
tive performance goes to zero). All of the rela- tive performance bounds presented in this section and 
previous sections can be achieved using a two symbol alphabet. THEOREM 11: For any string s,    i 
P,(S) I 1 < ,~pM(s), X 1 if overlapping is forbidden in the EPM model. Moreover, these bounds are tight. 
I Since we showed in the last section that for all s, l~OPM(S)I ! I~CPM(S)I, this result says that without 
the ability to overlap, the EPM model can never do better than either of the internal macro models. On 
the other hand, THEOREM 12: For all strings s,  (A) ~-~I~pM(S)I < ~pM(S)l l~Cps(S) I +P- (B) ½=~CPM(S): 
< i~EPM(S)~ ~ ~CPM(S)= if recursion is forbidden (for both). Furthermore, the bounds of A and B are tight 
and apply even if OPM is used instead of CPM and OEPM instead of EPM. | AS with the ratio l~OPM(S) 
I/l~pM(s)l, we have no tight lower bound on the ratios V~EPM(S) I/V~OEPM(S)I and V_~ps(S)~/V~OPM(S)~. 
Of course, for all strings s, just as ~pM(s)~ l~Ops(S)1, it is true that ~pM(s)~!l~0EPM(S)l. Similarly, 
just as l~pM(s)~!l~pM(s)l+p, it is true that l~OEPM(S)~!~OPM(S)~+p. We have investigated various aspects 
of the mac- ro model for performing data compression by text substitution. Results have included NP- 
completeness theorems on the complexity of finding the most compact encodings for several different macro 
schemes, relative performance bounds on many pairs of schemes, and a linear time algorithm for perfo:rming 
optimum compressions using one of the more practical schemes. Most of the schemes we have presented have 
efficient linear time decoding algorithms and so the NP-completeness results presented in this abstract 
should not discourage further investigation of these schemes. It seems likely that fast and effective 
approximation algo- rithms for compressing strings exist for many of the macro schemes with NP-complete 
encoding com- plexities. In addition, a number of further results that we have not been able to discuss 
in this abstract lead to polynomial time compression algorithms for various restricted forms of these 
problems. A. V. Aho, J. E~ Hopcroft, and J. D. Ullman [1976]. The Design and Analysis of ComDuter i~~eco~printing, 
Addison-~, Reading, Mass. S. A. Cook [1971]. II The Complexity of Theorem Proving Procedures , Proceedings 
Third Annual ACM Symposium on Theory of Computing, Shaker Heights, Ohio, 151-158. M. R. Garey, D. S. 
Johnson, and L. Stockmeyer [1976]. "Some Simplified NP-Complete Prob- lems". Theoretical Computer Science 
I, 237-267.  W. D. Hagamen. D. J. Linden, H. S. Long, and J. C. Weber [1972]. "Encoding Verbal Information 
as Unique Numbers", IBM SYstems Journal 11. B. Hahn [1974]. "A New TechniQue for Compression and Storage 
of Data", CACM 17:8, 434-436. D. A. Huffman [1952]. "A Method for the Construc- tion of Minimum-Redundancy 
Codes", Proceedings of the IRE 40, 1098-1101. R. M. Karp [1972]. "Reducibility Among Combina- torial 
Problems", in Miller and Thatcher (eds.), Comolexitv of Comnutations, Plenum Press, New York, N.Y. 
 A. Lempel and J. Ziv [1976]. "On the Complexity of Finite Sequences", IEEE Transactions on Information 
Theory, 22:1~-'/5-81. M. E. Lesk [1970]. "Compressed Text Storage", Com- puter Science Technical Report 
#3- Bell La- boratories, Murray Hill. D. Maier [1976]. "The Complexity of Some Problems on Subsequences 
and Supersequences". Technical Report 219. Dept. of Electrical Engineering and Computer Science, Princeton 
University, Princeton, N.J. D. Maier [1977]. "The Complexity of Some Problems on Subsequences and Supersequences", 
Confer- ence on Theoretical Computer Science, Univer- sity of Waterloo, Waterloo, Ontario, Canada. D. 
Maier and J. A. Storer [1977]. "A Note Concern- ing the Superstring Problem". Technical Report 233, Dept. 
of Electrical Engineering and Com- puter Science, Princeton University, Prince- son, N.J. J. P. McCarthy 
[1973]. "Automatic File Compres- sion", International Computing Symposium (North Holland). B. A. Matron 
and P.A.D. De Maine [1967]. "Automat- ic Data Compression", CAlM 10:11, 711-715. A. Mayne and E. B. 
James [1975]. "Information Compression by Factorising Common Strings", The Computer Journal 18:2, 157-160. 
 J. A. Storer [1977]. "NP-Completeness Results Con- cerning Data Compression", Technical Report 234, 
Dept. of Electrical Engineering and Com- puter Science, Princeton University, Prince- ton, N.J. J. A. 
Storer [1977b]. "PLCC-A Compiler-Compil@r for PLI and PLC Users", Technical Report 23b, Dept. of Electrical 
Engineering and Computer Science, Princeton University, Princeton, N.J. J. A. Storer and T. G. Szymanski 
[1977]. "The Mac- ro Model for Data Compression" Technical Re- port 235, Dept. of Electrical Engineering 
and Computer Science, Princeton University, Princeton, N.J.  F. Rubin [1976]. "A New Technique for 
ComPression and Storage of Data", CACM 17:8, 434-436. M. Rodeh, V. R. Pratt, and S. Even [1976]. "A 
Linear Time Algorithm for Finding Repetitions and its Application to Data Compression", Technical Report 
#72, Dept. of Computer Sci- ence, Technicon, Israel. S.S. Ruth and P. J. Kreutzer [1972]. "Data Compression 
for Large Business Files", Datamation 18:9, 62-66. M. Visvalingam [1976]. "Indexing with Coded Deltas 
-A Data Compaction Technique", Software - Practice and Experience 6, 397-403. R. A. Wagner [1973]. "Common 
Phrases and Minimum- Space Text Storage", CACM 16:3, 148-152. J. Ziv and A. Lempel [1977]. "A Universal 
Algo- rithm for Sequential Data Compression", IEEE Transactions on Information Theory 23~, 337-343. 
 -39 -   
			