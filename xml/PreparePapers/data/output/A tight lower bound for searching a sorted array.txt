
 A tight lower bound for searching a sorted array Arne Andersson* Johan H%tadt Ola Petersson** Abstract 
We show that given a k-character query string and an ai-­ray of n strings arranged in alphabetical order, 
finding a matching string or report that no such string exists requires k log log n +k+logn a (log log 
(4+ k 1;:;; n ) ) character comparisons in the worst case, which is tight. 1 Introduction The problem 
of searching a sorted set of strings is indeed fundamental. We assume that the strings are given in (lex­ 
icographically) sorted order in an array and that no extra information is available. In general, one 
cannot assume that two strings can be compared in constant time, but must consider the number of characters, 
or machine words, that need to be inspected. Given its significance, the problem has received surpris­ingly 
little attention. A first non-trivial upper bound of O(k log n/ log k) was mentioned by Hirschberg [3]. 
Next, Kosaraju [4] gave an upper bound of 0(.k= + log n), and recently, Andersson et al. [1] presented 
an upper bound of the same complexity as the lower bound claimed in the abstract. This subsumes both 
previous results. Hirschberg [3] pointed out a trivial lower bound of f2(k + log n): if k = 1 any algorithm 
makes fl(log n) compar­isons; moreover, it has to inspect all characters of the query string. The only 
non-trivial lower bound deals with con­stant factors: Kosaraju [4] showed a lower bound of roughly 10g 
n + ~~= = O(k + log n) characters comparisons. In this article, we show the following lower bound. Theorem 
1.1 Given a k-character query string and an ar­ray of n strings arranged in alphabetical order, to jind 
some matching string or report that no such string exists requires k log log n +k+logn n (log log (4+ 
k l:;gl:~ n ) ) character comparisons in the worst case. * Department of Computer Science, Lund Umvers]ty, 
Box 118, 22100 Lund, Sweden. {arne,ola}K2dna lth.se tDepartment of Computer Science, Royal Institute 
of Technology, 10044 Stockholm, Sweden. Johanh@nada.kth se. Part of the work was done while visiting 
MIT. $Department of Mathematics, Statlstlcs, and Computer Science, Vaxj6 University, 35195 Viixj6, Sweden. 
The work was done while visiting Columbia University. Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyn ht notice and the title of the publication and. its date appear, an 8 notice is given that 
copym ISby permission of the Association of Computing Machinery. o cop otherwise, or to republish, requires 
y [ a fee andlor specl ICpermission. STOC 95, Las Vegas, Nevada, USA 01995 ACM 0-89791 -718-9/95/0005 
..$3.50 As this bound matches the recently shown upper bound [1], we close the problem, at least regarding 
its asymptotic com­plexity. 2 Preliminaries For the purpose of proving a lower bound, we study the fol­lowing, 
somewhat restricted, problem: The input is stored in a matrix of width n and height k, in which the columns 
are numbered from left to right and the rows from top to bottom. The strings contain only O s and 1 s, 
no string con­t ains more than one O. and thev are storec~ in (lexico~raDh­ically) sorted order in the 
columns of the lmatr~x. Th e t~sk is to determine the column of the leftmost string consist­ing of k 
1 s, and we charge an algorithm ~according to how many matrix entries it examines. Lemma 8.1 elaborates 
on the relation between this seemingly simpler problem and the original one. To simplify matters further, 
we concentrate on a certain class of algorithms, called fence algorithms. The concept of a fence algorithm 
was defined in the paper which described the upper bound [1], and it was shown that for any algo­rithm 
there exists a corresponding fence algorithm of the same asymptotic complexity. We provide a brief sketch 
of this proof below. First, we recall what ccmstitutes a fence algorithm. A fence is a contiguous portion, 
starting at the top row, which is known to contain only 1 s, of a column of the ma­trix. The height of 
a fence F is denoted by IF I and defined as the number of rows spanned by the fence. The way we have 
stated the problem implies that all entries on the IFI top rows to the right of F (inclusive) contain 
1 s. To illustrate some important concepts, suppose an algo­rit hm starts by probing the middle position 
of the top row. If it finds a 1 then it has erected a fence of height one, and it can conclude that all 
entries on the top row to the right of the fence are also 1 s. Suppose the algorithm next probes and 
finds a 1 in the middle entry of the second row, i.e., the entry immediately below the just probed one. 
Suppose the next probe is made one quarter from the left end on the first row, and that it results in 
a 1. Our algorithm has then erected a second fence. The algorithm might then decide to probe at the first 
fence again, extending it to height three, etc. It is not difficult to see how the algcmithm can create 
several fences in this way. A fence algorithm is an algorithm which only makes two different kinds of 
probes: extension of an existing fence, or creation of a new leftmost fence. If a fence algorithm encounters 
a O when attempting to extend a fence F,, it can conclude that all columns to the left of the O (inclusive) 
need no longer be cc,nsidered, and the algorithm can thus reject them. The algorithm can further conclude 
that all rows above the O (exclusive) can be omitted from consideration. This follows from that the [F, 
[ top rows to the right of the fence F, contain only 1 s. The problem 417 can thus be reduced by excluding 
these rows. In our termi­nology, the following four events occur: (1) the rightmost O moves to the right; 
(2) we get a new top row; (3) fences of height at most ]F, I disappear completely (which makes sense 
because they no longer contribute any useful information of the whereabouts of the sought column); (4) 
the heights of all remaining fences are reduced accordingly. Let FI and FZ be two fences such that FI 
resides to the left of FZ and IFI I < IF2 j. If FI is extended to the same height as Fz then Fz ceases 
to exist. The justification for this is that the information that can be concluded about the matrix from 
Fj is strictly less than what can be concluded from FI. We say that F1 and Fz merge. The fences are numbered 
in descending order from right to left, starting with fence Ftj where t is a parameter to be specified 
below. Thus, from right to left, at any point in time we have fences Ft, Ft-1, . . . When two fences 
F, and F,+ I merge, F,+ I disappears, and all fences to its left are renumbered such that the indices 
of two neighboring fences differ by exactly one at any time. It follows that any fence is shorter than 
its right neighbor. For technical reasons we also have a virtual fence in column n + 1, which is denoted 
by F,+I, and which is of height k. A fence algorithm also allows an adversary to make fence probes at 
any moment. These probes will cost nothing to the algorithm but have the same effect in terms of creating 
fences, excluding rows etc. As already mentioned, in a previous paper [I], the fol­lowing lemma was proven: 
Lemma 2.1 If the restricted searching problem can be solved using at most T probes, it can be solved 
by a fence algorithm using at most 2T probes. Sketch of proof. The lemma is proven by showing that, given 
an arbitrary algorithm A and an input matrix -7, there exists a fence algorithm Af and a matrix 1 such 
that the cost of running Af on 1 is at most twice as high as that of running A on 1 , and the outcome 
of A on 1 is exactly the same as the outcome of Af on 1. At and 1 are defined on­line as A runs. At any 
time, the two algorithms maintain the same set of fences. Aj performs essentially the same probes as 
A, though not always in the same order. If A makes a fence probe at entry p, then Aj probes entry p of 
1, and its outcome is copied to 1 . If A makes a probe which does not extend a fence or create a new 
leftmost fence, there are two possibllties. First, A may probe an entry whose cent ents is known, or 
an entry in an excluded column. In this case, the probed entry in 1 is set to 1, and no probe is made 
by Af. Second, A may probe an entry p somewhere in the unex­plored area below the fences. p does not 
extend any fence, but might become part of a fence later on. In this case, p is set to 1 in 1 . If entry 
p in 1 contains a O, this is compen­sated for later on by placing a O in 1 . This happens when A makes 
a connecting probe at entry g in 1 that-if an­swered by l makes p part of a matching prefix. Then g is 
set to O; we also reveal a O in the topmost unknown entry in p s column. In this way, the invariant that 
both algorithms maintain the same fences is preserved. Af does not execute the probe at p immediately, 
but postpones it until a fence in p s column, or in a column to its left, reaches the row immediately 
above p. Note that this happens when A makes a connecting probe. If the arriving fence is in the same 
column as p, then Aj performs the probe. Otherwise, instead of probing p, Af extends the arriving fence 
by probing on the same row as p. If it finds a 1, p must also cent ain a 1. Otherwise, the probed row 
becomes the top row, and Af can execute the originaf probe as a fence probe. In the last case, two fence 
probes simulate the probe at p. We show: Lemma 2.2 Successful searches in the restricted searching problem 
require ( k log log n Q +k+logn log log (4+ k ;:;: n ) ) probes in the worst case. In Theorem 1.1 we 
claim that this lower bound applies to a somewhat different problem, in that we include unsuc­cessful 
searches as welf as only require a successful search to report some matching string. Observe that in 
the restricted p~oblem, there is a trivial @(k) -time query algorithm for the problem addressed in Theorem 
1.1, which simply inspects the rightmost string. If it contains only 1 s the search is suc­cessful; if 
it contains a O the search is unsuccessful. Thus, Theorem 1.1 does not follow immediately from Lemma 
2.2. We return to this issue in Section 8, where we show that it does indeed follow from our lower bound 
proof. 3 Intuition Let us try to give an intuitive explanation of some important parameters, used to 
prove the lower bound. Recall that fence algorithms maintain an ordered collection of fences, 7. Important 
properties are the number of fences in F, the distances between fences, and their heights. Suppose there 
is a fence algorithm which makes at most tkprobes, for some value of t.Below, we make three observations 
that relate the parameters of an algorithm to t. We stress that we do not claim to prove anything in 
this section; we merely give the intuition behind the choice of parameters. The arguments given are sometimes 
imprecise and sloppy. 1 Assume that a new fence F, is created by probing the middle entry of the unknown 
part of the top row, that is, one step of a binary search for locating the right­most O is made. (This, 
significantly simplifying, as­sumption is only made in this section for the sake of intuition. ) Suppose 
more such probes are made which all find 1 s. In effect, F? moves leftwards. An intuitive way to quantify 
the horizontal investment in F, is to count the number of binary search probes invested in it. Denote 
this quantity by Ai. 2, If x fences exist at the moment when a row is excluded, the algorithm has spent 
at least z probes on that row. If the algorithm want to ensure the cost per row to be at most t,the cardinality 
of Y should not exceed t at any time. This suggests that the algorithm should spread the fences wisely. 
3. Let us briefly describe a natural accounting scheme. When a fence is created or extended by one probe 
the 418 vertical investment in the fence increases by one, and when two fences merge, the new fence 
gets the sum of the vertical investments of the participating fences plus the number of actual probes 
performed to accomplish the merge. Then, the algorithm must ensure that the vertical investment in a 
fence during its lifetime must not be too large, unless it is tall enough. To see why, suppose more than 
tl~[ probes have been invested in fence F. Then, a failure to extend F results in that [Fl rows get excluded 
at a cost of more than t per row. Hence, a fence must be kept sufficiently tall so that a failure to 
extend it is not too costly for the algorithm. We proceed by combining the above observations to de­rive 
some ideas on how the algorithm should chose its pa­rameters. The second observation states that we should 
have at most tfences. A natural way to spread them is at exponen­tially increasing distances, where the 
distance is measured according to the first observation. This means that distances of neighboring fences 
should increase by a factor of c, where log log n c~=logn * logc= (1) t since the maximum distance between 
any two fences is at most log n. To apply the third observation, consider what happens when an extension 
of a fence F, fails, The number of rows gained must compensate for the loss of both horizontal and vertical 
investments. The algorithm should thus attempt to keep F, higher than some lower bound, which is a function 
of the total investment in F,. Denote this function by T. To determine the function T we have a number 
of relations to consider. Consider first the loss in horizontal investment. It must hold that T(A, ) 
> A,/t, (2) since otherwise a failure to extend F, would result in the exclusion of IF, I < A, /trows, 
which would cost the algo­rithm more than tprobes per row. Hence, the horizontal investment in F, puts 
one restriction on T. Next, the vertical investment in F, should be at most th,, since otherwise the 
loss of this investment cannot be com­pensated for by the number of rows excluded. The vertical investment 
in a fence depends heavily on how much it has been merged. In order to understand how it grows, note 
that when merging two fences F, l and F,, the A-value for the resulting fence F, (recall that renumbering 
occurs after the merge) becomes the sum of the previous A1._l and A,, Due to the distance ratio c described 
above, a merge increases the A-value by a factor (1 + l/c), that is, A: =A,-l +A, =(1+l/c) A,, (3) where 
A; is the distance after the merge has taken place. Suppose that, prior to the merge, F,_l and F, are 
of heights T(A,.-J ) and T(A, ), respectively, and that t T(A,-I ) and t T(A, ) probes, respectively, 
have been invested in them. Then, the vertical investment in the (new) fence F, after the merge is t[T(A,-, 
) + T(A, )] + T(A; ) T(A,-, ). If we disregard the last term (which turns out to be insignif­icant) 
and observe that T grows at least linearly, by Equa­tion (2), this expression is at least (t+l)[Z (A,_l 
) +T(A, )]. As the vertical investment in the new F, should be at most t T(L~), we get the relation: 
(t+ l)[T(A,_, ) +T(A,)] s t2 (A:). Using Equation (3) and disregarding T(A, 1) gives: (t+ l) T(A,) < 
tT((l + l/c)A,), which has a solution of the form T(A*) z a . A~ t, for some constant a. Setting Al+ 
C/t T(A, )= ~ satisfies this requirement as well as Equation (2), Finally, the fact that the tallest 
possible fence (which might have A-value of log n) should span about all rows gives a relation to the 
the number of rows, k, namely T(log n) = (lOg t~ +c = ~, which implies c log c = log(tk/log n), Together 
with Equa­tion (1) this gives the values of c and t. Essentially, the algorithm of Andersson et al. [I], 
which achieves the optimal upper bound, can be derived from the above discussion by defining everything 
precisely and ad­justing a few constants. The lower bound is proven by means c,f an adversary for fence 
algorithms. This adversary keeps track of the invest­ments made by an algorithm, and whenever the algorithm 
has not protected its investments by erecting tall enough fences, it reveals information that makes the 
algorithm lose its investment at too high cost. The adversary s actions ba­sically forces the algorithm 
to behave as described above, or it will do worse. One detail which makes the lower bound proof quite 
in­volved is that we need to take special care of probes on the first row since we cannot assume that 
the algorithm always makes its probes in the middle. Dealing with this is nontriv­ial. It is not intuitively 
clear that biased probes do not help. Interestingly, the algorithm that achieves the optimal upper bound 
does not make biased probes [1]. However, an algo­rithm using biased probes might achieve an improvement 
in constant factors. 4 Two proofs For small k s, k = O(log n/log log n), and for large k s, k = f@h ~) 
), for any constant t >0, the bound claimed in Lemma 2.2 reduces to the trivial lower bound of Q(k+log 
n). It thus suffices to provide a proof for intermediate values of k. The proof is divided into two similar, 
but different proofs handling two ranges of k s. The proof for small k s takes care of log n/log log 
n < k ~ log n, and the proof for large k s assumes that log n < k < 2(10s )1 4 . The two proofs share 
the same structure; however, the calculations are somewhat different. Due to lack of space, this extended 
abstract only contains a complete version of the proof for large k s, which is also the easier of the 
two. In Section 7 we outline the proof for large k s. Until then we can thus assume that log n < k < 
2( Og ) 4 . 419 5 The adversary Before specifying the adversary, we introduce some param­ eters and 
notation. Define c = og(k( o:::n) ) ~ = loglogn lologc B = max{lOclogc,l +logk}. Our aim is to prove 
an Q(kt)lower bound on the num­ ber of probes required. This yields the desired lower bound when k ~ 
log n. Observe that if t = O(1) the aimed bound reduces to the trivial lower bound, and so we can assume 
that t is greater than some sufficiently large constant. The same applies to c, which is super-constant 
for k ~ log n; and then also to 1?. Finally, note that the upper bound on k implies that B = 0(-. For 
any fence F,, h; denotes the height of F,, that is, h, = h(~,) = [F; 1. Let Fd be the leftmost fence. 
Define m&#38;l = m = log(column of ~~ column of the rightmost O). This reflects the uncertainty on the 
top row, in that by mak­ ing m binary search probes on the row an algorithm will know its entire contents. 
For any other fence F,, define m,= m(F,) = log(column of F,+l column in which F, was created), which 
approximates the new value of m if F, finds a O. Fi­ nally, for any fence Fi, define A, = A(F,) = Bm 
-l . This quantifies the dist ante between F, and F,+l. Note that h,, m,, and A, are attributes of fence 
F, not of index i so if F, changes index then its h-value, m­ revalue, and A-value remain the same (unless 
their underlying parameters change). We use the shorter forms for the sake of brevity. 5.1 A game Our 
adversary plays a game against a fence algorithm. Each probe made by the algorithm is answered by the 
adversary, which also sometimes reveals the contents of other entries at no cost to the algorithm. The 
adversary will reveal information which is unfavor­ able to the algorithm. Suppose the algorithm has 
erected a fence F, of height h, and that it has performed Q(h, t) probes on the top h, rows. Then the 
adversary might reveal a O immediately below fence F,. We call this putting a o on F,. This results in 
the exclusion of the columns to the left of F, (inclusive) and the top h, rows. The adversary does not 
always put a O on a fence once the above condition holds; however, whenever it does then the condition 
holds. It is not obvious why this would be unfavorable to the algorithm. After all, it learns everything 
it needs to know about the top h; rows, and thus need not invest any more probes on these rows. The underlying 
motivation for the adversary s behavior is that the dist ante from the leftmost fence to the rightmost 
O increases; a drawback for the algo­rithm. For each excluded row, the algorithm has thus made Q(t)probes. 
Since we aim to prove a lower bound of Q(H) it is natural to declare the adversary a winner of the game 
if it manages to exclude all rows. (Formally, excluding the kth row would require putting a O on row 
k + 1. However, there is no need to explicitly place this last O, just the fact that the adversary can 
allow itself to do so is enough to conclude that the algorithm has used Q(kt) probes.) On the other hand, 
if the adversary is not able to exclude the remaining rows when the algorithm has terminated the algorithm 
wins the game. (The adversary is thus allowed one more move after the algorithm has terminated.) The 
search can terminate in two ways: the algorithm successfully finds the leftmost column containing only 
ones, or it finds a O in the rightmost column, in which case the search was unsuccessful. 5.2 Accounting 
In order to be able to carry out its strategy, the adversary keeps track of the probes performed by the 
algorithm by attributing them to the fences and to a horizontal (probe) counter, as follows: If a probe 
extends an existing fence F,, attribute eight probes to F,.  Let F, be the leftmost fence. If a probe 
is made on the top row, erecting F,_l, theneight probes are at­t ributed to Fi-], three probes are attributed 
to F,, and four probes are attributed to the horizontal counter.  When F,. and F, l merge then the new 
Fi is attributed the sum of the attribu~ions to the two old fences.  s Whenever a O is put on F,, then 
delete h, attributed probes from each remaining fence; -~~=. A, attributed probes from the horizontal 
counter; and all probes attributed to F, and the fences to its left. Lemmas 6.6 and 6.7 below ensure 
that there will al­ways be enough probes to delete. Following these rules, each probe made by the algorithm 
yields at most 15 attributed probes. Hence, the total num­ber of probes getting attributed is at most 
linear in the ac­tual number of probes made. It is thus sufficient to derive a lower bound on the former 
quantity. In the following, A, = A(F,) and C denote the number of probes attributed to fence F, and the 
horizontrd counter, respectively. 5.3 The adversary s strategy In order to understand how the adversary 
acts, first note that, intuitively, the goal of any fence algorithm can be thought of as constructing 
a fence far to the left. Basi­cally, there are three different ways for the algorithm to pursue this 
goal, and for each of those there is a counteract­ing adversary rule. Before presenting the precise rules 
we give some intuition. First, when creating a new fence, the algorithm may try to place it far to the 
left of the leftmost existing fence. This 420 is prevented by rule A, which simply answers O if a probe 
is made too far to the left on the top row, Second, it may try to advance Ieftwards by erecting many 
fences. This is handled by rule B, which puts an absolute restriction on the number of fences that an 
algorithm is allowed to maintain simultaneously. Third, to be allowed to erect a new fence further to 
the left, the algorithm might start by reducing the number of fences by merging two existing fences F,_l 
and F,. This strategy has two consequences: the horizontal distance from the new F, (that results from 
the merge) to its right neighbor, F,+ 1, increases; and, by the accounting scheme following a merge, 
the number of probes attributed to F, increases. Adversary rule C ensures that fences are not too far 
apart, and rule D puts a restriction on how many probes can be attributed to a fence. The first of the 
rules specifies how probes on the top row are answered. Rule A: Let F, be the leftmost fence, and suppose 
that the rightmost O is in column r, that is, F, resides in column r + 2m. A probe in column r + a2m, 
where 0< a <1, on the top row is answered as follows: 1. If a s l/2B+l, a O is answered. The adversary 
also reveals a 1 in column r + 2m-B. 2. If a > l/2B+l, a 1 is answered. If a > l/2B the  adversary 
also reveals a 1 in column r + 2m-B. Thus, one new fence F,-1 is alwa s created between J columns T + 
2m-B-1 and r + 2m-. Any probe that attempts to extend an existing fence is answered by 1. However, after 
any probe made by the al­gorithm the adversary checks if any of the following rules apply. If it does, 
it is executed; otherwise, the algoritlun is allowed to make another probe. If several rules are enabled, 
they are executed in the order in which they are given. Rule B: Whenever FO exists, put a O on it. Rule 
C: If A, > h,t, put a Oon F,. Rule D: If A, > h,t, put a Oon Ft. 6 Analysis In Section 6.1 we state and 
prove a number of lemmas which explain the immediate effect on the A-values caused by the various actions 
by the adversary and the algorithm. Then, in Section 6.2 we provide the main argument of the proof, and 
in Section 6.3 we prove the main lemma used in the main argument. In the sequel, for any variable X, 
let X denote the new value of the variable after some type of change has taken place. 6.1 Basic lemmas 
The proofs of the lemmas below require no nontrivial obser­vations and are purely algebraic. During the 
first reading the impatient reader might therefore want to skip them in order to reach the action in 
the next subsection. The first two lemma investigate how a probe on the top row affects the A-values: 
Lemma 6.1 Let F, be the leftmost fence. Then, after a pTobe on the top Tow we have 1. m~=m~, foranyj~i; 
.2. m +log(l l/2B) ~ mJ_l ~ m +log(l l/2 D+l); 3.m l?-l<m <m-B. Proof. Recall the definition of m,. 
T% first claim is ob­vious. Consider the second claim. 2m*-I is the dktance (number of columns) between 
the new fence and F,. This is maximized (minimized) if F,_ I is erected as close to (far away from) the 
rightmost O as possible. Hence, m~_l ~ log (2m 2m B) = m +-logl(l l/2B) and m~_l < log (2  2m-B-1) 
= m +log(l l/2 B+]). 2m is the distance from the rightmost O to F,-l, and so m is maximized (minimized) 
if F, -I is erected as far away from (close to) the rightmost O as possible. Hence, m B l=log2m ~-1 <m 
~iog2 n-B=m B. The next lemma follows from plugging in the upper and lower bounds on m~_l, m;, and m 
, provided by the above lemma, in the definition of A,. Lemma 6.2 Let F, be the leftmost fence. Then, 
after a probe on the top row we haue 1. A, ~A; ~A,+1/2B; 2. 1/2<A;_l ~2. Proof. By definition and Lemma 
6.1, we have The first claim then follows by replacing m~_l by the upper and lower bounds provided by 
the above lemma: m, -(m +log(l -l/2B~ A; ~ B log(l l/2B) < &#38; + l/2B, = A, B for sufficiently large 
B, and A, > m, (m +log(l -l/2 B+l)) z_ B log(l l/2~+1) > A = A,-B Similarly, since A~_l = (m~_l m 
)/,I?, we have m+log(l l/2B+l) (m B -1)A; l < B log(2~+l 1) <B+1<2 . B B 421 because B~l; and Al 
, m+log(l l/2~) (m B) =,-1 L B log(2B l)>u~l/2. B B = 0 We also show that a A-value never declines below 
its initial value: Lemma 6.3 For any fence Fi, Ai > 1/2. Proof. The claim holds initially, by Lemma 6.2. 
As long as F, exists, the only parameter in the definition of A, that can change during the course of 
the search is ma-l. However, its initial value is an absolute upper bound on its future value. The lemma 
follows. o The next lemma shows that putting a O on a fence never increases the A-value of the new leftmost 
fence: Lemma 6.4 If a O is put on F,-l, then Al < At. Proof. Note that m~_l = m and m{ = m,. If F,-1 
has not merged with its left neighbor since it was created then m = m,_l, in which case Ai remains the 
same. Otherwise, F,_l has merged to the left, in which case m > m, .-l, and so A, decreases (slightly). 
0 The next lemma shows how a merge affects the A-values. Lemma 6.5 If F, and F, 1 merge then AJ_I j<i 
1, A; = A, +Ai-l j=i. { Proof. Recall that as a result of the merge, the former F, disappears , and 
due to the renumbering, after the merge, fence F: resides in the same column as F,_l did before the merge. 
Also, the indices of all fences to the left of F/ are incremented by one. For the new F;, we have ml 
 m~_l = m% m%-2 A; = BB mi mi_l m,_l mi-z = B+ B = A, + A,_I. For any fence F;, j s i 1,to the left 
of the merge, 0  6.2 Main argument We first prove that if the adversary wins, i.e., excludes all rows, 
then the algorithm has indeed made Cl(kt) probes (Lemma 6.8). We then show that the algorithm cannot 
win (Lemma 6.11). If combined, these two lemmas lead to Lemma 2.2. Lemma 6.6 For any fence F,, A, z h,. 
Proof. This is easily proven by induction. Whenever h, increases by one, A, increases by eight; and whenever 
hi decreases by one, A, decreases by one. 0 Proof. The proof is by induction on the probes. Initially 
the claim holds trivially. When a new fence F,--l is erected, the sum increases by by Lemma 6.2, and 
so the four probes added to C pay for the increase. If F, and F, -l merge then, by Lemma 6.5, the sum 
is not affected. When a O is put on Fi then, by Lemma 6.4, the sum decreases by  ~4+(&#38;+rL$+J2 ~&#38;, 
while C decreases by exactly X3 ~, AJ. !2 Lemma 6.8 If the adversary wins then Q(kt) probes have been 
made. Proof. When the adversary puts a O on fence F,, h, rows get excluded, and by the accounting scheme, 
a number of attributed probes get deleted. We show that this quantity is at least h,t. We distinguish 
three cases depending on which one of the rules B, C, and D triggered at F,: B. In this case h, = 1 and 
one attributed probe per fence gets deleted, giving a total of i + 1 deleted probes. Lemma 6.6 guarantees 
that no fence wiU ever run out of attributed probes, but can always pay one. c. The horizontal count 
er decreases by ~~=d Aj ~ A,, which is at least h,t, by rule C. Lemma 6.7 guarantees that the horizontal 
counter can be charged. D. In this case Ai > hit, so the (at least) hit attributed probes deleted from 
F: suffice. Hence, for each excluded row, at least t attributed probes, and thus at least t/15 = Q(t) 
actual probes, get deleted. If all rows get excluded, the algorithm must therefore have spent Q(kt) probes 
altogether. 0 To accomplish our second goal, that the algorithm never wins, requires two additional lemmas. 
Lemma 6.9 No fence is euer erected within distance n/2 from fence Ft~l. Proof. Consider the location 
of fence Ft during the course of the game. According to rule A, the first time Ft is created it resides 
to the left of column n/2B, and as long as it exists the (at least) n(l l/2B) columns to its right cannot 
be excluded, The second time Ft is created it resides to the left of column n(l l/2 B)/2B, and as long 
as it exists the (at least) TZ(l l/2B)2 columns to its right remain. Each 422 creation of Ft is preceded 
by the exclusion of at least one As ht s k it follows that At z 2htk, so rule D triggers at Ft, row, 
and at most k rows can be excluded. Therefore, the and the adversary puts a O on Ft and wins the game. 
0 number of columns that remain to the right of F~ after the search is at least  ( -ak4-AJ= (l-*)W 
for k~ 1. 0 The next lemma says that if F, is far from F,+I, it must have many probes attributed to it: 
Lemma 6.10 For any fence F,, / \ CIt Lemma 6.10 is the core of the entire proof, and its proof is postponed 
till the next subsection. Lemma 6.11 The algorithm never wins, Proof. Recall that the adversary never 
places a O to the right of Ft. Consequently, by Lemma 6.9, a search cannot be unsuccessful. The other 
possibility for the algorithm to win is by erecting a fence which reaches the bottom row in the leftmost 
non-rejected column. Note that this fence has no other fence to its right since it spans all rows, and 
so it must be Ft. We show that then At is large, and therefore, by Lemma 6.10, Ft must have many probes 
attributed to it. In fact, we show that At is so large that rule D will apply, so the adversary can put 
a Oon Ft and exclude all rows and win the game. At the end of the search, mt.-l = m = O, so At > log(n 
2 B, by Lemma 6.9. Since B = 0(S), this ~ 0( og n). Now, P A, A, = ,t10g(2c+l) (2C + 1) > , g *-zt 10gc 
[by clef. oft] = 21°g -(log 10 )/5 [fOr sutf. large ~] ~ 2@g g TT)/4, where the last inequality holds 
since At = Q(m. ..-, By Lemma 6.10, - At > 10g$:2) G v)c t @ n ,ooglog nJ14. cit > 2Bt log n ,Clog log 
~)/4 c. 10 bg .JlOg log n [by clef. oft] = 213t ,(5cl.g c)/2 log n 1010g C by clef. of B and t] > 2(10clog 
c + 1 + log k)loglogn 23 +1 10E n [for sufI. large c] ~ c log k log log n 2=+1 log n 2 > log logn logk 
2k(log log n)z log n k(log log n)2 [by clef. of c] = lognloglogn lognlogk [since k > log n] ~ Zklog log 
n [by clef. oft] > 2kt. 6.3 Proof of Lemma 6.10 Coupled with rule D, Lemma 6.10 immediately leads to 
the following lemma, which is very useful in the inductive proof of Lemma 6.10: Clt A, A, Lemma 6.12 
For any jence F,, h, ~ ~ (,(2C + 1) ) Proof of Lemma 6.10. For brevity, let .K = 2C + 1. We may assume 
that K ~ 6. The proof is by induction on the probes. Initially, when F, is created C, = 8, h, = 1, and 
A, ~ 2 (by Lemma 6.2). Hence because K z 2 and t>2. Inductively assume that the lemma, and consequently 
also Lemma 6.12, holds at any fence F, prior to a cert tin probe made by the algorithm. We show show 
that then it holds at fence F; after the probe. We have five cases to consider depending on how the next 
probe affects the values of i, h,, A,, and A,, In each case we need to show that A, increases by at least 
as much as the claimed lower bound. For each case, we provide a brief sketch of how it is handled; details 
are given after the enumeration. 1. F, is extended but does not merge with F,+ 1. This case is straightforward. 
 2. Fj is extended and merges with Fj+:(, for some j ~ i. Then the new F, is the former F,_l, and so 
A: = A,_I. As the claimed bound is decreasing on Z, the lemma follows by induction. 3. The adversary 
puts a Oon fence Fj, for some j $ i 1. According to Lemma 6.4, A, does not increase m this case, and 
both A, and hi decrease by lFj 1. Hence, the bound decreases by at least as much as does Ai. 4. F,_ 
I appears. In this case, A, increases by at most l/2B, by Lemma 6.2. The claim then follows from the 
mean value theorem and the fact that the derivative of our bound with respect to A, is at most 2B. 5. 
F, _l is extended and merges with F,. The new F, gets attributed A: = A, + A,-1 probes whale A; = A, 
+ A,-1, by Lemma 6.5. We need to prove that the additional A? -1 probes compensates for the increase 
in A,. This is accomplished by applying the inductive as­sumption to the two cent ributing fences, and 
requires a little bit of elementary calculus.  Case 1 is easy: A, increases by eight, and since A, does 
not change, the bound increases by one. In case 2, Fj and all fences to its left change index by one, 
so the new F, is the former F,_l. By induction, 423 as desired. Consider now case 3. If F,-, disamears 
then. accord­ .. ing to Lemma 6.4, A, decreases; otherwise it remains un­changed. Thusj in either case, 
A; < A,. Exclusion of h rows decreases both A~ and h, by h. Hence, by induction In case 4, F, gets attributed 
three probes, that is, A: = A, + 3. We show that the right side of the claimed bound increases by less 
than three. When F8 gets a new left neigh­bor, A, increases; however, the increase is at most l/2B, by 
Lemma 6.2. We show that the derivative of our bound with respect to A, in the point A, + l/2B is bounded 
by 2B. Since the bound is a convex function on A,, it follows from the mean value theorem that it increases 
by at most one. First note that A, + l/2B < 2A,, by Lemma 6.3. The derivative of the bound with respect 
to A, in the point 2A, is (Wt( +3+5 (%9 ( +3 2Aie It < K,() < (log n) lt [by clef. oft] = 2 0 108 C by 
clef. of B] ~ 2B. In case 5 the new F, gets attributed A; = A, + Ai_l probes. By induction, all we have 
to prove is or equivalently, since A; = A, + At-1 and hj = h, = h, 1, A, +A,-] A, +Ai l It >~  K, t( 
)  By induction, the lemma held at F, before the merge, and so, by Lemma 6.12, Replacing h, and putting 
A,_-l = a A,, we thus need to establish Ai C/t A, ++ F7F () Canceling the common factor (A; /t)(Ai/K 
) /t yields I+ C/ l<c/t _ (1+ U)l+ct ~ O. ~+l+a (4) Differentiating the left side with respect to a 
we obtain (l+:) ((aK) t-(~+a)ci ), and thus we have a minimum at a. = I/(K 1) = l/2c. We show that for 
a = ao the negative contribution in inequal­ity (4) is smaller than the positive: (1+ ao) +cf = (1+ ao)cl 
+ ao(l + ao)cl Clt K < e oclt + a~ () K 1 since we can assume t> 1,and we are done. 7 Proof for small 
k s The structure of the proof of Lemma 2.2 for small k s is exactly the same as that for large k s, 
and most of the lem­mas do indeed mirror the previous ones; however, there are some subtle differences. 
In particular, the difference between Lemmas 6.10 and 7.11 should be noted. In the next subsection we 
describe the required changes in parameters and adversary strategy. We then proceed in the same way as 
in Section 6, first st sting some basic lemmas and then providing the main argument. Recall that we can 
assume that log n/ log log n ~ k ~ log n. 7.1 Changes in parameters and adversary Let c=max{DIOg(kl~::n)}) 
where D is some large constant. We can thus assume that c is larger than some sufficiently large constant. 
t is defined as above. Since k < log n we have c = O(log log log n), and so t = Q(log log n/ log log 
log log n). Hence, also tcan be assumed to be larger than some sufficiently large constant. For any fence 
F,, define d, = /F,+l \, when F, is created. We stress that, when F, is created, d, = h,+l; while later 
on we can have either d, > h,+l or d, ~ h,+l. The definition of A, is altered: A, =m, m,_I logd,. The 
only change needed in the described adversary s is in rule A, which is modified slightly: Replace 2B+ 
1 by 8h, = 8d~ 1 . The accounting scheme is also changed slightly in that when two fences F, 1 and F, 
merge, the new fence does not get all the attributed probes, but log d~-l probes are transferred to the 
horizontal counter. (This stems from the new definition of A,. ) 424 7.2 Basic lemmas 7.3 Main argument 
The first five lemmas mirror Lemmas 6.1 6.5. We proceed along the same lines as in Section 6.2 Lemma 
7.1 Let F, be the leftmost fence. Then, after a Lemma 7.7 For any fence F, c F, A, > h, + 7H,. probe 
on the top row we have 1. m~=mJ, joranyj~i; Sketch of proof. Similar to the proof of Lemma 6.6. The 
,?. m +log(l l/4d,_I) < m~_l < m +log(l l/8d:-l); 3. m +log(l/8d, -l) ~ m < m + log(l/4d,_l). E+l by 
8d, _l in the proof of Lemma 6.1. Proof. Replace 2 0 Lemma 7.2 Let F, be the leftmost fence. Then, after 
a probe on the top row we have 1.A, ~A: ~A, +1/d, -~; 2. 1< A:_l <3. Proof. Plug in the bounds on m~_l, 
m;, and m from the preceding lemma into the definition of AJ. 0 Lemma 7.3 For any fence F, E F, A, >1. 
Proof, Identical to the proof of Lemma 6.3. 0 Lemma 7.4 If a O is put on F, 1, then A: ~ A,. Proof. Identical 
to the proof of Lemma 6.4. 0 When two fences merge, the situation is a little bit more complicated than 
before due to the revised definition of A,: Lemma 7.5 If F, and F,_l merge then AJ_I j<i 1, A; = A, +A, 
I + logd, 1 j = i. { Proof. Almost identical to the proof of Lemma 6.5. 0 When two fences merge we thus 
have to transfer some probes to the horizontal counter. For subsequent use we need to bound this quantity 
in terms of the increase incurred by the merge. Let H, = H(F, ) be the total number of times that F, 
has been extended (during its lifetime). Lemma 7.6 When F,-1 and F, merge then H,-.l ~ d,_.1. Proof. 
Omitted. 0 main difference is that, when two fences merge, we need to transfer some probes to the horizontal 
counter. This quan­tity is bounded from above using Lemma 7.6. 1 Sketch of proof. Again, the only difference 
from the cor­responding lemma for large k s (Lemma 6.7) is the transfer of probes to the horizontal counter, 
following a merge. 0 Lemma 7.9 If the adversary wins then Q(kt) probes have been made. Proof. Identical 
to the proof of Lemma 6.8. 0 Lemma 7.10 No fence is ever erected within distance n/k from fence F,+l. 
Proof. Consider the location of fence Ft during the course of the game. According to rule A, the first 
time Ft is created it resides to the left of column n/4k, and as long as it exists the (at least) n(l 
 l/4k) columns to its right cannot be rejected. In general, the ith time F~ is created, there are at 
most k + 1 i rows left. Hence, the second time .Ft is created, the number of columns to its right is 
at least 1 1 4k 1 4(k 1) l nl . 4k 1 4(k 1) n 4k 4(k 1)  ()( ) Suppose Ft is created 1 times altogether. 
Then the number of columns remaining when the algorithm is finished is at least 4k 1 4(k 1) l 4(k 2) 
l 4(k (1 1)) l . n 4k 4(k 1) 4(k 2)  4(k (t 1)) > n4(k 1) 4(k 2) 4(,%-3) 4(k 1) . . ... 4k 4(k 1) 
4(k 2) 4(k (1 1)) 4(k e) an 4k > ;. Lemma 7.11 For any fence F, G F, a~h+Ht++((2:l))c t1 As in the 
proof for large k s in Section 6.2, this lemma is the core of the argument, and its proof is omitted 
in this extended abstract. The proof has the sa,me structure as that of Lemma 6.10; however, it is much 
more technically involved. 425 Lemma 7.12 The algorithm never wins. If a 1 is found the corresponding 
string can be excluded as a candidate. Thus, it might make perfect sense for an algo­rithm to make probes 
that are not allowed by the definition Proof. By the same token as in the proof of Lemma 6.11, of fence 
algorithms. Note that according to Lemma 2.1, this it suffices to consider the number of probes attributed 
to is not the case in the restricted problem. In the spirit of feuce Ft at the end of the game. Lemma 
2.1, we show how to modify our adversaries such If the search terminates successfully, we have rnt-1 
= that for any non-fence probe there is a fence probe which m = 0, and so by Lemma 7.10, is at least 
as profitable. Consequently, we can still assume fence algorithms, and so the lower bound in Lemma 2.2 
ap­ > log n.logk= log ; _~ At ~ log plies to the modified problem as well. (): () The adversary answers 
any probe on the last row by 1. The probed entry is ignored by the adversary until the algo­rithm has 
erected a fence which spans all rows immediately for sufficiently large n, because k = O(log n). Now, 
the same argument as in the proof of Lemma 6.11 to its right. (Note that this fence has to be Ft. ) When 
this shows that occurs, the adversary reveals 1 s in the entire column above the probe. In effect, F, 
gets moved one step to the left. If the algorithm had probed also the next entry on the last ((,:l))c 
 o~((zfll)t) ) 22 0gc:g 0g i row, Ft gets moved two steps to the left, and so on. The key observation 
is that instead of moving F, one step Hence, by Lemma 7.11, to the left, the adversary can move the rightmost 
O one step to the right. This follows since this is equivalent of moving log n 2c g c log log 11 At all 
fences one step to the left, and the adversary is free to 2t 4 give the help of also moving the other 
fences. logn lologc 2 og c log log n Now, if an algorithm probes the entry immediately to the [by clef. 
oft] 2 log log n 4 right of the rightmost O on the top row, either one of our two original adversaries 
will answer O. Hence, instead of probing 2 tog clog n the last row, the algorithm is always better off 
probing the [for suff. large c] 2 +1 log n entry immediately to the right of the rightmost O on the top 
[by clef. of c and t] 2kt, row. The lemma follows. 1 Hence, rule D triggers at Ft, so the adversary will 
eliminate it and win the game. 9 Comments 0 We have given a tight lower bound on a fundamental search­8 
Extending the lower bound ing problem. The problem is natural and eaay to formulate, yet the solution 
the achieved bound as well as the proof is Suppose we are only interested in finding some matching surprisingly 
complicated. string, and that, if no matching string exists, then we do It should be noted that we make 
no other restrictions not care what the answer to the query is. Recall the trivial in the computational 
model; the algorithm is allowed to use @(k) -time query algorithm in Section 2. To neutralize this extra 
memory during the search, create hash tables etc. Our simplistic strategy, a slight modification of the 
restricted proof only relies on the fact that the content of an entry can problem is required. be determined 
in only two ways: either by the contents of We have not found an immediate reduction from success­ neighboring 
entries or by an explicit probe at that entry. ful searches in the restricted problem to that in Theorem 
1.1, but we have to modify the original proof of Lemma 2.2 Acknowledgements slightly. Thus, this proof 
relies on the specified adversaries; the lemma would not necessarily hold if we used different We would 
like to thank Torben Hagerup for several helpful adversaries. comments and suggestions. Lemma 8.1 The 
lower bound in Lemma 2.2 applies to the  References problem in Theorem 1.1. [1] A. Andersson, T. Hagerup, 
J. H&#38;stad, and O. Petersson. The complexity of searching a sorted array of strings. In Proof, We 
create a new problem of n strings of length k+ 1 Proc. 26th Ann. ACM Symp. on TheoTy of Comput%ng, pp.by 
appending a O to the leftmost string of 1 s and a 1 to all 317 325, 1994. other strings. We then search 
for the string of k 1 s followed [2] D. S. Hirschberg. A lower word-case coznplexity for searching by 
a O. This string is unique, and moreover it coincides a dlctiooary. In PTOC. 16th Ann. Alle7ton Gonf. 
on Commu­ with the leftmost string of k 1 s in the restricted problem. nication, ContTol, and Computing, 
pp. 50 53, 1978. It follows that any lower bound for successful searches in [3] D. S. Hirschberg. On 
the complexity of searching a set of the restricted problem applies to successful searches in the vectors. 
SIAM J. Comput. 9:126 129, 1980. original problem as well. Furthermore, as the outcome of a search, that 
is, whether it is going to be successful or not, is [4] S. R. Kosaraju. On a multidimensional search 
problem. In not determined until the last probe is made, it follows that P70c. llth Ann. ACM Symp. on 
Theory of Computing, pp. 67 73, 1979. the same lower bound applies to unsuccessful searches. Unfortunately, 
the above modification gives rise to a sub­tle complication. Suppose an algorithm probes the last row. 
426  
			