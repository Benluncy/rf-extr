
 Proceedings of the 1995 Winter Simulation Conference ed. C. Alexopoulos, K. Kang, W. R Lilegdon, and 
D. Goldsman SIMULATED ANNEALING: PAST, PRESENT, AND FUTURE Mark Fleischer Department of Engineering Management 
Old Dominion University Norfolk, VA 23529-0248, U.S.A. ABSTRACT This paper provides an overview of the 
simulated an­nealing algorithm and describes its historical founda­tion in thermodynamics as well the 
genesis and evo­lution for solving difficult optimization problems. An example illustrating its application 
to graph problems is provided as well as a look at ongoing, state-of-the­art research using SA. INTRODUCTION 
Few developments in the field of optimization have generated as much enthusiasm and criticism or spawned 
as many practioners and detractors as the invention of the simulated annealing (SA) algorithm. This paper 
describes the genesis and evolution of this remarkable optimization technique and how this com­puter 
simulation of a thermodynamic system can be used to solve many types of optimization problems. Along 
with a few other types of generalized opti­mization schemes, SA is considered a meta-heurwtic. Its generality 
and applicability stems from its foun­dation in thermodynamics and statistical mechanics. Thus, it can 
be used to solve many combinatorial optimization problems (COPS) and some continuous variable problems 
(Bonomi and Lutton 1984). The SA algorithm searches the set of solutions, referred to as a conjiguratton 
space (Tovey 1988), in much the same manner as a thermodynamic system changes from one energy state to 
another. The development of SA therefore established a mathematical analogy between optimization problems 
and thermodynamic systems thus creating a new foundation from which to analyze and solve such problems. 
It has over the years been extensively studied with varying degrees of enthusiasm, criticism, and a great 
deal of experi­mentation (see e.g., Bonomi and Lutton 1984, Eglese 1990). 2 WHAT IS BEING SIMULATED? 
The genesis of SA comes from attempts to simulate the effects of a heat bath on various chemical sub­stances. 
This was accomplished by Metropolis, et aL (1953) who established criteria to simulate how ther­modynamic 
systems change from one energy level to another. These criteria, based on the laws of thermo­dynamics, 
require that a system of particles exhibit energy levels in a manner that maximizes the thermo­dynamic 
entropy at a given temperature value. At the same time, the average energy level must be propor­t ional 
to a constant, the temperature. This average is based on some ensemble of energy states any one of which 
the system may be in at any particular mo­ment. This ensemble of energy states implies that the sys­tem 
visits such energy states spontaneously, but subject to the constraints mentioned above. Bonomi and Lutton 
(1984) state these requirements as a sim­ple nonlinear math program in which the entropy of the state 
vector is maximized subject to the con­straints that the expected kinetic energy is propor­tional to 
a fixed contant, the temperature and that the total probability of system states equals 1. This simple 
math program leads to requirements on how the system changes from one energy level to an­other. In simulation 
parlance, this is referred to as the Metropolis Acceptance Criterion which defines the probability that 
some candidate energy level is ac­ cepted as the current energy level in the next time increment and 
is given by the following expression: AElt AE >0 Pr {Accept AE} = ~ (1) { AE<O The steady-state probabilities 
mi(t)for some state is given by e E. ft 7r~(t) = (2) B(t) where l?(t)is the well-known Boltzmann partition 
155 function of statistical mechanics and Ei is the en­ergy level associated with some energy partition 
(a well-defined range of energy values) denoted by state i (Metropolis, et aL 1953). A simulation using 
this ac­ceptance probability therefore obeys the laws of sta­tistical mechanics in a discrete manner 
and therefore permits simulation studies of materials in a heat bath. 3 THE ROAD TO OPTIMIZATION It was 
only a matter of time till analogies were made between thermodynamic systems and combi­natorial optimization 
problems. Both deal with large ensembles in the former case, there are large num­bers of particles; in 
the latter case, there are large numbers of objective function values. But the sim­ilarity in complexity 
and size was eclipsed in the early 80 s. At that time Kirkpatrick, et al. (1983) and, independently, 
C&#38;ny (1985) reasoned that the Metropolis Acceptance Criterion could be used in a simulation of the 
annealing process. It is well known in the field of metallurgy, for example, that anneal­ ing a substance 
slowly cooling a material can re­ lieve stresses and aid in the formation of a perfect crystal lattice. 
By allowing particles to move about, but with gradually decreasing kinetic energy, condi­tions tend to 
prevail that lead to such perfect crystal lattices and low energy system states. They realized that an 
analogy between energy state values and ob­j ective function values in optimization problems was possible. 
Once the analogy was made, it was easy to see some advantages in using SA for solving such COPS. Us­ing 
the Metropolis Acceptance Criterion, transitions from one solution state to another can be defined us­ing 
the following expression. Gjie-Af:lt Af~ >0 Pij(tk) = (3) 1 Af~ <0 { where Gji is the probability of 
generating candidate j given the current state i (this means that j G N(i), or j is in the neighborhood 
of i) and Af~ = max{O, fj fi}. This transition probability implies that uphill moves are possible with 
a probability inversely related to the height of the hill and decreasing with decreas­ing temperature. 
This aspect of SA is one of its most attractive features it can avoid becoming trapped in local optima 
and, hence, has a greater chance of find­ing the global optima. Indeed, this is what anneal­ing is all 
about cooling the system slowly enough so that the minimum energy state or minimum objective function 
value can be realized. Fleischer Because the changes from one state to another can be expressed as a 
transition probability, it was pos­sible to model the annealing process as a Markov chain. This naturally 
lead researchers to investigate its mathematical properties. It was clear early on that the stationary 
distribution converged to the op­timum state vector (Aarts and Korst 1989). If m(t) is the stationary 
distribution at temperature tand q is the optimum state vector where the total probability of optimal 
states is equal to 1, then the ith element of the vector is very similar to (2) where the objective function 
value fi is merely substituted for the energy level and N(t) is a normalization coefficient analo­gous 
to the Boltzmann partition function (Aarts and Korst 1989). e f,lt 7r~(t) = (4) N(t) It is easy to see 
that lim ~(t) = q* (5) t-+o (Aarts and Korst 1989). From a mathematical point of view, this requires 
running SA at a fixed temper­ ature for an infinite number of iterations not very practical to say the 
least. The question therefore arose as to whether it was possible to lower the temperature at each iteration 
and still converge in probability to the optimum state vector. Since the talisman of annealing is lowering 
the temperature, how fast the temperature is lowered be­came a rich area of investigation. If the temperature 
is lowered too quickly, we end up quenching the sys­tem. This corresponds to finding a local optimum, 
not a global optimum. But if the temperature is low­ered at each iteration, the state distribution must 
be modeled as an inhomogeneous Markov chain. Mitra, et aL (1986) and Hajek (1988) determined various 
formulations (using different approaches) for such cooling schedules which yield an inhomogeneous Markov 
chain that is strong~y ergodic and therefore converges in distribution as well as probability using the 
form -Y (6) k= log(c+ k) where tk is the temperature at time index k. Thus, if V[kl is a state probability 
vector at time index k, then by using (6), J~mm V[kl = q* (7) These mathematical aspects, its hill-climbing 
ca­pabilit y, convergence in probability and distribution, and the ease of implementation (described 
below) Simulated gave rise to a great deal of enthusiasm for the algo­rithm (Eglese 1990). Yet, there 
was also the disquiet­ing fact that SA, in its generic form, is a dumb op­timization scheme; it is blind 
to the global optimum and can find it only to leave it in the next iteration searching the entire configuration 
space in total igno­rance of the quality of the solution it left. This lead to many criticisms of the 
method and a great deal of research designed to highlight its limitations (see e.g., Johnson, et al., 
1989). Enhancements to the generic implementation are, however, often obvious and easy enough to imple­ment. 
The most popular method is to keep track of the best solution obtained up to the current itera­tion. 
On the other hand, in iterated descent one can perform repeated local searches with random starting solutions 
often with similar results (Dowsland 1993). It therefore seemed that the convergence properties of SA 
were attractive only from a scientific and mathe­matical point of view, and that its practical use as 
an optimization scheme is often overstated. Indeed, this may explain why SA has so many variations, promot­ers, 
and detractors (Eglese 1990). There is, however, ongoing research into how to make SA more effective 
as described below. Thus, with the mathematical justifications for SA complete, many researchers explored 
the application of SA on many different types of problems. This re­vealed several important implementation 
issues that are addressed in the following section. IMPLEMENTATION ISSUES In addition to the cooling 
schedule, several implemen­t ation issues must be addressed before any reasonable SA algorithm can be 
developed for a specific problem. The following highlight the more salient implemen­tation issues all 
of which must have some clear artic­ulation. An appropriate cooling schedule.  A suitable objective 
function.  . A well-defined neighborhood structure. Insofar as the cooling schedule is concerned, many 
implementations use finite-time schedules based on an initial temperature and a final temperature (Fleischer 
1993). Other schedules that approximate (6), but are easier and faster to calculate have been used (see 
e.g., Johnson et al. 1989). Still others attempt to adapt the cooling schedule to the type of problem 
at hand by modifying the gross structure of the cooling schedule (Ingber 1993). Annealing 157 Central 
to SA is the definition of a suitable objec­tive function. This will depend on the type of prob­lem at 
hand. For COPS, it can often be calculated in conjunction with the selection of candidate solutions. 
For continous variable problems, however, this can be the slowest aspect of SA (Bohachevsky 1986). Many 
COPS, for example naturally lend themselves to a reasonable neighborhood structure once an ob­jective 
function is clearly defined (see the example below). These structures must make it possible for SA to 
explore all solutions (even if most are never visited) and at the same time permit efficient calcu­lation 
of A~J~. Indeed, the particular neighborhood structure used and the problem instance itself have implications 
for how well SA performs. Many researchers have explored various ways of modifying the neighbor­hood 
size used in SA in order to improve its perfor­mance. This has lead to differing and, at times, seem­ingly 
contradictory results. Waterman and Goldstein (1988) applied SA to several instances of the Trav­eling 
Salesman Problem (TSP) using different neigh­borhood sizes. They report that the finite-time per­formance 
of SA degrades if the neighborhood size is too large or too small, the implication being that some optimal 
neighborhood size exists. Cheh, et al. (1991) show that for some problems, including the TSP, performance 
improved for smaller neighborhood sizes. Yao (1991), on the other hand, reports that larger neighborhood 
sizes improve the performance of SA. Fleischer (1993) and Fleischer and Jacobson (1994) attempted to 
resolve these issues by showing that it is possible to model SA as a Markov information source. Relying 
on information theoretic concepts, it became apparent that the neighborhood structure can affect the 
information rate or level of total uncertainty as­sociated with SA. They showed that the higher the entropy 
of the associated Markov chain, the better SA tends to perform. For many practical applications, these 
implementa­tion issues do not present much difficulty. The follow­ing section demonstrates an implementation 
scheme for the minimum vertex cover problem. 5 AN EXAMPLE OF SA Perhaps the best way to illustrate how 
SA can be implemented is to use a simple example. Consider the vertex cover (VC) problem. A vertex cover 
is a set of nodes such that all arcs in some graph G(V, E) have at least one end impinging on a node 
in the set. This problem, along with other related problems, concern the determination of how many nodes 
(and which ones) constitute a mintmum vertex cover. Such COPS can be very difficult when the number of 
nodes becomes large and are, in fact, NP-hard (Garey and Johnson 1979) and can be solved using SA. Figure 
1 shows such a vertex cover where the shaded nodes correspond to the vertex covering set. Figure 1: A 
Vertex Cover Since solutions to this problem correspond to spe­cific combinations of nodes, a reasonable 
way of defin­ing the configuration space would be to have all combinations of nodes correspond to solutions. 
The neighborhood structure could therefore be defined by allowing candidate solutions to be obtained 
by adding or subtracting any one node from the current set. Changing the membership status of any one 
node creates a new combination of nodes and, hence, a new solution. Thus, if n is the number of nodes 
in a graph, then the neighborhood can be defined as all the new combinations obtainable by merely changing 
the membership status flipping-one of the n node s status to be either be in the set or out of the set. 
This means that each combination has n neighboring so­lutions. Thus, in the same instance we have defined 
the objective function to be some function based on the number of nodes in the current set of nodes and 
we have defined a neighborhood in which a candidate solution is obtained by flipping any one of n nodes. 
Athough this makes defining candidate solutions easy, it also permits ali combinations of nodes to be 
part of the solution space. This results in creating a solution space S the size of which is given by 
the following: Isl =~ (:) =2 (8) i=o There is therefore an apparent tradeoff in simplifying candidate 
selection at the expense of enlarging the solution space. This simplified generation technique, however, 
of­ten ends up generating solutions that do not consti­tute a vertex cover combinations of nodes that 
do not cover every arc. More generally, some solutions may violate the constraints of a given problem. 
One way around this problem is to use some penalty func­tion for solutions that violate the constraints 
of the problem. For the VC problem, one objective function formulation suggested by Aarts and Korst (1989), 
is the following: Let V ~ V be the subset of nodes cor­responding to the current solution. Let E(V ) 
be the number of uncovered arcs given the nodes in V . A suitable objective function can be defined as 
fvc (v )= Iv 1 + Nqv ) (9) where J > 1 serves as a penalty parameter (Aarts and Korst 1989). Anecdotal 
evidence suggests that allowing all combinations of nodes to be part of the configuration space smoothes 
out the landscape of SA making it easier for SA to find the global optima (see e.g., Johnson et al. 1989, 
Fleischer 1993). This method also leads to a very efficient way of calculating AjJ~. Aarts and Korst 
(1989) define the indicator variable 1 ifu~V ~vl(~) = { 0 otherwise (lo) Using this, it is possible to 
efficiently calculate the change in objective function by (Fleischer 1993). The following pseudo-code 
displays the simplicity and ease of application that is the hall­mark of the SA algorithm. initialize: 
Generate initial set. Calc cooling schedule parameters. anneal: do while k < k 1: .k=k+l, calct~ 2: select 
random node u. and temporarily change its membership status. 3: talc Af(u). 4: if A~(u) <0 then goto 
accept else generate a U(O, 1) random variable R 5: if R < e Af(u)/tk then goto accept else change the 
status of u back and goto anneal accept 6: adopt the change i-n status of node u 7: goto anneal As the 
SA algorithm proceeds and the tempera­ture parameter decreases, the probability of accept­ing a candidate 
solution violating the constraints is reduced, Typically, at termination of the algorithm, a solution 
which does not violate the constraints is pro­duced. Like twinkling stars, the nodes blink in and out 
of the current set randomly as they are flipped and pro babdisticaliy settle into an optimal configura­tion 
through the annealing process. 6 FUTURE DEVELOPMENTS 6.1 Simulating Realistic Annealing It would be 
nice if it were possible to simulate how a human being handles the annealing process in real life and 
take advantage of the artisan s experience and expertise. Such a simulation could lead to im­provements 
in SA S performance. From glass blowers to metallurgists, the art of annealing requires some sense and 
knowledge of how well something is being annealed. Usually, these experts have some notion of when parts 
of a system need to be reheated and cooled again. This notion has lead some researchers to consider non-monotonic 
cooling schedules. Glover (1995) describes a method of non-monotonic trajecto­ries in many different 
optimization settings. Osman (1993) applied such non-monotonic cooling schedules to SA for the vehicle 
routing problem. Some approaches seek to adapt the type of cool­ing schedule to a particular problem 
instance (Ingber 1995). Since the landscape of a solution space maybe hilly or smooth, how SA is cooled 
can have significant impact on the quality of the solution. This requires some a priori knowledge of 
the landscape which may not always be possible. But coupling the annealing process with some actual knowledge 
of how well the system is settling down could be even more ben­eficial. Like those hand-held amusements 
where one tries to get a small bead into a hole, the problem of annealing is to settle into the optimum 
state. The closer the bead is to the hole, the more delicately (lower temperature) one manipulates the 
puzzle. If the bead is far from the hole, the more vigorously the puzzle is manipulated. The use of some 
feedback information (discussed below) could therefore lead to improvements in SA S performance. 6.2 
Parallel Simulated Annealing Another avenue of active research involves the use of parallel computing. 
From massively parallel sys­tems, known as Boltzmann Machines (Aarts and Korst 1989), to smaller scale 
parallelization (Azen­cott 1992), research on effective parallel algorithms is moving along at a swift 
pace and SA is at the heart of many of these techniques. Many problems using par­allel computing schemes 
are based on SPMD (single program, multiple data) designs where it is not nec­essary to break up problems 
into independent sub­problems. This allows parallel SA to be applied to virtually any COP. The rationale 
for parallel SA is that if two heads are better than one, then two computers should be better than one. 
Intuitively, if two processors execut­ing SA are applied to a given problem, they ought to find the global 
optimum sooner than only one proces­sor. Roughly speaking, each processor would have to cover or search 
only half the solution space in a given amount of time. Adding more processors could speed things up 
even more. But some method of communication must exist be­tween the parallel processors. Otherwise all 
we can expect is two processors working independently and solving the problem as efficiently as a single 
processor. Indeed, two independent processors are just that two examples of a single processor. The only 
differ­ence compared to a single processor is that our elec­tric bill would double. In Boltzmann Machines, 
this communication is at the heart of its architecture. Each computer would be analogous to, for example, 
a node in the graph prob­lem described earlier. Each node would then execute SA in order to minimize 
some function based on the weight of selected arcs which are connected to other nodes and, hence, processors 
(see Aarts and Korst 1989 for a complete description). For those types of problems that do not have a 
structure amenable to Boltzmann machines, the SPMD architecture is avail­able. 6.3 Cybernetic Optimization 
by SA Certainly, if some problem is to be solved by SA, then knowing the best direction to move in (which 
candidate solutions to accept) would natually be ad­vantageous. More computational power coupled with 
more intelligent search patterns would obviously im­prove the efficiency of SA (see Glover 1989). But 
because SA is a random search algorithm, only proba­ bilistic information is available for feedback purposes. 
Thus, there is really no way to tell, with certainty, if the current solution is optimal or not. But 
it is use­ful information nonetheless. Fleischer and Jacobson (1995) and Fleischer (1995) have recently 
developed a method, cybernetic optimization by simulated an­nealing (COSA), that takes advantage of such 
prob­abilistic information. This method provides useful feedback information and encompasses a method 
of parallelization. This information comes from other parallel com­puters solving the same or related 
problems using SA and takes advantage of SA s convergence prop­ ert ies. Because of this property, parallel 
processors will tend to converge to the same or similar solutions. Consequently, the proximity of two 
or more solutions make it possible to develop a Probabilistic Measure of Quality (PMQ) that can be used 
to generate an error signal. This PMQ can then be used to modify the temperature control parameter that 
governs the search mechanism inherent in SA. Thus, rather than altering some direct ion, rate or acceleration 
by feed­back, as in many feedback control systems, we can alter the probabilities and associated uncertainty 
lev­els by feedback. This concept forms the foundation of what is referred to as a Probabilistic Feedback 
Control network. Put another way, if one is search­ing for gold (an inherently probabilistic endeavor), 
one is more likely to succeed if one spends more time looking where all the other prospectors are looking. 
SA can thus provide both aspects of feedback control: the generation of an error signal and the capability 
to utilize that information to modify a control parame­ ter. The idea behind the PMQ is basically this: 
if two or more processors generate solutions that are close to the optimum an increasing proportion of 
time (i. e., convergence in probability), then the two solutions should be close to each other an increasing 
proportion of time. Conversely, if two or more processors gener­ate solutions that are ciose] to each 
other in some sense, then tt ts more likely that at least one is close to the optamum. Measuring how 
close two or more solutions from parallel processors are to each other can therefore provide information 
as to the quality of the solutions, the PMQ. This probabilistic informa­tion provides the basis for the 
generation of an error signal. The idea behind the control scheme is this: when it is more likely that 
at least one processor is pro­ducing a relatively good solution, then the algorithm should lower the 
information rate and uncertainty as­sociated with the next state by lowering the temper­ature. This makes 
it more likely that the algorithm will explore solutions that are nearby for a greater number of iterations. 
Conversely, if the solutions are likely to be poor, then increasing the information rate and uncertainly 
levels by raising the temperature is appropriate. This would increase the randomness of the search and 
allow SA to explore more remote re­gions of the solution space. The PMQ metric can be based on the degree 
of coincidence of the sets of solutions from several pro­ cessors such as the intersection set or the 
symmetric difference of the sets depending on the nature of the problem (Fleischer and Jacobson 1995). 
The size of these sets can be used to modulate the temperature in the manner described above (see Fleischer 
and Ja­cobson 1995 for details).  7 CONCLUSION From early attempts to simulate thermodynamical systems 
to optimization strategies to parallel com­puting, SA seems to be involved in many threads of research. 
Recent advances and applications, in ad­dition to its use with other optimization strategies, suggest 
that SA will be intimately involved in many successful research endeavors well into the future. It is 
indeed, a cool algorithm notwithstanding some of the heat it has generated in the past. ACKNOWLEDGEMENTS 
This research was partially supported by the Na­tional Aeronautics and Space Administration, Con­tract 
NAS 1-19858-13. The author would like to thank Sheldon H. Jacobson and David Goldsman for their support 
in the writing of this article. REFERENCES Aarts, E. and J. Korst. 1989. Simulated annealing and Boltzmann 
machines: a stochastic approach to combinatorial optimization and neural computing, New York, N .Y. John 
Wiley &#38; Sons. Azencott, R. ed. 1992. Simulated annealing: paral­lelization techniques, New York, 
N. Y., John Wiley &#38; Sons, Inc. Bohachevsky, I., M. Johnson, and M. Stein. 1986. Generalized simulated 
annealing for function op­timization, Technometrzcs, Vol. 28, No. 3, pp. 209-217. Bondy, J.A. and U.S.R. 
Murty. 1976. Graph theory w!th applications, New York, N.Y. North-Holland, Elsevier Science Publishing 
Co., Inc. Bonomi, E, and J. Lutton, 1984, The n-city trav­eling salesman problem: statistical mechanics 
and the Metropolis algorithm, SIAM Review, Vol. 26, No.4. pp. 551-568. Cheh, K., J. Goldberg and R. Askin. 
1991. A note on the effect of neighborhood structure in simulated annealing. Computers in Operations 
Research, Vol. 18, No. 6, pp. 537-547. CGrny, V. 1985. A thermodynamical approach to the traveling salesman 
problem: an efficient simula­ Simulated Annealing tion algorithm. Journal of Optimtzatton Theory and 
Application, Vol. 45, pp. 41-55. Dowsland, K. 1993. Simulated annealing, in Modem Heuristzc Techniques 
for Combinatorial Problems, C. Reeves, editor, New York, John Wiley &#38; Sons. Eglese, R.W. 1990. Simulated 
annealing: a tool for operational research, European Journal of Opera­tional Research, Vol. 46, No. 3. 
June 15, 1990. pp. 271-281. Fleischer, M. 1993. Assessing the performance of the simulated annealing 
algorithm using informa­tion theory. Doctoral dissertation, Department of Operations Research, Case Western 
Reserve Uni­versity, Cleveland, Ohio. Fleischer, M. and S. H. Jacobson. 1994. Information theory and 
the simulated annealing algorithm: ex­perimental results. Technical Report, Department of Engineering 
Management, Old Dominion Uni­versity, Norfolk, VA. Fleischer, M. 1995. Cybernetic optimization by sim­ulated 
annealing: accelerating convergence by par­allel processing and probabilistic feedback con­trol, Technical 
Report. Department of Engineering Management, Old Dominion University, Norfolk, VA. Fleischer, M. and 
S. H. Jacobson. 1995. Cybernetic optimization by simulated annealing: an imple­mentation of parallel 
processing using probabilis­tic feedback control. In Metaheuristics: The State of the Art 1995 (Proceeding 
of the Metaheuristics International Conference 1995), ed. J. Kelly, I. Osman, Kluwer Academic Publishers, 
New York, N.Y. To appear. Garey, M. and D. S. Johnson. 1979. Computers and intractability: a guade to 
the theory of NP­completeness, New York, N.Y. Freeman and Co. Glover, F. 1989. Tabu search-part I. ORSA 
Journal on Computzng, Vol. 1, No. 3. pp. 190-206. Glover, F. 1995. Tabu thresholding: improved search 
by nonmonotonic trajectories. To appear in IN-FORMS Journal on Computing. Goldstein, L. and M. Waterman. 
1988. Neighbor­ hood size in the simulated annealing algorithm. American Journal of Mathematical and 
Manage­ment Sciences, Vol. 8, Nos. 3 &#38; 4. pp. 409-423. Ingber, L. 1995. Adaptive simulated annealing: 
lessons learned. Journal of Control and Cybernet­ics. To appear. Johnson, D. S., C. R. Aragon, L. A. 
McGeoch and C. Schevon. 1989. Optimization by simulated an­nealing: an experimental evaluation, part 
I (graph partitioning). Operations Research, Vol. 37, No. 6. November-December, 1989. pp. 865-892. Kirkpatrick, 
S., C. D. Gelatt, Jr., and M. P. Vec­chi. 1983. Optimization by simulated annealing. Sctence, Vol. 220, 
No. 4598, May 13, 1983. pp. 671-680. Manber, U. 1989. Introduction to algorithms: a cre­ative approach, 
New York, N.Y. Addison-Wesley Publishing Company. Metropolis, N., A. Rosenbluth, M. Rosenbluth, A. Teller 
and E. Teller. 1953. Equation of state cal­culations by fast computing machines. Journal of Chemical 
Physics, Vol. 21, pp. 1087-1092. Mitra, D., F. Romeo and A. Sangiovanni-Vincentelli. 1986. Convergence 
and finite-time behavior of sim­ulated annealing. Advances m Applied Probability, Vol. 18, pp. 747-771. 
Osman, I. 1993. Metastrategy simulated annealing and tabu search algorithms for the vehicle routing problem. 
Annals of Operations Research, Vol. 41, pp. 421. Tovey, C. 1988. Simulated simulated annealing. American 
Journal of Mathematical and Manage­ment Sciences, Vol. 8. Nos. 3&#38;4, pp. 389-407. Wiener, N. 1948, 
1961. Cybernetics: or control and communication in the animal and the machine, 2nd ed. Cambridge, Massachusetts. 
The M .I.T. Press. Yao, X. 1991. Simulated annealing with extended neighborhood. Internat~onal Journal 
of Computer Mathematics, Vol. 40, pp. 169-89. AUTHOR BIOGRAPHY MARK FLEIS CHER is an Assistant Professor 
in the Department of Engineering Management at Old Dominion University. He received his Ph.D. degree 
in Operations Research from Case Western Reserve University (1994), a J .D. degree from Cleveland State 
University (1984), and a B .Sc. degree from the Mas­sachusetts Institute of Technology (1978). Before 
his stint as an attorney, Dr. Fleischer worked in the Of­fice of Management and Budget in New York City 
where he was an early advocate of applying oper­ations research methods to the city s management problems. 
He is currently conducting research in op­timization using a cybernetic optimization scheme for the National 
Aeronautics and Space Administration at the Langley Research Center. His research inter­ests include 
applied probability, optimization, paral­lel computing, information theory and control theory and how 
these areas interface. He is an active mem­ber of INFORMS and its special interest section on computer 
science. 
			