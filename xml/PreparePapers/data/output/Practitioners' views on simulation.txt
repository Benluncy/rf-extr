
 Proceedings of the 1983 Winter Simulation Conference S. Roberts, J. Banks, B. Schmeiser (eds.) PPJ~CTITIONERS' 
VIEWS ON SIMULATION PANEL CHAIRMAN: Kenneth J. Musselman Pritsker &#38; Associates, Inc. P.O. Box 2413 
West Lafayette, IN 47906 PANELISTS: William A, Clark, Jr, Bethlehem Steel Corporation Bethlehem, PA 18016 
 Stanley A. HendryxBell Laboratories 555 Union Boulevard Allentown, PA 18103 Donald Segal Georgetown 
University Hospital 3800 Reservoir Road, NW Washington, DC 20007 The panelists are all actively engaged 
in applying simulation to a variety of systems. Their areas of application include manufacturing, electronics, 
steel, and health systems. The panel discussion will address issues relating to the practice of simulation 
and make recommendations for future consideration. The panelists' position statements follow. KEN MUSSELMAN 
I. NON-TECHNICAL EDUCATION Over the years we have become very adept at teaching simulation modeling and 
analysis. In fact, graduates almost always become effective modelers within a very short period of time. 
However, while these graduates are often good modelers, they are seldom good practitioners. This is because 
we fail to teach the simulation modeling process in its entirety. Most courses in simulation concentrate 
very heavily on modeling and analysis. This is very misleading, for it gives the impression that technical 
understanding leads to practical suc-cess. While technical understanding is unquestionably a key component, 
it does not, by itself, guarantee a successful project. A simulation project is more of a journey than 
a model. It is a journey that will take many turns and demand a variety of skills. In the end, the client's 
impression of the project team members may be more lasting than the merits of the final recommendation. 
For this reason, a successful project requires more than just good modelers; it requires people skilled 
in the fundamentals of active listening, technical writing, public speaking, selling, negotiating, and 
managing. While our education system tends to emphasize simulation languages and output analysis techniques, 
successful simu-lation projects require people competent in the non-technical areas of simulation as 
well. II. ANALYSIS AT THE DETAILED LEVEL The dynamics inherent in a simulation model offer a wealth of 
information. Yet, little has been done to capitalize on it. In fact, the other- wise very prominent dynamic 
qualities of a sim- ulation model are often purposely dampened for reasons of statistical convenience. 
Aggregated measures are used to draw conclusions about system performance, while the detailed dynamics 
of the system go virtually unnoticed. A decision based solely on summary performance could lead to unacceptable 
results. Consider, for example, a model in which bottlenecks, of a stochastic nature, are occurring. 
The existence of these bottlenecks, while of obvious interest and importance to the client, could be 
concealed in summary statistics. To help prevent such oversights, balanced treatment should be given 
to the analysis of both the system's global per-formance measures and its detailed interactions. CH1953-9/83/0000-0169 
$01.00 o 1983 IEEE 170 Kenneth J. Musselman While statistical techniques allow us to make valid conclusions 
from a global standpoint, we have few techniques to help us evaluate the detailed dynamics of a process. 
Nevertheless, the client's acceptance of the final recommen-dation may well rest on the analyst's ability 
to properly communicate and evaluate the details of the system. Clients generally view a system at this 
finer level of detail and base many of their decisions on information gathered at this level. For this 
reason alone, it makes practi- cal sense for us to learn how to properly amplify these details and to 
incorporate them into the evaluation process. III. INTUITIVE OUTPUT In most every simulation project, 
there is an element of risk associated with the result. Yet, as practitioners, we often fail to create 
an adequate setting for the client to truly understand this. Instead, the client is usually faced with 
an abstract statistical parlance that does little to help him comprehend the implica- tions of his decision. 
The simulation community has made significant progress in communicating how a given system has been modeled. 
Indeed, network and special purpose languages are good examples of this progress. However, equivalent 
progress has not been seen on the output side. Admittedly, some advances have been made (e.g., graphical 
out- put, animated traces), but clearly more should and could be done. Our ability to better con- vey 
the meaning of risk and uncertainty is central to this concern. As we continue to seek technical improvements 
in analyzing simulation output, let us not lose sight of the equally important need to make these techniques 
intuitively appealing as well. BILL CLARK I. EDUCATION OF PEOPLE WHO USE SIMULATION RESULTS Computers 
have become faster, more powerful, less expensive and more available than ever before. Simulation languages 
have evolved to the point where the user has most of the rou- tine bookkeeping, timing and statistics 
collec- tion handled with a minimum of effort. Many languages provide a combination of network, discrete 
and continuous capability. All of these features are significant to the simula- tion modeler. However, 
the practitioner has much more work to do in the area of education of people who are using the results 
of a model. These users frequently do not understand con- cepts such as random variables and drawing 
from probability distributions. Users frequently want results but aren't interested in the de- tails. 
This is a dangerous approach. The boundaries and underlying assumptions of a model should be clearly 
understood before trying to interpret output. Many models are designed as tools for a study team. The 
education of this team is very important in the proper use of the model. Boun-daries of the model, as 
well as required levels of detail, should be clearly established. Members of the study team should understand 
the tradeoffs between a very detailed model that requires many man-hours to develop and a less detailed 
model that can be put together quickly but only answer more basic questions. The study team must understand 
that as a model becomes more complex, more detailed input is required. The needs and constraints of the 
team must guide the modeler in establishing the level of detail required to answer the existing and potential 
questions of the team. Often detailed models are developed that include complex code to "look ahead" 
and make decisions based on what is most likely to happen in the future. Extra code is often needed in 
a detail- ed model for handling the first and last piece of a batch of material being processed. De-tailed 
delay information and routing sequences, along with system status checks may require additional complex 
coding. This type of model can be quite valuable to a study team. How-ever, the team must understand 
that it can not change the system boundaries or the previously agreed upon basic operating characteristics 
of the system and expect model results an hour later. In addition the team must understand the need for 
defining their alternatives in detail. Questions such as "What is the effect of moving Facility A to 
the other end of the shop?" certainly does not provide enough infor- mation for a detailed model to work 
with. The simulation practitioner will need to know the exact new location, how that affects operating 
sequences, product schedules, facility schedules, material handling, etc. Once all of that information 
is obtained, then the simu- lation modeler can begin revising the model. This revision process takes 
time. The study team must realize that the more complicated the change, the more time will be required 
to revise both the model and the data. The users must also understand the difference in time requirements 
to change data versus change logic. Also, a common sense approach must be taken to analysis of alternatives. 
If previous runs allow the user or modeler to de- termine the results of another alternative without 
making any additional model runs, this can save man-hours as well as computer time. Perhaps the most 
misunderstood item in simula- tion is optimization. Some models do include optimization modules or feedback 
loops to revise and try a different set of input. How- ever, the user of a simulation model must understand 
that simulation itself does not automatically optimize. Normally, the results of a run are an evaluation 
of the logic and input data provided, and not an optimal way to run the operation. This is an extremely 
impor- tant point. In the field of Operations Re- search many models are optimization models. Users must 
clearly understand the capabilities of the model they are using. Practitioners' Views on Simulation 
In summary, simulation practitioners need to concentrate more energy in educating people out- side this 
field with the basic concepts, capabilities and limitations of simulation. In order to accomplish this 
there must be good communications between simulation modelers and the users of the results. This communication 
is especially important before the simulation development effort begins. Documentation of system boundaries 
and logic, as well as data and sources of data, is required. Clearly designed output reports, using graphics 
when appropriate, can be very helpful in under- standing the level of detail included in a model. II. 
NETWORK MODELING CAPABILITY Several languages now offer network, discrete and continuous modeling capabilities. 
The net- work features have resulted in decreased model development time and decreased time to learn 
a language. The development of a network capabil- ity is an important contribution to the field of simulation. 
From a practitioners viewpoint the strong arguments for using a network approach include: I. A visual 
outline and a structured way of approaching a problem. 2. A faster way to develop and debug a model. 
 3. Easy interface to high level pro- gramming languages. 4. An easy way to teach and learn simulation 
without jumping in to all of the complications at once. 5. A good mechanism for the occasional user--it 
is easier to remember how to use network features than to code everything yourself. 6. Very rough documentation 
for the simulation practitioners.  These features are of great benefit to the simulation modeler. However, 
the modeler must understand what thelnetwork will not provide for him: I. Networks are not flow diagrams 
that can be shown to operating personnel to help validate a model. A compli- cated network will only 
be understood by a simulation practitioner and, in many cases, only by the person who developed it unless 
additional documentation is provided. 2. Networks are not self-documenting. They are an aid to the development 
and use of a model but they still need complete documentation, With- out documentation describing vari- 
ables, attributes, resources, events and logic a network will be diffi- cult to understand. 3. Networks 
do not include all of the features needed to develop a detailed model. Additional code will be necessary 
to handle real-life compli- cations and logic. As the network approach becomes more and more popular 
additional features will become avail- able. Features such as "CONVEY" and "TRANSPORT" found in SIMAN'[I] 
and the Crane Module and Roller Line Module found in BETHSIM [2] are good examples of features that let 
the language handle items that, in the past, were coded in high level language. The network capability 
is a fantastic tool for the simula- tion practitioner. The next step should be to allow users to develop 
their own nodes and easily embed them within the simulation language. III. NOTE SIMAN is a trademark 
of Systems Modeling Corporation. IV. REFERENCES [l] Pegden, C. Dennis. Introduction to SIMAN (State College, 
PA, Systems Modeling Corporation, 1982). [2] Clark, W.A. Jr. and Scriptunas, J.J. Jr. "Simulation Model 
to Evaluate Impact of Continuous Casting at Steelton," Iron and Steel Engineer, Vol. 60, No. 6 (June, 
1983), p. 47. STAN HENDRYX From the viewpoint of a manufacturing manager in the electronics industry, 
simulation is a useful tool in gaining increased unders.tanding of the complex interactions in a modern 
manu- facturing facility, both during the design of the facility and later in its operation. Major benefits 
of simulation come by providing industrial engineers with insight into their factories, and managers 
with a better under- standing of the consequences of policies and procedures they establish, Although 
simulation is an expensive tool to use, particularly for the uninitiated, I believe its greatest benefits 
will come from staff people using simulators themselves, Since staff training time and the considerable 
time re- quired to build and analyze models are major cost components in simulation, features of a simulator 
that make it easier to use and that make the staff more productive will generally be cost effective. 
The need to improve the productivity of simula- tion tools in the hands of staff members with other responsibilities 
besides simulation sug- gests developing simulation technology in at least two directions; Kenneth J. 
Musselman Integration of simulation in the workplace. II. Model architecture. I, INTEGRATION OF SIMULATION 
IN THE WORKPLACE A simulation tool has two principal interfaces: I. Interface place. with the people 
in the work- 2. Interface place. with the data in the work- I. ~nterface with People So that operation 
of a simulator is as intuitive and straightforward as possible, human-factors principles should be employed 
in its design, as attending to this detail will pay dividends throughout the life of the simulator. Prompts 
and help features urgently needed by a beginner should be able to be muted by a more experienced user 
who finds them unnecessary, even undesir- able; moving between branches of menu driven systems should 
be easy, as should editing and recovery from common errors. Separate documents will better meet the needs 
of users for tutorial and reference material; attempting to make one document do the work of two is usually 
inadequate, To speed learning and promote self-teaching, minimizing instruc- tor time, well designed 
on-line tutorial aids, such as might be achieved by invoking the simulator on a specially prepared help 
file, are helpful. To help the modeler communicate with other people, the simulator should be able to 
pro- duce readable documentation of the model, and its output should be available in presentation form, 
consisting of clearly annotated charts and tables. 2, Interface with Data A simulation model is only 
as good as the data used in its preparation. Access by a model to on-line shop floor data such as inventory 
records, process routings, and production schedules is necessary to simulate a factory efficiently. Ability 
to select, transfer and reformat this data from the host data base and use it in simulation should be 
a feature of simulators used in managing factories. Simulation is but one tool used by the manu- facturing 
staff. Ability to run other programs as subroutines during execution of a model could greatly expand 
the capability of simu- lators, and reduce model complexity. For example, take the job of testing by 
simulation an improved shop schedulingalgorithm that recomputes the priorities for each work station 
each shift. Testing could be simplified if the simulator could call on the new scheduling program to 
recompute the ranking of the work- in-process queues at the end of each simulated shift. Using the algorithm 
under development and the current contents of the simulator queues, whose initial contents were loaded 
from the on- line shop inventory, queue ranking would be determined for continuing the simulation. The 
capability described would allow testing the algorithm against a model of shop floor activ- ity, starting 
with real inventory data, without having to include explicitly the algorithm in the model, or even having 
to use the whole model if only part of the shop was involved. Note that in the above example, the link 
between model and scheduling program would also be useful in studying proposed changes on the shop floor 
that are reflected in the model. II, MODEL ARCHITECTURE Breaking a problem into small parts and building 
piece by piece from the parts is a time-honored method of enhancing productivity. This method permits 
many people to work on a project, makes it possible to deal with complex systems, and frequently reduces 
total effort by using some parts repeatedly, A modular hierarchical model architecture could bring these 
benefits to simulation. Modular means breaking a model into parts or modules that may be run like subroutines 
and used repeatedly in different places in the model. Hierarchical means that instances of modules in 
a model of a complex system are related in a tree-like structure, There is a difference between breaking 
a large model into pieces, and making the model to be modular and hierarchical. In the first case, the 
model is simply broken up and the pieces related to each other, Similar pieces, differ- ing only in variable 
names or parameter values, are explicitly repeated in each instance, and the entire model must be simulated 
together. In the case of modular hierarchical model archi- tecture, a module can be called repeatedly 
like a subroutine, having different arguments or parameters passed to it each time it is called. Main 
programs that relate the modules in a par- ticular analysis could be used to exercise a module alone 
or with other modules, A modular hierarchical model architecture would support developing models of complex 
systems from small, top level models into complete models having considerable detail. Adding detail only 
as required, and permitting modules to be run separately or in small groups, modular hierarchical model 
architecture would permit useful results to be obtained early on in the modeling process. A large model, 
existing as a library of compatible modules, may possibly never be run as an entity. Modules in the model 
library could be linked together for simulation in a fashion analogous to using a link editor to combine 
program modules for execution. Input entity streams or initial queue Contents Practitioners' Views on 
Simulation 173 required to run a module independently could be obtained from data files arising from 
the execu- tion of other modules or from outside sources. A modular and hierarchical model architecture 
would promote orderly development of models of large or evolving systems by several people working together. 
Such an architecture would improve the productivity of the modeler by enabling him to build onto his 
own work and onto the work of others. That such a model, or some modules of it, could be used benefi- 
cially for purposes not initially intended or expected, would not be surprising. With simulation tools 
available having fea- tures like those described here, simulation will have come of age. The people responsible 
for the factory could then build and maintain a factory simulation facility as the factory itself is 
built and maintained, and could use it to help run the factory effectively. Simula-tion will then become 
a standard tool used by manufacturing staffs to help them understand and control the increasingly complex 
environment in which they work, , Estimating the optimum model detail level for the situation is t therefore, 
not as easy as it appears. Some more rigorous techniques are suggested particularly in the preparation 
stages of system development. Results Presentation As we all know this is the most critical part of a 
project, Regardless of the adequacy of the model if the decision maker is not con- vinced, or if the 
owner of the system that is being simulated is skeptical, the project is surely going to fail. The question 
is, "What level of effort is required to familiarize an unknowledgeable executive to understand the results 
in terms of accuracy and risk?" It is suggested that a simulation project should be a participative process 
in which various mana- gers are involved at various depths throughout the process; from data collection 
to model flow building. DON SEGAL Several issues come to my mind as important and that are worth significant 
attention by the "Simulation Practitioner." How much detail is enough? The level of detail of a Simulated 
System is critical both as far as the adequacy of the results and the timeli- ness of the conclusion, 
Often you see good devoted analysts consuming 178 days out of 180 days time frame in constructing a model 
but having only 2 days to really run it and analyze the data. Figure l is a simplified graph reflecting 
the relationships between the deci- sion variables, EFFORT RISK COST TIME L LESS FIGURE l  s DATA COLLECTION 
ODEL BUILDING I..=DETAIL LEVEL OF MODEL MORE I I I I 
			