
 THESIS: The Hardware Environment for Small Intelligent Systems, for Engineering Applications K.F. Wong, 
B.Sc., G.G. Coghill, B.Sc.,Ph.D. and J.M. Hannah, B.Sc., Ph.D. Electrical Engineering Department, Edinburgh 
University, The Kings' Buildings, Mayfield Road, Edinburgh, EH9 3JL, Scotland. ABSTRACT System size, 
lack of standards and poor real time response have prevented the widespread acceptance of AI techniques 
in engineering applications. By tailoring the hardware configura-tion specifically for applications and 
by utilising an accepted bus standard, improved performance may be achieved. In this paper, the above 
approach is justified through the explanation of the principles of a hardware system, named The Hardware 
Environ- ment for Small Intelligent Systems (THESIS) which is currently under development in Edinburgh 
University. 1, Introduction Artificial Intelligence (AI) is a science which attempts to provide machines 
( artificial entities ) with human-like behaviour such as the ability to store and acquire knowledge 
and make use of it to reason and to act on deductions as a human being would. A study of how to best 
support AI applications programs in a real time engineering environment is being conducted in the Department 
of Electrical Engineering of Edinburgh University, Scotland [1]. Fields of interest include: signal processing, 
speech processing, engineering consultancy, monitoring, control and instrumentation. It has been shown 
[2] that practical systems for engineering applications have to be small in order to be easily transportable 
from one site to another. Frequently, they are operated by non- technical personnel and therefore they 
should have user-friendly interfaces. The ability to respond instantaneously to external stimuli is often 
an important requirement for engineering sys- tems. Commissioning considerations are also crucial as 
these can be more expensive than the system and its design cost taken together. For good design practice, 
factors such as ease of maintenance, serviceability and ease of future expansion, need to be taken into 
account as well. At present, most small engineering systems are only semi- automated. Users still have 
to interact with them to ensure acceptable performance. Take for example the case of a spec-trum analyser 
with data acquisition capability. Normally, Permission Io copy without fee all or part of this material 
is granled provided that the copies arc not made or distributed t~)r direct commercial advantage, (he 
ACM copyright nulice and Ihe litle of the publication and its dale appear, and notice is given thai copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. &#38;#169; 1986 ACM 0-89791-211-4/86/1200-0173 75Â¢ engineers have to 
interact with the instrument, so that ambigu- ous data samples are rejected leaving only valid cases 
for con-sideration. With built-in intelligence, unacceptable signal pat- terns could be initially stored 
as background knowledge. Using inference techniques, the instrument can 'smartly' filter out unwanted 
signals and continue sampling with little, or even no, human intervention. Complete automation in such 
instruments has long been an engineering aspiration. 1.1. Section Summary The factors prohibiting AI 
techniques from being con-sidered as a practical proposition are identified in section two. A suggested 
remedy may be found through proper system confi- guration and the use of a standard system interface. 
This is described in the third section. Finally, in section four, conclu- sions are drawn with suggestions 
of other configuration possibil- ities.  2. Predicaments of Existing AI Technology Presently, there 
are two major drawbacks of existing AI technology which have been prohibiting its wide acceptance in 
engineering applications. They are : 2.1. The bulk and lack of standards in AI systems hardware AI software 
is generally too large and complicated for con- ventional programming languages e.g Pascal. Efforts have 
been made by researchers to produce special AI languages [3] with optimising compilers. In addition, 
compact data structuring tech- niques applied to advanced algorithms, have reduced program size and complexity. 
Several small to medium scale systems are under research and development. Some of these have left the 
laboratory environment and have started to gain practical significance [3]. For example, Symbolic 3600, 
a commercial LISP machine which evolved from the CADR processor system first developed in Massachsetts 
Institute of Technology (MIT). These systems are meant to be design aids for AI software programmers, 
but they are unsuitable to be used for engineering applications. 2.2. Poor system response for real time 
applications Computer intelligence implies reasoning with knowledge or applying rules to facts. During 
the process of reasoning, units of memory (cells) are dynamically being consumed and released. With a 
finite storage system, memory exhaustion is bound to occur unless released memory can be re-used. The 
process of memory reorganisation so as to reclaim re-usable cells is called Garbage Collection. Garbage 
Collection is usually considered to be the responsi- bility of the host processor. Previously, to run 
such a process, the host would suspend all active jobs and dedicate itself solely to retrieving re-usable 
memory. This was acceptable in the research 173 and development system environments of the past. Nevertheless, 
the complexity of present AI software has rendered even this approach inadequate. If engineering applications 
had to stop at the middle of a continuous task the result could be costly or dangerous. Imagine an Intelligent 
System responsible for a manufacturing line halting during production to carry out a Garbage Collection 
cycle. Currently, three practical solutions to improve real time AI performance are being investigated: 
(1) software garbage collection algorithms with real time capa- bility; (2) special architecture AI 
machines with microcoded garbage collection schemes; and (3) a dedicated hardware garbage collector 
in a multiprocessor environment.  The software approach is becoming obsolete; nevertheless, it is still 
viable if a quick and cheap solution demanding moderate response is required. Effectively, ideas two 
and three are hardware realisations of the software algorithms. The special purpose processor with its 
dedicated architecture is promising, but it would not be practical until some standardised architec- 
ture, or architecture with an internationally accepted interface standard has been achieved. Because 
of its cheap production cost and ease of expansion the multiprocessor approach is superior to the rest 
at present. The multiprocessor solution consists of a coprocessing sys- tem working in parallel with 
the host, devoted mainly to Garbage Collection. In so doing, the problem of memory exhaustion is taken 
from the host. The result is a more dedicated host process- ing unit. As hardware dosts are ever decreasing, 
this approach becomes increasingly attractive. Unfortunately, the existing sys-tems are far from perfect. 
They are -- difficult to implement: usually crucial inter-processor com-munication protocols are required, 
e.g. de~Ld-iock avoidance using semaphores. Consequently, debugging and maintenance problems prevail; 
-- lack of flexibility: existing systems have their their g~rbage collectors constructed around specific 
processors. Com- munication between them is via non-standard interface specifications. In so doing, system 
designers are restricted to one specific type of processor. Worst of all, random interfacing design methodology 
is error prone and labori- ous. 3. THESIS The Hardware Environment for Small Intelligent System (THESIS) 
is a hardware system design tool. By down loading it with appropriate software, it can be customised 
to suit different engineering applications. Tolerable size, improved real time per- formance, ease of 
expansion and flexibility are its beneficial characteristics. Figure one illustrates the anatomy of THESIS. 
Basically, it comprises five compulsory modules: (1) the Host Processor (HP), (2) Input/Output channels 
(I/0), (3) the Inference Engine (IE), (4) the Knowledge Base (KB), and (5) the Cell Space (CS).  
HP is the kernel of the system. It is the coordinator which controls flow of information between other 
parts and handles mutual communications. Internally, it comprises the processing unit and some primary 
memory ( heap ). For system expansion, secondary storage devices could be incorporated. I/O supplies 
communication paths with the external world. This could also be stimuli such as electrical signals from 
transducers. The IE encompasses ~ules and guidelines for heuristic deductions. The KB is a massive database 
containing facts. During reasoning, facts in the KB are scrutinised under the guidance of the IE. The 
role of the CS is to transport information to and from the KB according to the HP's instructions. Physically, 
CS is a writable memory store where ceils are created. 3.1. Reasoning Initially, the KB and the IE are 
pre-programmed with relevant information. When real world stimuli enters from the I/O, the HP reacts 
promptly and monitors these stimuli. Infor-mation frameworks are generated by applying the IE's rules 
to the KB. The received stimuli are compared against such frame- works. The results are fed back into 
the HP which will send a response to some intended recipient and create more tasks. Effectively, the 
decision of the HP is made by applying heuristi- cal inference techniques on past 'experience'. In such 
a fashion, full system automation is established. 3.2. Adaption By Learning In situations when a fatal 
error occurs, such as overvoltage in the case of a power system monitor, which could cause real- functioning 
of the system, the HP would note such an error at the moment of break down. During bootstrapping, when 
the sys- tem resumes, the error pattern would be passed on to the KB; and from then on tagged as high 
priority. Moreover, the HP could then self-generate a set of precautionry procedures, accord- ing to 
existing 'experiences'. These procedures would be stored in the IE and would be invoked whenever the 
error recurs. Theoretically, the information stored in the KB and the IE would be ever increasing, thus 
providing the overall system with adap-tive bchaviour. Consequently, the concepts of learning and data 
acquisition, which are major AI functional issues are realised. 3.3. Separation of the CS from the Heap 
At first sight THESIS does not seem to be very different from classical AI systems [3a]. The contrast 
lies in the separa- tion of the CS from the primary heap memory. In classical AI systems, programs and 
data mingle together in the heap. In so doing, they exhibit referential transparency, one ot the unique 
features of AI languages [3]. There is no difference between program and data. Both are classed as symbols 
or objects. Each object is constructed from one or more cells and has some pro- perties associated with 
it. I~roperties can either be a collectiive list of other objects or a list comprising of some functional 
specifications. The actual constituents are only reviewed during run time. Thousands of objects form 
a program environment and new objects are created continuously whilst old ones are aug-mented during 
program execution. Because AI programs are generally large and complex, with codes and data stored in 
one common area, system performance can easily be degraded. For instance, if the memory is mostly filled 
with program code, it would not take long before memory exhaustion occurred. Moreover, the frequent need 
for garbage collection would cause untolerable interruptions. In practice, programs are mostly permanent 
objects which makes garbage col- lection on them not worthwhile. The reason for separating the CS from 
the heap is to facili- tate the division of program and data. Programs are stored in the heap within 
the HP. Since program codes are instructions to direct the HP, this ensures direct access to instructions 
from the HF. Cache memory can be used to further increase the rate of instruction fetching. For a large 
software environment, secon-dary memories, with page scheduling, can be attached to the heap. Data is 
restricted to the CS only. The dynamic memory allocation process will create and release cells from this 
region. Unfortunately, CS/heap separation has partially sacrificed the characteristic of referential 
transparency. However, this is not essential in an engineering environment. This contrasts with a development 
environment, where referential transparency is crucial because every object is dynamic and may be subject 
to changes. In engineering applications, programs are well defined 1'74 and mostly staY. It is not worth 
including these codes in the CS because this would do nothing but increase congestion. When objects which 
become permanent during program execution, e.g. experiences which are learned, the CS can transfer them 
to other non-temporary memory modules (the IE and the KB). In classical AI systems, the process of reasoning 
is implicit : it is regarded as part of the HP's responsibility. Users are virtu- ally transparent to 
such processes until they are interrupted by the need for garbage collection to reclaim re-usable cells. 
Having separated segments for programs and data, provides more room for the HP to work on and the frequency 
of garbage collection is reduced. Also, the rate of garbage collection is speeded up due to the fact 
that the collector is dealing with cells only --cells arc generally temporary entities [4] and so they 
required less effort to recycle. To concentrate on the CS only, greatly reduces the HP's search paths 
and processor throughput is increased. , -Currently, Clhssic~tI-~r-~-ystems contain a limited a~nount 
of ~nternal heap memory. Virtual memory techniques are often employed to accommodate large software systems. 
As a side effect of random dynamic cell allocation, non-contiguous cell dis- tribution occurs. Inevitably, 
this would lead to frequent page swapping and memory fragmentation. It is an expensive practice to transfer 
information from secondary memory into the heap. To do it frequently could be disastrous, even with large 
main- frame systems as they could end up spending most of their time swapping pages. This is a problem 
for the entire computer science commun- ity rather than simply for AI. To solve this problem, researchers 
have developed algorithms, such as compaction, cdr-coding, etc. The idea is to Iocalise cell distribution 
and reduce thrashing. The penalties paid with these methods are the extra effort required for cell processing 
and prolonged garbage collections. However, since the overall performance has been improved, the drawbacks 
have to be accepted. Program/Data partitioning in THESIS provides an alterna-. tive solution to the above 
problem, particularly suitable for small system designs. Since the CS comprises data cells only, there 
would be ample space for cell distribution. In most cases, the' heap would be sufficient even without 
secondary memory sup- port. This means that Iocalisation techniques are not required any more. Without 
them process execution would resume after garbage collection with no extra effort required for compaction 
techniques etc. In AI applications, cells are short-lived and a high percen- tage of them are re-usable 
[4]. The only trade-off is the fre-: quency of garbage collection, but the rate of this process has already 
been increased since program codes which are permanent objects need not be collected. In addition, if 
a garbage collector which recycles useful cells and rejects 'garbage' [4] is used, fewer cells have to 
be collected. 4. Th&#38;#169; Prototype of THESIS A prototype of THESIS is under construction using a 
VME multiprocessor bus system. VME is by far the most widely used industrial interface for system designs. 
By adopting this de facto standard, ease of maintenance, and design flexibility is aceom-. plished. The 
overall system performance can be enhanced by interfacing it with dedicated coprocessor systems, e.g 
SUM : an AI coprocessor for unification [5]. A garbage collection coprocessor (GC) system is incor-porated. 
The GC effectively sits between the HP and the CS which performs garbage collection in a incremental 
fashion. A modified Hewitt's garbage collection scheme [4] is adopted in the GC. Physically, the implementation 
is a direct microcoded translation of the algorithm. The microcodes control a blt-slice machine with 
a dedicated architecture, specially tailored to increase the rate of garbage collection. Architectural 
supports include dynamic type checking, cell structured storage, head/tail addressing and a flexible 
communication protocol with the host: processor. The flexibility of bit-slice technology [8] has made 
it suitable for the design. Currently, a cell is 48 bits in size ( 24 for head and 24 for tail ) with 
only two bits for type tagging. The GC is responsible for the process of cell allocation. The HP will 
prompt it for a new cell and it will ensure that the CS is not exhausted before granting a cell. If.the 
CS is running out of cells, garbage collection will be initiated '~. As by products, other ceil manipulation 
primitives are also included, e.g. HEAD, TAIL, etc. Therefore, this version of the GC can be considered 
as a cell processing accelerator. Hewitt's algorithm is originally based on Baker's [6]. A Baker type 
garbage collector is preferable because it ensures a strict upper time limit on the process. In engineering, 
where sys- tem timing is a paramount design specification, unbounded pro- cess cycles would render timing 
calculations virtually impossible. In Hewitt's algorithm, garbage collection is performed according 
to cells' lifetimes. Older cells are considered per-manent. Virtually, they are archived and so seldom 
require to be collected. This maps exactly into the idea of CS/hcap separa- tion of THESIS. However, 
real systems which based on [4] (e.g. LM2 machine from LAMBDA) performs cell archiving during run time. 
In THESIS, program code are regarded as permanent cells thus archival is done at compile time. This is 
acceptable in an engineering environment where application programs are well defined. The HP is an off-the-shelf 
CPU system with two serial I/O ports based on a Motorola 68000. In the preprogrammed section of the KB 
and the IE, Read Only Memory (ROM) devices are used, for simplification and to reduce the design cost. 
The remaining parts of the KB, the IE, and the CS are implemented with low power CMOS Random Access Memory 
(RAM) devices to reduce heat dissipation. 5. Conclusion THESIS provides a flexible general purpose structure 
for designing engineering applications. It provides a solution for current AI shortcomings in engineering 
areas. This is achieved by using de facto industrial standards, e.g. VME bus, proper sys- tem configuration 
and the incorporation of a parallel garbage col- lector to take the problem of memory reclamation away 
from the host processor. This leads to increased processor throughput and improved real time response. 
Unfortunately, THESIS is still in its developement stage. Its idea has yet to be justified by apply- 
ing it to practical applications. THESIS is, initially, designed for small scale systems. By loading 
it with different applications software, THESIS could be programmed to cope with various real world situations. 
Nevertheless, the THESIS approach should not be limited to a specific system size. The same design philosophy 
could be applied to large multi-processor systems integrated within a local area network. Moving to the 
other extreme, miniature systems could be implemented using a standard chip interface scheme, such as 
programmable Switch Matrix technology {7], in a tightly-coupled fashion. t Readers are s~ggested to refer 
to [4] and [6] for details. References I. Dept. of Electrical Engineering: project proposal, unpub- lished, 
internal document, Edinburgh University, Scotland. 2. Whittington,H.W., Coghill,G.G.: "Hand-Held Digital 
Sonic Pile Testing System", 1983, Ibid. 3. Barr,B., Feigenbaum,E.A.: "The Handbook of Artificial Intelligence", 
vol.2, chapter7, Pitman, 1983.  I75 3a. Barr,B., Feigenbaum,E.A.: "The Handbook of Artificial Intelligence", 
vo].2, chapter6, Pitman, 1983. 4. Liberman,H., Hewitt,C.: "Garbage Collection Based on the Lifetimes 
'of Objects', MIT AT Memo no.569, Cambridge, Massachsetts, 1981. Communications of the ACM, 1981. 5. 
"SUM: an AI coprocessor", Byte, April 1985. 6. Baker,J: "List-processing in Real-time on a Serial Com- 
puter', Communications of ACM, vol.21, no.4, April 1978, pp280-294. 7. Chen,W. : "Programmable Switch 
Matrix", unpublished, Ist yr. Ph.D. report, Dept. of Electrical Engineering, Edin- burgh University, 
Scotland. 8. Mick,J., Brick,J.: "Bit-Slice Microprocessor Design", McGraw-Hill, 1980.  l, I I a, Rgure 
I : The Anatomy of 11-IE:SIS.  
			