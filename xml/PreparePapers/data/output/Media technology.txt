
 MEDIA TECHNOLOGY Chair: Andrew Lippman, Massachusetts Institute of Technology Panelists: Marvin Minsky, 
Massachusetts Institute of Technology David Zeltzer, Massachusetts Institute of Technology Walter Bender, 
Massachusetts Institute of Technology MEDIA TECHNOLOGY Panel presentation at SIGGRAPH'88 Andrew Lippman 
David Zeltzer Waiter Bender Marvin Minsky MIT Media Laboratory August, 1988 ANDREW LIPPMAN: Good afternoon, 
and welcome to the panel on Media Technology which, I gather, like most of the panels in this room, is 
designed for refugees from radiosity and ray tracing -- words that many people have promised not to use 
on this panel. This afternoon, we have four panelists who will present their views of media technology 
as practiced at the Media Laboratory at MIT. When we began work to form the lab and adopted the name, 
our approach was unique in that we were the only lab that did basic research in communications and information 
technology in a context of creative application. While there were technical labs addressing components 
of media technology and groups that explored applications, we were the only place where the users and 
inventors were in one place and often in one mind. It is fair to say that to the extent that we were 
successful in engendering in our graduates knowledge of both the uses and the technical innards of media, 
they were to proportionately unemployable: No one outside the academic environment understood them. This 
is no longer the case. There are pockets of research and development of themes similar to what we do 
at places as diverse as Apple Computer and Dow Jones; and as geographically distributed as NYU and Stanford. 
There is growing awareness of the notion that computers can participate in communications in novel and 
significant ways through non-linear and content processing, and there is a growing recognition that creation 
of new media requires understanding of the underlying technology as well as human information processing. 
Unfortunately, these pockets are dispersed throughout academia and industry. Rarely are the efforts coupled 
with degree programs and a coherent, complete attack on the problem. The fact that some computer graphics 
programs are hidden in architecture and art departments attests to this, as does the fact that the television 
industry remains distinct from the computing industry. Outside of MIT, there are scattered media experiments 
but little coherence, and glaring omissions. For this reason, the panel on Media Technology is as much 
a review of the work of the MIT lab as a description of the field. I have deliberately selected four 
disparate views of our work for discussion. While we all hold many fundamental principles in common, 
our approach is not at all alike and we rarely all speak with quite the same voice. There is a thread 
tying us together, and that will become clear through the discussion: it involves computing and content 
processing as well as joint and simultaneous understanding of the electrical, cognitive and creative 
processes of learning and information processing, but in practice there are seemingly divergent experiments 
in progress. hope that this panel, through our presentations and your questions will thoroughly explore 
the area. Periodically, media technology intersects and diverges with SIGGRAPH. I can recall roughly 
12 years ago, in 1976, in Philadelphia, where there was a panel on interactivity. At that panel, we addressed 
the definition of interactive systems and the notion of graphical interaction. One of the analogies of 
the time that was used to illustrate the issue was made by Fernando Corbato, who's also a professor at 
MIT and, in fact, invented time sharing. In the course of the discussion, I used Corbato's description 
of interactivity to distinguish between alternation and interaction. Corbato hypothesized a computer 
system that appeared as a turnstile. One entered and presented a deck of punch cards for processing and 
received the result of the "run" as one exited the turnstile on the other side. In those turnstile turned 
rather slowly. But, as time went on, the turnstile could go faster and faster. And you could imagine 
submitting your deck, and one millisecond later, getting the answer. The question we posed in 1976, which 
I think we've successfully answered by today, is whether, ultimately, as the turnstile becomes extremely 
fast, does the system be interactive? And of course, the answer is no. Because you have to fully state 
the question before you get an answer, there is no sense of cooperation with the computer. The response 
is quick, but the entire problem has to be stated before any processing takes place. There is no sense 
of a mutual attack on the problem and no evolution or development of the theory along the way. While 
it may be an abstract historical reference to think about those kinds of things because you always work 
cooperatively with computers, especially in the kinds of applications that most of you are engaged in, 
but it wasn't always so. And the definition of that kind of cooperation and the environment needed to 
implement it, and exactly what the interface would be was, at one time, and remains a matter of study 
and a matter of investigation and exploration. In the intervening years, SIGGRAPH and interactivity diverged. 
Output and database processing grew in prominence as research domains and the mechanisms that generated 
that data base or used the images became distinct areas of research. Now, in 1988, we have come full 
circle, and the uses for graphics systems and the methods by which graphic data bases are designed are 
now as important as their presentation. Hence this panel. Let me tell you a little bit more with some 
pictures. Figure One is a recent chart that outlines the groups that form the Media Laboratory. Perhaps 
the only thing that's misleading about this particular diagram is that it gives you the impression that 
each one of those little bubbles or activities exists independently of the others. That's not the case, 
but the chart would get particularly undescriptive if we tried to demonstrate more exactly how overlaps 
between the several groups function. While there are a great many programs, there are as many interactions 
between them. Perhaps, through analysis of this diagram, you can gain some feel for what we believe Media 
Technology is and how we approach research. In the area of imaging, for example, there are programs that 
address basic image processing (The Advanced Television Research Program), interaction with still and 
moving images (Electronic Publishing and Movies of the Future), cognitive aspects of vision (Vision Research), 
and high level representations of movies (Film/Video.) The people involved include engineers and filmmakers. 
Similarly, work in sound spans cognitive domains of music understanding, through composers working in 
electronic media, to conversational computer systems. One program in place addresses building a computer 
system with which one can play a duet: it listens while it accompanies, and adapts to the interpretation 
you make of the music. As a case in point, in the early 1980's, we developed tele-conferencing systems 
that attempted to transmit the "presence" of the person with which you were conversing instead of the 
image. The idea was that when you became engaged in a distant conversation with that person, you would 
have the overwhelming impression that they were, in fact, there. To implement this, we built models of 
potential conversant's heads in the laboratory and cast masks in the shape of those heads that would 
serve as video projection screens. These masks, or screens, were then mounted in gimbals that allowed 
the replica head to move in synchrony with the person it represented. Onto this mask we then projected 
the image of the remote conferee. There's no ray tracing or radiosity or even B-splines involved in that 
particular experiment, and it can require no video processing at all. However, the effect of the work 
was to take the heads that were typical of teleconferencing systems of the time out of the box that the 
television monitor encased them in and, by correct placement of the "talking heads" around the conference 
table, allow eye contact. When one participant turned to talk to another, their images did likewise; 
the others saw this much as they would were all the people in the same room. The purpose of this illustration 
is to demonstrate a different approach to teleconferencing. Rather than use it as an excuse to investigate 
bit rate reduction of video signals, we used it to explore the essence of remote communications. Both 
the quality and the utility of the picture were subjects of research. In fact, in one demonstration, 
we processed no video at all, but simply animated the image projected on the head by retrieving various 
images of the person speaking controlled by speech analysis alone. I use this example to indicate that 
the teleconferencing system combined speech processing, image processing and computer graphics. In the 
course of the work, we learned about all three topic domains and crossed previously implicit boundaries 
set up between them. The graphics was a sync-sound movie, and the image was three-dimensional. In another 
experiment, we combined position sensing and speech recognition so that each could complement the other 
and provide an interface where the sum was greater than each of the parts: The notion was that a computer 
could not understand a conversation unless it had access to the verbal and physical context. Neither 
alone would be sufficient. The program, called "Put That There," demonstrated that the system could understand 
pronouns by their physical referent. Where you pointed when you said "that" determined what you meant. 
The theme in that work is simultaneity of the interface, using all of the modalities available and, again, 
solving the problem in as many different ways as one can. The moral of the story is: never use one interface 
when two will do. A current program in the lab is the "Movies of the Future Program." The theme of this 
work is the digital representation of moving picture information, and the ultimate goal is a model of 
moving images that can be manipulated with the facility with which we control existing synthetic, completely 
described data bases. This is investigated in the context of two broad application areas: new distribution 
media for traditional movies and the integration of moving images into computer interfaces. The first 
area is of direct interest to some of the supporters of the program -- motion picture distributors such 
as Paramount, Warner Brothers and Columbia - and the second aspect is relevant to personal computers 
where the tasks you require of them take time to accomplish. In this latter case, we anticipate that 
motion can represent the temporal aspect of the computation and create a dynamic visual interface. Part 
of this work involves creation of a "range camera" that senses the distance of the points in the image 
as well as their intensity. By suitable processing of the range images, we can alter the focal point 
and lighting of the image after it is recorded, and ultimately, we can alter the perspective from which 
the scene is rendered. One thesis student is developing a three- dimensional data base from the range 
images by correlating the motion, the image data and the range information in the scene. Each alone is 
ambiguous, but like speech and position in "Put That There", they complement each other and help create 
a more complete model. The range camera derives distance by a technique called "depth from focus." Two 
apertures are used in the lens that provide a short and long focal length image the difference between 
which generate the depth image. This has been both an introduction to the panel and one view of Media 
Technology. The overriding point has been the diversity of the technical approach: conferencing systems 
that combine graphics, speech processing, and image compression; command systems that combine physical 
environment sensing with speech recognition; and moving picture processing systems that require image 
processing, computer graphics and three-dimensional picture analysis. The other three panefists will 
each present their individual views and we will then discuss the issues during a question period. DAVID 
ZELTZER: May I have the first slide, please? I'm going to tell you about my slice of the Media Laboratory, 
which has to do with interacting with animated microworlds. What we're after --and the term is due to 
Marvin Minsky --is something we've been calling an "expressive animation workstation." The idea is that 
we'd like to take the power of computer graphics hardware and software and somehow make it available 
to professionals, educators, consumers and entertainers as a medium for visualizing ideas, for simulation 
and design, for learning, and so on. We take it for granted that this will be a real time high-quality 
graphics medium, and I think it's safe to say that the hardware is rapidly taking us there. We want the 
user to be able to interact with these animated worlds on their own terms. That is, we don't want to 
require people to learn Fortran or Lisp or "C" or some special-purpose animation language. We'd like 
users to be able to interact with the machine on their terms and not on the machine's terms. To do that, 
we need to incorporate a lot of knowledge about what kinds of simulations people are interested in, how 
living creatures interact, and how physical objects interact. We're interested in developing autonomous 
agents, so that if someone wants to use an animation with human figures in it, that person doesn't have 
to write a lot of code to do the transformation hierarchies and do the rendering and so on. By the same 
token, we don't want that person to have to take three or four years to train a simulated human being 
how to walk around, open doors, stand up and sit down. We want figures that know how to do some kind 
of problem solving on their own. To set this in context, let me talk briefly about how I view computer 
animation, and how people have been interacting with animation systems. I think there are basically three 
ways of specifying the behavior of animated figures. I call these modes of interaction guiding, animator 
level and task level animation. We'll look quickly at each of them in turn. Guiding means that the user 
explicitly specifies what every object in the animation is doing from moment to moment. This is terrific 
if you want to have control over all the details of the animation. But, as the simulated worlds that 
we're interested in become more and more complex, that just becomes too tedious and costly to do. This, 
though, is the principal means people currently use for controlling animation. That is, if you want to 
control a jointed figure, you attach a knob or a joy-stick to each of the joints in turn, and twiddle 
the knobs until the right things happen. The next level I call the animator level , and here we provide 
the user with a programming language or special-purpose animation language for defining and controlling 
the objects and events to be animated. This provides the user with the full power of aprogramming language, 
and gives the user the ability to program whatever abstractions and special-purpose mechanisms are required. 
The problem is that we've now made doing animation as hard as programming. We know the problem there. 
It also means that the user has to be either a programmer or has to hire or coerce or cajole a good friend 
who is a programmer to work with them. And that establishes a separation between the user of the system 
and the medium which we'd like to make available to them. Finally, there's a mode that's called task 
level animation. This is a term that's shared with the robotics world, where the problem is to control 
robotic agents by specifying a set of events and some constraints on the behavior of the agent, and letting 
that agent fill in the details as necessary. Let me distinguish here between animation, as many people 
think of it, -- and the kind of animated simulations I'm talking about. First of all, I think of output 
to film and video tape as a rather occasional use, in our case, perhaps, for demonstrating our work for 
sponsors and at conferences. For the most part, we're interested in real-time interaction, right there 
on the desk top with the user. Secondly, lately there's been a lot of interest in developing control 
paradigms for computer animation. This morning, we heard a paper by Witkin and Kass on space~time constraints. 
This way of thinking about animation requires that we know, globally, what the simulated agents are going 
to be up to. We need to know the start conditions and the end conditions and some key constraints in 
the middle. I want to distinguish between that and what we might call forward simulation. Suppose you've 
just designed a new six-legged robot and you want to see if it can, indeed, traverse the terrain it was 
intended for. You would like to place it in the simulated environment and find out if it works. If it 
breaks, fine. You've got to know that. So we're not interested in constraining simulated agents to do 
what we want them to do. Rather, we want to let them do what they want to do. How are we going to get 
there? Well, in my group, we're following three broad lines of research. The kinematics and dynamics 
of motion --in particular we're looking at legged locomotion. We're looking at modeling motor behavior. 
And, lastly, we're interested in natural and easy interaction with these 3-D virtual worlds. Let me quickly 
outline the work that we're doing, without going into great detail on any of it. Here's a single frame 
from a piece showing objects falling and tumbling in a gravity field. I think perhaps the first thing 
that you want to do is include in your simulation all those Newtonian mechanical attributes that we expect 
in a physical world. My earlier work involved modeling human walking using forward kinematics. Currently, 
we're looking at building locomotion models based on biological motor control. We'll show you a video 
tape of that shortly. We're also interested in 3-D interaction. This work has a long historyat the Media 
Lab, and earlier, at the Architecture Machine Group. This is work that was done by my colleagues, Patrick 
Purcell, Delle Maxwell, Carol Ginsberg, and others. Here you see some animation that makes use of speech 
recognition in addition to tracking the position and orientationof the human user. The main idea here 
is something called scripting-by-enactment. That is, ff you want to get an animated figure to do something, 
then you act out the movement and the animated figure will mimic that motion. Later on, this work continued 
in the development of the body suit. Here you see Mark Locasio modeling the latest version --one size 
fits all. I've forgotten how many degrees of freedom it tracks, but there's a ring of LED's around each 
joint in the figure and, not seen in this view, is a pair of cameras which, by comparing the two views, 
can reconstruct 3-D position and orientation information for the figure. Here's the body-tracking glove. 
The glove itself has as many degrees of freedom as the rest of the torso. This work is continuing now 
with a new technology, using fiber-optics. This is the Dataglove made by VPL Research in California. 
It uses fiber-optics that have been treated so that when the finger is bent, the light transmitted through 
the fiber is attenuated. By measuring that attenuation, we can then calculate the joint angle of the 
finger underneath it. So we are measuring data from ten joints -- two knuckles on each finger. In addition, 
there's a Polhemus electromagnetic sensor on the wrist, so we can also get position and orientation information. 
But we're not satisfied with just reaching out and appearing to touch objects -- we want to feel what's 
going on. Here's Alex Ferdman demonstrating a 2-D force feed-back joy-stick, which is due to Max Bahensky, 
Margaret Minsky, and others. I think you get the idea. Not only can you move the joy-stick around, but 
it pushes back. You can simulate a variety of forces reacting to the user's movement as appropriate. 
In conjunction with the mechanical engineering department, we're working on extending this to three dimensions. 
What you see here is a one-dimensional prototype of a force feed-back joy-stick that's actually a hybrid. 
If you want to get high-frequency response, that is, if you want to simulate hitting a brick wall, you 
have to have rather large motors to bring the joystick and the user's hand to a sudden stop. That means 
that the device will no longer fit on your desk- top, and -- what is worse -- if there's a bug in the 
control program, you might break somebody's hand. Naturally we want to avoid that, so, in this device, 
there's a particle brake on one side, and a rather small motor on the other side. The use of the brake, 
then, allows us to do sudden stops without using very large motors. The last thing I want to talk about 
is modeling behavior. What we want to do is understand how biological creatures organize their own routine, 
instinctive behaviors. In graphics, people generally draw on the disciplines of optics and physics to 
understand theinteraction of light with materials. For behavior modeling, we're drawing on the work of 
the ethologists -- in particular Conrad Loren's and Niko Tinbergen, who spent a long time thinking about 
how behavior is organized, although not quite in terms that lend themselves directly to implementing 
algorithms. On the slide you see Tinbergen's postulated view of how behavior is organized hierarchically 
from "higher level drives" on the top -- which might be things like, "I'm hungry," or "I'm thirsty." 
or "I need to go to sleep." At the bottom of the diagram you can see the lowest level of the motor output 
system. The point is that we need to think about how behaviors are organized, how we can build hierarchical 
suites of motor skills, and interconnect them in such a way, that the simulated agents can do certain 
kinds of problem-solving on their own. I don't do all this work by myself and, in fact, it couldn't be 
done without the help of my students. Why don't we roll the video tape. The first tape you'll see is 
a whimsical attempt to show you a bunch of these techniques -- primarily the work of Mike McKenna but 
with a lot of help from a lot of others. So let's roll the tape. Lastly, I want to point out that the 
production of this video tape and one that you saw in the film show yesterday by Bob Sabiston, required 
a close collaboration between the Computer Graphics and Animation Group, the Visible Language Workshop 
and the Electronic Music Studio to put these productions together. WALTER BENDER: There's been a resurgence 
of interest in television over the last few years. It's the first timesince the '50's that the good engineers 
are interested in television. One of the aspects of the lab that Andy mentioned briefly in his introduction 
was our advanced television research program. There's a group of people doing fine work on the quality 
axis of television. How to make the picture better and how to get that picture into your home. There's 
another group called the Audience Research Facility that's trying to understand how consumers and the 
public at large respond to things like high-definition television. If you ask the average person on the 
street -- even around MIT --what's wrong with television, they don't say artifacts, they say, programming. 
Our Audience Research Facility is off-site from campus, though, because you can't really test that at 
a facility in a technical institution. In any case, the Electronic Publishing Group, where I work, is 
more concerned with another axis of television evolution, that of programming alternatives rather than 
solely picture quality: what new degrees of freedom can we invent for television in the next thirty years 
rather than how many new lines of resolution can we bring to the image. You can see that Andy and I work 
closely on some projects. The theme is semantic bandwidth compression, with an emphasis on the word, 
semantic. We take seriously the notion that intelligence (or processing) in the channel can substitute 
for bandwidth, but we regard intelligent channels not simply as those that reduce noise in a picture, 
but instead as those that process content versus signal. As an example, in the early 1980's the group 
created a teleconferencing system where no video was transmitted through the telephone lines at all, 
yet a picture was reconstructed at the receiving end. Some of this work was reported by Lippman at the 
1981 Picture Coding Symposium and ironically, it has been resurrected recently in the form of "Model-based 
Coding." In the system we did in 1981, a gimbal-mounted image of the remote conferee done as a lenticular 
photograph that changed as your viewing angle changed was simply wiggled when the remote speaker spoke. 
These change-image-lenticular photos use the same technology as post cards you once bought where when 
you looked at them from one angle, you saw a person in one position, and as you shook the card, they 
moved, or changed clothes. In our work the gimbal provided the motion, and it was activated by the voice 
signal over the telephone line. We once thought of this as the 17-cent teleconferencing system. We think 
about media coming in three flavors in the Electronic Publishing group. There's traditional ink on paper, 
which is directly accessible. You don't need anything between you and it except, perhaps, eyeglasses. 
It's right there for you. Back, at the beginning of the century, people started experimenting with a 
new kind of media -- radio -- where you needed a box, a signal processor between you and the information. 
There's only really been one new knob added since the '50's, and that's the mute button. But you could 
imagine, now, a computational media --a medium where there's computing in the loop, so you can start 
making decisions based on the content of that signal, not just its electrical characteristics. And what 
the implications of that kind of media is really what we've been exploring for the last ten years. The 
first example I'm going to show you dates back to SIGGRAPH in Seattle in 1980. This is a system called 
the Aspen Movie Map. As Andy likes to say, there are only five people in America who have not seen this 
system. It was even on the Ripley Believe it or Not television show at one point. We used a mechanized 
camera to take one picture every ten feet along every street in the town of Aspen, Colorado, and one 
picture every ten feet around every corner in the town. We envisioned distribution of a data base of 
the town by storing those images on an optical videodisc and regarding the publication as that of a data 
base rather than as a predetermined travelogue or cinematic tour. The town was accessible via images 
taken in the fall and the winter, and you could envision a "season knob" on the television set augmenting 
the traditional channel knob. You could use a control that changed the content within the context of 
the program. That was something that happened locally. The packaging of the material was happening in 
conjunction with you, not necessarily dependent on what was happening in the head end, in the distribution. 
We took it a little bit farther a couple of years later with a project called the Movie Manual. And there, 
it was data as well, assembled on the fly. And there we had a primitive model of the user stored locally, 
so that how that data was put together, what you got, was somewhat determined by who you were and what 
your past interactions with the system might have been. We took that concept a little bit further in 
the next project I'm going to discuss, which is an electronic newspaper. A project called NewsPeek. In 
this project, we developed a more sophisticated model of the user and of the data base. And the idea 
was to take the normal model of how news is distributed and transform it so that each reader received 
a newspaper that reflected his or her own interests and personality rather than a newspaper identical 
to that read by someone else. We tried to model in the machine the functionality of a newspaper editor 
and the reporters. But now, the editor is working for you; he has a readership of one --an individual. 
We tried to present the information in a way that was familiar to the reader. We had a front page to 
our newspaper. It's ironic, every newspaper in the world has a front page. And it is not by coincidence. 
Somebody, at one point, invented the front page. It was a good idea. And it worked. And people used it. 
And yet, there's not, to my knowledge, a single on-line information system that has a front page. There 
are a few that have headline services, and there are a few that have the top of the hierarchy. But none 
of them have a front page. None of them give you that parallel access -- multiple stories on view at 
once. None of them go to the trouble to try to understand what's important, and what's the most important, 
and sort through the information for you. One of the other features of the Newspeek system was that when 
you opened up the newspaper, when you expressed interest in something, the system tried to respond to 
that. So that the example we like to use is page 14. You open up to page 14 for the continuation of an 
article; not only do you get the rest of the article, but you get related articles. You get articles 
that the computer thinks are related to that particular article. Those decisions being made as a joint 
decision between you, the computer, and the editor/publisher at the head end. We extended this notion 
to television. We developed a program called "Network Plus" where the captioning information associate 
with a normal broadcast cued the programs that composed the newspaper to annotate the broadcast with 
additional information that the viewer could query during the program -- a TV program with a "tell me 
more" button. Finally, we're also looking the other way: we're not just looking at the data, but we're 
looking at the user. We've got a system that was inspired -- I hate to say it -- but was inspired by 
the urinals in O'Hare Airport. The urinals in O'Hare Airport know when you're there. And they know when 
you're not there. And they operate accordingly. None of our computers seem to know that. We decided that 
it might be interesting to find out what you could do if the computer knew when you were there and, perhaps, 
where were you were relative to the screen. Whether you were paying attention or not. Whether you were 
looking in the direction of the screen. So we built a presence detector. It's got one bit which just 
says, he's there or she's not there. And then it also tells you an estimate as to how far away you are 
and whether you're looking to the left or center or right on. It's fairly simplistic image-processing, 
but it makes sort of a nifty tool for the interface. So if you're across the room, the computer can interrupt 
you with some voice. Or, as you get closer, it can put more and more dense information into the display. 
Finally, we have one other theme that we've been exploring off and on for a number of years. We still 
don't have the bugs worked out of this one. But this is the smile detector. I think that having a built-in 
smile detector and a built-in blink/stare detector is an essentially part of the interface, and as essential 
as having a keyboard there. And once we have it -- well the smile detector could be a little dangerous. 
But the blink/stare detector, I think, could be quite useful. Thank you very much. MARVIN MINSKY: Everyone 
at this conference is concerned with "media' - that is, with devices or materials through which the minds 
of different people can influence one another. Most of the time, when we write, paint, sculpt, or make 
movies, we're concerned with getting results. We want a certain kind of product, and we focus on the 
small details of getting it done. That's what we do most of the time. In this talk I want to encourage 
our community to think more about the nature of those activities. I'll argue that more thought about 
psychology could lead to better tools for practical arts. We're usually driven by short term goals. When 
we need to produce a movie, or an animation, we naturally tend to think in terms of the final result 
- for example, depicting a certain activity. The traditional way of doing that is to think in terms of 
breaking the scenario down into sequences of pictures or scenes - for example, by conceiving of a story-board 
represented by key frames spaced apart in time. Then we have our work cut out; we have our plan and all 
we need do is to find smooth ways to fill it in. But what are we really trying to do? We talk about communication 
in terms of passing thoughts and ideas from one person's mind to another's. But what do we mean when 
we talk of such things? What are ideas - those things inside minds? And what, for that matter, are the 
things we call minds? How far can we expect to get unless we try to force ourselves to form ideas about 
the things we're trying to do? What does it mean to communicate - for one person to tell an idea to another 
person? Whenever they start to think about that, our scientists and philosophers usually get stuck at 
defining terms like "symbol", "meaning", or "idea". A better way to get around this problem is to think 
instead about what sorts of structures and processes most exist inside a brain. Clearly, human communication 
must involve some family of "construction processes" in which one person manipulates media so as to cause 
new structures to form in another person's brain. How does that happen? It has to be indirect. Even if 
you had some direct way to reach inside and change another person's synapses, that wouldn't do you any 
good, because no one yet knows enough about how brains compute ideas. We're still in the dark ages of 
psychology. I suspect that this is largely because we are all immersed in a humanistic tradition that 
discourages us from trying to comprehend such matters - a world-view in which such subjects as emotion, 
consciousness, and the nature of Self are considered to be beyond the scope of scientific understanding. 
This tradition maintains that although we may be able to understand "reason" because it is rational, 
emotions are too inherently subjective for that, so we must accept them for what they appear to be, and 
not try to understand them. It is less than a century since that conviction started to weaken -for example, 
when workers like Sigmund Freud started to study the jokes and mistakes all of us make in everyday life. 
It is only a generation since Jean Piaget began to look closely at how children develop and Niko Tinbergen 
started to study the behavior of birds. Philosophers had long found themselves baffled by questions about 
the relation of minds to bodies and brains, and no clear image of what they could be even started to 
emerge until until Alan Turing and Warren McCulloch began to speculate about ways to build artificial 
intelligences. Now we can see the relation between mind and brain as simple in principle, although immensely 
complex in detail: minds are simply what brains do - and what they do is construct various kinds of structures 
that support various sorts of processes. And although we still know little about those structures or 
the processes that construct and exploit them, there is much to be gained from making theories about 
such matters - provided that we appreciate our uncertainty and remain ready to learn and change. If we 
each spend some hours or days each year imagining what we might do if we actually did have a good theory 
of how our brains work, that exercise itself will lead to better ideas about ideas. In this as in any 
other field, we can't expect to become proficient without practice; it is hard to become skillful at 
anything unless one first learns to tolerate being awkward. What I'm saying is that it is hard to make 
progress unless one begins with some sort of "top-down" theory. Consider, for example, the field of computer 
vision, which in a way is the inverse of computer animation. All sighted persons are able to move about 
through a home: how do we represent, and interpret all those floors and walls, things and materials, 
animals and people, and relationships between objects, symbols, gestures, and expressions? There are 
so many problems in dealing with this that most workers in the field of computer vision have adopted 
what we call the bottom-up approach. It would be far too difficult," they often maintain, "to directly 
attack the question of how people see," and argue that it is better to begin with lower level processes. 
In the biological realm, for example, one could start by studying the nerve cells of the retina, and 
then go on to understand the following clusters or bundles of cells. Or one can start disregarding the 
brain: by first treating a picture as made of separate pixels and then then aggregating these into features, 
edges, textures, and regions. It certainly sounds sensible first to thoroughly understand the lowest-level 
aspects of picture-things before speculating about the larger-scale procedures involved in discerning 
what pictures depict: boards and bricks, tables and chairs, and people looking at TV sets. But I've come 
to conclude that this approach is not so productive, after year after year of watching many of my colleagues 
trying to find better ways to discern the edges and textures of patches of light. Iask them when they 
expect their machines to be able to distinguish a dog from a cat, or a car from a truck. And every year 
the reply is the same: "Not quite yet, but as soon as we understand a little more about tow level vision, 
it will be easy to move up. The trouble with this is that there they'll always find more low level problems 
to work on. This is what would happen if all the painters became concerned with the chemistry of pigments 
and never returned to their studies of scenes. One can scarcely ever solve high level problems by proceeding 
only upwards from research on lover-level problems. I see the reluctance to compose high level theories 
as having retarded several parts of my own field of artificial intelligence. One must also conceive of 
some high-level plans - to guide that basic research. The "seeing machines of the future will not require 
not only "bottom-up" research; those insights will have to be fused with with separately conceived ideas 
about higher-level representations and processes. There are so many differently useful ways to process 
the input signals that it makes no sense to seek the "best way" to it. Vision involves so many different 
kinds of problems that our brains need whole societies of different methods. The advantage of this diversity 
is that none of those methods has to work well on every problem, so long as a few of them help for each 
problem. But once we look past that signal processing level, we see that we also need theories about 
how to manage the higher level structures and processes involved in seeing those cats and cars and human 
forms. To make machines that make movies from scripts, we'll need yet more theories about how our minds 
work. If you're working with media - that is, with means for changing what others think - you ought to 
have theories in several other domains - about thinking and reasoning, about memory, about emotions, 
and about the nature of communication itself. Suppose, for example, that a certain line in a story-board 
script requires one actor to to arouse a sense of affection (or hostility) in another actor. This demands 
some sort of emotional dialogue - but, today, today we can do little more than make sketches and interpolate. 
Why can't we instruct our drawing machines to think of how to depict such scenes? Some people might argue 
that it is impossible to mechanize such things. But I predict that in the end we'll find that it's actually 
easier to make machines to manipulate emotional gestures and expressions than to do the same for "intellectual" 
matters. I think we find that hard today only because our culture h, as burdened us with,!nadequate images 
of what we are; we have gotten stuck with an incorrect unified field theory - namely, that each of us 
has - or is - a single, unified, central Self. In other words, we have the illusion that inside each 
human person's head lurks another person inside that head who controls or decides what we shall do - 
save when, perhaps, we're confused or ill. What is so bad about that idea? Simply that so long as we 
maintain the concept of a central self we tend to resist attempts to analyze it - that is, to break it 
down into a more complex structure of components and relationships. And our humanists tell us that doing 
that makes one into a beastly "reductionist". We are told that being reductionistic" is somehow evil 
or sinful - a transgression to cost one the loss of one's soul. What can we do about such superstitions? 
My new book, The Society of Mind, (Simon &#38; Schuster, 1988) proposes a variety of more constructive 
theories about various aspects of mental activity. To be sure, only a few of those theories are probably 
right - but the point of the enterprise was less to propose final answers than to present a sort of fantasy, 
a work of psychology-fiction, to suggest an image of what it is like to have such a theory about the 
mind. For despite reductionism's bad repute, it is nevertheless our most powerful way to comprehend complex 
things: by breaking them down into into networks of parts and relationships. Seen from that viewpoint, 
indeed, the traditional image of the single self seems the opposite of ennobling; is that not degrading 
way to approach the brain, that most complex assembly of functioning parts in our universe of experience? 
It is no wonder that the humanist tradition was outraged by Sigmund Freud's reductionist vision of the 
mind: as a system containing several parts, none able to communicate directly with the rest. Yet, as 
I see it, it is just that fragmentation of machinery that accounts for most of the richness of mind, 
because it constrains the different parts of that machinery to employ the same sorts of signals and symbols 
to represent different sorts of wishes and goals. It must be this diversity that forces us to construct 
metaphors which combine new types of knowledge with old, and in that way to make us make connections 
between how we physically interact with worldly objects, how we socially interact with our communities, 
and how we ethically interact with traditions about what we ought and ought not become. In making the 
first mechanistic theories about such matters, Freud's reductionist analyses can be seen as the first 
constructions of artificial intelligence. Yet even that view was too unified. It took another generation 
for researchers like Niko Tinbergen and Konrad Lorenz to envision how what had always been seen as a 
single instinctive, emotional Self could emerge from near-separate specialists. Their careful studies 
of animal behavior led them to see each individual, less as a single (hence unexplainable) whole but 
as a package of smaller minds; one for finding food, another for building a nest, others for keeping 
wet or dry; for defense or attack, for flirtation or flight. In this view every animal can be seen as 
a sort of society composed of dozens or hundreds of smaller components, each kind evolving partly by 
itself, but mainly in the envkonment of the rest of them. Seen through their eyes, we can now envision 
a cat, or a human infant) as a virtual playing ground in which the different members or divisions vie 
with one another in competition for control. Then we can see why the infant might so suddenly switch 
from contentment to rage. At first there is not much cooperation among those components, which mainly 
tend to switch each other off. A young animal rarely seems angry and hungry and affectionate at the same 
time. But in later stages of development of animals with more complex brains, more kinds of compromise 
and cooperation can emerge, as the various divisions learn to deal with one another as well as with the 
outer world. What has this to do with Animated Computer Graphics? Simply, that if you want to make an 
animation machine to express affection (or hostility), that machine must embody a theory of how gestures 
affect a viewer's brain. To begin with, we could start with the Lorenz-Tinbergen idea that each animal 
is born with specific, genetically built-in kinds of signal-detectors that arouse particular parts of 
those specialized internal sub-minds. Evidently, certain kinds of abrupt, jerky gestures - or short, 
loud noises - tend to arouse defensive mechanisms, whereas slower, more graceful motions or sounds -those 
with smoother trajectories -tend to arouse mechanisms involved with comfort, attachment, and sympathy. 
Certainly, it will not suffice for all purposes to think of the mind as simply a package of separate 
instinctive machines. But you must start somewhere - and if you demand too much from your first theory, 
you'll never get very far. Of course, the human mind is not simply a collection of separate specialists; 
that is merely a first- order version of a larger theory in which minds grow from such origins. We can 
develop that concept of personal growth by drawing upon another modem current in psychology. In the same 
era in which most American psychologists had gotten stuck with behavioristic concepts about simple conditioning, 
Jean Piaget and his associates in Geneva were developing more powerful ideas on how children develop, 
stage by stage, into much more sophisticated systems. How do our initial mental "proto-specialists" learn 
to participate in less fragmented kinds of compromise and cooperation? In the final sections of The Society 
of Mind, I propose a more detailed fantasy about how the human nervous system might grow through stages 
eventually to learn to interpret gestures in social terms. Suppose our movie's storyboard requires John 
to give Mary some flowers. How could we make a machine "understand" enough of this to render it acceptably? 
By finding ways to represent that action - where the plural is intentional. We all know how to render 
such an action in the physical realm - for example, in terms of a spatial trajectory in which the flowers 
travel from John's hand to Mary's hand. But we need other representations for expressing its meaning 
in other realms. To express an affectionate mood, those spatial trajectories must use certain types of 
envelopes; hostility requires other forms; and yet other envelopes are appropriate for actions expressing 
respect or reverence - in which John might bow rather than approach. Once equipped with a diverse enough 
variety of representations, our rendering system can modulate each output in accord with several different 
requirements - to interpret the same action in several different experiential realms at once. Animators 
have long understood that social and emotional aspects of trajectories can become so dominant that no 
viewer is disturbed when objects behave in physically impossible ways. Not only in gesture but also in 
words, and in the forms of the objects themselves, the use of multiple representations can permit our 
machines to exploit the power of metaphor, using the selfsame object, action, or structure of plot to 
express different messages at the same time. It almost seems a paradox: that an oversimplified theory 
of the mind as mainly made of separate parts allows one to start building up worlds of endless complexity. 
But you are far more likely to get stuck if you commit yourself, right from the start, to what at first 
may seem to be more humanistic, less mechanical schemes -because models that have no separate parts provide 
no materials that you can manipulate, combine, or develop in different ways. Once you find the freedom 
that comes from using complex reductionist points of view, you can never retum to simplistic acceptance 
of person as thing. Like forbidden fruit, mechanistic analysis is food for ideas that our culture forbids 
- and this is perhaps why it is equally denounced by both humanist and religious instructors. You've 
got to get your movie out, but you don't want to spend your life drawing objects in each frame. We've 
seen wonderful progress in recent years from making models of actors' brains. We see this in such production 
movies as Tron and The last Starfighter and at SIGGRAPH in Karl Sims' walking animals and Craig Reynolds' 
flying birds. No longer do we mindlessly interpolate key frames; we not only describe our actors' bodies 
and articulate their joints, but we're starting to draft designs for their minds. And now that we've 
set out along that path, we'll add more stuff to those primitive brains, provide them with better goals 
and smarter memories, and make them more able to learn - perhaps to join the audience. Eventually, instead 
of having to draw and program yourself, you'll be able to produce a show as directors do, by showing 
and telling the the actors what you want. We can't do much of that yet, today, because neither Artificial 
Intelligence or Psychology is advanced enough. But every member of SIGGRAPH can help, simply by trying 
from time to time to aim more directly toward high-level goals. ANDREW LIPPMAN: We have a little bit 
of time left for questions. Q: Forrest Gudlare, Ford Aerospace, Houston. Wonderful things you all are 
doing. Are any of these things you're doing going to be released to,the public domain? And if so, how 
might one acquire them? MARVIN MINSKY: Everything my students do, practically, is public domain, but 
that's because they're almost useless for the next 17 years, so you can't patent it. ANDREW LIPPMAN: 
We have other reasons why some of the things the other students do are sometimes useless, or rendered 
so. They are mostly released in the form of theses and people rather than as packaged systems. Q: My 
name is Jeff Tanner of IntelliCorp. And I've noticed that there's a lot of good things coming out of 
MIT Media Lab. But how many artists are actually part of your program? And are artists actually directing 
what the new medias are going to be? A: Well, there isn't a simple answer to the question. Part of the 
answer is that many of our students at the laboratory are, in fact, artists who do art and also program 
and do research. We have in the laboratory students in my group (Computer Animation) who are exhibiting 
photographers and video artists, and so on. We have both kinds in the same person. Another part of the 
answer is that it varies with different groups. So, for example, the experimental music studio is quite 
used to inviting composers to come in and work with their systems. In my group, we're interested in programming 
dynamics, inverse kinematics, building rather large systems. So we're mostly interested in people who 
know how to program. Q: My name's Doug McKenna. This is directed to anybody and is prompted by a word 
that Waiter Bender used when he was referring to the smile detector. He said it was dangerous. I'm curious 
if there have been instances when you've experimented with new media, when you came up against some kind 
of ethical problems in using of the new media. WALTER BENDER: I'll start with an answer. I probably shouldn't 
have used that term, but I guess it got a question. We're trying to invent new degrees of freedom. We're 
trying to invent new ways of doing things and looking at things, and I don't think that the work we're 
doing implies that one would make systems in precisely that way. LIPPMAN: Just as printing implies plagiarism 
and image processing allows pictorial falsification, the technology in these cases carries no implicit 
ethics but the implementation does. While this is not always true of technology, it is true in our work 
and communications generally. A: I have a controversial answer to that. Which is, I think there ought 
to be a division of responsibility. There are all sorts of people who have feelings about ethics, and 
I feel that scientists aren't particularly good at that. In fact, I don't think anybody's particularly 
good at that. But that's another matter. So I like the idea that we invent new degrees of freedom and 
new devices and new ways to see where everybody is in the world all the time. And then there should be 
activist groups, graphics experts for social responsibility. And they should heckle us and try to get 
us to stop doing our research. I think if you try to get the people doing the research to think about 
the consequences of it, you will actually do net harm to the whole situation. Q: My name is Tony Ciccala. 
A lot of the technology that you show has been around for a long time. You've been working on these things 
for many years. And yet, we don't see a lot of the ideas in the marketplace. I'm wondering why things 
don't move more quickly into the marketplace, and I'm wondering whether it might have to do with acceptability 
or testing. Are people really happy to have this visual conferencing? Do you test these ideas in a usability-type 
arena? A: I think the answer is that it's just in the last two or three years that terrific graphics 
processors that can do all this stuff -- see, the stuff Andy and Walter were talking about took a lot 
of computers and a long time. And great graphics engines have reached the consumer market. They haven't 
quite reached it, have they. Well, I see the Atari's and Amega's are pretty capable, and machines that 
were a million dollars are not $30,000. So just wait a few minutes. A: There's another answer to that, 
also, in addition to the expense. Most of the things that we do, I guess as Walter said, are done in 
the nature of being a test, and they're not necessarily a compendium of features that you would want 
to embody in a particular product. They're supposed to exhibit a range and try to provoke the design 
of these kinds of products into other areas. And, to that extent, they actually do filter out into the 
design of products.  Q: When I was a kid, there was a practical joke which consisted of a fake fly imbedded 
in a plastic ice cube. I'm starting to feel that some of McCluhan's stuff is coming true, in that we 
are imbedded in this electronic matrix that not only checks who comes in the room and when but also, 
apparently, instructs our speakers to pick up their tempo. I think this is an excellent group to maybe 
expound a little on ff there's any cure for this problem. A: Well, you can pull the plug. Q: But we can't, 
because the plug is what allows us to communicate in an orderly fashion. A: In a lot of ways, one of 
the things that you've seen, or that we've tried to talk about, are systems where some agent of some 
kind -- in this case a computer -- tries to get to know you a little better. And it does that by looking 
at you or listening to you or receiving some inputs from you. And in that manner of getting to know you, 
tries to act a little bit on your behalf. Maybe not very expertly on your behalf yet, but certainly not 
subvertly. And, in fact, in most of the systems that we do, the fact that the machine is listening to 
you is well-known to you and you can use that as an input to it. In other words, you know when reading 
the electronic newspaper that by touching the screen and picking your way through articles, you're in 
effect telling it what articles you'd like to see amplified on more in future editions of the newspaper. 
So you can use that touch deliberately to kind of make those kinds of signals. I suppose there's a certain 
amount of strangeness in that kind of view because, in the end, what you're expecting the computer to 
evolve into is a brother or a wife or a sister or a very close friend. Now, those are the kinds of people 
to whom you occasional withhold things, but occasionally you're quite free with them. And they often 
do act on your behalf and they often act with you in a certain number of ways. And rather than see it 
as being a fly trapped inside of a matrix, I guess the question is really one of perspective. We see 
it as kind of the opposite: that these kinds of agencies can actually free us from the matrices that 
we're otherwise stuck with when you're given things in unresponsive manners. A: Well, I think it's just 
a matter for the laboratories of anti-media technology to worry about how to prevent communication. Q: 
My name's Tim Meyers from the University of Nebraska. And a previous question a few minutes ago, where 
you were saying that your tools aren't good enough is why you don't have very many artists currently 
working with you. And I think that's a mistake because your tools aren't going to be good enough until 
you get the people who are going to use them in working with you and developing them. Because there the 
people who are going to use them --it's severely retarding the development of the tools themselves by 
strictly putting technical people in there and saying, this is how we're going to do it. As the professor 
said, it's going from the bottom up. And it's not going to be as useful or as quickly developed as bringing 
in those people. They're used to using whatever they have at hand, however, difficult it is to use. ZELTZER: 
I said that there were a lot of answers to the question, and I didn't say any of the things that you 
just attributed to me. In the first place, I worked at Ohio State University in the computer graphics 
research group. And we worked --indeed, half of us were computer scientists and the other half were artists, 
and we had a very productive relationship between designers of software and users of software, and I 
think both communities learned a great deal from each other. I also said that many of my students were 
both artists and software developers and physicists. So I think in my own group, that I have both kinds 
of expertise. The reason I said that I thought the tools were too primitive, I felt that it wouldn't 
be fair to invite an outside artist to come and work in residence for some time. I think it's premature 
at the moment. But I don't think there's any lack of help with designing interfaces and user tools. Another 
point to be made is that the work that we're doing in graphics and animation we hope will be of use to 
artists at some point, but that's one piece of what graphics and animation is all about. I think it's 
a sub-set of the total uses which these kinds of animation tools. We're just as interested in getting 
engineers and scientists to use these smarter environments. I will say that, in terms of scientific visualization, 
Russell Kirsch, who's here today, told me some time ago that we have a lot of people around. In fact, 
the human race has been practicing the art of graphic communication for over 40,000 years. And, in terms 
of visualizing large amounts of data and phenomena, I think it's the graphic artists and the visual artists 
that have a lot to offer. I don't think we're quite as hostile to the arts as you seem to imply. Q: My 
name is J. C. Myda. I'm from GMS Technology in San Antonio, Texas. First of all, Mr. Minsky, I'm enjoying 
your book immensely. I'm in the middle of reading your book. I recommend it. I have a problem, however, 
with your top-down approach. I agree with top- down attack of a problem. But often times, I find that 
the top that I chose suddenly is not the top any more while I'm trying to go down. So I have to go up 
again. And how do I get out of such a dilemma? I haven't figured it out over the years. A: Well, I'm 
just worried that sometimes when people go on for many years without certain back-tracking and ask what 
problem was I really trying to solve. Computational linguistics, which probably doesn't bother most of 
you, bothers me a lot because people try to --in that field, there's been a lot of concern with the structure 
of language and the structure of grammar and so forth. And I talk to these people and most of them haven't 
thought -- since they were in grade school or college -- they haven't had that idea that language is 
a bunch of techniques by which the activities in one brain make something in the other brain. And I think 
that idea is in this book in some detail. But isn't it funny that such an idea should be new to people 
in linguistics? I talk to them and they say, oh, I never thought of it that way. And certainly any particular 
strategy you adopt has a 98% chance of being wrong because science is hard. But I was just saying a couple 
of weeks every year, you ought to sort of look at your calendar and say, have I done any high-level thinking 
this year? Q: I'm Orry Olebby from Georgia Tech. This is one of those top-down questions, I guess. And 
it comes in two parts: and the first one may be better directed towards Nicholas Negroponte, but since 
he's not here, I'll ask you guys. Given that the development that media technology is -- we accept it 
as a good thing and expect that maybe we'd like to see it proliferate, what would be the funding base 
that you would recommend looking to, to support the proliferation of educational and research centers 
for media technology? And the second half of that is what would be the national and international socio- 
economic trends that you would point to, to justify this development and proliferation as a good investment? 
A: Nicholas spends all his time, virtually, getting people to donate to this cause. I think a good deal 
of our laboratory's funded from people in Japan who share these visions. It's rather harder to get people 
here to do it. I guess I don't understand the last phrase about justifying it. There's no absolute justification 
for anything, and if you can get a lot of people to think it's good and pay for it, that's fine. A: 
There are probably 37 or 40 justifications for it who will mob you as you head towards the exit and, 
ff not, we'll inspire them to. But graduating some of the students is maybe one of the better socio-economic 
things we can do, and it's justification in its own fight, as far as I'm concerned. Probably should apply 
to the rest of you who are in school, as well.  Q: I just want to follow up on Marvin's comment on justification 
and the idea that if you can get enough people to pay for something, that justifies it. I just want to 
know does he feel that that, then, because they can get enough people to watch it, that justifies what's 
on television these days? A: It's your planet. ANDREW LIPPMAN: Okay, it's 5:00 o'clock and I think that 
gives us a good chance to stop. Thank you very much. i~lodle Labor,~lory Andrew Lippman Andrew Lippman 
  David Zeltzer MOD~L1NO BIIUAVIOll Compu~llUllll tikd~ ttcmiAi~, INmlAlUIIH IHdt~wl~, la otliulx4pd 
klJlrlreklil~ A# e4pINl'u Irel~rkl41m M ~ IkllJa ~lsd llle|m Ini41roonn4~ll~ul d4tllla l;u r~np ~r kkAv~'t 
 David Zeltze David Zeltzer  Walter Bend~ Wal{er Bender  Hardware Strategies for Hardware Strategies 
fo~ Scientific Visualization ScientificVisualization PANE[ INTRODUCTION PANEL IN]RODUCTION Robert Haber 
			