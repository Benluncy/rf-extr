
 Wide Format Floating-Point Math Libraries Victoria Markstein Peter Markstein Tung ISQUARE, Inc. IBM 
Advanced Austin, TX 78759 Austin, Abstract Math libraries are considered an extension of the hardware, 
providing common mathematical functions not supplied in hardware. Users expect these func­tions to be 
as accurate as the basic machine instruc­tions, whether or not these expectations are always justified. 
Presented in this paper are the performance and accuracy evaluations of eleven transcendental func ­tionsfound 
in 64 and 128 bit floating -point formats in math libraries on the CRAY Y-MP, the IBM 3090EIVF, the Convex 
C-240, the Hewlett Packard 90001720 and the IBM System 16000. Both architecture and algo­rithms are shown 
to impact the results. Brief History of Floating-Point: Since the mid 1950 s, when floating-point hardware 
became available, many scientific and engineering calculations required greater precision than the hard­ 
ware naturally provided. Doubling the precision of the computation, achieved by simulation of higher-preci­ 
sion through software assistance, provided the additional precision needed to overcome the spurious behavior 
of roundoff occurring on extremely lengthy computations. The cost of doubled-precision compu­ tation 
is quite steep: 1) performance penalties range from slow down factors of 10 to over 100. 2) additional 
memory is needed to hold the extra bits of precision. 3) extra memory requirements and longer code cause 
more cache misses and page faults. Software simulation of doubled-precision was usu­ ally implemented 
as a collection of library routines. At first, high-level languages recognized only one floating-point 
data type, so that computation at doubled-precision could not be written in the familiar infix notation, 
but instead required all arithmetic op­ erations to be coded as function calls. Such doubled­ precision 
codes were not portable. Eventually high- Nguyen Steve Poole Workstation Div. IBM Data Systems Div. TX 
78758 Kinsgton, NY 12401 Ievel languages recognized wide precision formats, and this eased the burden 
of the user who required the additional precision. However, the library routines that implemented the 
double width functions were not conveniently expressible in languages like FORTRAN, and had to be written 
in assembler language. Early machines which supported floating-point car­ried 27 bits of fraction, and 
that width (plus or minus a few bits) became known as single-precision float­ing-point representation. 
Fraction widths of 48 to 60 bits became known as double-precision floating­point representation, and 
widths from 96 to 120 bits became known as quad-precision , but this nomen­clature is not universal. 
In this discussion, we will use the term working precision or WP to mean the longest format of floating-point 
numbers supported conveniently by hardware on a computer, and doubled­preclsion or DP to denote the floating-point 
format of approximately twice the precision of WP. [1] Along with the ability to perform the basic opera­tions 
of addition, subtraction, multiplication and divi­sion in doubled-precision, software support for the 
common mathematical routines is required. Creating a library of doubled-precision routines is challenging, 
since the goal is to compute these functions to about twice the working precision, and at the same time, 
nol to introduce slowdown factors even greater than those caused by the use of doubled-precision arithmetic 
operations. Since functions such as exp(x) or sin(x) are usually computed by polynomial or rational ap­proximation, 
to compute to twice the precision re­quires longer approximating polynomials, which in turn, tends to 
aggravate the slowdown due to doubled precision arithmetic operations. At the same time, one would expect 
these routines to be accurate almost to the last bit, because, in the event of numerical difficulties, 
it is usually unprofitable to speculate on the libraries accuracy much as it is unwise to specu­late 
about hardware malfunction. Later architectures supported both single and double­precision floating-point 
computation directly. CI 1991 ACM 0-89791-459-7/ 91/0130 $01.50 Because double-precision arithmetic 
was supported by hardware, the time penalties for its use dropped to a factor of 2 or less. Computers 
with 32 bit words adopted a representation of single-precision with only 21-25 bits of precision. This 
loss of up to 2 decimal digits of precision compared to the 27-bit mantissa, forced many calculations 
to use double-precision. Fortunately, however, the hardware support for double­precision made the performance 
degradation small. On top-of-the-line machines, the hardware was biased to support double-precision arithmetic, 
even to the extent of making it faster than single-precision! Float­ing-point formats with 48-64 bits 
have become the working precision of all modern computers. At first, the demand for doubled-precision 
calcula­tion was slight, but by the early 1970 s, several sys­tems supported DP, usually by software. 
If high­precision was all that was wanted, then certainly there have been programming environments capable 
of sup­porting this need: Macsyma, Mathematical, and sev­eral other specialized programs. However, the 
need to provide extended precision must be met with an ac­ceptable level of performance.  Hardware Descriptions: 
We examine several contemporary computers which support doubled-precision arithmetic, and evaluate the 
mathematics libraries which support it, from both performance and accuracy perspectives. These ma­chines 
are the Cray Y-MP , Convex C-240b, IBM System 370 3090E/VP, the Hewlett Packard HP 9000/720 and the IBM 
RISC System/6000 which will be respec­tively referred to as Y-MP, C-240, 3090, HP/720 and RS/6000 in 
this discussion. Of the five machines in this study, only the 3090 supports doubled-precision in hardware: 
addition, subtraction, and multiplication are performed com­pletely in hardware at about 1/40 the speed 
of working precision. The 3090 s DP is correctly truncated at the 28th hex fraction digit, in keeping 
with the IBM hex floating-point format. While WP is supported in sca­lar and vector mode, DP is supported 
only in scalar mode. The other four machines depend entirely on soft­ ware support for doubled-precision 
support. The Cray Y-MP is a 6ns vector computer. Each processor consists of operating registers and func­ 
tional units associated with three types of processing: address, scalar and vector. There is not a separate 
scalar functional unit. Thus, vector operations cannot Cray Y-MP is a trademark of Cray Research Inc. 
b Convex C-240 IS a trademark of Convex Computer Inc. c IBM System/370 3090E/VF and IBM RISC System/6000 
are trademarks of International Business .Machmes, Inc. ~ HP 9000/720 M a trademark of the Hewlett Packard 
Corporation. be overlapped with scalar operations. The Y-MP s computational section is also capable of 
pipelining load/store, floating-point operations (add, subtract, multiply, and reciprocal approximation) 
and produce a result every cycle. Data flow in a computational section is from memory to registers and 
from registers to functional units. Result data flows from the func­tional units to registers and from 
registers to memory, or back to the functional units. The Y-MP can perform 2 vector loads and 1 vector 
store simultaneously, or deliver 24 bytes every cycle for a peak memory band­width of 4 Gbytes/sec. and 
has a peak floating-point performance is 333.33 Mflops. The Y-MP provides support for doubled-precision 
floating-point via software. The DP format consists of 1 sign bit followed by 15 bits of exponents and 
96 bits of fraction. The range for doubled-precision data is between 10-2466through 102465.Performance 
is achieved by vectorizing loops with intrinsic functions by seg­menting the loop range into segments 
and taking ad­vantage of the pipeline architecture to combine load/ store floating-point operations to 
improve the perfor­mance. Figure 1. illustrates how a vector function may be implemented on a vector 
machine. [9,10] fen(x) = (ax + b)x x is a constant I Scalar Time 1 Vector Time fen(x) Issue Exec. Comp. 
Issue Exec. Chairs Comp loadao 1 130 1 1375 loadb 1 214 1 21476 t=x*a 14 15 19 2 1520 82 u=t+b 202124 
3 212587 V=U*X 25 26 30 4 88 93156 storev 31 32 44 5 94 106 168 Fig. 1 Add m 5 Cycles . Multlply IS 6 
Cycles 1 Scalar result m 44 Cycles 1 Vector of 64 results m 168 Cycles Assumptions: Load/Store time is 
14 Cycles (2.6 cycleshesult) The Convex C-240 is a 40ns computer with vector processor(s). Each vector 
processor is capable of pipelining memory load/store, add/subtract, multiply/ divide and produces a result 
every cycle. Vector operations can also be overlapped with scalar opera­tions. The memory bandwidth is 
200 Mbytes. and the peak floating-point performance is 50 Mflops. The C-240 software supports 32 bits 
and 64 bits in IEEE 754 format. However, the hardware and run-time li­ brary do not conform to the IEEE 
Standard 754 [2] for arithmetic. The processor neither supports the com­plete floating-point arithmetic, 
nor the conversion and the exception handling as specified by the IEEE standard. Furthermore, the C-240 
uses a single round­ing algorithm which is also not consistent with the default rounding method or the 
directed methods speci­fied by the IEEE standard. The C-240 provides support for doubled-precision floating-point 
via software. [6,7,8] Doubled-preci­sion floating-point data (128 bits) is represented in an IEEE double 
extended format and consists of 1 sign bit fol­lowed by 15 bits of exponents and 113 bits of fraction 
(the leading fraction bit is implicit). The DP range is between 8.4 x 104 33 through 5.95x 104 3*. The 
HP 9000/720 is a 20ns scalar computer which supports IEEE double-precision arithmetic in hard­ware. The 
HP/720 s WP floating add takes 2 cycles, and WP multiplication requires 3 cycles. However, a multiplication 
and addition may be started every other cycle. The HP/720 is the only machine in this study to support 
square root in hardware. DP arithmetic, using a 15 bit exponent field and 113 bit mantissa, is sup­ ported 
by software. The RS/6000 architecture has been discussed ex­tensively in the open literature. [1 1,12] 
Its working precision conforms to IEEE double precision arith­metic. Its doubled-precision floating-point 
is sup­ported in software and is represented by two IEEE double-precision numbers, where the second is 
so small that, when added to the first, results in the first number. Since each number contains 53 bits 
of frac­tion, and IEEE numbers are always normalized, a quad-precision number carries at least 107 bits 
of precision in round-to-nearest mode. Doubled-preci­sion addition and subtraction require about 35 cycles, 
multiplication 10 cycles, and 50 cycles for division. The doubled-precision results, however, sometimes 
show a one-ulp error (error in the 107th place.) [11,12] Testing Methodology: We tested the following 
common functions on all the machines: square root, exponential, natural loga­rithm, sine, cosine, tangent, 
arc sine, arc cosine, arc tangent, atan2 (arc tan (y/x), given x and y, with principal value in the range 
[-n, n]), and power (xY). We ran two series of tests: one to determine the speed of the routines, and 
the other to gather results from the library routines using uniformly spaced arguments in order to determine 
precision. We did not test for robustness, that is, known pathological arguments were not used, nor did 
we test the error handling capabilities of the routines. In the performance tests, we wanted to determine 
not only the absolute running times for the routines, but the times in terms of machine clock cycles. 
Using the machine clock cycle factors out the effects of hard­ware technology and emphasizes hardware 
architec­tures. Furthermore, by quoting times in cycles, actual timings can be deduced for all members 
of a scalable family (such as 3090, RS/6000 and HP 9000/700), For both WP and DP, we first timed a loop 
which called the null function, so that we could remove from our timings the loop closing and subroutine 
linkage over­heads. We then timed a second loop, which called the desired function, and subtracted from 
that time, the time to run the first loop. That difference was divided by the number of times the function 
was called to arrive at the time for one execution of the function. Each such test was repeated 10 times, 
and the mini­mum time selected (to factor out any spurious effects of interrupts caused by other activities 
on the test machine). Since the library routines often use somewhat dif­ferent approaches over portions 
of the valid argument range, we selected 10 arguments for each routine in order to observe the timings 
over argument ranges where the computational techniques might be differ- Argument Values For Performance 
Measurements SQRT x = { 0.0, 0.03125, 0.0625, 0.6249999999999, 0.75, 875.0000000000, 9375.0, 10828567056280801.0, 
0828567056280800.0, 1.0) EXP: x = ( ().(), 0.03125, 0.5, 0.625, 0.6931471805599453094172321214581765680, 
13.86294361119890618834464242916353136151, 0,9375, -4.5, 10,0, -1) LOG: x = ( ().03125, 0.5, 0.75, 1.0, 
2.0, 2.718281828459045235360287471352662497757, 27182818284590 .45235360287471352662497757, 0.00000000096875, 
0.99999999, 1.0Q37 } POWER(XY): x = { ().5, 0.05, 1.0, 20.0} Y = { 0.096875, 1.0, 2.0, 40.0) SIN, COS, 
TAN: x = { ().0> -0.03125, 0.5, 1.625, 2.75, 30.875,  0.785398163397448309615660845819875721049, -1.570796326794896619231321691639751442, 
314.1592653589793238462643383279502, -1.0) ASIN: x = ( 0.0, 0.03125, 0.25, 0.5, 0.75, 0.875, 0.9375, 
-0.96875, 0.99999999, -1.0} ACOS: x = { 0.0, 0.03125, 0.5, 0.625, 0.75, 0.875> 0.9375, 0.96875, 0.99999999, 
-1.0) ATAN: x = ( ().0, -0.03125, 0.5, 0.625, 1.0, 1.75, 2.875, 4.9375, 8.9685, 100.0) ARG(x,y)=ATAN2( 
y,x): x = { 0.5, 0!05, 1.0, 20,0] y = { 0.096875, 1.0, 2.0, 40.0) . Fig. 2 ertt, as shown in figure 
2. For each function, we report the minimum and maximum observed times, as well as the arithmetic mean 
over all the arguments. For accuracy tests, we generated uniformly spaced arguments over a representative 
interval for each func­tion, as shown in figure 3. Argument Values For Accuracy Measurements SQRT x = 
0(0.1)99.9+ EXP: x = 5(0.01)4.99 LOG: x = 0.0001(0.01)9.9901 x = 0.01(0.733)21.267  Pow: y = 6(1.4 
)34.6 { SIN, COS, TAN: X = 0.0001(0.1)99.9001 ASIN: X = 1(0.002)0.998 ACOS : x = 1(0.002)0.998 = 0.001(0.002)0.999 
TAN: 1/; = 0.001(0.002)0.999 { X = 6(0.4) 5.6 ARG: y = -5(0.33)4.57 { Fig. 3 ~ The notation x=m(h)n denotes 
that x takes on values between x=m and x=n, inclusive, at increments of h units. The function was then 
evaluated both in working and doubled-precision, and we captured the argu­ments and results in hexadecimal. 
For each test machine s representation, the numbers were converted to a floating big-num (arbitrary precision 
floating­point) format, in which the computations could be carried out with sufficient precision. Since 
each ma­chine carried a different word-length, we report the errors in terms of ulps. An ulp (unit in 
the last place) is defined to be the difference between the absolute value of a number, and the next 
larger representable floating-point number. For doubled-precision on the 3090, an ulp varies between 
2- 08 and 2- 2 because the machine computes in hexadecimal, on the Y-MP, a one-ulp error is a relative 
error between 2-95and 2-96,on the C-240 and the HP/720, which both use an extended IEEE representation, 
an ulp corresponds to a relative error between 2- 11and 2-1 2,and on the RS/6000, an ulp is based on 
a mantissa of 107 bits. In the accuracy tests for power, we were constrained to use small exponents so 
that our tests would run on all platforms. Thus, on machines other than the 3090, the power routine was 
not exercised near the overflow or underflow thresholds. Our trigonometric tests were made against big-num 
functions with a transcendental period. The 3090 results were obtained on an IBM 3090/VF Model 600E at 
the Dallas Engineering and Scientific Center, running AIX/370f using VS FORTRAN re­lease 2.5. The Cray 
Y-MP, at Los Alamos National Laboratory, ran under Unicos 5.1.9, with the CFT77e FORTRAN compiler, version 
4.0.3.8. The Convex benchmark was also run on a C-240 at Los Alamos running Convex OS release V.9.0, 
using the Convex FORTRAN compiler, release 6.1. The HP/720 results were obtained on a machine at Workstation 
Laboratories, Inc. in Humboldt, Arizona, using the HP/UX 8.01 Operating System and the version FOR-TRAN 
8.01 compiler. The RS/6000 benchmark was run on a Model 530 at IBM Advanced Workstation Division / Future 
Systems Technology Laboratory under AIXf version 3.1.2, using the XL FORTRANf version 2 compiler. The 
test programs are available via request to one of the authors at tung@futserv.austin. ibm.com. The test 
results are summarized in figures 4-7. Performance Evaluation: The 3090, the only machine in our test 
with hard­ware support for DP showed slowdowns in DP averag­ing 6.5. DP timings were unchanged in vector 
mode, while WP timings improved an average of 1.78, so that in vector mode, DP is 11.6 times slower than 
WP. With its hardware support for DP addition and subtraction, was second to the RS/6000 in reducing 
the slowdown due to DP. It was also second in yielding the fastest DP routines in cycles. In scalar mode, 
the Y-MP s doubled-precision aver­aged a slowdown factor of 26 compared to WP. As with the 3090, the 
inverse trigonometric functions showed the greatest slowdowns. In vector mode, WP and DP times improved 
dramatically. The vector WP cycle times were the lowest of all the machines in our test, however; the 
vector DP ran 67 times slower than WP. The C-240 S DP library, while supporting a 113 bit mantissa, degraded 
by a factor of 88.6 in execution time compared to WP. Interestingly, the exponential family of routines 
slowed by an average of only 13.0. Results of the vector cycle times did not differ greatly from scalar 
cycle times for the set of routines in our test suites. Cray Y-MP and Convex C-240 rely entirely on software 
for DP, as does the RS/6000. But the C-240 , CFT77 is a trademark of Cray Research Inc. f AIX, AIX/370, 
and XL FORTRAN are trademarks of Interna­ tional Business Machines, Inc. E HP/UX is a trademark of Hewlett 
Packard Corporation. 133 EXPONENTIAL AND RELATED FUNCTIONS Scalar Performance Measured in Cycle Times 
Machine CRAY Y-MP IBM 3090E/VF CONVEX C-240 HP 9000/720 IBM RS/6000 Cycle Time 6.0 ns 17.5 ns 40 ns 20ns 
40 ns Significant Bits 48 96 53 109.112 53 113 53 113 53 107 SQRT Min 207 1,180 53 80 49 285 10 135 
45 26 Max 207 1,351 166 592 49 787 10 2,186 46 87 Ave 207 1,313 137 494 49 680 10 1,538 46 81 EXP Min 
239 6,728 107 153 72 105 82 401 46 207 Max 252 7,560 173 1,194 94 2,276 189 14,046 53 242 Ave 249 7,316 
163 1,095 90 1,474 175 11,875 48 213 LOG Min 268 4,951 165 784 98 79 148 251 57 244 Max 268 8,107 191 
1,143 109 2,675 155 11,743 66 284 Ave 268 6,500 171 971 105 1,251 151 6,672 63 259 Pow Min 701 9,110 
314 1,493 438 151 120 471 65 73 Max 714 16,122 388 2,194 444 5,380 481 35,527 332 754 Ave 708 13,364 
339 1,852 441 2,027 385 16,054 200 541 VectorPerformance Measured in Cycle Times age factor of 10.7 in 
WP and 4.3 in DP. The HP/720 s DP library, also sup- SQRT Min 13 207 53 80 35 275 porting a 113 bit mantissa, 
slowed down Max 13 209 53 592 35 778 by a factor of 76 compared to its WP Ave 13 208 53 494 35 670 library. 
The HP/720 s ability to issue a EXP Min 21 1,703 50 153 66 103 multiply and an add as a single instruc­tion 
does not enable the low order bits Max 21 1,705 55 1,194 88 2,275 of a product to be extracted in only 
one Ave 21 1,703 51 1,095 83 1,470 additional instruction. Furthermore, the LOG Min 27 1,835 50 784 91 
77 HP/720, as well as the C-240, usesa DP format which is 7 bits wider than twice its WP fraction width. 
This makes it Max 27 1,843 186 1,143 102 2,697 Ave 27 1,838 98 971 99 1,249 difficult to use WP arithmetic 
to simu-Pow Min 55 3,593 118 1,493 432 95 late DP, or to compute to DP precision Max 55 3,601 474 2,194 
438 5,411 with only a few WP instructions. The HP/720 also recognized special Ave 55 3,597 230 1,852 
435 2,001 cases in its pow and arg routines, which Fig, 4 lead to low average times for these DP format 
does not lend itself well to the use of its WP functions. The HP/720 WP square root, supported by floating-point 
unit to perform arithmetic, The C-240 S a hardware instruction, was the fastest of all machines in doubled-precision 
pow routine did exceptionally well this test, but the DP square root was the slowest. in recognizing 
special cases exponents of 1 and 2, or Of the computers evaluated, the RS/6000 showed bases of 1, which 
led to a low average time for this the least slowdown between the WP and DP functions, function. On the 
other hand, its working-precision pow with DP 4.95 slower than WP. The DP trigonometric routine, seemed 
not to show any significant timing routines showed significantly more slowdown than differences for special 
arguments. The Cray Y-MP, the exponential functions, There are two anomalous whose WP arithmetic neither 
rounds to nearest, nor timings for arg and pow which are not much slower in truncates, makes it a difficult 
machine for which to DP than WP. However, the WP routines: atan, exp, construct doubled-precision arithmetic. 
Neverthe-and log seem to have good performance in WP. less, the Y-MP exploits the vector capability to 
great The RS/6000 s DP showed the least slowdown, even advantage, accelerating the Math library by an 
aver-though the WP routines, in cycles, were the fastest TRIGONOMETRIC FUNCTIONS Scalar Performance 
Measured in Cycle Times Machine CRAY Y-MP IBM 3090EJVF CONVEX C-240 HP 9000/720 IBM RS/6000 Cycle Time 
6.0 ns 17.5 ns 40 ns 20 ns 40 ns Significant Bits 48 96 53 109-112 53 113 53 113 53 107 SIN Min 246 4,664 
64 517 81 11,226 37 169 24 289 Max 263 5,235 290 1,128 106 14,941 126 21,526 41 355 Ave 256 5,018 140 
963 94 12,983 92 14,044 35 319 Cos Min 247 4,474 51 553 83 11,021 43 163 25 285 Max 270 5,354 243 1,113 
107 14,263 126 21,506 44 339 Ave 261 4,994 142 969 95 12,333 92 14,041 35 316 TAN Min 241 10,117 83 821 
161 22,515 96 207 38 321 Max 262 10,614 312 1,600 164 27,250 206 19,429 109 404 Ave 256 10,990 209 1,431 
163 24,935 166 12,881 76 365 ASIN Min 255 1,070 66 1,222 135 1,667 96 207 15 61 Max 501 11,640 153 2,450 
186 24,481 308 15,246 85 475 Ave 323 9,730 121 1,957 166 18,645 228 7,176 50 334 ACOS Min 258 2,183 63 
1,281 142 2,504 94 109 19 84 Max 508 11,824 155 2,394 191 24,709 308 17,071 90 477 Ave 331 10,640 124 
1,986 176 18,067 228 12,446 59 331 ATAN Min 230 1,094 72 572 82 14,240 110 757 33 225 Max 264 9,469 182 
1,379 124 19,181 213 12,872 72 312 Ave 247 8,504 152 1,182 104 17,135 187 7,195 55 278 ARG Min 276 9,154 
206 1,127 145 16,917 354 1,543 220 276 Max 278 9,495 270 1,728 177 20,554 394 15,101 410 457 Ave 277 
9,317 231 1,441 160 18,775 371 9,804 332 379 Fig. 5a the entire DP library in FORTRAN. Use of a high­ 
scalar routines in our test. The DP routines for the level programming language allowed a great deal 
of RS/6000, in cycles, were the lowest of all tested platforms. In absolute time, they outperformed all 
experimentation with computational techniques with­machines except the Cray Y-MP in vector mode, which 
out undue concern about timing. The compiler was trusted to exploit the hardware to the fullest. (The 
WP enjoys a 6.75 fold advantage in cycle time. The RS/6000 DP routines, written by one of the library 
was coded in C). authors (V. Markstein) achieves its speed by perform­ing almost all calculations in 
WP. When DP was Accuracy Evaluation: required, analysis showed that substantially shorter, Several authors 
[3,4,51 have commented that the less general in-line routines could be used instead of performance penalties 
to obtain greater precision are the DP arithmetic library routines for addition and not as severe as 
one might be led to believe. In some multiplication. A major factor in the RS/6000 s per-cases, the same 
techniques that increase speed also formance is the multiply-and-add instruction, which increase accuracy, 
The IBM 3090E/VF WP library, allows an exact product of two WP numbers to be and both RS/6000 libraries, 
use techniques which computed in only two instructions. have these properties. The RS/6000 libraries 
pro-Essentially, all RS/6000 DP calculations are per-duced no observed errors as great as one-ulp, nor 
did formed in floating-point. The RS/6000 s architecture, the 3090 E/VF WP library. The only 3090 DP 
routines which is compiler friendly, made it possible to write which did not meet a one-ulp error criterion 
were log, 135 TRIGONOMETRIC FUNCTIONS served duced rounding errors), some errors larger but pow pro­than 
108 ulps Vector Performance Measured b CycIe Times (the low order 27 bits of such results are in error). 
The trigonometric routines Machine CRAY Y-MP I IBM 3090E/VF :ONVEX C-240 [ keep errors within 2.35 ulps 
in WP, but Cycle Time 40 ns errors as large as 190 ulps were ob- Significant Bits 53 113 served in DP 
tan. The C-240 vector and SIN Min 74 11,165 scalar libraries produced bit-for-bit Max 33 1,147 332 1,128 
100 14,915 identical results. The RS/6000 again derives benefit Ed Ave 33 1,145 97 963 87 12,924 from 
its multiply-and-add instruction, Cos Min 33 1,145 54 553 76 10,921 which is accomplished with only one 
Max 33 1,146 298 1,113 101 14,265 rounding error. For expressions involv­ 33 Ave ing products which occur 
in numeri­ 33 1,145 94 969 88 cally sensitive portions of the library, TAN Min 24 2,436 96 821 157 22,639 
a the low order bits can be recovered in Max 25 2,438 305 1,600 160 27,649 only one fast instruction. 
On other ma-Ave 24 2,437 138 1,431 159 25,143 chines in our study, recovery is more expensive, requiring 
either a DP multi- ASIN Min 22 2,174 65 1,222 131 1,680 ply on the IBM System 3090E/VF, or Max 49 2,513 
152 2,450 182 24,178 multiple precision fixed-point arith-Ave 33 2,209 120 1,957 162 18,590 metic on 
the other platforms. The alter- ACOS Min native is to accept accuracy degrada­ 23 2,173 61 1,281 J= 
E=-l tion, which, once allowed, is difficult Max 49 2,510 153 2,394 to control in subsequent computations. 
Ave 34 2,208 122 1,986 171 17,968 Except for square root, we found er-ATAN Min 24 1,787 55 572 75 14,174 
rors in excess of one-ulp in all the HP/720 s library routines. In WP, er- Max 24 1,789 124 1,379 117 
19,142 rors were kept less than 2.3 ulps, ex- Ave 24 1,788 91 1,182 98 17,098 cept for pow, where a 176 
ulp error was ARG Min 28 1,792 107 1,127 141 16,958 observed. In DP, the HP/720 s largest errors were 
also observed to be less Max 28 1,796 381 1,728 174 20,647 than 2.35 ulps (DP pow had a maxi- Ave 28 
1,793 190 1,441 %156 18.806 mum error of 1.84 ulps), except for Fig. 5b aces and atan which had errors 
in ex ­arg and pow. Vector and scalar libraries for the 3090 cess of 101s ulps (such results are only 
a few bits more produced bit-for-bit identical results. accurate than WP). Cray Y-MP WP routines produced 
the lowest frac-Even if it is necessary to resort to fixed point com­tion of correctly rounded results. 
The WP library putation to obtain sufficient precision, its judicious keeps errors below 4.25 ulps, except 
pow, for which a use can control error propagation without undue per­217 ulp error was observed. If pow 
is constructed formance loss. from log and exp, this is not surprising, since those Without the availability 
of source code, other than routines were observed to produce errors of 4.24 ulps for the RS/6000, it 
was not possible to ascertain the and 2.40 ulps, respectively. causes of large errors observed. Such 
discrepancies The Cray Y-MP DP library produced large errors for sin, can usually be attributed to errors 
in the DP arithmetic cos and tan, with 13 bits of precision being lost at times. routines, or insufficient 
analysis. For example, to log produced errors as large as 9,347 ulps (for an evaluate tan-l (a+x) when 
x<<a, one might use: argument close to 1). Surprisingly, however, the larg­est error observed in pow 
was only 181 ulps! As in the tart-l(a+x) = tan-la + A + 0(x2) case of the 3090, the Y-MP vector and scalar 
libraries l+a2 produced bit-for-bit identical results. For a< 1, it might be tempting to try: Convex 
C-240 sqrt, exp and log routines meet one­tan-l(a+x) = tan-la + x ulp requirements in DP (sqrt and log 
made no ob­However, these approximations would not yield re­sults acceptable in DP unless l-+a rounds 
to 1 in WP. EXPONENTIAL AND RELATED FUNCTIONS Precision Measured h Ulps Machine Cycle Time Mode I CRAY 
Y-MP 6.0 ns Scalar* I IBM3090E/VF 17.5 ns Scalar* I CONVEX C-240 40 ns Scalar* HP 9000/720 20 ns Scalar 
I IBM RS/6000 40 ns Scalar Simificant Bits 48 96 53-56 SQRT %Rounded Correctly 79.0 68.9 100 9. Error< 
1 ulp 99.2 95.6 100 Max Error (ulps) 1.12 2.71 0.50 EXP 7. Rounded Correctly 26.4 33.5 99.6 % Error< 
1 ulp 47.5 74.4 100 Max Error (ulps) 4.24 3.75 0.50 LOG %Rounded Corrwtly 35.8 45.3 96.7 %Error<l ulp 
69.9 75.5 100 Max Error (ulps) 2.40 9347.0 0.55 Pow % Rounded Correctly 3.9 4.9 96.5 9. Error< 1 ulp 
8.0 8.2 100 Max Error (ulps) 217.0 181.0 0.54 * Same accuracy in vector mode Conclusions: What is most 
often needed by the large majority of numerical calculations is a few more bits of precision in certain 
critical parts of the computations. These extra bits must be completely accurate and not cause severe 
perfor­mance penalties. Furthermore, since the accuracy criti­cal portion of a computation may itself 
involve mil­lions of operations, the sharper the error bound on an individual DP operation or function, 
the sharper the error bound on the entire calculation. Ultimately, it is hoped that computer manufacturers 
will be persuaded to provide high performing DP hardware as well as an arbitrary floating-point precision 
facility. In our study of DP math libraries, architecture plays an important role in the implementation 
of fast, accu­rate library routines. The RISC System/6000 has a multiply-and-add instruction which allows 
DP results to be generated with WP instructions conveniently and efficiently. The library implementor 
could decide to what degree of faithfulness each DP operation needs to be calculated, based on how the 
result of the operation is to be used later in the computation. For the IBM System 3090 E/VF, the hardware 
doubled­precision arithmetic, though relatively slow, allowed a mixture of WP and DP operations to be 
conveniently 109-112 53 113 53 1 113 53 99.9 86.0 100 100 100 100 100 100 100 100 I1 100 I 100 0.52 
0.75 0.50 0.5 I 0.5 I 0.50 93.9 82.9 67.6 85.7 56.9 99.8 100 99.5 100 99.6 90.3 100 0.69 1.38 0.90 1.20 
I 1.83 I 0.50 18.4 89.0 100 89.3 62.5 98.6 100 98.6 11.26 1.47 0.50 1.47 89.5 72.2 12.2 96.2 88.7 16.3 
84.0 2.94 1X108 I 88.4 I 100 I 100.0 I 100 I 0.92 I 0.50 I 107 100 I 100 I I 0.50 99.6 100 I 0.51 I 
99.9 100 I I 0.51 Fig. 6 expressed. The other platforms require either the use of DP basic arithmetic 
routines, or other more circumlocuitous expressions of arithmetic beyond WP. However, the underlying 
algorithms used in com­puting the elementary functions seem to be the crux of the issue. As was shown 
on the IBM RISC System/6000 [3,4,5], these techniques lead to fast and accurate libraries. If these techniques 
are implemented on a less floating-point friendly architecture, the task becomes more laborious, but 
it reasonable performance and the skill and determination are applied. We anticipate reporting on the 
accuracy of several numerically tions in a future paper. Acknowledgments: Special thanks are due to Professor 
can be done with same accuracy, if performance and intensive applica- W. Kahan, Com­ puter Science Department, 
University of California at Berkeley, who offered early, valuable advice on algo­rithms for the IBM RISC 
System/6000 s quad-preci­ sion library. The tests on the Cray and Convex ma­ chines were performed at 
the Los Alamos National Laboratory, through the assistance of Andrew B. White, Director of Advanced 
Computing Laboratory, and John Morrison, Group Leader, C-5. The tests on the HP 9000/720 were performed 
at Workstation Labo­ratories, Inc., by David Wilson. 137 TRIGONOMETRIC FUNCTIONS  Precision Measured 
in Ulps Machine CRAY Y-MP IBM 3090E/VF CONVEX C-240 HP 9000/720 IBM RS/6000 Cycle Time 6.0 ns 17.5 ns 
40 ns 20 ns 40 ns Mode Scalar Scalar* Scalar Scalar Scalar Significant Bits 48 96 .53-56 109-112 53 113 
53 113 S3 107 SIN %Rounded Correctly 59.6 4.4 97.2 31.0 70.1 63.8 73.8 46.7 86.7 99.8 % Error< 1 ulp 
90.2 8.8 100 74.8 94.8 93.5 96.6 78.7 100 100 :~::&#38;~;i*~(;~#&#38;: ;:2:.1%;+ ;:gglolj; :::@;$&#38;;jj 
; ::E?$l::: :I:j$s;k:: :yl.$y: ;I::i:.yll$ ;j;g,l$ : : Q,9L : %Q+%C: Cos 9%Rounded Correctly 59.2 4.5 
95.6 29.7 69.1 61.3 76.6 45.5 86.3 99.9 % Error< I ulp 92.5 9.1 100 74.4 95.2 75.1 96.5 78.2 100 100 
,,,­m:@i;~&#38;$ctz@$% $WWzz{ N*%lQ&#38; :;.;0;25:;:1 Wlligljl :+% 8$%; %2%s :; ?LT?22 ~ +0.$33 :: .::0;5 
3.+ : TAN % Rounded Correctly 34.0 0.3 96.8 34.6 58.0 41.4 70.2 52.5 99.9 99.8 % Error <1 ulp 63.0 0.6 
100 51.2 88.5 66.3 89.9 83.3 100 100 @$$@$ggQ<($$g ~3:,@g;: ggg$~ ~..&#38;o{j $$l;@@lj g;g.qfii Rl:q:lyi;: 
*@.@%: ::;%.$i 1{ : floisf : :: :%= ::: ASIN %Rounded Correctly 49.5 37.8 94.4 40.5 80.7 61.9 76.8 52.4 
99.1 98.6 %Error< 1 ulp 82.4 68.6 100 69.9 96.3 92.1 93.0 84.5 ,.. ,:.,. . , :,.,.,.,.,., ,..,... :m,iM$g,#*Ec+l$$) 
%g:g%: $@g+@ !lW?ti 3%23s: :.:WW. ti:?.09z : NI ;9W ACOS %Rounded Correctly 39.4 55.0 97.2 50.0 71.6 
58.3 73.0 36.8 % Error< 1 ulp 72.3 859 100 95.3 99.2 93.2 99.9 69.2 100 100 ,,.,,.. . ,,, , . . . ...,::,,,,,, 
,.... ...... . . . . . .. . ... . fi#,##~~E&#38;r(j~&#38;sfi : e~;<~~ ::3:TU : : S@&#38;% :;~.g:g$$l 
3$.$B #lzw ~:liQii; !&#38;*lQ!? ~:::Q.;$$ . : ..:O:$5:? ,,..,,!... .. . ... ... . . ATAN %Rounded Correctly 
41.9 51.2 96.8 62.5 77.1 70,2 49.7 64.7 100 99.9 % Error <1 ulp 809 84.1 100 94.5 96.8 96.6 84.4 92.3 
100 100 .... . .. ;;~;..?? ~ ;;) :2MQ: $$::6.Q;$: $jg+~ , :~;:fi~p,!: jjp:&#38;~, ,: ~:,4:, , ARG % 
Rounded Correctly 31.1 62.9 97.7 50.8 69.0 65.6 50.6 69.4 96.4 96.2 % Error< 1 ulp 66.7 84.1 100 84.9 
95.9 95.7 88.9 94.8 100 100 :::+?j fi$a#&#38;tugpsY: ~3,k6: $+p; j ~ti:$~ ;*;W:; jg;oqs :.$::~q: : ~&#38;,&#38;ti 
: :U:74 :: 0.99: ;0:49 * Same accuracy in vector mode Fig. 7 References: [1] Doubled-Precision IEEE 
Standard 754, Febru-[6] M. Chastain, G. Gostin, J. Mankovich, and S. ary 26, 1987, private communications 
of Pro-Wallach, The Convex C240 Architecture, Proc fessor W. Kahan, Electrical Engineering&#38; Com-Supercomputing, 
1988, IEEE Computer Soci­puter Science, University of California, Berke-ety, 1988, pp. 321-329. ley, 
CA 94720. [7] Convex Architecture Reference Manual, 3rd Edi­ [2] IEEE Standard for Binary Floating-Point 
Arith-tion, October 1988, Convex Computer Corporation. metic, ANSI/IEEE Standard 754-1985, Institute 
[8] Convex FORTRAN User s Guide, 8th Edition, of Electrical and Electronic Engineerings, New October 
1988, Convex Computer Corporation. York, 1985. [9] Cray Programmer s Reference Manual, SR­ [3] R.C. Agarwal, 
et al. New Scalar and Vector 0113, 1986, Cray Research, Inc. Elementary Functions for the IBM Sys~em 
1370. [10] M.L. Simmons, H.J. Wasserman, Los Alamos IBM Journal of Research and Development, National 
Laboratory Computer Benchmarking 30,2 (March 1986), 126-144. 1988, Los Alamos national Laboratory Report 
[4 S. Gal and, B. Bachelis, An Accurate Elemen-LA-1 1465-MS, December 1988. tary Mathematical Libra ryfor 
the IEEE Float-[11 IBMRISC System16000 Processor, IBM Journal ing-Point Standard, IBM Technical Report 
of Research and Development, 34,1 1990. 88,233, IBM Israel, Technion City, Haifa, Is-[12 M.L. Simmons, 
H.J. Wasserman, Performance rael, 1988. Evaluation of the IBMRISC System/6000: Com­ [5 P. Marks tein, 
Computation of Elementary Func-parison of an Optimized Scalar Processor with tions on the IBM RISC System 
J6000 Processor, Two Vector Processors, Proc. Supercomputing IBM Journal of Research and Development, 
34,1 90, Nov 12-16, 1990, pp. 132-141, IEEE Com­1990, 111-119. puter Society Press. 
			