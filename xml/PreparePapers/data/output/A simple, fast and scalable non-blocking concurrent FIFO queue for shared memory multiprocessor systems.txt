
 A Simple, Fast and Scalable Non-Blocking Concurrent . FIFO Queue for Shared Memory Multiprocessor Systems 
Philippas Tsigas Department of Computing Science Chalmers University of Technology SE-412 96 Göteborg,Sweden 
 tsigas@cs.chalmers.se Some text in this electronic article is rendered in Type 3 or bitmapped fonts, 
and may display poorly on screen in Adobe Acrobat v. 4.0 and later. However, printouts of this file are 
unaffected by this problem. We recommend that you print the file for best legibility. Yi Zhang Department 
of Computing Science Chalmers University of Technology SE-412 96 Göteborg,Sweden  yzhang@cs.chalmers.se 
ABSTRACT Anon-blockingFIFOqueuealgorithmformultiprocessor sharedmemorysystemsispresentedinthispaper.Theal­gorithmisverysimple,fastandscalesverywellinboth 
symmetricandnon-symmetricmultiprocessorsharedmem-orysystems.Experimentsona64-nodeSUNEnterprise 10000;asymmetricmultiprocessorsystem;andona 
64-nodeSGIOrigin2000;acachecoherentnonuniform memoryaccessmultiprocessorsystem;indicatethatour algorithmconsiderablyoutperformsthebestoftheknown 
alternativesinbothmultiprocessorsinanylevelofmultipro­gramming.Thisworkintroducestwonew,simplealgorith­micmechanisms.Thefrstlowersthecontentiontokeyvari­ablesusedbytheconcurrentenqueueand/ordequeueoper­ationswhichconsequentlyresultsinthegoodperformance 
ofthealgorithm,theseconddealswiththepointerrecycling problem,aninconsistencyproblemthatallnon-blockingal­gorithmsbasedonthecompare-and-swapsynchronisation 
primitivehavetoaddress.Inourconstructionweselected tousecompare-and-swapsincecompare-and-swapisan atomicprimitivethatscaleswellundercontentionandei­therissupportedbymodernmultiprocessorsorcanbeim­plementedefcientlyonthem. 
 1. INTRODUCTION ConcurrentFIFOqueuedatastructuresarefundamental datastructuresusedinmanyapplications,algorithmsand 
operatingsystemsformultiprocessorsystems.Toprotect theintegrityofthesharedqueue,concurrentoperationsthat 
havebeencreatedeitherbyaparallelapplicationorby theoperatingsystemhavetobesynchronised.Typically, algorithmsforconcurrentdatastructures,includingFIFO 
.Thisworkispartiallysupportedby:i)thenational SwedishReal-TimeSystemsresearchinitiativeARTES (www.artes.uu.se)supportedbytheSwedishFoundationfor 
StrategicResearchandii)theSwedishResearchCouncilfor EngineeringSciences. Permission to make digital or 
hard copies of part or all of this work or personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. SPAA 01 Crete, Greece &#38;#169; 
2001 ACM ISBN 1-58113-409-6/01/07 $5.00 queues,usesomeformofmutualexclusion(locking)tosyn­chroniseconcurrentoperations.Mutualexclusionprotects 
theconsistencyoftheconcurrentdatastructurebyallowing onlyoneprocess(theholderofthelockofthedatastruc­ture)atatimetoaccessthedatastructureandbyblock­ingalltheotherprocessesthattrytoaccesstheconcurrent 
datastructureatthesametime.Mutualexclusionand,in general,solutionsthatintroduceblockingarepenalisedby 
lockingthatintroducespriorityinversion,deadlockscenarios andperformancebottlenecks.Thetimethataprocesscan 
spendblockedwhilewaitingtogetaccesstothecriticalsec­tioncanformasubstantialpartofthealgorithmexecution 
time[5,9,10,14].Therearetwomainreasonsthatlocking issoexpensive.Thefrstreasonistheconvoyingefectthat 
blockingsynchronisationsufersfrom:ifaprocessholding thelockispreempted,anyotherprocesswaitingforthelock 
isunabletoperformanyusefulworkuntiltheprocessthat holdthelocksisscheduled.Whenwetakingintoaccount thatthemultiprocessorrunningourprogramisusedina 
multiprogrammingenvironment,convoyingefectscanbe­comeserious.Thesecondisthatlockingtendstoproducea largeamountofmemoryandinterconnectionnetworkcon­tention,locksbecomehotmemoryspots.Researchersinthe 
feldfrstdesigneddiferentlockimplementationsthatlower thecontentionwhenthesystemisinahighcongestionsitu­ation,andtheygivediferentexecutiontimesunderdiferent 
contentioninstances.Butontheotherhandtheoverhead duetoblockingremained.Toaddresstheproblemsthat arisefromblockingresearchershaveproposednon-blocking 
implementationsofshareddatastructures.Non-blocking implementationofshareddataobjectsisanewalterna­tiveapproachtotheproblemofdesigningscalableshared 
dataobjectsformultiprocessorsystems.Non-blockingim­plementationsallowmultipletaskstoaccessasharedobject 
atthesametime,butwithoutenforcingmutualexclusion toaccomplishthis.Sinceinnon-blockingimplementations 
ofshareddatastructuresoneprocessisnotallowedtoblock anotherprocess,non-blockingshareddatastructureshave 
thefollowingsignifcantadvantagesoverlock-basedones: 1.theyavoidlockconvoysandcontentionpoints(locks). 
2.theyprovidehighfaulttolerance(processorfailures willnevercorruptshareddataobjects)andeliminates deadlockscenarios,wherewtoormoretasksarewait­ingforlocksheldbytheother. 
3.theydonotgivepriorityinversionscenarios.  (a)Thearchitec­tureoftheSUNEn­terprise10000 (b)ThearchitectureoftheOri­gin2000 
 Figure1:Architectures Amongalltheinnovativearchitecturesformultiprocessor systemsthathavebeenproposedthelastfortyyearsshared 
memorymultiprocessorarchitecturesaregainingacentral placeinhighperformancecomputing.Overthelastdecade 
manysharedmemorymultiprocessorshavebeenbuiltand almostallmajorcomputervendorsdevelopandofershared memorymultiprocessorsystemsnowadays.Therearetwo 
mainclassesofsharedmemorymultiprocessors:theCache­CoherentNonuniformMemoryAccessmultiprocessors(cc­NUMA)andthesymmetricorUniformMemoryAccess(UMA) 
multiprocessors,theirdiferencescomingfromthearchitec­turalphilosophytheyarebasedon.Insymmetricshared 
memorymultiprocessorseveryprocessorhasitsowncache, andalltheprocessorsandmemorymodulesattachtothe sameinterconnect,whichisasharedbus.ccNUMAisarel­ativelynewsystemtopologythatisthefoundationfornext­generationsharedmemorymultiprocessorsystems.Asin 
UMAsystems,ccNUMAsystemsmaintainaunifed,global coherentmemoryandallresourcesaremanagedbyasin­glecopyoftheoperatingsystem.Ahardware-basedcache 
coherencyschemeensuresthatdataheldinmemoryiscon­sistentonasystem-widebasis.Incontrasttosymmetric sharedmemorymultiprocessorsystemsinwhichallmemory 
accessesareequalinlatency,inccNUMAsystems,mem­orylatenciesarenotallequal,oruniform(hence,thename -Non-UniformMemoryAccess).Accessestomemoryad­dresseslocatedon"far"modulestakelongerthanthose 
madeto"local"memory. Thispaperaddressestheproblemofdesigningscalable,prac­ticalFIFOqueuesforsharedmemorymultiprocessorsys­tems.Firstwepresentanon-blockingFIFOqueuealgo­rithm.Thealgorithmisverysimple,italgorithmicallyim­plementstheFIFOqueueasacirculararrayandintroduces 
twonewalgorithmicmechanismsthatwebelievecanbe ofgeneraluseinthedesignofefcientnon-blockingalgo­rithmsformultiprocessorsystems.Thefrstmechanismre­strictscontentiontokeyvariablesgeneratedbyconcurrent 
enqueueand/ordequeueoperationsinlowlevels;contention tosharedvariablesdegradesperformancenotonlyinmem­orytankswherethevariablesarelocatedbutalsointhe 
processor-memoryinterconnectionnetwork.Thesecondal­gorithmicmechanismthatthispaperintroducesisamech­anismthatdealswiththepointerrecycling(alsoknownas 
 ABA)problem,aproblemthatallnon-blockingalgorithms basedonthecompare-and-swapprimitivehavetoaddress. 
Theperformanceimprovementsareduetothesetwomech­anismsandtoitssimplicitythatcomesfromthesimplic­ityandrichnessofthestructureofcirculararrays.We 
haveselectedtousethecompare-and-swapprimitivesince itscaleswellundercontentionandeitherissupportedby 
modernmultiprocessorsorcanbeimplementedefciently onthem.Last,weevaluatetheperformanceofouralgo­rithmona64-nodeSUNEnterprise10000multiprocessor 
anda64-nodeSGIOrigin2000.TheSUNsystemisaUni­formMemoryAccess(UMA)multiprocessorsystemwhile theSGIsystemisaCache-CoherentNonuniformMemory 
Access(ccNUMA)one;SUNEnterprise10000supportsthe compare-and-swapwhileSGIOrigin2000doesnot.Theex­perimentsclearlyindicatethatouralgorithmconsiderably 
outperformsthebestoftheknownalternativesinbothUMA andccNUMAmachineswithrespecttobothdedicatedand multiprogrammingworkloads.Second,theexperimentalre­sultsalsogiveabetterinsightintotheperformanceand 
scalabilityofnon-blockingalgorithmsinbothUMAand ccNUMAlargescalemultiprocessorswithrespecttoded­icatedandmultiprogrammingworkloads,andtheyconfrm 
thatnon-blockingalgorithmscanperformbetterthanblock­ingonbothUMAandccNUMAlargescalemultiprocessors, andthattheirperformanceandscalabilityincreasesasmul­tiprogrammingincreases. 
ConcurrentFIFOqueuedatastructuresarefundamental datastructuresusedinmanymultiprocessorprogramsand algorithmsand,ascanbeexpected,manyresearchershave 
proposednon-blockingimplementationsforthem.Lamport [6]introducedawait-freequeuethatdoesnotallowmore thanoneenqueueoperationordequeueoperationatatime. 
HerlihyandWingin[4]presentedanalgorithmforanon­blockinglinearFIFOqueuewhichrequiresaninfnitearray. Prakash,LeeandJohnsonin[11]presentedanon-blocking 
andlinearisablequeuealgorithmbasedonasingly-linked list.Stonedescribesanon-blockingalgorithmbasedona 
circularqueue.MassalinandPu[8]presentanon-blocking array-basedqueuewhichrequiresthedouble-compare-and­swapatomicprimitivethatisavailableonlyonsomemem-bersoftheMotorola68000familyofprocessors.Valoisin 
[12]presentsanon-blockingqueuealgorithmtogetherwith severalothernon-blockingdatastructures,hisqueueisan 
array-basedone.MichaelandScottin[10]presentedanon­blockingqueuebasedonasingly-linklist,whichisthemost 
efcientandscalablenon-blockingalgorithmcomparedwith theotheralgorithmsmentionedabove. Theremainderofthepaperisorganisedasfollows.InSec­tion2wegiveabriefintroductiontosharedmemorymulti­processors.Section3presentsouralgorithmtogetherwith 
aproofsketch.InSection4,theperformanceevaluation ofouralgorithmispresented.Thepaperconcludeswith Section5. 
 2. SHARED MEMORY MULTIPROCESSORS: ARCHITECTURE AND SYNCHRONIZA-TION Therearetwomainclassesofsharedmemorymultiprocessors; 
theCache-CoherentNonuniformMemoryAccess(ccNUMA) multiprocessorsandthesymmetricmultiprocessors.The mostfamiliardesignforsharedmemorymultiprocessorsys­temsisthe"fxedbus"orshared-busmultiprocessorsys­tem.Thebusisapath,sharedbyallprocessors,butus­ableonlybyoneatatimetohandletransfersfromCPU 
to/frommemory.Bycommunicatingonthebus,allCPUs shareallmemoryrequests,andcansynchronisetheirlocal cachememories.SuchsystemsincludetheSiliconGraphics 
Challenge/Onyxsystems,OCTANE,Sun'sEnterprise(300­6000),Digital's8400,andmanyothers-mostservervendors 
ofersuchsystems. CentralCrossbarMainframesandsupercomputershaveof­tenusedacrossbar"switch"tobuildsharedmultiprocessor 
systemswithhigherbandwidththanfeasiblewithbusses, wheretheswitchsupportsmultipleconcurrentpathstobe activeatonce.Suchsystemsincludemostmainframes,the 
CRAYT90,andSun'snewEnterprise10000;Figure1(a) graphicallydescribesthearchitectureofthenewSUNEn­terprise10000.Shared-busandcentralcrossbarsystemsare 
usuallycalledUMAs,orUniformMemoryAccesssystems, thatis,anyCPUisequallydistantintimefromallmemory locations.Uniformmemoryaccesssharedmemorymulti­processorsdominatetheservermarketandarebecoming 
morecommononthedesktop.Thepriceofthesesystems risequitefastasthenumberofprocessorsincreases. ccNUMAisarelativelynewsystemtopologythatisthe 
foundationformanynext-generationsharedmemorymulti­processorsystems.Basedon"commodity"processingmod­ulesandadistributed,butunifed,coherentmemory,cc-NUMAextendsthepowerandperformanceofsharedmem­orymultiprocessorsystemswhilepreservingthesharedmem­oryprogrammingmodel.AsinUMAsystems,ccNUMA 
systemsmaintainaunifed,globalcoherentmemoryand allresourcesaremanagedbyasinglecopyoftheoperat­ingsystem.Ahardware-basedcachecoherencyschemeen­suresthatdataheldinmemoryisconsistentonasystem­widebasis.I/Oandmemoryscalelinearlyasprocessing 
modulesareadded,andthereisnosinglebackplanebus. Thenodesareconnectedbyaninterconnect,whosespeed andnaturevarieswidely.Normally,thememory"near"a 
CPUcanbeaccessedfasterthanmemorylocationsthatare "furtheraway".Thisattributeleadstothe"Non"inNon­ LL(pi,O) 
{ Pset(O): Pset(O)[fpig returnvalue(O) } SC(piv O) { ifpi2Pset(O) value(O):=v Pset(O):=f returntrue else 
returnfalse } Figure2:Theload-linked/store-conditionalprimi­tive Uniform.ccNUMAsystemsincludetheConvexExemplar, 
SequentNUMA-Q,SiliconGraphics/CRAYS2MP(Origin andOnyx2).IntheSiliconGraphicsOrigin2000systema dual-processornodeisconnectedtoarouter.Therouters 
areconnectedwithafathypercubeinterconnect,Figure1(b) graphicallydescribesthearchitecture. ccNUMAsystemsareexpectedtobecomethedominantsys­temsonlargehighperformancesystemsoverthenextfew 
years.Thereasonsare:i)theyscaleuptoasmanyproces­sorsasneeded.b)theysupportthecache-coherentglobally addressablememorymodelc)theirentrylevelandincre­mentalcostsarerelativelylow. 
Awidelyavailablehardwaresynchronisationprimitivethat canbefoundonmanycommonarchitecturesiscompare-and­swap.Thecompare-and-swapprimitivetakesasarguments 
thepointertoamemorylocation,andoldandnewvalues. AsitcanbeseenfromFigure3thatdescribesthespecif­cationofthecompare-and-swapprimitive,itautomatically 
checksthecontentsofthememorylocationthatthepointer pointsto,andifitisequaltotheoldvalue,updatesthe pointertothenewvalue.Ineithercase,itreturnsaboolean 
valuethatindicateswhetherithassucceededornot.The IBMSystem370wasthefrstcomputersystemthatintro­ducedcompare-and-swap.SUNEnterprise10000isoneof 
thesystemsthatsupportthishardwareprimitive.Some newerarchitectures,SGIOrigin2000included,introduce theload-linked/store-conditionalinstructionwhichcan 
beimplementedbythecompare-and-swapprimitive.The load-linked/store-conditionaliscomprisedbytwosim­pleroperations,theload-linkedandthestore-conditional 
one.Theload-linkedloadsawordfromthememorytoa register.Thematchingstore-conditionalstoresbackpos­siblyanewvalueintothememoryword,unlessthevalue 
atthememorywordhasbeenmodifedinthemeantime byanotherprocess.Ifthewordhasnotbeenmodifed, thestoresucceedsanda1isreturned.Otherwisethe, 
store-conditionalfails,thememoryisnotmodifed,and a0isreturned.Thespecifcationofthisoperationisshown inFigure2.FormoreinformationontheSGIOrigin2000 
andtheSUNENTERPRISEthereaderisreferredto[7,2] and[1],respectively. Compare-and-Swap(int*mem,registerold,new) 
{ temp=*mem. if(temp==old){ *mem=new. new=old. }else new=*mem } Figure3:TheCompare-and-Swapprimitive 
Thecompare-and-swapprimitivethoughgivesrisetothe pointerrecycling(alsoknownasABA)problem.TheABA problemariseswhenaprocesspreadsthevalueAfroma 
sharedmemorylocation,computesanewvaluebasedonA, andusingcompare-and-swapupdatesthesamememorylo­cationaftercheckingthatthevalueinthismemorylocation 
isstillAandmistakenlyconcludingthattherewasnooper­ationthatchangedthevaluetothismemorylocationinthe meantime.Butbetweenthereadandthecompare-and-swap 
operation,otherprocessesmayhavechangedthecontextof thememorylocationfromAtoBandthenbacktoAagain. Inthisscenariothecompare-and-swapprimitivefailstode­tecttheexistenceofoperationsthatchangedthevalueof 
thememorylocation;inmanynon-blockingimplementa­tionsofshareddatastructuresthisissomethingthatwe wouldliketobeabletodetectwithouthavingtousethe 
read_modify_writeoperationthathasveryhighlatency andcreateshighcontention.Acommonsolutiontothe ABAproblemistosplitthesharedmemorylocationinto 
twoparts:apartforamodifcationcounterandapartfor thedata.Inthiswaywhenaprocessupdatesthememory location,italsoincrementsthecounterinthesameatomic 
operation.Thereareseveraldrawbacksofsuchasolution. Thefrstisthattherealword-lengthdecreasesasthecounter 
nowoccupiespartoftheword.Thesecondisthatwhenthe counterroundsthereisapossibilityfortheABAscenarioto occur,especiallyinsystemswithmany,andwithfastpro­cessorssuchasthesystemsthatwearestudying.Inthis 
paperwepresentanew,verysimpleefcienttechniqueto overcometheABAproblem;thetechniqueisdescribedin thenextsectiontogetherwiththealgorithm. 
Compare-and-Swap(int*mem,registerold,new) { do { temp=LL(mem). if(temp!=old)returnFALSE. }while(!SC(mem,new)). 
returnTRUE. } Figure4:Emulatingcompare-and-swapfrom load-linked/store-conditional  3. THE ALGORITHM 
Duringthedesignphaseofanyefcientnon-blockingdata structure,alargeefortisspentonguaranteeingtheconsis­tencyofthedatastructurewithoutgeneratingmanyinter­connectiontransactions.Thereasonforthisisthattheper­formanceofanysynchronisationprotocolformultiprocessor 
systemsheavilydependsontheinterconnectiontransactions thattheygenerate.Ahighnumberoftransactionscauses 
adegradationintheperformanceofmemorybanksandthe processor/memoryinterconnectionnetwork. Asafrststep,whendesigningthealgorithmpresentedhere, 
wetriedtousesimplesynchronisationinstructions(primi­tives),withlowlatency,thatdonotgeneratealotofcoher­enttrafcbutarestillpowerfulenoughtosupportthehigh­levelsynchronisationneededforthenon-blockingimplemen­tationofaFIFOqueue.Intheconstructiondescribedin 
thispaperwehaveselectedtousethecompare-and-swap atomicprimitivesinceitmeetsthethreeimportantgoals thatwewerelookingfor.First,itisaquitepowerfulprim­itiveandwhenusedtogetherwithsimplereadandwrite 
registersissufcientforbuildinganynon-blockingimple­mentationofany"interesting"shareddata-structure[3]. 
Second,itiseithersupportedbymodernmultiprocessors orcanbeimplementedefcientlyonthem.Finally,itdoes notgeneratealotofcoherenttrafc.Theonlyproblem 
withthecompare-and-swapprimitiveisthat,itgivesriseto thepointerrecycling(alsoknownasABA)problem.Asa secondstep,wehavetriedwhendesigningthealgorithmpre­sentedheretousethecompare-and-swapoperationaslittle 
aspossible.Thecompare-and-swapoperationisanefcient synchronisationoperationanditslatencyincreaseslinearly 
withthenumberofprocessorsthatuseitconcurrently,but stillitisatransactionalonethatgeneratescoherenttraf­fc.Ontheotherhandreadorupdateoperationsrequire 
asinglemessageintheinterconnectionnetworkanddonot generatecoherenttrafc.Asathirdstepweproposeasim­plenewsolutionthatovercomestheABAproblemthatdoes 
notgeneratealotofcoherenttrafcanddoesnotrestrict thesizeofthequeue. Figure6andFigure7presentcommentedpseudo-codefor 
thenewnon-blockingqueuealgorithm.Thealgorithmis simpleandpractical,andweweresurprisednottofnditin theliterature.Thenon-blockingqueueisalgorithmicallyim­plementedasacirculararraywithaheadandatailpointer 
andaspecialsharedvariablecalledthevnull.Thevnull sharedvariablehasbeenintroducedinordertohelpusto avoidtheABAproblemaswearegoingtoseeattheendof 
thissection.Duringthedesignphaseofthealgorithmwe realisedthat:i)wecouldusethestructuralpropertiesofa 
circulararraytoreducethenumberofcompare-and-swap operationsthatouralgorithmusesaswellastoovercome moreefcientlytheABAproblemandii)allpreviousnon­blockingimplementationsweretryingtoguaranteethatthe 
tailandtheheadpointersalwaysshowtherealheadand tailofthequeuebutbyallowingthetailandheadpointers tolagbehindwecouldevenfurtherreducethenumberof 
compare-and-swapasymptoticallyclosetooptimal.Weas­sumethatenqueueoperationsinsertsdataatthetailofthe 
queueanddequeueoperationsremovedatafromtheheadof thequeueifthequeueisnotempty.Inthealgorithmpre­sentedhereweallowtheheadandthetailpointerstolagat 
mostmbehindtheactualheadandtailofthequeue,inthis wayonlyoneeverymoperationshastoconsistentlyadjust thetailorheadpointerbyperformingacompare-and-swap 
operation.Sinceweimplementthequeueasacirculararray, eachqueueoperationthatsuccessfullyenqueuesordequeues 
dataknowstheindexofthearraywherethedatahavebeen placed,orhavebeentakenfrom,respectively;ifthisindex canbedividedbym,thentheoperationwilltrytoupdate 
thehead/tailofthequeue,otherwiseitwillskipthestep ofupdatingthehead/tailandletthehead/taillagbehind theactualhead/tail.Inthisway,theamortisednumberof 
compare-and-swapoperationsforanenqueueordequeue operationisonly1+1/m,1compare-and-swapoperation perenqueue/dequeueoperationisnecessary.Thedrawback 
thatsuchatechniqueintroducesisthateachoperationon averagewillneedm/2morereadoperationstofndtheac­tualheadortailofthequeue;butifwefxmsothatthela­tencyof(m;1)/mcompare-and-swapoperationsislarger 
thanthelatencyofm/2readoperations,therewillbeaper­formancegainfromthealgorithm,andtheseperformance gainswillincreaseasthenumberofprocessesincreases. 
Itisdefnitelytruethatarray-basedqueuesareinferiorto link-basedqueues,becausetheyrequireinfexiblemaximum 
queuesize.But,ontheotherhand,theydonotrequire memorymanagementschemesthatlink-basedqueueimple­mentationsneedandtheybeneftfromspatiallocalitysig­nifcantlymorethanlink-basedqueues.Takingtheseinto 
accountandhavingaasimple,fastandpracticalimple­mentationinmindwedecidedtouseacyclical-arrayinour construction. 
Wehaveusedthecompare-and-swapprimitivetoatom­icallyswingtheheadandtailpointersfromtheircurrent valuetoanewone.FortheSGIOrigin2000systemwe 
hadtoemulatethecompare-and-swapatomicprimitivewith theload-linked/store-conditionalinstruction;thisim-plementationisshowninFigure4.However,usingcompare­and-swapinthismannerissusceptibletotheABAprob­lem.Inthepastresearchershaveproposedtoattacha 
countertoeachpointer,reducinginthiswaythesizeof thememorythatthesepointerscanpointatefciently.In thispaperweobservethatthecirculararrayitselfworkslike 
acountermodlwherelisthelengthofthecyclicalarray, andwecanfxltobearbitrarylarge.Inthiswaybyde­signingthequeueasacirculararrayweovercometheABA 
problemthesamewaythecountersdobutwithouthaving toattachexpensivecounterstothepointers,thatrestrict thepointersize.Henceforth,whenanenqueueoperation 
takesplace,thetailchangesinonedirectionandgoesback tozerowhenitreachestheendofthearray.Henceforth,the 
tailwillchangebacktothesameoldvalueaftertheshared objectfnisheslenqueueoperationsandnotaftertwosuc­cessiveoperations(exactlyaswhenusingacountermodl). 
Thesamealsoholdsforthedequeueoperations. Theatomicoperationsonthearrayareotherpotentialplaces wheretheABAproblemcantakeplacegivingrisetothefol­lowingscenario: 
1.thearraylocationxistheactualtailofthequeueand 1 itscontentisNull 2.processesaandbfndtheactualtail 1 
thecellisempty #MAXNUM structure{head:nodes:tail:vnull: canbethemaximumunsignedword Queue unsignedinteger, 
array[0..MAXNUM+1]ofpointer, unsignedinteger, unsigned newQueue():pointerQueue*temp; temp=(Queue*)temp->head=0; 
temp->tail=1; integer} toQueue malloc(sizeof(Queue)); #wedefineanotherNULL temp->vnull=NULL(1); for(i=0;i<=MAX_NODES;i++) 
 #NULLmeansempty temp->nodes[i]=NULL(0); temp->nodes[0]=NULL(1); returntemp; Figure5:Initialisation 3.processaenqueuesdataandupdatesthecontentof 
locationxwiththecompare-and-swap.succeeds 4.processcdequeueslocationxtoNull, 5.processbenqueueslocationxwiththecompare-and-swap.incorrectlysucceedsqueue. 
useof SincethecontentsofxisNull,a dataandupdatesthecontentof changingalsothepointerhead dataandupdatesthecontentsof 
useof SincethecontentofxisNull,b toenqueueanonactivecellinthe InordertoovercomethisspecifcABAinstanceinsteadof 
usingacounterwithallthenegativeside-efects,weintro­duceanewsimplemechanismthatweweresurprisednot tofndintheliterature.Theideaisverysimple;instead 
ofusingonevaluetodescribethatanentryinthearrayis emptyweusetwo,NULL(0)andNULL(1).Whenapro­cessordequeuesanitem,itwillswapintothecelloneofthe 
twoNULLsinsuchawaythatoperationsonthesamecellgivethecell.ReturningtotheABAthescenariowouldnowlookliket 
twoconsecutivedequeue diferentNULLvaluesto scenariodescribedabove, his: 1.arraylocationxistheactualtailandit'scontentis 
NULL(0) 2.processesaandbfndtheactualtail,ie.locationx 3.processaenqueuesdataandupdatesthecontentof locationxwithacompare-and-swapoperation.Since 
x 0 scontentisNULL 4.processcdequeueslocationxtoNULL 5.processbenqueueslocationxwith compare-and-swap.inthisturn. 
(0),asucceeds dataandupdatesthecontentof (1) dataandupdatesthecontentof AsthecontentisNULL(1),bfails 
Enqueue(t:pointertoQueue,newnode: pointertodatatype):Boolean loop te=t->tail; #readthetail ate=te; tt=t->nodes[ate]; 
#thenextslotofthetail temp=(ate+1)ANDMAXNUM; #wewanttofindtheactualtail while(tt<>NULL(0)ANDtt<>NULL(1))do 
#checktail'sconsistency if(te!=t->tail)break; #iftailmeethead, #itispossiblethatQueueisfull if(temp==t->head)break; 
#nowcheckthenextcell tt=t->nodes[temp]; ate=temp; temp=(ate+1)&#38;MAX_NODES; endwhile #checkthetail'sconsistency 
if(te!=t->tail)continue; #checkwhetherQueueisfull if(temp==t->head) ate=(temp+1)&#38;MAX_NODES; tt=t->nodes[ate]; 
#thecellafterheadisOCCUPIED if(tt<>NULL(0)ANDtt<>NULL(1)) returnFAILURE; #QueueFull #ifheadrewindtryupdatenull 
if(!ate) t->vnull=tt; #helpthedequeuetoupdatehead cas(&#38;t->head,temp,ate); #tryenqueueagain continue; 
endif #checkthetailconsistency if(te!=t->tail)continue; #gettheactualtailandtryenqueuedata if(cas(&#38;(t->nodes[ate]),tt,newnode)) 
if(temp%2==0)#enqueuehassucced cas(&#38;(t->tail),te,temp); returnSUCCESS; endif endloop Figure6:Theenqueueoperation 
Avariable,vnullisusedtohelpthedequeueoperationsto determinewhichNULLtheyshoulduseanytime. WiththismechanismtheABAscenariothatwastaking 
placebefore,whenaprocesswaspreemptedbyonlyone otherprocess,nowchangestoanABA0BAscenario.The ABA0Ascenarioisstillapointerrecyclingproblem,butin 
B0 ordertotakeplaceldequeueoperationsareneededtotake thesystemfromAtoBandsubsequentlyto,afterthat A0 
lmoredequeueoperationsareneededinordertotakethe systemfromtoandthentoA.Moreover,allthese A0B0 operationshavetotakeplacewhiletheprocessthatwill 
experiencethepointerrecyclingispreempted.Takinginto accountthatlisanarbitrarylargenumber,theprobability 
thattheaboveABA0B0Ascenariocanhappencangoas closeto0aswewant2. Theabovesketchesaproofofthefollowingtheorem: 
Theorem1.Thealgorithmdoesnotgiverisetothepointer recyclingproblem,ifanenqueordequeueoperationcannot bepreemptedbymorethanloperations,lisanarbitrary 
largenumber. Fortherestofthesepaperweassumethatwehaveselected ltobelargeenoughnottogiverisetothepointerrecycling 
probleminoursystem. Theaccessingofthesharedobjectismodelledbyahistory h.Ahistoryhisafnite(ornot)sequenceofoperation 
invocationandresponseevents.Anyresponseeventispre­cededbythecorrespondinginvocationevent.Forourcase therearetwodiferentoperationsthatcanbeinvoked,an 
EnqueueoperationoraDequeueoperation.Anoperationis calledcompleteifthereisaresponseeventinthesamehis­toryh;otherwise,itissaidtobepending.Ahistoryiscalled 
completeifallitsoperationsarecomplete.Inaglobaltime modeleachoperationq"occupies"atimeinterval[sqf]on 
onelineartimeaxis(sq<fq);wecanthinkofsqandfq asthestartingandfnishingtimeinstantsofq.Duringthis timeintervaltheoperationissaidtobepending.Thereex­istsaprecedencerelationonoperationsinhistorydenoted 
by<h,whichisastrictpartialorder:q1<hq2meansthat q1endsbeforeq2starts;Operationsincomparableunder<h arecalledoverlapping.Acompletehistoryhislinearisable 
ifthepartialorder<honitsoperationscanbeextendedto atotalorder!thatrespectsthespecifcationoftheobject 
q h [4]. Anypossiblehistory,producedbyourimplementation,can bemappedtoahistorywhereoperationsuseanauxiliary 
arraythatisnotboundedontherightside.Inorderto simplifytheproofwewillusethisnewauxiliaryarray.Our algorithmguaranteesthatenqueueoperationsenqueuedata 
atconsecutivearrayentriesfromlefttorightonthisar­ray,anddequeueoperationsdequeueitemsalsofromleft toright.Inthiswayitmakessurethattheoperationsare 
dequeuedintheordertheyhavebeenenqueued.Fromthe previoustheoremwealsohavethatwhenanEnqueue(x) operationfnishesafterwritingxtosomeentryeofthear­ray,theheadpointerofourimplementation,thatguides 
thedequeueoperations,willnotover-passthisentrye,thus makingsurethatnoenqueueditemisgoingtobelost.The 
abovesketchesaproofforthenexttheorem: Theorem2.InacompletehistorysuchthatEnqueue(x)! Enqueue(y),eitherDequeue(x)!Dequeue(y)orDequeue(y) 
andDequeue(x)overlap. 2 Weshouldpointoutthatthetechniqueofusing2diferent NULLvaluescanbeextendedtokdiferentvaluesrequiring 
morethank*ldequeueoperationstopreemptanoperation inordertocausethepointerrecyclingproblem.Wethink thattheschemewith2*NULLvaluesissimpleenoughand 
sufcientforthesystemsthatwearelookingat. Thedequeueoperationthatdequeuesxistheonlyonethat succeedstoreadand"empty"thearrayentrywherexwas 
written,becauseoftheatomiccompare-and-swapoperation; makinginthiswaysurethatnootheroperationdequeues 
thesameitem.Moreover,sincethearrayentrywaswritten byanenqueueoperation,thedequeueoperationswillalways 
dequeueitemsthathavebeen"really"enqueued.Theabove sketchestheproofofthefollowingtheorem: Theorem3.Ifxhasbeendequeued,thenitwasenqueued, 
andEnqueue(x)!Dequeue(x) Thelast2theoremsguaranteethelinearizablebehaviour ofourFIFOqueueimplementation[4].Duetospacecon­straints,weonlysketchedtheproofofthesetheorems. 
 4. PERFORMANCE EVALUATION Weimplementedouralgorithmandconductedourexper­imentsonaSUNEnterprise10000with64250MHzUl­traSPARCprocessorsandonaSGIOrigin2000with64 
195MHzMIPSR10000processors.TheSUNmultiprocessor isasymmetricmultiprocessorwhiletheSGImultiprocessor isaccNUMAone.Toensureaccuracyoftheresults,wehad 
exclusiveaccesstothemultiprocessorswhileconductingthe experiments.Forthetestswecomparedtheperformanceof 
ouralgorithm(new)withtheperformanceofthealgorithm byMichaelandScott(MS)[10]becausetheiralgorithmap­pearstobethebestnon-blockingFIFOqueuealgorithm. 
Inourexperiments,wealsoincludedasolutionbasedon locks(ordinarylock)todemonstratethesuperiorityofnon­blockingsolutionsoverblockingones. 
4.1 Experiments on SUN Enterprise 10000 Wehaveconducted3experimentsontheSUNmultiprocessor, inallofthemwehadexclusiveuse.Inthefrstexperiment 
wemeasuredtheaveragetimetakenbyallprocessorstoper­formonemillionpairsofenqueue/dequeueoperations.In thisexperiment(Figure8a)aprocessenqueuesanitemand 
thendequeuesanitemandthenitrepeats.Inthesecond experiment(Figure8b)processesstayidleforsomerandom timebetweeneachtwoconsecutivequeueoperations.In 
thethirdexperimentweusedparallelquick-sort,thatuses aqueuedatastructure,toevaluatetheperformanceofthe 
threequeueimplementations.Parallelquick-sorthadtosort 10millionrandomlygeneratedkeys.Theresultsofthisex­perimentareshowninFigure8c.Thehorizontalaxisinthe 
fguresrepresentthenumberofprocessors,whilethevertical onerepresentsexecutiontimenormalisedtothatofMichael 
andScottalgorithm. Thefrsttwoexperiments(on58processors),showthatthe newalgorithmoutperformstheMSalgorithmbymorethan 
30%andthespin-lockalgorithmbymorethan50%.The thirdexperimentshowsthatthenewqueueimplementation ofers40%betterresponsetimetothesortingalgorithm. 
 4.2 Experiments on the SGI multiprocessor OntheSGImachine,thefrstthreeexperimentswerebasi­callythesameexperimentsthatweperformedontheSUN 
multiprocessor.TheonlydiferenceisthatontheSGIma­chinewecouldselecttousethesystemasadedicatedsys­tem(multiprogramminglevelone)orasamultiprogrammed 
Dequeue(t:pointertoQueue,oldnode: pointerofpointertodatatype) loop th=t->head; #readthehead #hereistheonewewanttodequeue 
temp=(th+1)&#38;MAX_NODES; tt=t->nodes[temp]; #findtheactualheadafterthisloop while(tt==NULL(0)ORtt==NULL(1))do 
 #checkthehead'sconsistency if(th!=t->head)break; #twoconsecutiveNULLmeansEMPTYreturn if(temp==t->tail)return1; 
temp=(temp+1)&#38;MAX_NODES;#nextcell tt=t->nodes[temp]; endwhile #checkthehead'sconsistenicy if(th!=t->head)continue; 
#checkwhethertheQueueisempty if(temp==t->tail) #helptheenqueuetoupdateend cas(&#38;t->tail,temp,(temp+1)&#38;MAX_NODES); 
continue; #trydequeueagain endif #ifdequeuerewindto0, #switchingNULLtoavoidABA if(temp) if(temp<th) 
tnull=t->nodes[0]; else tnull=t->vnull; else tnull=(void*)(((unsigned)t->vnull).1); #checkthehead'sconsistency 
if(th!=t->head)continue; #Gettheactualhead,nullvaluemeansempty if(cas(&#38;(t->nodes[temp]),tt,tnull)) 
#ifdequeuerewindto0, #switchNULLstoavoidABA if(!temp)t->vnull=tnull; if((temp%2)==0)cas(&#38;(t->head),th,temp); 
*oldnode=tt; #returnthevalue return0; endif endloop Figure7:Thedequeueoperation systemwithtwoandthreeprocessesperprocessor(mul­tiprogrammingleveltwoandthreerespectively).Forthe 
SUNmultiprocessorthiswasnotpossible.Figures9,10 and11ashowgraphicallytheperformanceresults.Whatis veryinterestingisthatouralgorithmgivesalmostthesame 
performanceimprovementsonbothmachines. OntheSGImultiprocessor,itwaspossibletousethera­diosityfromSPLASH-2shared-address-spaceparallelappli­cations[13].Figure11bshowstheperformanceimprovement 
comparedwiththeoriginalSPLASH-2implementation.The verticalaxisrepresentsexecutiontimenormalisedtothatof 
theSPLASH-2implementation. 2 1.8 1.6 1.4 normalized time normalized time normalized time  normalized 
time normalized time normalized time 1.2 1 0.8 0.6 0.5 0.4 0.2 0 0 number of processors number of processors 
 (a)ontheSUNStarfrewithfullcontention (a)Levelone 2.5  2 1.5 1 0.5 0.5 00 number of processorsnumber 
of processors (b)Level2(b)ontheSUNStarfrewithrandomwaitingcon­tention 4  3.5 3 2.5 2 1.5 0.6 1 0.4 0.5 
0.2 0 number of processors 0 number of processors (c)Level3 (c)Quick-sortonSUNStarfre Figure9:ResultsontheSGImultiprocessorwith 
di.erentmultiprogramminglevelsunderfullcon­ Figure8:ResultsontheSUNmultiprocessor tention 5 3 4 2.5 
 normalized time normalized time 3 2 normalized time normalized time normalized time 2 1.5 1 1 0.5 0 
0 number of processors number of processors (a)Quick-sort (a)Level1 2 4.5 4 1.5 3 2.5 2 1 0.5 1.5 1 
00.5 number of processors 0 number of processors (b)Radiosity (b)Level2 Figure11:ApplicationsonSGI 5 
 4 3 2 1 0 number of processors (c)Level3 Figure10:ResultsontheSGImultiprocessorwith di.erentmultiprogramminglevelsunderrandom 
waitingcontention  5. CONCLUSIONS Inthispaperwepresentedanewboundednon-blockingcon­currentFIFOqueuealgorithmforsharedmemorymulti­processorsystems.Thealgorithmissimpleandintroduces 
twonewsimplealgorithmicmechanismsthatcanbeofgen­eraluseinthedesignofefcientnon-blockingalgorithms. Theexperimentsclearlyindicatethatouralgorithmcon­siderablyoutperformsthebestoftheknownalternativesin 
bothUMAandccNUMAmachineswithrespecttobothded­icatedandmultiprogrammingworkloads.Theexperimental resultsalsogiveabetterinsightintotheperformanceand 
scalabilityofnon-blockingalgorithmsinbothUMAandcc-NUMAlargescalemultiprocessorswithrespecttodedicated 
andmultiprogrammingworkloads,andtheyconfrmthat non-blockingalgorithmscanperformbetterthanblocking onbothUMAandccNUMAlargescalemultiprocessors. 
Acknowledgements WewouldliketothankDavidRutterforhisgreathelpdur­ingthewritingphaseofthispaper.WearegratefultoCarl 
Hallen,AndyPolyakovandPaulWaserbrot,theymadethe impossiblepossibleandattheendwecouldhaveexclusive accesstoourheavily(thankstoourphysicsdepartment) 
loadedparallelmachines.  6. REFERENCES [1]A.Charlesworth.Starfre extendingtheSMP envelope.IEEEMicro,18(1):39.49,1998. 
 [2]D.Cortesi.Origin2000andonyx2performancetuning andoptimizationguide. http://techpubs.sgi.com/library/,SGIInc.,1998. 
[3]M.Herlihy.Wait-freesynchronization.ACM TransactionsonProgrammingLanguagesand Systems,13(1):124.149,Jan.1991. 
 [4]M.P.HerlihyandJ.M.Wing.Linearizability:A correctnessconditionforconcurrentobjects.ACM TransactionsonProgrammingLanguagesand 
Systems,12(3):463.492,July1990. [5]A.R.Karlin,K.Li,M.S.Manasse,andS.Owicki. Empiricalstudiesofcompetitivespinningfora 
shared-memorymultiprocessor.InProceedingsofthe ThirteenthACMSymposiumonOperatingSystems PrinciplesOperatingSystemsReview(13thSOSP 
1991),pages41.55,PacifcGrove,CA,Oct.1991. [6]L.Lamport.Specifyingconcurrentprogrammodules. ACMTransactionsonProgrammingLanguagesand 
Systems,5(2):190.222,Apr.1983. [7]J.LaudonandD.Lenoski.TheSGIorigin:A ccNUMAhighlyscalableserver.InProceedingsofthe 
24thAnnualInternationalSymposiumonComputer Architecture(ISCA-97),volume25,2ofComputer ArchitectureNews,pages241.251,NewYOrk, 
June2.41997.ACMPress. [8]H.MassalinandC.Pu.Alock-freemultiprocessorOS kernel.TechnicalReportCUCS-005-91,Columbia 
University,1991. [9]J.M.Mellor-CrummeyandM.L.Scott.Algorithms forscalablesynchronizationonshared-memory 
multiprocessors.ACMTransactionsonComputer Systems(TOCS),9(1):21.65,Feb.1991. [10]M.M.MichaelandM.L.Scott.Nonblocking 
algorithmsandpreemption-safelockingon multiprogrammedsharedmemorymultiprocessors. JournalofParallelandDistributedComputing, 
51(1):1.26,25May1998. [11]S.Prakash,Y.Lee,andT.Johnson.Anonblocking algorithmforsharedqueuesusingcompare-and-swap. 
IEEETransactionsonComputers,43:548.559,May 1994. [12]J.D.Valois.Lock-FreeDataStructures.PhDthesis, RensselaerPolytechnicInstitute,Departmentof 
ComputerScience,1995. [13]S.C.Woo,M.Ohara,E.Torrie,J.P.Singh,and A.Gupta.TheSPLASH-2programs:Characteriation 
andmethodologicalconsiderations.InProceedingsof the22ndAnnualInternationalSymposiumon ComputerArchitecture,pages24.37,NewYork, 
June22.241995.ACMPress. [14]J.Zahorjan,E.D.Lazowska,andD.L.Eager.The efectofschedulingdisciplineonspinoverheadin 
sharedmemoryparallelprocessors.IEEETransactions onParallelandDistributedSystems, PDS-2(2):180.198,Apr.1991. 
 
			