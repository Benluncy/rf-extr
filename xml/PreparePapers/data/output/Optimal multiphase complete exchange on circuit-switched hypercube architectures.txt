
 Optimal Multiphase Complete Exchange on Circuit-Switched Hypercube Architectures* David M. Nicol Dept. 
of Computer Science College of William and Mary Williamsburg, VA 23187-8795 Abstract The complete-exchange 
communication primitive on a distributed memory multiprocessor calls for every pro­ cessor to send a 
message to every other processor, each such message being unique. For circuit-switched hyper­ cube networks 
there are two well-known schemes for im­ plementing this primitive. Dmect Exchange minimizes communication 
volume but maximizes startup costs, while Standard Exchange minimizes startup costs at the price of higher 
communication volume. This paper ana­ lyzes a hybrid, which can be thought of as a sequence of Direct 
Exchange phases, applied to variable-sized sub­ cubes. This paper examines the problem of determining 
the optimal subcube dimension sizes di for every phase. We show that optimal performance is achieved 
using some eqm-partitzon, where ]d~ dj I < 1 for all phases i and j. We study the behavior of the optimal 
partition as a function of machine communication parameters, hy­ percube dimension, and message size, 
and show that the optimal partition can be determined with no more than 2(W + 1) comparisons. Finally 
we validate the model empirically, and for certain problem instances observe as much as a factor of two 
improvement over the other methods. *This work was supported by the National Aeronautics and Space Administration 
under NAS1-19480 while the au­thors were in residence at the Institute for Computer Ap­plications in 
Science and Engineering (ICASE), NASA Lan­gley Research Center, Hampton, VA 23681. Nicol s work w= also 
supported in part by NSF grant C CR-9210372. Permission to copy without fee all or part of ttis material 
is granted provided that the copies are not made or distributed for direct commercial advarita~e, the 
ACM copyright notice and the title of the publication and Its date appear, and notice is given that copying 
is by permission of the Association of Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. SIGMETRICS 84-5/94 Santa Clara, CA. USA @ 1994 ACM 0-89791 -659-xKWO005..$3.5O 
Shahid H. Bokhari Dept. of Electrical Engineering University of Engineering (3 Technology Lahore, Pakistan 
1 Introduction Distributed memory multiprocessors are increasingly used to solve large scientific problems. 
Circuit-switched hypercube interconnection topologies are common, be­ ing used in machines such as the 
Intel iPSC/2, Intel iPSC/860 and Ncube-2. Even on later generation ma­ chines such as the Intel Paragon, 
Thinking Machines CM-5, IBM SP-1, and Cray Research T3D it some­ times makes sense to use the logical 
structure of a hy­ percube interconnect, especially when the networks are fast enough relative to software 
startup latencies so that the cost of sending a message is largely independent of the route it takes. 
This paper considers the problem of optimizing the complete ezchange primitive assum­ ing a local hypercube 
network. Under this operation each of 2d processors sends a unique iogtca! message to each of the remaining 
2d 1 processors. The operation lies at the core of a number of important algorithms, including matrix 
transposition, matrix-vector multipli­ cation, certain Fast Fourier Transform methods [6], and the ADI 
[4] method (Alternating Direction Implicit) for solution of partial differential equations. Figure 1 
illus­ trates how complete exchange arises when transposing a matrix where contiguous blocks of b columns 
have been distributed among processors. Arrows between blocks identify exchange-pairs involving processor 
O. Note that it must send, and receive, N 1 blocks of data. The operation is costly (a total of 2d(2d 
 1 ) messages are involved), and common; it is therefore worthwhile to minimize its cost. There are two 
fairly well known algorithms for complete-exchange on a circuit-switched hypercube. The Dn-ect Ezchange 
algorithm (DE) [7, 9] proceeds in 2d 1 steps. At each step, each processor sends one logical message, 
and receives one logical message. The communication pairs can be constructed so that no link contention 
is encountered during any step. Since every message is communicated exactly once, the communi­cation 
volume (total number of bytes transmitted) is N b CO&#38;lSIS Processor O1234567 II 1 I b rows - I 
ygy+ 11 ­ .-~..l-L. 1! J_-l 11 -- N // 1111, ,, -­ --L-l--lL-J _ -p 11 1111, - -1,,,, _, --r-T--}­ 
;__ 1111, ,, . L-.I --J-J-- L- J._ / 11, ,,, , 11, ,,, , Figure 1: Complete exchange for an N x N matrix 
trans­pose when contiguous blocks of matrix columns are as­signed to processors. The communication behavior 
of processor O is illustrated. minimized. However, the number of steps (2d 1) is relatively large, compared 
to the Standard llcchartge algorithm (SE) [5]. The SE algorithm employs only logz 2d = d steps, but at 
each step, each processor sends and receives one physical message comprised of 2d-1 log­ical messages. 
Thus the SE algorithm executes with fewer steps, but at the price of increased communica­tion volume. 
Under the SE algorithm a logical message from processor i to j is transmitted as many times as the bit-wise 
exclusive-OR vector i @ j has set bits. In this paper we analyze a hybrid algorithm, the mu!­tiphase 
complete ezchange algorithm (MCE) [1]. This algorithm combines aspects of the DE and SE algo­rithms in 
such a way that DE and SE are special cases. MCE S basic idea is to implement the exchange in a series 
of phases, where in each phase i the hypercube is partitioned into subcubes of dimension di, and DE is 
applied to exchange messages within each subcube. However, like SE, the physical messages sent contain 
more than one logical message. If an MCE algorithm employs k phases, then ~~=1 di = d; a logical message 
may be transmitted up to k times, depending on the distance between its source and destination. The problem 
we study is the choice of phase count k and dimension sizes {di } that optimize the performance of the 
MCE algorithm. Intuitively, the optimal param­eters will depend on characteristics of the architecture 
and on the length of the messages being exchanged. We prove that the optimal solution has the characteristic 
that Idi dj I < 1 for all phases i and j. We give suf­ficient conditions for optimal MCE to actually 
be SE, and for it to actually be DE. We discover upper and lower bounds on the optimal sizes {di}, and 
show that optimal MCE parameters can be determined with fewer than 2(W + 1) comparisons. We present data 
that val­ idates the analytic model, and illustrates as much as a factor of two improvement over the 
other methods. An earlier study of this problem [2] established the equipartition property, under a simpler 
communication model. The present paper improves upon that result by using a more complex model, by using 
a far simpler proof, and by establishing a more complete theory of the optimization problem s complexity. 
The remainder of this paper is organized as follows. Section 2 describes the algorithms in more detail, 
and develops mathematical models of their costs. Section 3 presents our analysis, Section 4 presents 
data that val­ idates the mathematical model, and which illustrates possible improvement gains. Section 
5 gives our conclu­ sions. 2 Preliminaries We first consider a model of message passing costs, and then 
apply it to the complete exchange operation. 2.1 Message Passing Cost Model It is well accepted that 
the delay cost of an m-byte mes­sage passed without network contention on a circuit­switched hypercube 
can be modeled as %.,(m) = A + rnr+ C$t where A is a startup cost (usually associated with soft­ware), 
~ is the per-byte transmission delay, and 6 is a hardware cost of setting up and tearing down a cir­cuit 
across tlinks. We simplify this model slightly, and choose a distance-independent value for 6, which 
is the average circuit setup cost over all paths. This is rea­sonable when the other costs dominate 6, 
which is ac­tually typical on the current generation of hypercube machines. Validations of this model 
are found in [3]. With this model in mind, we now turn to a more pre­cise description of the DE, SE, 
and MCE algorithms. 2.2 The Direct Exchange Algorithm The DE algorithm proceeds in 2d 1 steps. In each 
step k(k=l,2, . . ., 2d 1), each processor i exchanges a logi­cal message with processor i~k. We assume 
the network links are bidirectional. It has been proven that no net­work contention may occur if processors 
cycle through these steps synchronously. Assuming this occurs, the cost of a step is the cost of one 
message, and the total cost of the DE algorithm is then Zd-1 t~~(rn) = ~ kg(m)+ Q(d) k=l = (2 -l)(A+rnr+ 
6) + Q(d). where Q(d) is the cost of a barrier synchronization on a hypercube of dimension d. The need 
for such is ex­plained in Section 4. 2.3 The Standard Exchange Algorithm The SE algorithm is presented 
below. pid denotes the processor id. Each processor maintains a list of 2d log­ical messages; at each 
step it sends half this list to an­other processor. The algorithm includes actions which ensure that 
at each step j = d 1 to O, the first 2d-1 logical messages have bit j clear, and the second 2d-1 logical 
messages have bit j set. Following the exchange, the messages that were retained are shuffled with the 
messages that were received in order to produce the re­quired ordering for the next step. procedure StandardExchangeo 
forj=d l to Ode{ if(bit j of pid = O) then phys. msg. = log. msgs. 2d 1 to 2d 1; else phys. msg. = log. 
msgs. O to 2d-1 1; send phys. msg. to processor ptd @ 2j; shuffle log. msgs; } Here we see that the 
SE algorithm proceeds in only d steps, but at each step every processor sends out 2d 1 logical messages. 
Let p be the per-byte cost of imple­menting a shuffle. The cost of executing the SE algo­rithm for m-byte 
logical messages is given by t.sE(rn) = d(A + 2d-lrnr + 6 + 2drnp + Q(d)). The resson why DE has one 
global synchronization per phase while SE has one per step is explained more fully in Section 4. Our 
analysis does not qualitatively change if other arrangements (e.g., global synchroniza­tion at each DE 
step) are assumed. 2.4 The MultiPhase Complete Ex­change Algorithm  The MCE algorithm requires pre-definition 
of the num­ ber of phases, k, and the dimension di for each phase i. At the ith phase the hypercube is 
partitioned into subcubes of dimension d% with the property that the pids of processors in a subcybe 
match in all bit posi­tions except start, = d ~~~~ d, --1 through Stopi = d ~~.=ldj. We will say the 
phase spans dimension bits startithrough stopi. An intuitive way to think of the MCE algorithm is as 
a sequence of phases that col­lectively span the d dimension bits of the hypercube. At the beginning 
of a phase every processor holds 2d logical messages (there is a dummy self-addressed mes­sage to simplify 
the algorithm). Some of these may be addressed to the processor and hence are already de­livered. Some 
may be addressed to other processors in the subcube defined during this phase, and the re­mainder are 
addressed to processors that are not in this phase s subcube. A Direct Exchange operation is ap­plied 
between processors in a common subcube. During this exchange, processor i sends to processor j any log­ical 
message it presently holds that j would hold if we were to apply the Standard Exchange steps through 
di­mension bits Startithrough stop%, beginning with the message distribution at the beginning of the 
phase step. The physical message cent aining these logical messages is called the eflective biock. The 
number of logical mes­sages a processor sends during this phase is 2d- I (a gen­eralization of the SE 
exchange algorithm, where di = 1 fori=l . . . . . k). Note that this figure depends solely on the fixed 
total network size, and the variable subcube dimension. Receiving its messages, a processor emulates 
the effect of implementing the Standard Exchange algo­rithm through the phase s di dimensions by permuting 
the messages in its memory so that their order is the same as it would have been under Standard Exchange. 
All 2d messages are involved in this permutation. An invariant of this algorithm is that if exactly j 
dimension bits have been spanned by any number of phases, the message lists in each processor are exactly 
those they would contain if we had used SE through each of those dimensions. Pseudo-code from [1] describing 
MCE is given below. procedure MultiPhaseo start= d 1; fori=ltok do{ stop= start di+ 1; for j = 1 to 
(2 t rt-StOPtl 1) do send effective block to @ (j2s~0P); synchronize ; shuffle blocks; start = stop 
 1; } Now consider the cost of a phase i. There are 2dJ 1 steps in the Direct Exchange; during each 
step each pro­cessor sends and receives one effective block, comprised of 2d-dI logical messages. Again 
assuming synchrony between processors, the cost of executing phase i is ~d(di, ~) D ( 2d 1)(A+ 2d-d 
mr + t$) +2dmp + Q(d). (1) It is worth noting that this expression depends only on the size d; of the 
dimension, and not the phase number or the precise position of the dimension bits involved. Our analysis 
exploits this separability property. The overall cost of the MCE algorithm is then k t~c~(rn) = ~((2~ 
 1)(A + 2d-d ?nT + 6) ;=1 +2%np + Q(d)). (2) MCE actually describes a family of algorithms, de­pending 
on the number of phases and the sizes of sub­cubes involved. At one extreme there is k = 1 and dl = d, 
which describes the DE algorithm. At the other extreme there isk=danddi=1for alli=1,....d, which is the 
SE algorithm. The seminal work on MCE remarks that the optimal parameter settings may be obtained by 
examining every partition of the integer d into components {di } that sum to d [1]. The number of possible 
partitions grows exponentially in d. One of our contributions is to show that the optimal set of param­eters 
hss a particular form that restricts the number of possibilities to no more than 2(W + 1).  Analysis 
 Our main result is that the optimal MCE algorithm is described by some eqzti-partition, i.e., Idi dj 
I < 1 for all phases i and j. Since t.McE(m) is in no way af­fected by the ordering of the di, we may 
restrict our attention to sequences {di } that are monotone non­decreasing. There are no more than d 
possible monotone non-decreasing equi-partitions, which immediately re­stricts the search to a far more 
manageable space. Fur­ther analysis will identify a set of 2(W + 1) or fewer possibilities. The optimization 
problem is basically that of deciding how to partition the integer sequence d 1, d 2, . ...1,0 in k contiguous 
subsequences, with di being the number of integers in the ith subsequence. The ith MCE phase spans precisely 
those dimension indices described in the ith subinterval. However, the cost of the MCE algorithm depends 
only on the lengths of the subsequences, not on their composition. Throughout the analysis we will speak 
of partitioning d or spanning d, with subsequence lengths, with the understanding that we can always 
con­struct the subsequences from those lengths. Since order is immaterial, we may sssume that any partition 
of d has its lengths ordered in monotone non-decreasing order. Our results follow from an analysis of 
a continuous version of this problem, where we seek to optimally partition the real interval [0, ~ into 
disjoint real subin­tervals. Like the discrete problem, we actually work with lengths of subintervals 
rather than the subinter­vals themselves; the cost of spanning a subinterval with one MCE phase is a 
function of the subinterval length. We will define this cost with a continuous ver­sion of the function 
given ss Equation (1). Viewing the first argument now as the length of a continuous subin­terval we rewrite 
Pd(~, ~) = (2 1)(A + 2d- m7 + 6) +2dmp + Q(d) forz~[O, dl. Given k positive real numbers {Zi} that 
describe the lengths of spanning subintervals (e.g., ~~=1 Z; = d), the solution cost of the continuous 
problem is ~~nl Pd(zi, ). The first derivative of Pd with respect to z is ~Pd(~, m) = (In 2) (2Z(A + 
6) + 2~-om7) , which is always positive, and the second derivative of pd with respect to x is _j$Pd(~j 
m) = (ln 2)2 (2 (A + 6) 2d- mr) . The second derivative is negative (and hence pd is con­cave) over 
z ~ [0, x*] where Z* is the solution to (~+ 6)/(mr) = 2d-2 ; pd k convex over [x , d]. This makes the 
optimization problem somewhat harder than if pd($, m) were either increasing concave or increasing convex 
over [0, dl. Consider the following problem. Say we are given some subinterval length s < d to span (in 
the continuous problem) with two MCE phases-one that spans length x < s/2 and another that spans length 
.s x. The cost of the first phase is pd(~, m), and the cost of the second phase is pd(s x, m). We wish 
to choose z to minimize Ad(S, z,m) = pd(~,m) +p(s z,m). The derivative of Ad(s, x, m) with respect to 
z is -&#38; Ad(s, z,m) = ~pd(z, m) + $#d(s ~, m) = (/n 2)(2 (~ + 6) + 2d- mr _2 - (~ + ~) 2d- + m~) 
= (In 2)((2 -2 - )(A + 6) ­ (2d-S+Z 2d- )mT). Analysis of this derivative yields the surprising result 
that Ad(s, Z, m) is either monotone increasing or mono­tone decreasing in z over x G [0, s/2], depending 
on the relationship between (A + 6)/(mr) and 2d-s, for &#38;!id(S, Z, m) <0 2 - )(A + 6) < (Zd- + -2~ 
)mT* (2 ~ ~ + 6> 2d-S+Z -2d-x = Zd-s. 2. _ 28 . mr Given the monotonicity of Ad(s, x, m) in z, we have 
three possible situations. First, if s is small enough to satisfy (A + 6)/(m~) < 2d , then Pd(s, m) < 
&#38;(s, O,m) < &#38;(s, x,m) for z ~ [0, s/2]. Applying this observation to the discrete problem, sup­pose 
that we have a discrete partition {di } with elements di and dj such that s = di + dj satisfies (~+ c$)/(m~) 
< 2d-s. The inequality above shows that a new partition with lower cost can be constructed by removing 
di and dj, and replacing them with s = d; + dj. For, ~~d(da, m) a=l = ~ Pci(d.,~) +Pd(di~)+~ci(.$-di,~ 
Z) da#d,, da#d, () = ~ ~d(da,?~) + Ad(S,d,,~) da#di, d.a#dJ () > ~ Pd(da,m) +Pd(s, n). da+d,, da+d, () 
The second and third possibilities for Ad(s, z, rn) s behavior arise when (A + c$)/(rnT) ~ 2d-S. In this 
case we must compare Pd(s, m) and Ad(s, s/2, m) to deter­mine whether a subinterval of length s is better 
spanned in one phase, or in two. First, note that if a parti­tion has subintervals d, and dj, \di dj 
I z 2, so that s = di + dj satisfies (A + 6)/(mr) ~ 2d s, then it is possible to improve the cost of 
spanning s in two phases by choosing subinterval sizes dj = [(di + dj )/21 and d; = L(di + dj )/2]. This 
follows from the decreasing monotonicit y of Ad(s, x, m). These observations prove the following Theorem. 
Theorem 1 The optzmal MCE parameters {di} satisfy For all di, djj (A + 6)/(m~) ~ 2d dZ-dJ . . For a!!di, 
dj, ]di djl ~ 1. This result shows that the optimal MCE subcube dimensions form an equi-partition of 
d. Under the assumption that the sequence {di } is monotone non­ decreasing, for every k = 1,. ... d 
there is exactly one equi-partition with k elements, implying that for a given set of parameters, the 
optimal subcube dimensions can be determined with d comparisons by computing the cost of each monotonic 
equi-partition. For many prac­ tical purposes this approach suffices. If the message length m were to 
change dynamically during a compu­tation, it would be useful to store a small amount of in­formation 
that would accelerate the search for optimal parameters. We can do this by recognizing that for a given 
part ition {di}, cost function (2) is a linear function of m. Furthermore, one can show that as the number 
of phases in an equi-partition increases, the slope of the corresponding cost curve in m increases and 
the inter­cept decreases. The superposition of all equi-partition curves creates a convex hull (as will 
be seen in Figures and 3). Analysis of this hull will give us no more than d threshold pairs (mo = O, 
ko), (ml, kl), (mz, kz), . . . with the property that, if mi ~ m < mi+l, then the equi­partition with 
ki elements is optimal. Since the mi s are increasing, a binary search on mi will identify the optimal 
parameters. While the approach above is likely practical enough for anyone, for theoretical interest 
we now explore fur­ther characteristics of the optimal partition. This study helps to shed light on the 
characteristics of problems where MCE is useful. Knowledge that (A + 6)/(mr) ~ 2d-s does not com­pletely 
determine whether s ought to be spanned with one phase or two. For instance, Ad(S, x, m) changes from 
increasing in x to decreasing in x when s is the so­lution (~) to (~+&#38;) /(m~) = 2d- ; indeed, Ad(ii, 
z, m) k constant for z E [0, s/2], and Ad(~, O, m) > ~d(~, m) im­ plying that intervals of length 3 are 
best spanned with one MCE phase. If we think of the use one phase Vs. use two phases decision as being 
a function of the length s, then intuition suggests that there is some threshold s for which one phase 
is better than two when s < s* and two phases are better than one when s > S*. If such an s* exists, 
it is the unique solution to the equation Pd(s, m) = Ad(s, s/2, m), for at that s* the one-phase and 
two-phase costs are exactly the same. We now show that if such a solution exists, it is unique. Define 
Ad(S, m) to be the difference between the one­ phase cost, and the two-phase cost associated with split­ 
ting s evenly. Then Ad(s, m) = Pd(S, ? n) Ad(s, S/2, n) = Pd(S, m) zPd(S/z, m) = (2s -1)(A + 2d- mr 
+ 6) + 2dpm + Q(d) 2(2 /2 1)(A + 2d- /2mT +6) 2(2dpm + Q(d)) n (2 2J/ + )(A + 6) +(2k/Z+l _ 2d- )m7 
+ K, where K is constant. We are interested in the behavior of this function in the region where s ~ 
2 (because of the ultimate discrete application we cannot split fewer than two dimension indices!), and 
where (A+ti)/(mr) z 2d-S (because a one phase spanning ofs is known to be optimal otherwise). Taking 
the derivative with respect to s we obtain $&#38;(S, m) (In 2) ((2 2 @)(A + 6) (2~- /2 2d- )rnT) 
. If the derivative is positive in the region of interest, then Ad(s, m) = O at most once in that region. 
NOW +A~(s, rn) >0 ~ (2 S /2)(A + 6) > (Zd- /2 _ zd-~ )?7U > zd-./2 * A+ti 2* 2s/2mr 2d-s 2d-s(:::Lv 
 But this lsst inequality holds in the region of interest, since (~ + 6)/(mr) ~ 2d-S, and the coefficient 
of 2d-S . above is less than one. s+, if it exists, is unique. Now consider the existence of S*. Simple 
algebra re­duces the problem of solving Ad(s, rn) = O ins to solving ~+6=2d (1+2-s-2-s/2+1)+:+= mr 2 
2 /2+1 +1 ) ( The numerator of the right-hand-side decreases con­tinuously in s, while the denominator 
increases contin­uously. This implies that the right-hand-side achieves its largest value for the smallest 
s (= 2 in the region of interest) and its smallest value when s = d. The impli­cation is that s* exists 
when the left-hand-side is within certain bounds, given in the lemma below. Lemma 1 Let s be a posdive 
solution in s to Ad(s, m) = O. Then s exists, and is unique, if and on/y if 2d(:)+W Q(d) H_! <2q; +: 
+ )1+ Zd zd/2+1 + 1< rnr 4mT Furthermore, If (A + 6)/(mr) is iess than the lower bound above, then 
the DE algordhm is opttma! over al] posszble IWCE parameters.  If (A + 6)/(mr) is greater than the upper 
bound above, then the SE algorithm is optimal over all possible MCE parameters.  Ifs* exists, then s* 
~ ~ = d log2((A + 6)/(mr)).  We have thus shown that the decision problem of spanning an interval 
of length s with one or with two phases depends on the relationship of s to s*; s < s implies one phase, 
s > s* implies two. We can apply this result to try to improve any given continuous par­tition of d. 
If the partition has a subinterval of length # > s+, then that partition can be improved upon by replacing 
that interval with two subintervals, each hav­ing length x /2. It shows that if a partition of d has 
two subintervals ~i and Zj with xi + ZJ < s*, then that partition can be improved by replacing xi and 
XJ with one subinterval of length Zi + ~j. Thus, we have Theorem 2 Let s* be the sohdion m s to Ad(s, 
m) = O (when one exists). Then the optimal continuous partt­tion {xi} of d satisfies For alli andj, 
~i+~j~s*.  For alliandj, xi=  Xj. For aili,xi ~S*. There is an immediate corollary for the discrete 
problem Corollary 1 Let s* be the untque solution to Ad(S, m) = O (when one exists). Then the optimal 
discrete partition {di} of d satasjies For alliandj, di+dj~ls*J.  Foralii and j, Idi djl ~ 1.  For 
all i, d; ~ [s*1.  Returning to the discrete problem, we infer that for the largest subinterval size 
dmax in the optimal partition we have [s ] < d < ,S*, (3) 2 ax- This inequality can be used to limit 
the search for op­timal parameters. After solving for s* we consider only equi-partitions whose maximum 
element satisfies (3). There are no more than (s* + 1)/2 of these. However, when s* is large it may be 
more advantageous to search based on a bound on the optimal number of partition elements, as we next 
show. Let k be the number of intervals in the optimal par­tition. From Corollary 1 we observe that Ls*J 
/2 < d~,x. Furthermore, dmax < d/k* + 1, so that Using this and the fact that s* ~ ~ = d logz((~ + 6)/(mr)), 
we obtain the following results, Theorem 3 Let s* be the unique solution in s to Ad(S, m) = O (when one 
exists), let k* be the number of phases in the optimal A4CE algorithm, and let dmax be the largest element 
in the opt~ma! MCE partdion. Then and All the complete exchange algorithms discussed in this paper assume 
that pro cessors exchange messages ~W<2d+2 2di-2  in synchrony in such a way that contention is avoided. 
S* 1< d logz((~ + 6)/(mr)) 1 Some care must be taken on the iPSC/860 to ensure that Thus, the optimal 
MCE parameters can be found with no more than comparisons. This theorem provides insight into the behavior 
of the MCE algorithm. Of primary interest is the fact that the number of comparisons needed to find the 
optimal MCE parameters is O(m). Another interesting characteristic is the effect (both in direction and 
magnitude) that the communication parameters have on k s bound. As (A+ 6)/(m~) ranges from being small 
to being large, the upper bound on k* ranges from 2 to d. Small values of the ratio imply that startup 
costs do not dominate, and so intuition suggests that the DE algorithm will likely be best a small bound 
on k* is consistent with this notion. Similarly, when the parameter ratio is large, startup costs are 
important and need to be avoided. Values of k approaching d are then expected, consistent with the observation 
that SE minimizes startup costs. Experimental Results The MCE algorithm haa been implemented on the 
In­tel iPSC/860 hypercube. In this section we discuss the salient features of the implementation, identify 
the ap­propriate communication parameters, and validate the analytic model. The iPSC/860 has several 
idiosyncrasies that affect our problem. One is a selection of message types, either FORCED or UNFORCED. 
A message of type FORCED is discarded upon its arrival if the application has not yet posted a receive 
for it. A message of UNFORCED type is stored in a system buffer if it arrives and no receive has yet 
been posted. The buffered message is copied from system space to user space when the appli­cation posts 
the receive. Another characteristic is that messages of 100 bytes or fewer are treated differently than 
larger messages. For the smaller messages it is always assumed that the receiving processor has suffi­cient 
buffer storage to receive the message; for larger messages the system first reserves space in the receiving 
processor, prior to issuing the message. When the inter­communication pattern is fully known before runtime, 
as is the case for complete exchange, suitable receives can be posted at all processors before communication 
begins, and the more efficient FORCED type can be used. Our implementation does so. this happens. A 
receive and a transmit occurring nearly simultaneously at a processor can proceed concurrently, while 
a short delay causes them to be carried out seri­ ally. This issue has been researched in detail [8], 
where it is shown that two processors can execute a pairwise exchange concurrently if the transmissions 
start simul­taneously. This synchronization can be achieved by us­ing a global synchronization before 
each exchange; but that is an expensive solution. It has been shown that a pairwise exchange is guar­anteed 
to proceed concurrently if the two processors involved first exchange a pair of zero byte pairwise synchronizat 
ion messages. The time for this p airwise synchronization is far less than the time for global syn­chronization 
and is negligible for moderate to large mes­sages. When using FORCED messages, it is essential for each 
processor to post receives for all expected mes­sages in the procedure at the very beginning, and to 
carry out a global synchronization after this. Omission of the global synchronization is fatal as it 
leads to mes­sages arriving before their corresponding receives have been posted and thus being discarded 
by the operating system. When using UNFORCED messages, it is possi­ble to omit the global synchronization 
step since these messages are stored by the operating system until the required receive haa been posted. 
We have found that FORCED types give better performance, despite the overhead of global synchronization. 
We use FORCED types for pairwise synchronization messages as well as for the actual data transfers. We 
post all receives for all messages before a global synchronization. For ex­ample, prior to a DE exchange 
in a subcube of dimen­sion di, each processor allocates space and posts receives for the 2d 1 messages 
it knows it will receive during this phase. To ensure that none of these anticipated messages are sent 
before the posts are completed, the processors engage in a global synchronization, and then perform the 
DE phase. Each step in this phase is com­prised of two messages: pairwise synchronization, and actual 
transfer. Similarly, prior to an SE step, each pro­cessor allocates a buffer for the message it knows 
it will receive, and then engages in a barrier to ensure that all posts have completed. The communicating 
processors synchronize pairwise, and then perform the transfer. When messages of the FORCED type are 
used and all receives are posted before transmission begins, we have measured the values of A and r as 
95. Opsec and 0.394 ~sec/byte, respectively. The value of 6 is 5. 15psec x d. The A value of a zero byte 
message is sig­ nificantly better, being 85.5psec . When using these parameters to predict the time 
required by the multi­phase algorithm, we must remember that each pairwise exchange is preceded by an 
exchange of zero byte syn­ chronization messages. Thus we have the efleciive val­ ues of A = 177.5psec 
and 6 = 10.3psecxcZ. Note that these times are significantly larger than those on newer parallel architectures. 
The point is that given these pa­ rameters, the analytic model predicts performance fairly well, and 
ought to predict costs on other architectures well so long as the basic underlying form of the message 
costs are similar. The time for a barrier synchronization is measured as Q(d) = 150dpsec . The time for 
data permutation is P = 0.54psec/byte-This is considerably slower than the time to transmit the data, 
because of the cost of com­ puting the permutation required. It may be possible to improve upon this 
figure by pre-computing permu­ tations, and/or using hand-coded assembly routines to optimize this task. 
Finally, we present measured timings for MCE on In­tel iPSC/860 hypercubes of dimension 5 and 6. Our 
timings are presented as plots in Figures 2 and 3, where we represent each partition as a set of lengths. 
For in­stance, (3, 3) identifies the partition with two elements, each spanning three dimension indices. 
The plots use the communication parameters given above, and are presented as a function of the message 
size m. With the exception of the SE plot (which was never optimal, for any message size), only those 
portions of a curve which are optimal for a given message block size are shown. For instance, in Figure 
2, the observed cost (not shown) for DE with 1 byte messages is approximately 7 msec; 1 byte messages 
are better communicated with an MCE algorithm with partition (2, 3). This particular MCE algorithm has 
lower cost than DE for all message sizes up to about 100 bytes, after which DE is better. There­fore, 
the graph exclude the DE plot for m < 100, and excludes the MCE plot for m > 100. Dashed lines on our 
plots indicate predicted values and solid lines show measured values. Predicted curves for the DE line 
are modified slightly by excluding costs not observed in the DE code. As is to be expected, the DE algorithm 
is always op­timal for large enough message block sizes. When d = FJ the partition (2, 3) is optimal 
for block sizes less than 100 bytes. For d = 6, two partitions are optimal: (3, 3), and (6). The last 
of these is optimal for message sizes beyond about 140 bytes. observe that at m % 32 the cost of DE and 
SE are equal, about 17 resee,. At this same point the optimal MCE algorithm costs only 8 msec, which 
is a factor of two performance gain. This can make a difference for algorithms whose cost is dom­inated 
by complete exchange. 0014 ­ 0.012 ­ -Z­% ~ 0.010 ii ~ 2 . + 0,008­ 0,006­ 0.004­ 0 100 200 300 400 
Messoge Size (bytes) Figure 2: Performance of the multiphase algorithm for a 32 node (d = 5) Intel iPSC/860. 
Solid lines indicate measured values; dashed lines are predicted. Only re­gions of curves that are optimal 
are shown, except for the Standard Exchange (1, 1, 1, 1, 1), which is never op­timal. 0.030 0.025 ~ 
o 020 : 8 ~ : c 0.015 0010 0 005 Message Size (bytes) Figure 3: Performance of the multiphase algorithm 
for a 64 node (d = 6) Intel iPSC/860. Solid lines indicate measured values; dashed lines are predicted. 
Only re­ gions of curves that are optimal are shown, except for the Standard Exchange (1, 1, 1, 1, 1, 
1), which is never opt imal. In all cases there is good agreement between pre­dicted and measured results. 
The agreement is not perfect, since the performance characteristics of the [8] real iPSC/860 are much 
more complex than this sim­ple model. Nevertheless, the model is good enough to provide us with algorithms 
that can lead to substan­tial measured improvement which is of great practical relevance, given the ubiquity 
of the complete exchange pattern. [9]   5 Conclusions This paper has analyzed the multiphase algorithm 
for complete exchange, and other communication primi­tives, on a circuit-switched hypercube multiprocessor. 
Using a standard model of message-passing costs, we characterized the optimal multiphase algorithm as 
hav­ing phases that are all almost the same size . We fur­ther restrict the optimal solution to a set 
of no more than 2(W + 1) possibilities. The model was validated on an Intel iPSC/860, where we observed 
that perfor­mance gains in excess of a factor of two are possible over the Standard Exchange and Direct 
Exchange algo­rithms. References [1] S. H. Bokhari. Multiphase complete exchange on a circuit switched 
hypercube. In Proceedings of the 1991 Int ! Conference on Parai!ei Processing, pages 525 529, August 
1991. [2] S. H. Bokhari. Multiphase complete exchange: A theoretical analysis. ICASE Technical Report 
93­64, August 1993. [3] L. Bomans and D. Roose. Benchmarking the iPSC/2 hypercube multiprocessor. Concurrency: 
Practzce and Experience, 1(1):3 18, September 1989. [4] J. Douglas and J. E. Gunn. A general formulation 
of alternating direction methods. Numer. Math., 6(5), 1964. [5] S. Lennart Johnsson and Ching-Tien Ho. 
Matrix transposition on boolean n-cube configured ensem­ble architectures. SIAM J. Matrtz Anal. Appl., 
9(3):419-454, July 1988. [6] Richard B. Pelz. The parallel Fourier pseudospectral method. J. Comp. Phys, 
92(2):296 312, February 1991. [7] Thomas Schmiermund and Steve R. Seidel. A com­munication model for 
the Intel iPSC/2. Technical Report CS-TR 9002, Dept. of Computer Science, Michigan Tech. Univ., April 
1990. Steve Seidel, Ming-Horng Lee, and Shivi Fotedar. Concurrent bidirectional communication on the 
In­tel iPSC/860 and iPSC/2. Technical Report CS-TR 9006, Dept. of Computer Science, Michigan Tech. Univ., 
November 1990. Steve R. Seidel. Circuit switched vs. store­and-forward solutions to symmetric communication 
problems. In Proc. ~th. Conf. Hypercube Concurrent Computers and Apphcations, pages 253-255, 1989.  
			