
 Passage Retrieval Revisited Martin Kaszkiel Justin Zobel Department of Computer Science, RMIT GPO Box 
2476V, Melbourne 3001, Austrdla {marciqjz}t%a.rmit. edu.au Abstract Ranking based on passages addresses 
some of the short­comings of whole-document ranking. It provides convenient units of text to return to 
the user, avoids the difficulties of comparing documents of different length, and enablea iden­tification 
of short blocks of relevant material amongst other­wise irrelevant text. In this paper we explore the 
potential of passage retrieval, based on an experimental evaluation of the abMy of passages to identify 
relevant documents. We compare our scheme of arbitrary passage retrieval to several other document retrieval 
and passage retrieval methods; we show experimentally that, compared to these methods, rank­ing via fixed-length 
passages is robust and et%.ctive. Our experiments also show that, compared to whole-document ranking, 
ranking via fixed-length arbitrary psssagea signif­icantly improves retrieval effedivenees, by 870 for 
TREC disks 2 and 4 and by 18%-37% for the Federal Register col­lection. Introduction Text retrieval 
methods are typically deeigned to identifj whole documents that are relevant to a query. In these ap 
proachee a query is evaluated by using the words and phrases in each document-the index terrne to compute 
the simi­larity of document and query, without regard to the location or proximity of the index terms 
within the document. An alternative approach is to regard each document se a set of passages and to compute 
the similarity of each passage to the query [2, 5, 7, 8, 12, 14, 17], where a passage is a con­tiguous 
block of text in the original document. The units retrieved can then be the documents fkom which the 
meet Permission to maka digitalhard copies of all or part of IMs matarial fw parmnalcx~ wketitifmptiddtit 
iqim aladvantage?~ @PY­ arenotmadeor dialributad fakmfdw~ ri@t notice, the title of the publiion and 
its date ame=. andnoticck givenm mpyri$t isby permission of the ACM, inc.To copy otbmvk% to republish 
to peat on servers or to redktribute to lists, requires specific parlnissioll SniLforf=  SIGIR 97 Philadelphia 
PA, USA @@8bt 1997 ACM O-89791 -836-3 B7~..$3.5O similar psmagee are drawn+ thatpassagesprovide an 
al­ternative mechanism for whoblocument ranking-a can be the paeeagea themselves. Pamage retrieval has 
several potential advsntagee. First, since passages are relatively short, they embody locality: if the 
query terms occur together in the passage they must be fairly close to each other. In whole-document 
ranking, on the other hand, the relevance of a passage maybe obscured by low relevance overall. Second, 
paseagee are more conve­nient to the user than long documents, and in cases such as collections of transcripts 
there may be no clear separation of the text into discrete parts; that is, the concept of doc­ument doea 
not apply. Third, when used se a mechanism for document retrieval, passages can avoid the difkultiea 
of document length normalisation, that is, of appropriate die­crirnination of simihtrity between long 
and short documents. Some meammeetend to favour short documents and thus can be ineffective for collections 
of doeumente of mixed lengths, whereas for fixed-length passages the problems of normali­sation are less 
significant and overall document leng$h is not a consideration. Fourth, it can be argued that a document 
with a short passage with a high density of words match­ing a query is more likely to be relevant than 
a document with no such passage, even if the latter contains a reasonable number of matching words across 
its kmgth and has higher similarity overall. There are, however, some potential difficulties with pss­sage 
retrieval. The greater number of items to rank means that retrieval may be more computationally expensivq 
for schemee in whkh paeesga are of varying length, the issue of length normalisation rernairq passage 
ranking may neglect relevant documents with no highly similar paaeagq and pas­sage retrieval requires 
a reliable, robust method for deriving paseagw from documents. There have been several recent propoeals 
for retrieval based on passages, based on division of docunwds according to units such as sections [12, 
14], paragraphs [17], or fixed­length sequences of words [2], or according to bcnmdsriea given by inferred 
shift of topic [5, 7, 8]. We chose to fur­ther explore paesage retrieval by experimentally examining 
a scheme in which every word is the start of a set of passages, thus extracting large numbers of passegee 
from every docu­ 178 rnent. By this scheme, arbitm~ passage retrieval, we hoped to identify the beet-poeaible 
performance improvement avail­able from passage retrieval, and to identify promising direc­tions for 
practical, effective passage retrieval schemes. In this paper we compare arbitrary passage retrieval 
to other passage retrieval schemes and to methods for whole­document retrieval (extending our results 
presented at the moat recent round of TREC experiments [6]). These re­sults show that, compared to the 
beet whole-document re­trieval scbrne we tested, arbitrary passage retrieval can yield significant improvements 
for collections of long doc­uments, of up to 37% for our teat data. They also show that fixed-length 
arbitrary psessges give better effective­ness than paesegm baeed on semantic properties of docu­mente. 
Additionally, the results confirm that pivoting for document length normalisation [13] gives substantial-and 
in some CaMSdramatic-improvements in performance. Sirnilmity measures for document ranking are discuamd 
in Section 2. In Section 3 we review previous passage re­trieval schemes and introduce our approach to 
passage re­trieval in Section 4. Experimental results are presented in Section 5. Addressing the question 
of efficiency, in Section 6 we use our experimental reeulta to suggest possible passage retrieval schemes 
and out~me an efficient query evaluation mechanism. Conclusions are presented in Section 7. Document 
ranking A ranked query is evaluated by using a similarity function to compute a numerical score for each 
document in the ccd­lection with rwpect to the query. The documents with the hlghe&#38; such similarity 
are then retrieved for presentation to the user. Good choice of similarity !imction is essential for 
etfective ranking. A function that has proved reliable in decades of experimentation is the cosine measure 
[3, II]. One effective i%xrnulation of the cosine measure can be defined as where q is a query, d is 
a document, he= U.ld,t = ]og(~d,t+ 1) , Wq,t = log(fq,f + 1) . log(N/fi + 1) , the value f=,tisthe frequency 
of term tin z, there are N documents, ft isthe number of d~tinct documents contain­ing t, and the expression 
log(fV/ ft+ 1)isthe inverse docu­ment t%equency. We call this formulation C-standan.f. The divisors W. 
are known SEthe length of z. Dlvieion by Wq is in practice unnecemary because it is a constant for each 
query and has no &#38;ect on the rankin~ without division by Wd, however, long documents would be favoured 
over short, simply because they contain more terms and thus are likely to have a higher value for the 
numerator. The above formulation, although reasonably effective, does have a drawback: it tends to favour 
retrieval of short documents, while analysis of the TREC data [4] (which wn­tains a mix of document lengths) 
indicates that length is positively correlated with relevance [13]. Explicit use of this Corrdation provides 
a correction factor for Wd that can be formulated as w: = (l.o-s)+s. #L an where S is a slope and Wav 
is the average wd over atl d. We call the cosine measure incorporating the modified doc­ument length 
C-~ vot. The experiments of Singhal et al. [13] demonstrate that pivoting can yield significant improvements 
in &#38;activeness. The coeine measure with pivoted hmgth normalisation provides a natural baseline for 
evaluating the performance of passage retrieval, since it is known to be reasonably effective and there 
are straightfbrward algorithms for evaluating it efficiently [3, 9, 10, 13]. In Section 5 * experimentally 
compare C-standard and C-pivot. 3 Passage retrieval Passage retrieval is in principle similar to document 
retrieval, but involves the additional, preliminary stage of extract­ing passages from documentq the 
extraction mechanism de­pends on how the concept of ~aamge is defined. Given the passages, query evaluation 
proceeds as for document re­trievak a similarity function is used ta score each passage against the query, 
then the highest-ranked pasaag~r the documents containing those passages-are retrieved. Several definitions 
of passage are describedin recent vmrk. WMnson [14] suggests that document markup (that is, logi­cal 
structure) be used to delimit passages-or sections-and explores both the ability of sections to select 
relevant docu­ments and the use of similarity functions to select relevant sections. Although in these 
experiments the efkctivenees of structure as a basis for whole-document retrieval was mixed, the result.ashowed 
some of the other predicted advantages of passage retrieval to hold: for example, sections do provide 
a valuable mechanism for identifying the intereating parta of long documents. Salton et al. [12] also 
suggeeted using markup as paswgea (in thw case sections, paragraphs, and sentences) in a tw~pam method 
in which passagee are used to refine the ordering of documents whose rank exceeds a threshold. Thew results, 
despiti the threehold that may exclude long documents with only a small block of relevant material, show 
that use of pssaagea can significantly improve effectiveness. Zobel et al. [17] suggeet that passages 
be obtained by par­titioning documents into disjoint segments of roughly equal length. In these experiments 
the passages-or poges-were generated by gathering together adjacent paragraphs until each agglomeration 
was at least some fixed number of bytes. Thus each page boundary always coincides with a paragraph boundary. 
These experiments showed that retrieval based 179 on pages with minimum length in the range 1000-2000 
b­(or roughly 150-300 words) was significantly more effective than whol-document retrieval. As for Wflkinson 
s exper­iments, theee results were baaed on the Federal Regieter (FR) subcollection of TREC, which contains 
many long doc­uments. Hearst and Plaunt [5] suggest that passagea consist of sequences of sentences, 
where the boundaries between paas­ages-or tiles-are determined by automatically-detected shifts of topic. 
These shifte were identified by comparing a@cent blocks (sequences of a fkw paseageaeach) for sim­ilarity 
and applying a threshold. Blocks were preferred to paragraphs because the latter are highly irregular 
in length (a problem noted in the experiments of ZobeJ et al. [17], who broke long paragraphs after 5000 
bytes). These exper­iments also found blocks to be superior to partitioning doc­uments into diejoint 
fixed-length sequences of words. Mit­tendorf and Schauble [7, 8] also auggeatuse of infixred pas­sage 
boundaries, employing a hidden Markov model to de tennine passages appropriate to each qumy. This approach 
requires processing of the full text to evaluate a query, but doee demonstrate the ability of passage 
ranking to improve effectiveness. Most of these methods rely on semantic or stmctural fea­tures of documents 
(albeit, in some cases, low-level elemente suchasparagraphsorsentemms),but itisnot alwayseasy to identify 
these featurea. Moreover, they are all vulnerable to problems with length normalisation: sections and 
tiles can be of any length and, even with the minimum-length constraint, pagea can vary somewhat in sise. 
An alternative that doea not have these problems is pro­posed by CalIan [2]. In this approach, passagea-or 
win­dows-are determined at query evaluation time rather than in a preprocessing stage, and are of a fixed 
number of words. The middle of each window is the origin of the next, so that each window overlaps with 
exactly two othera (other than at document boundaries). The tlrst origin is determined by the location 
of the !lrst identified occurrence of a query term in each document. This approach allows ready extraction 
of passages, but it is at least plausible that, because semantic properties are disregarded,effectivenesswiIldegrade. 
Note that length norrmdiiation is not a problem for such &#38;ed-length passages. Although the formulation 
of wd in C­standard will yield different values for dMwent passagead, most wd valueafor fixed-length 
pasesgeewould be expected tofallintoanarrowrange. Moreover,useofapproximations to wd such as the square 
root of the number of term occur­rences doee not have a significant impact on ef&#38;tivenesa­and in 
this context, such approximations yield the same value for cdlpaasagea. Aspart of ourreviewof passageretrievalmethodsweex­perimentally 
compare sections, pagee, tiles, and fixed-length passag-inSection5. Ourinveetigationofthesemethodsin­dicated 
some shortcmni~. Not unexpectedly, C-standard tended to favour short paeaag~a particular problem for 
passagesdefined aa sections, which can be of only a few words-and so we also used C-pivot. Other potential 
prob­lems are that, with pages, a topic can be split so that no P-Contti enoughofthe query terms to earn 
a high rmdq and that, with tiles, aiithonghthe splitting method is reasonably reliable, a good division 
into paseagee for one query maynot be appropriate for another. 4 Arbitrary puwage retrieval Previous 
work on paaaage retrieval, and our experimental remdtewith these approached,shows that passageacan im­prove 
effectivermmbut doea not clearly identi&#38; a best kind of passage. Nor is it clear whether the limits 
of passage retrieval have been reached. Rather than simply propose and test yet another mechanism for 
extracting pammgea,we decided to exp@mentaUy explore the limits of passage re­trieval. Inprinciple,thepassageextraction 
mechanismwewished to use was to allow any sequence of words of any length start­ing at any word in the 
document to be a valid m-bitnwypas­sage. The similarity of the highest-rankedsequence of words, from 
anywhere in the document, would-using passages to rank documente-be the document s similarity. The inten­tion 
of this approach is not to provide a practical retrieval mechanism, but to evaluate the pertbrmance of 
passage re trieval more or less independent of the deilnition of passage and then, hopefully, to derive 
principles on which practictd passage retrieval might proceed. Note, however, that arbi­trary p~agea 
will not perfectly achieve this aim, for two reasons length normalisation difficulties must be rmolv~ 
and it is feaeiile that semantically-derived paeeagee (of, for example, sequences of paragraphs) will 
yield greater e&#38;c­tiveneaa,since it is plausible that a highly-ranked arbitrary passage is lem likely 
to indicate relevance than, say, a lees highly ranked tile. Given unlimited reeourcea, arbitrary passage 
retrieval would proceed by, for each document, extracting the passage of every length starting at every 
word; then computing the similarity of every such passage to the qu~ then ranking documents according 
to their higheet-rankedpassage. How­ever, a document of 1000 words wuuld yield approximately 500,000 
passag~, 10,000 words would yield 50,000,000 pas­sagee. Th~ is somewhat impractical. As an approximation 
we chose a set of fixed passagelengths-from 50 to 600 words in increments of 50, yielding twelve different 
lengths-but still allowed pasaageato start at every word in each docu­ment, and, by not using lengths 
smaller than 50 worda, we hoped to contain the problems of length nmmalieation. A documentof 1000wordathusyieldedabout 
8,100passages, 10,000words about 116,100passages. Pamageeof 600 words seemed a reasonablemaximum asthisfigurewellexceeds 
the median document length in TREC. Fbr each passage length we kept the highest similarity value for 
each document, or twelve valuee per document overall. (The passages are cre­ated on the %y,compared to 
every query, and discarded. A runwith2gigabyteaof text and50queriestakeaabout one week on a SPARC 20.) 
Given adefinitionof passage,wemustchoose asimilarity measure. Since cosine is known to work well for 
ranking text in general, it should work well fir passages. We initially used C-standard in our experiment 
with pam~, but did not adopt the strict definition of inverse document frequency aa to do so would have 
involved somewhat dubloua choices for ~t ~d ~; inste~ ws computed ftand~ aSif the database was a collection 
of documents. When comparing passages of dtierent length, it ia clear that normalisation is problematic. 
For fixed-length pw SW-, having around 150 to 350 words per passage pro­vided the beet overall performance, 
as shown in the next section. But for C-standard over 95% of the top-ranked pas­sages wwre of 50 words-evidence 
that length normalisation is poorly formulated. We therefore investigated other ap­proached to normalisation. 
One was the pivoted document length normalisation discussed above [13]. Formally it is in­applicable 
(it requires averages over all units of retrieval in the collection, which is not meaningful in this 
context) but Singhal et al. have argued that the length formulation w; = (l.o-s). L+s. ud ia reasonably 
robust, where S is the slope, L is a pivot or average length, and ud is the number of unique terms in 
passage d. We used S = 0.2, as recommended, and L = 300 worda as a typical paeaage length, giving a version 
of C-pivot applicable to arbitrary passages. Another approach to normalisation is to standardise the 
similarities for each query and passage length. By, for each passage length, dividing each similarity 
by the highest aimi­kwity for that passage length, similarities from different paa­sage lengths can in 
ettkct be compared according to their ranking amongst psesagea of the same length. (In a practi­cal implementation 
this information would not be available, but should it be successful it would provide a direction in 
which to search fbr better solutions to this problem.) We call this approach C-scaled. Other experiments 
have shown that airnh-ity valuee from P--drawn from a document can be combined to yield an overall similarity 
for the document, resulting in improved effectiveness [2, 5, 12, 14]. We have not explored such op tiona 
in our experiments, but plan to do so in future work. Experimental results We used experiments to compare 
similarity functions and definitions of paasage. The WI set of similarity functions and passage typea 
used was as follows. C-standard was ap plied to full documen~ to pagea of 2000 bytes; to para­graph, 
to aectionq and to tiles. C-pivot waa also applied to each of these, using S = 0.7 as it gave the beat 
reauha on our first data set. C-standard was applied to Windov and to axbltrary passages of each of the 
twelve lengths separately, to identify which passage length worked best. (C-standard and C-pivot give 
virtually identical reaulta for fixed-length passages because there is little variation in w.. vahm.) 
C­standard, C-pivot, and C-scaled were then applied to paa­sagea of all lengths together; in these experiments 
a passage of any of the twelve lengths can determine the rank of a doc­ument. Documents were ranked according 
to their higheet­ranked passages. We used exhausti~ranking code to ex­plore arbitrary passage retrieval; 
used the publicly-available MG text database system [1, 16] for the other experiment and used the publicly-available 
TextTiles code [5] to gener­ate tilea. We used three data sets, focueaing on the Federal Reg­ister (FR) 
collection because we would expect the greatest improvement to come from databaaea of long documents. 
The first data set was the FR data from TREC disks 1 and 2 and the 21 queries between 51 and 100 that 
had at least one relevant document in FR. This data set was used for developing the passage ranking techniques-to 
set pa­rameter values and so on. The second data set was the FR data from disks 2 and 4 and the 26 queries 
between 251 and 300 that had a relevant document in FW, these are blind experiments from the most recent 
round of TREC, but with results drawn from the FR data on]y. The third data set was the full contents 
of duks 2 and 4 and queries 251-300, that is, the most recent TREC run. In all thaw experiments we used 
the full queries. F@ulta for the first data set, FR from disks 1 and 2, are shown in 1 hble 1. We have 
regarded C-pivot applied to whole documents as the baseline; percentage changes from this baseline are 
shown in the last column. The second-last column showa eleven-point recall-precision figures, measured 
over the top 1000 documents retrieved. Pages of 2000 bytes and windowa are the most e&#38;c­tive of the 
previous methods, considerably improving on C-standard and C-pivot. Slightly better again was fixed­length 
arbitrary passages of 150-350 words, the most ef­fective performance observed for fixed-length pasaageq 
we show results for a selection of lengths but all lengths in ex­ cess of 100 worda worked well. Interestingly, 
there was no clear correlation between successful paaaagea (that ia, pas­sages that correctly identified 
a document as relevant) and semantic markup such as paragraph or sentence boundaries. That is, semantic 
information does not appear to add value to ranking via passages. Variable-length arbitrary passages 
slightly outperformed fixed-length arbitrary pasaagea, but by a disappointly small margin. These results, 
by focuaeing on a collection of long docu­ments, emphasise the improvements available through piv­oting 
document length normalisation. Whole-document re trieval improves by 17%; for paragraphs, performance 
im­proves by 35%; and for sections, where lengths are as small as a few worda, effectiveness improves 
by a remarkable 184Y0. In contrast, for pag=, where length variation is relatively smaI1, pivoting has 
little effect. These experiments provide strong confirmation that pivoting is effective. Reaulta for 
the second data set, FR from diska 2 and 4, are shown in Table 2. The strongeat previous method wae­by 
a large margin-windowa, and as before pivoted docu­ment length normalisation haa improved effectiveness. 
Win­dows and tked-length arbitrary passages of 150 words or more dramatically outperformed the other 
methods includ­measure. Since cosine is known to work well for ranking text in general, it should work 
well fir passages. We initially used C-standard in our experiment with pam~, but did not adopt the strict 
definition of inverse document frequency aa to do so would have involved somewhat dubloua choices for 
 ~t ~d ~; inste~ ws computed ftand~ aSif the database was a collection of documents. When comparing passages 
of dtierent length, it ia clear that normalisation is problematic. For fixed-length pw SW-, having around 
150 to 350 words per passage pro­vided the beet overall performance, as shown in the next section. But 
for C-standard over 95% of the top-ranked pas­sages wwre of 50 words-evidence that length normalisation 
is poorly formulated. We therefore investigated other ap­proached to normalisation. One was the pivoted 
document length normalisation discussed above [13]. Formally it is in­applicable (it requires averages 
over all units of retrieval in the collection, which is not meaningful in this context) but Singhal et 
al. have argued that the length formulation w; = (l.o-s). L+s. ud ia reasonably robust, where S is the 
slope, L is a pivot or average length, and ud is the number of unique terms in passage d. We used S = 
0.2, as recommended, and L = 300 worda as a typical paeaage length, giving a version of C-pivot applicable 
to arbitrary passages. Another approach to normalisation is to standardise the similarities for each 
query and passage length. By, for each passage length, dividing each similarity by the highest aimi­kwity 
for that passage length, similarities from different paa­sage lengths can in ettkct be compared according 
to their ranking amongst psesagea of the same length. (In a practi­cal implementation this information 
would not be available, but should it be successful it would provide a direction in which to search fbr 
better solutions to this problem.) We call this approach C-scaled. Other experiments have shown that 
airnh-ity valuee from P--drawn from a document can be combined to yield an overall similarity for the 
document, resulting in improved effectiveness [2, 5, 12, 14]. We have not explored such op tiona in our 
experiments, but plan to do so in future work. Experimental results We used experiments to compare similarity 
functions and definitions of paasage. The WI set of similarity functions and passage typea used was as 
follows. C-standard was ap plied to full documen~ to pagea of 2000 bytes; to para­graph, to aectionq 
and to tiles. C-pivot waa also applied to each of these, using S = 0.7 as it gave the beat reauha on 
our first data set. C-standard was applied to Windov and to axbltrary passages of each of the twelve 
lengths separately, to identify which passage length worked best. (C-standard and C-pivot give virtually 
identical reaulta for fixed-length passages because there is little variation in w.. vahm.) C­standard, 
C-pivot, and C-scaled were then applied to paa­sagea of all lengths together; in these experiments a 
passage of any of the twelve lengths can determine the rank of a doc­ument. Documents were ranked according 
to their higheet­ranked passages. We used exhausti~ranking code to ex­plore arbitrary passage retrieval; 
used the publicly-available MG text database system [1, 16] for the other experiment and used the publicly-available 
TextTiles code [5] to gener­ate tilea. We used three data sets, focueaing on the Federal Reg­ister (FR) 
collection because we would expect the greatest improvement to come from databaaea of long documents. 
The first data set was the FR data from TREC disks 1 and 2 and the 21 queries between 51 and 100 that 
had at least one relevant document in FR. This data set was used for developing the passage ranking techniques-to 
set pa­rameter values and so on. The second data set was the FR data from disks 2 and 4 and the 26 queries 
between 251 and 300 that had a relevant document in FW, these are blind experiments from the most recent 
round of TREC, but with results drawn from the FR data on]y. The third data set was the full contents 
of duks 2 and 4 and queries 251-300, that is, the most recent TREC run. In all thaw experiments we used 
the full queries. F@ulta for the first data set, FR from disks 1 and 2, are shown in 1 hble 1. We have 
regarded C-pivot applied to whole documents as the baseline; percentage changes from this baseline are 
shown in the last column. The second-last column showa eleven-point recall-precision figures, measured 
over the top 1000 documents retrieved. Pages of 2000 bytes and windowa are the most e&#38;c­tive of the 
previous methods, considerably improving on C-standard and C-pivot. Slightly better again was fixed­length 
arbitrary passages of 150-350 words, the most ef­fective performance observed for fixed-length pasaageq 
we show results for a selection of lengths but all lengths in ex­ cess of 100 worda worked well. Interestingly, 
there was no clear correlation between successful paaaagea (that ia, pas­sages that correctly identified 
a document as relevant) and semantic markup such as paragraph or sentence boundaries. That is, semantic 
information does not appear to add value to ranking via passages. Variable-length arbitrary passages 
slightly outperformed fixed-length arbitrary pasaagea, but by a disappointly small margin. These results, 
by focuaeing on a collection of long docu­ments, emphasise the improvements available through piv­oting 
document length normalisation. Whole-document re trieval improves by 17%; for paragraphs, performance 
im­proves by 35%; and for sections, where lengths are as small as a few worda, effectiveness improves 
by a remarkable 184Y0. In contrast, for pag=, where length variation is relatively smaI1, pivoting has 
little effect. These experiments provide strong confirmation that pivoting is effective. Reaulta for 
the second data set, FR from diska 2 and 4, are shown in Table 2. The strongeat previous method wae­by 
a large margin-windowa, and as before pivoted docu­ment length normalisation haa improved effectiveness. 
Win­dows and tked-length arbitrary passages of 150 words or more dramatically outperformed the other 
methods includ­ Precision at N documents Avg. %A 5 10 20 30 200 prec. C-standard: Documents 0.2222 0.2333 
0.1595 0.1540 0.0724 0.2434 -14.7 Paragraphs 0.2540 0.2190 0.1833 0.1603 0.0621 0.2227 -22.0 Pagea 0.2619 
0.2619 0.2214 0.1905 0.0688 0.3278 +14.9 sections 0.1302 0.1143 0.1286 O.NOO 0.0424 0.0891 -68.8 Tiles 
0.2349 0.2238 0.1929 0.1635 0.0650 0.2692 -5.6 Gpivot: Documents 0.2556 0.2238 0.1714 0.1571 0.0667 0.2852 
0.0 Paragraphs 0.2651 0.2333 0.2071 0.1810 0.0664 0.3013 +5.6 Pagea 0.2651 0.2571 0.2238 0.1921 0.0700 
0.3224 +13.0 Sections 0.2429 0.2238 0.1905 0.1619 0.0645 0.2533 11.2 Tiles 0.2413 0.2333 0.2119 0.1841 
0.0629 0.2805 -1.6 Wlndoww 150 words 0.2508 0.2476 0.2167 0.1905 0.0731 0.3213 +12.7 350 worde 0.2984 
0.2905 0.2333 0.1984 0.0731 0.3391 +18.9 Fixed-length arbitrary pzwages 50 words 0.2460 0.2238 0.1929 
0.1698 0.0724 0.2789 -2.2 150 words 0.2587 0.2667 0.2238 0.1984 0.0743 0.3364 +18.0 250 words 0.2794 
0.2714 0.2286 0.2000 0.0755 0.3432 +20.3 350 words 0.2762 0.2714 0.2405 0.2048 0.0748 0.3413 +19.7 450 
words 0.2698 0.2476 0.2357 0.1889 0.0738 0.3280 +15.0 Variabldength arbitrary pasaage$x C-standard 0.2508 
0.2333 0.2024 0.1714 0.0712 0.2953 +3.5 C-pivot 0.2635 0.2524 0.2143 0.1921 0.0743 0.3304 +15.8 c-scaled 
0.2587 0.2429 0.2262 0.1936 0.0745 0.3487 +22.3 Table 1: Experiments with FR, dish 1 and 8, queries 
selected from 51-100. ingC-standardandC-pivot. Wehavealsoshownresultsfor arbitrary pasaageaof 350 worda. 
Variabl&#38;length passage re­trieval has not been as successful as hoped, because of the difficultiesof 
comparing the similaritiesof passsgeeof diiFer­entlengths. InparticularC-scaledhasnotworkedwell;ssit 
does not appear to be suited to practical document retriewd we have not investigated it further. The 
behaviour predicted by the 6rst data set-that win­dows and tied-length and vsriable&#38;ngth arbitrary 
psaaage retrieval are the moat efective ranking methods-ii sub­stantially confirmed. That is, our exploration 
shows that tied-length passage methods such as windows are, as sug­gested by earlier results [2], highly 
effecti~ and that signif­icant further improvements via pasaageado not appear to be available. However, 
this does not exclude improvement using technique such as combination of passage-level and document-level 
evidence. R.eeultafor the third data set, the full contents of disks 2 and 4, me shown in Table 3. We 
would not expect pas­sage retrieval to result in large improvements on this data set, since most of the 
documents are fairly short. (Al­though C-pivot is fairly etfective we have not applied any refinements-phrase 
extraction and so on that might yield increased eilectivenas. However, such refinements are, we believe, 
orthogonal to pssaage retrieval.) But we expectd passages to perform at least as well as C-standard or 
C­W uot. As can be seen, variable-length passages have not workedwell,but fixed-length arbitrarypassageeimproveef­fectiveneaeby 
around 8%. Other psmage techniques have not performed as well. Indeed, over the series of experi­ments 
none of the previous techniques has been consistently efTective,with even the better methods performing 
poorly in some caees. In contrast, freed-length arbitrary passages haveprovedrobust, workingatleastreasonablywellinevery 
experiment. The results in th~ section ahow that fixed-length srbi­trarypassageaareaneilkctive,reliablemechanismfor 
docu­ment ranking, significantly improving on preview methods. We now consider whether arbitrary pssaageaare 
practical. 6 Practical passage retrieval Arbitrary passages,of either tixed or variable length, present 
considerable problems for practical query evaluation. A par­ticular difficulty in either case is the 
number of distinct enti­ties to be rrmked. In traditional ranked query evaluation [3], an accumulator 
is allocated to each document in the cOWc­tion. As the query terms are procemed, the accumulator of each 
document containing each query term is updated so that at any stage it holds a partial sum repmaenting 
the numerator in the cosine measure. At the completion of pro­ceaeing of query terms the accumulators 
are normalised by Precision at N documents Avg. %A 5 10 20 30 200 prec. Cstandard: Documents 0.1613 0.1423 
0.1135 0.1051 0.0308 0.1534 -12.6 Pages 0.1436 0.1385 0.1115 0.1000 0.0275 0.1549 -11.7 Tiles 0.1603 
0.1577 0.1192 0.0974 0.0267 0.1817 +3.5 C-pivot: Documents 0.1859 0.1731 0.1212 0.0897 0.0287 0.1755 
0.0 Pages 0.1615 0.1577 0.1269 0.1077 0.0288 0.1881 +7.2 riles 0.1590 0.1654 0.1327 0.1038 0.0288 0.1922 
+9.5 Wlndowa: 150 worde 0.1974 0.1808 0.1308 0.1090 0.0275 0.2428 +38.3 350 worda 0.1897 0.1846 0.1231 
0.0949 0.0275 0.2187 +24.6 Fixed-length arbitrary passages: 150 words 0.1936 0.1731 0.1346 0.1115 0.0281 
0.2416 +37.7 350 words 0.1923 0.1731 0.1288 0.0987 0.0275 0.2219 +26.4 Variablelengt.h arbitrary passages 
C-standard 0.1949 0.1846 0.1385 0.1039 0.0288 0.2002 +14.1 C-pivot 0.1872 0.1885 0.1365 0.1077 0.0277 
0.2268 +29.2 C-&#38;led 0.1821 0.1654 0.1327 0.1103 0.0308 0.1984 +13.0  Ihble 2: Ezpm ments with FR, 
di8ks 1?and ~, queti~ selected jivm 251-300. the respective document lengths, then a partial sort is 
used to extract the highest similarity values. Such an approach is impractical if each document con­tains 
thousands of pasaagea, and thus requirea thousands of accumulators However, for document retrieval effective 
neas is not degraded if the number of accumulators ie held to a small percentage, say 1%-5%, of the number 
of doc­uments [9, 10]. In these approaches accumulators are aUo­cated dynamically, as the query terms 
are processed, and only the moat significant terms are allowed to force cre­ation of an accumulator. 
In conjunction with appropriate reorganisations of index structures, these limited accumu­lator tilques 
can for whole-document retrieval reduce query evaluation times by a factor of five and memory re­quirements 
by a t%ctor of thirty. Such approached can be readily applied to passage retrieval. In the case of variable-length 
passages, however, query evaluation via thw method is still impractical because of the vaat numbers of 
items to be ranked. A poesible eolu­tion is to approach the problem in a different way: instead of ranking 
each distinct passage, partition each document into a sequence of tiny fragments of text-which might 
con­ceivably be as short aa a single word each-and accumulate information about thaw ihgrnents. When 
index process­ing is complete, the accumulators can be used to identify regions of high similarity, by 
identifying eequencea of sim­ilar fhgrnents. A related approach haa been successfully applied by Williams 
and Zobe.1to querying of nucleotide databases [15]. We therefore believe that such an approach is practical. 
What is not clear is ita eflbctivenese. We have not tasted aggregation of t%agrnents,but (given that 
similar­ity is not additive) it would yield an approximate similarity only, and the actual pasaageawould 
have to be retrieved, or the index data processed a second time, to compute passage airrdarit.ieqhowever, 
the aggregation scheme suggested by Hearat and Plaunt [5] maybe suitable. In the case of fixed-length 
passages, ranking using a limited-accumulator scheme may well be practical, with one passage for each 
word occurrence in the stored data. Should the memory requirements still be prohibitive, it would be 
poeeibleto allowpassagesto beseparatedby smallintervals, of say five words, or perhaps to start a passage 
at every sen­tencq at the potential coat of some impact on efktiveneas. In lhble 4 we show the results 
of retrieval with paasagea startedat intervala. Each line shows effectiveneaaof p-age retrievaJfor pasaaga 
starting at regular intervals, or start­ing with each aentencq the 1 word lines are copied from kble 
2. These resultsshow thatmoderate intervalshavelit­tle impact on effectiveness, but that performance 
degradea as the degree of overlap between passagea is decreased. A similar efkct can be seen in the other 
tables, where in all but one case windowa have performed slightly worse than arbitrary paaeageaof the 
same length. Starting a passage at every sentence has not worked well, probably because of variation 
in sentence length. These results allow us to gauge the practicality of passage retrieval. All retrieval 
methods require thatthe index infor­mation for each query term be fetched and pmceaaed. In a practical 
system this reformation identifies the documents containing in each term and, within each document, the 
P sitione at which the term occurs; with this information it ia poeaible to use the index to evaluate 
queries on passagea. (For whole-document retrieval, the positional information is used to identifi phrases.) 
Thus the same amount of index data is processed whether paasagea or documents are ranked. With one fixed-length 
passage for each word occurrence Precision at N documents Avg. %A 5 10 20 30 200 DWC.. C-standard: Documen@ 
0.3480 0.3480 0.3090 0.2680 0.1288 0.1798 -1.8 Pagee 0.3287 0.3260 0.2890 0.2540 0.1205 0.1740 -5.0 Tiles 
0.2960 0.2920 0.2670 0.2353 0.1106 0.1504 -17.8 C-pivot: Documents 0.3853 0.3740 0.3130 0.2740 0.1244 
0.1831 0.0 Pagee 0.3800 0.3820 0.3190 0.2720 0.1293 0.1915 +4.6 Tiles 0.3707 0.3740 0.3210 0.2727 0.1265 
0.1824 -0.4 Windowa: 150 words 0.3813 0.3840 0.3210 0.2773 0.1260 0.1889 +3.2 350 worda 0.3633 0.3580 
0.2980 0.2707 0.1090 0.1507 17.7 . Fixed-length arbitrary pamagee: 150 worda: 0.3707 0.3760 0.3220 0.2883 
0.1309 0.1983 +8.3 350 worrh 0.3860 0.3800 0.3230 0.2887 0,1318 0.1974 +7.8 Variabl~length arbitrary 
passages: C-pivot 0.3707 0.3608 0.3050 0.2760 0.1221 0.1804 -1.5 Table 3: Experiments with TREC disks 
$?and ~, queries 251-900, Interval Precision at N documents Avg. %A 5 10 20 30 200 prec. Passages of 
150 words 1 word 0.1936 0.1731 0.1346 0.1115 0.0281 0.2416 0.0 25 worda 0.1962 0.1885 0.1346 0.1077 0.0279 
0.2450 +1.4 75 worda 0.1987 0.1731 0.1288 0.1038 0.0279 0.2338 -3.2 1 sentence 0.1808 0.1654 0.1269 0.1026 
0.0256 0.2182 9.7 Paesagea of 350 words 1 word 0.1923 0.1731 0.1288 0.0987 0.0275 0.2219 0.0 25 words 
0.1885 0.1769 0.1250 0.0962 0.0277 0.2208 0.5 75 words 0.1880 0.1751 0.1262 0.0925 0.0224 0.2197 1.0 
1 sentence 0.1782 0.1731 0.1250 0.0974 0.0269 0.2182 -1.7 Table 4: Bzperiments with Jim&#38;length passages 
starting at regular intemds, wing FR, dish Z and ~, and queries selected  jivm 251-900. in the database, 
other than worda close to the end of a doc-accumulators,allowing passage retrieval to take place on a 
ument, the full contents of TREC disks 2 and 4 would con-small dedtop macldne. tain about 300 million 
paaaagea. With a naive implementat­ion, this would require one accumulator per passage, but for 7 Conclusion 
ranking documents with limited accumulator only 1%-5% of the number of accumulators is required; and 
for passages We haverevisitedpassageretrieval,investigatingtheabiity somewhat smaller percentages would 
be involved because ofpassagerankingtoidentifyrelevantdocuments.We have pamages contain fewer query terms 
than do whole docu-shown that fixed-length arbitrary paesaga+of 150 worda mente. Taking 2% as a typical 
figure we require 6 million or more and starting at small intervalsso that the pamages accumulators, 
each of 12 bytes (pointer, passage identifier, heavily overlap-can give substantial improwrnents in ef­and 
value), or around 72 megabytee. By introducing inter-fectiveness,particularly for collections of long 
documents. vals of 25 words between the start of passages-which has lit-Theeeresultscontirrntime ofCaUan[2]andmmeover 
w­tle impact on etlkctiven~nly 3 megabytea are required. geetthatalternativepassageformationmdaniams 
arenot The other major in-memory cost for document ranking ia likely to yield significant further irnprovement.Fixed-k!mgth 
the document lengths; for iixed-kngth paasagee wd values paeasgeeare simplq highly efktivq rob-au~ we 
argue, canbeneglected,butthenumberofwordoccurrencesin suitableforpracticalquery evaluation. each document 
is required to identify the legal passages in Our results also confirm that pivoted document kmgth eachdocument.At4bytesperdocumentthisstructurere-normalisation[13]iaa 
suweasM innovation.Fbrdecthms quires about 3 megabytes, a total of 6 megabytes with the of text of varying 
length-in particular whole documeata, sections, or paragraphs-it gave marked improvements in performance. 
It was not m succeaethl at comparing srbi­trary passages of different lengths, but in this comparison 
a ditferent formulation of pivoting had to be employed. In contrsst to some previous passage schemes, 
not only do arbitrary passages give greater effectiveness but no use is made of semimtic properties such 
88 sentence or para­graph boundaries; indeed, our resulte indicate that use of such information degradee 
performance. Moreover, our ex­periments show that previous pawage retrieval schemes are by comparison 
to fixed-length arbitrary passages unreliable, as they have worked well in some casea but not in otherv. 
The main observed drawback of arbitrary passages is that there is no single passage length that is always 
beet, but, as also observed eleewhere [2], all lengths in a broad range work well. Although aspects of 
arbitrary passage retrieval remain to be considered, such as making use of variable-length pse­aagea 
and combination of evidence, we believe that arbitrary passages are an appropriate mechanism for ranking 
in col­lection of documents of mixed length. Acknowledgements We thank Finn Sacks-Davis for suggesting 
the query evalua­tion method for fixed-length passages. We also thank Alis­tair Moffat and Roes Wdkinaon. 
This work was supported by the Australian Research Council. R.derences [1] T.C. Bell, A. Moffat, LH. 
Witten, and J. Zobel. The MG retrieval system: Compreming for space and speed. Communication of the ACM, 
38(4):41-42, April 1995. [2] J.P. CalIan. Paasag&#38;level evidence in document r~ trieval. In Pnw A 
CM-SIGIR International Conference on Resewch and Development in information Retrieva&#38; pageS 302-309, 
Dublin, Ireland, 1994. [3] W.B. Frakea and R. Baeza-Yates, editors. Information Retieval: Data Structures 
and Algorithms. Prentice-Hall, 1992. [4] D.K. Harman. Overview of the first Text Retrieval Con­ference. 
Ln D.K. Hmmm, editor, Pmt. TREC Ted Re­trieval Conference pages 1-20, Washington, November 1992. National 
Institute of Standarda Special Publica­tion 500-207. [5] M.A. Hearat and C. Plaunt. Subtopic structuring 
for full-length document scceea. In Pmt. A CM-SIGIR In­ternational Conference on Research and Development 
in Information Retrieva~ pages 59-68, Pittsburg, 1993. [6] M. Kaszkiel, P. Vines, R. Wlkineon, and J. 
Zobel. The MDS experiments for TREC5. In Pmt. Ted Retrieval Confenmce (TREC), November 1996. Proceedings 
to appear. [7] D. Knaua, E. Mittendorf, P. Schiiuble, and P. Sheridan. Highlighting relevant passages 
for users of the interac­tive SPIDER retrieval system. In D.K. Harman, editor, Proc. Ted Rettieval Confenmz 
(TREC), pagee 233­243, Waahrngton, 1995. National Institute of Standards and l%chno]ogy Special Publication 
500-236. [8] E, Mittendorf and P. Sci&#38;ble. Document and pss­sage retrieval based on hidden Markov 
models. In Ptuc. A G M-SIGIR International Conference on Reseamh and Development in Information Retriev~pagee 
318-327, Dublin, Ireland, 1994. [9] A. Mofht and J. Zobel. Self-indexing inverted files for fast text 
retrieval. ACM tinsactiow on Znfownation Systems, 14(4):349-379, October 1996. [10] M. Pezain, J. Zobel, 
and lL Sacks-Davis. Filtered doc­ument retrieval with i%squency-sorted indexes. Jour­nal of the Amm can 
Soa ety for Information Science, 47(10):749-764, 1996. [11] G. SaltOn. Automatic Test Pmcesaing: The 
!thms­fownation, Analysw, and Retrieval of Information bp Computer. Addison-Wesley, Reading, MA, 1989. 
[12] G. SaltOn, J. Allsn, and C. Buckley. Approaches to pas­sage retrieval in full text information systems. 
In Pmt. A CM-SIGIR International Conference on Reseamh and Development in Information Retrieva~ pages 
49-58, Pittsburg, 1993. [13] A. Singhal, C. Buckley, and M. Mitra, Pivoted docu­ment length normalization. 
In Proc. A CA4-SIGIR k­ternatienol Conference on I&#38;eam.h and Development in Infownation Retiev~ pages 
21 29, Zurich, Switzer­land, August 1996. [14] R. Wllkineon. Etfective retrieval of structured docu­ments. 
In Prvc. A CM-SIGIR International Conference on Rwcsmh and Development in Information lletrieva~ pSgSS 
311-317, Dublin, Ireland, 1994. [15] H. Wfliama and J. Zobel. Indexing nucleotide databases for fast 
query evaluation. In P?uc. Zntema­tional Conference on Advances in Database Tec/mo~ (EDBT), pages 275-288, 
Avignon, Wince, March 1996. Springer-Verlag. Lecture Notes in Computer Science 1057. [16] I.H. WWen, 
A. Moffat, and T.C. BeIl. Managing Giga­b@a: Compressing and Indezing Documents and Im­agea. Van Nostrand 
Reinhold, New York, 1994. [17] J. Zobel, A. Moffat, R. Wflkineon, and R. Sacks-Davis. Efficient retrieval 
of partial documents. Infomtation Processing /?4Management, 31(3):361-377, 1995.  
			