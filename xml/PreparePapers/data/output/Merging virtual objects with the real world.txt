
 Computer Graphics, 26,2, July 1992 Merging Virtual Objects with the Real World: Seeing Ultrasound Imagery 
within the Patient Michael Bajura, Henry Fuchs, and Ryutarou Ohbuchi Department of Computer Science 
University of North Carolina Chapel Hill, NC 27599-3175 Abstract 2) creating a working virtual environment 
which acquires and dis­plays 3D ultrasound data in real time, and 3) recovering structural We describe 
initial results which show live ultrasound information for volume rendering specifically from ultrasound 
data, echography data visualized within a pregnant human subject. The which has unique image processing 
requirements. This third area is visualization is achieved by using a small video camera mounted in presented 
in [Lin 199 I ] and is not covered here. front of a conventional head-mounted display worn by an observer. 
Section 2 of this paper reviews previous work in 3D ultra-The camera s video images are composite with 
computer-gener­sound and Section 3 discusses our research on processing, rendering,ated ones that contain 
one or more 2D ultrasound images properly and displaying echographic data without a head-mounted display. 
 transformed to the observer s current viewing position. As the Since the only real-time volume data 
scanners available today are 2D observer walks around the subject. the ultrasound images appear ultrasound 
scanners. we try to approximate our ultimate system by stationary in 3-space within the subject. This 
kind of enhancement incrementally visualizing a 3D volume dataset reconstructed from a of the observer 
s vision may have many other applications, e.g., never-ending sequence of 2Ddata slices [Ohbuchi 1990; 
199 I ]. This image guided surgical procedures and on location 3D interactive is difftcult because the 
volume consisting of multiple 2D slices needs architecture preview. to be visualized incrementally as 
the 2D slices are acquired. This CR Categories: 1.3.7 [Three-Dimensional Graphics and Realism] incremental 
method has been successfully used in off line experi-Virtual Reality, 1,3.I [Hardware architecture]: 
Three-dimensional ments with a 3-degree-of-freedom (DOF) mechanical arm tracker displays, 1.3.6 [Methodology 
and Techniques]: Interaction tech-and is extendible to 6 degrees of freedom, e.g., a 3D translation and 
niques, J.3 ILife and Medical Sciences]: Medical information sys-a 3D rotation, at greater computational 
cost. tems. Sections 4 and 5 present our research on video see-through Additional Keywords and Phrases: 
Virtual reality, see-through head-mounted display (HMD) techniques involving the merging of head-mounted 
display, ultrasound echography, 3D medical imaging computer generated images with real-world images. 
Our video see­ through HMD system displays ultrasound echography image data in the context of real (3D) 
objects. This is part of our continuing see­ 1. Introduction through HMD research, which includes both 
optical see-through HMD and video see-through HMD, Even though we concentrate We have been working toward 
an ultimate 3D ultrasound here on medical ultrasound imaging, applications of this displaysystem which 
acquires and displays 3D volume data in real time. technology are not limited to it (see Section 6.2). 
 Real-time display can be crucial for applications such as cardiac diagnosis which need to detect certain 
kinetic features. Our ulti­mate system design requires advances in both 3D volume data 2. Previous Research 
in 3D Ultrasound acquisition and 3D volume data display. Our collaborators, Dr. Olaf von Ramm s group 
at Duke University, are working toward real-time The advantages of ultrasound echography are that it 
is rela­3D volume data acquisition [Smith 1991; von Ramm 1991]. At tively safe compared with other imaging 
modalities and that images UNC-Chapel Hill, we have been conducting research on real-time are generated 
in real time [Wells 1977]. This makes it the preferred 3D volume data visualization. imaging technique 
for fetal examination, cardiac study, and guided surgical procedures such as fine-needle aspiration biopsy 
of breast Our research efforts at UNC have been focused in three areas: tumors [Fomage 1990]. Ultrasound 
echography offers the best real-I ) algorithms for acquiring and rendering real-time ultrasound data, 
time performance in 3D data acquisition, although slower imaging modalities such as MRI are improving. 
 Permlssmn to copy with{wt lee all or part of this material is gmrrted The drawbacks of ultrasound imaging 
include a low signal to provdd that the copim are not made or distriimned for direct noise ratio and 
poor spatial resolution. Ultrasound images exhibit commercial advantage, the ACM copyright nntfce and 
the title of the speckle which appears as grainy areas in images. Speckle arises  publication and its 
date appear, and notice is given that copying is by from coherent sound interference effects from tissue 
substructure. permission of the Association for Computing Machinery. To cnpy otherwise. t]r [o repuhllsh, 
requires a fee and/or specific permission. Information such as blood flow can be derived from speckle 
but in ,( 1992 ACM -()-89791 -479-1/92/007/0203 $0150 203 SIGGRAPH 92 Chicago, July 26-31, 1992 general 
speckle is hard to utilize [Thijssen 1990]. Other problems with ultrasound imaging include attenuation 
that increases with frequency, phase aberration due to tissue inhomogeneity, and reflec­tion and refraction 
artifacts [Harris 1990] 2.1 3D Ultrasound Image Acquisition Just as ultrasound echography has evolved 
from 1D data acquisition to 2D data acquisition, work is in progress to advance to 3D data acquisition. 
Dr. Olaf von Ramm s group at Duke University is developing a 3D scanner which will acquire 3D data in 
real time [Shattuck 1984; Smith 1991; von Ramm 1991 ]. The 3D scanner uses a 2D phased array transducer 
to sweep out an imaging volume. A parallel processing technique called Explososcan is used on return 
echoes to boost the data acquisition rate. Since such a real-time 3D medical ultrasound scanning sys­tem 
is not yet available, prior studies on 3D ultrasound imaging known to the authors have tried to reconstruct 
3D data from imaging primitives of a lesser dimension (usually 2D images). To reconstruct a 3D image 
from images of a lesser dimension, the location and orientation of the imaging primitives must be known. 
Coordinate values are explicitly tracked either acoustically [Brinkley 1978; King 1990; Moritz 1983], 
mechanically [Geiser 1982a; Geiser 1982b; Hottier 1989; McCann 1988; Ohbuchi 1990; Raichelen 1986; Stickels 
1984], or optically [Mills 1990]. In other systems, a human or a machine makes scans at predetermined 
locations and/or orientations [Collet Billon 1990; Ghosh 1982; Itoh 1979; Lalouche 1989; Matsumoto 1981; 
Nakamura 198A Tomographic Technologies 1991]. A particularly interesting system under development at 
Philips Paris Research Laboratory is one of the closest yet to a real-time 3D ultrasound scanner [Collet 
Billon 1990]. It is a follow on to earlier work which featured a manually guided scanner with mechanical 
tracking [Hottier 1990]. This near real-time 3D scanner is a mechani­cal sector scanner, in which a conventional 
2D sector scanhead with an annular array transducer is rotated by a stepper motor to get a third scanning 
dimension. In a period of 3 to 5 seconds, 50 to 100 slices of 2D sector scan images are acquired. Currently 
the annular array transducer in this system provides better spatial resolution, but less temporal resolution, 
than the real-time 3D phased array system by von Ramm et al., mentioned above. A commercial product, 
the Echo-CT system by Tomographic Technologies, GMBH, uses the linear translation of a transducer inside 
a tube inserted into the esophagus to acquire parallel slices of the heart. Image acquisition is gated 
by respiration and an EKG to reduce registration problems [Tomographic Technologies 1991]. 2.2 3D Ultrasound 
Image Display One should note that 3D image data can be presented not only in visual form, but also as 
a set of calculated values, e.g., a ventricular volume. The visual form can be classified further by 
the rendering primitives used, which can be either geometric (e.g., polygons) or image-based (e.g., voxels). 
Many early studies focused on non­invasively estimating of the volume of the heart chamber [Brinkley 
1978; Ghosh 1982; Raichelen 1986; Stickels 1984]. Typically, 2D echography (2 DE) images were stored 
on video tape and manually processed off-line. Since visual presentation was of secondary interest, wire 
frames or a stack of contours were often used to render An interesting extension to 2D display is a system 
that tracks the location and orientation of 2D image slices with 6 DOF [King 1990]. On each 2D displayed 
image, the system overlays lines indicating the intersection of the current image with other 2D images 
already acquired. The authors claim that these lines help the viewer understand the relationship of the 
2D image slices in 3D space. Other studies reconstructed 3D grey level images preserving grey scale, 
which can be crucial to tissue characterization [Collet Billon 1990; Hottier 1989; Lalouche 1989; McCann 
1988; Nakamura 1984; Pini 1990; Tomographic Technologies 199 1]. [Lalouche 1989] is a mammogram study 
using a special 2DE scanner that can acquire and store 45 consecutive parallel slices at 1 mm intervals. 
A volume is reconstructed by cubic-spline interpolation and then volume ren­dered. [McCann 1988] performed 
gated acquisition of a heart s image over a cardiac cycle by storing 2DE images on video tape and then 
reconstructing and volume rendering them. Repetitive low­pass filtering was used during reconstruction 
to fill the spaces between radial slices, which suppressed aliasing artifacts. [Tomographic Technologies 
1991] provides flexible re-slicingby up to 6 planes as well other imaging modes. [Collet Billon 1990] 
uses two visualization techniques: re-slicing by an arbitrary plane and volume rendering. The former 
allows faster but only 2D viewing on a current workstation. The latter allows 3D viewing but often involves 
cumbersome manual segmentation. The reconstruction algorithm uses straightforward low pass filtering. 
3. Incremental Volume Visualization We have been experimenting with volume rendering as one alternative 
for visualizing dynamic ultrasound volume data. Stan­dard volume rendering techniques which rely heavily 
on preprocess­ing do not apply well to dynamic data which must be visualized in real time [Levoy 1988; 
Sabella 1988; Upson 1988]. We review here an incremental , interactive, 3D ultrasound visualization technique 
which visualizes a 3D volume as it is incrementally updated by a sequence of registered 2D ultrasound 
images [Ohbuchi 1990; 1991]. Our target function is sampled at irregular points and may change over time. 
Instead of directly visualizing samples from this target, we reconstruct a reguktr 3D volume from this 
time series of spatially irregular sample points. This places a limit on storage and computation requirements 
which would grow without bound if we retained all the past sample points. The reconstructed volume is 
then rendered with an incremental volume-rendering technique. The reconstruction is a 4D convolution 
precess. A 3D Gaussian kernel is used for spatial reconstruction followed by a temporal reconstruction 
based on simple auto regressive moving average (ARM A) filtering [Haddad 1991]. Time stamps are as­signed 
to each 3D voxel, which are updated during reconstruction. The time stamp difference between a reconstructed 
voxel and an incoming sample is used to compute coefficients for the ARMA filter. The 3D Gaussian filter 
is loosely matched to the point spread function of the ultrasound transducer and is a good choice because 
it minimizes the product of spatial bandwidth and spatial frequency bandwidth [Hildreth 1983; Leipnik 
1%0]. An image-order, ray-casting algorithm based on [Levoy 1988] renders the final images incrementally. 
Rendering is incre­mental and fast only if the viewpoint is fixed and if the updated volume is relatively 
small. Shading and ray sampling are done only for voxels proximate to incoming data. The ray samples 
are stored Computer Graphics, 26, 2, July 1992 Figure 1. Two of 90 2D ultrasound echography images of 
a plastic toy doll phantom which was scanned in a water tank. The scans shown are at the torso (left) 
and at the head (right). The clouds at the bottom of the scans are artifacts due to reflections from 
the bottom of the water tank. in a 3D array in screen space called a ray cache for later use. The ray 
cache is hierarchical so that a small partial update of the ray cache can be composited quickly (0(&#38;(n))) 
[Ohbuchi 19911. The hierar- chical ray cache also allows fast rendering of polygons properly composited 
with volume data, which can enhance the volume visu-alization [Levoy 1990, Miyazawa 19913. This incremental 
volume rendering algorithm is not restricted to ultrasound and is applicable to other problems which 
update volume data incrementally, e.g., interactive volume modeling by sculpting [Galyean 19911. To test 
this visualization technique, we acquired a series of 2D images with a manually guided conventional 2DE 
scanhead attached to a mechanical tracking arm with 3 DOF (two translations and one rotation). As we 
scanned various targets in a water tank, their images and their corresponding geometry were stored off-line. 
We then ran the incremental volume visualization algorithm on a DECstation 5000 with 256 MB of memory 
using this data. With a reconstruction buffer size of 150 x 150 x 300 and an image size of 256 x 256, 
it took 15-20 seconds to reconstruct and render a typical image after insertion of a 2D data slice. This 
time varied with reconstruction, shading, and viewing parameters. Figure 1 shows 2 out of 90 2D images 
of a plastic toy doll phantom which is visualized in Figure 2. The 2D images were producedbyanATLMark-4Scannerwitha3.5MHzlinearscanhead. 
The 2D images overlap but are roughly parallel at approximately 2 mm intervals.  4. Virtual Environment 
Ultrasound Imaging Various medical ultrasound imaging applications require a registration of ultrasound 
images with anatomical references, e.g., in performing a fine needle aspiration biopsy of a suspected 
breast tumor [Fomage 19901. A virtual environment which displays images acquired by ultrasoundequipment 
in place within a patient s anatomy could facilitate such an application. We have developed an experi- 
mental system that displays multiple 2D medical ultrasound images overlaid on real-world images. In January 
1992, after months of development with test objects in water tanks, we performed our first experiment 
with a human subject. Our virtual environment ultrasound imaging system works as follows (note that this 
is a different system than our older one described in the previous section): as each echography image 
is acquired by an ultrasound scanner, its position and orientation in 3D world space are tracked with 
6 degrees of freedom (DOF). Simulta-neously the position and orientation of a HMD are also tracked with 
6 DOF. Using this geometry, an image-generation system generates 3D renderings of the 2D ultrasound images. 
These images are video mixed with real-world images from a miniature TV camera mounted on the HMD. The 
resulting composite image shows the 2D ultra- sound data registered in its true 3D location. Figure 3 
is a block diagram of our system s hardware. There are three major components: 1) an image-acquisition 
and tracking system, which consists of an ultrasound scanner and a Polhemus tracking system, 2) an image-generation 
system, which is our Pixel- Planes 5 graphics multicomputer, and 3) a HMD which includes a portable TV 
camera, a video mixer, and a VPL EyePhone. Each component is described in more detail in Sections 4.14.3. 
Figure 2. Reconstructed and rendered image of the toy doll phantom using incremental volume visualization. 
 SIGGRAPH 92 Chicago, July 26-31, 1992 environment are registered to the real world within the update-rate 
m k Ultrasound scanhead 2D B-mode II Ultrasound scanner m m mm arrays lE%E!Lr -32Prw s ~ Figure 3. 
Hardware block diagram for the virtual environment ultrasound system. 4.1 Image Acquisition and Tracking 
Two dimensional ultrasound images are generated by an IREX System III echography scanner with a 16 mm 
aperture 2.5 MHz phased array transducer. These images are digitized by a SUN 4 with a Matrox MVP/S real-time 
video digitizer and trans­ferred to our Pixel-Planes 5 graphics multicomputer [Fuchs 1989]. The SUN 4 
operates as a 2DE image server for requests from the Pixel-Planes 5 system. Images are distributed among 
the Graphics Processors (GPs) on a round-robin scan-line by scan-line basis. Due to the bandwidth limitations 
of the SUN 4 VME bus, transfer of the 512 x 480x 8 bits/pixel images is limited to 2 Hz. A Polhemus system 
with one source and two receivers is used for tracking [Polhemus 1980]. One receiver tracks the HMD. 
The other tracks the ultrasound transducer. The Polhemus system is mounted in non ferrous materials away 
from magnetic interference sources such as the ultrasound transducer, HMD, and other lab equipment. A 
calibration procedure is used to relate both the ultrasound transducer to its Polhemus receiver and the 
HMD TV camera to its Polhemus receiver mounted on the HMD. This calibration procedure is described in 
Section 4.4. 4.2 Image Generation Images are generated by the Pixel-Planes 5 system based on geometry 
information from the tracking system. Pixel-Planes 5 runs a custom PHIGS implementation which incorporates 
a facility to update display structures asynchronously from the display process. This separates the interactive 
virtual environment update rate from the 2D ultrasound image data acquisition rate. Images in the virtual 
limit of the tracking and display system and not within the acquisi­tion-rate limit of the image-acquisition 
system. Pixels from the 2D ultrasound images are rendered as small, unshaded sphere primitives in the 
virtual environment. The 2D ultrasound images appear as space-filling slices registered in their correct 
3D position. The ultrasound images are distributed among the GPs where they are clipped to remove unnecessary 
margins and transformed into sphere primitives, which are then sent to the Renderer boards for direct 
rasterization. Pixel-Planes 5 renders spheres very rapidly, even faster than it renders triangles, over 
2 million per second [Fuchs 1985; 1989]. Final images are assembled in double buffered NTSC frame buffers 
for display on the HMD. To reduce the number of sphere primitives displayed, the ultrasound images are 
filtered and subsampled at every 4th pixel. Due to the low resolution of the HMD and inherent bandwidth 
limitation of the ultrasound scanner, this subsampling does not result in a substantial loss of image 
quality. An option to threshold lower intensity pixels in 2D ultrasound images prior to 3D rendering 
can suppress lower intensity pixels from being displayed. 4.3 Video See. Through HMD A video see-through 
HMD system combines real-world im­ages captured by head-mounted TV cameras with synthetic images generated 
to correspond with the real-world images. The important issues are tracking the real-world cameras accurately 
and generating the correct synthetic images to model the views of the cameras. Correct stereo modeling 
adds concerns about matching a pair of cameras to each other as well as tracking and modeling them. [Roblnett 
1991] discusses stereo HMD in detail and includes an analysis of the VPL EyePhone. A Panasonic GP-KS 
102 camera provides monocular see­through capability for the left eye in our current system. Images from 
this camera are mixed with synthetic images from the Pixel-Planes 5 system using the luminance (brightness) 
keying feature on a Grass Valley Group Model 100 video mixer. With luminance keying, the pixels in the 
output image are selected from either the real-world image or the synthetic image, depending on the luminance 
of pixels in the synthetic image. The combined image for the left eye and a synthetic image only for 
the right eye are displayed on a VPL EyePhone. 4.4 Calibration Two transformations, a transducer transformation 
and a camera transformation, are needed to calibrate our test system. The transducer transformation relates 
the position and orientation of the Polhemus tracker attached to the ultrasound transducer to the position 
and scale of 2D ultrasound image pixels in 3D space. The camera transformation relates the position and 
orientation of the head-mounted Polhemus tracker to the HMD TV camera position, orientation, and field 
of view. Both transformations are calculated by first locating a cali­bration jig in both the lab (real) 
and tracker (virtual) 3D coordinate systems. This is accomplished by performing rigid body rotations 
with the transducer tracker about axes which are to be fixed in both the real and virtual coordinate 
systems. Two samples from the tracker, each consisting of both a position and an orientation, are  
 generation systems are needed if we are 10 be able to visualize usefully detailed 3D imagery.  6.2 
(lther Applications 1) Vision in surgery: In neurosurgery, ultrasound is already used m image nearby 
arteries that should be avoided by an impending surgical incision. 2) Burning buildings: With close-range, 
millimeter wavelength radar, rescuers may be able to see through the smoke in the interior of burning 
buildings. 3) Building geometry: Geometry or other structural data could be added to a live scene. In 
the above burning building scenario, parts of a building plan could be superimposed onto the visual scene, 
such as the location olstairways, hallways, or the best exits out of the building. 4) Service information: 
Information could be displayed to a service technician working on complicated machinery such as a jet 
engine. Even simpler head-mounted displays, ones without head tracking, already provide information to 
users on site and avoid using a large cumbersome video screens. Adding head tracking would allow 3D superimposition 
to show, for instance, the location of special parts within an engine. or the easiest path for removal 
or insertion of a subassembly. 5) Architecture on site: Portable systems could allow builders and architects 
to preview buildings on site before construction or visual­ize additions to existing architecture. With 
the work presented here and the identification of prob­lems and possibilities for further research. we 
hope to encourage applications not only of virtual environments (imaginary worlds), but also applications 
that involve an enhancement of vision in our real world. Acknowledgments We would like to thank the 
following people: David Chen and Andrew Brandt for experimental assistance: General Electric Medical 
Systems (and especially R. Scott Ray) for the loan of an ultrasound scannen Stefan Gottschalk for much 
assistance with video acquisition, editing, and printing; Professor Olaf von Ramm (Duke University) for 
donation of the IREX ukrdsound scannefi ultrasound technician George Blanchard, RDMS, for scanning the 
subject; David Harrison and John Hughes for video and laboratory setup: Andrei State for experimental 
assistance; John Thomas for fabrication of a custom camera mount; Terry Yoo for video tape editing: Vem 
Katz, MD, for assistance with multiple ultrasound machines and scanning experiments; Nancy Chescheir, 
MD, for loan of an ultrasound machine and arrangements with the ultrasound technician: Warren Newton. 
MD, and Melanie Mintzer, MD, for finding our subject; Warren Robinett and Rich Holloway, for consul­tation 
with HMD optics and software; Professor Stephen Pizer and Charlie Kurak for consultation on the difficulty 
of enhancing ultra­sound images: David Adam (Duke University) for instruction in the use of tbe IREX 
scanner: and our subject and her husband for their time and patience. This research is partially supported 
by DARPA ISTO con­tract DAEA 1R-90 -C-(W44,NSFERC grant CDR-86-2220 1, DARPA Computer Graphics, 26,2, 
JUIV 1992 ISTO contract 7510, NSF grant MI P-9000894, NSF cooperative agreement ASC-89202 19, and NIH 
MIP grant PO I CA 47982, and by Digital Equipment Corporation. References [Brinkley 1978] Brinkley, J. 
F., Moritz, W. E., and Baker, D.W. Ultrasonic Three-Dimensional Imaging and Volume From a Series of Arbitrary 
Sector Scans. Ultrasound in Med. &#38; Biol,, 4, pp~ 17-327. [Collet Billon 1990] Collet Billon, A., 
Phi/ips Paris Research Ld. Personal Communication. [Fomage 1990j Fomage, B. D., Sneige, N., Faroux, M,J,, 
and Andry, E. Sonographic appearance and ultrasound guided fine-nee le ! aspiration biopsy of brest carcinomas 
smaller than 1 cm . Jaurnal of Ultrasound in Medicine. 9, pp559-568. [Fuchs 1985] Fuchs, H., GoldFeather, 
J,, Hultiquist, J. P., Spach, S., Austin, J., Brooks, Jr,, F,P,. Eyles. J., and Poulton, J. Fast Spheres. 
Textures, Transparencies, and Image Enhancements in Pixel Planes. Computer Graphi[s (Proceedings of 
.WGGRAPH 8.$). 19(3), ppi 11-120. [Fuchs 19891 Fuchs, H., Poulton, J., Eyles, J., Greer. T., Goldfeather, 
J., Ellsworth, D., Molnar. S., and Israel, L. Pixel Planes 5: A Heterogeneous Multiprocessor Graphics 
System Using Proces­sor-Enhanced Memories. Computer Graphics (Proceedings of SIGGRAPH 89). 23(3). pp79-X8. 
[Galyean 1991] Galyean, T. A., and Hughes. J.F. Sculpting: An Interactive Volumetric Modeling Technique. 
 Conrpurer Graph­ic,s (Pro(eedin<y,v of SIGGRAPH 89), 25(4), pp267-274. lGeiser 1982a] Geiser, E. A.. 
Ariet, M,, Conetta, D. A., Lupkiewicz, S.M., Christie, L.C., and Con[i, C.R. Dynamic three-dimen­sional 
echocardiographic reconstruction of the intact human left ventricle: Technique and initial observations 
in patients . Arneri­can Heart ./mows/, 103(6). pp 1056-1065. [Geiser 1982b] Geiser, E. A.. Christie, 
L.C., Conetta, D.A., Conti, C. R., and Gossman, G.S. Mechanical Arm for Spatial Registra­tion of Two-Dimensional 
Echographic Sections. Carher. Cariora.w. Diagn.,8,pp89-101, [Ghosb 1982] Ghosh, A,, Nanda, C. N., and 
Maurer, G. Three-Dimensional Reconstruction of Echo-Cardiographics Images Using The Rotation Method. 
U/trusound in Med. &#38; Bird., 8(6), pp655-661. [Haddad 199 I I Haddad, R, A., and Parsons, T.W. Digital 
Signal Proce.xsin,q, Theory, Applications, and Hard~are. New York. Computer Science Press. [Harris 1990] 
Harris, R. A., Follett, D. H., Halliwell, M, and Wells, P.N.T. Ultimate limits in ultrasonic imaging 
resolution. U/fra­.soutrd in Medicine urrd Biology, 17(6), pp547-558. [Hildreth 1983] Hildreth, E, C. 
The Detection of Intensity Changes by Computer and Biological Vision Systems. Compu[er Vision, Graphi[s, 
and lmu~e Processing, 22, pp 1-27. [Hottier 1989] Hottier. F.. Phi/ips Paris Research Lub. Personal Communication. 
[Hottier 1990] Hottier, F.. Collet Billon, A, 3D Echngruphy: Stafus and Perspecrire. 3D Imaging in Medicine. 
Springer-Verlag. pp21-41. [Itoh 19791 Itoh, M., and Yokoi, H. A computer-aided three­dimensional display 
system for ultrasonic diagnosis of a breast tumor. Ukra.wmics, , pp26 I -268. [King 1990] King. D. L., 
King Jr., D. L., and Shao, M.Y, Three-Dimensional Spatial Registration and Interactive Display of SIGGRAPH 
92 Chicago, July 26-31, 1992 Position and Orientation of Real-Time Ultrasound Images. Journal of Ultrasound 
Meal,9, pp525-532. [Lalouche 1989] Lalouche, R. C., Bickmore, D., Tessler, F., Mankovich, H. K., and 
Kangaraloo, H. Three-dimensional re­construction of ultrasound images. SPIE 89, Medical Imaging, pp59-66. 
[Leipnik 1%0] Leipnik, R. The extended entropy uncertainty principle. Info. Control, 3, ppl 8-25. [I-soy 
1988] Levoy, M. Display of Surface from Volume Data. IEEE CG&#38;A, 8(5), pp29-37. [Levoy 1990] Levoy, 
M. A Hybrid Ray Tracer for Rendering Polygon and Volume Data. IEEE CG&#38;A, 10(2), pp33-40. [Liang 1991] 
Liang, J., Shaw, C., and Green, M. On Temporal-Spatial Realism in the Virtual Reality Environment. User 
Interface Sofware and Technology, 1991, Hilton Head, SC., U. S. A., pp19-25. [Lin 1991] Lint W., Pizer, 
S. M., and Johnson, V.E. Surface Estima­tion in Ultrasound Images. Information Processing in Medical 
imaging i99J, Wye, U. K., Spnnger-Verlag, Heidelberg, pp285­ 299. [Matsumoto 1981] Matsumoto, M., Inoue, 
M., Tamura, S., Tanaka, K., and Abe, H. Three-Dimensional Echocardiography for Spatial Visualization 
and Volume Calculation of Cardiac Struc­tures. J. Clin. Ultrasound, 9, ppl 57-165. [McCann 1988] McCann, 
H. A., Sharp, J. S., Kinter, T. M., McEwrm, C.N., Barillot, C., and Greerdeaf, J.F. Multidimensional 
Ultra­sonic Imaging for Cardiology. Proc.lEEE, 76(9), pp 1063­1073. [Mills 1990] Mills, P. H., and Fuchs, 
H. 3D Ultrasound Display Using Optical Tracking. First Conference on Visualization for Biomedical Computing, 
Atlanta, GA, IEEE, pp490-497. [Miyazawa 1991] Miyazawa, T. A high-speed integrated rendering for interpreting 
multiple variable 3D data. SPIE, 1459(5), [Molnar 1992] Molnar, S., Eyles, J., and Poulton, J. PixelFlow: 
High-Speed Rendering Using Image Composition. Computer Graphics (Proceedings of SIGGRAPH 92), ((In this 
issue)), [Moritz 1983] Moritz, W. E., Pearlman,A.S., McCabe, D.H., Medema, D. K., Ainsworth, M. E., and 
Boles, M.S. An Ultrasonic Technique for Imaging the Ventricle in Three Dimensions and Calculating Its 
Volume. IEEE Trans. Biom. Eng., BME-30(8), pp482-492. [Nakamura 1984] Nakamura, S. Three-Dimensional 
Digital Dis­play of Ultrasonograms. lEEE CG&#38;A, 4(5), pp36-45. [Ohbuchi 1990] Ohbuchi, R., and Fuchs, 
H. Incremental 3D Ultra­sound Imaging from a 2D Scanner. First Conference on Visu­alization in Biomedical 
Computing, Atlanta, GA, IEEE, pp360­ 367. [Ohbuchi 1991] Ohbuchi, R., and Fuchs, H. Incremental Volume 
Rendering Algorithm for Interactive 3D Ultrasound Imaging. Information Processing in Medical Imaging 
1991 (L-ectureNotes in Computer Science, Springer-Verlag), Wye, UK, Springer-Verlag, pp486-500. [Pini 
1990] Pini, R., Monnini, E., Masotti, L., Novins, K. L., Greenberg, D. P., Greppi, B., Cerofolini, M., 
and Devereux, R. B. Echocardiographic Three-Dimensional Visualization of the Heart. 3D Imaging in Medicine, 
Travemunde, Germany, F 60, Spnnger-Verlag, pp263-274. [Polhemus 1980] Polhemus. 3Space Isotrak User s 
Manual. [Raichelen 1986] Raichelen, J. S., Trivedi, S. S., Herman, G.T., Sutton, M.G., and Reichek, N. 
Dynamic Thee Dimensional Reconstruction of the Left Ventricle From Two-Dimensional Echocardiograms. Journal. 
Amer. Coil. of Cardiology, 8(2), pp364-370. [Robinett 1991] Robinett, W., and Rolland, J.P. A Computational 
Model for the Stereoscopic Optics of a Head-Mounted Display. Presence, l(l), pp45-62. [Sabella 1988] 
Sabella, P. A Rendering Algorithm for Visualizing 3D Scalar Fields. Computer Graphics (Proceedings of 
SIGGRAPH 88), 22(4), pp5 1-58. [Shattuck 1984] Shattuck, D. P., Weishenker, M. D., Smith, S.W., and von 
Ramm, O.T. Explososcan: A Parallel Processing Technique for High Speed Ultrasound Imaging with Linear 
Phased Arrays. JASA, 75(4), pp1273-1282. [Smith 1991] Smith, S. W., Pavy, Jr., S.G., and von Ramm, O.T. 
High-Speed Ultrasound Volumetric Imaging System -Part I: Transducer Design artd Beam Steering. IEEE 7 
ransacfion on Ultrasonics, Ferroelectrics, and Frequency Control, 38(2), pp100-108. [Stickels 1984] Stickels, 
K. R., and Warm, L.S. An Analysis of Three-Dimensional Reconstructive Echocardiography. Ultra­sound in 
Med. &#38; Biol., 10(5), pp575-580. ~ijssen 1990] Thijssen, J. M., and Oosterveld, B.J. Texture in Tissue 
Echograms, Speckle or Information ? Journal of Ultra­sound in Medicine,9,pp215-229. [Tomographic Technologies 
1991 ] Tomographic Technologies, G. Echo-CT. [Upson 1988] Upson, C., and Keeler, M. VBUFFER: Visible 
Volume Rendering. ACM Computer Graphics (Proceedings of SIGGRAPH 88), 22(4), pp59-64. [vonRarnm 1991 
]von Ramm, O. T., Smith, S.W., and Pavy,Jr., H.G. High-Speed Ultrasound Volumetric Imaging System -Part 
II: Parallel Processing and Image Display. IEEE Transaction on Ultrasonics, Ferroeiectrics, and Frequency 
Control, 38(2), pplo9-115. [Ward 1992] Ward, M., Azuma, R., Bemett, R., Gottschalk, S., and Fuchs, H. 
A Demonstrated Optical Tracker with Scalable Work Area for Head-Mounted Display Systems. 1992 Symposium 
on Interactive 3D Graphics, Cambridge, MA., ACM, pp43-52. [Wells 1977] Wells, P. N. T. Biomedical ultrasonics. 
London, Academic Press.  
			