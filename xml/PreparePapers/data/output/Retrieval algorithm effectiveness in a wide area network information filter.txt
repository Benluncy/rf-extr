
 Retrieval Algorithm Effectiveness in a Wide Area Network Information Filter H. P. Frei M. F. Wyle Swiss 
Federal Institute of Technology (ETH) Zurich, Switzerland Abstract We present an application of the usefulness 
performance measure in a WAN-based SDI system. Components of two basic indexing and retrieval algorithms 
are compared ex­perimentally. The components we investigate include in­dexing token type (words versus 
N-grams), the amount of word reduction used in indexing, and the use of an indi­rect similarity component 
in retrieval. The theoretical ba­sis and implement at ion of the basic algorithms and varia­tions are 
discnssed. Results indicate that words perform better than N-grams, that S-stemming is better than full­stemming, 
and that indirect similarity provides an improve­ment to the cosine measure. Performance improvements 
are, however, small. 1 Introduction 1.1 Problems and Goals The Pasadena (Periodic, asynchronous selective 
extraction and dissemination of information throuzh . network access) , system was developed not only 
to provide a useful service to its subscribers, but also as a test-bed for Wide-area network (WAN) information 
filteriug algorithms [Wyle89]. WAN in­formation is distinctive in its timeliness. duration. audience. 
and volume. It provides a fertile, though somewhat noisy and dynamic environment for developing and measuring 
the applicability of modern indexing and retrieval algorithms. During our development of Pasadena, we 
encountered problems measuring the performance of the indexing and retrieval algorithms used to filter 
WAN information. A new performance measure [Frei91] with worthwhile advantages to the standard precision 
-recall indicator was developed and calibrated on a static standard test collection, In this report, 
we present an application of this measure using variations of two known and interesting algorithms running 
in our WAN information filtering system. An algorithm based on text traces and indirect similarity is 
contrasted to a standard word-based cosine method. This paper is organized as follows. First we present 
an overview of the Pasadena subscription service. In order to present the algorithm comparison, we shall, 
in passing, note Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. @ 1991 ACM 0.8979J.448.~j9J\OO09/0~ 14... $1 .5(3 some interesting aspects of the realization 
of Pasadena. In section 2 we provide a detailed description of the algorithms to be compared. In addition 
to an exact specification of two baseline methods, we present the motivation and underlying hypotheses 
behind each processing step. Section 3 provides an overview of the issues involved in algorithm assessment 
in a Selective Dissemination of In­formation (SDI) system. We describe ~anking possibilities and relevance 
assessments, presenting our motivation and a description of how these measures are implemented in the 
Pasadena system. We give a review of the usefulness mea­sure, and briefly consider precision -recall. 
Section 1.2 describes the experimental methods and re­sults obtained from the comparison of the two algorithms 
described in section 2. We systematically vary one con­ponent of one algorithm in a series of carefully 
controlled experiments. The results explain which factols arc respon­sible for the retrieval performance 
differences bet ~veen tllc methods. In the final section, we conclude with a dlscnssion of the results 
of these experiments and consideratrous fo~ the direction of future algorithm development.  1.2 The 
Pasadena SD I System Figure 1.2 gives a general description of the Pasadena WAN subscription service. 
The system acti~,ely and al>e­riodic ally queries diverse information sources; it maintains a local database 
of current information items, deleting oldeu information and adding new items continually. Pasadena s 
information sources are extlemely heteroge­neous. The bulk of the information items come froln usenet 
[Ande87] newsgroups; however, the system also receives mes­sages from mailing lists and actively queries 
WAN-accessible databases for new information. All of these sources contain pure-text items which are 
meant for electronic distribntiou, In addition to the usual mailing list and distributed electronic bulletin 
board system (bbs) messages [Wyle89], Pasadena also taps information from news wire services. These news 
items are usually only a paragraph or t~vo in length, and adhere to the Associated Press (AP) style guide 
for journalistic prose. Such messages are ultimately targeted at paper publication and dissemination. 
All of these hetelogenous information categories have an important characteristic in common, namely that 
the ne~vs they contain is timely. The value of the information they comprise is therefore dependent upon 
quick distl ibution, Receiving such information a week too late is like reading a week-old newspaper. 
Pasadena s subscribers typically set their query intervals to span at most a few days because they have 
come to expect prompt service from WAN-based systems. In Pasadena, each subscriber has one profile which 
con­tains one or more queries. Each query is composed of a comparison text and several other parameters 
described be­low. The system manages user-dialog, starts and runs the indexing and retrieval algorithms, 
and administers the simi­larity measures for comparing query texts with information item texts. The system 
also provides facilities for profile management and process scheduling. of the item s rank by the information 
retlieval (IR) vector space algorithms. After submitting a query and receiving some documents, subscribers 
are encouraged to refine the query in order to en­hance retrieval performance. Any of the above parameters 
can be changed. Changes to enhance a low-perfo~mance query might include: increasing the qucxy intro 
val ill o~del to increase the number of documents searched, changing the query text, adding or omitting 
inclusion or exclusion pat­terns, and specifying a larger number of documents to be retrieved. nn r WAN 
Queries *pe,io&#38;c Information Schedulim User Dialog  U( .: lnfOrmatiOn Items Text Format COm-Collier, 
io parwon Database Profile Management Management m Uu Figure 1: Pasadena Overview One subscribes to 
the Pasadena system through a four­step process. First, one sends a message containing the word help 
to the system. A message is sent back explaining what the service is and how to register. After registration, 
a users manual is mailed out electronically. This manual contains instructions for formulating and refining 
queries. Then the subscriber formulates one or more queries; each query contains the following parameters: 
a list of databases to be searched a pattern for document inclusion a pattern for document exclusion 
the number of documents to be sent per run how often a run takes place a comparison text formatting information 
for how delivered documents should appear The list of database categories defines which WAN in­formation 
items should be examined; other criteria for the formally defined attributes of WAN messages may be defined 
in this portion of the query. The patterns can be considered Boolean (actually regular expression) formulations 
used as second and third filtering stages. Finally a longer compari­son text is given for retrieval based 
on vector space models. The first Boolean filter stage is a list of regular expressions which, if found 
in an item, cause the item to be eliminated from consideration and not sent to the user. The second Boolean 
filtering stage contains a (typically shOrt) list of regular expressions which cause remaining items 
matching any of the expressions to be presented to the user, regardless Our experiments concentrate 
on measuring the perfor­mance of the vector space algorithms desc~ibed in t]le next section. These algorithms 
are used in Pasadena s third filter­ing stage to rank the promising messages passing thlough the first 
two stages of the filter. Using carefully controlled, double-blind experiments in which only one component 
of a ranking algorithm is varied, we can discover which comlm­nents of the vector space algorithms pelform 
bettel in our WAN-based SDI service and why. 1.3 User Interaction A user specifies in each quely of his/her 
pr ofde 11OJV UIanY items he or she wishes to receive and how often the sys­tem should deliver information. 
The Pasadena system 1uns both ranking algorithms currently being e~,aluatcxl, and (le­livers those items 
with the highest ret~ieval status valnes from each. Simultaneously, Pasadena sends a form asking for 
the user s ranking of the relative usefulness of the de­livered items. In order to factor out biases, 
the items are delivered in random order, And neither the Pasade,iz admin­ istrator nor the subscriber 
knows how each algorithm ranked the items. In other words, the experiment is double blind. ) On the feedback 
form, the subscribe may specify ties, i.e. items of equal usefulness by giving them the same rank order. 
If, for example, three items are delivered, such ranks as 2-3-1, 1-2-1, and 1-1-1 are all acceptable 
The Iattel indi­cates that the subscriber found all three items equally useful. Many users felt an overwhelming 
desire to express zbsolute relevance of the delivered items; therefore, a column for ab­solute relevance 
(yes/no) of each delivered item was added to the feedback form in order to measure precision and g,ive 
users the satisfaction of normal relevance assessments. Simple database methods are used to filter out 
a set of documents from the entire collection which match the cat­egories specified in the query, This 
subset of documents is then searched for documents which match the inclusion pat­tern. Those documents 
matching the patttern are searched again for the exclusion pattern. Matches here generate a warning message 
to the subscriber and documents match­ing both patterns are not sent. Documents malching the inclusion 
pattern which do not contain the exclusion lJat­tern are always sent to the subscriber. Those documents 
that fall into the categories contained in the query and which do not contain the qnmy s exclusion pattern 
are ranked by both vector space algorithms. Both algorithms compute a retrieval status value (RS\r) for 
each query. Ranking is then simply the descending order of RSVS, Ranks in a set of identical RSVS are 
arbitrary. Documents chosen to be sent to a subscriber bec~use they matched the 115 inclusion pattern 
are still ranked by both vector space al­gorithms. If neither vector space algorithm gives these doc­uments 
a high rank (retrieves them) then these documents do not contribute to any performance measures.  III 
1I1II nf ~~~~~~~ d Zz3 categories HH 10 Mbytes A5zz9 Xc]usionpaiterns 10 Kbyte 11 Rankin~ Algorithms 
Text Comparison I 5 Kbyte Figure 2: Information Filtering Figure 1.3 graphically depicts the filtering 
stages used by Pasadena. Note that the inclusion pattern matching does not filter out information items 
and is therefore not included in the diagram. 2 Algorithms 2.1 information Trace Comparison One of the 
primary motivations for completely automatic text comparison methods is the large effort involved in 
man­ual indexing. Most of these completely automatic index. ing systems approximate the similarity of 
meaning between two documents, horneosemg, by statistical analysis of the component features of the documents. 
Investigations into the applicability of text traces hypotheses that the use of text fragments smaller 
than words will lead to a better ap­proximation of homeosemy than comparisons based only on words. Teufel 
[Teuf89] presents three arguments which suggest an advantage to the use of text traces over words as 
indexing tokens in a retrieval method. 1. The set of all text traces of a given size and a given alphabet 
can be established a priori. If the vocab­ulary of source messages and queries is uncontrolled, the number, 
size, and identity of all indexing tokens is still known before comparison operations begin, which suggests 
that methods based on text traces may be more flexible in a highly dynamic source collection. 2. Indexing 
based upon text traces is tolerant of spelling and typographical errors. Whe~eas word tokens re­quire 
exact matches for a meaningful comparison, sire. ple statistical measures using smaller text traces pro­vide 
a kind of fuzzy matching. 3. When new words become part of a language, it is often problematic to adapt 
a controlled-vocabulary system which uses words as tokens to make meaningful com­parisons among messages 
and queries. The advantage of using traces is obvious: new terms are simply re­duced to their component 
traces in an identicaifashion to the way old ones are handled.  Teufel has also shown that the use 
of word fragments or text traces as indexing terms has promising potential as the basis for retrieval 
algorithms in environments with an uncontrolled vocabulary. His method is quite robust m its precision 
performance, especially when compared to a sim­pler trigram strategy used by de Heer [DeHe74]. The method 
developed by Teufel stancls in sharp contrast to earlier strategies using text traces because the indexing 
algorithm includes some important semantic components. It uses a large, collectioll-specific stop list 
and eliminates very short words, but uses an anti-stoplist to prevent the elimination of short, semantically 
significant words. Additionally, the method includes an anglnentecl Porter suffix reduction step which 
reduces semantically similal words to common word-fragments. Teufel s augmentation adds reduction steps 
in order to insure that, certail~ m ulf i­ple suffixes are reduced to identical morphological forms. 
It does not insure linguistically correct word stems; however, linguistic correctness is dispensable 
in a syntactical compar­ison. Overlapping N-grams derived from recluced wolck are used as indexing tokens. 
A unique, and important aspect of Tenfel s method is the use of the noise measure [Salt83, p.65] to 
clefine the set of text traces used as indexing tokens. N-grams ~vitb large noise values relative to 
all N-grams of a given size in a given collection are ezterzded to larger N-grams. N-gLam exten­sion 
starts by extracting all overlapping t,rigrams from t ]ic reduced words and counting their frequency 
in each query, in each message, and in the entire collection. The noise of each trigram, the average 
noise, and the standald clc­viation are then calculated. Those trigrams tvith :L uoise value larger than 
the average plus one staudarcl cleviatiotl are extended to tetragrams. Tetragrams ,vith noise gleateL 
than the average plus one standard deviation ale eytendecl to pentagrarns. The lesulting set of tligrams, 
tetragralub, and pentagrams, along with any bigrarns present holn a[l anti-stoplist contains all the 
tokens used for inclexing and retrieval. All other N-grams are eliminated from considerat­ ion as indexing 
tokens. The N-grams derived from a document or a cluery alc called the in~ommtiorr trace of this document 
or query. Al­gorithm A determines the information tlace 01 each InloI ­mation item or query as it arrives 
in the system according to the following steps. A 1 If a WAN header is present in the document,, tvolds 
from the Subject field are extracted and the lest of the header is ignored. 116 A-2 Words are extracted 
from the message text. A 3 Words from a stoplist ([Rljs79] p. 18) are removed. A 4 Words shorter than 
3 letters which do not appear in an anti-st oplist are removed. A 5 The remaining words are reduced using 
an extension of the Porter stemming algorithm ([Teuf89] p. 58). A 6 Overlapping N-grams of lengths three, 
four, and five are generated from the reduced words. A-7 The token frequencies of the resulting set of 
indexing tokens, that is, N-grams of lengths two through five, t~(d, i) are determined. When a query 
interval time has elapsed, the retrieval status values RSVA (q, d) between the query g and each d in 
the current promising subset of the document collection are calculated. RSVA (q, d) uses two methods 
of comparing information traces, direct and indirect; they are applied in combination as proposed in 
[DeHe82]. The direct similar­ity represents the minimum overlap of the two information traces and is 
defined as follows. D.(q, d) = ~min tf(q, ~ ~ t) tf(d, t) tcT ( ) T f(t) = ~ tf(cz, t), d<D The idea 
behind indirect similarity is that certain docu­ments can act as a bridge between a query and other doc­uments 
that contain few or no indexing tokens in common with the query. One examines these bridge documents 
from the collection which contain indexing tokens from a query and other indexing tokens found in a separate 
docu­ment. The indirect similarity [Teuf89] between a query q and a document d, is defined as follows. 
Let G~ be the set of all N­grams in a query q. For each N-gram z in query q (x c Gq), we define a value 
fV=d as the number of documents that contain, in addition to N-gram x, at least one other N-gram from 
document d Then IVz~ is normalized by N=, the number of documents containing N-gram z and by Nd, the 
number of N-grams in document d. The indirect similarity contributed by N-gram x is defined as: N=d u.(d) 
= ~ Summing these components over G~, the complete indirect similarity between a document d and query 
g is defined as  s(q) )=Wq $(d) The direct and indirect similarities between the traces of q and d are 
obtained according to the definition of the algebraic sum of two fuzzy sets: RsvA(q, d) = D.(q, d) + 
Is(q, d) ~.(q, 4 * Is(9, ~)  2.2 S-stemmed Word Comparison The complications involved in word reduction 
are well known. Context free suffix removal is not sufficient to prc,­duce morphologically equivalent 
stems from semantically similar words. Sufix stripping algorithms therefore take fur­ther reduction steps 
to achieve the desired level of Feduction. There is no inexpensive algorithmic word reduction method 
which will retain 100~0 of the semantic meaning of the words in a source text. Advanced methods using 
complex natural language parsing, or algorithms specific to frozen test collections have been developed. 
htost systems, however, prefer to allow for a certain amount of error in or­der to maintain simplicity. 
Even in an environment usiu g purely syntactical comparison, semantic content should be considered. The 
precision of a system using a high level {of suffix stripping is provably worse than a system using on!ly 
a moderate amount of suffix reduction [Ham187]. The second method presented here (called algorithm B) 
therefore takes a different approach to word reduction, Oniy the first two steps of the Porter algorithm 
[Port80] are used. These steps, collectively called S-stemming, lecluce some common plural word forms 
to their singular form and hence produce a negligible rate of over-reduction error. The clis­advantage 
of such a scheme is the large number of different indexing tokens that result after preprocessing. Instead 
of extracting N-grams, method B uses S­stemmed words as indexing tokens. The general approach of this 
algorithm is more precision oriented than that of the extended text traces method. Additionally, the 
%stemmed word algorithm uses the cosine similarity measule il~stead or the minimal overlap measure, and 
no indirect comparison is used. The first few filtering stages in algolithm B ale identi­cal to the strategy 
used in the N-gram method. Database methods and regular expression matches are used to SCICC[ a promising 
subset of the document collection, Steps B-I through B-4 are identical to A-1 through =1--4, B-5 The 
remaining welds are reduced using the first tivo steps of tlLe Porter algorithm, namely pln La,l tvords 
ilre reduced to singular form. B-6 The document frequency df(d, t) of each term is deter­mined. B-7 For 
each d in D and for the query q, te,m frequencies tf(d, t) and t~(q, t),are determined.  Once again, 
the above indexing steps are car] ied OILt for each document and query incrementally as each one entels 
the system. When the time comes to send documents to a subscriber, retrieval status values RSVB (q, d) 
bet\veen the query q and each d of the subset of docunLelLts selected as promising are calculated using 
the standald cosine similarity measure. First, term weights are calculated: d, = ff((l, tt) * t(lf(tt) 
q, = tf(q, tt) * idf(tt) where the inverse document frequency, idf is tdf(t) = I togz(df(t)) + iogz(l~ 
(J ~1) Finally, RSVB (g, d), the cosine of the weighted query term vector and the weighted document term 
vector is de­ termined: &#38; c   SVB( )= where T is the number of different terms in q U D. The 
fundamental questions of this report are: which of these two algorithms performs better at ranking WAN 
in­formation items using natural language queries, and why? Before we can begin to answer these questions, 
we must define what better performance means. The traditional recall-precision graphs are hardly applicable 
because recall requires the number of relevant information items contained in the entire WAN. Calculating 
recall is practically impos­sible. What we need is an effectiveness measure based on the relative usefulness 
of a set of documents. For experi­ments, we would also like some indication of how reliable the retrieval 
performance estimation is. Usefulness [Frei91] is such a measure. 3 The Assessment of Filtering Methods 
3.1 Existing Preference Measures for Effectiveness Precision -recall graphs from standardized test collections 
are used ubiquitously in the IR literature to evaluate the performance of retrieval systems. Because 
of the simplicity of these measures and also because of experiences gained by users and researchers over 
the years, there is a danger that precision -recall values may be interpreted directly, without examining 
component contributions to their overall values. It is misleading and inappropriate to make direct interpretations 
of these parameters. Precision-oriented users are interested in how many non­relevant or fallout documents 
they will have to view for a given retrieval set size. In contrast, recall-oriented users usually prefer 
to gauge system performance by counting how large a retrieval set size they must view in order to obtain 
a certain number of relevant documents. The construction of precision -recall graphs hides this important 
effectiveness information in the curve smoothing process. A number of effectiveness measures that are 
simple vari­ ations of precision -recall have been proposed to make up for some of these shortcomings 
[Salt83]. They all use binary relevance assessments, however. 3.2 Relevance and Retrieval Experiments 
The timeliness ofdelivered information isimportaut. Stale news or known information will not be relevant 
to sub­scribers. In this respect, WAN information hasan advantage overprinted material, because the medium 
delivers infolma­tion faster. Although wedo not measure auser s assessment of the usefulness of the overall 
system relative to newspapers or other printed matter, there are encouraging results from other WAN-based 
information systems [Giff90], [Nlalo87]. SDI services model the user s information need with a so-called 
user pr-ojite. Oneof the most important aspects of any SDI system is how well a profile accurately and 
effec­tively mirrors its user s information need. Commercial SDI services use a simple Boolean retrieval 
model ancl stored Boolean queries for user profiles. Delivered items are usw ally not ranked, and when 
the effectiveness of sL~ch systems is measured, the measurements are always binary relevance assessments. 
The usefulness of a retrieved item depends not only on its timeliness and availability, but also ou the 
user s n~o­rnentary interest. It is also quite evident that the abso­lute relevance and usefulness of 
individual items in a rapidly changing source message collection must be difeleut from day today. Although 
definitions ofrelevance in information retrieval are once again gaining attention in the literature [Lose91], 
measurements other than precision -,ccall have unfortunately not been heavily exploited for performance 
comparisons in evaluating new IR systems. It is impossible to control the large fluctuu(iolls ilk atxo­lute 
message relevance. Likewise, it is impossible 10 plecfict or restrain the drift in a subscriber s intelests. 
Theleforcj comparisons ale restricted to an enviromneut tvhere indiv­idual users specify their retrieval 
set sizes aiLd quety texts. In Pasadena, subscribers have swift and direct control over these parametersin 
their profiles. Since the retrieval set size varies from subscriber to subscriber in these experiments, 
we do not attempt tomeasure itsinfluence in algorithm perfor­mance. In SDI systems, meaningful performance 
comparisons are restricted to relatively short timeintervals because freez­ing any part of the system, 
be it query text, item col]c?ctiou, or even retrieval set size reduces the usefulness and absolute relevance 
of all items in the system, thereby depressing per­formance ofanyretrieval algorithm used. Ollelrl~~stclllestioll 
the real-world applicability of results based on such artificial conditions. We have therefore restricted 
experiments to a leal op­erating environment. The Pasadena inforlnation filter has quite a few user-features 
to improve absolute message rel­evance; these features, however, make it some]vhat more difficult to 
compare retrieval algorithms. Fol example, snl>­scribers specify positive and negative Boolean filtel 
stages, which can override the two vector space retrieval algorithms and reduce the number of usable 
results i)er e~periment,  3.3 Usefulness Usefulness is an effectiveness measule whic]l compales two 
retrieval algorithms. Giveu t\vo algori(lims, .A al~d B, ~o (A, B) expresses Whethel A is more effectrve 
than B or vice versa. A positive value indicates that B is more effec­tive than A; a negative value signifies 
that B is less effective than A. The measure is specifically suited to gauge IR al­gorithm performance 
in a WAN envirolllnclit. It uses all preference relations contained in each user s ranliiug of a 118 
retrieved set of information items. The notion of item rele­vance in this effectiveness measure is not 
an absolute binary (relevant / non-relevant) judgement. Instead, subscribers rank information relevance 
relative to other items. The approach and notation is that of a probability space, where the probability 
of certain events is modeled by the function values of random variables. Each delivery of a set of messages 
to a subscriber is an experiment, and each rank­ing the user specifies is treated as a sample. The usefulness 
measure also includes an error probability calculation which is helpful in experimental evaluation of 
algorithm perfor­mance. The error calculation indicates the reliability of the measured difference in 
performance between two algorithms. A more detailed discussion and calibration of usefulness can be found 
in [Frei91]. The measure is implemented in Pasadena as follows. Subscribers fill out feedback forms (see 
figure 3) in which they rank the relative usefulness of the messages which were delivered. These rankings 
are then interpreted as a set of preferences among all pairs of messages in a, retrieved set. The usefulness 
measure uses the notion of preference rela­tions that was formalized in [Scha89]. A person p s prefer­ence 
of message d to message d is written as d <P d . In [Frei91] the set of these preference relations obtained 
for a person p whose information need is represented by query g on the retrieved set of WAN messages 
R is expressed as Ifp n {(d, d )ld, d @D,q, r-)}, where D is the promising subset of the WAN message 
col­lection, and T is the number of items received, a parameter specified by the subscriber p, and, HP 
= {(d, d )[d+P d }. Each of our two retrieval algorithms produces a ranked list of RSVS, namely the 
RSVA and RSVB values. These values can also be used to define the preference relations of the ranking 
algorithm among the messages. Algorithm A, produces a set of preferences: ~,4 := {(d, d )lRSvA(q, d) 
< RSvA(g, d )}. Likewise, algorithm B defines the set of preferences ffB := {(d, d )lIiLSVB(q, d) < 
RSVB(q, d )} from the retrieved message set R(D, g, r). Then, the portion of user-assigned preferences 
satisfied by each algorithm is expressed in two random variables: which expresses the fraction of preferences 
satisfied by algo­rithm A, and ~(D, p,q,,) = lR2(D,q,~)nIIPnIrBl lR (D, g,r)n IIPl which is the fraction 
of preferences satisfied by method B. These fractions are, by definition, between (1 and 1; they are 
the number of preferences that the user and algorithm have in common divided by the total number of user-preferences. 
To: wyleClinf.ethz.ch Subject: Feedback form (query ir) FEEDBACK 302 Please rank the usefulness of the 
information items you just received. The most useful item should be ranked 1, the sec- I ond most useful 
2, and so on. You can also specify whether you consider the postings relevant to your clnery by entering 
Yes or No. Enter your rank assessments in the Rank fields and your relevance judgement into the Relv 
fields below. This form should be returned to pasadena. Please do not delete the line above which begins 
with the word FEEDBACK or the END line below. Thank you for participating. Msg Subject Rank r{clv 354 
Call for Papers: \Vorkshop on Language . 355 NL-KR Digest, Volume 8 No. 4 356 electronic clictionaries 
 END @(#) feedback.sam 1.2 91/01/?-1 10,32:28 PASADENA Last Challgc: 91/01/24 Figure 3: Feedback Form 
 The preferences expressed on the feedback forms lead to experimental approximations of the random vari.] 
bles .Y and Y. These experimentally determined values are c[euoted by x and y. The tth experiment produces 
p~eference ratios z ~ and V, because both algorltl~lns are used to pIoduce the list of messages deliveled 
to that subsclibel. For each of the feedback forms (experiments) processed, the differences between z, 
and y, are calcul~ted; zero dif­ferences are discarded. The differences are theu sorted in ascending 
order according to theil absolute ~,alues Differ­ences with identical absolute values are assigned an 
arith­metic average of all sorted sequence positions (1 anks). w+ .. . is defhed as the sum of the ranks 
with posltl~,e differences. Usefulness is then defined as: 4W+ A B = k(k+l) 1 where k is the number 
of feedback forms processed mill us those with zero differences. Usefulness indicates how often the J, 
values are larp,el than the x, s. Adjusted usefulness is an indication of how much greater the g, s are 
than the 2, s. It i> dc(III(,(l ah: The error probability, or the probability of lejecliup, a tl ue hypothesis 
is ap})loxiluated by: where random UA, B var is a iable function W+, valued random value based on the 
~=k(k+l) 4 ~, = k(k + l)(2k 24 + 1) and J!!$2 =l-A .. eT. _t2 4 Applying Usefulness to WAN Information 
As noted earlier, the development of the usefulness measure was motivated by perceived shortcomings in 
the precision ­recall evaluation parameters. The error probability associ­ated with usefulness is particularly 
helpful for experimen­tation because it establishes a stopping criterion. In this section we shall present 
some of the experiments we have run in Pasadena to measure algorithm effectiveness. Upon receiving a 
feedback form, the system calculates the x and y preference ratios for the two algorithms being compared. 
The precision tallies for each algorithm are also updated from the absolute relevance column of the form 
(see figure 3). Running for a few tainty (P~ the method the weeks, < 0.05) B. two we algorithms established 
that method descwith A ribed a perfo in high rmed 2.1 and degree better of 2.2 cer­than AB I .1.050 
05 1 Figure 4: Usefulness, N-gram versus S-stemmed word meth­ods Figure 4 displays this result both numerically 
and graph­ically. The graphic has a scale ranging from -1 to 1 repre­senting the possible values in the 
usefulness measure. The filled-in bar on the scale represents the usefulness measure comparing the two 
algorithms. The size of the bar is the magnitude of the measure and it s direction from the origin corresponds 
to which algorithm is better. Note that although the performance of algorithm A is unmistakably better, 
the adjusted usefulness indicates that the difference in performance is small. The precision mea­sures 
of the two algorithms are also relatively close; there is a difference of only 15% (figure 5). Precision 
in these experiments is determined by sum­ming all documents retrieved by a given algorithm that were 
judged relevant by the recipient, and dividing this sum by the total number of documents retrieved by 
the algorithm for all subscribers. The retrieval cut-off point of the algo­rithm is not held constant. 
The measure does not distinguish between precision-oriented users, who typically choose small retrieval 
set sizes, and recall-oriented users who are willing to examine more documents. 02 + ,,ds N-srun Figure 
5: Precision of baseline methods 4.1 Variations of Baseline Methods To find out which component(s) of 
method B were respon­sible for this performance difference, we systematically ran experiments whereby 
one component of one method was var­ied, then measured the retrieval performance of the variation relative 
to the baseline algorithms and each other. Table 1 describes the variations of the baseline algorithms, 
cate­gorized by the extent of the word reduction, type of token used in indexing, and the type of text 
comparison algorithm. The first two entries are the baseline methods, A and B re­spectively. The last 
two entries are variations of method B, described below. Algorithm Reduction Token S1mllar]ty Description 
Label Method Type Measure N-grams, Indirect Min Overlap Similarity A Porter N-grams &#38; Incllrect 
S-stemmed Words B S.stemming CosllleW. ~d~ Reduced Words B.1 Porter \Vords Cosllle Reduced Words, NIIII 
overlap Indirect S]mdarity B.2 Porter Words &#38; I]ldlrect Table 1: Variations of baseline methods The 
measurement of retrieval performance differences due to different degrees of word reduction have been 
re­peated often in the literature [Harm87], [Lovi71], [Salt 83] ou a variety of static collections. The 
variation of Algorithm B called B. 1, simply increases the amount of word leduction used during indexing; 
the text comparison method and all other components of the algorithm are identical to B. The in­dexing 
tokens used for comparison in B. 1 are Leduced ~volds resulting from the application of the modified 
Porter algo­rithm used in method A. Using the usefulness measure, the performance of B. 1 is compared 
to A, B, and B.2 described below. The second variation to algorithm B is called B.2. This algorithm again 
uses tokens resulting from the application of the reduction algorithm used in algorithm A. However, it 
also uses the same comparison measure flom algorithm A when calculating RSVB z (y, d) values. The difference 
be­tween B.2 and A is that algorithm A uses N-grams, while B.2 uses highly reduced words. In B.2, noise 
is not conl­puted and no tokens are eliminated. The performance of B.2 is measured against A, B, and 
B. 1. 120 BZA B B.1 u U*pk u u* ~k u u* l k uu* pk~ A -0.40 -0.02 0.04 -0.43 -0.04 0.03 0.33 0.09 0.06 
B 0.40 0.02 0.04 0.39 0.03 0.12 0.34 0.03 0.21   B.1 0.43 0.04 0.03 -0.39 -0.03 0.12 0.50 0.01 0.07 
B.2 -0.33 -0.09 0.60 -0.34 -0.03 0.21 -0.50 -0.01 0.07 Table 2: Performance of variations to baseline 
methods 4.2 Performance Improvements 5 Conclusion Table 2 summarizes our effectiveness estimations of 
the var­5.1 Performance in SD I Systems ious algorithms listed in table 1. The methods listed in the 
left-most column of table 2 are compared to the methods We must reluctantly conclude that in our lt7AN 
suhscriptioulisted in the column headers. In each case, the u and u* val­service environment, neither 
extended N-grams as iudexing ues displayed are for uro~,c~ttimn and u~OW,cOIUmm. Notice tokens nor the 
indirect text comparison algolitfln~ plovidesthat u and U* are symmetric, and the upper-diagonal ma­significantly 
better retrieval performance than the standard trix is simply the lower-diagonal matrix with signs reversed. 
methods of using word tokens and the dilect cosine similar-Values in the diagonal of this table are, 
of course, all zero ity measure. Retlieval effectiveness is of the same older of and therefore not displayed. 
magnitude in both biseline methods and all variatiom \ve The B.2 algorithm, that is, using Porter stemmed 
words have examined so far. and indirect similarity, performs best. Algorithm A, namely Extended N-grams 
as indexing tokens do not offer anythe N-gram method with indirect similarity, performs second performance 
improvement over words. In fact tl~ew expel ­best, and results from B. 1 indicate that, in general, porter. 
 iments indicate that they are slightly WOISC. The iuduec t stemmed words are better than S-stemmed words 
when us-. . . Slmlklty measule 1s Sollle}v hat better th~n t]le c05111e l~~e:i,­ing the cosine direct 
similarity measure in the Pasadena sys­sure, but again, the difference is not large. FI]ially, \ve CaII 
tem. }Ve can also observe that in all cases, an algorithm conclude that full-pelter stemming is slightly 
better fol iLl­employing indirect similarity performs better than one using dexing WAN messages than 
$stemmiug. the standard cosine similarity. Performance improvements due to the type of similarity measure 
used are larger than Another conclusion we can draw from the experience differences caused by the type 
of indexing token used. gained running these experiments is that the usefulucss pcL­ formauce measure 
is very advantageous in mea,sllriug rl:-All of the performance improvements detected in these trieval 
effectiveness. LVe know, for example, t]ial lnolc ex­experiments are relatively small. The adjusted usefulness 
periments are needed to velify one of ollr fiiitlillg:., ii] >l,il c values are within the range of 0.01 
< UJ, B < 0.1. Though of having a fair number of samples. No other effeci, i~,enms the effectiveness 
differences are small, we can observe (under measure offers this kind of elror estimation,the conditions 
of these experiments), that: c Extra word reduction steps improve performance. 5.2 Future Directions 
Indirect similarity is better than the standard cosine An important goal of the on-going rievelopmell( 
UI Pasadell,i method. is, of course, to improve the serwices provided to su bsc~ibels. Because many 
of the fundamental elements of the system ,IM Reduced words as indexing tokens are better than N­new, 
nearly all efforts in the area of retlicval pellolIlia]Lccgrams. improvement are simultaneously research 
topics. 1 helefole, if a new, efficient indexing and retrieval met hod is publisl~c[l, The error probability 
of the A versus B.2 comparison in it requires only a small effort to graft the nctv ,ilSoliLIL1il llL 
lu table 2 indicates that the retrieval performance difference Pasadena and compare it to existing methods. 
calculated has a large degree of uncertainty. The number of For example, a p~oject was recently inlpletl)cntcd 
iii experiments in this particular comparison was 90. Because Pasadena that expands single-word t,e,ms 
illt,c ~,llrases, aiLd of ties, approximately ten values were rejected. Although a k value of 80 is not 
particularly small, the variance and there­ uses the indirect similarity measure on the Iesl]lting t,okcl~ 
collection of words and phrases. There are definitely li,~­fore the pk value is high, indicating that 
more experiments provements to be gained from using l)lu,lse~, l~llt [ILCSC ill)­ are needed to determine 
the real difference in effectiveness. plovements do uot seem monumentally better [IL<II[ st{][lda],1 
 From these results, we must report that we measured no methods. It is too early to say with certainty 
that 1}~c pe~for­ difference, in spite of running 90 different experiments, with mance improvements from 
phrases is small, I>u t prelimin My 80 valid results. indications ale that this stlategy is not tl~c 
pcl folmamce Here lies one of the most compelling reasons for using the breaktluough for which we ale 
searchiug. usefulness measure: the probability of error approximation Although some of the genelal theory, 
met]~ods, and fil~d­ pk, This error estimation prevents our drawing an improper k@ from StatiC collections 
tlall?.fer well to Like dynamic il~­ conclusion based solely on precision performance. formation available 
on WANS, other aspects of system per-[Malo87] T, W. Malone, K. R. Grant, F.A. Turbak, S. A. formance 
are different. Many statistical aspects of the WAN Brobst, M. D. Cohen, Intelligent Information­ document 
collection at a given point in time are similar to sharing systems, Commun. ACM 30, (5), May static collections 
[Wyle89]. However, in contrast to test col- 1987, pp. 390-402 lections with known recall values, live 
SDI filtering sys­ [Port80] M. F. Porter, An Algorithm for Sufix Stripping,tems cannot hope to measure 
the number of relevant docu-Program, 14 (3), pp. 130-137; 1980. ments in the system. [Rijs79] C.J. van 
Rijsbergen, Information Retrieval, Sec- Many more experiments on variations of the algorithms ond Edition, 
Butterworths, London, pp. 17-23;presented here are now running to verify our current results and further 
reduce the error probabilities in the hypotheses 1979. tested. We are also measuring the improvements 
gained by [Salt83] G. Salton, M. J. McGill, lntroductzon to Modern using phrases as indexing tokens. 
 fn~ormation Retrievai, McGraw-Hill, New York; We are very hopeful that strategies involving differen-1983. 
tial weighting of text from separate areas of WAN messages [Scha89] P. Schauble, Information Retrieval 
Based on In­will give much larger performance improvements than we formation Structures, Informatik-Dissertationenhave 
thus far obtained. Having formed a theoretical frame­ Vdf-Verlag, Ziirich Nr. 15; 1989, p. 8. work for 
differential term weighting based on a term s source paragraph, we are still testing weighting methods 
on static [Teuf89] B. Teufel, Informationsspuren zum numerischen collections. Und graph ischen Vergleich 
uon reduzierten natiirlichsprachlichen Texten, Informatik-Dissertation Vdf-Verlag Ziirich Nr. References 
13; 1989. [Ande87] B. Anderson, B. Costales, H. Henderson, Unix [Wyle89] M. F. Wyle, H. P. Frei, Retrzec.ung 
Htghly Dy-Communications, Howard W. Sams and Com-namic, Widely Distributed Information, Proc. of pany 
The Waite Group, Indianapolis, Indiana; the 12th ACM SIGIR Conf. on R8zD in Informa­1987. tion Retrieval, 
ACM, Boston MA, pp. 108-115; 1989. [DeHe74] T. De Heer, Experiments with syntactic traces in information 
retrieval, Inform. Stor. Retriev. 10, pp. 133-144; 1974. [DeHe82] T. De Heer, The application of the 
concept oj horneosemy to natural language information r-e. trieval., Information Processing &#38; Management 
18, no. 5, pp. 229-236; 1974. [Frei91] H. P. Frei, P. Schauble, Determining the Ef­fectiveness of Retrieval 
Algorithms, Information Processing &#38; Management, 27, (2 &#38; 3), 1991. [Giff90] D. K. Gifford, Polychannel 
Systems for Mass Digital Communication, Commun. ACM 33, (2), February 1990, pp. 141-151. [Harm87] D. 
Harman, A failure anaigsis on the limitations of sufixing an an online environment, Proc. of the 10th 
ACM SIGIR Conf. on R &#38; D in Infor­mation Retrieval, ACM, New Orleans, LO, pp. 10~-108; 1987. [Lesk71] 
M. E. Lesk &#38; G, Salton, Relevance Assess­ments and Retrieval System Evaluation, in G. Salton (Ed.) 
The SMART Retrieval System- Experiments, ch. 26. Prentice-Hall, Englewood Cliffs, NH; 1971.  [Lose91] 
R. M. Losee, An Analytic Measure Predicting Information Retrieval System Performance, Im formation Processing 
&#38; Management 27 (l), pp. 1-13, 1991. [Lovi71] B. J. Lovins, Error evaluation for stemming al­ gorithms 
as clustering algortthrns, Journal of the American Society for Information Science, 22, pp. 28-40; 1981. 
  
			