
 Online Algorithms for Locating Checkpoints Marshall Bern * Daniel H. Greene * Arvind Raghunathan t 
Madhu Sudan * Abstract Motivated by applications in data compression, debug- ging, and physical simulation, 
we consider the problem of adaptively choosing locations in a long computation at which to save intermediate 
results. Such checkpoints allow faster recomputation of arbitrary requested points within the computation. 
We abstract the problem to a server problem in which k servers move along a line in a single direction, 
modeling the fact that most computa- tions are not reversible. Since checkpoints may be arbi- trarily 
copied, we allow a server to jump to any location currently occupied by another server. We present on-line 
algorithms and analyze their competitiveness. We give lower bounds on the competitiveness of any online 
algorithm and show that our algorithms achieve these bounds within relatively small factors. 1. Introduction 
Suppose you are building software for accessing an en- cyclopedia. To save space, you store the encyclopedia 
in compressed form using an adaptive data compressor [8, 14]. Your software must handle requests from 
users wishing to read arbitrarily-located articles within the encyclopedia. Here a problem arises: in 
order to de- compress a specific article, you must recreate the com- pression statistics as they were 
at the time that article was compressed. There are several possible approaches to this prob- lem. One 
could save all compression statistics, but this defeats the purpose of compression. One could *Xerox 
PAI=tC, 3333 Coyote Hill Rd., PMo Alto, CA, 94304 t Courant Institute, New York University I Computer 
Science Division, UC - Berkeley, supported in part by NSF grant CCR-8947792 Permission to copy without 
fee all or part of this material is granted pro-vided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. break the encyclopedia into smaller 
files-or equiva-lently restart the compressor occasionally- but this, too, compromises compression. A 
similar solution is to occasionally save-or checkpoint- the compression statistics while compressing; 
then a request is handled by finding the closest previous checkpoint and recom-puting statistics from 
that point up to the requested article. The most flexible solution allows the locations of the checkpoints 
to move and adapt to the pattern of requests. In this paper we investigate adaptive solu- tions to the 
problem of locating checkpoints. Besides data compression our work applies to a num- ber of other contexts. 
 In debugging a long program, one typically probes an irreversible computation at various points in or- 
der to check intermediate values [10].  In studying an irreversible physical system, one would like 
to interactively probe a computer sim- ulation.  In testing a VLSI design, different members of a design 
team may work on different parts of a criti- cal path simultaneously. Thus a useful feature of a waveform 
simulator such as Spice would be the ca- pability to answer probes at arbitrary points along a path. 
As above, the computation of a waveform is typically irreversible.  We model the problem as follows. 
(Here we use the terminology of the data compression application.) We can afford k "permanent" checkpoints; 
in addition, we set aside scratch space for one temporary checkpoint. We think of the temporary checkpoint 
as residing in fast memory so that it can be rapidly updated as we read through the encyclopedia; the 
other k checkpoints may reside in slow memory. We are presented with a sequence of n requests, each at 
a real number in the half-open interval [0, m). A permanent checkpoint may (1) move forward (towards 
larger numbers) along positions in [0, m), incurring cost equal to the difference between starting and 
ending po- sitions; (2) fork, that is, immediately move at no cost, &#38;#169; 1990 ACM 089791-361-2/90/0005/0359 
$1.50 359 to a position currently occupied by another checkpoint; or (3) reslarl, at no cost, at position 
0. Any number of these moves may be made in response to a request. Af-ter these moves, the request at 
r E [0, m) is serviced by the temporary checkpoint, incurring fixed cost 1 plus the distance to the request 
from the closest checkpoint at a position no greater than r. In the terminology of Manasse et al [11], 
each request is serviced by an excur-sion from the nearest permanent checkpoint. The tem- porary checkpoint 
does not persist between requests. We would like to minimize the total cost of a sequence of requests; 
that is, we are interested in maximizing throughput rather than minimizing worst-case latency. In our 
model, the only costs are computation; copying one block of memory to another, as in a fork move, is 
free. For simplicity, we carry out our analysis assuming that position m coincides with position 0, that 
is, the encyclopedia is circular. This assumption eliminates move (3) and clarifies our arguments. We 
then show how to transfer our results back to the linear case. We analyze the compelitiveness of our 
algorithms [3, 9, 11, 13]. That is, we compare the performance of an online algorithm against the performance 
of an opti- mal offiine algorithm that sees all requests in advance. An algorithm is called c-competitive 
if its cost on any sequence of n requests is at most O(1) greater than c times the offline algorithm's 
cost. This style of analy- sis refines traditional worst-case analysis.. Competitive analysis is worst-case 
in that no assumptions about the distribution or correlation of requests are made; how- ever, it measures 
performance relative to what is achiev- able by an omniscient algorithm, rather than in abso- lute terms. 
A discretized version of our problem is an example of a task system as defined by Borodin et al [3]. 
Borodin et al, however, study a more general model in which the costs of serving requests- rather than 
just request locations-may be chosen by an adversary, so their bounds have no nontrivial implications 
for our prob-lem. Other related work includes a number of recent papers on server problems [2, 4, 5, 
6, 7, 11, 12]. The paper that addresses the problem most similar to our work is by Chrobak et al [5]. 
This paper presents an optimally (i.e., k-) competitive algorithm for k servers moving on a line. Our 
problem differs from this problem in several ways: our servers move in only one direction, we include 
the additive cost of 1 for each request, we allow excursions, and, most crucially, we allow the fork 
move. To our knowledge, our work introduces the fork move to the server literature. This move is very 
natural for applications in which servers represent information rather than physical objects. We obtain 
the following results, comparing online al- gorithms against offiine algorithms with an equal num- ber 
of checkpoints: For the case of k = 1, that is, only one per-manent checkpoint, a lower bound of (ml/3/2)-competitiveness 
that applies to any deterministic online algorithm.  For k = 1, a rnemoryless 4mX/3-competitive algo- 
rithm.  For any k, a 2(k + 1)ml/Z-competitive algorithm when the fork move is disallowed for both online 
and offline algorithms. (This result generalizes the upper bound for k = 1 and separates the difficulties 
introduced by one-way motion and forking.)  For k >_ 3, a lower bound of fl(ml/2)-competitiveness. (Here 
f~ notation implies a con-stant independent of k as well as m.)  For k >_ 2, a memoryless 3(km)X/2-competitive 
al-gorithm.  We also give lower bounds on the competitiveness of an online algorithm compared with 
an offiine algorithm with fewer servers. Finally, we give algorithms for the offiine problem. Some proofs 
are omitted or merely sketched in this preliminary version. The variable m is the ratio between the total 
amount of computation and the minimum amount of work to answer a request. In some sense it represents 
the num-ber of smallest units: articles in an encyclopedia or lines of code in a program to be debugged. 
For the location of checkpoints to matter, m must be much greater than k; moreover, since the size of 
intermediate results typi- cally increases as the overall length of the computation increases, k may 
have to decrease with increasing m. So except for the case of k = 2 we have obtained al-gorithms that 
match our lower bounds up to relatively small factors. From a practical point of view, our results are 
mixed. Although it is encouraging that there exist algorithms more competitive than the (m/k)-competitiveness 
of static checkpoints, our performance guarantees are quite weak for interesting values of m (say 100,000). 
Our lower bounds show that no online algorithm can always be satisfying when viewed retrospectively. 
Finally, we believe our work introduces an interest-ing test case for competitive analysis. We are extending 
this type of analysis to a problem more difficult than those previously considered (caching, list access, 
online scheduling of elevators and disk drives), as indicated by our strong lower bounds. Can competitive 
analysis nev- ertheless lead us to algorithms for locating checkpoints that perform well in practice? 
360 2. Preliminaries In subsequent sections, we refer to the permanent checkpoints as servers and the 
temporary checkpoint as the temporary server. In analyzing competitiveness, we usually refer to the online 
algorithm under consid- eration as the player and the optimal offiine algorithm as the adversary. Player 
servers and adversary servers (sometimes called simply players and adversaries when no confu-~sion is 
possible) both move on a directed circle of cir- zumference m, with m 1/3 > max{3, k} where k is the 
aumber of player servers. On the directed circle, all servers move only clockwise. We use interval notation 
to denote arcs of the di-rected circle. For example [x, y) with x < y < m de-notes the clockwise half-open 
arc from x to y, i.e., the one that does not contain m, while [y,x) denotes the (:omplementary arc. The 
distance d(s, x) is the length of [s, x]. The sequence of request locations is denoted rl,r2,..., rn, 
where each ri is a real number in [0, m). J~t denotes rl,... , r t and R[s,t] denotes r~, rs+l,... , 
r t. By the term online, we mean that the player chooses the positions of his servers at time t deterministically 
as a function of the request history Rt. If in addition, the ]:,layer uses only the current request r 
t and the current positions of his servers to choose his next move, then lhe algorithm is called memoryless 
[11, 12]. The offtine algorithm (i.e., the adversary) may use all of Rn to choose server locations at 
any time t. For an online algorithm P, let Ralio(P,R,~) denote the ratio of the cost incurred by P to 
the cost incurred by the adversary cn request sequence Rn. The competitiveness of online algorithm P 
is then defined to be the "worst ratio" limsupn_.oo suPR" Ratio(P, P~ ). 3. 1-Server Lower Bound This 
section gives the first in a series of lower bounds on the competitiveness of deterministic online algorithms 
as compared to optimal offiine algorithms. There ap-pears to be no advantage in allowing the online algo- 
rithms to make probabilistic choices based on Rt, but for clarity the proofs are restricted to deterministic 
al- gorithms. (See [1] for more on randomization.) Theorem 1. An online 1-server algorithm can be no 
better than (ml/3/2)-competitive. Proof." We describe an adversary strategy that can be repeated on epochs 
of n = [m 1/3] requests. Let the adversary's server be at location z and the history of requests be Rt. 
The adversary considers extending the history by n -1 requests at location z + m 1/3 followed by one 
request at either (1) z or (2) z+m 1/3. Case (2) is used if the player algorithm would keep its server 
in (z+ m 1/3, z] for the entire subsequence R[t + 1, t + n] (most likely by holding back at z). In this 
case the adversary moves up to z+m 1]3, incurring a cost ofm 1/3 and then has n requests at cost 1. By 
contrast the player has n requests at cost at least m 1/3 + 1 each, for a total of at least n(m 1/3 -~ 
1). The ratio n(m U3 + 1)/(n + m 1/3) is at least mi/3/2. If the player ever leaves the arc (z + m 1/3, 
z], then case (1) is used; the adversary holds back at z, spending n(mW3 + 1) _< 2m ~/3 to process the 
requests, and the player must spend m -m 1/3 + n because of the empty arc. In either case the player 
incurs cost at least mW3/2 times the adversary's cost for the epoch. Essentially the same argument works 
for the case of servers moving on the line rather than the circle. The adversary first moves its server 
to m/2. There follow at least m2/3/2 epochs of the form above, as the adver- sary's server progresses 
from m/2 to m. In each epoch the ratio of the player's cost to the adversary's cost is at least ml/3/2. 
The player's total work before the ad- versary must reset at m/2 is at least m 4/3, so over an entire 
"superepoch" the player's ratio can he no better than m113/2 I. 4. 1-Server Upper Bound In this section 
we give an algorithm for the movement of a single server. This algorithm will lead us to the more general 
algorithm for an arbitrary number of servers when both player and adversary are not allowed to fork. 
We show that the following simple, memoryless algo- rithm, called Two-PHAsE, is 4ma/3-competitive. for 
each request r do (Phase 1) Move the server (at s) towards r by max{O, d(s, r) -m 2l~} (Phase 2) Move 
the server (now at s') further towards r by max{0, d(~',r)-mW3m,/3+l } Serve r using the temporary server 
od In order to analyze the performance of this algorithm and later online algorithms, we think of player 
and ad- versary working in parallel on rl, r2,..., rn. We define a potential function (I) that is used 
to "smooth" the induction. The player's work typically reduces (I) by at least the work done, while the 
adver- sary's work increases (I) by at most the competitive fac- tor times the amount of work done. These 
bounds, along with bounds on the initial and final values of 4), suffice to bound the player's work on 
sequence Rn by a multiple of the adversary's. 361 In this section, we define <I, as follows, where s 
de-notes the position of the player's server and x denotes the position of the adversary's server. ~1 
= d(s, x) if2 = min{m, m 1/3 . d(s, z)} ~3 ---- max{O, 2m213(rn 1/3 -- d(s, x))} = (]~1 -1- (I)2 "~- 
(I)3 This ~ is a piecewise-linear function of the distance between player and adversary. When adversary 
and player are further than m 2/3 apart, ff decreases with slope 1 as the player approaches the adversary, 
reflect- ing the rapid motion of Phase 1. When adversary and player are between m 2/3 and m 1/3 apart, 
 decreases with slope about m 113 to compensate for the slower mo- tion of Phase 2. Closer than m 1/3 
apart, ~ increases with slope about 2m 2/3 so that it does not jump dis-continuously when the player 
crosses the adversary or vice versa. Let s denote (as above) the player's position before Phase 1, s 
~ the player's position after Phase 1 and be- fore Phase 2, and s" the player's position after Phase 
2. Similarly let x and # be the adversary's starting and final positions. Let Wp denote the total cost 
incurred by the player in serving r, that is, 1 plus the total per- manent and temporary checkpoint motion. 
Similarly let WA denote the total cost incurred by the adversary. For ease of analysis, the actions following 
the re-ceipt of a request r (= 7"/ for some i) are conceptu-ally divided into the following steps: (1) 
the adversary moves arbitrarily; (2) the player executes an iteration of Two-PHASE; and, (3) the adversary 
services the re- quest without moving a permanent checkpoint. The first two lemmas analyze the changes 
in during steps (1) and (2). Lemma 1. When the adversary moves, increases by at most (m I/3 + 1). d(x, 
#). Proofi First note that ¢ varies continuously when the adversary crosses over the player or when the 
player crosses over the adversary (i.e., when d(s,x) changes from m to 0 or 0 to m). Next observe that 
when the adversary moves distance d without crossing the player, ~1 increases by at most d, ~2 increases 
by at most ma/3d, and q~3 does not increase. Thus ¢ increases by at most (m 1/3 + 1)-d(z, z') when the 
adversary moves fromxtox ~. Lemma 2. Assume d(x', r) < m 2/3 m 1/3. Then in Phase 1, ~b decreases by 
at le~t d(s, s'), and in Phase 2, (b decreases by at least (m 1/3 + 1). d(s', s") -2m 1/3, d(z', ~). 
Proof: If d(s,#) = 0, then the player does not move in Phase 1, so cannot increase. On the other hand, 
if d(s, s') > 0 then d(s', r) = m 2/3, and the adversary at z ~ is at least m 1[3 ahead of the player. 
Hence if1 decreases by at least d(s, #) and neither <I'2 nor if3 in- crease. We now analyze the change 
in ~ during Phase 2. As above, the case that d(#, s") -0 is trivial. So assume d(s',s") > 0 and consider 
the case that x' E (r,#], that is, the adversary lies behind the player at the end of Phase 1. Then in 
Phase 2, ~x decreases by d(#, s") and if2 and if3 do not increase. Thus if- their total- de- creases 
by at least 0 >__ (m 1/3 + 1)d(s', r)-2ml/3d(s ', r) > (m 1/3 + 1)d(s', s")-2ml/3d(x', r). So assume 
z~ E (#, r]. To handle this difficult case we further subdivide the player's Phase 2 motion. Let z be 
such that m~/3d(s ',z) = d(#,r), and let s* be the first of s", z, and x ~ after #. As the player moves 
from s ~ to s*, ffa decreases by d(#,s*) and ff~ decreases by ml/3d(#, s*). Now let r* be the point such 
that d(r*, r) = ml/3d(s ', s*). Note that r* = x' exactly when s* = z; otherwise, r* is in (x ~, r]. 
Also note that r* E [s", r] since d(r*,r) = ml/3d(s ',s*) < ml/3d(s ',s'') < ml/3 d(s''r) -- ml/3 m 1/3 
--[- 1 < d(s', r) -m 1/3 < d(s", ~). The increase in ~3 as the player moves from # to s* is at most 
2m2/3d(s ', s*) = 2ml/3d(r *, r). Altogether, qb decreases by at least (m 1/3 + 1)d(s', s*) - 2ml/3d(r 
*, r) in this first "subphase". For the second subphase- from s* to s"-we sep-arately consider the three 
cases: (1) s* = s", (2) s* = z (and hence x' = r*), and (3) s* = z'. We assert that in each case, decreases 
by at least (m 1/3 + 1) -d(s*, s") -2ml/3d(z ', r*). Summing this assertion with the bound above for 
the first subphase will complete the proof. In case (1), d(s*, s") = 0 and the assertion is trivially 
true. In case (2), d(s", x') = d(s', r) -d(s', s") -d(x',r) >_ d(s', r) -d(s', s") -ml/3d(s', s*) > d(s', 
~) -(m ~13 + 1). d(s', s") > d(s', ~) -(d(~', ~) -m 1/~) > ml/3 follows from the definition of Two-PHASE. 
Thus ~3 does not increase during the motion from s* to s". (b I q- ~2 decreases by at least (ml/3+ 1)d(s*, 
s"), so the total decrease in satisfies the assertion. 362 In case (3) the player crosses over the adversary 
at s*. Recall that ff is continuous at the crossover. In the subsequent motion from s* to s t~, ffl decreases 
by d(s*,s'l), while ¢2 and ¢3 remain fixed at m and 0. So ¢ decreases by d(s*, s") = (m 1/3 + 1)d(s*, 
s") -ml/3d(s *, s"), which is at least (ml/3 + 1)d(s*, s") -2ml/3d(z', r*) since d(z', r*) = d(s*, r*) 
> d(s*, s"). The next lemma relates A¢, the total change in ¢ during steps (1) and (2), to the total 
player and adver- sary costs Wp and WA (in all three steps). Lemma 3. For each request r, Wpq-A¢ < 4ml/3.W 
A. Proof: The adversary's work WA = 1 + d(x,x') + ,t(z',r), since an optimal offiine algorithm would 
not Naste motion by going all the way around the circle. Assume first that d(z t, r) > m ~/3- m 1/3. 
In this case ~.;he lemma follows from Wp < m and the fact that at ~dl times 0 < ff < 2m. So assume that 
d(x', r) < m 2/3 - m 1/3. By Lemma L, the increase in ff in step (1) is bounded by (m 1/3 + 1)d(z, z'). 
The player's work Wp in step (2) is l+d(s, s")+d(s", r), which is no greater than d(s, st) -q- (~/1/3 
..~ 1)d(s', s '1) + m 1/3 -[- 1. Finally, by Lemma 2, ¢ decreases in step (2) by at least d(s, s') + 
(m 1/3 + 1)d(s', s") -2ml/3d(x ', r). Subtracting this expression from the sum of the first two and then 
dividing by 1 + d(z, x') + d(z', r), we obtain (Wp + Arb)/WA G 2m 1/3, which implies the lemma. Theorem 
2. TwO-PHASE is 4ml/3-competitive. Proof: Let ¢Pi be the initial value of ¢ before request sequence Rn, 
and let ¢1 be the final value of ¢ after L',~. The theorem then follows from Lemma 3- summed over all 
requests- and the fact that ¢1 -¢bi < 2m. The 1-server problem on the line is quite different. The restart 
move, in which a server jumps to location 0, introduces many of the complexities of forking. We d9 not 
have an O(m 1/3) upper bound for this problem. 5. Forking Disallowed ht this section we generalize Theorem 
2 to give a 2i'k + 1)ml/Z-competitive algorithm for locating check- points in the case that neither the 
online nor the offiine algorithm is allowed to fork. The 1-server lower bound argument can be extended 
to give an f2(m 1/3) lower bound by adding requests that "freeze" k -1 of the player's servers, as in 
the proof of Theorem 4 below. In response to each request r, the algorithm applies Two-PHASE to the 
server nearest to r. We analyze this algorithm's performance as in Section 4, only this time the potential 
function is somewhat more elaborate. For a player server at s and adversary server at x we define the 
following functions: l(s, x) = d(s, z) + max{0, m2/Z(m 1/3 - d(s, z))}, f(s, x) = m -d(s, z) + min{m, 
m 1/3. d(s, z)). Let the positions of player (adversary) servers 1, 2, ..., k be denoted sl,s2,..., 
sk (respectively, zl,x2,...,xk). Next we define M to be the minimum weight of a matching of player servers 
to adversary servers where the weight of matching player server i to adversary server j is l(si, xj). 
We now define our potential func- tion, ff = (k + 1)M + ~f(si,xj). i,j Roughly speaking, we match players 
to adversaries in ¢ so that a player's motion is paid for by increased proximity to its matched adversary. 
As in the previous section, weights are piecewise-linear functions in order to compensate for the varying 
"speed" of Two-PHASE. As above we divide the response to request r into steps: (1) the adversary moves 
arbitrarily; (2) the player executes Two-PHASE; and (3) the adversary ser- vices r without moving a permanent 
checkpoint. Lemma 4. When an adversary server moves distance d, ~b increases by at most kml/3d + (k + 
1)d. Proof: Observe first that l(s,x) and f(s,z) are both continuous at crossovers. Since "nested" matched 
pairs have the same total distance as "crossed" matched pairs, M is also continuous at crossovers, and 
hence ¢ is as well. When adversary server z/ moves distance d without crossing a player, M increases 
by at most d and for each i, f(si, zj) increases by at most rnX/3d. As above let s denote the initial 
position of the player that services r, and s ~ and #1 its positions after Phase 1 and Phase 2, respectively. 
Denote by x ~ the position of the adversary closest to v after step (1). Lemma 5. If x ~ E [s,r] then 
there exists a minimum weight matching in which the distance from the player at s to its matched adversary 
is at least d(s, r'). Proof: Assume that s is matched to some adversary at z* with x* E [s,z~), while 
the adversary at x' is matched to some other player at s*, necessarily be- hind s (i.e., in (r,s)). We 
show that switching these 363 two matched pairs does not increase the weight of the matching, that is, 
l(s, x*) + l(s*, x') > t(s, x') + l(s*, x*). In backwards order from r, we have x', x*, s, and s*. Our 
first observation is d(s, x*) + d(s*, x') = d(s, x') + d(s*, z*). Thus we have only to show that max{O, 
m-m~/3d(s, x*)}+max{O, m-m2/3d(s * , x')} >_ max{O,m -m2/ad(s, z')} + max{O, rn -m2/ad(s * , z*)}. This 
follows from our first observation if all quantities within the brackets are nonnegative. Also if d(s*, 
x') > m 1/3 and all other distances are no greater than m 1/3, the inequality holds strictly. If one 
of the distances on the righthand side is greater than m 1/3, then so is d(s*, x'), and then the inequality 
holds since d(s,x') and d( s*, z* ) are both at least d( s, x* ). Lemma 6. Assume d(x', r) _< m 2/a -m 
1/3. Then in Phase 1, (I) decreases by at least d(s, s'), and in Phase 2, rb decreases by at least (m 
1/3 + 1). (d, s', s") -(k + 1)m 1/a d(x', r). Proof: We consider Phase 1 first and assume d(s, s') > 
0 (so d(s, r) > m2/3). If the player at s is not matched to the adversary at x ~, then by Lemma 5, we 
may as-sume that it is matched to an adversary at x* with x* E (r,s). In either case the matched adversary 
is at least m 1/a past s ~, so the weight of the current matching decreases by d(s, s I) as player moves 
from s to s I. Hence M decreases by at least this amount. The k functions f(s, xj) each increase by at 
most d(s, s'). So overall decreases by at least (k + 1)d(s, s') -kd(s, s'), which is   d(s, For Phase 
2, first assume that the player at s ~ is not matched to an adversary in [s',r] by any mini- mum weight 
matching. Then the adversary matched to s' lies at least m I/3 beyond s". Thus the match- ing part of 
the potential function decreases by at least (k + 1)d(s',s") as the player moves from s' to s". Since 
d(s ~,x') < m s/a, the function that is initially f(s', x') decreases by (m 1/a- 1)d(s', s") during this 
mo- tion. Each of the other f(s', xj) terms increases by at most d(s', s"), and thus overall (I) decreases 
by at least (m 1/3 + 1)d(s', s"). So assume that the player at s t is matched to an adversary in Is 
~, r]. By Lemma 5, we may assume that s ~ is matched to x ~. The analysis of this case closely follows 
that of Lemma 2 and shows that decreases by at least (m 1/3 + 1). (d, s', s") -(k+ 1)m 1/3. d(x', r). 
Lemma 7. For each r, Wp + A~ < 2(k -t- 1)ml/3WA. Proof: WA is at least 1 + d(x', r) plus the motion in 
step (1). By Lemma 4, the change in ¢ in step (1) is bounded by the distance moved times km 1/3 + k + 
1; this factor is less than 2(k + 1)m 1/3. First assume d(x', r) < m 2/3 -m 1/3. The player's cost Ws 
: d(s, s') + d(s', s") + d(s", r) + 1, which is no greater than d(s, s') + (m 1/3 + 1)d(s', s") + m 1/3 
+ 1. By Lemma 6, the decrease in ~ in step (2) is at least d(s, s') + (m 113 + 1)d(s', s") -(k -t- 1)ml/ad(x 
', r). Subtracting this expression from the previous one and dividing by 1 + d(x', r) now gives the 
result. If d(x', r) > m 2/3 -m 1/3, the lemma follows from Wp < m, WA > m 213 -- ml/3 + 1, and the fact 
that the increase in due to the movement of any one player is at most (2k+ 1)m- km 2/3. Theorem 3. TwO-PHASE 
is 2(k + 1)ml/a-competitive for locating k checkpoints in the case that forks are disallowed. 6. Lower 
Bounds for 3 or More Servers In this section forking is allowed. We prove a lower bound of f~(ml/2), 
which is much larger than the upper bound proved in the last section for the case of forking disallowed. 
Thus the fork move is major contributor to the difficulty of competitiveness. Theorem 4. For k > 3, a 
k-server algorithm can be no better than Q(ml/2)-competitive. Proof: We first give the proof in the 
case that k = 3, followed by the modifications for the general case. The adversary incurs a one-time 
cost of m/2 to po- sition two servers on opposite sides of the circle, and then the proof proceeds as 
before in epochs, where each epoch begins with two of the adversary's servers at zl and z2 = zl + m/2 
and with history R4. The adversary considers extending R, by [m 1/2] alternating requests at zl + m 1D 
and z2 + m 1/2, followed by a single request at either zl or z2, and the adversary processes these requests 
by placing servers at zl + m 1/~, z2 + m 1/2, and at one of Zl or z2 for the last request. Thus the adversary's 
solution will have cost 2m 1/2 + [m 1/2] for the epoch. If the player fails to leave a server in both 
(zl + m 1/2, z2] and (z2 + m 1/2, Zl] then the last request is at the forward endpoint, z~ or Zl, of 
the arc that was empty at some time during the epoch. This last request implies at least m/2 -m 1/2 + 
[m 1/2] player cost for the epoch. On the other hand, if the player maintains servers in both (zl + m 
1/2, z2] and (z2 + m 1/2, zl], then the alternating requests must be processed with only 354 one additional 
server, so one of the arcs (Zl, z 1 + m 1/2] or (z~, z2 + m 1/2] is left empty after each alternation, 
and yet both forward endpoints must be processed dur- ing each alternation. The player obtains a total 
cost of at least [m1/2]m1/~/2. In either case the player is no better than ((m 1/~- 1)/6)-competitive. 
After this epoch, the adversary can repeat the pat- tern with Zl + m 1/2 and z~ + rn 1/2 serving as zt 
and z2. By using the fork move, the adversary moves its third server to whichever of these two positions 
will he the endpoint of an arc of length m/2 -m 1/2 not occupied by a player server at some point in 
the next epoch. We now consider the case of k > 3. As above the adversary places servers at 0 and m/2. 
It also places servers at k - 3 other locations zl, z2,..., zk-3 that are m 1/2 apart in the interval 
[m/8, 3m/8]. The adversary incurs total set-up cost O(km) and has one server left over. Now we have epochs 
of size 3[ml/2]. Each epoch is divided into cycles of 3 requests. Each cycle consists of a request at 
rn t/2, another at m/2 + m 1/2, and a third request at one of the locations zi. The adversary considers 
all possible ways to extend the current history Rt with an epoch of this form. If the player leaves either 
(rn - m/8, 0] or (3m/8, m/2] empty at any time in one of these extensions, the adversary chooses that 
extension and follows the epoch with a request at whichever of 0 and rn/2 is at the endpoint of a vacated 
arc. In this case the player's cost exceeds m/8. In answering this epoch, the adversary does not move 
its servers at zl, z2,..., zk-3. It advances its servers at 0 and m/2 t(~m 1/2 and m/2 + m 1/2, leaving 
its leftover server at the location of the final request. Thus the adversary incurs total cost about 
5m 1/2. So assume that the player leaves arcs (m-m/8, 0] and (3m/8, m/2] occupied at all times. In this 
case, either the player pays at least m 1/2 per request for one of the locations m 1/~ or m/2+m 1/2, 
or the player leaves an arc of the form (zi -m t/2, zi] empty at some point during each cycle. If the 
latter is true, then the adversary "hits 'era where they ain't" by choosing the third request of each 
cycle to be at a location zi that was-at some time during that cycle- the endpoint of an empty arc. Either 
way the player's cost per cycle is at least m 1/2 ~nd cost for the entire epoch at least m/3. As above 
;he adversary's cost is about 5m 1/2. The pattern can now repeat with m 1/2 and m/2 + m 1/2 serving as 
0 and m. Locations zl,z2,...,zk-z need not change until the adversary server that occu-pies successive 
positions 0, m 1/2, 2ml/2,..., comes too ('.lose to the first zi. This happens only after Q(m 1/2) epochs, 
by which time the player has incurred Q(m 3/2) total cost. The adversary can now reset incurring an asymptotically 
negligible cost of O(km). It is straightforward to show that Theorem 4 also holds for the case of servers 
moving on a line. 7. An Upper Bound for the Problem with Forking In this section the number of servers 
is at least 2 and as above both adversary and player may fork (though in our algorithm the player never 
does). We show that the following algorithm, called HOLDBACK, is 3(kin) 1/2- competitive. for each request 
r do Let s be the position of the server nearest r Move the closest server max{0, d(s, r) -(km) 1/2} 
Serve r using the temporary server od For B a subset of the set of adversary servers A, let M(B) be 
the minimum cost of a matching of members of B to player servers, where the cost of matching ad- versary 
server j with player server i behind j is d(sl, xj). For adversary server j, let prey(j) = minl;~j{d(xt, 
xj)} if d(xz,xj) > 0 for all l ¢ j. If several adversary servers occupy a single position, let all but 
one of them have prey value 0 and an arbitrarily chosen one, say j, have prey value equal to the minimum 
nonzero value of d(xl, xj). Now define (B) = M(B) + 2(kin) 1/~ E prey(j) j~B and our potential function 
(I) = rain {(I)(B)}. BCA Here the new ingredient in (I) is that we choose a subset of the adversaries 
to match. This added level of opti- mization keeps (I) from jumping up when the adversary forks. We think 
of the actions following request r as consist- ing of the following steps: (1) the player moves accord- 
ing to HOLDBACK above, and (2) the adversary moves arbitrarily (and serves request r). First observe 
that at all times 0 < (I) <km since M(A) < kin. Let s = si be the position of player server i, a closest 
player server to request r, and let s' he the position of server i after step (1). Lemma 8. Assume d(s,r) 
>_ (kin) 1/2 and that there is an adversary server at position x such that d(x, r) <_ (km)1/2/2. Then 
in step (1), ¢b decreases by at least  d(s, s'). Proof: The assumptions above imply that there is an 
adversary server between s and r. Thus in a matching 365 M(B) for which (I)(B) is minimum, some adversary/is 
paired with player server i. Ifxz lies in [s', s) then M(B) decreases by d(s, s') in step (1), so (I) 
must decrease by at least d(s, s'). So assume x~ lies in nonempty [s,s'). In this case d(s', r) = (kin) 
1/2, so there must be another adversary server h in [s', r]. Let us now assume h E B for a choice of 
B that minimized (I)(B) before step (1). Then since player server i was the closest player to r, adversary 
h must have been paired with a server between r and s. After step (1) we can pair adversary h with player 
i and adversary l with h's old partner. This new pairing reduces M(B) by d(s, d); hence (I) must decrease 
by at least d(s, s*). The remaining case is that all adversary servers in [#,r] are in A \ B (before 
step (1)) for each B that minimizes ¢(B). Then ~ before step (1) is at least E p ev(j), where the sum 
is over all adver- saries between s ~ and r. Either this sum is greater than d(s', r)/2, which is at 
least (km)1/2/2, or there is no ad- versary server h such that d(xh, r) < (kin)x~2~2. The latter case 
contradicts one of our assumptions; the for- mer case contradicts (I) < kin. Lemma 9. (1) When the adversary 
forks, dp cannot in- crease. (2) When an adversary server j moves distance d, a9 increases by at most 
2d(km) 1/2. Proof: When adversary j is forked to be coincident with adversary l, we may assume that prey(j) 
becomes 0 and prey(l) retains its former value. So j's contribu- tion to decreases to 0. The contribution 
of the first adversary ahead ofj's old location increases by no more than j's old contribution to (I). 
In order to prove (2), let B be a set of adversary servers that minimizes (I)(B) before the adversary 
mo- tion. After j moves, ~(B) has increased by at most d in the case j E B and by at most 2d(km) 1/~ 
in the case that j t~ B and 2(kin) 1/~ prey(j) appears in (~(B). Hence (I) increases by at most 2d(km) 
1D. Theorem 5. HOLDBACK is 3(km)l/2-competitive. Proofi We show that for each request r, Wp + A(~ < 3(kin) 
1/2 WA, where A(I) is the total change in the po- tential function in both steps. This inequality and 
the invariant 0 _< <km suffice to prove the theorem. First assume that there is no adversary server 
j such that d(zj, r) < (krn)l/2/2 when request r arrives. Then WA > (krn)X/2/2 and the right-hand side 
above is greater than (3/2)km. The work done by the player is at most m, and the increase in can be 
at most kin, so the left-hand side is smaller than the right-hand side for k > 2. Now assume that there 
is an adversary server j such that d(xj, r) ~_ (km)112/2. If Wp < (kin) 1/2, then the player does not 
move in HOLDBACK,and hence does not increase ft. By Lemma 9, Aft) < 2(km)l/2WA, and the fact that WA 
> 1 implies the inequality above. So we now assume that Wp > (km)W2. Then by Lemma 8, in step (1) (I) 
decreases by at least the distance that the player server moves before sending a temporary server, that 
is, at least Wp -(kin) 1/2. By Lemma 9, the increase in q) during step (2) is at most 2(kin) 1/2 WA. 
Thus Wp + A(~ <_ (kin)l~ 2 + 2(kin) 1/2 WA <_ 3(kin) 1D WA. HOLDBACK and other checkpoint algorithms 
for the circle can be extended to the line by thinking of the line as a circle with k + 1 servers, one 
of which is fixed at 0. (This restriction applies to both the player and the adversary.) Whenever HOLDBACK 
tries to move the server at 0, instead the closest server behind 0 should be moved to the same spot. 
The analysis can be carried out in almost the same manner as above to prove that this version of HOLDBACK 
is O((krn)l/2)-competitive for the checkpoint problem on the line. 8. Lower Bounds for Unequal Numbers 
of Servers So far we have only compared online algorithms against offiine algorithms with the same number 
of servers. Time was the resource used to measure competitive-ness. It is natural to explore the space 
resource as well by allowing the online algorithms more servers than the offiine algorithms. (Here we 
are following the lead of Manasse et al [11].) The next theorem also shows that our lower bounds are 
robust; strong (i.e., rn e) lower bounds still hold even when the player is allowed k servers and the 
adversary only 1. Below we implicitly assume that k is much smaller than m, say k is o(m ~) for any fixed 
e > 0. Theorem 6. On-line algorithms with k servers can be 1 no better than fl(m 2-v'4"vT;-~ ) competitive 
when compared to the 1-server optimal algorithm. Proof: The proof depends on a hierarchy of epoch sizes 
IreS'I, [m~q,..., Ira"q, (given largest to small- est) defined by the recurrence: 1 oq = 2oq+ 1 -1- eek, 
Oek--2k+1 _ 1 or the closed form: 2 k+l-i --1 2 k+1 - 1 366 At the beginning of an epoch, the adversary 
is at an arbitrary location zl. (Thus the adversary's strat- egy can be repeated for any number of epochs.) 
The adversary considers all possible ways of extending the current request sequence Rt by [m a'] requests 
in the arc [zl + m c'1 , zl + kmC~]. If one of these (infinite num- ber of) extensions causes the player 
to vacate the arc (zl + krn a~, zl], then the adversary chooses this exten- sion, followed by a request 
at Zl, and processes the se-quence by leaving its server at zl. This results in player cost f2(rn) while 
the adversary cost is only O(m2a'), giving the ratio claimed in the theorem. On the other hand, if the 
player would maintain a server in (zl -b km c'~, Zl] for all possible extensions, then the adversary 
divides the epoch into f2(m ~'-~2) subepochs of duration [m a2] each. The adversary starts the jth subepoch 
with its server at location zl +ms' +(j -1)(k- 1)m a2. In each subepoch, the ad- versary considers all 
extensions of Rt by [m a2] requests in an arc of length (k-2)m a2 starting m a2 ahead of its server. 
If the player fails to maintain a server behind ~he adversary's location, a final request at that location 
brces the player's cost to f2(m aa) while the adversary's :ost is O(ma2), thus giving the ratio claimed 
in the ~,heorem. If the player would maintain a server, then 1;hat subepoch is further divided into subsubepochs 
of .:]uration [m ~3] comprising requests in subarcs of the e:ubepoch's arc. In the ith level of this 
recursion a sub- arc has the form [zl + m ~'', zi + (k -i + 1)m~'], where ~he choices of zi are such 
that these subarcs are evenly spaced within a subarc of level i - 1. The recursion ter- minates with 
a case identical to the single server proof of Section 3, since the player has k- 1 confined servers 
and hence only one server free to process requests in the most deeply nested, zero-length subarc. 9. 
The Offline Problem Ia this section we sketch algorithms for the problem of c3mputing oft]ine an optimal 
sequence of responses to a sequence of requests rl, re,  , rn. We first consider the c~se k = 1. Let 
Ci(s) be the minimum cost of serving requests rl, r~,..., ri and leaving the server at position s E [0, 
m). We have the recurrence Ci(s) = min{ Ci_l (S) -b d(s, ri), Ci-l (ri) q- d(ri, s)}, ~here the first 
term corresponds to the option of leaving the server at s and serving the ith request with the temporary 
server and the second term corresponds to the option of leaving the server at ri after the previous request 
and then moving to position s after serving the ith request. Other possibilities, such as leaving a server 
at a position s ~ and then moving from s ~ to ri to s, are dominated by these two options. A reasonable 
initial condition is Co(s) = s. Lemma 10. Ci(s) is a continuous, piecewise-linear function with i + 1 
pieces and maximum slope 1. Let p denote the number of distinct locations among rl,r2,...,r,,. Obviously 
p _< n; we state our running times in terms of p rather than n as in many applica- tions p << n. The 
function Ci(s) can be stored implic- itly in a complete binary tree with p+ 1 leaves in which each node 
stores a linear function of s. The value of this function at a specific s is computed by summing values 
from a leaf to the root. This data structure can be updated from Ci-1(s) to Ci(s) in amortized time O(logp). 
We omit the details. Theorem 7. For k = 1, the ot~tine problem can be solved in time O(n logp), where 
p < n is the number of distinct request locations. The general offline problem can also be solved by 
dynamic programming, though in this case we did not speed up the algorithm using special data structures 
(as it looks rather messy). Note that although standard k-server problems can be reduced to minimum-cost 
flow [5], the checkpointing problem is quite nonlinear due to forking and excursions. Theorem 8. For 
fixed k >_ 2, the otttine problem can be solved in time O(npk). 10. Conclusions We have explored adaptive 
online schemes for locating checkpoints. To do so we introduced a server problem that includes several 
nonstandard features: a fixed cost per request, one-way motion, excursions, and forking. Including the 
fixed cost enabled us to differentiate algo- rithms that would otherwise have simply been declared noncompetitive. 
One-way motion and excursions taken together raise the optimal competitiveness from k (the number of 
servers [5, 11]) to about rn 1/3, where m is in effect the size of the playing field. Forking further 
raises this bound to about m 1/2. A number of interest- ing open problerr~s remain: Does there exist 
an O(ml/3)-competitive algorithm for locating checkpoints in the case k = 2? (This question raises the 
important issue of whether fork- ing is of any use to the player. For k = 2, we can prove a lower bound 
of f2(m 1/~) on the com-petitiveness of any online algorithm that does not fork.) 367 Except for k = 
2, our upper and lower bounds match in their dependence on the dominant factor m. There remain, however, 
constant gaps and gaps depending on k. Can these be closed?  What happens to our bounds if we disallow 
excur- sions? That is, memory is now assumed homoge- neous.  What is the effect of allowing forking 
on other server problems?  For some problems, most notably accessing a lin-ear list, competitive analysis 
seems to give "the right answer"- that is, it leads to an algorithm that arguably dominates all others. 
For the checkpointing problem, the situation is less clear. We believe that competi-tive analysis has 
demonstrated the utility of an initially rapid, then increasingly slow, approach to a repeated request 
location. We also think that it has invalidated some initially attractive algorithms, such as one that 
always moves halfway towards a request. On the other hand, due to its emphasis on worst-case sequences, 
com- petitive analysis may have led us to overly conserva- tive algorithms. In practice one would probably 
want to move a checkpoint closer than the distance (kin) 1/~ prescribed by HOLDBACK. In fact the choice 
of a practical algorithm, whether HOLDBACK,TwO-PHASE (which is slightly more ag-gressive), or something 
else, should depend on how "ad- versarial" are the expected request sequences. In appli- cations such 
as debugging or physical simulation, there may be a small number of "hot spots" and users may often step 
backwards in time. In such situations request sequences may indeed appear quite adversarial. It would 
be interesting to investigate the checkpoint location problem using other styles of analysis, such as 
probabilistic analysis assuming random (possibly corre- lated) requests. Acknowledgements We would like 
to thank Mike Paterson and Howard Karloff for some valuable discussions. References [1] S. Ben-David, 
A. Borodin, R. Karp, G. Tardos, and A. Wigderson, On the Power of Randomiza- tion in Online Algorithms, 
these proceedings. [2] P. Berman, H. Karloff, and G. Tardos, A Com- petitive Three-Server Algorithm, 
1st A CM-SIAM Symp. on Discrete Algorithms, 1989. [3] [4] [5] [6] [7] [8] [9]  [10] [11] [12]  [13] 
[14] A. Borodin, N. Linial, and M. Saks, An Optimal Online Algorithm for Metrical Task Systems, 19th 
ACM Symp. on Theory of Computing, 1987. A. Calderbank, E. Coffman, and L. Flatto, Se- quencing Problems 
in Two-server Systems, Math. Oper. Research 10, 1985, 585-598. M. Chrobak, H. Karloff, T. Payne, and 
S. Vish- wanathan, New Results on Server Problems, 1st A CM-SIAM Symp. on Discrete Algorithms, 1989. 
M. Chrobak and L. Larmore, An Optimal On-Line Algorithm for k Servers on Trees, manuscript, UC- Riverside, 
1989. D. Coppersmith, P. Doyle, P. Raghavan, and M. Snir, Random Walks on Weighted Graphs, and Applications 
to On-line Algorithms, these pro- ceedings. E. Fiala and D. Greene, Data Compression with Finite Windows, 
CA CM 32, April 1989, 490-505. A. Karlin, M. Manasse, L. Rudolph, and D. Sleator, Competitive Snoopy 
Caching, Algorith-mica 3, 1988, 79-119. R. Korf, Complexity of Reverse Execution, manuscript, 1981. M. 
Manasse, L. McGeoch, and D. Sleator, Com- petitive Algorithms for On-line Problems, 20th ACM Symp. on 
Theory of Computing, 1988. P. Raghavan and M. Snir, Memory vs. Random- ization in Online Algorithms, 
ICALP, 1989. D. Sleator and R. Tarjan, Amortized Efficiency of List Update and Paging Rules, CACM 28, 
Febru- ary 1985, 202-208. J. Storer, Data Compression, Computer Science Press, 1988. 368  
			