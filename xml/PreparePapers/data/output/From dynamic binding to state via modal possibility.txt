
 From Dynamic Binding to State via Modal Possibility Aleksandar Nanevski School of Computer Science Carnegie 
Mellon University Pittsburgh, PA 15213-3891 aleks@cmu.edu Abstract In this paper we propose a typed, 
purely functional calculus for state (with second-class locations) in which types re.ect the dichotomy 
between reading from and writing into the global store. This is in contrast to the usual formulation 
of state via monads, where the primitives for reading and writing introduce the same monadic type constructor. 
We hope to argue that making this distinction is useful, simple, and has strong logical foundations. 
Our type system is based on the proof-term calculus for constructive modal logic S4, which has two modal 
type operators: .for neces­sity and . for possibility. We extend this calculus with the notion of names 
(which stand for locations) and generalize to indexed fami­lies of modal operators (indexed by sets of 
names). Then, the modal type .CA classi.es computations of type A which read from store locations listed 
in the set C. The dual type .CA classi.es compu­tations which .rst write into the locations from C and 
than use the changed store to obtain a value of type A. There are several bene.ts to this development. 
First, the necessita­tion fragment of the language is interesting in its own: it formulates a calculus 
of dynamic binding. Second, the possibility operator . is a monad, thus forcing the single-threading 
of memory writes, but not of memory reads (as these are associated with .). Finally, the different status 
of reads and writes gives rise to a natural way of expressing the allocation of uninitialized memory 
while also pro­viding guarantees that only initialized locations are dereferenced. Categories and Subject 
Descriptors D.3.1 [Software]: Programming Languages Formal De.nitions and Theory General Terms Languages 
Permission to make digital or hard copies of all or part of this work for personal or classroom use is 
granted without fee provided that copies are not made or distributed for pro.t or commercial advantage 
and that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, 
to post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PPDP 
03, August 27-29, 2003, Uppsala, Sweden Copyright 2003 ACM 1-58113-705-2/03/0008 ...$5.00 Keywords modal 
lambda-calculus, effect systems, dynamic binding, state 1 Introduction Dynamic binding in functional 
programming languages is a concept by which the value of a certain variable is not .xed statically at 
the time the variable is introduced, but is determined dynamically from the current scope, each time 
the variable is used. This characterization makes dynamically bound variables very sim­ilar to memory 
locations in an appropriate de.nition of store. Just like dynamic variables, the store locations can 
be changed arbitrary number of times, and each dereferencing of a location will return the most recent 
value. There is, however, a difference between the two. When a store lo­cation is changed, that change 
is supposed to have global scope; it holds until the end of the program, or at least until something 
else is written into the location. When a dynamic variable is changed, that change has only local scope. 
Once this scope is exited, the old value of the dynamic variable is restored. In this sense, a location 
in the global store can be described as a dynamically bound vari­able which is updated by assignments 
whose scope can never be exited. Conversely, a dynamic variable is a memory location which is updated 
in a non-destructive way. Following this intuition, we present in this paper a typed calculus capable 
of encoding both dynamic binding and global store at the same time. It is based on the modal .-calculus 
for a variant of the intuitionistic S4 modal logic [23], which we extend with the concept of names. Names 
are labels that can be dynamically in­troduced into the computation and we will use them as a theoretic 
abstraction of memory locations. In this paper, names are explicitly second-class; they cannot be passed 
as function arguments, so all the memory operations must be over explicitly given locations. As we have 
already observed in another paper [21], the operator .of modal necessity, in combination with names, 
can be used to model effects that have local scope and can be handled. When this system is instantiated 
to treat names as memory locations, name dereference becomes an effect which is handled by corresponding 
name initializations. For example, similar to indexed monads in [31], we will have a type .CA which classi.es 
suspended com­putations of type A which, in the course of eventual executions, may read from the memory 
locations whose names are listed in the set C. Assignment to memory locations is modeled by ex­plicit 
substitutions, and a suspended computation reading from C can be evaluated only in an environment in 
which all the names from C have been initialized by some explicit substitution. Be­cause explicit substitutions 
have a delimited scope, they can only represent non-destructive update. Consequently, the obtained sys­tem 
models dynamic binding. This fragment is very similar to our meta-programming calculus from [20], with 
several important dif­ferences concerning names and explicit substitutions that make the distinction 
between meta-programming and dynamic binding; we comment on these in Sections 2 and 3. As already remarked, 
global store can be obtained from dynamic binding if the assignments to dynamic variables are single-threaded, 
and their scope is extended to the end of the program. A natural way to achieve this in a modal calculus 
is to tie the explicit substitutions to the type of modal possibility (which is a monad). Thus, dually 
to .CA, this will provide us with a type .CA classifying suspended computations that write into the memory 
locations represented by the names in C. The obtained nominal modal calculus will therefore be capable 
of encoding the following important features related to state: (1) dy­namic allocation of uninitialized 
locations which is modeled by the constructors for introduction of names; (2) non-destructive update 
which is modeled by the necessitation fragment of the calculus; (3) destructive update which is modeled 
by the possibility fragment of the calculus; (4) typing guarantees that non-initialized cells will not 
be dereferenced. We believe that this makes our system an interesting contribution to the theory of monadic 
calculi for state, as to the best of our knowl­edge, most monadic calculi for state usually only model 
destructive update and allocation of initialized locations, and have not been used to represent non-destructive 
update or allocation of uninitial­ized memory [17, 18, 29, 30, 31, 11, 14]. 2 Nominal necessity and 
dynamic binding In this section, we brie.y outline our calculus for dynamic binding. It is a speci.c 
instantiation of the more general effect calculus from [21]. The system is based on the proof-term calculus 
for the necessita­tion fragment of a variant of modal logic S4 [23]. The idea is to separate the notion 
of ordinary variables (which we also refer to as expression variables) which are statically bound by 
.-abstraction, from the notion of dynamic variables whose values depend on the context in which they 
are used. As we outlined in the introduction, we represent dynamic variables via names. Names are labels 
which can be dynamically introduced into the computation via a separate binding mechanism. Upon the introduction, 
names are not initial­ized, and the type system will track the propagation of names in order to ensure 
that only initialized names are ever dereferenced. For that purpose, the type system will feature a family 
.C of modal necessity types, index by a set of names C. A useful operational intuition about the terms 
of type .CA, is to see them as suspended computations of type A which may dereference the dynamic vari­ables 
listed in the set C. On the other hand, a non-modal type A is populated with computations which are executable. 
Values are assigned to dynamic variables by means of explicit substitutions. A suspended computation 
of type .CA can be forced and executed only in an environment in which all the dynamic variables in C 
are de.ned. It is exactly because the explicit substitutions have delim­ited scope, that our calculus 
in fact implements non-destructive up­date of memory locations, i.e., dynamic binding. In Section 4, 
we will extend the calculus with a mechanism to globalize the scope of explicit substitutions and obtain 
a calculus for state with destructive update. The described indexing of the modal operator with names 
is simi­lar to the one found in the monadic language from [31], where la­bels are used to identify the 
effects that may occur under a monad. In our setup, however, we will also allow dynamic introduction 
of fresh names into the computation (which corresponds to allocation of new dynamic variables), and establish 
a typing discipline for it. We start by explaining the syntax and various syntactic conventions. Names 
X . N Supports C, D . P.n(N ) Types A ::= b |A1 .A2 |A1 .A2 |.CA Explicit T ::= ·|X .e,T substitutions 
Terms e ::= u |X |(T)e |.x:A. e |e1 e2 | box e |let box u =e1 in e2 | .X:A. e |choose e Variable contexts 
. ::= ·|.,u:A[C] Name contexts S ::= ·|S,X:A The .nite set C of names that a suspended term of type .CA 
may dereference, is referred to as support of such a term. All the names in a support are drawn from 
a countably in.nite universe of names N . In order to track the use of names, the typing assignments 
in the context . of expression variables must account not only for the typing, but also for the support 
of a variable. So, for example, the typing u:A[C]declares a variable u which can be bound to an ex­pression 
of type A and support C. When the support of a variable is empty, we will abbreviate u:A[], simply as 
u:A. Similarly, we will simply omit the index support set in the type constructor .C when C is empty. 
While the context . declares ordinary expression variables, which can be bound to expressions of arbitrary 
support, the context S de­clares the names (i.e., dynamic variables), and their types. For sim­plicity 
purposes, names in S have only types, but not supports, as­sociated with them. Because the types of the 
calculus depend on names, we impose conditions on well-formedness of contexts: the context S is well-formed 
if every type in S uses only names declared to the left of it; the variable context . is well-formed 
with respect to S, if all the names that appear in the types of . are declared in S. The term constructors 
box and let box are the introduction and elimination forms for the .modality. Operationally, the term 
constructor box suspends the evaluation of its argument expres­sion e, and wraps it into a thunk box 
e which can then be fur­ther manipulated by the rest of the program. The elimination form let box u =e1 
in e2 takes the suspended expression boxed by e1 and binds it to the expression variable u to be used 
in e2. Example 1 The function sum presented below takes an inte­ger argument n and creates a suspension 
for computing the sum 1 +···+n. fun sum (n : int) : .int = if n = 1 then box 1 else let box u = sum 
(n -1) in box (u + n) end -s5 = sum 5; val s5 =box (1 +2+3 +4+5) : .int The expression variable 
u may be used in e2 in both suspended po­sitions (i.e., under a box), and in executable positions. For 
example, if we would like to force the evaluation of the suspended computa­tion s5 from the above example, 
we can do it with in the following way. let val u = s5 in u; -val it = 15 : int A dynamic variable 
X is dereferenced by simply using its name as part of some term. Assignment to a dynamic variable is 
done by an explicit substitution. We use the term constructor (T)e to ap­ply an explicit substitution 
T over an expression e. This is one of the important distinctions of the calculus for dynamic binding 
from our meta-programming calculus in [20]. For the purposes of meta­programming we syntactically tied 
explicit substitutions to expres­sion variables, rather than to arbitrary expressions. This enabled us 
to substitute open terms for names within boxed expressions. Such a behavior is not required of a calculus 
for dynamic binding here we substitute names at the time they are dereferenced (i.e., the surrounding 
term is unboxed), and we substitute them only with expressions which are closed at run-time. Explicit 
substitutions are syntactically de.ned as lists of assign­ments of expressions to names. Furthermore, 
they are simultane­ous; there is no ordering between the assignments. Also, no name is assigned twice 
in the same substitution. In other words, an ex­plicit substitution is a function from the set of names 
to the set of terms T : N .Terms We treat the substitutions in our calculus as providing assignments 
for all the names; some names are assigned speci.c terms, and some names are simply unchanged by the 
substitution. For example, the empty substitution ()maps every name to itself. Given a substitu­tion 
T, its domain dom(T)is the set of names that the substitution does not .x. In other words dom(T)={X .N 
|T (X) =X} Range of a substitution T is the image of dom(T)under T: range(T)={T (X)|X .dom(T)} Here we 
only consider substitutions with .nite domains. A substitu­tion T with a .nite domain has a .nitary syntactical 
representation as a set of ordered pairs X .e, relating a name X from dom(T), with its substituting expression 
e. The opposite also holds any .nite and functional set of ordered pairs of names and expressions determines 
a unique substitution. We will frequently equate a sub­stitution and the set that represents it, when 
it does not result in ambiguities. Just as customary, we denote by fv(T)the set of free variables in 
the terms from range(T). Names are introduced into the computation by means of construc­tors .X:A. e 
and choose e, which are the introduction and elimina­tion forms for the type constructor A .B. As we 
already pointed out, names stand for dynamic variables, and dynamic variables can be viewed as memory 
locations. Thus, introduction of new names into the computation intuitively corresponds to allocation 
of new memory cells, where the exact size of the allocated segment would depend on the type of the name. 
With this in mind, we can describe the term constructor .X:A. e of type A .B as declaring (but not allocating) 
a name X:A that may be used in e:B, and prescribing a certain discipline in the use of X. The actual 
allocation is the duty of choose. So, for example, the redex choose (.X:A. e)introduces a new, uninitialized 
dynamic variable X:A, and then proceeds to evaluate e. The pattern of use of X in e is restricted in 
such a way that upon the evaluation, the value of e will not contain any signi.cant references to X; 
all the appearances of X will either be substituted away, or otherwise appear in some dead-code part 
of e. This way, X is forced to be local; it is prevented from escaping the scope of its introducing ., 
and making an observable effect. The usual variable conventions on binding, a-renaming and capture-avoiding 
substitution, apply here for both ordinary and dy­namic variables. The binding forms in the language 
are .x:A. e, let box u =e1 in e2 and .X:A. e. Given a term e, we denote by fv(e)the set of free variables 
of e. The set of names appearing in the type A is denoted by fn(A). Example 2 The following code segment 
illustrates the interaction between the several binding mechanisms of our language. First, we introduce 
new dynamic variables X and Y of integer type, by means of choose and .. Then we build the polynomial 
X2 +Y 2 over these dynamic variables, and bind it, via let box to an expression variable u. Then we use 
u to create a function f which takes another expression variable z and returns a suspended code for computing 
X2 +Y 2 +z. Notice that f is bound using a let val form, which has the usual operational behavior, and 
will be formally introduced shortly. The function f is an ordinary .-abstraction, and we apply it to 
1 to obtain the polynomial v =X2 +Y 2 +1. Finally, the program instantiates X and Y to 1 and 2, respectively, 
before evaluating the polynomial X2 +Y 2 +1 +2XY at the point (X =1,Y =2). -choose .X:int. choose .Y:int. 
let box u = box (X2 +Y2) val f = .z:int. box (u + z) box v = f 1 in <X->1, Y->2> (v + 2XY) end; valit=10: 
int The type system of the calculus for dynamic binding consists of two judgments: one for typing ordinary 
expressions, and another for typing explicit substitutions. The expression judgment has the form: S;. 
fe : A[C] Given an expression e, the judgment checks whether e has type A, and whether the names that 
are dereferenced in unsuspended po­sitions in e are accounted for in the support C. The judgment for 
explicit substitutions has the form: S;. f(T): [C].[D] The substitution T will be given a type [C].[D] 
if it provides de.nitions for names in C, and those de.nitions are themselves Nominal modal .-calculus 
C .D S;(.,x:A)fe : B[] S;(.,u:A[C])fu : A[D] S;. f.x:A. e : A .B[C] S;. fe1: A .B[C] S;. fe2: A[C] S;. 
fe1 e2: B[C] S;. fe : A[D] S;. fbox e : .DA[C] S;. fe1: .DA[C] S;(.,u:A[D])fe2: B[C] S;. flet box u 
=e1 in e2: B[C] (S,X:A);. fe : B[] X .fn(B) S;. fe : A .B[C] S;. f.X:A. e : A .B[C] S;. fchoose e : B[C] 
 Name dereference and explicit substitution C .D S;. f(): [C].[D] S;. fe : A[D] S;. f(T): [C \X].[D] 
X:A .S S;. f(X .e, T): [C].[D] X .CX:A .SS;. fe : A[C] S;. f(T): [C].[D] S;. fX : A[C] S;. f(T)e : A[D] 
Figure 1. Typing rules for dynamic binding. terms with support D. Therefore, one and the same substitution 
can be given many different types, depending on the supports C and D at which it is considered. For example, 
the substitution T =(X .1,Y .2) can be given (among others) the typings: [].[], [X].[], as well as [X,Y,Z].[Z]. 
And indeed, when T acts on a term of support [], another term with support []is pro­duced; when T acts 
on a term of support [X], it substitutes X away, and the obtained result is a term with empty support; 
when acting on a term with support [X,Y,Z], X and Y are substituted by con­crete terms, and only the 
dynamic variable Z remains in the support of the residual term. The rules of both judgments are presented 
in Figure 1, and we explain them next. One of the important characteristic of the type system is the 
support weakening principle; that is if S;. fe : A[C]and C .D, then S;. fe : A[D] Support of the expression 
e determines which names should be in­stantiated by means of an explicit substitution before e can be 
ex­ecuted. The support weakening principle simply states that instan­tiating more names than e actually 
requires, will not in.uence the typing (and therefore, the evaluation) of e; e could still be safely 
executed. We make the support weakening principle admissible by explicitly instrumenting the typing rule 
for hypothesis; a variable can be typed with a support which is larger from the one that the variable 
is declared with. Furthermore, we allow the values of the calculus, which are the .-and .-abstractions, 
and boxed expres­sions, to be typed with arbitrary supports. The evaluation of val­ues is already .nished, 
so it does not depend on any particular set of names being initialized; therefore, we can initialize 
any set we want. .-calculus fragment. The most important characteristic of the rule for .-abstraction 
is that the body e is required to be pure; that is, e has to match the empty support. Thus, all the dynamic 
variables that e may dereference must be so dereferenced under a box (and correspondingly accounted for 
in the type of e). This is very similar with the monadic calculi, which require that their functions 
be pure, and the effects must appear guarded by a monad. This is also one of the points in which the 
calculus for dynamic binding differs from our meta-programming language from [20]. In [20] we do not 
in­sist that .-abstractions be pure; impurity is handled by explicit sub­stitutions, and explicit substitutions 
can descend under .-binders. However, in such a setup, names would be instantiated before they are actually 
dereferenced it is not how dynamic variables or state locations should behave. A further observation 
about this rule is that .-terms are values, so we can weaken their support arbitrarily, as explained 
before. Con­cerning the rule for function application, it simply checks both the function and the application 
argument against the same support. Modal fragment. To type a suspended code box e, we must check if e 
is well-typed and matching the support that is supplied as an index to the .constructor. Boxed expressions 
are values, so their support can be arbitrarily weakened to any well-formed support set C, just like 
in the case of .-abstractions. The let box construct is supposed to .rst evaluate the branch e1 to a 
boxed expression, and then bind the obtained expression to u before proceeding with e2. Therefore, let 
box rule requires that both the branch e1 and the body e2 be ran in the environment de.ning the same 
set of names C. Names fragment. The rule for .X:A. e must check e for well­typedness in a context S extended 
with the new dynamic variable X:A. Similar to the . rule, we require that e has empty support. The . 
constructor, however, further requires that X does not appear in the type B. This ensures that X is used 
only locally in e; the process of evaluation can never make X escape the scope of its introducing . in 
any observable way. Practically, this typing discipline translates into a requirement that all the uses 
of X in e are either substituted by an explicit substitution, or appear in some dead code part of e. 
While .-abstraction only declares a name X that can be used in e and enforces the described typing discipline, 
it does not actually allocate X. As we already pointed out, the allocation is the duty of the term constructor 
choose, which is the elimination form for A . B. Operationally, choose allocates a fresh name, and substitutes 
it for the bound name in the .-abstraction. Since this fresh name is irrelevant for the typing purposes, 
we don t place it into the context S in the conclusion or the typing rule for choose, but it will appear 
in the de.nition of the operational semantics. Explicit substitutions The identity explicit substitution 
()does not provide de.nitions for any names, or rather, as discussed before, each name is simply substituted 
by itself (in this sense, the substi­tutions ()and (X .X)are really the same). Therefore, obviously, 
if an identity substitution is applied to an expression of support C it will produce an expression of 
support C. To preserve the sup­port weakening principle, we allow the target support of the identity 
substitution to be weakened to an arbitrary D . C. Composite sub­stitutions are typechecked by recursively 
typechecking all of their assignments. Last in this fragment are the rules for name dereferencing and 
sub­stitution application. The rule for name dereferencing allows X to be used only if it is present 
in the support set C. Substitutions ini­tialize the names in the expression over which they are applied, 
and so the rule for substitution application requires that the domain support C of the substitution T 
matches the support of the argument expression e. Example 3 We can introduce let val x =e1 in e2 as a 
syntactic sugar for let box u =(.x. box e2)e1 in u. The boxing of e2 is required in order to ensure that 
the purity of the .-abstraction (as discussed before). The corresponding typing rule is S;. f e1: A[C] 
S;(.,x:A)f e2: B[C] S;. f let val x =e1 in e2: B[C] Similarly, we introduce the term constructor let 
name X:A in e as an abbreviation for let box u =choose (.X:A. box e)in u, with the derived typing rule 
(S,X:A);. f e : B[C] X . fn(B,C) S;. f let name X:A in e : B[C] Example 4 Assume that C1, C2 and D are 
arbitrary support sets. Then the following terms are well-typed of empty support. f1: .C1 A . .C2 A = 
(where C1 . C2) .x. let box u =x in box u f2: .A . A = .x. let box u =x in u f3: A . .DA = .x. box 
x f4: .C1 A . .D.C2 A = (where C1 . C2) .x. let box u =x in box (box u) f5: .C1 (A . B). .C2 A . .DB 
= (where C1,C2 . D) .x. .y. let box u =x in let box v =y in box (uv) The function f1 simply eta-expands 
its argument. It shows that support weakening in boxed types is derivable. The function f2 illustrates 
that we can unbox and evaluate suspended expressions which do not read from dynamic variables; notice 
that the argument type of f2 has empty index support. The function f3 shows that it is possible to coerce 
values into suspended computation, by simply boxing them. Because values are name-free, their support 
can be weakened to an arbitrary support set D. The other two functions generalize the characteristic 
axioms of S4 modal necessity without names [7, 23].  3 Operational semantics for dynamic binding The 
operational semantics of the calculus for dynamic binding is de.ned through the judgment ' S,e ,e -. 
S' In this judgment, S and S' are run-time contexts of currently allo­cated, but not necessarily initialized 
names. The judgment relates the expression e with its one-step reduct e' , and is de.ned on ex­pressions 
which do not contain free expression variables. Expres­sion e can contain names (i.e., dynamic variables), 
but it must have empty support. In other words, we only consider for evaluation those expressions which 
do not dereference uninitialized names; their names are either initialized by some explicit substitution, 
or otherwise appear in suspended or dead-code subterms. The reduc­tion can allocate new names, and that 
is why we must keep track in the judgment of the run-time contexts of allocated names. The judgment implements 
call-by-value operational semantics for the calculus in the style of Wright and Felleisen [34]. The idea 
is to decompose each expression e uniquely as e =E[r]where E is an evaluation context and r is a redex. 
To de.ne a small-step opera­tional semantics, it is enough to de.ne primitive reduction relation for 
redexes (which we denote by -. ), and let the evaluation of ex­pressions (which we denote by -. ) always 
.rst reduce the redex identi.ed by the unique decomposition. The de.nition of the judgment relies on 
the notion of values, re­dexes and evaluation contexts below. Values v ::= x | .x:A. e | box e | .X:A. 
e Value s ::= ·| X . v,s substitutions Redexes r ::= v1 v2 | let box u =v in e | choose v |( s) e Evaluation 
E ::=[]| Ee1 | v1 E | let box u =E in e | contexts choose E |(s,X . E,T)e Notice that the de.nition of 
evaluation contexts proscribes a left­to-right evaluation strategy for function applications and for 
the as­signment clauses in explicit substitutions. The primitive reduction and the evaluation relation 
for the call-by-value version of our cal­culus are de.ned below. S,(.x. e)v -. S, [v/x]e S,let box u 
=box e1 in e2 -. S,[e1/u]e2 S,choose (.X:A. e) -. (S,Y :A),[Y /X]e where Y . dom(S) S,( s) e -. S,{s}e 
' S,r -. S' ,e S,E[r]-. S' ,E[e' ] The operational semantics of the fragment corresponding to the modal 
.-calculus is fairly standard: function application and let box reduce by performing a capture-avoiding 
substitution. The more interesting are the reductions concerning name introduction and explicit substitutions. 
For example, the operational semantics for choose (.X:A. e)pre­scribes that the run-time name context 
S be extended with a fresh name before proceeding with the evaluation of e. As we pointed out before, 
this provides our calculus with a formal way to model memory allocation. Further observe that the operational 
semantics does not allow eval­uations under an explicit substitution, and thus uninitialized names will 
never be encountered during the evaluation. Rather, the substi­tution application (s)e is reduced by 
employing the meta-operation { s} e to carry out the substitution s over e, before the evaluation of 
e can proceed. We next de.ne the meta-operation { s} e. DEFINITION 1(SUBSTITUTION APPLICATION). Given 
a sub­stitution T and a term e, the operation {T}e of applying T to e is de.ned recursively on the structure 
of e as given below. Substitu­tion application is capture-avoiding. {T} X = T(X) {T} u = (T)u {T} ((T')e)= 
(T .T')e {T} (.x:A. e)= .x:A. e {T} (e1 e2)= {T}e1 {T}e2 {T} (box e)= box e {T} (let box u = e1 in e2)= 
let box u = {T}e1 in {T}e2 u . fv(T) {T} (.X:A. e)= .X:A. e {T} (choose e)= choose {T}e The most important 
aspect of the above de.nition is that substitu­tion application does not descend under box. Names appearing 
in a suspended code need not be initialized because suspended code is not evaluated, and hence its names 
are not dereferenced. How­ever, when a suspension is actually unboxed and executed, this has to be done 
in a scope of a substitution that initializes the relevant names, as illustrated in Example 2. On the 
other hand, the other value forms are not of particular interest in this de.nition, because values are 
name-free, so substitution application does not descend into .-and .-abstractions. As we already commented 
before, this is in sharp distinction from the meta-programming calculus in [20], but it is the characteristics 
of dynamic binding, and it will allow us to extend the calculus to model state in Section 4. Further, 
notice that substitution application over a variable u is explicitly remem­bered, resulting in a term 
(T)u. When the variable u is substituted by a certain expression, the names appearing in this expression 
will be initialized by T. The operation of substitution application depends upon the opera­tion of substitution 
composition T1 . T2, which we de.ne next. DEFINITION 2(COMPOSITION OF SUBSTITUTIONS). Given two substitutions 
T1 and T2 with .nite domains, their composition T1 . T2 is the substitution de.ned as (T1 . T2)(X)= {T1}(T2(X)) 
This operation is obviously well-founded as both the substitutions have .nite domains, and substitution 
application of T1 to the terms from the range of T2 proceeds recursively on terms of decreasing size. 
Example 5 Consider the ML-like program below. let val x = ref 0 fun f (y) = !x + y val z = f 1 in 
 ((x:=1; f 1), z) end A similar program can be written in our calculus of dynamic bind­ing as follows. 
-choose (.X:int. <X -> 0> let fun f(y: int) : .X int = box (X + y) boxu= f1 valz= u in (<X -> 1>u, 
z) end); val it = (2, 1) : int * int Note that in this code segment it is not necessary that the substi­tution 
<X -> 0> immediately follows the introduction of the name X. Indeed, we could have moved this substitution 
further down. It is only important that some substitution is active when the variable u is used in unsuspended 
positions. The variable u is bound to the suspended expression (X + 1),so X must be initialized before 
u is used. In this particular example, the .rst unsuspended reference to u (and therefore to X as well) 
is in the scope of a substitution <X -> 0> and the second one is in the scope of <X -> 1>.  4 Nominal 
possibility and state In the previous sections, we have demonstrated how the modal op­erator of necessity 
can be used to obtain a calculus for dynamic binding. We represented dynamic variables by names, and 
con­sidered a reference to a name to be an effect, while substituting a name is the handler. This way, 
the calculus keeps track of names which are used, and prevents references to uninitialized names. In 
this section we build on this calculus to obtain a modal calculus for state. We would like to treat names 
as locations; dereferencing a name would correspond to a read, and substituting a name would correspond 
to an update. But, as the following program formulated in the type system from Section 2 illustrates, 
explicit substitutions cannot perform the update destructively. choose (.X:int. <X -> 0> let fun f(y: 
int) : .X int = box (X + y) box u = f 1 in (<X -> 1>u, u + 1) end) Indeed, the subterm <X -> 1>u 
cannot possibly destructively up­date X to 1 before evaluating u, simply because the old value of X (in 
this case 0), has to be preserved for the evaluation of the sec­ond element of the pair, u+1. Explicit 
substitutions alone are too weak. A solution is to single-thread the explicit substitutions, so that 
once a substitution is attempted, its scope extends to the rest of the pro­gram; it is never required 
to revert back to some previous substitu­tion. Thus, there would always be exactly one substitution active 
at every single moment, and it would play the role of global store. Single-threading and scope extension 
are exactly the duties of mon­ads, and in modal logic we have the monad . of modal possibility. Thus, 
if we want to use explicit substitutions to model destructive state update, we need to tie explicit substitutions 
to .. Intuitively then, we should obtain a whole family .C of possibility operators indexed by support 
sets, where the type .CA classi.es an explicit substitution for C paired up with a computation of type 
A in other words, a closure. More concretely, .C types programs of type A which .rst write into locations 
C and then compute a value of type A in the changed context. This would pleasantly contrast the type 
.CA that we already used in Section 2 to type programs which read from locations C before computing a 
value of type A. We introduce the nominal possibility into the language by de.n­ing the following syntactic 
categories on top of the syntax of the calculus of dynamic binding from Section 2. Types A ::= ...|.CA 
Closures f ::=[T,e]|let dia x =e in f |let box u =e in f Terms e ::= ...|dia f As expected, the grammar 
of types is extended with the family .CA, whose term constructor is dia f , encapsulating a closure f 
. Closures are a new syntactic category intended to describe com­putations which change the global store. 
The basic closure con­structor is the form [T,e]which ties a substitution T and a term e together; this 
is a computation which .rst writes into the locations determined by T before evaluating e in the new 
store. When T is the identity substitution, we will only write [e] instead of [(),e]. Closures are deconstructed 
by the form let dia x =e in f . It takes a term e which encapsulates a closure, thus carrying a substitution 
and a term. Intuitively, the term is then bound to x and the sub­stitution carried out, before the evaluation 
of f is undertaken. The closure form let box u =e in f takes a suspended expression en­capsulated in 
the term e and binds it to u to be used in the closure f . Example 6 Assuming that X and Y are integer 
names and that no other names are de.ned in the global store, the expression let dia z = dia [<X->1, 
Y->2>, 2XY] in [<X->X, Y->Y>, X2 +Y2 +z] end writes 1 and 2 into the locations X and Y respectively, 
then binds 4 to the local variable z, before evaluating to the closure [<X->1, Y->2>, X2 +Y2 +4]. Observe 
that the substitution in [<X->X, Y->Y>, X2 +Y2 +z] is the identity; we could have reduced the verbosity 
by writing the closure simply as [X2 +Y2 +z]. The type system of the calculus for nominal possibility 
consists of two mutually recursive judgments: one for typing expressions, and another one for typing 
closures. The expression judgment extends the system from Section 2, and has the form S;. fe : A[C] establishing 
that e may possibly read from locations listed in the support set C. The closure judgment has the form 
S;. f f ÷DA[C] This judgment establishes that the closure f consists of a substitu­tion of type [D].[C], 
and a term of type A. The term may deref­erence the names from the support D, because they are initialized 
by the substitution. We present the type system in Figure 2, and comment on the rules below. The closure 
introduction rule simply makes explicit the intuition about closures: the names used in the closure body 
are initialized by the closure substitution; the substitution closes the body up. Note that this rule 
is almost identical to the rule for substitution appli­cation from Section 2. This is only to be expected 
since, after all, we introduced closures with the intention to single-thread substitu­tion applications. 
The two constructs, however, will have different S;. fe : A[D] S;. f(T): [D].[C] S;. f[T,e]÷DA[C] S;. 
fe : .D1 A[C] S;(.,x:A)f f ÷D2 B[D1] S;. flet dia x =e in f ÷D2 B[C] S;. fe : .D1 A[C] S;(.,u:A[D1])f 
f ÷D2 B[C] S;. flet box u =e in f ÷D2 B[C] S;. f f ÷DA[C] S;. fdia f : .DA[C] Figure 2. Typing rules 
for nominal possibility. operational meaning. The explicit substitution (T)e carries out the substitution 
T over the expression e, while the closure [T,e]sus­pends the substitution, until it is explicitly forced 
by the let dia rule, as would be formalized in the operational semantics of the calcu­lus. The .rst provides 
non-destructive location update, while the second should be used when destructive update is desired. 
What is interesting is that both capabilities harmoniously coexist within the system. The typing rule 
for dia is a judgmental coercion from closures to terms. When coerced into the category of terms, a closure 
is given the type of modal possibility .C. The index support C of this type records the names that the 
substitution in the closure de.nes. The construct let dia is an elimination form for closures because 
let dia e =x in f is intended to destruct the closure computed by e, and use its parts in to compute 
f . To give a more speci.c de­scription of the typing rule for let dia e = x in f , we start with the 
observation that the term e is required to be of type .DA.It is supposed to encode a closure consisting 
of a substitution T of type ' [D].[C]and a term e : A[D]. The role of let dia is to institute the substitution 
T as a new global store providing de.nitions for names ' in the support D, then evaluate e to a value, 
bind it to x and proceed with the evaluation of f . Following this semantics, we can allow f to be supported 
by D, because the new global store in which f is evaluated de.nes the names from D. We are also free 
to declare x as being of empty support in the typing of f , because x will always be bound to a value. 
Example 7 We will use some further syntactic abbreviations as well: let val x =e in f is short for let 
dia y =(let val x =e in dia f )in [y] and let name X:A in f is short for let dia y =(let name X:A in 
dia f )in [y] Operationally, the let box rule could also be seen as a similar ab­breviation, but it is 
usually consider primitive because of proof­theoretic reasons: it is required during proof search in 
order to pre­serve the subformula property of the calculus. In contrast, let val does not have any signi.cance 
for proof search, and the same holds for let name. The typing rules for the two are easily derived as 
S;. f e: A[C] S;(.,x:A)f f ÷ DB[C] S;. f let val x=ein f ÷DB[C] (S,X:A);. f f ÷ DB[C] X. fn(B,C,D)  
S;. f let name X:Ain f ÷ DB[C] Example 8 Assume that Cand Dare support sets. Then the fol­lowing terms 
are well-typed of empty support. f1: .DA. .CA= (where C. D) .x. dia (let dia y=xin [y]) f2: A. .A= .x. 
dia [x] f3: .C.DA. .DA= .x. dia (let dia y=xin let dia z=yin [z]) f4: .C(A. B). .DA. .DB= (where C. D) 
.e1. .e2. dia (let box u=e1 in let dia x=e2 in [ux]) The function f1 simply eta-expands its argument 
x. It illustrates that strengthening at the index supports of . types is derivable. This is not surprising, 
as it only involves forgetting some entries from the substitution part of the closure x. The rest of 
the terms generalize the characteristic axioms of a variant of S4 modal pos­sibility introduced in [23], 
which can be recovered if the involved supports are set to be empty. For example, the function f2 is 
a co­ercion from terms into closures with empty substitution; notice that the range type is .Awith empty 
index support. Coercions from A to .CA with non-empty C are not generally available as they re­quire 
providing de.nitions for each name in C. The function f3 illustrates that it is only the last layer of 
. s that matter; all the ad­ditional ones can be ignored. The function f4 takes a function e1 which needs 
names Cin order to be generated, and a computation e2 providing a term xand de.nitions for these names 
(and possibly some more, since its index support is D. C). Then the de.nitions provided by e2 are plugged 
into e1 to obtain the function uwhich is then applied to xto obtain the .nal result. It is important 
to emphasize that the particular typing assigned to an explicit substitution in a closure will have a 
signi.cant impact on its operational behavior. As explained in Section 2, explicit substitu­tions have 
polymorphic typing. For example, the identity substitu­tion <> can have (among others) all of the following 
types []. [], or [X]. [X],or [X]. [X,Y]. But, when a substitution is viewed as global store, the speci.c 
type assigned to it determines which loca­tions will be used in the rest of the program, and which locations 
are irrelevant and can therefore be deallocated and garbage-collected. In that sense, the identity substitution 
with type []. []may be seen an empty store, while the identity substitution with the type [X]. [X]describes 
a store with a live location Xwhich is .lled ac­cording to the value of Xfrom the previously active store. 
For sim­plicity, we do not consider here a type system and an operational semantics that would make use 
of this distinction, although it is an interesting future work. Rather, we consider that all the operations 
on substitutions never forget any assignments that the substitution may implicitly contain, depending 
on the support at which it is con­sidered. When substitutions are viewed as global store, this means 
that our operational semantics does not prescribe deallocation and garbage-collection of store locations. 
In a realistic implementation, just as customary, these processes would be performed by a sepa­rately 
speci.ed run-time system. Example 9 We can use the new type and term constructors for nominal possibility 
to single-thread and sequence the example given at the beginning of the section. let name X:int dia 
dummy = dia [<X->0>, ()] fun f(y : int) : .Xint = box (X + y) box u = f 1 val z=u +1 let dia w = dia 
[<X->1>, u] in [(w, z)] end end The resulting program is typed in the judgment for closures, and 
evaluates to [(2, 2)]. The substitution associated with the re­sult is suppressed as it is equal to the 
identity. But, even more is true; this substitution can actually be typed as []. []. Indeed, the body 
(w, z) of the innermost let dia is name-free because it only depends on variables wand z which themselves 
bind (name free) values. The outcome of the program will, hence, be closed; we can type it in empty global 
store. In particular, the newly introduced location X could have been deallocated.  5 Operational semantics 
for state In this section we develop a call-by-value operational semantics for the modal calculus with 
possibility. We ignore the closure construc­tors let box, let val and let name; for operational purposes, 
they can be viewed as syntactic abbreviations and will not in.uence the properties we explore here. The 
.rst step is to extend the meta operation of substitution appli­cation to account for the new constructs. 
{T} dia f = dia {T} f {T} [T' ,e] =[T . T' ,e] {T} let dia x=ein f = let dia x={T}ein f Note that the 
substitution application is carried out only over the branch e, but not over the body f of a let dia 
construct. This is justi.ed because f is evaluated under a substitution determined by e; any in.uence 
that T might have over f has to be via e. The operational semantics is de.ned by means of two evaluation 
judgments: one for expressions and one for closures. We adopt a particular formulation of these judgments 
which emphasizes the relationship between the nominal possibility and global state. The expression evaluation 
judgment has the form s ' S,e-. S' ,e and reads: in a context of declared locations S and a store s as­signing 
values to these locations (and some locations may remain ' uninitialized), the term esteps into e and 
possibly introduces new locations S' . The evaluation steps cannot change the store s,as ex­pressions 
can only read from the store but not write into it. This judgment is a straightforward extension of the 
evaluation judgment from Section 2. The judgment for evaluating closures is the default judgment of the 
operational semantics, because it prescribes evaluation of stateful constructs. It has the form ' (S,s), 
f -. (S' ,s' ), f where f steps into f ' , changing in the process the set of allocated locations from 
S into S' and the global store from s into s' . The evaluation strategy that we consider will evaluate 
under the con­structor dia only if it is found in a let-branch of a let dia. This way, the changes to 
the global store prescribed under dia will take place only when they are single-threaded by a let dia. 
Note that this is not the only possible evaluation strategy, but it is the one that relates nominal possibility 
to global state and destructive update. Following this idea, we extend the categories of values, evaluation 
contexts and redexes from Section 2 as summarized below. Values v ::= ...| dia f Redexes r ::= ...| X 
Closure F ::=[] | let dia x = dia F in f | contexts let dia x = E in f | let dia x = dia [E] in f | 
let dia x = dia [(s,X . E,T),e] in f Closure c ::= let dia x =[s,e] in f | let dia x =[v] in f redexes 
The two evaluation judgments require two primitive reduction re­lations. Primitive reductions for expressions 
are duplicates of the reductions from Section 3, except that now the reductions are con­sidered in the 
context of a distinguished substitution s serving as a global store. We also add a new rule for reducing 
names. s S,(.x. e) v -. S,[v/x]e s S,let box u = box e1 in e2 -. S,[e1/u]e2 s S,choose (.X:A.e) -. (S,X:A),e 
s S,(s')e -. S,{s'}e s S,X -. S,s(X) The primitive reductions for closures are de.ned as follows. (S,s),let 
dia x = dia [v] in f -. (S,s),[v/x] f (S,s),let dia x = dia [s' ,e] in f -. (S,s . s' ),let dia x = dia 
[e] in f if s' =(·) The .rst rule simply binds v to x if the substitution in the closure of v is the 
identity, and therefore does not prescribe any changes to the global store. The second rule is more complicated. 
Its meaning is to change the global store according to the closure substitution and continue evaluating 
in the new store. Thus, the substitution s' is moved out of the closure and composed with s which is 
the current global store. As discussed before, the composition is performed so that no assignments in 
the result are omitted. The composition with s' will change some assignments in the global store, but 
no assignments will be lost. The evaluation of expressions and closures are now de.ned as fol­lows. s 
' S,r -. S' ,e s' ] S,E[r] -. S' ,E[e s'' S,r -. S' ,e (S,s),c -. (S' ,s' ), f (S,s),F[r] -. (S' ,s),F[e 
' ](S,s),F[c] -. (S' ,s' ),F[ f ' ]  6 Structural properties and type soundness In this section we establish 
the basic properties of our type system. We start with the admissibility of support weakening, as discussed 
in Section 2. LEMMA 3(SUPPORT WEAKENING). 1. if S;. f e : A[C] and C . D, then S;. f e : A[D] 2. if S;. 
f(T) : [C1] . [C] and C . D, then S;. f(T) : [C1] . [D] 3. if S;. f f ÷C1 A[C] and C . D, then S;. f 
f ÷C1 A[D] PROOF. By simultaneous induction on the three derivations. LEMMA 4(EXPRESSION SUBSTITUTION 
PRINCIPLE). Let S;. f e1: A[C]. Then the following holds: 1. if S;(.,u:A[C]) f e2: B[D], then S;. f [e1/u]e2: 
B[D] 2. if S;(.,u:A[C]) f(T) : [D ' ] . [D], then S;. f([e1/u]T) : [D ' ] . [D] 3. if S;(.,u:A[C]) 
f f ÷C1 B[D], then S;. f [e1/u] f ÷C1 B[D]  PROOF. By simultaneous induction on the three derivations. 
LEMMA 5(EXPLICIT SUBSTITUTION PRINCIPLE). Let S;. f (T) : [C] . [D]. Then the following holds: 1. if 
S;. f e : A[C] then S;. f{T}e : A[D] 2. if S;. f(T') : [C1] . [C], then S;. f(T . T') : [C1] . [D] 
3. if S;. f f ÷C1 A[C], then S;. f{T} f ÷C1 A[D]  PROOF. By simultaneous induction on the structure 
of the deriva­tions. The proof of the second statement is the most interesting, and we present it here. 
Given the substitutions T and T' , we can always split the representation of T . T' into two disjoint 
sets: T' = {X . T(X) | X . dom(T) \ dom(T' )} 1 T' = {X .{T}(T' (X)) | X . dom(T' )} 2 Regarding these 
sets, we could obtain the .nal result, if we show that (a) S;. f(T' 1) : [C1 \ dom(T' )] . [D], and 
(b) S;. f(T' 2) : [C1 n dom(T' )] . [D].  Indeed, it is easy to establish by induction that the union 
of these sets, when viewed as a substitution, has the required typing. To establish (a), observe that 
from the typing of T it is clear that T' 1: [C \ dom(T' )] . [D]. Then, by de.nition of dom(T' ),if X 
. C1 \ dom(T' ), then X is .xed by T' . Thus, either X does not appear in the syntactic representation 
of T' , or the syntactic representation of T' contains a sequence of mappings X . X1, X1 . X2, ..., Xn 
. X. In the second case, X is the substituting term for Xn, and thus X . C. In the .rst case, X . C by 
inductively appealing to the typing rules for substitutions until the empty substitution is reached. 
Either way, C1 \ dom(T' ) . C, and furthermore C1 \ dom(T' ) . C \ dom(T' ). Now, appealing inductively 
to the typing rules for substitutions, we easily obtain that S;. f(T' 1) : [C1 \ dom(T' )] . [D]. To 
establish (b) observe that if X . dom(T' ), and X:A . S, then S;. f T' (X) : A[C]. By the .rst induction 
hypothesis, S;. f {T}(T' (X)) : A[D]. The typing (b) is now obtained by induc­tively applying the typing 
rules for substitutions for each X . (C1 n dom(T' )). LEMMA 6(CANONICAL FORMS). Let v be a closed value 
such that S;·;f v : A[C]. Then the following holds: 1. ifA =A1 .A2, then v =.x:A1. e and S;x:A1 fe : 
A1 [] 2. ifA =.DB, then v =box e and S;·fe : B[D] 3. ifA =A1 .A2, then v =.X:A1. e and (S,X:A1);·fe 
: A2 [] 4. ifA =.DB, then v =dia f and S;·f f ÷DB[C]  As a consequence, the support of v can be arbitrarily 
weakened, i.e. S;·fv : A[D], for any support D. PROOF. By case analysis on the structure of closed values. 
LEMMA 7(REPLACEMENT). 1. If S;. f E[e] : A[C], then there exists a type B such that (a) S;. fe : B[C], 
and (b) if S' ,.' extend S,., and S' ;.'fe ' : B[C], then S' ;.'f E[e ']: A[C]  2. If S;. fF[e]÷CA[D], 
then there exists a type B such that (a) S;. fe : B[D], and (b) if S' ,.' extend S,. and S' ;.'fe ' 
: B[D], then S' ;.'f F[e ']÷CA[D]  3. If S;. fF[f ]÷CA[D], then there exists a type B and support C1 
such that (a) S;. f f ÷C1 B[D], and (b) if S' ,.' extend S,. and D1 is a support set such that S' ;.'f 
f '÷C1 B[D1], then S' ;.'fF[f ']÷CA[D1]  PROOF. By simultaneous induction on the three derivations, 
using support weakening. LEMMA 8(SUBJECT REDUCTION). Let S;·f(s) : [C]. []. Then the following holds: 
s 1. if S;·fe : A[C]and S,e -.S' ,e ' , then S' extends S and S' ;·f e ' : A[C] 2. if S;·f f ÷DA[C]and 
(S, s), f -.(S' ,s'), f ' , then S' ex­'  tends S and S' ;·f(s'): [C '].[]and S' ;·f f ÷DA[C ']for some 
support set C '.dom(S') PROOF. By case analysis using canonical forms lemma, support weakening and the 
substitution principles. The following theorem establishes that the evaluation relation is sound with 
respect to typing. THEOREM 9(PRESERVATION). Let S;·; f(s): [C].[]. Then the following holds: s 1. if 
S;·fe : A[C]and S,e -.S' ,e ' , then S' extends S and S' ;·f e ' : A[C] 2. if S;·f f ÷DA[C]and (S, s), 
f -.(S' ,s'), f ' , then S' ex­tends S and S' ;·f(s'): [C '].[]and S' ;·f f '÷DA[C ']for some support 
set C '.dom(S')  PROOF. By evaluation rules, the term is decomposed into a con­text and a redex. Then 
use the replacement and subject reduction lemmas. LEMMA 10 (PROGRESS FOR -.). Let s be an arbitrary value 
substitution. Then the following holds: 1. if S;·fr : A[C], then there exists a term e ' and a context 
S' , s ' such that S,r -.S' ,e. 2. if S;·fc ÷DA[C], then there exist a closure f ' , a value substi­' 
tution s' and a context S' , such that (S,s),c -.(S' ,s'), f. PROOF. By case analysis on the structure 
of redexes, using canon­ical forms lemma. LEMMA 11 (UNIQUE DECOMPOSITION). 1. For every ex­pression e, 
either: (a) e is a value, or (b) e =E[r]for a unique evaluation context E and a redex  r. 2. For every 
closure f , either: (a) f =[T,e]for some substitution T and expression e, or (b) f =F[r]for a unique 
closure context F and term redex r, or (c) f =F[c] for a unique closure context F and closure redex 
c.  PROOF. By simultaneous induction on the structure of e and f . The next theorem proves that a well-typed 
term can always be re­duced at least once. In combination with the preservation theorem, it establishes 
that well-typed terms do not get stuck. THEOREM 12 (PROGRESS). Let S;·f(s): [C].[]. Then the following 
holds: 1. if S;·fe : A[C], then either (a) e is a value, or s (b) there exists a term e ' and a context 
S' , such that S,e -. ' S' ,e. 2. if S;·f f ÷DA[C], then either (a) f =[T,e]for some substitution T and 
an expression e, or (b) there exists a closure f ' , a context S' , and a value sub­'  stitution s' 
, such that (S,s), f -.(S' ,s'), f PROOF. By unique decomposition lemma, the term can be decom­posed 
into an evaluation context and a redex. Then appeal to the replacement lemma and progress for primitive 
reduction. The reduct e ' and the context S' are not necessarily unique for each given e and S. Because 
fresh names may be introduced during the course of the computation, two different evaluations of one 
and the same term may choose the fresh names differently, resulting in dif­ferent e ' and S'. The determinacy 
lemma below shows that the dif­ferences between two reducts of one and the same term arise only from 
this arbitrary choice of fresh names. As customary, we denote by -.n the n-step reduction relation. LEMMA 
13 (DETERMINACY). 1. Ife,e1,e2 are terms such snn s that S,e -. S1,e1 and S,e -. S2,e2, then there exists 
a permutation of names p : N . N , .xing the domain of S, such that S2 =p(S1)and e2 =p(e1). 2. Iff, f1,f2 
are closures such that (S,s), f -.n (S1,s1), f1 and (S,s), f -.n (S2,s2), f2, then there exists a permutation 
of names p : N .N , .xing the domain of S, such that S2 = p(S1)and s2 =p(s1), and f2 =p(f1). PROOF. The 
most important case is when n =1, the rest follows sn by induction on n, by using the property that if 
S, e -. S' ,e ', then n e) s(S' ,s'), f ', then (p(S),p(s)),p(f )-.n (p(S'),p(s')),p(f ') (for closures). 
p(S),p(-. p(S'),p(e ')(for expressions), and if (S,s), f -.n We present the proof for the .rst statement; 
the second one is trivial, as there are no primitive closure constructors that intro­duced fresh names. 
The proof proceeds by decomposing the term e into a context E and a redex r. The only important case 
is when '' r =choose .X:A. e. Then it must be e1 =[X1/X]e, e2 =[X2/X]e, and S1 =(S,X1:A), S2 =(S,X2:A), 
where X1 and X2 are fresh names. Obviously, the involution (X1 X2)which swaps these two names has the 
required properties. 7 Related work Dynamic binding has been inadvertently introduced in the .rst ver­sions 
of LISP, but then became a feature, rather than a bug, in the subsequent implementations and dialects. 
For example, a formal­ized proposal for dynamic binding in the untyped setting of LISP, can be found 
in [13]. For semantic treatment of dynamic binding we refer to [19]. Dynamic binding has been considered 
in typed cal­culi as well. An example is a calculus .N, developed in [4, 5], for the purposes of explaining 
certain features of object-oriented pro­gramming. The .N-calculus is related to our system in that both 
use names, but in a slightly different way. The dynamic variables of .N are introduced as ordinary .-bound 
variables, but are then indexed by names to distinguish the various values that can be assigned to them. 
This type system, however, does not prevent reading from uninitialized dynamic variables. Implicit parameters 
as introduced in [16] are similar to dynamic variables, with the restriction to be used only in a .rst-order 
way. Implicit parameters has been pro­posed in [10] as a convenient mechanism for representing global 
variables in a monadic language. The dynamic allocation of memory cells and the typing annota­tions that 
we use in the presented calculus somewhat resemble the constructs in calculi with region-based memory 
management [27, 3, 28, 2]. The exact correspondence between the two remains future work. Monadic type 
systems have been used to represent effects related to state, almost since the inception of monads for 
denotational se­mantics by Moggi [17, 18]. For example, Wadler in [29, 30, 31], describes how monads 
can be used to model various effects, among which is state with destructive update. A thorough description 
of state and it s practical implementation in a monadic language, can be found in Launchbury and Peyton 
Jones [14]. The calculus of dynamic binding that we presented in this paper is a speci.c instantiation 
of a more general system of effects that we described in [21]. Both calculi use the natural deduction 
and proof-assignment for a variant of S4 modal logic, that are devel­oped by Pfenning and Davies in [23], 
and extend them with the notion of names. Pfenning and Davies in [23] and Kobayashi in [12] present a 
decomposition of a monad in terms of modalities . and .. Kobayashi further uses . to model global state, 
but the pos­sibility of using .for marking state-related effects is not explored. We have previously 
considered names in the necessitation frag­ment of S4 (but not in the possibility fragment), for purposes 
of meta-programming and higher-order syntax in [20]. The system described in that work is very similar 
to our calculus for dynamic binding from Section 2, with some important differences: (1) Dy­namic binding 
allows a map with a type A . .DA as shown in Example 4, which gives a coercion from values into computations; 
these are prohibited in meta-programming, (2) Dynamic binding only substitutes closed terms for names 
upon name-dereference, while meta-programming substitutes open terms for names in boxed expressions, 
(3) Functions and .-abstractions in dynamic bind­ing may only dereference names in suspended positions. 
In [20], we did not consider nominal possibility for purposes of meta­programming, but it should be possible 
to do so. We should also note that the developments in the current paper, as well as in [20], were directly 
motivated by the work on Nominal Logic and FreshML by Pitts and Gabbay [9, 25, 24, 8] which introduces 
names as urelements of Fraenkel-Mostowski set theory. The necessitation fragment of S4, and the corresponding 
..-calculus, but without names, have also been considered for purposes of staged computa­tion [6, 33], 
and run-time code-generation [15, 32]. 8 Conclusions and future work In this paper, we introduce a .-calculus 
capable of modeling mem­ory allocation, initialization, destructive and non-destructive up­date. It is 
based on the modal .-calculus corresponding to the vari­ant of intuitionistic modal logic S4, as developed 
by Pfenning and Davies in [23]. We extend this calculus with names, which are la­bels that can be dynamically 
introduced into the computation, and serve as theoretical abstraction for store locations. Store locations 
in this setup should be understood as chunks of memory of size that is appropriately determined by the 
type of the location. In our calculus, the allocation of uninitialized memory is modeled by dynamic introduction 
of names. Non-destructive update is ob­tained using the necessitation fragment of the calculus, and destruc­tive 
update is obtained with the possibility fragment. Each term is associated by the type system with its 
support set; that is, the set of names that the term may dereference. The type system features two families 
of nominal modal types: .CA, which classify suspended computation of type A which may dereference names 
from the set C, and .CA which classify suspended computations of type A which assign values to the names 
in C. Computations of type .CA may only be executed in an environment in which the names from C are provided 
with de.nitions by means of some explicit substitution. Because substitutions have delimited scope, this 
fragment of the calculus implements non-destructive up­date, i.e. dynamic binding. When the substitutions 
are associated with the .CA modal types, then their scope is not delimited, but extends till the end 
of the program. That way, substitutions model global store. We should mention, however, that our calculus 
for state is probably not very practical, because the support annotations in types may be too verbose. 
Therefore, a signi.cant future work will be to investi­gate type and support inference in the system 
(which may be similar to region and effect inference algorithms of [26, 2]). In a previous work [20], 
we have considered explicit support polymorphism as a way to make functions applicable to arguments with 
various sup­port annotations. This line of work may continue with developing, for example, existential 
quanti.cation over support sets, or even monadic abstraction in the style of [22, 1]. It would be interesting 
to see if these abstractions can be used to embed into our calculus the standard monad of state [30, 
31, 14] where the typings of al­locations, reads and writes are not indexed by names. We should also 
consider derived language constructs which could capture the patterns of use of the calculus, to provide 
appropriate levels of ab­stractions, relevant to the considered applications. All these men­tioned research 
questions are also applicable to the general case of arbitrary effects, and not only to effects related 
to state. 9 Acknowledgments The author would like to thank Frank Pfenning for the numerous discussions 
and his suggestions regarding the topic of this paper. 10 References [1] S. Awodey and A. Bauer. Propositions 
as [Types]. Technical Re­port IML-R 34-00/01 SE, Institut Mittag-Lef.er, The Royal Swedish Academy of 
Sciences, 2001. [2] L. Birkedal and M. Tofte. A constraint-based region inference algo­rithm. Theoretical 
Computer Science, 258:299 392, 2001. [3] L. Birkedal, M. Tofte, and M. Vejlstrup. From region inference 
to von Neumann machines via region representation inference. In Symposium on Principles of Programming 
Languages, POPL 96, pages 171 183, St. Petersburg Beach, Florida, 1996. [4] L. Dami. Functional programming 
with dynamic binding. In D. Tsichritzis, editor, Object Applications, pages 155 172. Technical Report, 
University of Geneva, 1996. [5] L. Dami. A lambda-calculus for dynamic binding. Theoretical Com­puter 
Science, 192(2):201 231, 1998. [6] R. Davies and F. Pfenning. A modal analysis of staged computation. 
In Symposium on Principles of Programming Languages, POPL 96, pages 258 270, St. Petersburg Beach, Florida, 
1996. [7] R. Davies and F. Pfenning. A modal analysis of staged computation. Journal of the ACM, 48(3):555 
604, 2001. [8] M. J. Gabbay. A Theory of Inductive De.nitions with a-Equivalence. PhD thesis, Cambridge 
University, August 2000. [9] M. J. Gabbay and A. M. Pitts. A new approach to abstract syntax with variable 
binding. Formal Aspects of Computing, 13:341 363, 2002. [10] J. Hughes. Global variables in Haskell. 
To appear in the Journal of Functional Programming. [11] R. B. Kieburtz. Taming effects with monadic 
typing. In International Conference on Functional Programming, ICFP 98, pages 51 62, Bal­timore, Maryland, 
1998. [12] S. Kobayashi. Monad as modality. Theoretical Computer Science, 175(1):29 74, 1997. [13] J. 
Lamping. A uni.ed system of parameterization for programming languages. In Conference on LISP and Functional 
Programming, pages 316 326, Snowbird, Utah, 1988. [14] J. Launchbury and S. L. P. Jones. State in Haskell. 
Lisp and Symbolic Computation, 8(4):293 341, 1995. [15] P. Lee and M. Leone. Optimizing ML with run-time 
code generation. In Conference on Programming Language Design and Implementa­tion, PLDI 96, pages 137 
148, 1996. [16] J. R. Lewis, M. B. Shields, E. Meijer, and J. Launchbury. Implicit pa­rameters: Dynamic 
scoping with static types. In Symposium on Princi­ples of Programming Languages, POPL 00, pages 108 118, 
Boston, Massachusetts, 2000. [17] E. Moggi. Computational lambda-calculus and monads. In Sympo­sium on 
Logic in Computer Science, LICS 89, pages 14 23, Asilomar, California, 1989. [18] E. Moggi. Notions of 
computation and monads. Information and Computation, 93(1):55 92, 1991. [19] L. Moreau. A syntactic theory 
of dynamic binding. In M. Bidoit and M. Dauchet, editors, TAPSOFT 97: Theory and Practice of Software 
Development, volume 1214 of Lecture Notes in Computer Science, pages 727 741. Springer, 1997. [20] A. 
Nanevski. Meta-programming with names and necessity. In In­ternational Conference on Functional Programming, 
ICFP 02, pages 206 217, Pittsburgh, Pennsylvania, 2002. A signi.cant revision is available as a technical 
report CMU-CS-02-123R, Computer Science Department, Carnegie Mellon University. [21] A. Nanevski. A modal 
calculus for effect handling. Technical Report CMU-CS-03-149, Computer Science Department, Carnegie Mellon 
University, June 2003. [22] F. Pfenning. Intensionality, extensionality, and proof irrelevance in modal 
type theory. In Symposium on Logic in Computer Science, LICS 01, pages 221 230, Boston, Massachusetts, 
2001. [23] F. Pfenning and R. Davies. A judgmental reconstruction of modal logic. Mathematical Structures 
in Computer Science, 11(4):511 540, 2001. [24] A. M. Pitts. Nominal logic: A .rst order theory of names 
and bind­ing. In N. Kobayashi and B. C. Pierce, editors, Theoretical Aspects of Computer Software, volume 
2215 of Lecture Notes in Computer Science, pages 219 242. Springer, 2001. [25] A. M. Pitts and M. J. 
Gabbay. A metalanguage for programming with bound names modulo renaming. In R. Backhouse and J. N. Oliveira, 
editors, Mathematics of Program Construction, volume 1837 of Lec­ture Notes in Computer Science, pages 
230 255. Springer, 2000. [26] J.-P. Talpin and P. Jouvelot. Polymorphic type, region and effect in­ference. 
Journal of Functional Programming, 2(3):245 271, 1992. [27] M. Tofte and J.-P. Talpin. Implementation 
of the typed call-by-value lambda-calculus using a stack of regions. In Symposium on Princi­ples of Programming 
Languages, POPL 94, pages 188 201, Portland, Oregon, 1994. [28] M. Tofte and J.-P. Talpin. Region-based 
memory management. Infor­mation and Computation, 132(2):109 176, 1997. [29] P. Wadler. The essence of 
functional programming. In Symposium on Principles of Programming Languages, POPL 92, pages 1 14, Albe­querque, 
New Mexico, 1992. [30] P. Wadler. Monads for functional programming. In J. Jeuring and E. Meijer, editors, 
Advanced Functional Programming, volume 925 of Lecture Notes in Computer Science, pages 24 52. Springer, 
1995. [31] P. Wadler. The marriage of effects and monads. In International Con­ference on Functional 
Programming, ICFP 98, pages 63 74, Balti­more, Maryland, 1998. [32] P. Wickline, P. Lee, and F. Pfenning. 
Run-time code generation and Modal-ML. In Conference on Programming Language Design and Implementation, 
PLDI 98, pages 224 235, Montreal, Canada, 1998. [33] P. Wickline, P. Lee, F. Pfenning, and R. Davies. 
Modal types as staging speci.cations for run-time code generation. ACM Computing Surveys, 30(3es), 1998. 
[34] A. K. Wright and M. Felleisen. A syntactic approach to type sound­ness. Information and Computation, 
115(1):38 94, 1994.  
			