
 109 Distributed Processing A Paper Session Chairman: Paul A.V. Thomas, Brock University THE CONCEPT 
OF ATTACHED PROCESSING AND ATTACHED RESOURCE COMPUTER SYSTEMS Victor D. Poor Datapoint Corporation 
Attached Processing, a new concept in business data processing, specifies a new system architecture constituting 
an on-line computer system o£ arbitrary size, made up of an arbitrary number of functionally dispersed 
processors which nevertheless maintain common data bases. Information stored in such a system is immediately 
accessible, under user-configured security controls, by any processor attached to it. Such a system 
can expand by simple accretion, without economic penalty. To obtain more processing throughput, one attaches 
more processors. To obtain more data storage, one attaches additional disk drives as needed. In its 
practical realization, Attached Processing assumes the form o£ an Attached Resource Computer. The Attached 
Resource Computer does not employ a central, controlling host computer. System control is decentralized. 
Failure o£ any individual processor in the system cannot bring all processing to a halt. Functional reconfigurations 
are easy since no processor is hard-wired to a specific task or tasks. Dispersed processors attached 
to such a system use its resources at their will. A single operating system command grants them access 
to information stored anywhere in it. System participation overhead is minimal. System software maintenance 
is simple, and existing system procedures are minimally changed Dy being transferred to an Attached Processing 
environment. To fully understand Attached Processing and the Attached Resource Computer, a brief review 
of past techniques in business electronic data processing may De helpful. The first computers were single-process 
devices. At first no more than calculating tab card equipment, they accepted batches of input data --generally 
on cards --performed some process upon it, and generated batches o£ output, after which a different program 
would be loaded and the cycle repeated. Long delays were common between data preparation and the appearance 
of results. As business computers grew faster it became necessary to make better use of the costly central 
processing units, so multiprogramming operating systems were designed. These were very complex software 
systems which allowed more than one process to use the mainframe at a time. Peripheral device delays, 
such as disk accesses, could be overlapped with central processing activities associate<~ with other 
processes. Complex operating systems improved CPU performance, but as the number of processes co-resident 
in the machine went up by factors of three, four, five, or more, memory requirements rapidly increased, 
too. Eventually, as total processing tasks expanded to consume every available machine cycle, the central 
processor would again bog down. Meanwhile, in the attempt to gain additional features, more complex operating 
systems consumed greater percentages of machine cycles, leaving less time for user program processing. 
 As business data processing loads increased toward machine saturation, there were two choices: upgrade 
to bigger machines, or obtain a seconu machine and transfer some of the processing tasks over to it. 
If the latter was done, problems of common files needed by many applications systems frequently mace 
it difficult to divide processing among independent processors. Moreover, it appeared that while two 
independent processors could almost double the amount of work done, a single processor double in size 
could do approximately four times as much. Thus the choice was often a bigger machine, even though in 
those early days upgrading was a unpleasant prospect because it frequently meant rewriting entire applications 
systems for the different instruction set of the larger machine. Then came compatible computers. In 
theory, this mace possible an upgrade from one machine to the next in a manufacturer's series without 
program changes because they all used the same instruction set. However, by that time operating systems 
had grown quite complex, and were often incompatible from one machine to the next. Instead of instruction 
set conversions when upgrading, the business user faced operating system conversions. The basic problem 
remained --in any single computer of whatever size, limits to growth and capacity are eventually reached. 
True, mainframes keep getting bigger and faster, but the maximum capacity one can expect from a single 
processor may be within sight. What shall be done then? Another development of the multiprogramming 
concept was timesharing --a 112 different kind of attempt to get more use from a single machine. Significantly, 
 timesharing's inherently interactive nature tended to humanize computers by making them more responsive 
to users. Users in turn found many more ways in which to apply the benefits of computing to their needs. 
Again, the computing load grew, and again the problem of computer growth limits arose, confronting business 
data processing users with the same dilemma as before. As an outgrowth of the spread of timesharing, 
business began to notice that the time value of information is often quite significant. Data is more 
valuable when current than when days or weeks old. On-line business transaction processing and interactive 
inquiry developed from this discovery --transaction-oriented processing systems attaching many hundreds 
of terminals, all of which could access and modify common files with immediate response to varied inquiries 
and up-to-the-second information. They typically used large mainframes for support, generally running 
very special systems software. But big machines designed for batch processing and equipped with complicated 
multiprogramming systems do not lend themselves too well to on-line processing. They bog down badly under 
only moderate transaction loads. They have to De very large indeed to support the necessary number of 
terminals. Unless there's a duplicate machine for backup, when such a mainframe goes down, all data processing 
tasks throughout the company --and every terminal in the place -- goes with it. Is there a solution 
to this dilemma? Or must conventional computers simply continue growing bigger and bigger --can they 
in fact grow bigger indefinitely? The more important question is: does building ever larger conventional 
computer systems really serve the needs of the transaction-centered world of business? Clearly, no. The 
business computing solution to the dilemma descripea above is not just an infinitely large, infinitely 
fast machine. One way to obtain arbitrarily great processing throughput is with arbitrarily many processors. 
Using a number of relatively independent processors provides an answer to the problem of downtime, too. 
This idea, as such, has been attempted, but its success depends upon the method used. In the Attached 
Resource Computer announced by Datapoint Corporation in December, 1977, the method used relies upon two 
techniques: first, a software-controlled specialization of processors into two functional types --one 
to execute applications, the other to manage data base information; second, a combined hardware/software 
interprocessor bus which hanales the whole task of high-speed interchange of information between the 
two types of processors without imposing an overhead penalty on them. These techniques work together; 
neither could do the job alone. Functional specialization of processors achieves little if interchange 
of aata must take place at slow speeds. High-speea interconnection of processors avails nothing if large 
portions of each processor must be devoted to managing communications. But when both these plans are 
coordinated, the result is nearly unlimited throughput and unfettered growth. An ARC system consists 
of both hardware and software. The haraware interconnects processors for automatic high speed exchange 
of data over short distances. The software makes this hardware data exchange completely user transparent, 
meaning that the user can take operation of the ARC system interconnection hardware for granted, anu 
concentrate instead on what it allows him to do: namely, attach any stana-alone compatible processor 
to an ARC system and execute applications programs with it --in an environment limite~ only Dy the resources 
of the system to which it is connected. Thus attached, a user's computer is styled an Applications Processor. 
By participating in the ARC system it can access files on disk volumes attache~ to and managed by File 
Processors. File Processors, for their part, buffer data, optimize use of their aisks, and prevent conflicts 
when several programs on an Applications Processor --or on several Applications Processors --want to 
update the same file at the same time. They coordinate data base updating transactions, provide data 
security, ana service incoming data requests. A File Processor runs no applications programs while serving 
as a file resource manager. Any of its memory not devoted to ARC system software --i.e., almost all of 
its memory --is used to Duffer data. Thus, for example, when ISAM files are maintained on a File Processor, 
indexes to those files tend to become resident in its random access memory buffers, of which there are 
a great many. The result is extremely fast responses to Applications Processor requests for data --frequently 
faster than that obtainable from Applications Processor local drives. Moreover, a File Processor is 
in no sense a host processor or control processor whose failure brings everything to a sudden and disconcerting 
halt. A breakdown of a File Processor merely requries that an Applications Processor De "borrowed" and 
physically substituted for it. On the other hand, if an Applications Processor in an ARC system should 
fail, its work load may be temporarily parceled out among other Applications Processors attached to the 
same system. In such emergencies, the remaining machines may not do as much work as usual, but processing 
will not De utterly crippled, either. The hardware interconnecting Applications and File Processors 
in an ARC system consists of small devices called Resource Interface Modules which connect to the standard 
I/O ports of each processor attached to the system. Each RIM is a bipolar microprocessor dedicated to 
the task of monitoring and controlling the operation of the high speed data link. It handles all data 
transmission, buffer management, error control, and automatic subsystem reconfigur ation. Each RIM in 
an ARC System has a unique identification number and packets of data may be sent to one specific RIM 
or broadcast to all RIMs in a system. RIMs receive only those packets addressed to them or broadcast 
to all RIMs (reception of broadcast packets may be inhibited under processor control). Data packets are 
interleaved so that the system can simultaneously support a number of independent communications paths 
without the Application Processors or File Processors realizing that they do not have exclusive use of 
the system. Data is carried between RIMs over low-cost coaxial cable at 2.5 Mbits per second in a unique 
proprietary format which includes error checking. A self-polling feature eliminates the need for a master 
station in the system. A RIM consists of six logical sections: BUFFER, STATUS WORD, CONTROLLER, TRANSMITTER, 
RECEIVER, and LINE INTERFACE. The attached processor can transfer data to and from the BUFFER and test 
and reset bits in the STATUS WORD. The LINE INTERFACE interfaces the TRANSMITTER and RECEIVER to the 
coaxial line. The RIM contains a 1024 byte memory --divided into 4 pages of 256 bytes each--as random 
access speed buffer between the attached processor and the RIM's transmitter and receiver. Data transfers 
to or from the attached processor may be made at any time, whether or not the transmitter or receiver 
is busy and independently of any status bits, at the full I/O rate of the processor. As a result of 
the actions of this device, a processor attached to an ARC system devotes no overhead whatsoever to data 
link control, but is free to execute applications programs or manage files. The coaxial cable linking 
RIMs may be extended several miles by inserting simple hub repeaters at intervals of 2,000 feet or less, 
to perform signal conditioning, amplification, and distribution of the high speed data transmissions 
transmitted through the Interprocessor Bus. Interprocessor Bus is a name embracing the whole set of 
devices --Resource Interface Modules, standard coaxial cables and Active Hubs --constituting the processor 
interconnection. Up to sixteen attached processors may be linkeo together in a single ARC system by only 
one Active Hub --always provided, o£ course, that none of the sixteen is more than 2,000 feet away from 
the Hub by cable. System growth is accomplisheS by plugging in additional processors and their uniquely 
addressed RIMs. Active use of the ARC system by any Applications Processor is completely voluntary. 
Participation is handled entirely with ARC system software. Being physically connected into the system 
hardware does not compel participation o£ any Applications Processor. Such processors can be bootstrapped 
(initialized), powered down, powered up, serviced, or anything else while physically attached to the 
high speed interprocessor bus subsystem. Access to remote disk volumes is a one-way affair; while any 
Applications Processor can request data of a File Processor as easily as it could of its own disk controllers, 
no other processor --whether File Processor or Applications Processor --can access disk volumes that 
are locally attaches to any Applications Processor. This provides the ultimate --though not the only 
-- security for private files. The maximum number of disk volumes simultaneously accessible to any 
Applications Processor is sixteen --for a maximum of 200 million characters of storage if all drives 
contain multi-disk packs. An Attached Resource Computer can also enhance the efficiency and prolong 
 the useful life of a central mainframe by means of a device known as the Direct Channel Interface Option. 
The DCIO permits an IBM 360/370 machine to participate in an ARC system by attaching to the Interprocessor 
Bus, thereby gaining access to remote volumes maintained by File Processors much faster than it coulo 
via ordinary telecommunications or the exchange of compatible recording media. Precisely how many processors 
may be attached to an ARC system? The limit is a large one --255. At least one of the 255 must be a File 
Processor. The maximum aggregate user memory of such a system --admittedly an unrealistic and impractical 
extreme example --would exceed 30 megabytes, and be capable of 116 simultaneously executing more than 
6,000 DATASHARE programs. In practical large ARC systems, multiple File Processors will be needed. 
How many File Processors may a single ARC system attach? As many as required up to a maximum of 254 --for 
there must be at least one Applications Processor in an ARC system or no useful work will get done. However, 
a ratio of 254 File Processors to one solitary Applications Processor is even less likely in practical 
systems than the opposite extreme of 254 Applications Processors to one File Processor. The number 255 
--the limit of RIM addresses in one ARC system --is not an absolute imitation, because any attached processor 
can participate in more than one ARC system. Any given processor can simultaneously attach to a maximum 
of six different ARC systems. More than one processor attached to one ARC system may also attach --in 
a fully concurrent manner --to another ARC system. In the real world of business, in which dispersed 
data processing has accustomed users to functionally locate computer power where data is generated and 
used, constructing ARC systems by sharing resources according to need is much less likely to generate 
extremely large single ARC systems than to configure multiple conjoint ARC systems. This capability of 
forming multiple conjoint ARC systems implies that for practical purposes, the geographical and computational 
size of an Attached Resource Computer is essentially Doundless. 
			