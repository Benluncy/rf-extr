
 Improved Algorithms for Stretch Scheduling Michael A. Bender* S. Muthukrishnant Rajmohan Rajaramant 
Abstract We study the basic problem of preemptive scheduling of an on!i~e stream of jobs on a single 
processor. The ith job arrives at time r(i) and has processing time p(i) that is known at the time of 
its arrival. If C(i) is the completion time of job i, then the flow time is C(i) -r(i) and stretch of 
a job is the ratio of its flow time to its processing time; that is, ~ Flow time considers the time a 
job is in p(i) " the system regardless of the service it requested; the stretch measure relies on the 
intuition that a job that requested long service must be prepared to wait longer than the small jobs. 
In this paper, we present improved algorithmic results in stretch scheduling. We first show that a simple 
online algorithm that takes amortized O(1) time per job arrival is O(A1/2)-competitive with respect to 
maximum stretch, where A is the ratio of the largest processing time to the smallest processing time. 
This is significantly more efficient than the best known online algorithm for this problem which takes 
ft(n 2) per scheduling step (n is the number of jobs seen thus far). We next present a polynomial time 
approximation scheme for average stretch scheduling. The previous best polynomial-time algorithm is the 
shortest remaining pro- ceasing time algorithm, which achieves a 2-appraximation. Finally, we consider 
the impact of incomplete knowledge of job sizes on the average stretch performance of scheduling al- 
gorithms. We show that a constant-factor competitive ratio for average stretch is achievable even if 
the processing times (or remaining processing times) of jobs axe known only to within a constant factor 
of accuracy. Introduction We consider the basic uniprocessing scheduling scenario. We have a single 
processor that processes jobs as they arrive online. The ith job arrives at time r(i) and has processing 
time p(i) that is known at the time of its arrival. We restrict our attention to scheduling with preemption; 
that is, jobs may be stopped before their completion and resumed later after other jobs get executed 
in the interim. Traditionally, the focus of performance has been on the flow time (also referred to as 
the response time), which is defined as the amount a time that b given ~rI~partment of Computer Science, 
SUNY at Stony Brook, NY 11794--4400, USA. Emaih bende~ce.stmysb.edu. Supported in part by HRL Laboratories, 
the National Science Foundation, and Sandia National Laboratories. ?AT&#38;T Shannon Laboratories, Florham 
Park, NJ 07932, USA. Email: muthuQxeseazch, aI:1:, c ore. tCollege of Computer Science, Northeastern 
University, Boston, MA 02115, USA. Email: x~caj@ccs.neu.edu. Supported in part by NSF CAREER award NSF 
CCR-9983901. job spends in the system. That is, if C(i) is the completion time of job i, then the flow 
time is C(i)-r(i). Alternatively, practitioners have long used dowdown or stretch to measure the effect 
of scheduling on an individual job. The stretch of a job is the ratio of its flow time to its processing 
time; that is, ~. Stretch is a rather natural criterion: jobs that require large processing time must 
be prepared to wait longer than the ones that need the system for less time. Until recently, little was 
known about stretch scheduling, even in the basic scheduling scenario de scribed above. In this paper, 
we provide improved al- gorithmic results for stretch scheduling. Overview of our results. Our work primarily 
focuses on two performance metrics: maximum stretch and average stretch (or equivalently, total stretch). 
Many of our performance guarantees depend on a parameter A of the scheduling instance, which we define 
as the ratio of the largest job size to the smallest job size. Without loss of generality, we normalize 
the sizes so that the smallest job has size i and the largest job has size A. Online algorithm for mazimum 
stretch: We present a simple, fast online algorithm that takes 0(1) amortized time per job arrival and 
is O(AIP) - competitive with respect to maximum stretch. The previously best known online algorithm for 
maximum stretch is also O(A1/2)-competitive, but the algorithm takes time f/(n 2) per job arrival, where 
n is the number of jobs in the instance [5]. In particular, the algorithm maintains a history of all 
jobs seen thus far at any point during the execution of the online schedule, and hence is impractical. 
Furthermore, most recent papers that attempt to optimize the max£mum stretch measure in practice have 
provided heuristics [1, 9, 12, 13] that do not have provable guarantees. In contrast, we are able to 
establish an O(A 1/2) bound on the competitive ratio for a simple algorithm that rounds the job sizes 
into two classes, and schedules greedily. This algorithm is easy to implement; the algorithm and its 
analysis appear in Section 2. For comparison, the best known lower bound on the competitive ratio is 
A 1/3 [5]. PTAS for average stretch: We present a polynomial time approximation scheme (PTAS) for minimizing 
average stretch ofl]ine. For any constant c > O, our algorithm yields an (1 + e)-approximation in O(n 
p°ly( l /e) ) time. The previous best polynomial-time approxima- tion for average stretch was the online 
shortest remaining processing time algorithm (SRPT) that yields a 2-approximation [18]. Furthermore, 
there exists a constant e > 1 such that no online algo- rithm can achieve a competitive ratio of better 
than c [18]. In Section 3, we present the first PTAS for the average stretch problem. This result has 
also been independently obtained in recent work [8], which presents a quasi-polynomial approximation 
scheme for weighted flow time. A natural idea for developing a PTAS for aver- age stretch is to round 
the job sizes to the nearest integral power of (1 + e), thus dividing the jobs into groups, and then 
scheduling the groups from the smallest rounded job size to the largest. Scheduling one group of jobs, 
however, constrains the times at which other groups of jobs may be scheduled. De- signing a (1 +e)-approximate 
schedule for such "con- strained" scheduling problems poses a key challenge in the design of a PTAS. 
The heart of our result, which is presented in Section 3, is a useful character- ization of (1 +~)-approximate 
schedules that reduces the size of the search space of relevant schedules. A technique that is common 
to both of the above results is that of rounding job sizes. Rounding of job sizes is a simple yet powerful 
tool that has been effec- tively used in reducing the space of schedules of interest to yield efficiently 
computable schedules. Rounding also has great practical significance. Traditionally, schedul- ing algorithms 
assume complete knowledge (clairvoy- ance) of the processing times of the jobs. In practice, however, 
estimating job sizes cannot be accurate in gen- eral. So a more reasonable approach is to assume that 
the upper and lower bounds on the job sizes are known that are correct up to a constant factor. In Section 
4, we analyze the average stretch and flow performance of two natural on-line algorithms that schedule 
jobs on the basis of the rounded values of the remaining processing. times, and processing times, respectively. 
Study of the impact of rounding: We first analyze a generalization of SRPT, referred to as )t-SRPT, which 
schedules in each step a job with remain- hag processing time within a (1 + A)-factor of the shortest 
remaining processing time, for some con- stant ~ > 0. We show that while A-SaPT is O(1)- competitive 
with respect to average stretch, it is ~(logA)-competitive with respect to average flow time. We then 
present a suitable refinement of A-SRPT that is O(1)-competitive with respect to both average stretch 
and average flow time. The preceding results are applicable in scheduling sce- narios in which remaining 
processing times of jobs are approximately known at each step. A more re- alistic model for partial knowledge 
of job sizes is a relaxation of the non-clairvoyant model, in which the processing time of any job is 
known to within a constant factor only at the time of the release of the job. Under this model, we show 
that a variant of the shortest processing time algorithm (SPT) is O(1)-competitive with respect to average 
stretch. Due to space constraints, we are unable to include many of the proofs in this paper. We refer 
the reader to the the full paper [6] for the omitted proofs. Related work. This paper focuses on the 
online and offiine complexity of stretch scheduling. Two mea- sures closely related to average stretch 
are weighted completion time and weighted flow time, each of which associate a weight w(i) with each 
job i. If we set the weight of job i to the reciprocal of flow time then opti- mizing average weighted 
completion time also optimizes average stretch. In terms of approximation, however, these two metrics 
are significantly different. Conse-quently, the recent PTAS for average weighted comple- tion time [2] 
does not yield any useful approximation for average stretch. The average weighted flow time with weights 
given by the reciprocal of processing times, on the other hand, is identical to the average stretch metric. 
The best known approximation result for weighted flow time is the recent approximation scheme of [7], 
which takes time superpolynomial, but subexponential, in the input size. In subsequent work [8], it has 
been shown that a quasi-PTAS is achievable for weighted flow time when A and the ratio of the maximum 
weight to mini- mum weight are both polynomiaily bounded. Our models for capturing incomplete information 
of job sizes may be viewed as relaxations of non-clairvoyant scheduling. In non-clairvoyant scheduling, 
no information about job sizes is available at release time. The competitiveness of non-clairvoyant unipro- 
cessor scheduling~ with respect to the average flow met- ric, is studied in [14, 17]. Our model of uncertainty 
in job sizes is related to a general framework developed in [3, 4], which also captures the variance 
in job sizes by using lower and upper limits. The underlying model of job arrivals and the performance 
metric studied are dif- ferent, however; in [3, 4], the jobs are given at the start of the computation 
and need to be scheduled on an asyn- chronous multiprocessor system to minimize makespan. As mentioned 
at the outset, our study concerns the basic uniprocessor preemptive scheduling setting. More complex 
scheduling scenarios have been studied, in-cluding multiprocessor scheduling (e.g., [16]), broadcast 
scheduling (e.g., [15l), and network connection schedul- ing (e.g., [11]). Clearly, some of the questions 
we have raised are relevant in these scenarios, and deserve fur- ther attention. Max|mum stretch In 
this section, we provide a new online algorithm for optimizing maximum stretch. Our algorithm achieves 
the best known competitive ratio of O(Al/2), where A is the ratio of the maximum processing time to the 
min- imum processing time. Our algorithm only performs an amortized constant amount of computation per 
job ar- rival. Thus, the total running time of the algorithm over an entire scheduling instance is linear 
in the number of jobs in the instance. We contrast this property with the previously known O(A1/2)-competitive 
ADJUSTIBLE- DEADLINE-EDF algorithm of [5]. In ADJUSTIBLE-DEADLINE-EDF, every time a new job arrives, 
the offiine optimal maximum stretch of all jobs that have arrived thus far is recomputed, deadlines are 
assigned according to this maximum stretch value, and then the algorithm assigns jobs according to the 
earliest-deadline-first rule. Thus, the computational time at each step of the algo- rithm is t2(n2), 
where n is the number of jobs that have arrived so far. We first analyze a simple scheduling policy that 
achieves an 0(Al/2)-competitive ratio and performs O(1) work for every job arrival, under the assumption 
that A is known. Later in this section, we describe how to implement this policy without the knowledge 
of ~. The resultant scheduling algorithm achieves the same competitive ratio of O(£x t/2) and performs 
amortized O(logloglogA) work per job arrival. It can be shown that our algorithms generate schedules 
that have only O(n) preemptions. A natural algorithm to optimize maximum stretch is a greedy policy in 
which we always execute the job in the system that has the current largest stretch. An implementation 
of the greedy policy needs to maintain the current stretch values of the jobs, which change at different 
rates depending on the processing times of the jobs. In particular, the scheduler has to determine when 
one job's stretch becomes larger than the stretch of the job being currently executed. We now describe 
a simplified variant of greedy, GREEDY-WITH-ROUNDING, in which the stretches axe appro~Amately maintained. 
For each job j, we define the pseudostretch s~ (t) of ] at time t as follows: = { if i < p(j) < ~, if 
A'/2 < p(j) <_ A. At each time t, algorithm GREEDY-WITH-ROUNDING schedules the job that has the largest 
pseudostretch at time t. One desirable property of the algorithm is that all jobs with size at most A 
1/2 (henceforth referred to as shor~ jobs) are scheduled first-in first-out (FIFO) and all jobs of size 
greater than A I/2 (henceforth referred to as long jobs) are scheduled FIFO. THEOREM 1. Algorithm GREEDY-WITH-ROUNDING 
i8 0 (VI~ - competitive for max-stretch. In order to establish Theorem 1, we need to under- stand the 
structure of the optimal schedule OPT. Let S* >_ 1 denote the stretch used by OPT. This schedule can 
be computed as follows: (1) To each job j, assign the deadline d(]) --r(j) + S* .p(j). (2) Execute the 
jobs Earliest Deadline First (EDF), in which the scheduler always executes the job in the system that 
has the earli- est deadline. For any scheduling problem in which jobs have arrival times, processing 
times, and deadlines, the (preemptive) EDF scheduling policy will find a feasible schedule (i.e., all 
jobs finish before their deadlines) if one exists. Consequently, the value of S* can be approxi- mated 
by binary searching on stretch sizes. It can be computed exactly by observing that even though there 
axe an unbounded number of assignments for deadlines, there are only O(n 2) different relative priorities 
of the jobs, and therefore there are only O(n 2) different EDF schedules of the jobs. In our analysis, 
we axe going to consider a modifi- cation of OPT, PSEUDO-OPT, which we use to compare with our online 
algorithm. Before presenting this sched- ule, we introduce some additional definitions. Above we have 
defined the pseudostretch of a job at each time step. We define the pseudostretch s(]) of a job j in 
a schedule as simply the pseudostretch of j at its comple- tion time. We now define PSEUDO-OPT as a Schedule 
that minimizes the maxium pseudostretch of a job. We compute PSEUDO-OPT in the same manner as OPT; as 
before we search over the possible values of maxstretch, assign deadlines according.y, and determine 
whether the schedule is feasible. Let S* denote the maximum pseu- dostretch of PSEUDO-OPT. Let d(j) denote 
the deadline of job ] in PSEUDO-OPT. We say that job j is a pseudo-predecessor (resp., pseudo-successor) 
of job k if j has an earlier deadline than k according to PSEUDO-OPT. LEMMA 2.1. Let S* and S* denote 
the maximum stretch and the maximum pseudostre~tch, respectively, for a 9iven instance. Then, we have 
S* <_ S*. F~rther-more, the maximum stretch achieved by PSEUDO-OPT for the instance is at most ~tl2s*. 
The heart of the proof of Theorem I is a competitive analysis Of GREEDY-WITH-ROUNDING with respect to 
pseudomaxstretch, as stated in the following lemma. Theorem 1 then follows from Lemmas 2.1 and 2.2. LEMMA 
2.2. GREEDY-WITH-ROUNDING iS Oil )- COmpetitive with respect to maximum pseudostretch. We begin the 
proof of Lemma 2.2 by first describ- ing the circumstances tAhat cause a job j to have a pseu- dostretch 
larger than S*. Suppose that a job completes x units after its deadline. This happens because for at 
least z units of time, PSEUDO-OPT chooses to execute jobs that are successors of j, while predecessors 
of j are in the system. If k is one of these successor jobs then we say that job k delays job j. We need 
not worry about the delay incurred by jobs in the large queue: LEMMA 2.3. A job is never delayed while 
it is in the large queue. We now consider the delay incurred by small jobs. LEMMA 2.4. I] small job j 
is delayed by a ~rge succes- sor, then j is delayed only before deadline d(j). For each small job j we 
identify a critical time, in which the pseudostretch in the system is not too large. DEFINITION 2.1. 
For each small job j, let the critical time ~-j denote the earliest time beyond which no (large) job 
delays j. That is, ~- is the earliest time after which no large job is executed while j or predecessors 
o] j are in the system. Lemma 2.3 and 2.4 can be used to establish the following claim. LEMMA 2.5. In 
GREEDY-WITH-ROUNDING, at time Tj the pseudosVretch of all jobs in the system is at most S*. Therefore, 
whenever GREEDY-WITH-ROUNDING makes a scheduling decision that disagrees with eSEUDO-OPT and risks delaying 
job j, the system has the following structure. Before time ~-j the scheduler has executed some work on 
successor jobs that it should have executed after time ~-#. As a result there are some small jobs in 
the system that should have been executed or partially executed by time T#. We consider the work from 
these jobs that is completed before ~-j in PSEUDO-OPT but is completed after time Tj in GREEDY-WITH-ROUNDING. 
These small jobs can be viewed as "being pushed forward" by the work on the longer jobs, causing them 
to "jut out" beyond time r~. At time rj they all have stretch at most ~. In the next lemma we bound the 
total amount of work on such small jobs. LEMMA 2.6. Consider all (small) predecessors k of j, such that 
r(k) < TI and k is not completed by time T. Then the total amount of work on these jobs is at most 2A112~. 
Lemma 2.6 shows that there can be at most O(Al/2ff ~) work from predecessor jobs of j, such that the 
work is executed before vj in PSEUDO-OPT and after T i in GREEDY-WITH-ROUNDING. This additional prede- 
cessor work in the system can only delay j by O(A1/2ff ;) units and conseqeuntly yields a competitive 
ratio of O(1) with respect to maximum pseudostretch. The analysis of of GREEDY-WITH-ROUNDING is tight 
to within constant factors. Consider the following problem instance: Large jobs 1 and 2 arrive at time 
0 and have size A. At time 2A -A 1/2 a medium-sized job 3 arrives, which has size A 1/2. Then between 
time 2A and 3A a stream of small jobs of length 1 bombard the system one job per time unit. The optimal 
schedule OPT would defer one of the large size A jobs to the end obtaining a maxstretch of 3. However, 
GREEDY-WITH-ROUNDING and greedy without  rounding will finish both size A jobs by time 2A. The consequence 
of this scheduling mistake is that the A 1/2- size job or some of the unit-sized jobs have a stretch 
of O(AI/~), which implies a competitive ratio of 0(A1/2). THEOREM 2. When GREEDY-WITH-ROUNDING iS pro- 
vided with the value of A it runs in linear time, exe-cuting only 0(1) operations per job arrival. The 
bound on the running time is established because the jobs can be malntMned in two FIFO queues, one for 
small jobs and one for large jobs. Thus, the scheduler can make its scheduling decisions by merely examining 
the first job in each queue. The analysis of GREEDY-WITH-ROUNDING and The- orem 1 still holds when A 
is unknown and must be esti- mated as the algorithm progresses. We assume that the algorithm is provided 
with the size of the smallest per- missable job, that is, the scheduler knows mini p(j) = 1 Thus, as 
the computation progresses, the scheduler must estimate the size of the largest job. At time t, let p(j) 
be the size of the maximum job so far, that is p(j) = mini such that r(i) < t. Then, the algoriithm determines 
that any job k such that p(k) < p(j)x/2 is small and any job k such that p(k) > p(j)l/2 is large. As 
larger jobs arrive, jobs from the small queue may migrate to the large queue as the definition of small 
and large changes. It can be established that the previous lemmas still hold in this case, except for 
the analysis of the running time. The difficulty with the running time is that now jobs migrate from 
the large group to the small group and so queues may need to be divided and combined. Our solution is 
to maintain a min(logA,n) dif-ferent queues, which group jobs by powers of two. Queues are called large 
or small depending on whether they hold large jobs or small. In order for GREEDY-WITH-ROUNDING to be 
efficient, the algorithm must find the earliest element in all the small queues and the earliest element 
in the large queues. Thus, we main- taln a priority queue of FIFO queues. Each FIFO queue is inserted 
into the priority queue, with the arrival time of the first job in the queue as the key. Each time a 
job is executed, the FIFO queue is removed and reinserted with a different key. Furthermore, the FIFO 
queues may be inserted from the large priority queue and inserted in the small. Thus, just with a simple 
heap, we obtain a O(nloglogA) running time. If we use more efficient data structures we can obtain faster 
results. For ex- ample, using the priority queue of Thorup [19] which assumes the word model of computation 
[10], we obtain the near-linear running time of O(n log log log A). PTAS for oflline average stretch 
In this section, we describe a polynomial-time approx- imation scheme (PTAS) for average stretch scheduling 
in uniprocessors. Let :Z be a given scheduling instance. Recall that a scheduling instance is specified 
by a set of jobs if, and for each job j E J, a release time r(j) and a processing time p(j). We assume 
without loss of generality that the size of the smallest job is 1. In the process of constructing a complete 
schedule for a given instance, we derive partial schedules in which we schedule a subset of the jobs 
in the instance. The remaining jobs are thus forbidden to be scheduled at the times assigned in the partial 
schedule. We refer to the set of remaining jobs, their release times, and the forbidden times as a constrained 
instance. A concept commonly used in scheduling is that of list schedules. A list schedule is a schedule 
in which there is a priority order among the jobs and in each step the job with the highest priority 
is scheduled. It is easy to show that every optimal schedule is a list schedule (Observation 1 of Section 
3.1). We restrict our attention to another class of schedules that is well- suited for flow and stretch 
metrics. Let Pt(j) denote the remaining processing time of job j at time t in the given schedule. We 
say that a schedule 8 is natural if it satisfies the following property: if a job j delays job j' at 
time t and p(~) > p(j~), then Pt(~) < Pt(f) = P(f). It can be shown that every optimal schedule is a 
natural schedule (Observation 2 of Section 3.1). We divide the jobs into groups such that the sizes of 
the jobs within a group differ from one another by a factor of at most (1 + e). Formally, for any nonnegative 
integer i, let group i consist of all jobs with size at least (1 + ~)i and less than (1 + ¢)i+1. To motivate 
our algorithm and to facilitate the analysis, we introduce the notion of rounded stretch. The rounded 
stretch of a job j in a given schedule is the ratio of the flow time of j in the schedule to (1 +~)i, 
where i is the group to which j belongs. Since the processing time of a job in group i is at least (1 
+ ~)~ and at most (1 + ~)i+1, it follows that the rounded stretch of a job in a schedule is within a 
factor of 1 + e of the actual stretch of the job in the schedule. We define the rounded cost of a schedule 
to be the sum of the rounded stretch of all the jobs in the schedule. Thus, the rounded cost of a schedule 
is within a (1 + e) factor of the actual cost of the schedule. We henceforth adopt rounded cost as our 
objective function. Thus, unless otherwise stated, whenever we refer to an optimal schedule, we refer 
to a schedule with minimum rounded cost. A naive approach to minimiz- ing rounded cost for a given constrained 
instance is to assign equal "weight" to each job within a group and schedule the jobs within the group 
in FIFO order. It turns out, however, that the resultant schedule can have cost twice that of the optimal. 
It can be shown in- stead that in a schedule with optimal rounded cost, the jobs within a group need 
to be scheduled in S~eT order. We refer to such schedules as SRPT-friendly schedules. In Section 3.1, 
we show that every optimal schedule is SRPT-friendly (Lemma 3.4). We next partition the groups into blocks. 
Block i, for i >_ 0, consists of groups ig through (i + 1)g -1, where g equals logl+~(1/v2). For simplicity, 
we assume in this section that 1/e is an integer. All our arguments can be easily modified to address 
the case where 1/~ is non-integral. It follows from the definition of a block that the size of any job 
in block i is at least 1/e 2 times the size of any job in block j for any j <: i --1. We further partition 
the blocks into superblocks. Superblock 0 consists of blocks 0 through b- 1, where b < 1/¢ is specified 
below. Superblock i, for i > 0, consists of blocks b + (i - 1)/e through b + i/~ -1. Thus, for any superblock 
i, jobs in every block of i, but for the largest numbered block, have size at most e 2 times that of 
any job in superblock j for j > i. We select b such that the total number of jobs in the largest numbered 
blocks of all of the superblocks is at most he. We note that since there are 1/e choices for b, one such 
choice exists. LEMMA 3.1. There exists a (1 + 2~)-approximate nat-ural SRPT-friendly list schedule in 
which no job in su- pcrblock i delays any job in superbloc~ j ]or ~ < i, for any i. Lemma 3.1 divides 
the given instance into several independent constrained instances, each of which con- tains jobs belonging 
to one superblock only. A su-perblock contains jobs belonging to a constant num-ber of groups. The fact 
that the optimal schedule for a superblock is natural and SaPT-friendly enables us to divide the given 
instance into a sequence of con- strained instances, in each of which there is exactly one job from the 
largest numbered group. Unfortunately, this alone does not significantly limit the number of dif- ferent 
schedules for one of these instances. We overcome this hurdle by showing that we can restrict our space 
of schedules to those schedules in which a particular job (in our case, the lone job from the highest 
numbered group) delays at most 1/J smaller jobs, for a J chosen suitably small. LEMMA 3.2. Let :E be 
any constrained instance. Let m denote the largest group number of any job in :T. Furthermore, suppose 
that there is exactly one job j from group m in Z. Then, given any positive integer c, any natural list 
schedule .for Z can be transformed into another list schedule in which j ddays at most e smaller jobs, 
while incurring an increasa in rounded cost by a factor of at most 1 + 1ft. Lemma 3.2 and an enumeration 
of schedules of interest establishes the following claim, that forms the final piece of the algorithm. 
LEMMA 3.3. For any J > O, ther~ exists an n °(m/e)- time algorithm to determine a (1 + ~)ra-approximate 
schedule for any constrained instance with m groups. THEOREM 3. There exists a PTAS for average stretch 
scheduling. Proof: Our algorithm consists of sequentially go- ing through the superblocks, from the smallest 
to the largest job sizes, and applying the algorithm of Lemma 3.3 to each superbloek (subject to the 
schedule already computed prior to the consideration of the su- perblock). A superbloek consists of at 
most g]e groups where g = loga+~(1/e 2) < 21og2(1/e)/e. Applying Lemma 3.3 with 6 equal to e3/lg(1/e 
2) and m equal to 2 log2(1/s)/E 2, we obtain a (1 + 2e)-approximate sched- ule for each superblock in 
N °Ol(e8 l°s2{a/e))) time, for e > 0 sufficiently small, where N is the number of jobs in the superblock. 
By Lemma 3.1, we lose another factor of (1 + 2e) for restricting to schedules in which no job in superblock 
i delays any job in superblock j > i, for any i. Thus, the approximation factor is (1 + 26) 2 < (1 + 
5e) for any positive constant e sufficiently small. The running time is n °(l/(~Si°s20/~))). We thus 
have a PTAS for average stretch scheduling. The remainder of this section is organized as follows. Section 
3.1 establishes certain characteristics of optimal schedules. Sections 3.2 and 3.3 establish Lemmas 3.1 
and 3.2, respectively. Due to space constraints, we refer the reader to the full paper [6] for the proof 
of Lemma 3.3. 3.1 Natural SRPT-friendly Hst schedules. The following two observations apply to optimal 
schedules with respect to both stretch and rounded stretch. OBSERVATION 1. For any constrained scheduling 
in-stance, every optimal schedule is a list schedule. OBSERVATION 2. For any constrained scheduling in-stance, 
every optimal schedule is a natural schedule. Consider a schedule that minimizes total rounded cost. 
Since the rounded cost assigns equal "weights" to all of the jobs in the same group, scheduling within 
a group in an optimal schedule minimizes the total flow time of the jobs subject to constraints placed 
by jobs outside the group. Since the total flow time is minimized by SRPT scheduling, we have the following 
lemma. LEMMA 3.4. For any constrained instance, every opti- mal schedule is SaPT-friendly. 3.2 Eliminating 
delays of small jobs by larger jobs. In this section, we prove Lemma 3.1. Given a constrained instance 
I and a natural SRPT-friendly list schedule 8 for I, we derive a natural SRPT-friendly list schedule 
in which no job in superblock i delays any job in superblock j for j < i, while incurring a cost increase 
by a factor of at most (1 + 2¢). Let m denote the largest group in I and let s denote the superblock 
to which group m belongs. We first describe a sweep procedure by which we convert S into a new natural 
SRPT-friendly list schedule in which no job in group m delays any job in superblock s - 1 or lower. Sweep 
procedure. Let t be the earliest instant at which a job j in group rn delays a job in superblock s - 
1 or lower. Let t ~ be the earliest time step after t at which there are no jobs from superblock s- 1 
or lower in the queue. We now claim that at every time step tl in the interval It, t~], either j or some 
job in superblock s-1 or lower is executed. The proof is by contradiction. Let tl be the earliest time 
in It, t ~] at which a job, say jl ~ j belonging to superblock s is executed. If r(jl) < t, then since 
S is a natural schedule and j is executed at time t, it follows that Pt (jR) = P(jl). Since tl is the 
earliest time at which jl is executed, Ptl (jR) = p(jl)-Since tl < t ~, there exists a job smaller than 
jl in the queue, and yet jl is executed. This yields a contradiction to the fact that $ is natural. We 
next observe that since S is a list schedule and j delays some job in superblock s -1 or lower at time 
t, j completes before time t ~. Let J denote the set of jobs other than j that are executed in the interval 
It, t']. We modify the schedule during so that j is given a priority lower than any job in J, and the 
jobs in J are scheduled according to an optimal SRPT-friendly, natural list schedule within It, t~]- 
In the new schedule, the rounded stretch of the jobs in J is at most that in S, while the completion 
time of j is at most t ~. Let kl denote the number of jobs in J from group i. Therefore, the increase 
in rounded cost iS at most ~~j'eJ P(f)/P(J)" Let S' denote the new schedule obtained. LEMMA 3.5. The 
schedule 3 ~ is an SRFrofriendly nat-ural lis~ schedule, m We repeat the above sweep procedure with the 
new schedule which, by Lemma 3.5, is an SRPT-friendly natural list schedule, and continue until every 
job in group m delays no job in superblock s -1 or lower. The increase in cost due to this transformation 
is at most ~'~i<(b+(~-l)/~D ~=r, where n~ iS the number of jobs in group i. We now describe how to convert 
a natural SRPT-friendly list schedule into another natural SRPT-friendly list schedule in which no job 
in superblock i delays any job in superblock j < i, for any i, while incurring an increase in cost by 
a factor of at most 1+2e. 1. Let m (resp., s) denote the maximum group (resp., superblock) in S. We 
apply the sweep procedure described above to obtain a new SRPT-friendly natural list schedule S in which 
no job in group m delays any job in superblocks s -1 or lower.  2. We fix the scheduling of the jobs 
in group m according to S. Let S ~denote the partial schedule of 8 induced by the jobs in groups m -1 
and lower and let 2: t denote the associated constrained instance. We set ~q to 5 ~, I: to 2:' and repeat 
step 1.   We now calculate an upper bound on the increase in cost due to the above procedure. If mi 
is the number of jobs in block i, then the total increase in cost iS at most Jr (1 + k>_b+(e-l)/e ">e 
< -+ ~ m~,e <_ 2~~. (In the last step, we use the fact that the number of jobs in the largest numbered 
blocks of all of the superblocks is at most n$ 2.) This completes the proof of Lemma 3.1. 3.3 Eliminating 
delays by many larger jobs. In this section, we prove Lemma 3.2. Let 8 be the given natural list schedule 
for instance 1. Let m be the largest group number in ~q and let j denote the lone job from group m in 
8. The goal is to determine a list schedule S' for / of cost at most (1 + 1/c) times the cost of ~q such 
that j delays no more than c smaller jobs in S'. Let t denote the earliest time step at which j delays 
more than c smaller jobs. Let t t denote the earliest time step after t in which there are exactly c 
jobs smaller than j in the queue. Let J denote the set of c jobs smaller than j that are alive at time 
t ~. We claim that none of the jobs in J is scheduled until time ~. The proof is by contradiction. Let 
j' be a job in J that is executed at time ti prior to t'. Clearly, tt >_ t since no job smaller than 
j can be executed prior to t and then delayed by j at step t in S because S is a natural schedule. If 
j~ is executed at time t~ E It, C], then at time tl there are greater than c jobs in the queue. Since 
f delays the remaining c jobs at time tl and is still alive at time t t, the remaining c jobs should 
also be alive at time t ~ because S is a list schedule. But there are only c jobs alive at time t ~, 
thus yielding a contradiction. We modify the schedule 8 to derive schedule 3 t as follows. During the 
interval [t, tt], we assign a priority to j higher than all jobs in J and lower than all other jobs. 
Subject to this constraint, we derive the best schedule for the remaining jobs that complete during the 
interval [L t t] in S. It is easy to see that the increase in rounded cost is at most (~'--t)/(1 +e) 
m. Since there are at least c jobs in groups m- 1 or lower at each time step in It, f], each contributing 
as much to the rounded stretch as j, it follows that the increase in rounded stretch is by at most a 
factor of I + 1/c. We note that the resultant schedule obt~ed may not be a list schedule. We convert 
~q' into a list schedule by assigning priorities to each job according to their completion times. The 
number of larger jobs that j delays cannot increase. Furthermore, by Observation 1, the rounded cost 
does not increase either. This completes the proof of the desired claim. 4 Rounding of job sizes In this 
section, we study the impact of incomplete knowledge of job sizes on stretch and flow metrics. We first 
consider a natural variant of SRPT, in which jobs are scheduled according to the rounded values of their 
remaining processing times, rather than the actual remaining processing times. This algorithm, which 
we refer to as A-SRPT, iS analyzed in Section 4.1. The algorithms studied in Section 4.1 rely on partial 
knowledge about the remaining processing time of each job at each step. A more realistic model for studying 
incomplete knowledge of job sizes is a relaxation of the non-clairvoyant model in which the total processing 
time of any job is known to within a constant factor only at the time of the release of the job. Section 
4.2 analyzes A-SPT, a variant of SPT, under this model. 4.1 Analysis of A-SRPT. Recall that in each step, 
SRPT schedules a job that has the least remaining processing time. In each step of A-sa~r, we schedule 
a job whose remaining processing time is within a (1 + A) factor of that of the job with the least remaining 
processing time. More formally, at any step, the jobs are divided into groups as follows: a job j is 
in group i at time t if Or(j) E [(1 + ~)i, (1 + ),),+l). (Recall that Pt(j) is the remaining processing 
time of j at time t.) At any step t, A-SRPT schedules a job from the smallest numbered group that is 
nonempty. (Note that 0-SRI'T is the same as SRPT.} The two main results in this section concern the performance 
of ~-SRPT with respect to the average flow and average stretch metrics. We first show that ~-SRPT is 
O(1)-competitive with respect to average stretch, for constant )~ > 0. With respect to average flow, 
however, we show that an adversarial mechanism of breaking ties among jobs in the same group leads to 
an ft(log A)- competitive ratio. This is a surprising departure from the true optimality of SRPT for 
average flow. We finally present a specific tie-brealdng mechanism and show that the resulting refinement 
of A-SRPT achieves an 0(1) competitive ratio for average flow, and thus is simultaneously competitive 
for the average flow and stretch metrics. Our analysis of A-SaPT proceeds by comparing the state of the 
queue in A-SRPT with the state of the queue in any other schedule, say S. Let St(i) (resp., S~(i)) denote 
the set of jobs in group i at time t in the )~-$RPT schedule (resp., S). Let Nt(i) (resp., N~(i)) denote 
the number of jobs in St(i) (resp., S~(i)) and let Vt(i) (resp., Vt'(i)) denote the total volume of jobs 
in St(i) (resp., S~(i)). We note that the total flow of a schedule is simply the sum, over all time steps 
t, of the number of jobs in the queue at time t. In particular, the total flow of the A-SRPT schedule 
equals Y~.t ]~]j>0 Nt(j). Similar to total flow, the total stretch of a-schedule can be calculated as 
the sum, over all time steps t, of the sum of the reciprocal of the processing times of the jobs in the 
queue at time t. The following lemma relates the prefix sum of the group volumes in the A-SRPT schedule 
with that in S. LEMMA 4.1. For all times t and groups i, we have Lemma 4.1 can be used to establish a 
constant-factor upper bound on the competitiveness of )t-SRPT with respect to average stretch. THEOREM 
4. For any constant A > O, )t-SRPT i8 Oil )- competitive with respect to average stretch. We now present 
a simple lower-bound argument that A-SRPT is f~(log A)-competitive with respect to average flow time. 
For concreteness, let A be 2. At time 0, we introduce two jobs, one of size 2 e+l -1 and the other of 
size 2 t, for some integer £. Since both the jobs are in group £, 2-SRPT may schedule the large job. 
When the large job enters group £ - 1, we introduce a new job of size 2 t-l. Again, since 2-SRPT does 
not distinguish between the two jobs, it may continue to process the first job. If we proceed in this 
manner, we note that in 2 TM time steps~ 2-SRPT completes one job and has at least l- 1 jobs in its queue, 
while an alternative schedule completes all but the largest job. Now, if we introduce a long sequence 
of say M unit-size jobs, all of which get priority in both schedules, we obtain that the total flow of 
9.-$RpT is fl(£M), while that of the alternative schedule is O(M), for M sufficiently large. Since ~ 
= O(log A), the desired lower bound on 2-SRPT holds. A tight analysis of A-SRPT with respect to average 
flow is given in the full paper [6]. We now show that a refinement of -SItPT achieves a constant factor 
competitive ratio for average flow as well; our analysis assumes that A is a positive integer. As A-SRPT 
is presently defined, the algorithm does not differentiate among jobs in the same group. Since there 
is uncertainty in the remaining processing times, certainly we cannot use the actual remaining processing 
times. Nevertheless, we do know the total processing times of the jobs up to a (1 + A) factor; we make 
use of this information in our tie-breaking mechani.qm. Let St(i) denote the set of jobs in St(i) that 
have actual processing time in [(1 + ),)i, (1 + )t)~+l). Consider a refinement of ),-SRPT which executes 
at each step a highest-priority job from the smallest numbered group that is nonempty, where the priority 
within a group is assigned as follows: the jobs in St(i) have higher priority than those in St(i) -St(i); 
within St(i), a partially executed job is given the highest priority. We now analyze the refined A-SRPT 
algorithm. We begin by noting that by the definition of the algorithm there is at most one job in St(i) 
-St(i). We define a quantity wt (i), which measures the amount of work performed on the Clone) job in 
St (i)- St (i) while it is in group i, if such a exists. More precisely, if St(i) -St(i) = {j}, we set 
wt(i) to be (1 + A) ~+1 - 1 - pj(t); otherwise, we set wt(i) to be A(1 + A) i. The following lemma is 
a variant of Lemma 4.1. LEMMA 4.2. For all times t and groups i, tee have (4a) +(1 + II We now show 
that refined ~-SRPT iS O(1)-competitive with respect to average flow. For all times t and groups i, we 
establish (4.2) ~Nt(j) < (I+A)EN~(j)+ rl/~l. j<i .i<~ The proof is by induction on i. The base case follows 
from Equation 4.1. For the induction hypothesis, assume that Equation 4.2 holds for all indices less 
them k, k > 0. We now establish the claim for index k. For 0 < i < /¢, we multiply both sides of Equation 
4.2 by A(1 + %)~, add the equations together to obtain (4.3) ~ ((I + A) ~ -- (1 + %3-~) N,(j) j<k < ~ 
((I + A) *+' -(I + A,).#+') N~(j) + [l/A] (1 + ~)~. Adding together Equation 4.1, with index k substituted 
for i, and Equation 4.3, we obtain (1 + A) k ~ Nt(j) < (1+ ~)k+lE NI(J) j<k #<_~ (4.41 +(I + A)*(rl/AI 
+ 1). Dividing both sides of Equation 4.4 by (1 + ~)t and noting that the LHS is an integer yields the 
desired inequality for the induction step. The O(1) bound on the competitive ratio of A-SRPT directly 
follows from Equation 4.2. 4.2 Analysis of ~-SPT. We now consider a different model for uncertainty 
in job sizes. In this model, when a job j arrives the actual processing time p(j) of the job is not known. 
Instead, what is known is the number i SUch that (1 + A) ~ < p(j) < (1 + A)~+I; we refer to i as the 
group of job j. In this section, we show the following simple algorithm, %-Sl'T, achieves an O(1) competitive 
ratio with respect to average stretch: In each step, A-SPT executes one unit of work on a job that has 
the smallest numbered group. The analysis of ~t-SPT is similar to that of A-SRPT.  Let Nt(i) (resp., 
N~(i)) denote the number of jobs in 770  group i at time t in the A-SPT schedule (resp., 8). Let Vt(i) 
(resp., Vt'(i)) denote the total volume of jobs in group i at time t in the A-SI-T schedule (resp., S). 
LEMMA 4.3- For all timem t and groups i, we have vt(j) < Ej< W(s). In each group i, there is at most 
one partiany executed job. Let S~(i) denote the subset of complete jobs in St(i). (Thus, ISt(i)l ~ Nt(i)- 
10 Let Nt(i) denote the number of jobs in St(i). The following claim follows from Lemma 4.3. LEMMA 4.4. 
For all times t and groups i, tee have <_ 0 + x) NI(J+ j<i #<i From Lemma 4.4, it follows that we can 
map each job in St(i) to distinct jobs in O#<~S~(j). Since the size of each job in St(i) is at least 
(1+ A) i and the size of each job in U~<~S~(j) is at most (1 + A) i+1, it follows that the stretch contribution 
of jobs in USa(j) is at most (1 + A) 2 times that of jobs in S at time t, which is at most S "-z. We 
now consider the stretch contribution of the partially executed jobs in A-SPT at time t. We note that 
this contribution is at most (1 + A)/A times that of the partially executed job in the smallest numbered 
nonempty group; this job is the one that is executed at time t. Since the stretch contribution of the 
active jobs, over all time t, is at most n, it follows that the total contribution of partially executed 
jobs, over all times, is at most (1 + 1/A)n. We thus obtain that the total stretch of ~t-SPT is at most 
(I + A)2~ r# + (I + I/A)n, which is O(~) for constant % > 0. For A : 1, the total stretch is at most 
4S* + 2n, and thus has a competitive ratio of at most 6 since S* ~_ n. The mi,!mum bound on the competitive 
ratio is achieved when % - 0.565; for this value of A, the competitive ratio is at most 5.22. While 
A-SPT is near-optimal with respect to aver-age stretch, its competitive ratio with respect to av-erage 
flow is ~/(logA), as exemplified by the following instance. For concreteness, we fix A -1. Consider a 
sequence of ~ - logt jobs of size 2 k, Iog£ __. k < ~, that arrive as follows: the job of size 2 k arrives 
at time (~/<i<k 21) - (~-k). Finally, l- 1 time units after the ~a*rival of the job of size £, a sequence 
of a large number, say M, of unit-size jobs arrive one after an- other at consecutive time steps. It 
is easy to see that the average flow achieved by 2-SPT is ~/(~M), while the average flow achieved by 
an optimal schedule is O(M). Since t = O(logA), the claimed lower bound on the competitive ratio of 2-SPT 
follows. The primary reason for the failure of )I-SPT to per- form well with respect to average flow 
is that almost complete jobs that may have a large total processing time are abandoned in favor of jobs 
that have shorter processing time. Since the information about processing times is only accurate up to 
a factor of 1 + ~, the algo- rithm does not have a good estimate on the remaining processing time of 
the jobs being partially executed. In fact, the range for the estimate could be a constant frac- tion 
of the actual processing time. To see this, we con- sider A = 1; when 2 i - 1 units of a job of group 
i is exe- cuted, the remaining processing time could be anywhere in the range [1, 2i). We conjecture 
that an O(1) com-petitive ratio with respect to average flow is achieved by a particular refinement of 
A-SeT, in which the algo- rithm tends to schedule jobs in the smallest group, yet maintains the constraint 
that the number of partially scheduled jobs is within a constant fraction of the total number of jobs 
in the queue. References [1] S. Achaxya and S. Muthukrishnan. Scheduling on-demand broadcasts: New metrics 
and algorithms. Proceedings of MOBIUOM, 1998, pages 43-54. [2] F. Afrati, E. Ba~npis, C. Chekuri, D. 
Karger, C. Kenyon, S. Khanna, I. Mills, M. Queyranne, M. Sart- inutella, C. Stein, and M. Sviriden~o. 
Approximation schemes for minimizing average weighted completion time with release dates. Proceedings 
of the 4~h An-nual IEEE Symposium on Foundations of Computer Science, 1999, pages 32-44. [3] H. Bast. 
Dynamic scheduling with incomplete informa- tion. Proceedings ofthe lOth Annual A CM Symposium on Parallel 
Algorithms and Architectures, 1998, pages 182-191. [4] H. Bast. On scheduling parallel tasks at twilight. 
Theory of Computing Systems, 33(5/6):489-563, 2000. [5] M. Bender, S. Chakrabarti, and S. Muthukri~nan. 
Flow and stretch metrics for scheduling continuous job streams. Proceedings of the 9th Annual ACM-SIAM 
Symposium on Discrete Algorithms, 1998, pages 270- 279. [6] M. Bender, S. Muthukrishnan, and R. P~jaraman. 
Im- proved algoritbm.q for stretch scheduling. Technical re- port NU-CCS-01-07, Northeastern University, 
October 2001. [7] C. Chekuri, S. Khann~, and A. Zhu. Algorithms for minimizing weighted flow time Proceedings 
of the 33rd Annual ACM Symposium on Theory of Computing, 2001, pages 84--93. [8] C. Chekuri and S. Khanna. 
Approximation schemes for preemptive weighted flow time. Manuscript, April 2001. [9] M. Crovella, R.. 
Frv~tgioso, and M. Harchol-Balter. Connection scheduling in web servers. Proceedings of the USENIX Symposium 
on Internet Technologies and Systems, 1999. [10] M. L. Fredman and D. E. Willard. Surpassing the in- 
formation theoretic bound with fusion trees. Journal of Computer System and Sciences, 47(3):424-436, 
1993. Ill] A. God, M. Henzinger, S. Plotkin, and E. "ikrdos. Scheduling data transfers in a network and 
the set scheduling problem. Proceedings o] the 31st Annual A CM Symposium on Theory of Computing, 1999, 
pages 189-197. [12] M. Harchol-Balter, M. Crovella, and C. Mutts. On choosing a task assignment policy 
for a distributed server system. Journal of Parallel and Distributed Computing, 59(2):204-228, 1999. 
[13] N. Joshi, S. Kadaba, S. Patel, and G. Sundaram. Do~nllnk schednll,g in CDMA data networks. Pro-cecdings 
of MOBICOM, 2000, pages 179-190. [14] B. Kalyanasundaram and K. Pruhs. Minimizing flow time nonclairvoyantly, 
Proceedings of the 38th Annual IEEE S~pnposium on Foundations of Computer Sci- ence, 1997. [15] B. Kalyanasundaram, 
K. Pruhs, and M. Velauthapil- lai. Scheduling broadcasts in wireless networks. Pro-ceedings of the Annual 
European Symposium on Algo- rithms, 2000, pages 290-301. [16] S. Leonardi and D. Raz. Approximating total 
flow time on parallel m~hlnes. Proceedings of the ~gth Annual A CM Symposium on Theory of Computing, 
1997, pages 110-119. [17] P~ Motwani, S. Phillips, and E. Torng. Nonchirvoywut scheduling. Theoretical 
Computer Science, 130(1):17-47, 1994. [18] S. Muthukrislman, P~ P~jaraman, A. Shaheen, and J. Gehrke. 
Online scheduling to minimize average stretch. Proceedings of the ~Oth Annual IEEE Symposium on Foundation8 
of Computer Science, 1999, pages 433-442. [19] M. Thorup. On RAM priority queues. In Proceedings of the 
7~h Annual ACM-SIAM Symposium on Discrete Algorithms, 1996, pages 59-67.   
			