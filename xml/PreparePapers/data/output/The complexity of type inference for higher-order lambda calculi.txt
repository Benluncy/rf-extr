
 The Complexity of Type Inference for Higher-Order Typed Lambda Calculi Courant Fritz Henglein Institute 
of Mathematical New York University New York, N.Y. 10012 and Sciences Harry G. ikfairsonf Computer Science 
Department Brandeis University Waltham, Massachusetts 02254 Computer Science Department Utrecht University 
3508 TB Utrecht The Netherlands Abstract We analyze the computational complexity of type inference for 
untyped A.terms in the second-order polymorphic typed ~-calculus (l z) invented by Gi­rard and Reynolds, 
as well as higher-order extensions F3, F4, . . . . Fw proposed by Girard. We prove that recognizing the 
F2-typable terms requires exponential time, and for Fw the problem is nonelementary. We show as well 
a sequence of lower bounds on recogniz­ing the Fk-typable terms, where the bound for Fk+l is exponentially 
larger than that for Fk. The lower bounds are based on generic simulation of Turing Machines, where computation 
is simulated at the expression and type level simultaneously. Non­accepting computations are mapped to 
non-normalizing reduction sequences, and hence non-typable terms. The accepting computations are mapped 
to typable terms, where higher-order types encode reduction sequences, and first-order types encode the 
entire computation as a circuit, based on a unification simulation of Boolean logic. A primary technical 
tool in this reduction is the composition of polymorphic functions having different domains and ranges. 
*Supported in part by Office of Naval Research grant NOO14-9O-J-111O t Supported by grants from Texas 
Instruments and fmrr the Tyson Foundation. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and ha date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy other­wise, or to republish, requires 
a fee and/or specific permission. @ 1990 ACM 089791-419-8/90/0012/01 19 $1.50 119 These results are the 
first nontrivial lower bounds on type inference for the Girard/Reynolds system as well as its higher-order 
extensions. We hope that the analy­ sis provides important combinatorial insights which will prove useful 
in the ultimate resolution of the complexity of the type inference problem. 1 Introduction One of the 
outstanding open problems in programming language theory and type theory is the decidability of type 
inference for the second order polymorphic typed A­calculus invented by Jean-Yves Girard [Gir72] and 
John Reynolds [Rey74]. More precisely, does there exist an effective procedure which, given an untyped 
A-term, can decide whether the term is typable in the Girard/Rey­nolds system? If so, and the term is 
typable, can the algorithm produce the required type information? While this decision problem remains 
tantalizingly open, we present techniques which can be used to prove significant lower bounds on the 
complexity of type infer­ence for the Girard/R,eynolds system, also called F2, as well as higher-order 
extensions F3, F4, ., , , FU proposed by Girard. In particular, we show that recognizing the F2-typable 
terms requires exponential time, and for Fw the problem is nonelementary. We show as well a se­quence 
of lower bounds on recognizing the Pk-typable terms. k integer, where the bound for Fk+l is exponen­tially 
larger than that for f k. These results are the first nontrivial lower bounds on type inference for the 
Girard/Reynolds system as well as its higher-order extensions. We hope that the analY­sis provides important 
combinatorial insights which will prove useful in the ultimate resolution of the complexity of the type 
inference problem. The problem of type inference is one of both theo­retical and practical interest. 
Following the insights of Landin [Lan66], Strachey [Str73], Penrosel, and others, the untyped ~-calculus 
has long been recognized as not merely Turing-complete, but a syntactically natural foundation for the 
design of programming languages. The process of /?-reduction is a simulation of compu­tation and function 
call, while normal forms simulate final returned answers. Types augment programming languages with addi­tional 
guarantees about resultant computational behav­ior. For instance, static typing as in Pascal requires 
explicit typing by the programmer, but allows all type checking to occur at compile time, with the guarantee 
that no compiled program will go wrong at run time due to type mismatches. The price paid for this guaran­tee 
is a loss of parametric polymorphism ( code reuse ), so that programs designed for abstract data types 
must be recoded for each type on which they are used. As an example, the computation of the identity 
function 1(z) = z is certainly data-independent, yet its real­ization in Pascal demands identical code 
with different type declarations for the identity function on integers, booleans, arrays of length 10 
of characters, etc. all this redundancy merely to please the compiler. A powerful extension to this methodology 
was pro­posed by Robin Milner, namely a theory of type poly­morphism for achieving code reuse, while 
retaining the benefits of strong typing. He gave an algorithm which, presented with an untyped program, 
could construct the most general type information (known as the princi­pa/ type [Hin69, DM82]) for the 
program [Mi178]. These insights are implemented in the ML programming lan­guage [HMT90] as well as a 
variety of other functional languages [HW88, Tur85]. The principal type of an ML program provides an 
important functional specifi­cation of the program, describing how it can be used by other programs; 
as such, types are useful as specifi­cations, and to facilitate incremental compilation. The ML module 
system is an elegant realization of these basic intuitions. The ML language is not merely an example 
of suc­cessful software engineering. It is also an important departure point and testbed in our theoretical 
exam­ination of type inference: studying type inference for ML has provided important insights. The Core 
ML language comprising typed ~-calculus with polymor­phism (as embodied in let) enjoys the strong normaL 
ization property: typable programs are guaranteed to 1In his 1977 Turing Award lecture, Dana Scott mentions 
that it was physicist Roger Penrose who pointed Strachey in the direction of the A-calculus as a useful 
device for de­scribing programming language semantics [SC077]. terminate2. Reconstructing the type of 
an (untyped) ML expression is thus in essence the synthesis of a ter­mination proof. Of special interest 
here is the fact that typable ML expressions are, modulo synt attic sugar, a nontrivial subset of the 
A-terms typable in F2, F3,. . . . Fw. Fur­thermore, all of these type systems enjoy strong normal­ization. 
Since kterms typable in Fk are also t ypable in Fk+l, we may regard the higher-order type systems as 
more and more powerful expression languages in which to encode termination proofs. It is natural to expect 
that greater expressiveness may facilitate the extrac­tion of stronger lower bounds; proving lower bounds 
on type inference for FW should at least be easier than for F2. We note, however, that FU is not ~ust 
an esoteric variation on F2, since it has been proposed as the math­ematical foundation for a new generation 
of typed func­tional programming languages, in particular Cardelli s language Quest [Car89] and the LEAP 
project at CMU [PL89]. The lower bounds presented here are all generic re­ductions, where an arbitrary 
TM M with input x of length n is simulated by a A-term VM,Z, such that M accepts z in time ~(n) iff VM,. 
is typable. In con­structing strong lower bounds, the challenge is to en­code as rapidly increasing an 
~(n) as possible, while constraining the transducer reducing M and x to QM, Z to run in logarithmic space. 
By the time hierarchy the­orem [HS65, HU79], these complexity-class relativized hardness bounds translate 
(via diagonalization argu­ments) to nonrelativized bounds. For instance, the DTIME[2 ]-hardness bound 
for typability in F2 implies a Q(cn) lower bound for some constant c > 1. The structure of WM,G is basically 
a consequence of the fol­lowing proposition [KMM90]: Proposition 1.1 Given a strongly normalizing A-term 
E, the problem of determining whether the normal form of E is first-order typab(e is DTIME[f (n)] -hard, 
for any total recursive function f(n). Proof. (Sketch) Given a TM M halting in f(n) steps on input z 
of length n, construct a )i-term 6 encoding the transition function of M, so that if y codes a machine 
ID, (6 y) /?-reduces to a A-term en­coding the ID after a state transition. Let ~ be the Church-numeral 
encoding of f, E be the Church nu­meral for n, and IDO be the encoding of the initial ID. Consider the 
typing of the normal form of E ­~ R 6 IDO D ~(n) 6 IDO D df( ) IDo. The normal form of As a consequence, 
ML is in practice augmented with a set of typed fixpoint operators, 13 codes a machine ID after ~(n) 
transitions; construct E to force a mistyping in the case of nonacceptance. w The fundamental contribution 
of this paper is to de­tail what is absent from this proof sketch, strengthening the statement of the 
proposition to concern the typabil­ity of E (instead of its normal form) in the various sys­tems Fk, 
while weakening the proposition by restricting the possible asymptotic growth of ~(n).3 The remainder 
of the paper gives these details, mixed with some short tutorials on the type systems under study, where 
we have forgone the formality of infer­ence rules in preference for intuition. In Section 2, we briefly 
outline F2, the second order polymorphic typed A-calculus, and in Section 3 we present an exposition 
of the DTIME[2n~]-hardness bound for typability in F2. In Section 4, we provide a description of the 
systems F3, F4, ..., Fu generalizing Fz, with emphasis on the significance of kinds in these systems. 
In Section 5 we outline the nonelementary lower bound on typability for FW, and show the connections 
between this bound and related lower bounds for the Fk. our tutorial ma­terial follows the presentation 
of [PDM89], which we enthusiastically recommend to anyone desiring a read­able introduction to programming 
in higher-order typed A-calculi. 2 The second order polymor­phic typed A-calculus (Fz) F2 is best introduced 
by canonical example: the identity function. In Fz, we write the typed polymorphic iden­tity function4 
as Id ~ Aa: *. Ax:cY.x. The Ax.x should be familiar; the Aa: * denotes abstraction over types5. For instance, 
given a type Int encoding integers, we can represent the identity function for integers as: Id [Int] 
E (As: *. Ax:a.x) [Int] B-~x:lnt.x The b indicates @reduction at the type level, where Int is substituted 
for free occurrences of cr. Given a type Bool encoding Boolean values, we may similarly write Id [Bool] 
to get the identity function for booleans. In short, Id is a polymorphic function which may be parametrized 
with a given type to derive an identity function for that type. We write the type of Id as 3Observe that 
these type systems preserve typings under /3-reduction. 4 For clarity, we show expression variables in 
boldface and type variables in itaiic when both occur in the same expression. 5For the moment, we consider 
the x to be syntactic sugar, though in generalizations of FZ this will not be so. ld G Aa: *.CY+ a, where 
A (sometimes written as V) represents universal quantification over types. Church numerals may be typed 
in a similar fashion: ~ E As:*.M:cx + (1 .~X:~.X i = Aa: *.Af:a + a. Ax:a.fx 2 G ACY: *.Af:a + a.~x:a.f(fx) 
... The type of all Church numerals is IntzAa: *.(a + a)+ a+ a. In the untyped Lcalculus, we realize 
the exponent nm by reducing the expression (Aj.k.~~x) (A~.k.~nZ) to normal form. This reduction can be 
typed in F2: A&#38;*.(Ri [/3+ /8])(fi ~]) E Afl: *. ((AcK *.Af:a + a.~x:a.fmx) [~ + ~]) ((As: *.&#38;a 
+ ody:a.gny) [B]) D A@*. (Af:(p + @ + p + /3. Ax:/3 + J3.fmx) (Ag:p + /3. Ay:p.gny) D A/3: *.~X:~ + /?. 
(Ag:/3 + /3. Ay:o.gny)~x D AB: *.~X:~ + ~. (Ag:p + p. Ay:p.gny)~- (Ay :p.xny) b A~: *.~X:~ + ~. (Ag:/? 
+ /3. Ay:/?.gny)~- (Jy :/3,xn2y) ... D A/3: *.~X:~ + ~. ~y:~.Xnmy. Observe that the normal form is also 
of type lnt.6 Church numerals are merely polymorphic functions which compose other functions having the 
same domain and range, while exponentiation is just a higher-order mechanism for constructing such function 
composers. What happens when we want to compose a function having a different domain and range? We will 
show that the answer to this question is crucial to the devel­opment of lower bounds. 6Here, we allow 
a-renaming of A-bound variables at the type level. 3 An exponential lower bound Example 3.1 on F2 type 
inference 3.1 Paradise lost: lessons learned from ML It has been know for some time that type inference 
for the simply-typed (first-order) ~-calculus can be solved in polynomial time. A simple and elegant 
exposition of this fact can be found in [Wan87], where a syntax­ directed algorithm is given that transforms 
an untyped A-term into a linear sized set of type equations of the form X =YandX =Y+ Z,suchthat thesolu­ 
tion of the equations (via unification [Rob65, PW78]) determines the principal type of the term, In progressing 
from this language to ML, it is neces­sary to understand the effect of quantification over type variables 
on the complexity of type inference. Natu­rally, this insight is also crucial in the case of F2. The 
progress in understanding ML quantification and type inference is primarily due to two straightforward 
obser­vations. The first, given in [Mit90]7, is that the fol­lowing inference rule for let preserves 
exactly the type judgments for closed terms usually derived using the quantification rules: Because TO 
and ~1 are first-order types, this alternate inference rule is a classic instance of quantifier elimina­tion. 
In the spirit of the Curry-Howard propositions­as-types analogy, it also acts as a sort of cut elimina­tion, 
preserving propositional theorems at the expense of greatly enlarging the size of the proofs. The added 
combinatorial insight comes from that fact that type inference can be completely reduced to first-order 
uni­fication. The second observation, due to Paris Kanellakis and John Mitchell, is that let can be used 
to com­pose functions an exponential number of times with a polynomial-length formula [KM89]: 71n this 
survey, the rule is attributed to Albert Meyer. However, it appears as well in the thesis of Luis Damas 
[Dam85], and in fact a question about it cau be found in the 1985 postgraduate examination in computing 
at Edinburgh University [Edi88]. The above expression let-reduces to Ay. j 2 y, where the occurence oft 
is polymorphic. The significance of this polymorphism is exploited in the lower bound of [Mai90, KM M90], 
where it is shown that recognizing typable ML expressions can be solved in DTIME[2n], and is DTIME[2 
~]-hard for every inte­ger k >1 under logspace reductions The lower bound is a generic reduction: it 
proceeds by using types to encode TM IDs, and constructing a A-term simulating the transition function 
at the type level. The type of (Q Illo), where lDO is a ~-term whose type encodes the initial ID of the 
TM, and the transition function is sub­stituted for ~, then encodes the state of the machine after 2nk 
state transitions. A mistyping is forced in the case of a final rejecting state, The circuitry of the 
TM is effected through taking the simulation of Boolean logic by first-order unification found in [DKM84], 
and real­izing the Boolean gadgets found there by the types of l-terms. In its nascent state, the ML 
lower bound is useless to bound the complexity of F2 type inference. The proof of machine accepts iff 
ML formula types is made by a straightforward appeal to the simple logic of first-order unification, 
where in the case of a rejecting computa­tion, it is obvious how to force a mistyping. To fur­ther claim 
that there is no F2 typing is far from clear, since F2 types do not admit naive quantifier elimina­tion, 
hence first-order arguments are too weak. Prov­ing that strongly normalizing terms are not Fz-typable 
is very difficult: as evidence, we point merely to the tremendous effort of Giannini and Ronchi dells 
Rocca [GR88] in their identifying a single, simple, strongly normalizing term which is not F2-typable. 
 3.2 Paradise regained: an F2 lower bound The force of the ML argument can be regained, how­ever, by 
changing the simulation of Boolean logic from that found in [DKM84] to the classic simulation in the 
~-calculus. For example, we type the Boolean values An alternate proof is found in [KTU90]. as: We remark 
that this encoding is not Girard s inductive­type definition of Boolean values; observe simply that true 
and false have different types, while in Girard s construction, the Boolean values are both terms of 
type Acr:*. cr* m + a. By using the ~classic logic, the ML proof can be simplified, with the added bonus 
that the simulation of TM computation is carried out (as before) on the type level, but mirrored exactly 
at the value level. For in­stance, the ML typings of the classical simulations of conjunction and disjunction 
produce the correct terms as outputs, and also the correct Boolean types as de­scribed above. Values 
of expressions are immaterial to the ML type checker, which computes only their types; the proof of [Mai90] 
goes to great lengths to exploit this point. Restoring the duality between values and types is one of 
the key ideas in the F2 bound. A Boolean value A is computed (via @reduction) which answers the question 
Did the TM accept its input? ; this term is used in the expression ~ R (.kr.zz)(A (k.z) (~y.yy)) Observe 
that if A D fake, then W b (Ax.zx)(Ay.yy). By the simple appeal to Girard s strong normalization theorem 
for F2 [Gir72, GLT89], we then know that if the TM rejects its input, Q is not typable. What re­mains 
is to show that if the TM accepts, then W can be typed. We must in this case look more carefully at the 
structure of the term A. 3.3 Encoding Turing Machines by lambda terms Given a deterministic TM M, we 
show how to encode the transition function of M as a A-term 6 such that if ID is a A-term encoding a 
configuration of M, and ID is the next configuration of M coded as a J-term, then IS ID Dp H? . We call 
this a simulation at the value level. The encoding also yields a very compact and simple proof of the 
DTIME[2 k]-hardness bound ior recognizing ML-typable terms. Let M have finite states Q = {ql, . . . . 
gk} with ini­ tial state ql and final states F C Q; tape alphabet C = {cl, . . . . cl} with blank symbol 
)5 = c1; tape head movements D = {dl, d2, d3} (left, no movement, right); and transition map d: Q x C 
-Q x C x D. A config­uration (ID) of M is a triple (q, L, R) E QxC xC giving the state and contents 
of the left and right hand sides of the tape; we thus define the transition function of AI by the usual 
extension of 13. We assume that the TM never writes a blank, that it does not move its tape head iff 
it reads a blank, and that it never runs off the left end of the tape. We represent the finite sets Q, 
C, D, and Bool = {true, fake} by projection functions. Given a finite set @={e~, ..., e$ }, we code e! 
by the ~-term d; z Aiv1.Ax2. . . .Axk.xi. A k-iuple E = (eI, ..., ek) is coded by the J-term ~z.~el 
. . .e~; note ~d~ Dp ei. A /ist [xl, . . . . xk] denotes the tuple (*1, (82, . . . . (Xk,nil) . . .)), 
where nil E A2..Z. A function m: Ek + F with finite domain can then be coded as the tuple 77i= (m(el), 
. . ..rn(ek)). so that Hid: bp m(ei). When the finite domain of a function is the product of several 
finite sets (as in 8), we realize the function in its curried form. The coding of the )-term 6 is simplified 
by using a notation for pattern matching on tuples. If tis a k-tuple, we write (xl, .... z~) = t; e for 
t(kcl. ..Axk. e). For example, fst can be defined as At.(xl, X2) = t; X1. We allow nesting of patterns, 
e.g., ((xl, zz), y, (a, zz)) = e; e means (z, y, z) = e; (X1,*2) = 2; (~1,~2) = z; e . We represent a 
TM ID by a tuple (q, L, R), where L-[ll, . . ., /m] and R E [rl, . . . . rn] are lists coding the left 
and right contents of the tape; we assume the tape head is reading rl, and /1 is the cell contents to 
the immediate left, Given all these technicalities, the transition function of M has a very simple encoding: 
6 s MD. (g, (/, L), (r, R)) = ID; (q , c , d ) = d gr; d (q , L, (~, (c , R))) (q , (~, L), (c , (}, 
W)} (q , (c , (~, L)), ~) Note that (q , c , d ) codes the state, symbol written, and head direction 
for the next machine configuration, as computed by 8; d is then used as a projection func­tion to choose 
the ~-term coding the next configuration. Because no value is used more than once, no side­effecting 
of type variables occurs, and the equivalent of the fanout gates of [Mai90, KMM90] is not necessary. 
 3.4 Encoding Turing Machines by types The simple encoding 6 of the transition function is ty­ pable 
in ML; moreover, it has the following property: Lemma 3.2 Let ID and ID be A-terms coding succes­sive 
configurations of M, and let u and u be their re­ spective first-order principal types. Then C$ID bp 
ID , and 61D E u . Furthermore, if ~Dk a s a ~-term with principal type ok coding the state of M after 
k transi­tions from ID, then (Id) ID bp ~Dk, and (16) ID E Ok. The Lemma states that the computation 
of Al is sim­ulated not only at the vatue level~but also at the type level. Observe that the typing of 
k 6 is rank 2. Corollary 3.3 Let E ~ (Jf.~(~. . .(~f) . . .)) 6 IDO, where there are m occurances of 
~, and Ill. codes an initial ID of M. Then E has the same norms! form and rank 1? type as (~ti) IDO. 
Proof. (sketch) Let T~ be the rank 2 principal type of ~~i_~ype the m occurrences of Z, from left to 
right, as 2m 2m 2 ~ ~2 -1 r -+7-,T T2 --+ T ,T1 + T . 1 .,., w Theorem 3.4 Recognizing the lambda terms 
typable in F2 is DTIME[2n ]-hard for any integer k ~ 1 under logspace reduction. Proof. Assume that F 
= {qP+l, . . . . q~} C Q are the accepting states of A4. Consider A s (q, L,R) D (Af.Z(Z. . .(~f) . . 
.)) 6 IDO; q false . false true . . . true where ~ occurs n~ times, the first p arguments of q are false 
and the remaining k p arguments are true. If M accepts input z after exactly 2n steps, then A /3­reduces 
to true. By Lemma 3.2 and Corollary 3.3, the A-expression A has principal type ACY: *.A~: *.cr + ~ -+ 
a, so that WM, &#38; ~ (~Z.ZZ)(A (1.c.z) (J,y.vv)) i. typable in rank 3. If M rejects z, then A ~-reduces 
to Ax. Ay.y, and consequently TM,Z reduces to (Ax. xx)(Jy, yy), By Girard s strong normalization theorem 
[Gir72, GLT89], VM,C is not F2-typable. It is easily seen that ~~,z can be const rutted in logarithmic 
space from M and z. m The A-expression E we use for simulating M on x has a rank 2 typing in F2 whenever 
it has an F2-typing. Since rank 2 Girard/Reynolds typability is equivalent to ML typability [KT89], which 
is DEXPTIME-complete, this result is the best we can achieve without resort­ing to higher-rank typings. 
Note that a slight varia­tion of the representation WM,Z gives a compact and simple proof of DEXPTIME-hardness 
for recognizing ML-typable terms. Corollary 3.5 (Fixed type inference) Let r be an ar­bitrary but fixed 
F2 type. Then the problem of recogniz­ing the lambda terms which can be given the F2 type r is also DTIME[2n~]-hard 
for any integer k > 1 under logspace reduction.  4 An overview of F3, F4, . . . . F. The F2 lower bound 
given above has two parts: (1) a simulation of the transition function of an arbitrary TM by a closed 
A-term; and (2) a method for compos­ing the transition function an exponential number of times. The analogous 
ML bound stops at exponential because of ML s limited ability to (polymorphically) compose arbitrary 
functions. No such limit is appar­ent in F2 or its higher-order extensions, so a natural place to strengthen 
the F2 bound is to improve the function composition realized in (2) and thus turn the crank (of the transition 
function) faster. Note that the crank of Example 3.1 is (without syntactic sugar) merely the A-term which 
has the same power as the term E in Corollary 3.3. Might there be more powerful typable reduction sequences 
in the systems Fk? We show this program can be carried out in FU to derive a nonelementary lower bound. 
Related super­exponential bounds can be proven for the F~ so that re~ognizing typable A-terms of length 
n requires ~~ (n) time, where fk(n) is an exponential stack of 2s grow­ing linearly with k, and n on 
top of the stack. Before describing these lower bounds in more detail, we pro­vide a brief overview of 
the type systems F3, F4, ., ., FW. 4.1 Kinds and abstraction over func­tions on types  In the first-order 
typed A-calculus, the type language is made up of type variables, and a binary function + mapping a pair 
of types to a type. In F2, we add uni­versal quantification, but only over type variables. The higher-order 
systems F3, F4, . . . . FW are designed to al­low abstraction and quantification as well over functions 
on types, with varying degrees of freedom. Let * denote the kind of types that may be gener­ated in F2: 
we could describe the functionality of (a curried) + as --+ c x a x ~ x, where + is a higher­order version 
of + describing functions from types to types. If we now introduce A-abstraction at the type level, imitating 
its existence at the expression level, we can describe other functions on types, for example: This expressiveness 
adds considerable power to the type language. Its practical need is apparent in trying to give a meaning 
to List when parametrizing the identity function as ki [List Int] we want List to be a higher­order type 
(i.e., one of kind * + *) which maps a type (Int) to a type (List-lnt). A logical example of the need 
for higher-order types is found in the intuitionistic pro­gram for the disjunction of propositions (types) 
p and q: PV qE Ar: *.(p -r) e (q~ r) -+ r. (We consider p V q to be of kind * it is also a proposition.) 
By ab­stracting over p and q, in a higher-order system we may write: V ~ ~p:*. ~q:*. Ar:*. (p + r) + 
(q + r) + r. To use such definitions, a-renaming and ~-reduction are introduced at the type level. The 
type systems Fk differ in the degree to which they allow higher-order type abstraction. In F2, no such 
~-abstraction is allowed, and all types have kind *. In F3, A-abstraction is allowed only over types 
of kind *, and in Fk+l abstraction is allowed only over types of kinds found in Fk. In Fu, there are 
no such restric­tions. We can describe the kinds ~k allowed in Fk by a grammar: K2 ::= * Kt+l ::= El 
I K!* KL+I Kw ::= * [KW+K.  5 Type inference for Fw is nonelementary To derive a nonelementary bound, 
we show how to type the A-term C 6 IDO, where c E (Af.Az.f2z)(Agn .Ayn.g;zJn) (~gn-l.~yn-l.g: -,yn-l) 
o ( J90.AYO.9;YO), and S and IDO code the tramition funct,ion and initial ID of a TM, as in Section 
3. The method we describe for typing C makes very broad assumptions about the reductions caused by 6, 
and thus provides a general technique for composing functions. Observe that C 6 ~DCI b (~yl .~y0.f(n+2)yo) 
6 ~Do b 6@(n+2)ID0, where the function @ is defined as 0(0) = 1, @(t + 1) = 2@(~). The technical challenge 
is to type C so that yl gets the type of 6, and y. the type of IDO. The term C codes repeated exponentiation 
as in Example 3.1, except that the function 6 being composed does not have the same domain and range. 
To understand how to compose functions with different domains and ranges, we have to examine the type 
of 6 more closely; we abstract its structure as: 6 c AV1:*.AV2:*. . . .AvT:*. Z(vl, vz, . . ..vr )+?Z(v,, 
v2,..., vr). Proposition 5.1 ~(vl, V2, . . . . v,) is a substitution in­ stance oj%?(wl, v.q, . . .Izvr). 
 Proof. They both encode TM IDs, and so are unifi­ able. The (circuitry of the unification logic exists 
on the ~ side, which induces structure on the (~ side. - We now represent the type of 6 by using higher­order 
type constructors. Divide the type variables V={vl,. ... W} into disjoint sets VI = {VI, . . . . Vp} 
and V. = {VP+l, . . ., Vp+g=r } ~ w here the output vari­ables V. appear in ~(vl, V2, . . . . w.), and 
the intermedi­ate variables VI form the complement. We can then de­fine an ID-constructor makeID as a 
function on types: make-ID E AX1:*, AX2: *. . . .Axq: *. R(zl, x2, . . ..zq) E *9+1, where we use the 
abbreviation xl s x, Xa+l ~ * + *Q, and 7? is ~ restricted to the output variables. Lemma 5.2 There exist 
type functions 17i E * +1, 1< i < q, such that the type of 6 can be represented as: 6 E AVI:*.AV2: * 
. . .. AVT. *. (make-ID (r, Vlv, ~.. v.) (r2v1v2... vr) ... (rqV1V2...Vr)) + make-ID VP+l VP+Z . . . 
VP+q. Proof. By first-order unification and Proposition 5.1. We remark that the functions 17i encode 
what we have called (TM circuitry. m How is 6 composed polymorphicatiy, namely the equivalent of ML 
s let 62 = MD.6(6 ID)? In ML, the type of ?i2 is realized by first-order unification; we sim­ulate this 
using the functions I i. 1 ?s Proposition 5.3 The A-term 62 can be giwen the Fw ­type Observe that the 
output variables WP+l, . . . . VP+* in the type of 6 have been instantiated so that vP+i = r~ vi . v;. 
The primed variables form a second floor of circuitry, while make-ID puts a roof on the type struc­tures 
generated by the variables and the ri. Repeated composition yields a giant directed acyclic graph, where 
the depth of the dag (i.e., the number of floors) is lin­early proportional to the degree of composition. 
 5.1 Higher-order type data structures We now show how A-abstraction and application at the type ievel 
can be used to manufacture huge dags repre­senting the t-fold composition of 6. The existence of A at 
the type level allows the construction of such ab­stract data structures. The basic idea is the following: 
we construct a cer­tain A-term I _ at the type level which represents the type of the j-fold composition 
of 6, where the kind ~ of T does not depend on j. We then define a function map: K +-K such that map 
~ represents the type of the (.7 -i-I)-fold composition of 6. Because the domain and range (both kinds) 
of map are identical, we can at the type level engage in conventional function composi­tion tricks that 
would not work at the expression level. For instance, we can define E(K*K)+K*K and write ~map D ~7: 
K.map(map(map(map 7))). The coding of the type map is not pretty, but its use is quite elegant. The 
fundamental data structure manip­ulated by map is called a pair. A pair has two parts: a prototype, and 
a variabie list. A prototype is a ~-term of the form AZ1:*.AZ2: *.... Axq: *. A@: *q+@+l. @ dl~zdgdl 
@ The d ~ di are just dummy type variables to pad the kind, and the ~i are types involving some set 
Vi, ..., vPt of type variables, xl, . . . . x., and --+, so each ~i is of kind *. We imagine the 4i to 
be the dag under construction, so that make-ID 41 . . q$qwould form a suitable ,C, given type variables 
for the xi. A variable list is a A-term of the form Azl: *.AX2: *. . . ~Azq: *. A@: *q+@+l. Qflfz tqvl 
 %t, where the ji are the output variables of the dag ul­ timately to be constructed, and the vi are 
a list of variables to be used during the construction. The Azi­ bindings are padding. A pair is a A-term 
of the form ~~:K + K + K .~ PV G(K + K =+K ) + K , where P is a prototype and V is a variable list 
(both of kind K ). Because of the kind identity, fst and snd are definable on pairs, as is projection 
of types of kind * in the pair. The A-term map maps pairs to pairs, where the new pair is one composition 
step closer to the ultimate t­fold composition, as represented by the prototype. The definition of map 
is tedious and is postponed to the fi­nal version of the paper; it involves straightforward list processing 
on pairs, where the type variables in the vari­able list are repeatedly shifted cyclically and retrieved 
as the floors are built. We also define a A-term z which takes a final pair and produces a first-order 
type of the t-fold composition of 6. 5.2 Composing map Now comes the elegant and truly fun part: we 
use the <crank c = (Af.Az.f2z)(J9n .~Yn.9:Yn) (Agn_,.Ayn-,.g: -~yn-l) . (J90. JYO.98YO), (at the expression 
level) to compose map @(n+2) times. The dag gets constructed at a speed controlled by the reduction sequence 
of C to normal form. Suppressing kinds for readability, we recursively define a set of types used to 
type C: Go{ao} -Amap.(A~.Z(maP T) + ZT) -+ (Ar.Z(aomap ~) ~ Zr) G1{cY1} s Aao.Go{ao} -+ Go{alaO} s AaO.~O{aO} 
-+ Amap. (A~.Z(map ~) + ZT) -+ (A~.X(alaOmap T) a zr) ~~+l{a~+l} a Aa~.G~{a~}+g~{a~+la~} Lemma 5.4 For 
each O < i < n, ~gi.~yi.g~yi can be typed as ~~{~}, where ~S ~u.~r.uzr is a type having the same kind 
as ~i. Proof. For~go.Ayo.g~yo, wehave the typing Amap. Jg: A~.Z(map ~) A ZT. AT. Jy: Z(map(map r)) ~ 
Z(2mapr). g [r] (g [map ~] y) and for Jgi+l .Ayi+l .g~+lyi+l, i > 0, we have the typing Aai. ~g:~i{ai} 
= A~i_l.~i_l{~i_l} + ~i_.l{~i~i_l}. Acw_l. Ay: g&#38;l{a&#38;l}d g [C&#38;@i-1] (g [ai_l] y) Lemma 5.5 
In the term C , Af./kz.f2z E G.{z} + G.-I{2} -+ Gn_l{m}. Theorem 5.6 The term C (the crank ) has typing 
C S (Af .k.f 2X)(~gn.~yn.g~Yn) (~gn_l~Yn_lg~_lYn.1)[2 (Agn-2JYn.2g~_2 Yn_2)[~ (~g~_3~Yn-3g~_3Yn-3)[Z 
... (%(1 .~Y() .giYo),  We now briefly sketch how this typing for C can be used to type C 6 IDO. We 
take the type and parame­ trize it with the definition of map, and then show that 6 E (Ar.Z(map r) + 
XT). Next, parametrize this term over an initial pair r., abstracting over all the variables Vj appearing 
in the pair. By then parameterizing the Vj with (huge) first-order types pj, we simulate the uni­ fication 
process of ML, matching IDO with a suitable parameterization z. We then have: M F (Ad:* .Avl:+. 0. .Avg+Pt: 
*. C[map]6[~o]) [WIIPII  [P,+PJ (~Do[d) The type of M codes the state of the TM after @(n+ 2) state 
transitions; we extract the accepting state A (known by assumption to be coded true), and type the term 
(Az.zz)(A(Ac. z)(Ay.yy)) (details to be given in the full paper). We then have our nonelement ary bound: 
TIleorem 5.7 Recognizing the lambda terms of length n typable in FW is DTIME[@(n~)]-hard for any integer 
k >1 under logspace reduction, where m(o) = 1, @(t+ 1) = 2@(t). Corollary 5.8 Recognizing the lambda 
terms of length n typable in Fk is DTIME[!k_4(n)] -hard under /ogspace reduction, where ~o(n) = n, ~~+~(n) 
= 2~k(n). We remark only that the -4 reflects the kind overhead of building pairs.  6 Discussion; Open 
problems We have provided the first lower bounds on type in­ference for the Girard/Reynolds system Fz 
and the extensions F3, F4, . . . . Fw. The lower bounds involve generic simulation of Turing Machines, 
where computa­tion is simulated at the expression and type level simul­taneously. Non-accepting computations 
are mapped to non-normalizing reduction sequences, and hence non-typable terms. The accepting computations 
are mapped to t ypable terms, where higher-order types en­code the reduction sequences, and first-order 
types en­code the entire computation as a circuit, based on a uni­fication simulation of Boolean logic. 
Our lower bounds employ combinatorial techniques which we hope will be useful in the ultimate resolution 
of the F2 type inference problem, particularly the idea of composing polymor­phic functions with different 
domains and ranges. Even if our bounds are weak (if the F2 problem is undecidable, they certainly are!), 
the analysis puts for­ward a certain program; it remains to be seen how far that program can be pushed. 
While the higher-order systems are of genuine interest, it is F2 which occu­pies center stage: in particular, 
we would like to know if the techniques of the higher-order lower bounds can be lowered to F2, somehow 
using the F2 ranks to simulate the expressiveness we have obtained from the kinds in F3, F4, . . . . 
FW. The computational power of the kinds includes not merely higher-order quantifica­tion, but more importantly 
,f-reduction at the type level. Generic simulation is a natural setting for lower bounds, particularly 
when the complexity classes are superexponential, and there are no <known difficult problems on which 
to base reductions. It seems equally natural that the type information added to an (un­typed) term is 
of a length proportional to the time com­plexity of the TM being simulated. Furthermore, the program 
of generic simulation generalizes nicely, as ex­pressed in the slogan, how fast can the crank (of the 
transition function) be turned? : better lower bounds can be proven by analyzing different cranks. We 
ob­serve in particular that the typing outlined in Section 5 was discovered by studying the reduction 
sequence of the untyped term C to normal form, and constructing the type as an encoding of that sequence. 
This analysis suggests an examination of F2 types, particularly in the light of the strong normalization 
theorem, as encodings of reduction sequences. We should observe as well the pitfalls of the method, or 
at least the hurdles which wait to be surmounted. The cranks described are all strongly normalizing in 
a manner such that we will never get an undecidability result. As long as we pursue bounds for F2 based 
on expressiveness of the type language, we are constrained by the strong normalization theorem, and the 
repre­ sentation theorem (that the representable integer func­ tions are those provably total in second 
order Peano Arithmetic) [Gir72, GLT89]. We have some idea how to get around the first hurdle, but are 
done in by the second. Does it seem possible that the representation theorem would allow reduction sequences 
of function­ ally unbounded length on typable terms? We conclude with a final caveat lector. The lower 
bound we have proven for Fti is unlikely to be improved further by naively trying a better (crank, unless 
the foundation of the simulation is changed substantially. The explanation of this limitation is that 
the type lan­guage of FW is fundamentally the first-order typed A­calculus with a single type constant 
(*). The dualit y approach forces reductions at the expression level to match those at the type level, 
and a result of Schwicten­berg [Sch82] indicates that our construction is using the type language at 
its maximum capacity. Encouraged and excited as we are to have made progress on these open questions 
in programming language theory, the hard work may have only just begun. Acknowledgements. The results 
of Section 3 were reported earlier in [Hen90]. For their encouragement, suggestions and criticisms, we 
thank Paris Kanellakis, Georg Kreisel, Daniel Leivant, Angus Macintyre, Jon Riecke, and Rick Statman. 
The second author wishes to acknowledge the generosity of the Computer Science Department at UC Santa 
Barbara, the Music Academy of the West, and the Cate School of Carpenteria, for their hospitality during 
his visit to Santa Barbara in the summer of 1990.  References [Car89] L. Cardelli. Typeful programming. 
Lec­ture Notes for the IFIP Advanced Seminar on Formal Methods in Programming Lan­guage Semantics, RIO 
de Janeiro, Brazil, 1989. See also SRC Report 45, Digital Equipment Corporation. [Dam85] L. Damas. Type 
assignment in program­ming languages. Ph. D. dissertation, CST­33-85, Computer Science Department, Ed­inburgh 
University, 1985. [DM82] L. Damas and R. Milner. Principal type schemes for functional programs. In 9­th 
ACM Symposium on Principles of Programming Languages, pp. 207-212, January 1982. [DKM84] C. Dwork, P. 
Kanellakis, aild J. C. Mitchell. On the sequential nature of unifi­cation. Journal of Logic Programming 
1:35-50, 1984. [Edi88] Edinburgh University. Postgraduate Ex­amination Questions in Computation The­ory, 
1978 1988. Laboratory for Founda­tions of Computer Science, Report ECS­LFCS-88-64. [GR88] P. Giannini 
and S. Ronchi Della Rocca. Characterization of typings in polymor­phic type discipline. In Proceedings 
of the 3-rd IEEE Symposium on Logic in Computer Science, pp. 61 70, July 1988. [Gir72] [GLT89] [HMT90] 
[HS65] [Hen90] [Hin69] [HU79] [HW88] [KM89] [KMM90] [KTU90] J.-Y. Girard. Interpretation Fonc-on Trees 
in Algebra and Program­tionelle et Elimination des Coupures de ming, May 1990. (See also Boston Uni­l 
Arithmetique d Ordre Superieur. Thkse versity Technical Report, October 1989). de Doctorat d Et at, University 
de Paris [KT89] A. J. Kfoury and J. Tiuryn. Type recon-VII, 1972. struction in jinite rank fragments 
of the J.-Y. Girard, Y. Lafont, and P. Taylor. second-order lambda calculus. Technical Proofs and Types. 
Cambridge Univer-Report BUCS 89-011, Boston University, sity Press, 1989. October 1989. Also in Proceedings 
of the 5-th IEEE Symposium on Logic R. Harper, R. Milner, M. Tofte. The Def­ in Computer Science, pp. 
2 11, June inition of Standard ML. MIT Press, 1990. 1990. [Lan66] P. Landin. The next 700 programming 
lan- J. Hartmanis and R. E. Stearns. On the guages. Communications of the ACM computational complexity 
of algorithms. 9(3): 157-166. Transactions of the American Math­ematical Society 117, pp. 285 306. [Mai90] 
H. G, Mairson. Deciding ML typability is complete for deterministic exponential F. Henglein. A lower 
bound for full poly­ time. In Proceedings of the 17-th morphic type inference: Girard/ Reynolds ACM 
Symposium on the Principles typability is DEXPTIME-hard. University of Programming Languages, pp. 382 
of Utrecht, Technical Report RUU-CS-90­ 401, January 1990. 14, April 1990. [Mi178] R. Milner. A theory 
of type polymorphism R. Hindley. The principal type scheme of in programming. Journal of Computer an 
object in combinatory logic. Transac-and System Sciences 17, pp. 348 375, tions of the American Mathematical 
1978. Society 146:29-60, 1969. [Mit90] J. C. Mitchell. Type systems for program- J. E. Hopcroft and J. 
D. Unman. Intro-ming languages. To appear as a chapter duction to Automata Theory, Lan­ in the Handbook 
of Theoretical Com­guages, and Computation. Addison put er Science, van Leeuwen et al., eds. Wesley, 
1979. North-Holland, 1990. P. Hudak and P. L. Wadler, editors. Re-[PW78] M. S. Paterson and M. N. Wegman. 
Linear port on the functional programming lan-unification. Journal of Computer and guage Haske//. Yale 
University Technical System Sciences 16, pp. 158-167, 1978. Report YALEU/DCS/RR656, 1988. [PDM89] B. 
Pierce, S. Dietzen, and S. Michaylov. P, C. Kanellakis and J. C. Mitchell. Programming in higher-order 
typed lambda Polymorphic unification and ML typing. calculi. Technical Report CMU-CS-89- Brown University 
Technical Report CS-111, Carnegie Mellon University, March 89-40, August 1989. Also in Proceed-1989. 
ings of the 16-th ACM Symposium [PL89] F. Pfenning and P. Lee. LEAP: a lan­ on the Principles of Programming 
guage with eval and polymorphism. TAP- Languages, pp. 105-115, January 1989. SOFT 1989: Proceedings of 
the In- P. C. Kanellakis, H. G. Mairson, and J. ternational Joint Conference on The- C. Mitchell. Unification 
and ML type re-ory and Practice in Software Devel­construction. In Computational Logic: opment, Barcelona, 
Spain. See also CMU Essays in Honor of Alan Robinson, Ergo Report 88-065. ed. J.-L. Lassez and G. Plotkin. 
MIT [Rey74] J. C. Reynolds. Towards a theory of typePress, 1990. structure. In Proceedings of the Paris 
 A. J. Kfoury, J. Tiuryn, and P. Urzyczyn. Colloquium on Programming, Lecture ML typability is DEXPTIME-complete. 
Notes in Computer Science 19, Springer Proceedings of the 15-th Colloquium Verlag, pp. 408-425, 1974. 
[Rob65] J. A. Robinson, A machine oriented logic based on the resolution principle. Journal of the ACM 
12(1):23 41, 1965. [Sch82] H. Schwictenberg. ization in the lus. The L. C omp!ezit y of norms!­pure typed 
lambda calcu-E. J. Brouwer Cente­ nary Symposium, D. van Daalen (eds.), Holland, 1982. A. S. Troelstra 
and pp. 453-457. North­ [SC077] D. Scott. Logic and guages. Communications 20(9):634-641, 1977. programming 
of the lan-ACM [Str73] C. Strachey. The varieties of programming language. Technical Monograph PRG­10, 
Programming Research Group, Oxford University, 1973. [Tur85] D. A. Turner. Miranda: A non-strict func­tional 
language with polymorphic types. In IFIP International Conference on Functional Programming and Com­puter 
Architecture, Nancy, Lecture Notes in Computer Science 201, pp. 1-16, Springer-Verlag, 1985. [Wan87] 
M. Wand. A simple algorithm for type inference. Fundament maticae 10 (1987). and proof a Infor­  
			