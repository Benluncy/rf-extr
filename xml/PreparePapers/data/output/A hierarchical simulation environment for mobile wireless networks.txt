
 A HIERARCHICAL SIMULATION ENVIRONMENT FOR MOBILE WIRELESS NETWORKS R. Bagrodia M. Gerla L. Kleinrock 
J. Short T.-C. Tsai Computer Science Department University of California at Los Angeles Los Angeles, 
CA 90095 ABSTRACT A hierarchical simulator has been designed for multi­media communication protocols 
in a wireless mobile environment. The hierarchical approach integrates performance evaluation of protocols 
with their imple­ment ation. The approach supports scalability studies of the protocols in an efficient 
manner using coarse grain models that abstract implementation details of the protocol and its execution 
environment by a few key parameters. Fine grain, low-level models that capture implementation details 
are used for detailed evaluation of small networks and for automatic im­plementation on radio platforms. 
The design, eval­uation, and implementation cycle is closed by feed­ing the measurements from the implementation 
back into the model to improve its accuracy. The paper describes the use of the environment in the evalua­tion 
and implementation of a cluster-based multihop protocol for multimedia traffic. INTRODUCTION The exploding 
demand for nomadic computing and communication has led to a significant need for in­frastructure to support 
the mobile user. Applica­tions that could greatly benefit from such support include disaster relief operations, 
next generation of PCS (personal communication systems) services, and tactical mobile units in the military. 
A relatively high quality of support for integrated voice, video and data traffic is becoming available 
over a wireline net­work; however integrated support for these services over a wireless network is still 
in its infancy. The need for such an infrastructure underlies the goals of the UCLA WAMIS project. A 
central component of this project is to develop wireless multimedia instant infrastructure that is capable 
of establishing instant network infrastructure, of maintaining communica­tion, perhaps via topological 
reconfiguration, in the presence of node mobility and failures. As is well known, such protocols are 
complex to design, evaluate and implement. Their performance depends on a combination of factors that 
include multimedia traffic patterns, mobility models, appli­cation objectives (e.g., maximize throughput, 
mini­mize noise/loss), processor characteristics (cpu speed, load), and radio characteristics (bandwidth, 
power). Before investing significant resources in their imple­mentation, it is generally desirable to 
model the pro­tocols such that their expected behavior can be evalu­ated in the projected operational 
environment. Eval­uation of the protocol as a function of these diverse parameters using only analytical 
models is hard; a detailed performance study is often impossible due to analytical intractability. An 
alternative to per­formance prediction is to build and deploy protocol implementations and then test 
them in actual oper­ation. However, this approach may preclude tests of the protocols over a wide parameter 
space. This paper describes an environment to support rapid protot yping of mobile, multimedia protocols, 
a comprehensive evaluation of their performance over a large parameter space and over large numbers of 
mobile units, and eventual implementation into oper­ational network systems. The next section describes 
the networking and node architectures of the physical system that is being simulated. Section 3 describes 
the modeling environment; Section 4 describes its use to evaluate and implement a cluster-based instant 
in­frastructure. Section 5 discusses related work and Section 6 is the conclusion. 2 PHYSICAL SYSTEM 
ARCHITECTURE The design of the multimedia instant infrastructure relies on innovations in the internetworking 
and sub­networking layers as well as in the interfaces linking the network to the operating system and 
to the ra­dio. A network operating system for mobile multi­ 563 Bagrodia media nodes is being designed 
at UCLA as an en­hancement to the public-domain KA9Q NOS kernel by Phil Karn. In order to provide a flexible 
environ­ment for experimentation with multiple radios, mod­ules that implement various network control 
functions are written in C and supported by the operating sys­tem to isolate the architecture and implementation 
details from the network algorithms. The network control functions comprise numerous software compo­nents 
which can be used to support self-configuring, multihop, multimedia networking. These components can 
be broken down into end-to-end transport con­trol, internetworking_ and connectivity control, sub­network 
control, and finally link and mobility con­trol. An environment to model each of these compo­nents has 
been designed (Short, et al. 1995) and is described briefly in the next section. Many of the pre­ceding 
components are needed for the cluster-based communication protocols that are used in the instant infra.st 
ructure. In the packet radio network, each node contains an identical transceiver which can either transmit 
or re­ceive at any one time. In the spread spectrum code division environment, the receiver should be 
set to the same code as the designated transmitter before or at the time it transmits. In order to increase 
the control efficiency and to reduce power interfer­ence from neighboring nodes (even hidden nodes), 
we have adopted a clustering architectures (Baker, et al. 1984). The idea is to group some neighboring 
nodes together into a c/uster. Each cluster is coor­dinated by the clusterhead (CH) which can directly 
communicate with all the member nodes in the clus­ter. The role of CH serves as a regional broadcast 
node, and as a local coordinator to enhance channel throughput. Following the clustering approach, we 
can easily en­force time-division (and even code division) schedul­ing within the cluster, and can facilitate 
spatial reuse of time slots and codes across clusters. The store-and­forward multi-hop sessions across 
different clusters will be carried through by gateways (G W), which are nodes that can directly communicate 
with 2 or more CHS. The proposed clustering architecture can be viewed as a hybrid between traditional 
packet radio and cellular networks. The clusterhead approach and the support of guaranteed bandwidth 
connections re­minds us of cellular networks. The datagram traffic support, the multihopping and the 
dynamic recon­figurability follow the tradition of earlier packet ra­dio projects. A fast reservation 
virtual circuit (VC) scheme is developed for real time traffic in order to guarantee bandwidth. Datagram 
traffic uses the S-ALOHA scheme with CH acknowledgments. De­ et al. tails of the network protocols and 
the channel access scheme are described in the paper by Gerla and Tsai (1995). 3 SIMULATION ENVIRONMENT 
A general purpose parallel environment is being de­veloped at UCLA for the simulation and prototyp­ing 
of protocols for mobile computing. Our aim is to decompose the protocols and their execution environ­ment 
to allow maximum flexibility y in experimentation with alternative implementations of a given function­ality 
(e.g., radio characteristics) as well as to support a plug and play capability that generates composite 
prototypes constructed from pieces that model sys­tem components at widely differing levels of detail. 
The simulator is being built on an existing process­oriented, parallel simulation language called Maisie 
(Bagrodia and Liao 1994). This section describes the simulation environment and the methodology. 3.1 
Maisie Language A Maisie program is a collection of entity definitions and C functions. An entity definition 
(or an entity type) describes a class of objects. An entity instance, henceforth referred to simply as 
an entity, represents a specific object in the physical system and may be created and destroyed dynamically. 
Entities commu­nicate with each other using timestamped messages. Every entity is associated with a unique 
message­buffer. The language provides an asynchronous send primitive to deposit a message with a current 
or fu­ture timestamp in the message buffer of a destination entity. Blocking and non-blocking receive 
primitives are also provided by the language to allow an entity to remove messages from its message buffer. 
The re­ceive construct can be used to remove selective mes­sages from the buffer such that a message 
is removed only when it is ready to be processed by the destina­tion entity. Appropriate use of selective 
receives help in the generation of concise model descriptions. Event scheduling constructs in Maisie 
are inte­grated with the send and receive primitives. Thus transmission delays in a physical network 
can be mod­eled simply by incrementing the timestamp on the message when it is sent from the source to 
the des­tination node. A receive statement can optionally specify a timeout interval, where time is measured 
using the simulation clock; such a statement may be used to simulate the passage of time corresponding 
to activities like servicing of a job in a model, or trans­mission of a message in a network. A program 
written in Maisie is independent of Mobile Wireless Net works 565 The OSM simulates the relevant portion 
of the op­ erating system kernel that is involved in interfacing Applhbcil SOURCEM Trmqort } N.@+mk 
OSM hxk m }Data link g) W,*=  }m Figure 1: Networking Layers and their Models any synchronization 
algorithm. When it is compiled, the analyst can indicate the specific simulation algo­rithm that is to 
be used to synchronize execution of the model: sequential, parallel conservative, or par­allel optimistic. 
The compiler generates the appro­priate code to interface the model with the corre­sponding run-time 
system: a splay-tree based imple­mentation of the global event-list algorithm for the sequential implementation, 
a null-message or condi­tional event implementation of the parallel conser­vative synchronization algorithm 
(Jha and Bagrodia 1993), or a space-time implementation of the opti­mistic synchronization algorithm 
(Bagrodia, Chandy, and Liao 1991). Maisie has been implemented on a variety of sequential and parallel 
architectures and has been used to model diverse applications from par­allel software to VLSI designs. 
3.2 Integrated Simulation and Implement a­tion Environment An integrated environment for the simulation 
and im­plementation of network protocols has been built us­ing Maisie (Short, et al. 1995). Fig. 1 displays 
the relationship between the modeling components and the 0S1 reference model. The components have been 
enhanced in various ways to support wireless oper­ations and to integrate wireless and wireline opera­tions. 
The primary components of the environment Operating System Models (OSM) Application Traffic Models (SOURCEM) 
Network Algorithm Models (NAM) Wireless Radio Models (RFM) Channel Models (CHM) Mobility Models (MOM) 
with the application (e.g., delivery of incoming mes­sages) or with the network (e.g., transmission of 
a re­mote message). The SOURCEM components can be broken down into the source and destination streams 
(e.g.: hard disk, keyboard, camera, screen, micro­phone, or speaker) corresponding to the voice, video 
and data traffic, the control of these streams via the application, and the transport mechanism (e.g.: 
TCP, UDP, or Virtual Circuits) which the application chooses to use. The NAM components are broken down 
into inter­network models such as 1P, subnetwork control such as clustering, and mobility control such 
as power con­trol, logical link control, and media access control. The MOM components are responsible 
for movement patterns of the nodes such as the speed in which the nodes move and their motion pattern 
such as brow­nian random motion or drift. The CHM cc)mponents are responsible for the transmission media 
including the range in which two nodes are able to communi­cate with each other, and environment al eilects 
such as multi-path fading, shadowing, and interference. The RFM components are responsible for the physical 
layer modeling of the radio frequency modem and in­cludes the raw channel bandwidth, modulation tech­niques, 
and acquisition delays. In the remainder of this section, we describe the facilities for the simula­tion 
of clustering based wireless network architecture for instant infrastructure networking. The infrastructure 
exists at the subnetwork level in order to control the wireless multihop network trans­parently for applications 
and TCP/IP. As shown in Fig. 2, the clustering subnetwork control contains a synchronization module to 
either adapt to existing clusters, if available, or to create new clusters based upon the clusterhead 
election algorithm. The TDMA module is responsible for queueing up packets from the 1P level in order 
to provide guaranteed bandwidth delivery of data. The multihop routing algorithm based upon Bellman-Ford 
s minimum hop is done at the subnetwork level to provide the wireless multihop functionality. The lower 
layers are responsible for in­telligently setting parameters of the radio and adjust­ing to measurements 
such as SIR. The CDMA module is responsible for assigning one code per cluster. The LLC module is responsible 
for providing piggyback and explicit link level acknowledgment since CDMA is used between hops (between 
different clusters) so passive acknowledgment schemes can not be used. The distributed power control 
module:, which is based upon work by Chen, Bambos, and Pottie (1994), adjusts the transmit power based 
upon the Figure 2: Instant Infrastructure Algorithms Figure 3: Simulation Environment Control Panel 
SIR measured at receiving nodes to minimizes trane­mit power necessary and reduce CDMA interference and 
reduce the near-far effect. Vaiious radio param­eters such as bandwidth, acquisition time, and error 
rates were used. As seen in Fig. 3, the simulation environment is able to control various environmental 
and node parameters such as location, speed of mo­bility, and transmit power of radio. Based upon these 
parameters, the channel model determines and trana­mits packets between appropriate nodes. The simu­lation 
environment provides several unique abilities including the ability of each node to dejine its own virtual 
operating environment where parameters such as transmit power, code, and mobility ~attem_ can be set 
interactively while the simulation is running. To facilitate the transition of simulation models into 
implementations, the interfaces of the modeling environment components must be designed with care. et 
al. The OSM is responsible for process scheduling, com­munication, and synchronization as well as for 
inter­actions between the applications and the communica­tion device s packet driver. By isolating the 
interface among these modules, it is possible to interface the packet driver on the node with various 
network al­gorithms and operating systems like the KA9Q NOS kernel, the Mach kernel, and Windows. Given 
a com­patible design for these interfaces, it is possible to automatically and transparently migrate 
the detailed simulation models to operational implementations of network algorithms with different operating 
system kernels and communication devices. This is a poten­tially significant achievement as it would 
provide a direct path for the network model to evolve into op­erational software. The rapid prototyping 
ability of the environment was demonstrated by porting the synchronization, TDMA, and clusterhead election 
algorithmof the in­stant infrastructure models to a real system. The r­fined models used in the simulation 
study described in the next section were ported, without any redesign or programming, to a set of four 
486 laptops running WAMISNOS using two different radios: the UCLA Direct Sequence Spread Spectrum radio 
operating at 32Kbps (Jain, et al. 1995), and the Proxim Range-LAN2 Frequency Hop Spread Spectrum radio 
oper­ating at 1.6Mbps.  3.3 Hierarchical Modeling The integrated design, evaluation, and implement tion 
of the instant infrastructure protocols uses a multi-level modeling methodology where initial ab­stract 
or coarse models are refined into detailed jike models and eventually into protocol implementations. 
The coarse simulation model is used to develop and teat network algorithms in a large, multicluater net­work 
setting. Various routing policies and virtual circuit maintenance issues are investigated in the presence 
of node mobility. In order to o~tain run time efficiency and to support interactive protocol de sign, 
many implementation details of the protocol are omitted. At this level, the performance measures of intereat 
are the ones related to efficient support of the target multimedia applications, namely: delay (both 
average and variance), throughput, packet loss, out of sequence packet delivery, and net~work connectivity 
(both physical and logical). These performance mew surea depend not only on network algorithms, traflic 
pattern and physical network parameters, but are also impacted by the hardware and software characteris­tics 
of the mobile node which are typically omitted to keep the models simple and the run-times reasonable. 
 The refined simulation model captures the imple­mentation details of the protocol and its execution 
environment that are omitted in the coarser model. Characteristics of the execution environment that 
are modeled include many of the components from the NOS model described in the previous section including 
the node OS architecture and CPU load caused by the various applications from the OSM and SOURCEM models, 
and the impact of CPU load on TDM frame synchronization from the RFM and CHM models. Thus, the fine grain 
simulator must support an enriched set of performance measures, including CPU loading, synchronization 
timing, detailed radio modem behavior etc. This model is developed us­ing as inputs the measurements 
from the actual radio node prototype on which the protocols are being im­plemented. The presence of the 
detailed model characteristics allows the refined models to estimate performance measures not derivable 
in the coarse grain simul~ tor (e.g., TDM frame synchronization loss and conse­quent packet loss due 
to varying application loads). Once these parameters have been estimated in the fine-grain model, they 
are subsequently introduced w macroscopic parameters in the coarse grain simula­tor as illustrated in 
the experimental study reported in the next section. For example, link failure rate (due to synchronization 
loss) can be defined as coarse grain simulator input. Another function of the de­tailed simulator is 
to serve as an intermediate step to protocol software implementation in the radio plat­form. In fact, 
ss discussed in Section 3.2, the faithful reproduction of the WAMIS operating system envi­ronment in 
the simulator makes it possible to port and run the simulator on WAMISNOS with minimal alterations. The 
hierarchical approach is well suited to the in­teractive design and implementation of the network protocols. 
It permits us to carry out conceptual al­gorithm design on large network topologies in an effi­cient, 
interactive manner using the coarse grain simu­lator. In this high level design process, the implemen­tation 
details are hidden behind a few key parameters which were derived from the fine grain simulator. In turn, 
the high level network algorithms tested in the coarse simulator are implemented in the fine grain simulator 
to verify efficiency of operation in the radio node platform. Eventually, the fine grain simulator will 
serve as a conduit to software implementation on the radios. This design and evaluation cycle is closed 
by feeding back the measurement results to the simulation model to further improve its accuracy for predicting 
the performance of large-scale network models. 4 EXPERIMENTAL STUDY This section describes a performance 
study that used the multi-level modeling methodology described in the previous section. In the sequel, 
we show an ex­ample of the interplay between the coarse and refined models. More specifically, we show 
how experiments with the refined models can be used to evalnate link failure rate due to loss of TDM 
frame synchroniza­tion. The latter can be caused by three independent events: (a) CPU overload; (b) control 
packet loss due to channel propagation effects or interference; and (c) radio mobility. The coarse model 
can accept as input the link failure rate, but does nd include enough de­tail to compute, for example, 
the CPU loading caused by the applications, and its effect on link failure rate. We first describe the 
detailed experiments which were executed for a 4-node cluster to compute link failure rate due to each 
of the preceding factors. The first set of experiments studies the impact of CPU load on link failure 
rate. We recall that in the TDMA access control algorithm, when it is time for a node to transmit a packet, 
the TDMA process selects and transmits the next packet in the queue. V the CPU is heavily loaded, then 
the TDMA process will be de­layed before it can gain access to the CPU to transmit the packet. To compensate 
for this delay,, a guard time is added to the TDMA slot time. In order to study the effects of CPU loading 
for a given guard time, a model of the CPU scheduler is used, which simulates the effect of the CPU load 
on frame synch loss. When packets are delayed so that synchroniza­tion can no longer be maintained, then 
a link failure occurs. In Fig. 4, CPU load (assumed to be uniform lco 80 w 40 20 o 0 20 40 mlCO CPU &#38;d(me) 
Figure 4: Link Failure Rate vs. CPU Load for all nodes) is expressed in terms of job scheduling delay 
(in ins). The slot guard time is 20 ms, which was experimentally determined to be adequate for most applications. 
However, if the maximum CPU holding time by an application increases beyond 20 ms, the effect on the 
link failure rate can be quite dramatic (as shown in F,ig. 4). Based on these con­siderations, slot guard 
time should be set to the max­imum CPU holding time. However, this is not pos­sible in practice because 
a slot guard time increase contributes directly to channel overhead. A proper compromise must be found 
via simulation, using the approach here described. Another set of experiments relates channel packet 
loss to link failure rate. Fig. 5 shows the impact of a packet loss in a channel on the failure rate 
of the corresponding link. Every 300ms a node transmits I  I-___A o 0.1 0.2 GIA PktL%RateOs 0 7 Figure 
5: Link Failure Rate vs. Ch. Pkt Loss Rate a control packet used for synchronization and topol­ogy creation. 
This is done during each node control slot period. With 4 nodes synchronized, each node sends out its 
control information every 1.2 seconds. This control packet can be lost for several reasons in­cluding 
radio channel factors such as background in­terference, multipath fading or shadowing which fre­quently 
cause bit errors, and packet collision (interfer­ence from another radio). Based upon Fig. 5 results, 
we see that the logical topology synchronization is fairly stable for packet loss rates up to 50%. Exper­iment 
al results reported in Jain, et al. (1995), show that packet loss rates as high as 16% have been ob­served, 
with corresponding logical link failure around 1.2%. Note, however, that even though the logical topology 
is accurate 98.8% of the time, 16% of the data packet transmission still fail. A final set of fine grain 
experiments studies the im­pact of mobility and transmission range on link fail­ures. In Fig. 6 we can 
examine the effects of various radio ranges (power levels) and node speeds on link failure rate. As the 
transmission range is increased, the link failure rate decreases. Conversely, as speed increases, failure 
rate increases. Next, we show how frame synch loss due to CPU overload, control packet loss and mobility 
can be in­directly accounted for in the coarse grain simulator using link failure rate as input parameter. 
The coarse grain experiments were based on 20 Figure 6: Link Failure Rate vs. Mobility nodes (radios) 
placed randomly inside a 100x100 square. During the simulation, in every time frame, a node may randomly 
move X units in each direc­tion or stay where it is. If a node tries to move be­yond the boundary, its 
position is set at the bound­ary ( sticky boundary model). Two nodes can com­municate directly with each 
other if they are within hearing range, which can be modified by adjusting the power level. The following 
parameters were used in this study: CPU load = 23 ms, mobility(X) = 5 units/frame, control packet loss 
rate = 1670, transmission range varying between 20 and 30 units (note that to make 4 node and 20 node 
experiments consistent the range must be scaled down by a factor ~ when moving from 4 to 20 nodes, since 
in both cases the nodes are distributed over a 100x100 area, and yet must have the same average number 
of neighbors). From the 4 node results presented in Figs. 4 through 6 we de­rive the equivalent link 
failure rate for the 20 node experiment corresponding to the above input param­eters. For example, for 
a transmission range = 18 units the link failure rate (due to the cumulative con­tribution of CPU load, 
packet loss, mobility) results to be 21 .2Y0. We then input this link failure value in the coarse grain 
simulator to compute the logical connectivity in the 20 node network. Connectivity for the network is 
computed as the average connec­tivity of each node, where the connectivity of a node is defined as the 
fraction of nodes that it can reach via single or multiple hops. We distinguish between logical and physical 
connectivity. In the presence of synchronization loss, a link may physically be up but will logically 
be considered to be down as it cannot be used to transmit data packets. In other words, logical connectivity 
is defined as the fraction of node pairs communicating with each other, accounting for the link failure 
rate due to frame synch loss. The consistency of the large, coarse grain models and small, fine grain 
models can be systematically Mobile Wireless 1, 0.8 , he grh mcdd . caarn gfdn modd --­ 0.6 a4 a2 n. 
0204060 m 120 140 F&#38;? Figure 7: Connectivity vs. Range (4 nodes) 1 0.2 no nl-41mule ti211idlh&#38;.u* 
- a 0.8 a4I 0.2 / . !0152025 254045s0 P.%. Figure 8: Connectivity vs. Range (20 nodes) verified by 
running the coarse model for a small net­work configuration. Fig. 7 shows logical connectivity versus 
transmission range in a four node, mobile net­work configuration. The experiment was carried out with 
both fine and coarse simulator. There is good agreement between the two sets of results, thus veri­fying 
the consistency of the assumption. Fig. 8 compares physical connectivity (i.e., without accounting for 
link failures) and logical connectivity (with link failures) for the above mentioned 20 node experiment 
using the coarse simulator, We note that the impact of link failure (i.e., synch loss) on con­nectivity 
is quite substantial, especially in the criti­cal region between 20 and 40. This impact could be captured 
only through proper interaction of fine and coarse grain simulation. 5 RELATED WORK A number of commercial 
tools are available for anal­ysis and evaluation of network protocols including BoNeS, COMNET (CACI), 
and OPNET (Mi13). All existing tools, use sequential model execution and none provide a path towards 
eventual protocol imple­mental ion. We specifically examine the limitations of OPNET for prototyping 
mobile protocols. Most other systems suffer from similar drawbacks. Net works 569 OPNET has a number 
of drawbacks that make it unsuitable for mobile wireless: limited support for node mobility patterns 
(for instance specifying ran­dom node movements), restrictive channel models, rigid modeling methodology 
which forces the user to specify the models at a much greater level of detail than may be appropriate 
or feasible for the analyst (the three level methodology must be followed), and long execution times 
for even moderate sized models. The last and significant problem is that there is no path towards implementation. 
Although many university projects are aimed at simulation and analysis of networking protocols, rela­tively 
few addreas integrated network simulation and prototyping (Abbott and Peterson 1992; Montz, et al. 1994). 
For instance, the approach used in the x-kernel and Scout projects at the University of Ari­zona is to 
develop an operating system which can support the implementation of networking protocols (possibly automatically). 
A simulation environment wss developed specially for the x-kernel (Hutchinson and Peterson 1991) which 
successfully analyzed the performance of the new protocol based upon various simulation model parameters. 
6 CONCLUSION AND FUTURE WORK An environment for hierarchical modeling of multi­media protocols in a wireless 
mobile environment has been developed at UCLA. This environment supports the iterative transition of 
simulation models into pro­tocol implementations on operational radio platforms using a multi-level approach. 
The environment has been designed using the Maisie simulation language. Although Maisie models can be 
executed on various parallel architectures, the study reported in this pa­per only used the sequential 
executions. Parallel im­plementations of the model are currently under in­vestigation. Our eventual goal 
is to support an inte­grated modeling environment, where detailed models of a sub-network are executed 
in parallel with the ab­stract models, to interactively evaluate protocol per­formance for large networks 
over a wide parameter space. ACKNOWLEDGMENTS This research was supported by the U. S. Dept. of Justice/FBI, 
ARPA/CSTO under contract J-FBI-93­ 112, and by the Advanced Research Projects Agency, ARPA/CSTO, under 
Contract DABT-63-94-C-0080 Transparent Virtual Mobile Environment . REFERENCES Abbott, M. and L. Peterson. 
1992. A language­based approach to protocol implementation. Tech­nical Report No. 92-2, Department of 
Computer Science, University of Arizona. Bagrodia, R., K. M. Chandy, and W-T. Liao. 1991. A unifying 
framework for distributed simulations. ACM Tkans. on Modeling and Computer Simula­ tion 1(4):348-385. 
Bagrodia, R. and W-T. Liao. 1994. Maisie: A lan­ guage for design of efficient discrete-event simula­ 
 tions. IEEE Transactions on Sofiware Engineering 20(4):225-238. Baker, D. J., A. Ephremides, and J. 
A. Flynn. 1984. The design and simulation of a mobile radio net­work with distributed control. IEEE JSA 
C SAC­2(1):226-237. Chen, S., N. Bambos, and G. Pottie. 1994. On dis­tributed power control for radio 
networks. In IEEE International Conference on Communication, New Orleans, LA, 1281-1285. Gerla, M. and 
J. Tsai. 1995. Multicluster mobile multimedia network. ACM -Beltzer Journal of Wireless Networks, August 
(To appear). Hutchinson, N. C. and L. L. Peterson. 1991. The x-Kernel: An architecture for implementing 
network protocols. IEEE Transactions on Soflware Engi­neering 17(1):6476. Jain, R., J. Short, S. Nazareth, 
L. Kleinrock, and J. Villasenor. 1995. PC-notebook based mobile networking: Algorithms, architectures, 
and imple­mentation. In Proceedings of the 1995 IEEE Inter­national Conference on Communications, Seattle, 
WA, 771-777. Jha, V. and R. Bagrodia. 1993. Transparent im­plementation of consei%ative algorithms in 
paral­lel simulation languages. In Proceedings of the 1999 Winter Simulation Conference, December, 677-686. 
Montz, A., D. Mosberger, S. W. O Malley, L. L. Pe­terson, T. A. Proebsting, and J. H. Hartman. 1994. 
Scout: A communications-oriented operating sys­tem. Technical Report No. 94-20, Department of Computer 
Science, University of Arizona. Short, J., R. Bagrodia, and L. Kleinrock. 1995. Mo­bile wireless network 
system simulation. In Pro­ceedings of the 1995 ACM International Confer­ence on Mobile Computing and 
Networking, Berke­ley, CA, November, 195-205 (To appear). AUTHOR BIOGRAPHIES RAJIVE L. BAGRODIA received 
the B. Tech. de­gree in Electrical Engineering from the Indian Insti­ tute of Technology, Bombay in 1981 
and the M.A. and Ph.D. degrees in Computer Science from the Uni­versity of Texas at Austin in 1983 and 
1987, respec­tively. He is currently an Associate Professor in the Computer Science Dept. at UCLA. His 
research in­terests include parallel languages, parallel simulation, distributed algorithms, and software 
design method­ologies. He was selected as a 1991 Presidential Young Investigator by NSF. MARIO GERLA 
was born in Milan, Italy. He received a graduate degree in engineering from the Politecnico di Milano, 
in 1966, and the M.S. and Ph.D. degrees in engineering from UCLA in 1970 and 1973, respectively. He joined 
the Faculty of the UCLA Computer Science Department in 1977. His research interests cover the performance 
evaluation, design and control of distributed computer commu­nication systems and high speed computer 
networks (ATM, Optical Networks and Wireless). LEONARD KLEINROCK received the B.S. de­gree in Electrical 
Engineering from the City College of New York in 1957 and the M. S.E.E. and Ph. D.E.E. degrees from the 
Massachusetts Institute of Technol­ogy in 1959 and 1963, respective y. He is currently a Professor in 
the Computer Science Department at UCLA. His research interests focus on performance evaluation and design 
of many kinds of networks (e.g., packet switching networks, packet radio networks, lo­cal area networks, 
metropolitan area networks broad­band and gigabit networks) and of parallel and dis­tributed systems. 
Dr. Kleinrock is a member of the National Academy of Engineering, a Guggenheim Fel­low, and an IEEE Fellow. 
JOEL E. SHORT received the B.S. degree in Com­puter Science from California State University, Chico in 
1992 and the M .S. degree in Computer Network Modeling and Analysis from University of California, Los 
Angeles in 1995. He is currently a Ph.D. candi­date in the Computer Science Department at UCLA studying 
wireless and nomadic system simulation and implementation. JACK TZU-CHIEH TSAI received his B.S. and 
M.S. degrees both in Electrical Engineering from the National Taiwan University in 1988, and from the 
University of Southern California in 1991, respec­tively. He is currently a Ph.D. candidate in Computer 
Science at UCLA. His research interests include net­ work protocol design and implementation for wire­less 
radio networks; performance evaluation for dis­tributed computer communication network systems.  
			