
 Augmented Reality Micromachines   Adrian Clark, Thammathip Piumsomboon, Mark Billinghurst The HIT 
Lab NZ, University of Canterbury, Christchurch, New Zealand INTRODUCTION As augmented reality (AR) applications 
become more common, users are expecting increasingly sophisticated experiences combining impressive visuals, 
interaction, and awareness of the environment. To establish a stronger connection between real and virtual 
content, virtual content should behave realistically in the physical environment it s placed in, with 
realistic physics, occlusion, collision detection, illumination and shadowing [1]. Monocular registration 
can calculate the pose of the camera, but has no awareness about the 3D environment. This can cause virtual 
content to float above or appear inside real objects, or occlude objects it should appear behind, breaking 
the illusion that the virtual content exists in the real environment This research explores how the Microsoft 
Kinect [3], a low cost device featuring a colour and infrared depth camera which allows the real time 
capture of 3D data, can be used to enable environmental awareness in augmented reality. The Kinect is 
used to examine a three dimensional volume within the task space, and with the transformation between 
the Kinect and the AR viewing camera known, virtual content can be realistically composited in the environment. 
SYSTEM DESIGN To create an interaction volume, the Kinect is positioned above the desired interaction 
space facing downwards, as shown in Figure 1. A reference marker is placed in the interaction space to 
calculate the transform between the Kinect co-ordinate system and the co-ordinate system used by the 
AR camera.  Figure 1. Interaction set up. The Kinect is suspended above the interaction volume, with 
the reference image marker below it. The user wears colored markers for interaction In the initialization 
phase, the transformation from the marker to the Kinect is calculated using natural feature based registration. 
This transformation is used to project the corners of the marker into the Kinect co-ordinate system and 
calculate the three dimensional position for each corner. Finally, the transformation between the corner 
positions in the Kinect co-ordinate system and the corner positions in the AR co-ordinate system is calculated 
and stored. With the transformation between the Kinect and the AR co-ordinate systems known, three dimensional 
data from the Kinect can be transformed into the AR co-ordinate system. EXAMPLE APPLICATION The AR Micromachines 
game uses a physics engine to create a representation of the real world for virtual cars to drive in 
based on 3D information provided by the Kinect. The user can create obstacle courses using real objects 
and realistically control the virtual car as if it were a real remote controlled car. With a 3D model 
of the real world, realistic occlusion and shadowing effects can be applied. Collision detection and 
physics between the cars and the environment is handled by the physics engine. Figure 2 shows, clockwise 
from top left, examples of the wireframe representation of the real world, shadows, occlusion and physics 
in the AR Micromachines application.  Figure 2. Clockwise from top left: Terrain mesh, Shadows, Occlusion, 
Physics. CONCLUSION This research shows that Microsoft Kinect can be used to capture three dimensional 
data about the environment in real time, which can be used to provide features such as realistic physics, 
collision detection, occlusion and shadowing. These features have been shown to establish stronger connections 
between virtual content and the real world in Augmented Reality [1]. REFERENCES [1] Sugano, N., Kato, 
H., Tachibana, K.; "The effects of shadow representation of virtual objects in augmented reality", Proceedings 
International Symposium On Mixed And Augmented Reality (ISMAR), pages: 76-83, 2003 [2] Leyvand, T., 
Meekhof, C., Wei, Y., Sun, J. and Guo, B.,"Kinect Identity: Technology and Experience," Computer, vol. 
44, pages 94-6, 2011.  
			