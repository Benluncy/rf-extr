
 Proceedings of the 1993 Winter Simulation Conference G. W. Evans, M. Mollaghasemi, E. C. Russell, W.E. 
Biles (eds.) ASYMPTOTIC AND FINITE-SAMPLE CORRELATIONS BETWEEN OBM ESTIMATORS Antonio C. Pedrosa Bruce 
W. Schmeiser School of Industrial Engineering Purdue University West Lafayette, IN 47907, U.S.A. ABSTRACT 
Linear combinations of estimators offer a variety of good computational and statistical properties. The 
values of the optimal linear-combination weights de­pend upon the estimators covariances. We inves­ tigate 
the asymptotic covariances and correlations between overlapping-batch-means estimators of the variance 
of the sample mean when applied to a com­mon sample from a stationary finite-order moving­ average data 
process. After reviewing the asymp­totic formulas, we report a Monte Carlo study that suggests that the 
asymptotic correlation formula pro­vides a good approximation to the true finite-sample correlation if 
(1) the sample size n is at least sev­eral multiples of -yO and (2) the both batch sizes are between 
70 and n/2, where 70 is the sum of all auto­correlation. INTRODUCTION Engineers are faced with real-world 
stochastic sys­tems that are frequently too complex to allow an an­alytical evaluation. Often, in such 
cases, a computer simulation model must be developed and Monte Carlo techniques used to study these systems. 
Stochastic simulation experiments create statistical point esti­mators to infer the value of system performance 
mea­sures. Because of this inferential nature of Monte Carlo techniques, it is necessary to indicate 
how likely these statistics are to be wrong and by how much. Usually the uncertainty is measured in terms 
of esti­mator variance. We refer to the the process of esti­mating the variance of the point estimator 
as output analysis. Classical issues in output analysis of a simulation study include (1) how to obtain 
good estimates of some measure of performance, (2) how to evaluate the quality of these estimates, and 
(3) how to deter­mine the goodness of the quality measure. Often in simulation the measure of performance 
is a popula­tion mean, the point estimator is the sample mean, and the goodness of the point estimator 
is measured by its standard error. Several procedures for estimating the standard error from stationary 
autocorrelated data have been proposed: For example, direct (DI) [Han­nan, 1957, and Moran, 1975], spectral 
(SP) [Brat­ley, Fox and Schrage, 1987; Heidelberger and Welch, 1981], non-overlapping-batch-means (NBM) 
[Schmeiser, 1982], overlapping-batch-means (OBM) [hleketon and Schmeiser, 1984], standardized-time­series-area 
(STS .A) [Schruben, 1983] and orthonor­mally weighted (STS.W) [Foley and Goldsrnan, 1988]. No type of 
estimator dominates the others in terms of computational and statistical properties across all types 
of time-series data. Our main objective is to develop robust and com­putationally efficient methodology 
to estimate the variance of the sample mean. Previous studies [Poli­tis and Romano, 1992, Song and Schmeiser, 
1988b] suggest that linear combinations of estimators of the variance of the sample mean lead to better 
estimators; i.e., with smaller mean squared error (rose) than the component estimators. We consider the 
;problem of determining the minimal mse optimal linear combina­tion weights of OBM estimators. We stud,y 
OBM es­timators since they are conceptually simple methods, they are easy to compute, and they can be 
written as quadratic forms, which leads to tractable analysis. The key to using linear combinations, 
as discussed in Section 2.3, is to derive the asymptc)tic covari­ante/correlation between OBM estimators. 
In Sec­tion 3 we present our asymptotic results and in Sec­tion 4 we show empirically that the asymptotic 
corre­lation formula provides a good approxima.tion to the finite-sample correlation, except when the 
batch size is quite small or larger than half the sample size. Here small is with respect to the sum 
of autocc~rrelations. 481 482 Pedrosa and 2 BACKGROUND Bratley, Foxand Schrage [1987] and other simulation 
textbooks discuss output analysis. Here we summa­ rize background information about the variance of the 
sample mean, batch means estimators, and optimal linear combinations. 2.1 The Variance of the Sample 
Mean For stationary time series {Xi} a natural unbiased estimator of the population mean px is the sample 
mean (1) where n is the number of observations. The variance of any sample mean is (2) i=l j=l var(X) 
= --+ ~ Y COV(Xl, Xj). For stationary time series, cov(Xi, Xi+~) = R(h) is a constant, yielding var(X) 
= % 5 (1 -:) P(~), (3) h= . where R(O) = var(X) and p(h) = corr(Xi, Xi+~). Define w 7 0 = ~ p(h). (4) 
h. m If -yO< m then Jirg nvar(X) = y~ R(O), (5) as shown in, for example, Anderson [1971, p. 460]. For 
independent and identically distributed (iid) data, yO = 1. More generally, Equation 5 implies that y. 
can be thought of as the number of contiguous observations that carry the same information as one independent 
observation. The rate of convergence in Equation 5 depends on m ? 1 = ~ 1~1P(h)= 2-5 P(h), (6) h.. h=l 
cm the weighted sum of the correlations. In particular, Schmeiser and Song [1989] show that if ~1 < cm 
then Schmeiser 2.2 The Batch-Means Methodology and the OBM Estimator of var(~) The batch-means methodology 
is based on dividing the n observations Xl, Xz, . . . . Xn into b batches of size m. Thus batch 1 consists 
of observations Xl, . . . . Xm and batch i consists of observations XJ(i_l)+l, . . . . Xl(i_l)+m where 
1 is the lag between the first ob­servations of two consecutive batches. For 1 = 1 there is full overlap 
and the estimator is called overlapping­batch-means (OBhI) [Meketon and Schmeiser, 1984] and for 1 = 
m there is no overlap and the es­timator is the non-overlapping-batch-means (NBM) [Schmeiser, 1982]. 
The main concept underlying the NBNI methodology is to transform correlated data into fewer batch means 
that are normally distributed and uncorrelated. OBM also batches observations but the batches contain 
common observations and are therefore correlated. The OBM estimator of var(X) is asymptotically ecluivalent 
to the Bartlett spectral es­timator, and therefore it has only 2/3 the asymptotic variance of NBhl s 
[Meketon and Schmeiser, 1984]. The overlapping-batch-means (OBM) estimator of var(~~) is defined as (8) 
where b= n m+ 1,d= (n m+ l)(n m)/m, l<m~n-l, and x, = : -~m xl. j=, This estimator is unbiased for iid 
data for any sample size n and any batch size m, but it is biased in general. For normal iid data and 
fixed batch size m the fol­lowing equation holds: ~~~ n3var(V) = w(2m+:) ) [Song and Schmeiser, 1988a]. 
This limit can be com­pared to the analogous expression 2mR(0)2 for the NBM estimator, to conclude that 
the asymptotic ra­tio is two-thirds. The OBM is a cluadratic-form estimator since it can be written as 
F = ~~qijxzx~ (lo) %J for constant coefficients q,], or equivalently ylR(o) + ~ 1 nvar(X) = -fo R(O) 
 . (7) () n n P = Xtgx, (11) where Q is a constant symmetric matrix, Q = [qij]~j=~ and ~ is the vector 
of observations. A= ex­tensive study of the quadratic-form class is presented in Song and Schmeiser [1993]. 
The quadratic-form coefficients of the OBM esti­mator of var(X) are 1 Uij U;i + Ujj n rn+l (12)  ij=i 
[mz 1 mn+nz where aij, the number of batches that includes both Xi and Xj, is defined by (lij = min[n 
m+l,max(O,rn-lj-ii), min(i, j), n max(i, j) + 1] . (13) the first term, n m + 1, is the number of batches; 
the second reflects the batch size m and lag of cross product; the third and fourth terms are end effects 
[Song and Schmeiser, 1993]. 2.3 Linear-Combination Estimators of var(.~ ) There are several examples 
in the literature of us­ing linear combinations of estimators to obtain a bet­ter estimator in terms 
of statistical properties: small variance, bias or mean squared error. The OBM esti­mator can be viewed 
as a linear combination of NBM estimators [Meketon and Schmeiser, 1984]. Schruben [1983] considered a 
linear combination of the STS.A and the NBM estimators, which are asymptotically independent. Politis 
and Romano [1992] propose a linear combination of two Bartlett estimators of the spectral density with 
different bandwidths for the re­duction of the bias. The linear combination of 0Bi14 s is P ;Lc = CYiV, 
, (14) x inl where p is the number of ~omponents, the a, s are the L.C. coefficients and the ~ s are 
the 0Bh4 component estimators applied to the same data but each with a different batch size m,. By definition, 
the bias of ~~C is bias ~Le = E (~LC) -var(~) () Since the linear-combination variance depends upon the 
various estimator covariances, any method to se­lect optimal linear-combination parameters must con­sider 
the estimator covariances. In Section 3 we state the asymptotic covariances, which in Section 4 we see 
empirically provide a good approximation to the finite-sample covariances. In the rest of this section, 
we review how these covariances can be used to select the optimal linear-combination weights. Song and 
Schmeiser [1988b] address the problem of selecting the component estimators and determining the optimal 
linear combination coefficients given the covariances between component estimators and their individual 
biases. They consider two problems: (Pi) the weights sum to one, and (P2) no constraint on the weights. 
Let 1. ~ be the vector of estimators; 2. ~ be the p x p matrix whose (i,j)~h element is A,j = bias(i) 
x bias(~); 3. ~ be the p x p dispersion matrix, Xij = Cov(fi, Q); 4. ~ be the risk matrix, i.e., 
 ~ = 131 L+ P2z, where ~1 and /32 are positive constants that re­flect the relative weight that we want 
to give to the bias and the variance; 5. Q be the vector of the coefficients of the lin­ear combinations 
and ~ the vector of optimal weights. Let g ~ g = ~1 biasz(~ z) + ~z var(!g~~). The optimal q for (PI) 
hlinimize Qt ~ Q St. ~~~= 1, is ~.= A-l 1 (17) It A-l l; and for (P2) i14inimize Qt ~ Q g = plvar(~) 
[Pl E(~)E(~)t +/@ 1 E(t).  (-l+z?i)var(x) 15) is (18) and the variance is Their work also includes 
a numerical study, based on AR(1) data, of effect on the mse of combining two estimators of the same 
or different types. The results 484 Pedrosa and suggest that the use of linear combinations can lead 
to substantial improvements. The Q* formulas (Equations 17 and 18) show, again, that the optimal linear-combination 
estimator depends on the covariance/correlation coefficients be­tween the component estimators of the 
variance of the sample mean. 3 ASYMPTOTIC COVARIANCE/COR-RELATION FORMULAS In this section we present 
the asymptotic covariance and correlation between two OBM estimators of the variance of the sample mean 
with batch sizes ml and rnz from n observations. The derivation and addi­tional details are in Pedrosa 
and Schmeiser [1993 b]. Suppose that the observations {Xt} are from a sta­tionary time series and these 
data can be expressed using a moving-average model of order q, i.e., X~ = 60&#38;i + bl&#38;i 1 + . . 
. + b~&#38;,.-q, (19) where b., . . . . bg are constants and {&#38;i} is a sequence of iid random variables 
with finite variance UC2, fourth cumulant 1fC,4 and mean ,uC. The asymptotic results are derived using 
the OBM quadratic forms. The end-effects cannot be ignored unless we assume conditions Cl : as n ~ cm, 
ml ~ cm and rn2 ~ co while simultaneously rnl/n ~ O and ml/m2 * c, where c is a non-negative constant. 
Notice that the limits of Equations 21 and 22 exist only if ml/mz ~ c. Assume, without loss of generality, 
that m2 ~ ml. Then 4 ~ 702 R(0)2, (20)  1~~ 2 ) {:~02R(0)2[1++(m2:271} and 9 {Corr= (=)} l&#38;~{(# 
[1+: (mz;,ml)]}, (22) where fi and ~ are two OBM estimators of var(~) with batch sizes ml and m2, -yO 
is the sum of correla­tions, and R(O) is the data variance. A similar result Schmeiser for the variance 
(Equation 9) was obtained by Song and Schmeiser [1988a]. The asymptotic variance of the OBM estimator 
is proportional to the square of the sum of the correla­ tions ~o, and the population variance R(O). 
It 1s also directly proportional to the the batch size and in­ versely proportional to n3. Using Equation 
5, Equa­ tion 20 can be rewritten as This result shows that, for a large fixed value of n, the variance 
of the OBM estimator is directly pro­ portional to ml and the square of the variance of the sample mean. 
The covariance and correlation results depend upon a simple function of the relative distance between 
the batch sizes. The asymptotic covariance between two OBM es­ timators of var(X) can be viewed as the 
product of the asymptotic variance~f the OBM estimator with smaller batch size, var(V1), by the correction 
factor g(ml, mz). Equation 21 can also be rewritten as (24) This indicates that given the data type the 
asymp­totic covariance only depends on the relative batch sizes ml and mz. The asymptotic correlation 
between OBM estima­tors does not depend upon the data type. Rather it depends only upon the two relative 
batch sizes through (ml/rn2)li2 and ~(ml, m2). 4 FINITE-SAMPLE RESULTS We now describe Monte Carlo experiments 
that esti­ mate the correlation between two OBM estimators of var(X) and compare these finite-sample 
results to the asymptotic results of the previous section. The pur­ pose is to study the applicability 
of the asymptotic formulas for finite samples and different data types. Equations 22 and 24 indicate 
that the quality of the covariance approximation is similar to that provided by the correlation approximation. 
Therefore, we con­ sider only correlation here. 4.1 The Monte Carlo Experiment The Monte Carlo experiment 
estimates corr 0,; ()for six cases: two sample sizes and three steady-state data processes. The sample 
sizes are n = 100 and n = 1000; the three data processes are iid normal (7o = 1, 7 1 = O), AR(1) normal 
with 70 = 10 and 71 = 49.5, and 5-state DPSS with 70 = 10 and 71 = 35.2 (and uniform marginal distribution). 
For each sample {Xl, X2, . . . . X.} from the data process, OBM estimates ~m are computed for m = 1, 
2, . ...99 if n = 100 and for m = 1, 10,20, . ...990 if n = 1000. From 10,000 such samples the correlations 
corr fi, fij are () estimated to negligible sampling error. We now briefly review the three data processes. 
They have different correlation structures and differ­ent marginal distributions, but all are illarkov 
pro­cesses: the distribution of the next value depends (at most) on the current value. The iid-normal 
process has no memory since its value at time t is independent of all past values. Therefore p(h) = O 
for all nonzero values of h, To = 1 and 71= (). The AR(1) normal time series is Xt = # Xz-l + .ct, where 
lq51 < 1 and {Sf} is a sequence of iid normal random variables with zero mean and variance UC2. The autocovariance 
and autocorrelation functions are R(h) = aC2#hl/(1 42), and p(h) = ~lhl. This ge­ometrically decreasing 
correlation structure implies that the sum of correlations is 70 = (1 + #)/(l ~) and the weighted sum 
of autocorrelations is 71 = 24/(1 f$)z = (70 1)(-(0 + 1)/2. The DPSS(d, p,s, S) process models a d-state 
(s, S) inventory system with Bernoulli demands [Pedrosa and Schmeiser, 1993a]. At each time t the ran­dom 
demand is zero with probability p and is A = (S s)/(d 1) units with probability 1 p; non-zero demand 
at inventory s causes immediate reordering and a return to state S. The Markov chain is doubly stochastic, 
so the unique steady-state marginal distri­bution is uniform over the d states {S, S A, ,s}; the steady-state 
mean and variance are then p = (S+ s)/2 and var(X) = (d2 l) A2/12. In addition to having a non-normal 
marginal distribution, the DPSS process differs from the AR(1) process by hav­ing a more-complex autocorrelation 
structure. The lag-l autocorrelation is p(l) = (d 5 + 6p)/(d + 1), the sum of autocorrelations is 70 
= p/(1 p), and the weighted sum of autocorrelations is 71 = {[(19 d2)(y0 + 1)]/30 1}(7o + 1). 4.2 
Discussion of Experimental Results The experimental results indicate that the quality of the approximation 
provided by the asymptotic corre­lation in Equation 22 is good if both batclh sizes are between 70 and 
n/2. The quality is relatively insensi­tive to the marginal distribution and to the weighted sum of correlations 
71. To aid the discussion, we introduce two figures. Figure 1, for normal data, and Figure 2, for DPSS 
data, illustrate the results for n = 100, the small­est sample size considered. Each figure cc~ntains 
six charts, each corresponding to a batch size mi = 5, 10,30,50,60,90. The horizontal axis is the other 
batch size mj, ranging from 1 to n 1. For each chart, two curves are shown: the asymptotic corre­lation 
from Ecluation 22 and the true finite-sample correlation; the true correlation goes to zero for large 
values Of ?T2j The closer are the two curves the better is the approximation. The approximation iis exact 
at m, = mj, since both the approximation and the true correlation are then one. A relatively good approximation 
is shown in Figure 1. The independent normal data have ~,. = 1, so n = 100 is a relatively large sample 
size. Whenever both batch sizes are less than n/2, the approximation cluality is good. The quality typically 
degenerates as either batch size increases beyond n/2. The n = 1000 graphs (not shown) are similar to 
Figure 1 for all three process. In both the AR(1) and DPSS cases, y. = 10, so the ecluivalent number 
of independent observations n/70 = 100. A less good approximation is shown in Figure 2. The DPSS dependent 
data have 70 = 10, so the equiv­alent number of independent observations is quite small, n/70 = 10. Here 
the approximation quality degenerates when either mj is too large or too small. Roughly, the quality 
is good whenever both batch sizes are between 70 and n/2. Similar graphs result for the AR(1) process 
with To = 10 and n = 100. For sample sizes n at least a few multiples of 7., these experimental results 
suggest these four conclu­sions 1.The graphs in Figure 1 are representative of the asymptotic correlations, 
regardless of marginal distribution and autocorrelation structure. 2. The cluality of the approximation 
is insensitive to the marginal distribution and to 71. 3. The equivalent sample size n/70 is sufficient 
in­formation to characterize the quality of the ap­proximation. 4. The approximation is good if both 
batch sizes are between 70 and n/2.  1 - corr , Corr o 100 o m~ 100 corr 1 o (2s100 mj corr 0 mi = 50 
mj 100 1 mi = 60 m~ = 90 corr corr o m, mj 100 m .l Figure and a 1: Correlations sample size n = corr 
100. (~, ~J) as a function of rnj for an iid  normal m~=s m~= 10 1 corr 0 0 100 100 mj m.) m~=30 
m~=50 1 corr corr o 0D 100 100 TKtj m%=60 m,=90 11 corr corr 7 0 0 100 100 mj mj Figure 2: Correlations 
corr (~, ~j) as a function of rmj for a MCBT(S = 27 S = 2, G?= 5,p = 0.91) and a sample size n = 100. 
This robustness to batch size is encouraging since various guidelines for choosing batch size fall within 
this range: 1. NBM (non-overlapping batch means) batch sizes chosen for good confidence-interval performance 
are between n/30 and n/10 [Schmeiser, 1982]; 2. The OBM estimator for the same batch size pro­vides 
50% more degrees of freedom (d.f.); then for the same d.f. good OBM batch sizes are, roughly, between 
n/20 and n/7; 3. The asymptotic rose-optimal batch size [Schmeiser and Song, 1989],  3ny12+ m =l+ T 
% [()] is 1 for the iid normal process, is 17 and 34 for the AR(1), and is 13 and 28 for the 5-state 
DPSS for n = 100 and n = 1000, respectively. ACKNOWLEDGMENTS This work was supported by the National 
Science Foundation under Grants No. DMS-87-17799 and DDM-93-00058 and by JNICT Junta National de Investiga@o 
Cientifica e Tecno16gica, Portugal. We thank Dimitris Politis for stimulating discussions. REFERENCES 
Anderson, T. W. 1971. Analysis of Time Series. New York: John Wiley &#38; Sons. Bratley, P., B. L. Fox, 
and L. E. Schrage. 1987. A Guide to Simulation. New York: Springer-Verlag. Foley, R. D., and D. Goldsman. 
1988. Confidence in­tervals using orthonormally standardized time se­ries. In M. Abrams, P. Haigh, and 
J. Comfort, editors, Proceedings of the 1988 Winter Simulation Conference, 422-424. Hannan, E. J. 1957. 
The variance of the mean of a stationary process. Journal of the Royal Statistical Society, B 19:282-285. 
Heidelberger, P., and P, D. Welch. 1981. A spectral method for confidence interval generation and run 
length control in simulation. Communications of the ACM, 24:233 245. Meketon, M. S., and B. W. Schmeiser. 
1984. over­lapping batch means: something for nothing? In S. Sheppard, U. Pooch, and D. Pegden, editors, 
Proceedings of the 1984 Winter Simulation Con­ference, 227-230. Moran, P. A. P. 1975. The estimation 
of stan­dard errors in Monte Carlo simulation experiments. Biometrika, 62:1 4. Pedrosa, A. C., and B. 
W. Schmeiser. 1993a. The d-State Bernoulli-Demand (s, S)-Inventory Markov Chain. School of Industrial 
Engineering, Purdue University, West Lafayette, Indiana. Pedrosa, A. C., and B. W. Schmeiser. 1993b. 
Asymp totic covariance between Bartlett estimators of the spectral density. Working Paper. School of 
Industrial Engineering, Purdue University, West Lafayette, Indiana. Politis, D. N. and J. P. Romano. 
1992. Bias-Corrected Nonparametric Spectral Estimation. Technical Report 92-50, Department of Statistics, 
Purdue University, West Lafayette, Indiana. Schmeiser, B. W. 1982. Batch size effects in the anal­ysis 
of simulation output. Operations Research, 30:556-568. Schmeiser, B. W., and W.-M. T. Song. 1989. Opti­mal 
mean-squared-error batch sizes. Technical Re­port 89-3, School of Industrial Engineering, Purdue University, 
West Lafayette, Indiana. Schruben, L. W. 1983. Confidence interval estima­tion using standardized time 
series. Operations Re­search, 31:1090 1108. Song, W.-M. T., and B. W. Schmeiser. 1988a. On the dispersion 
matrix of variance estimators of the sample mean in the analysis of simulation output. Operations Research 
Letters, 7:259-266. Song, W.-M. T., and B. W. Schmeiser. 1988b. Minimal-rnse linear combinations of variance 
es­timators of the sample mean. In M. Abrams, P. Haigh, and J. Comfort, editors, Proceedings of the 1988 
Winter Simulation Conference, 414421. Song, W.-M. T., and B. W. Schmeiser. 1993. Vari­ance of the sample 
mean: Properties and graphs of quadratic-form estimators. Operations Research, 41:501-517. AUTHOR BIOGRAPHIES 
ANTONIO PEDROSA is a Ph.D. student in the School of Industrial Engineering at Purdue Univer­sity. He 
received a B.S. degree in electrical engineer­ing from Porto University, Portugal, in 1982 and an M .S. 
degree in engineering from Purdue University in 1991. His research interests include simulation and, 
more generally, stochastic operations research. BRUCE SCHMEISER is a Professor in the School of Industrial 
Engineering at Purdue University. He is the Simulation Area Editor of Operations Research and an active 
participant in the Winter Simulation Conference, including being Program Chairman in 1983 and Chairman 
of the Board of Directors dur­ing 1988-1990.  
			