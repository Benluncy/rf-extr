
 Optimal Online Scheduling of Parallel Jobs with Dependencies Anja Feldmann* Ming-Yang Kaot Ji~i Sgalli 
Shang-Hua Teng~ Abstract We study the following general online scheduling problem. Parallel jobs arrive 
dynamically according to the depen­dencies between them. Each job requests a certain number of processors 
with a specific communication configuration, but its running time is not known until it is completed. 
We present optimaJ online algorithms for PRAMs, hypercubes and one-dimensional meshes, and obtain optimal 
tradeoffs between the competitive ratio and the largest number of processors requested by any job. Our 
work shows that for efficient online scheduling it is necessary to use virttia/:za­tion, i.e., to schedule 
parallel jobs on fewer processors than requested while preserving the work. Assume that the largest number 
of processors requested by ajob is AN, where O< A s 1and N is the number of processors of a machine. 
With virtualization, our algo­ *-, . rithm for PRAMs has a competitive ratio of 2 + Our lower bound 
shows that this ratio is optimal. As J goes from O to 1, the ratio changes from 2 to 2 + +, where x 0.618 
is the golden ratio. For hypercubes and one­dimensional meshes we present @( ~O~fO~N)-competitive al­gorithms 
ea well as matching lower bounds. Without vir­t ualization, no online scheduling algorithm can achieve 
a competitive ratio smaller than N for A = 1. For A < 1, the lower bound is 1 + &#38; and our algorithm 
for PRAMs achieves thw competitive ratio. We prove that tree constraints are complete for the scheduling 
problem, i.e., any algorithm that solves the scheduling problem if the dependency graph is a tree can 
be converted to solve the general problem equally efficiently. # *School of Computer Science, Carnegie 
Mellon University, Pittsburgh, PA 15213. t Department of Computer Science, Duke Universit y, Durham, 
NC 27706. Supported in part by NSF Grant CCR-9101385. t School of Computer Science, Czu-negie Mellon 
University, Pittsburgh, PA 15213. On leave from Mathematical Institute, AV dR, ~itrvi 25, 11567 Praha 
1, Czech Republic $Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA 02139. 
Supported in part by AFOSR F49620-92-J-0125 and Darpa NOO01492-J-1799. Part of the work was done at Xerox 
Palo Alto Research Center. Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is givan that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. 25th ACM STOC 93-51931CA,USA 01993 ACM 0-89791 -591 -719310005 /0642 . ..$1 .50 
1 Introduction This paper investigates online scheduling problems for parallel machines. Parallel jobs 
arrive dynamically ac­cording to the dependencies between them (precedence constraints); a job arrives 
only when all jobs it depends on are completed. Each job requests a part of a ma­chine with a certain 
number of processors and a specific communication configuration. The running time of a job can only be 
determined by actually running the job. A scheduhng algorvthm computes a schedule-that sat­isfies the 
resource requirements and respects the depen­dencies between the parallel jobs. The performance of an 
online scheduling algorithm is measured by the competitive ratzo [12]: the worst-case ratio of the total 
time (the rnakespan) of a schedule it computes to that of an optimal schedule, computed by an offline 
algo­rithm that knows all jobs, their dependencies, resource requirements and running times in advance. 
Any schedule is required to be nonpreemptave and without restarts, i.e., once a job is scheduled, it 
is run on the same set of processors until completion. We consider this the most reasonable approach 
to avoid high overheads incurred by resetting a machine and its interconnection networks, reloading programs 
and data, etc. An important fact is that a parallel job can be sched­uled on fewer processors than it 
requests. The job is ex­ecuted by a smaller set of processors, each of them sim­ulating several processors 
requested by the job. This yields good results if the mapping of the requested pro­cessors on the smaller 
set preserves the network topol­ogy, which is true for common architectures including PRAMs, meshes and 
hypercubes. The work of a job is preserved and the running time increaaes proportion­ally. This technique 
is called virtualizatton [2, 8, 10, 11]. We show that it is essential for efficient online schedul­ing. 
We prove that in the restricted model where a job cannot be scheduled on fewer processors than it re­quests, 
no efficient online scheduling is possible, un­less some additional restrictions are imposed, such as 
a bound on the number of processors a job can request. This result demonstrates a fundamental difference 
be­ tween online scheduling with and without dependen­cies the previous work [5] shows that for scheduling 
without dependencies virtualization is not essential. We present optimal online scheduling algorithms 
for PRAMs (shared memory parallel machines), hyper­cubes and one-dimensional meshes, most of them use 
virtualization. These results are summarized in The­orem 3.1. All our lower bounds apply even if an on­line 
algorithm knows the dependencies and resource requirements of all jobs in advance. In contrast all our 
algorithms are fully online, i.e., they receive this information online as well. With virtualization 
we obtain the following results. For PRAMs we show a tradeoff between the optimal competitive ratio and 
the largest number of proces­sors requested by a job. Let AN be the largest num­ber of processors requested, 
where (1 < ~ ~ 1 and N is the number of processors of a machine. Our algo­rithm for PRAMs has an optimal 
competitive ratio of 2 + _. For ~ = 1, i.e., with no restrictions on the nul{ber of processors requested 
by a job, this ra­tio equals 2 + 4 where # % 0.618 is the golden ratio. If A is close to O, the competitive 
ratio approaches 2, which is the optimal ratio for scheduling sequential jobs even without dependencies 
[5, 13]. Our algorithms for hypercubes and one-dimensional meshes have compet­itive ratio of @( ,0~~~~ 
). Our lower bounds prove that this competitive ratio are within a constant factor of the optimal one. 
The dependence of the results on the topology of a parallel machine shows that the network topology needs 
to be considered in order to schedule parallel jobs efficiently. Without virtualization, we again obtain 
a tradeoff between the optimal competitive ratio and the largest number of processors requested by a 
job. For A < 1, we have a stronger lower bound of 1+ ~ for an arbitrary network topology. We give an 
algorithm for PRAMs with a competitive ratio matching this lower bound. For A = 1, i.e., the number of 
requested processors is not restricted, we have a much more dramatic result. We prove a lower bound of 
N on the competitive ratio. This implies that no online scheduling algorithm can use more than one processor 
efficiently! Consequently, if there are dependencies between jobs, virtualization is a necessary technique 
for scheduling parallel jobs ef­ ficiently. We show that tree dependency graphs are complete for the 
scheduling with dependencies any online al­gorithm for scheduling job systems whose dependency graphs 
are trees can be converted to an algorithm for scheduling general dependency graphs with the same competitive 
ratio. This is easy to prove for fully online algorithms, but a more difficult proof is required for 
the algorithms that may know the dependencies and resource requirements in advance. This result shows 
that the combinatorial structure of a dependency graph is much less relevant for our model than for offline 
scheduling, although even the presence of simple de­pendencies makes the scheduling problem much harder 
than online scheduling of independent jobs. This com­pleteness result enables us to focus on simple depen­ 
dency graphs in the lower bound proofs. The new feature of our model is that it takes into account the 
dependencies between jobs. The previous work [5] assumes that all jobs are available at the be­ginning 
and independent of each other. In that case the competitive ratios for PRAMs, hypercubes, lines and two 
dimensional meshes are (2 ~), (2 ~), 2.5 and O(@-N-), respectively; except for the line these ratios 
are optimal. 1 These results can be extended to the model in which each job is released at some fixed 
time, instead of being known from the beginning, but the jobs have to be independent of each other [13]. 
With the dependencies between jobs, online schedul­ing becomes much more difficult. It is not immediately 
obvious that there exist efficient online scheduling al­gorithms at all. In principle jobs along a critical 
path in a dependency graph could be forced to accumulate substantial delays. We show that this indeed 
happens if the communication topology is complex, e.g., hyper­cubes and one-dimensional meshes, or if 
the jobs re­quest many processors and virtualization is not used. Virtualization is an important technique 
originally developed for the design of efficient and portable par­ allel programs for large-scale problems 
[2, 8, 10, 11]. Our work complements these results and shows that virtualization is a necessary technique 
for efficient on­ line scheduling of parallel jobs as well. Other work on online scheduling assumes that 
jobs are independent of each other and their release times are independent of scheduling [3, 4, 5, 7, 
13, 14]. Fur­ thermore, only the work in [5, 14] considers parallel jobs and the network topology of 
the parallel machine in question. Most of the other cited work emphasizes other issues, e.g., different 
speeds of processors. De­ pendencies between the jobs were previously considered only in the classical 
offline model when the dependency graph and the running times are given in advance (for example [61). 
In Sections 2 and 3 we state the basic definitions and our results. In Sections 4 and 5 we prove the 
results which are independent of the network topology the 1These improved results for PRAMs, hypercube 
and line will appear in the journal version of [s] completeness of tree dependency graphs and the lower 
bound for scheduling without virtualization. The re­sults for PRAMs and other architectures are given 
in Sections 6 and 7. 2 Definitions 2.1 Parallel machines and parallel job systems with dependencies 
For the purpose of scheduling, a parallel machine with a specific net work topology is an undirected 
graph where each node u represents a processor pa and each edge {u, v} represents a communication link 
between PU and Pv . The resource requarernents of a job are defined as fol­lows. Given a graph H representing 
a parallel machine, let ~ be a set of subgraphs of H, each called a job type, that contains all singleton 
subgraphs and H itself. A parallel job J is characterized by a pair J = (G, t) where G E G is the requested 
subgraph and t is the running time of J on a parallel machine G. The work of J is \Glt, where IG[ is 
the size of the job J, i.e., the number of processors requested by J. A sequential job is a job requesting 
one processor. A parallel job system J is a collection of parallel jobs. A parallel job system wzth dependencies 
is a directed acyclic graph F = ($, S) describing the dependencies between the parallel jobs. Each directed 
edge (J, J ) c Z indicates that the job J depends on the job J, i.e., J cannot start until J has finished. 
2.2 Virtualization During the execution of a parallel job system, an avail­able job may request p processors 
while only p < p processors are available. Using vzrtuahzatzon [8, 11], it is possible to simulate a 
virtual machine of p pro­cessors on p processors. A job requesting a machine G with running time t can 
run on a machine G in time a(G, G )t, where a(G, G ) is the stmulatzon factor [1, 9]. Neither the running 
time nor the work can be de­creased by virtualization, i.e., a(G, G ) ~ max(l, ~). If the network topology 
of G can be efficiently mapped on G , the work does not increase [1, 9]. For example, the computation 
on a d-dimensional hypercube might be simulated on a d -dimensional hypercube for d < d by increasing 
the running time by the simulation factor Zd-d . 2.3 The scheduling problem and the performance measure 
A scheduling problem is specified by a network topology together with a set of available job types and 
all sim­ ulation factors. A family of machines with a growing number of processors and the same network 
topology usually determines the job types and simulation factors in a natural way. (See Section 2.4 for 
examples.) An inst ante of the problem is a parallel job system with dependencies F and a machine H with 
the given topol­ogy. The output is a schedule for 3 on the machine H. It is an assignment of a subgraph 
G: &#38; H and a time interval t; to each job (Gj, t~) 6 X such that the length of tj is a(Gi, G: )ti; 
at any given time all subgraphs as­signed to different currently running jobs are mutually disjoint and 
each job is scheduled after all the jobs it depends on have finished. A scheduling algorithm is ofline 
if it receives com­plete information as its input, i.e., all jobs including their dependencies and running 
times. It is online if the running times are only determined by scheduling the jobs and completing them, 
but the dependency graph and the resource requirements may be known in advance. It is fully online if 
it is online and at any given moment it only knows the resource requirements of the jobs currently available 
but it has no information about the future jobs and their dependencies. We measure the performance by 
competitive ratio [12]. Let Ts(~) be the length of a schedule computed by an algorithm S, and let Topt(3) 
be the length of an optimal schedule. A scheduling algorithm S is u­competitzve if T5 (F) < aTOPt (Y) 
for every %. Note that deciding whether a given schedule is optimal is coNP-complete [6]. 2.4 Some network 
topologies PRAM: For the purpose of online scheduling, a parallel random access machine of N processors 
is a complete graph. Available job types are all PRAMs of at most N processors. A job (G, t)can run on 
any p < [G 1 processors in time ~t, i.e., the simulation factor is ~. Hypercube: A d-dimensional hypercube 
has N = 2* processors indexed from O to N 1. Two processors are connected if their indices differ by 
exactly one bit. Available job types are all d -dimensional subcubes for d s d. Each job J is characterized 
by the dimension d of the requested subcube. The job J can run on a d -dimensional hypercube in time 
2d d tford sd . Line: A line (one-dimensional mesh) has N proces­sors {Pi 10 s i < N}. Processor pi 
is connected with processors Pi+l and pi-1 (if they exist). Available job types are all segments of at 
most N connected proces­sors. The job (G, t) can run on a line of p processors in time ~t for ps IGI. 
For d z 2, d-dimensional meshes and d-dimensional jobs are defined similarly.  Results Theorem 3.1 
Let N be the number of processors of a machine. Suppose that no job requests more than AN processors, 
where O < A ~ 1. Without virtualization we have the followtng results. network topology upper bound lower 
bound 6r PRAM, O<A<l 1+* 1+* With vtrtualization we have the following results. K hypercube, lane 0( 
10:E:N ) Q( lo:lo&#38;N ) K d-dimensional mesh 0(( ,O:f$ )d) ( lo:io~N ) Remarks. All algorithms in 
the upper bounds are fully online. All lower bounds apply to all online algo­rithms, not only to fully 
online ones. The competitive ratios for PRAhIls are the best con­stant ratios that can be achieved for 
all N if A is fixed. There is a small additional term that goes to O as N grows. All our lower bound 
results assume that the running time of a job may be zero. This slightly unrealistic assumption can be 
removed easily. As all our proofs are constructive, we simply replace all zero times by unit times and 
scale all other running times to be suffi­ciently large. This only decreases the lower bounds by arbitrarily 
small additive constants. The next theorem shows that the structure of a de­ pendency graph is less 
important than it seems at first. Theorem 3.2 Let S be an online scheduhng algorithm for an arb~trary 
network topology. Suppose that S M ~-compettttve for all job systems whose dependency graphs are trees. 
Then we can construct from S an on­ line algordhm which is o-compeitttve for all job systems U)ath generaldependency 
graphs. 4 Tree dependency graphs In this section we prove Theorem 3.2. First notice that a similar theorem 
for fully online algorithms is easy to prove. Suppose that we have a fully online algorithm for tree 
dependency graphs and a general dependency graph 7. We dynamically construct a tree subgraph Y of F and 
use the algorithm on F . We can do that because the fully online algorithm does not know the dependencies 
in advance. For each job J we only keep the edge from a job J such that J became available when J! finished. 
The generated schedule is a valid schedule for both F and F1, and the optimal sched­ule for 3 can only 
improve if some dependencies are removed. Therefore the achieved competitive ratio for 3 is no worse 
than the ratio for the tree dependency graph F . The important case is Theorem 3.2, where the algo­rithms 
may know the dependency graph in advance. Proof of Theorem 3.2. Given a general dependency graph 3, we 
create a job system with a tree dependency graph F . Then we use the schedule for F produced by S to 
schedule 3. We determine the running times of jobs in 3 dynamically based on the running times of jobs 
in F. The set of jobs of 3 is the set of all directed paths in ~ starting with any job that has no predecessor. 
There is a directed edge (p, q) in .F if p is a prefix of q. If J E F is the last node of p E 3 , then 
p is called a copy of J. The resource requirements of any copy of J are the same as those of J. A path 
p is the last copy of J if this is the last copy of J to be scheduled. Let f be the subgraph of $ consisting 
of all last copies and all dependencies between them. Our scheduling strategy works as follows. We run 
S on ~ . Suppose S schedules p c 7. There are two possibilities. (i) p is the last copy of some J. In 
this case we schedule J to the same set of processors as p was scheduled by S. (ii) p is not the last 
copy. Then we remove p and all jobs that dependend on it. If a job J E F finishes, we stop its last copy 
p E F . Notice that if p is the last copy of J, then we schedule J in the same time, on the same set 
of processors and with the same running time as S schedules p. All other copies of J are immediately 
stopped. To show that our schedule is correct, we need to prove that when the last copy of J is available 
to S, J is available to us. Suppose this is not the case. Then there is some J ~ F such that .J depends 
on J and J has not finished yet. Then the last copy of J , say q c F , is also not finished, and there 
is a copy p of J suchthat qisaprefix ofp. Sopisacopy ofJthat is not available yet, a contradiction. The 
schedule S generated for Y and our schedule for ~ have the same length, Only the jobs from 3 (i.e., the 
last copies of the jobs from 7) are relevant in X ; all other jobs have running time O and can be scheduled 
at the end. By construction, any schedule for Y corresponds to a schedule for 7 and therefore to a schedule 
of f . So the competitive ratio for F is not larger than the competitive ratio for $ and this is at most 
c by the assumption of the theorem. 1 Algorithmically, the above reduction from general constraints 
to trees is not completely satisfactory, be­cause 7 can be exponentially larger than r. Neverthe less, 
it proves an important property of online schedul­ing from the viewpoint of competitive analysis. 5 
Is virtualization necessary? The difficulty of online scheduling without virtualiza­tion is best seen 
by the strong lower bounds of this sec­tion. Theorem 5.1 implies that no efficient scheduling is possible 
if virtualization is not used and the num­ber of processors requested by a job is not restricted. This 
demonstrates the importance of virtualization in the design of competitive scheduling algorithms. It 
also shows that online scheduling with dependencies is fun­damentally different from scheduling without 
depen­dencies. Without dependencies neither the size of the largest job nor virtualization changed the 
optimal com­petitive ratios dramatically [5]. Theorem 5.1 Without virtualizatzon, no online scheduling 
algorzthm can achieve a better competitive ratzo than N on any machine with N processors. Remark. Notice 
that the corresponding upper bound can be achieved by scheduling one job at a time. Proof. The job system 
used by the adversary consists of N independent chains. Each chain starts with a se­quential job and 
has N sequential jobs alternating with N parallel jobs requesting N processors. See Figure 1 for illustration. 
The adversary assigns the running times dynamically so that exactly one sequential job in each chain 
haa running time T for some predetermined T, and all other jobs have running time O. i- F-... :: . . 
N-1 e levels I } Figure 1: Example of the job system as used in the proof of Theorem 5.1 In the beginning 
the algorithm can only schedule sequential jobs. The adversary keeps one of the se­quential jobs running 
and assigns running time O to all other sequential jobs on the first level, both running and available. 
There is only one processor busy while all other processors are idle because no parallel job can be scheduled. 
The adversary keeps the chosen sequen­tial job running for time T, then terminates it and sets the running 
times of all remaining jobs in this chain to O. This process is repeated N times. Each time at most one 
parallel job of each chain can be processed, hence the schedule takes time at least NT. The optimal schedule 
first schedules all jobs before the sequential jobs with running time T, then the N sequential jobs with 
time T in parallel and then the remaining jobs. The total time is T, and hence the competitive ratio 
of the online scheduling algorithm is at least N. c1 Now we prove a lower bound on the competitive ra­tio 
if the number of processors requested by a job is restricted. Theorem .5.2 Suppose that the largest number 
of pro­cessors requested by a job on a machine with N pro­cessors is JN. Then no scheduling algorithm 
without virtualization can achieve a smaller competitive ratio than 1 A. Proof. We first present a proof 
for fully online schedul­ing algorithms. We then sketch how to modify the job system for any online algorithm. 
The job system used by the adversary has N 1 lev­els. Each level has N [AN] + 2 sequential jobs and 
one parallel job requesting [ANJ processors. The par­allel job depends on one of the sequential jobs 
from the same level; all sequential jobs depend on the parallel job from the previous level. In addition 
there is one more sequential job dependent on the last parallel job. See Figure 2 for illustration. N-1 
 Figure 2: Example of the job system as used in the proof of Theorem 5.2 In the beginning the algorithm 
can schedule only se­ quential jobs. The adversary forces that the sequen­tial job on which the parallel 
job depends is started last; this is possible since the algorithm cannot dis­tinguish between the sequential 
jobs. The adversary terminates this sequential job and keeps the other se­quential jobs running for some 
sufficiently large time T. Note that during this time the scheduling al­gorithm cannot schedule the parallel 
job. As soon as the parallel job is scheduled, the adversary imme­diately terminates it and all remaining 
jobs of this level. This process is repeated until all jobs except the last sequential job have been 
scheduled. The ad­versary assigns time T = (N lAN] + 1) T to the last job. The total length of the generated 
schedule is (N -l)T+ T = (2N -[/VV])Z . The adversary assigned to each job a time of either O, at most 
T or T . Moreover, all jobs with nonzero time are independent of each other. The offline algo­rithm first 
schedules all jobs of time O; then schedules the sequential job with running time T and in par­allel 
with it all the other sequential jobs. There are (N 1)(N [AN] +1) of such jobs, all with running time 
at most T and independent of each other. The schedule for them on N 1 processors takes time at most 
(N lJNJ + l)T = T . So the length of the of­fline schedule is at most T and the competitive ratio is 
~-l)T+T at least i T l+*i. This is arbitrarily close to 1 + &#38; for large N and constant A. Now we 
modify the job system to handle the case where the online algorithm knows the job system in advance. 
The proof is similar to the proof of Theorem 3.2. We generate sufficiently many copies of each job, so 
that the graph is very symmetric and the schedul­ing algorithm cannot take advantage of the additional 
knowledge. The new job system is a tree of the same depth and each paraliel job has the same fanout as 
before. There is one parallel job dependent on each sequential job except for the last level. So instead 
of a constant width tree we have a wide tree which is ex­ponentially larger. The adversary strategy is 
the same except for the following modification. When a sequen­tial job is scheduled, then except for 
the last one on each level the whole subtree of jobs dependent on it is assigned time O. Thus the resulting 
schedule has the same length as in the fully online case and the lower bound holds. c1  6 Scheduling 
on PRAMs Let Tmax(F) be the maximal sum of running times of jobs along any path in a dependency graph 
~. Clearly T m ax < TOP,($). Suppose S is a scheduling algorithm for a parallel machine H. The eficiency 
of S at time tis the number of busy processors divided by IH 1. For each a ~ 1, let T<. (S, 3) be the 
total time during which the efficiency of S is less than a. The next lemma has proven to be very useful 
for analyzing scheduling algorithms [5]. The lemma is valid also for job systems with dependencies. Lemma 
6.1 Let S be a schedule for a parallel lob sys­ tem F such that the work of each job M preserved. If 
T<. (S, 7) ~ ,BToP~(F). where Ts(~) < (:+ 9)Topt(~). 6.1 PRAMs without virtualization We start by giving 
a generic algorithm for online scheduling of parallel job systems with dependencies. By generic , we 
mean that the scheme does not di­rectly depend on the underlying network topology, Al­though not highly 
competitive in general, it is the best possible algorithm for PRAMs without virtualization. This algorithm 
maintains a queue Q that contains all jobs available at the current time. All jobs that become available 
are added to Q immediately. First(Q) is a function such that for each nonempty Q, First(Q) c Q. It may 
choose an arbitrary available job in Q, although in practice we suggest selecting an available job based 
on best fit principle. algorithm GENERIC while not all jobs are finished do if the resource requirements 
of First( Q) can be satisfied then begin schedule First (Q) on a requested subgraph; Q -Q -First(Q); 
end. Let TemP~Y be the total time when Q is empty. The following lemma gives an upper bound on T,~P~Y. 
Lemma 6.2 For all online parallel job systems wdh dependencies F, Tempty < Tmax(3) < T~pt(F). Proof. 
Consider the schedule generated by GENERIC. Let Jo be the job that finishes last. Let 11 be the last 
time interval before Jo is started for which Q is empty. There exist a job Jl running at the end of II 
that is an ancestor of JO in the dependency graph, since otherwise JO would be available already during 
11 and Q would not be empty. By the same method construct Iz, Jz, 13, J3, . . . . Ik, Jk, Until ~here 
k no interval for which Q is empty before Jk is started. Because of the way we selected the jobs, Jk, 
Jk _ 1,. ... JO is a path in the dependency graph. Moreover all time intervals for which Q is empty are 
covered by the time intervals during which the selected jobs are running, and hence T,mpty ~ Tmax(7). 
L1 Now we show that the competitive ratio of GENERIC matches the lower bound from Section 5. Theorem 
6.3 Suppose that the largest number of pro­ cessors requested by a job is JN, where O < A < 1. Then GENERIC 
is (1+ +)-competitive. Proof. No job requests more than [~Nj processors. therefore if the efficiency 
is less than 1 A, there is no available job. It follows that T<( 1-~] s TemptY < Topt. Lemma 6.1 finishes 
the proof. 0 If all jobs are sequential, we can prove an exact bound in terms of N. For sequential jobs 
the network topology is irrelevant, and thus this bound applies to an arbitrary network topology. This 
bound matches previous results [7]. Theorem 6.4 Suppose that each job in the parallel job system is a 
sequential job. Then GENERIC is (2 ~)­ competitive for an arbitmry network topology, Proof. Whenever 
Q # 0, the efficiency is 1. Let T be the time when the efficiency is 1, let T = T< ~ be the remaining 
time. By Lemma 6.2, T < T,mPty < T.Pt. As in Lemma 6.1, we have T + ~T < TOPt. Combining these two inequalities 
we obtain T + T s (1 -t ~)T.Pt =(2 ~)T.Pt. 0  6.2 PRAMs with virtualization The main result of this 
section is an optimal (2+ #c­ompetitive algorithm, where # = ~ = 0.618 is the golden ratio. We also study 
the pr~blem where each job requests at most AN processors, where O < A < 1. In this case the competitive 
ratio can be improved. We give tight lower and upper bounds. The basic idea of the algorithm is to maintain 
the efficiency at least a for some constant O < a < 1. To do so, we sometimes have to schedule large 
jobs on fewer processors than they request. algorithm PRAM(a), (O < a ~ 1) while not all jobs are finished 
do 1 if the efficiency is less than a then begin schedule First (Q) on the requested number of processors 
or on all available processors, whichever is less; Q +-Q First(Q); end.  Theorem 6.5 Suppose that each 
]ob requests at most AN processors. Then PRAh4(cx) M u-competatwe for U=2+V and~=~-A + + din-, Remark. 
The above a and u satisfy u = 1 + ~ and az+(2A l)a A = Oorequivalently (l a)(~++) = 1. Corollary 6.6 
If the number of requested processors ts unrestricted (~ = 1), then PRAM(4) M (2 + q$)­ competitave, 
where q5 = @# M the golden ratio. . Proof of Theorem 6.5. First, observe that when Q is nonempty, the 
efficiency is at least cr, otherwise another job would be scheduled. Let T be the total time during the 
schedule when the efficiency is at least a, T the time when the efficiency is between 1 a and Q and 
T = T<(l_@) the remaining time. If some job is scheduled on less than the requested number of processors 
then it is scheduled on at least (1 a)N pro­cessors. Therefore no job running during T is slowed down 
and any job running during T is slowed down by a factor at most &#38;. As in Lemma 6.2 it fol­lows that 
~T1 + T) s Tmax < TOPt. Because the efficiency of the optimal schedule cannot be greater than one, we 
have ~T + (1 ~)T ~ TOPt. By adding the first inequality and the last one divided by a, we obtain T + 
(1 cr)(~ + ~)T + T ~ (1 + ~)TOPt. Since (1 @)( ~ + 1) = 1, the competitive ratio is 1 We prove a matching 
lower bound. The proof is given for the fully online algorithms only, it can be general­ized to all online 
algorithms by the same method w in Theorem 5.2. Theorem 6.7 Suppose that the largest number of pro­ cessors 
requested by a job is AN, where N is the number of processors of the machine and O < A ~ 1. Then no online 
scheduling algorithm achieves a better competi­ tive ratio than u = 2+ * for all N, Proof. The proof 
is divide; into two cases, J = 1 and A<l. The case of J = 1. The strategy of the adversary is to keep 
the efficiency of the machine under ~, or to force the algorithm to schedule a job on a number of processors 
that is smaller by the factor of 2 + C#than the requested number. The job system used by the adversary 
is similar to that in Theorem 5.2. It has 1 levels, each level has l@Nj + 2 Sequential jobs and one parallel 
job of size iV. The parallel job depends on one of the sequential jobs from the same level, all sequential 
jobs depend on the parallel job from the previous level. In addition there is one more sequential job 
dependent on the last parallel job. As in Theorem 5.2 the adversary can force that the parallel job always 
depends on the sequential job from that level that is scheduled last. Now we describe the adversary strategy. 
If a parallel job is scheduled on fewer than (1 @)N processors, it is slowed down by a factor greater 
than &#38;. In this case the adversary assigns sufficiently long time to this job and removes all other 
jobs. Therefore the competitive ratio is at least &#38; = 2 + # and we are done. Otherwise the adversary 
assigns the running time O to all parallel jobs and all the sequential jobs on which the parallel jobs 
depend. All other sequential jobs are assigned running time T for some preset time T, except for the 
last sequential job which is assigned running time T = ~lT. The previous paragraph shows that no parallel 
job can be scheduled earlier than time T after the previous parallel job has finished. Therefore the 
schedule takes at least time lT + T =(1 + @)/T. The optimal schedule first schedules all jobs with time 
O and then the sequential job with time T in parallel with all other sequential jobs. The length of this 
schedule is [1( l~~~~l)T 1, which is arbitrarily close to I#lT for sufficiently large N and 1. Therefore 
the competitive ratio is arbitrarily close to ~ = 2 + @. This finishes the proof for ~ = 1. The case 
of A < 1. The proof of this case is more complicated. The method used in the previous case does not lead 
to the optimal result. However, if it is iterated with 1$replaced by a which decreases each it­eration, 
then the upper bound is matched in the limit. The adversary uses a job system similar to the one in the 
previous case. Given a sequence al, Crz, . . .. the job system has a phase for each a,. Phase i haa / 
levels, each level has [~iN] + 2 sequential jobs and one parallel job of size [Aiv]. The dependencies 
are as before, each parallel job depends on one sequential job from the same level and all sequential 
jobs depend on the parallel job from the previous level. Also the adversary strategy is similar. The 
running times of all parallel jobs and all sequential jobs on which the parallel jobs depend are set 
to O: the running times of all other sequential jobs are T, except for the last level. This scheme only 
changes if some parallel job is scheduled on too few processors. Let u z 2 be the competitive ratio that 
we want to achieve as a lower bound. W e choose al, 02, . . . so that if the parallel job of the i-th 
level is scheduled together with more than a,N sequential jobs, it is slowed down too much. Let Ai = 
~ ~~=1 al. Let a, be such that A 1-(2,anda=&#38;+-&#38; fori >l. Allai andu= Ai are between O and 1. 
Both sequences are decreasing to the same limit L satisfying a = &#38; + ~. First suppose that no parallel 
job is scheduled earlier than time T after the previous parallel job has finished. Then the schedule 
takes time T for each level and the average efficiency of the first i phases is at most Ai + ~. After 
sufficiently many phases this is arbitrarily close to L + ~. At that point the adversary stops the process 
and assigns a nonzero time T to a single sequential job. Time T is chosen so that the optimal schedule 
for the previously scheduled jobs takes time T on N 1 processors. This forces the competitive ratio 
to be arbitrarily close to 1 + ~. So suppose that some parallel job J of phase i is scheduled early. 
Then J is scheduled on at most (1 ai)N processors. We prove that the adversary can achieve a competitive 
ratio arbitrarily close to a. For z = 1, the job J is slowed down by a factor &#38; = a, so the adversary 
just runs J long enough. For i > 1 let T be the time when J is scheduled, let A be the average efficiency 
of the schedule before ~. Obviously A < Ai -1. The adversary sets the running time of J to T = AT and 
removes all jobs that have not yet been scheduled. Then the generated schedule takes time T+*T = (~+&#38;)T 
~ (&#38;+&#38;)T = uT . The op~imal schedule r~ns first ~rl parallel jobs and then all sequential jobs 
together with the parallel job of time Tt. Time T) was chosen so that the length of the optimal schedule 
is within an arbitrarily small fac­tor of Tt for large 1 and N. So the competitive ratio is arbitrarily 
close to (~ + &#38;T )/T z U. So if we chose u such that a = 1 + ~, then no algo­rithm has competitive 
ratio smaller than a. We know thatu=~+r. 1 ~ The substitution of u = 1 + ~ and a short calculation shows 
that the condition for L is equivalent to the equation for a in Theorem 6.5 and therefore a = 2 + _ is 
the solution of the equation. 1  7 Hypercubes and meshes In contrast to scheduling on PRA Ms, jobs 
on hyper­cubes and meshes require a structured subregion of a parallel machine. Thus the geometry of 
the underlying network topology has to be considered. First we present an algorithm for a d-dimensional 
hypercube. A normal k-dimensional subcube is a sub­cube of all processors with all coordinates except 
the first k fixed. Let h be the smallest power of two such that h log h z d. Notice that h = 0( *). We 
parti­tion the jobs into h job classes ~~, 1 ~ i s h. A job is in $i if it requests a hypercube of dimension 
between d ilogh and d (i l)logh. Qi is a queue for the available jobs in fli. The hypercube is partitioned 
into h normal (d log h)-dimensional sub cubes Ml, . . . . Mk. Jobs from $i ar~ scheduled on Mi only. 
algorithm HYPERCUBE while not all jobs are finished do for all i such that Q?i # @do if a normal (d 
i log /-t) -dimensional subcube in Mi is available then begin schedule First(Q~) on that subcube; Qi 
-Q!i -First(Qi); end. Theorem 7.1 The competitive ratio of HYPERCUBE is 0(&#38;) = 0( ,0~#~ ) for the 
d-dimensional hyper­ cube with N = 2d processors. Proof. The algorithm assigns a (d i log h)-dimensional 
sub cube to each job from J i. First, this implies that no job is slowed down by a factor greater than 
h and as in Lemma 6.2 we obtain ~cmpty S ~~max (Tcmpty now refers to the time when all queues are empty), 
Second, if Qi is nonernpty then the efilciency of the sub cube Mi is equal to 1, and the overall efficiency 
is at least ~. Thus, by Lemma 6.1, the competitive ratio is O(h) = O(&#38;) = o(lo~o~~). 1 A similar 
algorithm can be used for the d­dimensional mesh of N = nd processors. Let k be the smallest integer 
such that k~ > n. Notice that ~ = O(lo:pg. ). We maintain h = kd queues. The jobs are partitioned into 
h job classes ~a, i = (il, . . . . id), 1 ~ ij ~ k. A job belongs to $i if it requests a submesh of size 
(al, az, ..., ad) such that fi < aj ~ A. Qi is a queue for the available jobs from {i. The mesh is partitioned 
into h submeshes Lf, of size [~] x . . . x 1~]. Jobs from Ji are scheduled on submesh &#38;i only. - 
­ algorithm MESH while not all jobs are finished do for all isuch that Qi # 0do if an L&#38;-j x... x 
[*] submesh in M, is available then begin schedule First(Qi) on such a submesh with the smallest coordinates: 
Qi ~ Qi -Fkst(C?i); end. The proof of following theorem is similar to that of Theorem 7.1 and omitted. 
Theorem 7.2 MESH is 0( ( 10~&#38; ,v Id )-c~mpettt2tie for a d-dtmenstonal mesh of N = nd processors. 
7.1 Lower bounds In this section, we prove that tile conlpetitive ratios of our algorithms for one dimensional 
meshes and hy­percubes are within a constant factor of the optimal competitive ratio. Our approach to 
these lower bounds is similar to [5]. The adversary tries to block a large fraction of processors by 
small jobs that use only a small fraction of all processors. Dependencies give the adversary more control 
over the size of available jobs, and therefore we are able to achieve larger lower bounds. Theorem 7.3 
No online scheduling algortthm can achzeve a better competatwe ratzo than Q( ,Jfi:iv ) for a one-dimensional 
mesh of N processors. Proof. Put s = 2 (log N1 and t = l+ log, NJ. Notice that t = @(lO~O~~), t ~ s and 
S?t < N. Our job system has t2N independent chains, each consisting of t2 jobs, a total of t4N jobs. 
In each chain the sizes of jobs are S2, S4, . . . . SZt, repeated s times, i.e., the jt+i-th job in each 
chain has size Szi. During the process the adversary ensures that only one job in each chain has nonzero 
running time, i.e., whenever he removes a job with non-zero time, he also removes all remaining jobs 
in its chain. The adversary also maintains that at any moment all available jobs are at the same position 
in their chain. The i-th subphase of the j-th phase is the part of the process when each available job 
is the jt+ i-th job in its chain. A normal k-segment is a segment of k processors starting at a processor 
with position divisible by k. A segment is used if at least one of its processors is busy. The adversary 
chooses some time T and then reacts to the actions of the algorithm by the following steps. SINGLE JOB: 
If the algorithm schedules a job of size s2i on a segment with fewer than 2s2i 1 processors, then the 
adversary removes all other jobs, both running and waiting, and runs this single job for a sufficiently 
long time. CLEAN UP: If the time since the last CLEAN UP or since the beginning is equal to T and there 
was no SIN-GLE JOB step, the adversary ends the current phase, i.e., he removes all running jobs and 
all remaining jobs in those chains, and all remaining jobs of the current phase in all chains. DECREASE 
EFFICIENCY: If in the i-th subphase of any phase at least ~ processors are busy, the adver­sary does 
the following. For every used normal s2i+l­segment he selects one running job that uses this seg­ment 
(i.e., at least one processor of it). He keeps run­ning these jobs and removes all other running jobs 
and all remaining jobs in their chains, and all available jobs of length S2 , thus ending the current 
subphase. Evaluation of the adversary strategy We can assume that the algorithm never allows a SINGLE 
JOB step, otherwise it obviously cannot be t-competitive. Our analysis is based on the following lemma. 
 Lemma 7.4 Durtng the i-th subphase of any phase (z) only jobs of size s2i and smaller are running and 
only jobs of size s2i are available to be scheduled; (ii) the, total length of used normal s2i-1 -segments 
is at ieast *.  Proof. We prove this inductively. At the beginning of the whole process (i) and (ii) 
are trivial. During any subphase no job is removed, so (i) and (ii) remain true. From one subphase to 
the next one, (i) is obviously maintained.  To prove that (ii) is maintained, we first show that at 
the beginning of each subphase the total area of run­ning jobs is at most ~. This is trivial for the 
first sub­phase of each phase. Otherwise the subphase is started by DECREASE EFFICIENCY step, in which 
for each normal 52*-1-segment only one job is left running. By (i), these jobs have size at most s2i-2 
and so their to­ tal area is at most ~, because the normal segments are pairwise disjoint. So during 
the i-th subphase new jobs must be sched­uled on at least ~ $ > ~ processors to induce the nex% DECREASE 
EFFICIENCY step. Scheduled jobs have length s2i and therefore (to avoid SINGLE JOB) at least half of 
their area consist of whole normal s2i l-segments. These segments could not be used at the beginning 
of the subphase, so during the subphase the total area of used normal Szi-l-segments increases by at 
least $ and at the end of the subphase it is at least H. The area of used S21+1-segments is at least 
as large, since the normal segments of different lengths are aligned. During the DECREASE EFFICIENCY 
step the used normal szi+l-segments remain used so the area does not decrease. This proves that (ii) 
is true at the beginning of the next subphase. From (ii) it follows that at the beginning of the t-th 
subphase all normal sot-l-segments are used and so no available job can be scheduled. Hence a CLEAN UP 
step ends every phase and both (i) and (ii) are also true at the beginning of the next phase. 0 From 
the last paragraph of the proof of the lemma it also follows that every phase takes time T. Every DE- 
CREASE EFFICIENCY or CLEAN UP step removes at most n chains. It follows that there are sufficiently many 
chains available for t phases. Therefore the whole schedule takes at least time tT. Every chain contains 
at most one job with non-zero time, so Tmax <_ T, at most ~ of the length of the schedule; moreover 
all these jobs are independent and we can use the results on scheduling without dependen­ cies from [5]. 
The efficiency of the online schedule was at most ~ all time, therefore there N an offline schedule O(t) 
-times shorter. 0 Theorem 7.5 No onltne scheduling algorlthm for a d-dtmenstonal hypercube of N = 2d 
processors can achieve a better competitive ratzo than Q(&#38;) = i3 ( lo:lo~N ) Proof. The proof is 
similar to the previous one pro­ vided that normal segments are replaced by subcubes with s = 2k processors. 
Thus we have to choose s to be a power of 2. It is easy to verify that this changes the bound only by 
a constant factor. 0 Conclusions In this paper we have presented efficient algorithms for one of the 
most general scheduling problems, which is of both practical and theoretical interest. We have shown 
that virtualization, the size of jobs and the network topology are important issues in our model, but 
the structure of the dependelicy graph is not that impor­tant. A main open question is whether randomization 
helps to improve the performance. Acknowledgment We would like to thank Avrim Blum, Steven Rudich, Danny 
Sleator, Andrew Tomkins and Joel Wein for helpful comments and suggestions. References [1] S.N. Bhatt, 
F.R.K. Chung, J.-W. Hong, F.T. Leighton, and A.L. Rosenberg. Optimal simulations by butterfly networks. 
In STOC, pages 192 204. ACM, 1988. [2] G.E. Blelloch. Vector Models for Data-Pamilel Com­ puting. MIT-Press, 
Cambridge MA, 1990. [3] E. Davis and J.M. Jaffe. Algorithm for scheduling tasks in unrelated processors. 
.l.4CiM, pages 712-736, 1981. [4] F.G. Feitelson and L. Rudolph. Wasted resources in gang scheduling. 
In Proc. of the 5th Jerusaleni Confer­ ence on Information Technokgy, 1990. [5] A. Feldmann, J. Sgall, 
and S.-H. Teng. Dynamic scheduling on parallel machines. In FOCS, pages 11l 120, IEEE, 1991 [6] M.R. 
Garey and D.S. Johnson. Computer and In­ tmctabdity: a gnmde to the theory of NP-completeness. Freeman, 
San Francisco, 1979. [7] R.L. Graham. Bounds for certain multiprocessor anomalies. Bell System Technicol 
Journal., pages 1563 1581, 1966. [8] K. Hwang and F.A. Briggs. Computer Architecture and Para/le/ F rocessmg. 
McGraw-Hill, Inc. 1984. [9] S R. I{osaraju and M.J. Atallah. Optimal simulation between mesh-connected 
arrays of processors. In STOC, pages 264-272. ACM, 1986. [10] H.T. Kung. ComputationsJ Models for Parallel 
Com­puters. Technical report, CMU-CS-88-164, 1987. [11] J.L. Peterson and A. Silberschatz. Opemtmg System 
Concepts. Addison-tVesley Publishing Company, 1985. [12] D.D. Sleator and R.E. Tarjan. Amortized efficiency 
of list. update aud paging rules. CA CM, 28(2):202 208, 1985. [13] D.B. Shmoys, J. Wein, and D.P. Williamson. 
Schedul­ing parallel machines on-line. In FOCS, pages 131 140, 1991, IEEE. [14] Q. Wang and K.H. Cheng 
A Heuristic of Scheduling Parallel Tasks and its Analysis. SIAM Journal on Com­putmg., pages 281 294, 
1992.   
			