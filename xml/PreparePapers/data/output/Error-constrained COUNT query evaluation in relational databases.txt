
 Error-Constrained COUNT Query* Evaluation in Relational Databases Wen-Chi HO U+, Gultekin 0z90yoglu-, 
and Erdogan Dogdu- ABSTRAGT An error-constrained COUNT query in rela­tional algebra is of the form Estimate 
COUNT(E), where E is a relational algebra expression, such that the error in the estimate is at most 
en. The general approach is to evaluate an estimator for COUNT(E) using a large enough sample from input 
relations such that the error is less than the specified bound with a certain confidence level. We present 
an approach which utilizes double sampling for error-constrained COUNT queries. We compare thk approach 
with another approach, called adaptive sampling, in terms of the sample sizes needed to obtain the desired 
error bound with a given confidence level. We have implemented both approaches (i.e., adaptive sampling 
and double sampling) in a proto­type, real-time DBMS called CASE-MDB. We present some of the results 
of our performance evaluation experiments. 1. Introduction In thk paper, we discuss the problem of estimating 
a COUNT(E) query having a guaranteed error bound with a certain confidence level, where E is an arbitrary 
relational algebra (RA) expression with Select, Join and Intersection operations. Such a~ estimate is 
useful in query optimization as well as in real-time databases as it takes significantly less time to 
obtain compared with evaluating COUNT(E) completely. To guarantee the desired error bound with the given 
confidence level, we use double sam­pling (or two-phase sampling) where in the first stage preliminary 
information is obtained from a small pilot sample taken from the input relations. And then, the sample 
size for the second stage is deter­ * This research is supported by the National Science Foundation under 
Grants IRI-8S11057, IRI-9009897, and IRI-9008632. + Department of Computer Science, Southern Illinois 
University at Carbondale, Carbondale, IL 62901. - Department of Computer Engineering and Science, Case 
Western Reserve University, Cleveland, OH 44106. Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
tha ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. 01991 ACM 0-89791 -425 -2/9110005 /0278... $ 1.50 mined such 
that the estimator is guaranteed to pro­duce an estimate with the desired error bound and the given confidence 
level. There is only one other approach in the litera­ture discussing the error-constrained COUNT(E) 
esti­mation problem. In [LiNa 89, 90, LNS 90], random sample tuples are repetitively taken until the 
number of output tuples meets a lower bound (i.e., the stop­ping condition) for a given relative error 
and a confidence level. The lower bound was first derived in [lXNa 90] and later refined in [LNS 90] 
by assum­ing a normal dktribution for the outcomes of the samples. Thk refinement is based on the Central 
Limit Theorem. We will call the associated algo­rithm the LNS algorithm. Detailed comparisons between 
LNS algorithm and our approach are presented later. In section 2, we briefly summarize the estima­tor 
we use. Section 3 dkcusses two basic sampling techniques, namely, simple random sampling and sys­tematic 
sampling, which can be used as the underly­ing sampling methods for double sampling. Section 4 describes 
and compares adaptive sampling and double sampling. Sectilon 5 improves the double sampling for the use 
of simple random sampling without (as opposed to with ) replacement. Section 6 describes the experimental 
results that we have run on our prototype DBMS, called CASE-MDB. Section 7 con­cludes. 2. Estimators 
for COUNT Queries In [HoOT 88, HOOZ 88], COUNT(E) is com­ puted as ~i(~) COUAW(E; ), where E is an arbitrary 
RA expression and E, is an RA expression containing only Select, Join, Intersection, Project and Difference 
(if any+) operations. Different estimators are used for diierent COUNT(Ei) expressions. However, in thk 
paper, we will restrict ourselves to RA expres­sions with only Select, Join and Intersection opera­tions. 
2.1. Point Space Model A relation instance r with I r I tuples is modeled as a finite one-cEmensional 
space with a set of I r I points. A Select-Join-Intersection (SJI-) expression E with n operand relations 
is modeled as a finite n-dimensional space, called the point space of E, such that + If difference operators 
do appear in Ei, they are always preceded by projection operations. Each relation corresponds to one 
dimension : there are totally ~~~~ I ri I points in the point space, where I ri I is the number of tuples 
in rela­ tion ri, assuming that the n different operand relations are numbered from 1 to n. Each point 
uniquely maps to a sequence of n-tuples (~1,.... fn), where ti Eri, 1~ i ~ n. (ii) A point in the point 
space assumes the value 1 if the set of corresponding n-tuples (t ~, .... tn ) pro­duces an output tuple 
when substituted into E; otherwise the point has the value O. 2.2. SJI-Expressions For a Select-Join-Intersection 
(SJI-) expression E, computing COUNT(E) is equivalent to counting the number of points with the value 
1 in the point space. In [HoOT 88, HOOZ 88],A a consistent and unbiased estimator, denoted by Y, is proposedafor 
estimating the number of 1 s in the point space. Y is defined as N . (y / m), where N is the total number 
of points in the point space of E, m is the number of sample points, and y is the number of sample points 
with the value 1. 8. Sampling Techniques In tlds section, we dkcuss two commonly used sampling techniques, 
namely, simple random sam­pling and systematic sampling [HaHM 53, Coch 77, Sukh 84]. These two sampling 
techniques (and oth­ers) have been implemented in two DBMSS, called CASE-DB and CASE-MDB, as the underlying 
sam­pling methods for an error-constrained query process­ing technique, called double sampling. Simple 
random sampling (SRS) is a method of selecting m elements (sample size) out of N (the population size) 
such that each possible sample of m elements has an equal chance of being selected. If an element that 
is already selected is removed from the population for all subsequent draws, tlds method is also called 
simple random sampling without replace­ment. On the other hand, if the element drawn is placed back to 
the population for subsequent draws, the method is called simple random sampling with replacement. Simple 
random sampling has simple mathematical properties, and serves as a prelude to other sampling techniques. 
Assuming that we have an ordering among the population elements, systematic sampliig takes a unit at 
random from the first k elements and every k h unit from there on. Systematic sampling (SS) is often 
said to follow the every kth rule [Coch 77]. The procedure is simple; however, the performance depends 
on the properties of the population [Yama 67]. The technique may greatly improve the esti­mate, as compared 
to simple random sampliig, for those populations in which elements are ordered, 4. Error-Constrained 
Query Evaluation -Three Approaches In order to compare error-constrained approaches, we assume that (1) 
error constraints (or the precision requirements) are always specified in relative errors with confidence 
levels, e.g., a 10% error with a 95% confidence level, and (2) simple random sampling with replacement 
is the  underlying sampling method in thk section. However, in Section 5, we will revise the methodol­ogy 
to incorporate simple random sampling without replacement. In section 6, we will also use systematic 
sampling for comparison purposes.  4.1. Known Population Characteristics Consider an ideal situation 
where the charac­teristics of the population (i.e., the variance and the mean) are known. Then, for a 
given error constraint, the required sample size can be easily obtained as fol­lows. Let N be the population 
size and m be the sample size. Let Yi be the value of an individual unit in i~~ population, Y be the 
population total (i.e, ~i~l Yi), y be the population mean (i.e., Y_= Y / N ), and ~ be the sample mean 
(i.e., j = (~~~l-yi) / m). To obtain an estimate of the population total Y (o; the population mean Y) 
preci~e ~o a given rela­tive error bound e with a confidence level / (where I equals 1 a), we have (Avrn)~:y 
f)i -Y Pr IL) se Y (1 .pr(p=q ?e ) Y =Pr(lj-Yl 2eY)=a (4.1) where Pr denotes the probability, m is 
the required sample size, and a is the risk of having a higher rela­tive error than e. If a sample of 
size m is randomly taken with replacement then the standard error Ui is defined as (4.2) where, U2, the 
v~riance of the population, is defined as ~~~lN(Yi Y) / N. Let us assume that the sam­ ple size is large 
enough for the Central Limit Theorem to apply (i.e., ~ is approximately normally dktributed), we have 
eY = ta. (4.3) Y where f is the abscissa of the standard normal curve that cuts off an area of a at 
the tails. Solving for m, we have wkdle it may deteriorate the estimate for those popu- 2 tu  lations 
with periodic variations. (4.4) m= () el Unfortunately, in an error-constrained environ­ment, information 
such as variance and mean of the population is usually not available. In the tables of Section 4.4, we 
list the required sample sizes for vari­ous error constrains computed from equation (4.4) under the column 
entitled wReference sizes w. These columns can be used as an indices to show how efficient an error-constrained 
algorithm is. Note that any error-constrained algorithm without the knowledge of variance and mean can 
not have a better performance (i.e., a smaller sample size) than in the idea situation. 4.2. Sequential 
Sampling Sequential sampling [Wald 45] has been used in error-constrained environments in social sciences, 
industry, etc., when there is no or little knowledge about the population at hand. It is characterized 
by its sequent ial sample gathering (i.e., taking the sam­ples step by step) and its stopping condition. 
That is, sample units are taken one at a time. By checking the outcome of each sample unit, a decision 
(i.e., the stopping criterion) as to whether an additional sam­ple unit is to be taken is made. The stopping 
cri­terion sets a lower bound on the required sample size for a given error constraint. Deriving stopping 
con­ditions is a major concern on the efficiency of a sequential samplhg method, since, though an over­sized 
sample may produce an estimate satisfying the required precision requirement, it may also result in a 
waste of resources. On the other hand, too small a sample may not be enough to produce an estimate satisfying 
the required precision. 4.2.1. Adaptive Sampling and LNS algorithm Lipton and Naughton propose A daptiue 
Sam­pling [LiNa 89, 90, LNS 90] for error-constrained queries by taking a sample unit one at a time. 
Stop­ping concMions used to determine the required sam­ple size are also presented. Clearly, adaptive 
sam­pling is a variant of sequential sampling. Lipton and Naughton [LiNa 89, LiNa 90] use an urn model 
to lay down the theoretical framework for estimating the size of a Select-Join(-Intersection) query by 
sampling. The output tuples of the SJI­expression is subdivided into disjoint sets, and each disjoint 
set is represented by a ball in the urn model. Each ball has the size of the dkjoint set as its value. 
In an SJI-expression with n operand relations r,, .... rn, a ball corresponds to a tuple tin a desig­nat 
ed relation, say r ~, and the ball value corresponds to the number of output tuples of an SJI-expression 
produced by tuple t and relations rz, .... and rn. The algorithm proposed in [LiNa 89, 90, LNS 90] (i.e., 
the LNS algorithm) repetitively draws and evaluates sample tuples from a relation untill the number of 
output tuples of the SJI-expression meets certain stopping con~ltions for a given error con­straint. 
There are two stopping conditions in [LNS 90], one for the cases in w~lch a reasonable amount m of balls 
have non-zero values, and the other for those cases where few balls have non-zero values, e.g, an extremely 
low selectivity for the SJI-expression. Without loss of generality, here we compare only the ,, first 
stopping criterion y > k ~ b 3 (: + 1)with our ee results (i.e, assuming a reasonably large selectivity), 
where y is the number of output tuples accumulated so far, k ~ is a value associated with a given cotidence 
level, b is the maximum size of the dk­joint sets, and e is the desired limit of a relative error. Unfortunately, 
the b value is usually unk­nown, wKlch determines the efficiency of LNS algo­rithm. In such cases, a 
guess value, which may be much larger than the maximum size of the dkjoint sets, has to be used. When 
preliminary information about the popu­lation is available, the performance of LNS algorithm can be significantly 
improved. That is, instead of using a guessA valu~ for b in the stopping co~dition, one can use V / ~ 
for b [LiNS 90], where ~ is an estimate of the the population variance and ~ is an estimate of the population 
mean. To obtain such information, one possible approach is to take a pilot sample, just as what we do 
in the first stage of dou­ble sampling (to be dkcussed in next section). Hereafter, we will call theeLNS 
~lgorithm which uses preliminary information V / Y ) to determine the stopping condition the Improved 
LNS (ILNS) algorithm. Performance of both LNS and ILNS will be presented in Section 4.4. 4.8. Double 
Sampling and Our Approach In Double sampling, a sample is taken in two steps [Cox 52, Coch 77]. Cox [Cox 
52] has shown that double sampling has a performance close to that of the optimal sequential sampling 
method, if exists. Another advantage is the reduced overhead, because a required sample is taken in two 
steps, rather than m steps as in a regular sequential sampling method (including adaptive sampling), 
where m is the sample size. In the first step of double sampling, a sample of size, say, m ~, is taken 
to obtain a preliminary infor­mation about the mean and variance of the popula­tion. Based on this preliminary 
information, the required sample size, say, m, that guarantees that the estimate meets the precision 
requirement with a certain confidence level is computed. In the second step, additional (i. e., m ml) 
sample units, are taken, and the final estimate is produced. Note that the first step sample is not only 
used to provide prel­iminary information, but it also constitutes a part of the final sample of size 
m. An SJI-expression with n operand relations rl~ ...! r~ ! is modeled as an n-dimensional point space 
in our point space model with points having values O and 1. The urn model (which is one-dimensional) 
can be considered as a simpliEcation of the n-tlmensional point space model by merging n 1 dimensions, 
say r2~ ...7 rn. Here, by merging n 1 dimensions we mean that all the points which have the same value 
for r ~ coordinate, regardless of their r2, .... and rn coordinate values, are merged into a single point 
(which then becomes a ball of the urn model). Each point after the merge (i.e., a ball) has as its value 
the sum of the values of the set of original points in the original n-dimensional space. There are some 
differences worth mentioning between the point space model and the urn model. (1) In the point space 
model, sample tuples can be drawn from any or all of the relations while, in the urn model, sample tuples 
can be drawn only from a single relation. (2) The values of points in the point space model can be obtained 
simply by evaluating the SJI­expression using sample tuples as input without using index files on the 
join attributes. In the LNS approach, the value of a ball has to be obtained using index files. Index 
files are used to provide fast access to the entire relations. There­fore, from a sampling point of view, 
using index files of rz, . . . and rn is equivalent to using entire relations rz,  . and rm as samples, 
as far as the sample size (in terms of points) is con­cerned. When index files are available, point space 
model can also take this advantage (by merging dimensions) just as LNS S urn model.  In order to compare 
the efficiency of different error-constrained algorithms on the same basis. Hereafter, in the remainder 
of Section 4, we will assume that the urn model (a special case of the point space model) is the underlying 
model. That is, sample tuples (i.e., the balls) are taken from a single relation in both the double sampling 
and the adap­tive sampling, and the ball values can be immediately determined using index files. In Figure 
4.1, we present the error-constrained algorithm using double sampling, revised to sample only from rl 
so that it can be compared meaningfully with the LNS algo­ rithms. 4.3.1. Determining the Sample Size 
For double sampling and ILNS algorithm, the database designer has to determine how to compute the first 
step sample size. It can be determined based on precision requirements, experience or, simply, using 
a fixed number. For simplicity, we assume that the DBMS always chooses 100 tuples from r ~ as the first 
step sample size for the comparisons in Section 4.4. When the error is specified as the coefficient of 
uariat ion @, defined as u ~ / Y, the formula for computing the tot al sample size m [Cox 52] is Algorithm 
Estimate-COUNT(E, e, 1) Input : E: an SJI-expression with n operand relations; e : a given relative 
error; 1: a given confidence level. output : an estimate of COUNT(E) satisfying the given error constraint. 
Var t : the abscissa of the normal curve that cuts off an area of 1 1 at the tails; xl : the first step 
sample size; y : sample mean of the first step sample; V2 : sample variance of the first step sample; 
 m : the overall sample size; $ : population size; Y : an estimate of COUNT(E);  Begin Determine and 
draw the first step sample of size ml from relation r ~; value, l~i~m,, for eachEvaluate y, (ball) sample 
tuple in m,; ;.~ {Compute the overall sample size m} if m > m ~ then Evaluate ad~ltional m rn, sample 
units as the second step else m := m,; %:= N yi / m;    ~~~,rn Return (~ (1 2(3)2)); { adjust bias) 
t End. Figure 4.1. COUNT Query Estimation Algorithm Using Double Sampling where m is the total sample 
size, m ~~: the sample size at the first step, V2, defined as ~,=, (y; 1)2 / ml, is an estimate of 
the population variance W2 from the first sample. We can rewrite equation (4.5) in terms of the relative 
error e and the confidence level I using equa­tion (4.3) as m = (1)2(1 + 8(1)2+% +:) (4.6) t ml e~ 
mlv Note that m m ~ is the additional sample units to be taken at the second step, if m > m,. When thk 
is not true, i.e., m ~ ml, it means that the sam­ple size is already large enough to obtain the required 
accuracy, and one can simply stop the process without going on to the second step and return the estimate 
from the first step sample result as the final result. Also one can see from equation (4.5) that, the 
larger the fist sample size m ~ is, the smaller the total sample size m will be, assuming m > m ~. The 
estimator Y becomes slightly biased; to adjust the bias, Cox suggests to take Y(I 2(e / t)z) as the 
final estimate for the size of the query, which is what the algorithm in Figure 4.1 returns. Please note 
the similarity between equations (4.4) and (4.6). That is, the first term in equation (4.6) is the sample 
size needed when the population variance and the mean are known (i.e., equation (4.4)), and the 2nd, 
3rd and 4th terms of equation (4.6) are the adjust­ment terms (i.e., the extra cost) for not knowing 
the variance and mean in an error-constrained environ­ment. That is, information about the population 
may help reduce the sample si%e. Cox [Cox 52] also provides another formula for computing the sample 
size when the population has only O and 1 values. Clearly, the point space model meets thk condition. 
The formula in [Cox 52], after some modifications as above, is written as (j (1-P,) 3 t2 ~. + +  (4.7) 
PI P1(l-P1) e2plml where p ~ is the proportion of the sample units having the value 1 at the first step. 
This formula gives a better performance (i.e., a smaller total sample size m) than equation (4.6) when 
the population has only O and 1 values, wKlch is the case in the point space model. However, equation 
(4.6) is more general, and can be applied to both the point space model and the urn model. The estimator 
is also slightly Iiased. To reduce the bias, Cox [Cox 52] suggests to take N(p (Z)zp / (1 p)) as the 
final estimate, where t  p is the proportion of the overall sample units with the value 1. We will use 
thk formula for our experi­ ments in Section 6. 4.4. Comparison of the Three Approaches In thk section, 
we compare the performance of the double sampling algorithm described in Figure 4.1 (i.e., we only sample 
from r ~) with LNS and ILNS algorithms. Since LNS and ILNS algorithms are developed for only select, 
join and intersection opera­tors, here we only consider these operators. 4.4.1. Select Operator Let us 
now consider the select operation, i.e., the query to be estimated is COUNT (ur (r)), where r is a relation 
with 10,000 tuples, and F is a selection formula, Note that, for a single select operation, the point 
space model and the urn model are exactly the same, i.e., each point or ball has only the value O or 
1. We have chosen the selectivities to be 20% (i.e., 0.2) and 50% (i.e., 0.5) for the comparison that 
fol­lows. In Table 4.1, we list the sample sizes (i.e., the number of input tuples) needed to obtain 
an estimate withki an error of 10% (i.e., e = 0.1) with different confidence levels of 0.8, 0.9, 0.95 
and 0.99. First, let us consider the figures under the column Reference sizes n. For a opulation with 
the ~ selectivity of 0.2 (i.e.. variance u = 0.2 0.8 = 0.16 . ,, ), the required sample size is (w) 
U = 655 0.04 for a 80% confidence level (f = l ~~). Now let us consider LNS algorithm, For the select 
operation, b is equal to 1 in the stopping condi­ 71 tion y > kl . b : (l+l). With the same error con­ee 
straint, on the average, 1430 sample tuples are required for a population with selectivity 0.2. The sample 
size is obtained as follows. For a 0.8 confidence level, k ~ = 2.6 from the table in [LiNa 90b]; for 
a 10% error, e = 0.1; thus, y has to be larger than 2.6 . 10 11 = 286. Since the selectivity is 0.2, 
the expected sample size is 1/0.2 286 = 1430. The expected sample sizes are listed under the column 
LNS sizes n. As for ILNS algorithm, as well as for double sampling, we have assumed that preliminary 
infor­mation is obtained from 100 sample tuples: OnA the average, from the first 100 sample tuples, V 
/ Y = 0.2 -0.8 / 0.2 = 0.8 (< b =1 in LNS algorithm) for selectivity 0.2; and thus for a 10% error and 
a 80% confidence, the expected sample tuples in ILNS algo­tithm would be 0.8 1430 = 1144. As for double 
sampling, with a sample size of 100 at the first step and selectivity 0.2, the average sample selectivity 
at the first step is 0.2, With a 10% (e = 0.1) error and a 80% (~ = ~~~ confi~e:;e level, the overall 
sample size m is (~)z (L) .,. 2 (1+ 8(W)2 + 0 16 + ) = ~5; + 33~26 1.28 1000.22 100 +13 = 727. Note that 
the first term in equation (4.6) is exactly the same as the equation (4.4), which is the required sample 
size for a situation where the variance and the mean of the population are known, The second, third terms 
can be considered as the extra cost for not knowing the population variance and mean. In the example, 
the extra cost is around 10% higher than the sample size from equation (4.6), and is much smaller than 
those for the LNS and ILNS algorithms. 4.4.2. Join Operation Let us consider the join operation Counter 
ItXr2) Assume that both r, and ra have 10,000 tuples, For simplicity, we also assume that there is a 
single join attribute with a domain of integers between 1 and 10,000. Selectivity = 0.2 confidence 
Reference LNS ILNS Our level sizes sizes sizes sizes 0.8 655 1,430 1,114 727 0.9 1,082 2,090 1,672 1,179 
0.95 1,537 2,750 2,200 1,661 0.99 2,652 6,100 4,880 2,843 Selectivity = 0.5 confidence Reference LNS 
ILNS Our level sizes sizes sizes sizes 0.8 164 572 286 177 0.9 271 836 418 287 0.95 384 1,100 550 404 
0.99 663 2,684 1,324 691 II Error e=lO% Table 4.1. Sample Sizes Required for the Desired Error Bound 
For the Select Operation. We have arbitrarily chosen to use normal dk­tributions for the values of balls 
to compare the efficiency of different algorithms, since normal distri­butions have been claimed to be 
close to real life &#38;k­tributions. For the following comparisons, we assume that each tuple in rl 
has a distiict join attri­bute value between 1 and 10,000; and the join attri­bute values of rz have 
a normal dktribution with mean 5,000, and variances 2502 and 1,0002, respec­tively. Each tuple t in rl 
corresponds to a ball in the urn, and the ball has as its value the number of tuples in rz that have 
the same join attribute value as t; thus values of balls have a normal distribution. The total number 
of output tuples of rllxrz is 10,000. That is, the population mean (i.e., the aver­age value of the balls) 
Y is 1. Based on 100 indepen­dently generated normal dktributions for the join attribute values with 
variances 2502 and 1,0002, the variance of the ball values are, on the average, 11.276 and 2.818, respectively; 
and the average b values are 27.84 and 11.76, respectively. Please note the Mference between the variance 
of the join attributes values (i.e., 2502 and 1,0002) and the variance of the ball values (i.e., 11.276 
and 2.818). Corresponding to the above two distributions with ball value variances 11.276 and 2.818, 
there are about 1270 and 3700 balls (out of 10,000), respectively, having non-zero values, i.e., we do 
not deal with the cases where very few balls have non-zero values. Also, the former popula­tion has a 
sharp peak than the latter one. Consider the normally dktributed ball values with variance 11.276. For 
a given relative error of 10% (e = 0.1) and a confidence level 0.8 (t = 1.28), the expected sample sizes 
are obtained, for example, as follows. The Reference sizes 9 is (;)2 (~ ) = 1847 from equation (4.4). 
We assume that, in LNS algorithm, the lowest upper bound for the ball values, i.e., b, is known in 11 
the stopping concMion y > k, b ~ ~ ( + 1). Note that thk information is usually un~now; and is not needed 
in the double sampling algorithm. When b is unknown, the sample size will be larger than the figures 
listed in Table 4.2 depending on how much larger the guessed b values are. With the same error constraint 
and the assumption that the b value is known, the y value has to be larger than 2.6.27.84.10.11 = 7962. 
Since Y = 1, the expected sample size is 1 7962 = 7962. As for ILNS algorithm, the average $(~) / ? 
are 11.276 / 1 (compared to b = 27.84 in LNS) and 2.818 / 1 (compared to b = 11.76 in LNS) for the two 
normal dktributions, respectively. Therefore, the expected sample sizes for a 10% error and a 80% confidence 
level for the same population is 7962 . (11.276 / 27.84) = 3225. As for double sampling, the expected 
sample 1.28 size, for the same error constraint, is ( )2 0.1 11.276 . (1+8(W)2 + u + + ) = 2183, 12 
1.28 100.12 100 w~lch is much smaller than 7962 and 3225 required for the LNS and ILNS algorithms. Variance 
= 11.276 Confidence Reference LNS ILNS Our levels sizes sizes sizes sizes 0.8 1,847 7,962 3,325 2,183 
0.9 3,051 11,637 4,713 3,546 0.95 4,332 15,372 6,226 4,997 0.99 7,477 37,361 1,5132 8,559 Variance = 
2.818 Confidence Reference LNS ILNS Our levels sizes sizes sizes sizes w 806 507 1,178 822 1,550 1,157 
3,769 1,981 Error e=lO% Table 4.2. Sample Sizes Required for the Desired Error Bound for the Join Operation. 
4.4.3. Intersection Operation Though the intersection operation is not dis­cussed in [UINa 90 b], it 
can be easily modeled by the urn model or the point space model [HoOT 88, HoO z 88]. To model r ~(l rz 
in the urn model, each ball corresponds to a tuple tin a designated relation, say rl. A ball has a value 
1 if the corresponding tuple t is also in rz; otherwise, the ball has a value O. Clearly, as far as the 
urn model is concerned, inter­ section is exactly the same as selection. Thus, Table 4.1 can be used 
as a source of comparison for inter­section operations producing 2,OOO and 5,000 output tuples. 5. Improvement 
Using Simple Random Sampling Without Replacement  In the dkcussions of Section 4, all the samples are 
taken with replacement (i.e., simple random sam­pling with replacement). From the tables, in many cases, 
the sample sizes can be very high, i.e., close to or even more than the population size. When the population 
size is not very large compared to the sample size, a better choice is to use simple random sampling 
without replacement. Simple random sam­pling without replacement may reduce the sample variance U: by 
a factor of N m / N 1 (wVlch is . called the finite population correction), and thus, may reduce the 
required sample size. When N is large, N 1 = N. Let us consider the equation (4.2). If simple random 
sampling without replacement is used, equation (4.2) should be written as (5.1) TO simplify the equation, 
let S2 be ~~~,N(y; ~) / N 1. And then, the equation (4.4) will be ~ = p) + ;(:) ) (5.2)   /( 1 ey 
e We now consider an example to see how sim­ple random sampling without replacement can affect the efficiency. 
For a 10% error and a 99% confidence level, the required Reference sizen for simple ran­dom sampling 
without replacement is 7,477 / 7,477 (l+ ) = 4278, which is much smaller than 10,000 7,477 from Table 
4.2. Similarly, one can use the sim­ple random sampling without replacement as the underlying sampling 
method for double sampling, and rewrite the equation (4.6) by first replaci?~~the U2 by (N-m) s /N, where 
s is defined as ~i=l (gi-~) / (m 1), and then solving for m. As for equation (4.7), whkh is the formula 
for a population with values only O and 1 (e.g., the point space model), one can replace the term (1 
p J (more accurately, the term PI (l PI)) by ((N m) / N) (l PI), where N is the population size (i.e., 
the number of points in the point space) and m is the overall sample size. To simplify the equation for 
the sample size rn, let the first, second and third terms of equation (4.7) be z 1, X2 and ZS~ respectively. 
BY solving the following quadratic equation, m can be obtained. where N is the population size, i.e., 
the number of points in the point space. Equation (5.3) gives a tighter bound on the sample size than 
equation (4.6), and is implemented in CASE-DB, the prototype DBMS. 6. Experimental Results Double sampling 
and adaptive sampling are incorporated into two database management systems, called CASE-DB [HoOT 89] 
and CASE-MDB [Liu 89], for error-constrained COUNT query estimation purposes. CASE-MDB is a main memory 
version of CASE-DB wKlch is a disk-resident, real-time (or time-constrained) prototype database management 
system. Double sampling implemented in CASE-DB and CASE-MDB uses simple random sampling without replacement 
(SRS) and systematic sampling (SS) (as well as other sampling techniques such as cluster sampling) to 
draw sample tuples. Due to space limitations, in this paper, we present the exper­imental results for 
double sampling on single select, join and intersection operations in CASE-MDB. Estimators for projection 
operations and experimen­tal results for arbitrary relational algebra expressions can be found in [Dogd 
90]. 6.1. Design of Experiments Instead of using the number of tuples as a measure of the sample size, 
we choose to use the samp­ling fraction ~ as the measure, wKlch is defined to be the ratio of the number 
of tuples to the total number of tuples in a relation. Furthermore, for the double sampling approach, 
equal sampling fractions are drawn from all the input relations, not just from r,. Recall from Sections 
2 and 4.3 that, in the point space model, sample tuples are drawn from (some or) all of the operand relations 
and no index files on join attributes are needed. Experiments are performed on relations with 10,000 
tuples each, and each data value in the tables of this section is obtained from 200 experiments. The 
experiments have been designed to sbowj for a given confidence level (here always 95%) and different 
relative error limits (e.g., 2%, 5%, 10%, etc.), the actual errors, confidence level and the required 
sample sizes for different sampling tech­niques. In the tables, the column f% gives the aver­age sampling 
fraction from each input relation. The column e% gives the average of actual errors observed during 200 
runs, wldch is to be compared with the specified error limit. And the column 1% gives the ratio of the 
number of runs in which the relative errors are found to be less than or equal to the specified error 
limit e, which is to be compared with the specified confidence level 1 (in this section, always 95%). 
(N+z,)m2 -(N + 2Nz, + Nz,)m 6.2. Creation of Input Relations + (Z1 + Z2 + Z3)N2=0 (5.3) Each input relation 
has two attributes, both with integer values. The first attribute contains Given SRS Adaptive Samplingunique 
random numbers to dMerentiate one tuple Error unordered/ordered unordered/ordered Ifrom another. The 
second attribute is the one of f% e% 1%f% e% 1%j interest in the query, i.e., the attribute involved 
in the selection formula or the join attribute. To 2% 80 1 97 100 0 100 observe the effect of the distributions 
of attribute 5% 39 2 951000 100 values, we have experimented with relations in which 10% 14 4 96 28 3 
100 second attributes have either a uniform or a normal 20%4897 85 98 J E chstribution. To observe the 
behavior of the double sampling using Wferent sampling techniques, we have also run experiments with 
relations in wKlch tuples are ordered with respect to the second attribute. Hereafter, we use ordered 
and unordered relations to dMerentiate relations with ordered and unordered tuples, respectively. 6.3. 
Experiments on a Single Selection and Join Operations 6.3.1. Selection Operation I he experiments are 
performed on a selection operator with selectivities 0.2 and 0.5. The sampling fraction used in the first 
step is always 2% of the total relation (i.e., j = 2% or 200 tuples here). As far as the COUNT estimator 
is concerned, either a tuple satisfies the selection formula or it does not; the actual attribute values 
are not important. Therefore, we do not discuss the distributions of attribute values for the selection 
operation since they will not affect the performance [HoOT 88]. For simple random sampling (SRS), the 
storage ordering of tuples in a relation has no effect on the performance because every tuple has an 
equal chance to be selected into a sample, and every combination of m tuples has an equal chance to be 
selected as a sample. Thus, by definition, any sample of size m randomly taken is a simple random sample, 
regardless of the storage ord­ering. However, the storage ordering has a significant influence on systematic 
sampling. In sys­tematic sampling, not every combination of m tuples can be drawn. When a sample is a 
good representa­tive of the whole population, the systematic sampling gives a precise estimate; otherwise, 
it gives a bad estimate. Thk phenomenon is observable in tables 6.1 and 6.2. The f% columns give the 
average of sampling fractions for different relative errors (e.g., 2%, 5%). For simple random sampling 
without replacement, these values are quite close to the expected values computed from equation (5.3). 
For example, for a 10% relative error and a given 95% confidence level, the experimental average size 
is 14% for selectivity 0.2 from Table 6.1, and the computed value is also 14%. Also, the confidence levels 
(i.e., 1% columns) are quite close to the specified confidence level 95%. This means that double sampling 
on top of simple random sampling without replacement behaves exactly as the formula (5.3) specifies. 
Given Error I Systematic unordered Sampling ordered f% e% 1% f% e% 1% 2% 50 2 0 50 2 0 5% 38 4 83 38 
49 6 10% 14 4 91 14 10 51 20% 4 8 98 48 100 I I Selectivity == 0.2 Table 6.1. Select Operation with 
Selectivity of 0.2. Given SRS Adaptive Sampling Error unordered/ordered unordered/ordered f%e% 1%f% e% 
l%_ 2% 49 1 961000 100 5%1429442 1100 10% 4 4 97112100 20% 2510035100 Given Systematic Sampling Error 
unordered ordered 1 f% e% 1%f% e% 1% 2% 48 1 9449 1100 5% 13 2 98133 80 10% 449741 100 20% 26 100 20 
100 Selectivity = 0.5; Table 6.2. Select Operation with Selectivity of 0.5. For systematic sampling 
(SS), only a limited number of possible samples can be drawn. For exam­ple, if the sampling fraction 
is 10%, there arc only 10 possible samples cafi be dra~~. A typic~l sample may consist of the k ,k+lo 
, k -t 20 , , tuples, where k has only 10 possible valnes, 1~ks 10. Therefore, the precision of an estimate 
is determined by a limited number of underlying samples. We have chosen to use a cut on the sampling 
fraction at 50% when the sampling fraction is larger than 50% for systematic sampling. When the relation 
is unor­dered, tuples are (more or less) randomly distributed. Therefore, in general, the results for 
systematic sam­pling should be similar to simple random sampling. Of course, whether this similarity 
occurs or not depends on how the underlying samples are con­structed. Thk explains why in the case of 
systematic sampling there are cases with 1% values much lower than 95% and others with 1% values quite 
close to those observed in simple random sampling. When the tuples are ordered, it is possible that at 
a certain sampling fraction, the underlying sam­ples have exactly (or almost) the same selectivity as 
that of the entiie relation while for some other sam­pling fractions, the underlying samples are not 
good representatives of the population. This explains why in tables 6.1 and &#38;2 there are cases where 
the esti­mates are very precise while in others the estimates are very bad. We now compare f% columns 
for double sam­pling (using simple random sampling) and adaptive sampling. Clearly, sample sizes for 
double sampling is much smaller than adaptive sampling, for the same given error constraint. Note that 
adaptive sampling has a higher confidence level, w~lch is Elgher than the required 95% and considered 
unnecessary. Thk is due to unnecessarily large samples obtained from adaptive sampling.  6.3.2. Join 
Operation Experiments are performed on a join operation producing 72,750 output tuples, i.e., selectivity 
= 72,750/10,0002 = 0.00073 with operand relations having 10,000 tuples each. We assume that the first 
step sampling fraction is 5% from each relation, and there are no index files available. With 500 tuples 
drawn from each operand relation, one can construct 500 independent sample points, or 5002 correlated 
sample points in the point space [HoOT 88, HOOZ 88], in which each point corresponds to one pair of tuples 
from dMerent operand relations. Clearly, with the same effort, the latter tremendously cuts down the 
cost of sampling, and thus is adopted in CASE-DB and CASE-MDB. Note that even though the sample tuples 
are drawn randomly, the sample points are no longer independent. The experimental results in [HoO z 88] 
have shown that the introduced correla­tion does not have a severe effect on the performance of the estimator. 
Also note that a 5% sample frac­tion from each relation corresponds to a s~mple of 0.25% (i.e., 0.052) 
of the point space. Consider the point space of a join operation r ,(X Irz. The number of points with 
value 1 on the same row (or the same column) represents the number of tuples produced by a tuple in, 
say, r ~ and the entire relation r2 in the join operation. If the join attribute values are not uniformly 
dktributed, each row/column will have different number of points with value 1. Since sample points are 
no longer independent] y drawn, the dktribut ions of join attri­bute values, and thus the distributions 
of points with value 1, will have an effect on the precision of esti­mates. This explains why a better 
performance is obtained from relations with join attribute values uniformly distributed than from normally 
distri­buted, since the points with value I is more evenly dktributed over the point space when the join 
attri­bute values have a uniform dktribution. Since the sample points are correlated, larger variance 
in estimation may be obtained compared to a sample with independent points of the same size. However, 
the effects are not severe in our empirical evaluations. As for systematic sampling, when the relations 
are not ordered, the results are close to those with simple random sampling, as explained in the selection 
operation. When the relations are ordered, there are some estimates that are very high and some that 
are very low. Systematic sampling applied to ordered tuples in join operations tends to give a large 
vari­ance in estimates. As we explained earlier, thk phenomena is due to having limited number of under­lying 
samples for systematic sampling. Given SRS Ss Error unordered/Ordered unordered ordered f% e% 1% f% e% 
1% f% e70 1% 2% 39 1 99 39 1 100 39 16 12 5% 19 1 99 19 1 98 19 5 53 10 % 10 3 100 10 2 100 10 3 99 20 
% 5 6 100 56 100 56 100 Selectivity = 0.00073 Table 6.3. Join Operation with Join Attribute Having 
Uniform Distribution. Given SRS Ss Error I unordered/ordered I unordered ordered f% eYo I% f% e%1% f% 
e70 1% 2% 38.7 1 92 38.7 1 9938.8 29 0 5% 18.5 2 92 18.5 2 %718.5 8 5 10% 10.3 4 97 10.3 3 9810.3 7 91 
20% 5.0 8 95 60 6100 5.0 3 100 Selectivity = 0.00073 Table 6.4. Join Operation with Join Attribute Having 
Normal Distribution. 6.3.3. Intersection Operation Intersection operation can be considered as a special 
case of the join operation in which all the attributes (or the key attributes) are joinm attri­butes, 
with probably a low selectivity. In order to guarantee that we have some points with the value 1, we 
take a higher first step sampling fraction (10%) than in the join operation. Each row or column has at 
most one point with value 1, Here! we do not have to discuss different distributions of njoin m attri­bute 
values, since each join! attribute value is unique in a relation. Systematic sampling has a poor performance 
especially when tuples are ordered. Given SRS Ss Error unordered/ordered unordered ordered f% eYo 1% 
f% e% 1 %If% e% 1% 2% 100 0 10050 2 40 39118 0 6% 76 1 99 60 210019159 0 10 % 50 3 98 48 4100 11108 0 
20% 30 6 99 30 7 85101880 First Stage Sampling Fraction = 10% Table 6.5. Intersection Operation with 
2,OOO Output Tuples. - Given SRS Ss Error I unordered/ordered I unordered ordered f% e% 1% f%e%1%f%e%1% 
2% 91 0 100 50 248391180 6% 57 1 100 50 2100 18145 0 10 % 35 3 100 35 16 38 10183 0 20% 20 5 100 20 994101830 
First Stage Sampling Fraction = 10% Table 6.6. Intersection Operation with 5,OOO Output tuples. 7. Conclusions 
We have presented a double sampling-based COUNT(E) query estimation approach that guaran­tees a desired 
error bound with a 8pecified confidence level. The estimates is unbiased and consistent, and performs 
very well with simple random sampling without replacement as the underlying sampling plan. We have also 
presented the experimental results we performed on our prototype DBMS called CASE-DB. We have also implemented 
and compared another error-constrained COUNT(E) estimation approach, the (I)LNS algorithms based on adaptive 
sampling. Given an error constraint and a confidence level, the LNS approaches determine whether or not 
an additional sample unit is to be taken by observing the number of sample output tuples. We have shown 
that these approaches perform, at least under the assumptions we have te8ted, worse than the double sampling 
we propose. Also, there are some problems that remain to be solved with the adaptive sampling approach, 
e.g., the bias of the estimator for the size of the Select-Join(-Intersection) query, w~lch is denoted 
by n .slm in [LiNa 89, LiNa 90, LNS 90]. Note that the estimator n s/m is basically the same as the one, 
denoted by Y, in [HoOT 88, HoOT 89]. The estimator is unliased when the sample size is prefixed; however, 
it may become biased in an error­ constrained environment [COX 52, Coch 77]. The magnitude of the bias 
in the estimator, which depends on how the sample units are taken (e.g., checking the number of output 
tuples and then decid­ing whether an ad&#38;ltional sample unit is to be taken -this is actually how 
the bias is introduced), needs to be worked out. More importantly, if the magnitude of the bias is unknown, 
the confidence levels will also be inaccurate. 8. References w. Cochran, !! Sampling Techniques! , Third 
 [Coch 77] Ed. John Wiley &#38; Sons, 1977, [Cox 52] D.R. Cox, Estimation by double sampling!!, Biometrika, 
39. [Dogd 90] E. Dogdu, Experimental results on Double samplingfl, Unpublished Manuscript, CWRU, 1990, 
[HOOT 88] W-C. Hou, G. Ozsoyoglu and B. Taneja, Statistical Estimator for Relational Algebra Expressions 
, ACM PODS, Austin, TX, 1988. [HOOT 89] W-C. Hou, G. Ozsoyoglu and B. Taneja, Processing Aggregate Relational 
Queries with Hard Time Constraints , ACM SIG- MOD, Portland, OR, 1989, [HoOZ 88] W-C. Hou and G. Ozsoyoglu, 
Statistical Estimator for Aggregate Relational Algebra Expressions , to appear in ACM TODS, sub­mitted 
1988. [LiNa 89] R. Lipton and J. Naughton, Estimating The Size of Generalized Transitive Closures , the 
15th VLDB Conference, Amsterdam, The Netherlands, 1989. [LiNa 90] R. Lipton and J. Naughton, Query Size 
Esti­mation by Adaptive Sampling , ACM PODS, 1990. [LNS 90] R. Lipton, J. Naughton and D. Schneider, 
!Ipractical Selectivity Estimation through Adaptive Sampling ! , ACM SIGMOD, 1990, [Li 89] Liu, Y-M 
., A Main Memory Real-Time Data­base Management System--Implementation and Experiments 11, MS Thesis, 
CWRU, July 1989. [Sukh 84] p, Sukhatme, etc.,, Sampling Theory of Sur­ veys Applicationfl, Third Ed., 
New Delhi, India and Iowa State Univ. Press, Ames, Iowa, 1984. !Iseq ential Tests of Statistical [Wald 
45] A. Wald, Hypotheses , Ann. Math. Stat. Vol 16, 1945. [Yama 67] T. Yamane, Elementary Sampling Theory 
! , Prentice-Hall, Inc , 1967.  
			