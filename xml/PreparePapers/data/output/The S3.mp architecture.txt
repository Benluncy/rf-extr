
 The S3.rnp Architecture: A Local Area Multiprocessor A.Nowatzyk, M. Monger, M. Parkin, E. Kelly, M. 
Browne, G. Aybay Stm Microsystems computer Corporation (SMCCI D. Lee Xerox Paio Alto Research Center 
(PMC) Introduction The S3.mp prototype system is being irnplentented by SMCC S Technology Development 
group to demonstrate a low overhead. high throughput communication systan tltat is based on distributed 
shared memory (DSM). Conceptually, S3.mp is a virtual bus­extertder that preserves the semantics of accesing 
memory across alt nodes. Unlike multiprocessor busses that use broadcast$tg to preserve memory coherency, 
S3.mp uses directories and #xrqt-to­point messages over a packet switched interconnect abrlc to achieve 
scalabfity over a tie range of system cordigurations. communication technology advances, such as high 
speed fiber optics, are the driving force behind the S3.mp develcpmen~ While it is technically easier 
to utilize the increasa.d bandwidth with con­ventional DMA devi=, the resulting message passing hardware 
re@res substantial software overhead to process protocol stacks, manage bufkxs, encode apd decode messag=y 
etc. In S3.mp, com­munication happens as a st&#38;-effect of accemng memory a single store or load instruction 
is sufficient to send or receive data. The set of transactions that are required to support the DSM paradigm 
is small and well delined w that the S3.mp protocols were amena­ble to formal verification methods and 
are implemented directly in hardware. S3.mp systems are similar to ALEWILE, DASH, PLUS and other nonuniform 
memory access multiprocessors. However untike th= conventional NUMA MPs, wtuch strive to det.iwx the 
most IvfFtops to one.scientdic application, S3.mp is optimized for a large collection of independent 
applications that share common comptttin resources which maybe spatially distributed. Conse­qtrently, 
$ 3.mp nodes maybe separated by up to 200m, which mean that a S3 .m s stem could be distributed over 
an entire building. Essential{ y, 3.mp systemsare build by adding a special­LzJirti:hcoutect controller 
to the memory subsystem of a norrnat FIGURE 1: S3.mp System Overview Workstations suitable for S3.mp 
must have a coherent process­ or/ memory intercomtect system. The current implementation is based on 
the Mbus. which M used in the SparcStation 10 series. Each node may have se~eral processors, each equipped 
with caches that are kept consmtent via snooping. When a processor accesws a remote memory location, 
the S3 .mp memory controller translates the bus transaction into a message that is send to the remote 
memory controller, which repties with the data attd which maintains a directory of externaUy cached blocks. 
S3.mp s interconnect controller is part of a distributed switch that is opdrnized for rhe fine grain%, 
trregular traffic of a DSM system. There is no nmd for a cenfraltzed switch, rathcx each node comes with 
a number of high speed tinks to umnect to other nodes. Hence the interconnect fabric grow incrementally, 
as nodes are added to the system. Because the S3.mp architecture allows spatial distribution it must 
address a nuxrtbez of issues that are of lesser concern to con- Permission to copy without fee all or 
part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appaar, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permksion. ACM-SPAA 93-6/93 /Velen,Germany. @ 1993 ACM 
0.89791 .599.2 /93/0006/0140...$ 1 .5r) ventional NUMA machines o ~~ m comwttopologyis subject to external 
constmittta, so tlrat the intercmnect ccotrolk musl be able to deal with arbitrary topologies. Faolt 
tolerance is importmt to some S3.mp coofiguratioas, which requires barrtwam sapprt to manage and prvtect 
mutdple address spaces. This ad-trsnshdoo mechanism snows to rao maf.dple, ~@ -g SWE=U 00 ous S3mP ey-m­ 
* S3.mp must have facilities to dynamically change the system cOotigu­ration, add w remove nedea. e S3mp 
compomnts must be remotely controllable, so that ttre entire system can bemsintaird fromasinglepoint. 
S3.mp support real-time aud multimedia applications by pro­viding support for global synchronization, 
precise clock distribu­tion, mukicasting, and prioritized bandwidth allocation.  The S3.mp Processing 
Element 5(EK gates each that are d-i module. The memory controller the ?ogic to translate between memo 
@nssction ad rnes­saggs send to remote nodes. The T#C is also inchargeof maintaining memory cohere .The 
TMCiscOrmectedto two processors through the %76 us. The TMC is also con­=~~titv~mtercomect controller 
(TIC) chi s), rconnect network logic (router, $uff­ers, link protocol engines, etc.).  of approxunately 
hs mpn*misE f2sm~;~o:%~&#38; . FIGURE 2: A S3.mp Node .... ................. . . ......... .... :Cp 
l #cp 2# .:,,$,.,.. :,:::.,.:....:,,,. :. W.:.,.,.,:.,.,.::::.::,.,:::..., -:, :;: ., ,.:,:::.,:, x,:,.,,,:.,,,,,:,:,:.:,:,. 
. . ,:,.:::.;,:: .. . . . $:.~~ : ~; Muiti Chip Mod@ :TI :TMCZ .::::::::: 2.rxl.!7x022&#38; :,. .. 
.,.:..,:,.::.: . . . . . . . . ...<..... . . .. . . a­ .... 4 (8) High Speed &#38;rid Links The-rMcis&#38; 
todiredydrivea~hfb mem­ory array that uses 1P b@it devices with a high ormance 2 interface. Integrated 
mto this memory array is a small amount of ex.~a storage to hold a directory struetyre that is collocated 
with the actual mam memory. Operating on 32 byte block, each b@ck uses 32 bits of dkctory information 
artd32error detwtwnandcorrectionbitstha talsocovwthe dil-ec &#38;%C chi suppmt.s 4 foil duplex, serial 
point to point communication %nka,eachcapableof sen~andrecewing at a sustained rate of 100 Mbytes/sec. 
The C chip imple­ments an adaptive, virtual ctlt-~;%m$%$sz%zg %z%F&#38;V&#38;E\::k:ti&#38;k$=&#38; are.integrated 
into the C chip and do not require external Sermhzers. l%e TIC can interface directty with fiber-optic 
trans­ ceivers, which are used if the link tength exceeds 10m. Two CPU chips (each with on-chip caching), 
a TIC, a TMC, and 64 Mbytes of memory are integrated in one mukichip mcdttte. This tight integration 
is possible because the entire computing node require-s only 4 chips plus memory, which fit into one 
match­ box sized building block that is a fully functional multiprocessors with 2 CPUS, each delivering 
alxmt 50/63 irrteger/fioating point specmarks, thathas more than 200 Mbytes/w of I/O bandwidth. The raw 
TIC I/O bandwidth is %(KI Mbytes/see, but depeding on system size and actual topolo~, it is expected 
that there is a signif­ icant transient traffic load. The Mbus of each S3.mp node is can be connected 
to 140 other devices, which is the primary facility to attach I/O devices to the system. In articdar, 
it is possible to plug a S3mp module into any d us slot (for example into a Spare statkm 10Wdataticm). 
 The S3.mp Interconnect System Unlike the intemmnection networks of other sqdable multiprogxsors that 
use a s cfic topology (typically *, sorhypemubes),&#38; S3mpsystemhas nopm­ferred topo? ogy, rather it 
explores the actual intercomect network whenever nodes are added or removed from the system. An off-line 
recess com utes the routing tables which are then load J into each 1? C. It is possible to add/ remove 
nodes and/or change the interconnect to ology whale other arts of the systems ~ opeqtmg nOrmal The T 
K?router uses an adaptwe routing strategy. L the cqe of the TIC is aocommon b@fer 1that:s=dl .4 links, 
each $ whwh haye loge r yin ters and receivers. Recavers accept T pac etq, verify their integri~ (CRC 
codes are used to ensure a I@ de ee of robustness), and deposit them into the buffer area. &#38;lcur­rently, 
the tranarnitters retrieve pdret from t@ buffers and send them to other nodes. Bufie~ and trananutters 
are all­cated based on packet e load. Each TIC IScapab Y e XE&#38;$H!G:;s:E continuously. The node traversal 
lateq is between 100 and 200 nsec, which only slightly more than one packet trans­mis&#38;mntice. One 
o! two TICS can comect to each TMC. 4 levels of priority such that higher priority trafii=block by congestion 
at a lower prior­ity level. Two levels of priorities am requid to enswe that the memory ~herency mechanism 
is deadlock free. The levels are used to su port time critical =+AP!7 ? or example video or-au-$ o trafiic). 
While the S3.mps stem can be &#38;stnbuted over a large area, it operates isoc IL onously. Since outbound 
traffic IS encoded with the system clock of the originadng node, and since each receiver must recoveq 
this clock m order to decode the in@und traffic, each par ofpodes @t are con­ Fm$,b&#38;;iFtimF?$S~&#38;=pLY~G~~7S 
all system clocks. As a consequence, all nodes ymd and recewe tra.fiic at exactly the same rate, which 
sunpliiies flow catrol. Other advantages of this method include the abWy to have a high resolution clock 
that is visible to all nodes and to have precise delays for each channels (which am used to compute the 
routing tables). Theisochronicity isalsoused inthedesign of theclum­nel protocol, which treats each link 
a conveyor belt with a know inte al number of acket slots. This allows a pi ­@ackhan&#38;ake protocol&#38;atdoesnotneedtorefertot&#38; 
actual packet, rather the aglmowledge bit is associated with the sent packet simply b Its tune-slot. 
This is one examples of themeaaureauaedm 3m toincrease tberatioofusable bandwidth to total bandwld~ k 
. Up to 66% of the physical media bandwidth is delivered to the a plication, wluch is competitive to 
conventional networ E protocols. which a@ieve @s level of efficiency @y for very.large message sines, 
whale S3.mp operate with t.lus efficiency even on highly irre ar, h grained traflic. Psummarizes performance 
for ran- The tab e below the TIC domly generated Iogim and random accessto remote memory. The bandwidth 
anT latency for 1 (2) TIC configurations below IS the effective Dwformanc8 asseenbv an aooiicstion. Number 
of nedea Bandwidth / node Remote acccm latency 2 <406 (C812) MB/s* 0.s4 (0.84)M 8 112 (313) MB/s 1.8(1 
.4)jIs 32 63 ( 194) Mllh 2.8 (1.0) w 128 43 (144) MB/s 3.8 (24) ys 512 32(117) MB/s 5.0(2.7) y9 1, 1024 
26 (%) . MB/S / ., 1 . 6.1(3 .l)u.s 1 * : Limited by TMC ~f~mm  The Memory Controller By inte sting 
the interconnect interface into the mem­aycul &#38;oF er, remote refenmcea do not need to traverse the 
local bustore*themainmemory ofanode, Italsohasthe advantage of integrating the directory structure into 
the main menmy. The memory c(mtroller reserves a programmable frac­ticmoftbmaiu memory andusestbiss qs 
a cdw for remote references. This inkmock cache% Lsrequimdto in@pde all locally cached bloclq of remote 
memory and is critical for an address compressmrt scheme that conserves bandwidth for control messages. 
One of the requirements fors aq~~disi$tisfg &#38; peed fm @dress space protection. ?hl Irttroductlon 
of an address translation mechaim . ,.that takes a local I@us memory transaction qnd transbs It mto a 
o­bal 64 blt address s ace, which M composed of a 18 bit node-ID Y refer­ and a 52 bl~ qcal address. 
Incunmg memory ences are handled smular to locally generated memory n3f­erences and are subject to address 
traqslatk l%is recursive address translation allow~ the spqctication of multicast trees that are embedded 
~to the interconnect topo@gy. These trees are used to rephcate memory to shadow cmtical data StIUCtlltt, 
to increase the read-bandwidth of COmLUOdy read data stmdures and to distribute v$ko or audio data S3.rnp 
supports memory replicahon as a way to cow with losing puts of the mam mermxy. ~ory repbcatmn is asymmetmc 
in the sense that all write transactions are directed at the master copy of some memory block. The memory 
controller of the master page sends updates to the slaved ages. Since the consistency mechanism uses 
a write invaii z te scheme, there is at most one node in thes stem thathas write permission andthatcan 
betrackedso tL tm case of a failure, the recovery process can quickly determine which memory blocks wexe 
stale. S3.mp System Configurations The S3.mp pr ocesaing element can be addd to Wveral existing Workstation 
platforms, adding p rocessors, memory and communi­cation capabilities. Interconnecting a number of workstations 
in this manner leads to a workgroup that can run shared memory applications. Clients of either cordiguration 
may use low end sys­tems with just one link in a starlike topology. H@ performance senwscanbe realizdbydensel 
sckingm system. A massively parallel ~fmp withfi~%~~~, ~$ Gbytes of memory and >20 GB/s I/O will fit 
in 1 ~ of space. Summary Theinnovations of the S3Jnp technology development project includes the use 
of DSM to reduce communication overhead. S3.mp allows spatial distribution of computa­tional resources 
while preserving the convenience and e5­ciency of using memory semantics to access them. Additionally 
this allows workstations and I/O nMources to be viewed as bvilding blocks that make up a salable isystam 
rather than a distributed collection of independent entities. Finally it hides the artifacts of adaptive 
routing, namely out of order delivery, by integrating it with a order insensitive coherency mechanism. 
141 
			