
 Proceedings of the 1999 Winter Simulation Conference P. A. Farrington, H. B. Nembhard, D. T. Sturrock, 
and G. W. Evans, eds. OPTIMIZATION VIA ADAPTIVE SAMPLING AND REGENERATIVE SIMULATION ´ Sigurdur Olafsson 
Department of Industrial and Manufacturing Systems Engineering Iowa State University Ames, IA 50010, 
U.S.A.  ABSTRACT We investigate a new approach for simulation-based opti­mization that draws on two 
recent stochastic optimization methods: an adaptive sampling approach called the nested partitions method 
and ordinal optimization. An ordinal comparison perspective is used to show that the nested par­titions 
method converges globally under weak conditions. Furthermore, we use those results to determine a lower 
bound for the required sampling effort in each iteration, and show that global convergence requires relatively 
little simulation effort in each iteration. INTRODUCTION In system optimization it is often desirable 
to optimize the performance of a system where the solution parameters are discrete and the outcomes are 
uncertain. This means that there is no analytical expression relating the discrete deci­sion parameters 
to the corresponding expected performance of the system. Such stochastic discrete optimization prob­lems 
have received considerable attention in recent years, and methods proposed for this problem include, 
for exam­ple, the stochastic ruler method (Yan and Mukai, 1992; Alrefaei and Andrad´ottir ottir, 1997), 
the method of Andrad´(1995), the stochastic comparison method (Gong, Ho, and Zhai, 1992), ordinal optimization 
(Ho, Sreenivas, and Vak­ili, 1992), the stochastic branch-and-bound (Norkin, P.ug, and Ruszczy´ nski, 
1996), and the nested partitions (NP) ´ method (Shi and Olafs-son, 1998a,b). Under certain con­ditions, 
all of these methods have been shown to converge almost surely to an optimal solution. For recent reviews 
of simu-lation-based optimization methods the reader can for example consult Carson and Maria (1997) 
and Andrad´ ottir (1998). In this paper we investigate the NP method from the perspective of ordinal 
comparison, which enables us to gain insights into the convergence of the NP method and proves that the 
ordinal nature of the method is indeed bene.cial. Leyuan Shi Department of Industrial Engineering University 
of Wisconsin-Madison Madison, WI 53706, U.S.A. Furthermore, we derive conditions for asymptotic conver­gence 
of the algorithm and provide practical guidelines for how to conduct the adaptive sampling in terms of 
the computational effort needed for each iteration. The remainder of this paper is organized as follows. 
In Section 2 we de.ne the problem and discuss the optimization methodology applied. In Section 3 we present 
convergence results for this method, and .nally, Section 4 contains some concluding remarks. 2 OPTIMIZATION 
METHODOLOGY In this paper we are concerned with optimizing a perfor­mance function J : 8 = R over a .nite 
feasible region 8; that is, min J(e), (1) en8 where |8| < .. For simplicity of presentation, we assume 
that there is some unique solution eopt n 8 that solves this () {} problem, that is, J eopt <J (e), for 
all e n 8 \ eopt . In practice J(e) is often the expected performance of a complex system given some 
underlying solution parameters e, and there may be no analytical expression available to relate this 
expected performance to the solution parame­ters. In such situations, J(e) must be estimated from a simulation 
sample performance Lt (e), where t is the sim­ulation time. We assume that regenerative simulation is 
used to estimate the system performance, that is, {Lt } is a regenerative process and the problem is 
that of simulation­based optimization with discrete decision parameters. Such simulation-based optimization 
has numerous applications. However, in practice it is very computationally expensive to obtain accurate 
steady-state simulation estimates of the performance of a complex system, and it is hence often necessary 
to content with a short simulation that results in noisier estimates; that is, t may be very small and 
Lt (e) may hence only be a rough estimate of J(e) for each e n 8. It has been observed that when dealing 
with such noisy estimates it is bene.cial to focus on the ordinal rather than 666 cardinal values of 
the solutions (Ho, Sreenivas, and Vak­ili, 1992), and we show that due to the ordinal nature of the NP 
method it may indeed converge despite very noisy simulation estimates. First, however, we describe the 
NP method itself. 2.1 The Nested Partitions Method The basic idea of the NP method is simple. In the 
k-th iteration there is a region .(k) Ø 8 that is considered the most promising. In the .rst iteration 
nothing is assumed to be known about where good solutions are, so the entire solution space .(1) = 8 
is taken as the most promising region. The most promising region is then partitioned into M.(k) subregions, 
where M.(k) may depend on the subset .(k) but not the iteration. What remains of the solution space, 
8\.(k), is aggregated into one region called the surrounding region. Clearly the NP method shifts the 
focus from individual solutions to sets of solutions, and the following de.nitions, that identify the 
most important classes of such sets, will be convenient throughout the analysis. De.nition 1 A set constructed 
using a .xed parti­tioning strategy is called a valid region. The collection of all valid regions is 
denoted by ;. Singleton regions are of special interest, and we let ;0 * ; denote the collection of all 
such valid regions. Finally, we let ;g * ; denote all the good subregions, that is, . n ;g if and only 
if eopt n . . It will also be convenient to be able to identify the valid region which was partitioned 
to obtain the current most promising region, which motivates the next two de.nitions. De.nition 2 If 
a valid region . n ; is formed by partitioning a valid region p n ;, then . is called a subregion of 
region p, and region p is called a superregion of region . . De.nition 3 We de.ne the superregion function 
s : ; = ; as follows. Let . n ; \ 8. De.ne s(. ) = p n ;, if and only if . * p and if . Ø . Ø p then 
. = p or . = . . For completeness we de.ne s(8) = 8. It will also be necessary to keep track of distance 
between valid regions, so we de.ne two concepts, the depth of a region, which essentially is its distance 
from the entire solution space 8, and a metric that de.nes the distance between any two valid regions. 
De.nition 4 The singleton regions in ;0, are called regions of maximum depth. More generally, we de.ne 
the depth, d : ; = N0, of any valid region iteratively with 8 having depth zero, subregions of 8 having 
depth one, and so forth. De.nition 5 We let m(·, ·); : ; × ; = R be a metric given the partitioning strategy 
;, de.ned by m(p1,p2); = min (d(p1) - d(p)) + (d(p2) - d(p)), pn; p1Øp, p2Øp (2) and call it the partitioning 
metric. We note that the depth of a region p n ; is its distance from the entire feasible region 8, that 
is, d(p) = m(8, p);. Furthermore, the performance of the NP method turns out to depend on how the partitioning 
is performed, and we can use this metric to de.ne the ideal case. De.nition 6 A partitioning strategy 
; is called op­timal if and only if the global optimum .opt has the following property: For all p1,p2 
n ; such that d(p1) = d(p2) and m(.opt ,p1); < m(.opt ,p2);, then J(e) < J(s), ve n p1, vs n p2. (3) 
Returning to the procedure of the NP method, then given a partitioning of .(k), at the k-th iteration 
M.(k) +1 disjoint subsets that cover the feasible region are considered. Each of these regions is sampled 
using some random sampling scheme, resulting in a set D.j (k) of sample points. The samples are then 
used to estimate the promising index for each region. This index is a set performance function I : ; 
= R, that determines which region becomes the most promising region in the next iteration and the estimate 
()() I .j (k)= I D.j (k)depends only on the set of sample points. If one of the subregions is found to 
be best, this region becomes the most promising region. If the surrounding region is found to be best, 
the method backtracks to a larger region. To choose this larger region a .xed backtracking rule is used. 
De.nition 7 Let j k be the index corresponding to the best region found in the k-th iteration. j k = 
arg min I(.j (k)) (4) j Based on j k, either move to a subregion or backtrack to the superregion of the 
current most promising region. That is, let .j k (k), if j k <M.(k) + 1, .(k + 1) =(5) s (.(k)) , otherwise. 
where the function s : ; = ; is as in De.nition 3 above. The new most promising region .(k + 1) is then 
par­titioned and sampled in a similar fashion. This generates a sequence of set partitions, with each 
partition nested within the last. We assume that the partitioning is continued until eventually all the 
points in the feasible region correspond to a singleton region, and we let the estimate of the best 
667 Optimization Via Adaptive Sampling and Regenerative Simulation solution be the singleton region that 
has been considered the most promising the most often. De.nition 8 Let Nk(.) be the number of times region 
. n ; has been considered the most promising region by the k-th iteration. The estimate of the best solution 
is . opt (k) = arg max Nk(.), (6) .n;0 the most frequently visited singleton region by the k-th iteration. 
We note again that the basic idea of the NP algorithm is to shift the focus from the solution space itself 
to a sequence of subsets of the solution space. These subsets are sampled with variable density and a 
promising index for each subset is estimated. The ordinal values of these estimates determine how the 
algorithm proceeds in the next step. It is clear from equation (4) that accurately estimating the promising 
index is not critical. Only the ordinal values affect how the NP algorithm proceeds. If subregion .jopt 
n ;g contains the true global optimum, then it is suf.cient that ()() I .jopt (k)< I .j(k), vj == jopt. 
If this holds then the subregion containing the global optimum is identi.ed. We conclude that if the 
rank is preserved then nothing is gained from more accurate estimates.  2.2 An Ordinal Promising Index 
It is clear from the description of the NP method that a critical element is the selection and estimation 
of a promising index. Indeed, the estimated values of this index determine, in each iteration, how the 
sampling is concentrated in the next iteration. In its simplest form the estimated promising index can 
be taken as a summary statistic for the sampling information (Shi and Olafsson, 1998a). We can for example 
´de.ne the promising index function as I(.) = min J(e), . n ;. (7) en. For a given region . n ; and a 
set of sample points D. Ø ., we need to obtain an estimate I(.) of the promising index value I(.). This 
estimate must be based on the sample performance Lt(e) for each sample point e n D. , but the problem 
is that an accurate estimate of the performance is very expensive. If the performance is estimated using 
simulation it is well known that the estimate J(e) converges to J(e) at a rate that is at the most O(.1) 
in the total t simulation time t. This in turn implies that the estimate I(.) converges to I(.) at a 
rate that is at least as slow. However, recall that if it is desirable to move into a good region .g 
n ;g, where ;g is as in De.nition 1, and this is being compared to another bad region .b n ; \ ;g, then 
it is suf.cient that I(.g)< (8) I(.b), that is, if the rank is preserved then the correct valid region 
is selected. The advantage of this being suf.cient is that the estimated rank of a random variable may 
converge to its true rank at an exponential rate even if the cardinal values converge at a much slower 
rate (Dai, 1996). The implication is that it is not necessary to accurately estimate J(e) for each e 
n D. to obtain a suf.ciently good estimate of the promising index. Therefore, for every . n ; and corresponding 
set of sample points D. ,welet I(.) = min Lt(e). (9) enD. Since Lt(e) is obtained using regenerative 
simulation, and such estimates are strongly consistent, we have that I(.) = min J(e), w.p.1. enD. So, 
in the long-run, if minenD.g J(e) < minenD.b J(e) then .g will be selected. However, it is also known 
that this convergence occurs rather slowly. On the other hand, as we pointed out above we do not need 
accurate estimates of the cardinal values and we will show that if the estimated promising index (9) 
is used then, for certain systems, the probability of equation (8) holding converges to a suf.ciently 
large value at an exponential rate.  3 CONVERGENCE ANALYSIS By noting how the NP algorithm moves from 
one region in ; to the next, based only on the current sampling in­formation, it is clear that the algorithm 
generates a Markov chain {.(k)}. k=1 with state space ;. Furthermore, it is not dif.cult to show that 
this Markov chain has a unique station­ary distribution. To prove asymptotic convergence of the method, 
we show that given certain regularity conditions, the stationary probability of the singleton .opt ={eopt 
} is greater than that of any other singleton region and the NP algorithm converges to this maximum stationary 
probability ´ singleton Shi and Olafsson (1998a,b). 3.1 Asymptotic Convergence We begin by stating the 
asymptotic convergence result pre­cisely. Theorem 1 Assume that () () I . I . P.gI (.b). P.gI(.b), (10) 
 v.g n;g,.b n; \;g. Then the NP method converges {} with probability one to the global optimum .opt =eopt 
, that is, as k =.then . opt (k) =.opt , w.p.1. (11) Proof: We will only sketch a proof here and refer 
to ´ Shi and Olafsson (1998b) for full analysis of the stochastic . NP method. We start by observing 
that {.(k)}is an k=1 irreducible positive recurrent Markov chain. Therefore, it has a unique stationary 
distribution n, and it is well known that with probability one, as k =., Nk(. ) =n(. ), v. n;, k where 
Nk(. ) counts, as before, the number of times . n; is visited. Since, by De.nition 8 the NP method estimates 
the best solution as . opt (k) =arg max Nk(. ) . n;0 it can be seen that with probability one as k =., 
. opt (k) =arg max n(. ). . n;0 Hence, the algorithm converges to the singleton region that maximizes 
the stationary distribution. Now to show that {} this singleton region is indeed .opt =eopt , .rst note 
that the Markov chain is reversible and we hence have that for any p n;0, () ()() PK(p,.opt ) n(p) =P 
K(p,.opt ) p,.opt .opt ,pn .opt , where K(p, .opt ) is the number of transitions it takes to go from 
p to .opt and vice versa. Hence, if the K(p, .opt )­step transition probability from p to .opt is larger 
than the K(p, .opt )-step transition probability from p to .opt to p for {} all p n;0 \.opt , then .opt 
=arg max n(p) pn;0 and the theorem is proven. To see why this holds, we look at the superregion of () 
the optimum, s .opt . By equation (10) it is clear that the probability of moving to the .opt is larger 
than the (()) probability of backtracking to s s .opt , (() ) ()(()) P s .opt ,.opt = PI .opt I 8 \s 
.opt (()) () . PI 8 \s .opt I .opt (()(())) = Ps.opt ,ss.opt , and in general, the same result holds 
for any region on the {} path between .opt and an arbitrary p n;0 \.opt .We conclude that .opt is a singleton 
region that maximizes the stationary probability and the theorem holds. It remains to justify that equation 
(10) may indeed be satis.ed then applying the method in practice, and how (10) relates to the implementation 
parameters of the method, in particular the partitioning and sampling. We approach this via the perspective 
of ordinal comparisons.  3.2 Ordinal Comparison To show analytically that using ordinal comparison is 
bene­.cial we use the following theorem from Dai (1996), which shows that (9) converges rapidly when 
used to estimate the promising index. Theorem 2 Let D Ø 8 and let 8g = D .G be the good solutions and 
let 8b =D \8b denote the bad solutions. We assume that 8g ==0and 8b ==0. Then the probability of the 
estimated best solution in 8g being better than the estimated best solution in 8b converges to one at 
an exponential rate. () Pmin Lt (e) min Lt (e)=1 -Oe -.t , (12) en8g en8b and () Pmin Lt(e) > min Lt 
(e)=Oe -.t . (13) en8g en8b Proof: See Theorem 4.5 in Dai (1996). We immediately obtain the following 
theorem. Theorem 3 Assume that two regions .g n;g and .b n; \;g are compared, where .g contains the global 
optimum but .b does not. Let D.g denote the set of sample points from .g, and similarly D.b denote the 
set of sample points from .b. Then enD.g enD.b P I(.g) I(.b) = Pmin J(e) < min J(e) () +Oe -.t , (14) 
where t is the simulation time. Proof: By conditioning on the best solution sampled being from the good 
region, that is, A =min J(e) < min J(e), enD.g enD.b Optimization Via Adaptive Sampling and Regenerative 
Simulation this follows directly from Theorem 4: enD.g enD.b P I(.g) I(.b) = P min Lt (e) min Lt (e) 
  = P min Lt (e) min Lt(e)A · P [A] enD.g enD.b  Ac + P min Lt (e) min Lt (e)· (1 - P [A]) enD.g 
enD.b (()) () -.t -.t = 1 - Oe · P [A] + Oe · (1 - P [A]) () = P min J(e) < min J(e) + Oe -.t . enD.g 
enD.b This proves the theorem. In the k-th iteration of the NP method exactly one of the subregions 
sampled, say .j* (k) n ;g, contains the global optimum. This subregion is compared with all of the other 
regions, and will be selected if I(.j (k)), vk = 1, 2, ..., M(. (k)) + 1. It follows that the method 
is inherently ordinal and by Theorem 3 the probability of moving towards .j* (k) in the next iteration 
converges exponentially fast to a probability that depends only on which solutions were randomly selected 
in the current iteration. In other words, if we de.ne the probability of selecting I(.j * (k)) ) the 
best solution from the right region as P * (.j* (k)= P minenD.J(e) < minenD.j(k) J(e), vj == j*] , then 
j* (k) Theorem 3 states that P I(. j* (k)) I(.j (k)), vk = 1, 2, ..., M(. (k)) + 1 () = P *(.j* (k)) 
+ Oe -.t , where t is as before the simulation time. The probability P *(.j* (k)) can be made large by 
partitioning such that many good solutions fall in the same regions or by increasing the sampling effort 
in each iteration. This probability depends on comparing multiple regions, but to simplify the analysis 
we assume without loss of generality that we only compare two regions .g n ;g and .g n ; \ ;g. Accordingly, 
we de.ne the success probability * () P .g,.b= P min J(e) < min J(e) , (15) enD.g enD.b for all .g n 
;g, .g n ; \;g. For the remainder of the paper ) we focus on how P * (.g,.bdepends on the partitioning 
strategy and the sampling effort, and how it can be made suf.ciently large.  3.3 Partitioning and Sampling 
To better understand the relationship between the partitioning and the required sampling effort, we start 
by looking at the ideal case. Theorem 4 Let the assumptions and de.nitions of .g n ;g ,.b n ; \ ;g be 
as in Theorem 3. If ; is an optimal p arti thention -.t () P I(.g) I(.b) = 1 + O (16) e, where t is 
the simulation time. Proof: By De.nition 5 we have that m(.opt ,.g); < m(.opt ,.b); , so by De.nition 
6 of an optimal partition J(e) < J(s), ve n .g,s n .b. Therefore, P min J(e) < min J(e) = 1 enD.g enD.b 
so the theorem follows directly from Theorem 3 above. We note that Theorem 3 and Theorem 4 provide new 
insights into when the NP method converges to the global optimum. In particular, Theorem 3 implies that 
if P * () 1 .g,.b> 2 for all .g n ;g, .b n ; \ ;g, then the global convergence condition (10) will be 
satis.ed at an exponential rate in terms of the simulation effort used for evaluating each solution. 
By Theorem 6 this clearly holds for optimal partitioning. In practice, however, optimal par­titioning 
is never realized, and it is therefore of interest to determine how good the partitioning needs to be. 
It is also clear that as the partitioning becomes worse, more sample effort may be needed from each region. 
To mea­sure the quality of a partitioning strategy ; we de.ne the non-overlap set function, a : ;g = 
8 by {} a(.g) = e n .g : J(e) < J(1), v1 n 8 \ .g, (17) .g n ;g. This function counts, for each good 
region .g n ;g, how many of the solutions in the good region have better expected performance than all 
of the solutions outside this region, that is, the non-overlap in expected performance. A high value 
indicates that it may be easy to differentiate between the the good region and other regions, and vice 
versa for low values. By de.nition of ;g we have that eopt n a(.g) so a(.g) == 0 for all .g n ;g. It 
is also clear that if ; is optimal then by De.nition 6, J(e)<J(1) for all e n .g,1 n 8 \ .g,so a(.g) 
= .g for all .g n ;g. Therefore, the size of this set |a(.g)|n{1, 2, ..., |.g|} for all . n ;g is a measure 
of the quality ;. We now obtain the following theorem. 670 Theorem 5 Let the assumptions and de.nitions 
of .g n;g,.b n;\;g be as in Theorem 5. Let n(.g) =|D.g |be the number of sample points from .g n ;g. 
De.ne |.g|-|a(.g)| r(.g) = to be the percentage overlap, and |.g| assume that 1 log( 2 ) n(.g) . , (18) 
log(r(.g)) and that uniform sampling is used. Then the global con­vergence condition (10) is satis.ed 
at an exponential rate, that is, 1 () P I(.g) I(.b) .+Oe -.t, (19) 2 where t is the simulation time. 
Proof: It is clear that if one of the solutions in a(.g) is selected in D.g then the best solution in 
D.g is better than the best solution in D.b . That is, P minenD.g J(e) < minenD.b J(e) [] .P a(.g) .D.g 
==0 [] =1 -P a(.g) .D.g =0 ( )n(.g) |.g|-|a(.g)| =1 -, |.g| where the last equation follows from the 
uniform sampling strategy. On the other hand, by the assumption (18) we have n(.g) |.g|-|a(.g)| )n(.g) 
= r(.g |.g| 1log( 2 ) log(r(.g)) r(.g) 1 () log( 2 ) log(r(.g))log(r(.g)) = e 1 log( 2 ) = e 1 = , 2 
so 1 min J(e) < min J(e) . , enD.g enD.b 2 which, combined with Theorem 3, proves the theorem. This theorem 
illustrates the relationship between the partitioning and the sampling effort needed. If the par­titioning 
is poor, that is |a(.g)| small for at least some .g n;g, then more sample effort is need, and vice versa. 
| In particular, if |a(.g)|. |.gfor all .g n;g, then (19) is 2 satis.ed even if we use only one sample 
solution from each region. Moreover, Theorem 5 illustrates just how important a good partitioning strategy 
is, because the lower bound (18) on the number of sample solutions needed converges |.g| to one at an 
exponential rate as |a(.g)| goes to from below. This is illustrated in Figure 1 where the minimum required 
number of sample points to obtain a given suc­ ) cess probability P *(.g,.bn{0.25,0.50,0.75} is plotted 
against the percentage overlap |.g|-|a(.g)| r(.g) = n[0.50,0.95], |.g| that is |a(.g)|n[0.05,0.50]. The 
opposite is also true, increasing the sampling effort in each iteration leads to exponential improvement 
in the success probability as is illustrated in Figure 2 for four different partitioning quality levels 
r(.g) n{0.5,0.7,0.9,0.99}. We conclude that when optimizing certain systems using regenerative simulation, 
ordinal rather than cardinal opti­mization is indeed bene.cial. Furthermore, this translates into weak 
convergence conditions for the NP algorithm, and relatively little simulation effort being needed in 
each iteration.  4 CONCLUSIONS We have analyzed a new simulation-based optimization al­gorithm that 
draws from the paradigm of ordinal optimiza­tion and a recently proposed adaptive sampling algorithm 
called the nested partitions (NP) method. The new algo­rithm falls into the NP method framework, which 
guarantees global convergence under certain conditions, and the ordi­nal optimization perspective is 
used to show that for certain problems the method also has certain exponential conver­gence rate characteristics. 
We derived new conditions under Number of Sample Points 140 120 100 80 60 40 20 0 505560 657075 80 859095100 
Percentage Overlap Figure 1: Sample Effort Needed In Each Iteration Optimization Via Adaptive Sampling 
and Regenerative Simulation Probability 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Sample Points Figure 
2: Probability of Correct Selection which asymptotic convergence holds and provided practi­cal guidelines 
for determining the sampling effort in each iteration.  ACKNOWLEDGEMENT This research was supported 
in part by the National Science Foundation under grant DMI-9713647. REFERENCES Alrefaei, M.H., and S. 
Andradottir. ´1997. Accelerating the convergence of the stochastic ruler method. In Proceedings of the 
1997 Winter Simulation Conference, ed. S. Andrad´ ottir, K.J. Healy, D.H. Withers, and B.L. Nelson, 352-357. 
Institute of Electrical and Electronics Engineers, Piscataway, New Jersey. Andrad´A method for discrete 
stochastic ottir, S. 1995. optimization. Management Science 41: 1946-1961. Andrad´ ottir, S. 1998. A 
review of simulation optimization techniques. In Proceedings of the 1998 Winter Simula­tion Conference, 
ed. D.J. Medeiros, E.F. Watson, J.S. Carson, and M.S. Manivannan, 151-158. Institute of Electrical and 
Electronics Engineers. Piscataway, New Jersey. Carson, Y. and A. Maria. 1997. Simulation optimization: 
methods and applications. In Proceedings of the 1997 Winter Simulation Conference, ed. S. Andrad´ ottir, 
K.J. Healy, D.H. Withers, and B.L. Nelson, 118-126. Insti­tute of Electrical and Electronics Engineers, 
Piscataway, New Jersey. Dai, L. 1996. Convergence Properties of Ordinal Com­parison in the Simulation 
of Discrete Event Dynamic Systems. Journal of Optimization Theory and Appli­cations, 91, 363-388 Gong, 
W.-B., Y.-C. Ho, and W. Zhai. 1992. Stochastic Comparison Algorithm for Discrete Optimization with Estimation. 
In Proceedings of the 31st IEEE Conference on Decision and Control, 795-800. Ho, Y.-C., R.S. Sreenivas, 
and P. Vakili. 1992. Ordinal Op­timization of DEDS. Discrete Event Dynamic Systems: Theory and Applications, 
2, 61-88. ´ Olafsson, S. and L. Shi. 1998. Stopping Criterion for a Simulation-Based Optimization Method. 
In Proceed­ings of the 1998 Winter Simulation Conference, ed. D.J. Medeiros, E.F. Watson, J.S. Carson, 
and M.S. Mani­vannan, 743-750. Institute of Electrical and Electronics Engineers. Piscataway, New Jersey. 
´ Shi, L. and S. Olafsson. 1997. An integrated framework for deterministic and stochastic optimization. 
In Pro­ceedings of the 1997 Winter Simulation Conference, ed. S. Andrad´ ottir, K.J. Healy, D.H. Withers, 
and B.L. Nelson, 352-357. Institute of Electrical and Electronics Engineers, Piscataway, New Jersey. 
´ Shi, L and S. Olafsson. 1998a. Nested Partitions Method for Global Optimization. Operations Research, 
to appear. ´ Shi, L and S. Olafsson. 1998b. Nested Partitions Method for Stochastic Optimization. Working 
Paper, 98-115, Department of Industrial and Manufacturing Systems Engineering, Iowa State University. 
Tang, Z.B. 1994. Adaptive Partitioned Random Search to Global Optimization. IEEE Transactions on Automatic 
Control, 39, 2235-2244. Yan, D. and H. Mukai. 1992. Stochastic Discrete Opti­mization. SIAM Journal Control 
and Optimization, 30, 594-612. AUTHOR BIOGRAPHIES ´ SIGURDUR OLAFSSON is an assistant professor in the 
Department of Industrial and Manufacturing Systems Engineering at Iowa State University. He received 
a B.S. in Mathematics from the University of Iceland in 1995, and an M.S. and a Ph.D. in Industrial Engineering 
from the University of Wisconsin -Madison in 1996 and 1998, respectively. His research interests include 
applied probability, stochastic optimization, and simulation. He is a member of IIE and INFORMS. LEYUAN 
SHI is an Assistant Professor in the De­ partment of Industrial Engineering at the University of Wisconsin-Madison. 
She holds a B.S. degree in Mathematics from Nanjing Normal University, China (1982), an M.S. degree in 
Applied Mathematics from Tsinghua University, China (1985), and an M.S. and a Ph.D. degrees in Applied 
Mathematics from Harvard University (1990,1992). Her research interests include modeling, analysis, and 
optimization of discrete event systems, discrete-event simulation, and sensitivity analysis. 
			