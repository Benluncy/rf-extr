
 ON THE SIZE OF PROGRAMS IN SUBRECURSIVE FORMALISMS Robert L. Constable Department of Computer Science 
Cornell University Ithacaf N. Y. 14850 Abstract  This paper gives an overview of subre- cursive hierarchy 
theory as it relates to computational complexity and applies some of the concepts to questions about 
the size of programs in subrecursive programming languages. The purpose is three-fold, to reveal in simple 
terms the workings of sub- recursive hierarchies, to indicate new re- sults in the area, and to point 
out ways that the fundamental ideas in hierarchy theory can lead to interesting questions about programming 
languages. A specific application yields new information about Blum's results on the size of programs 
and about the relationship between size and efficiency. § 1 Introduction Consider a programming language 
~ such as reference Algol or LISP capable of ex- pressing algorithms for all partial recur- sive functions 
~ : ~m + ~ where = {0,1,2 .... } . It is well-known that such languages have the capacity to express 
algorithms which produce astronomically large computations. In other words, contains algorithms for functions 
whose computation at any input would exhause all imaginable computing resources. Letting denote the 
class of all (total) recur- sive functions,this fact means that the functions "actually computed" belong 
to subrecursive classes, ~ c 6q . For in- stance there is reason to believe that all functions actually 
used in computing belong to ~i the class of primitive recursive t functions. t One can argue that 
only finite functions are "actually computed". However, for reasons of mathematical application a first 
approximation to actual computing should allow for the computability of infinite functions such as x+y 
, x.y , xY , etc. See Elgot &#38; Robinson [i0] and McCarthy [16] for a discussion of this point. It 
is in fact one of the tasks of computing theory to discover a class or classes of functions which adequately 
represen~ the functions actually computed. The class ~ of ele- mentary functions may be a more reasonable 
candidate than ~i J Programming languages, ~ , can be de-  signed which express algorithms only for 
the functions in a subrecursive class ~ . These languages have been based on the logicians' formalisms 
for special classes like ~i In 1965 Cleave [5] designed a language for 6~ 1 based on ideas in Grzegorczyk 
[12] (1953) while Meyer &#38; Ritchie [18] (1965) designed another such language based on the ideas 
of R.M. Robin- son [22] (1947) and P. Axt [2] (1963). Constable designed languages for ~n (de- fined 
below) based on the notion of a stack [8] and of restricted program modifi- cation [7]. The subrecursive 
languages have several virtues. All programs terminate so there is no "halting problem". A bound for 
the running time of a program can be determined from the input and syntax. The conceptual structure of 
programs is simpler than the structure of general recursive programs. Computational efficiency is not 
sacri- ficed for these advantages. In a forth- coming article, the author and Allan Boro- din [9] show 
there is no significant loss of computational efficiency caused by com- puting with certain subrecursive 
languages. In Cleave's language the loss is at most a constant factor c of the total running time. In 
the case of various modifications of the "Loop" language of Meyer &#38; Ritchie the loss is again at 
most a linear factor c F and for their original language the loss is at most a square factor. What are 
the disadvantages of subrecur- sive languages? Blum [3] has shown that program compactness is sacrificed. 
He de- fines the notion of program size axiomati- cally. If i is a program, let lil be its size. One 
valid measure of size is the length of a program (number of cards in the deck). Blum shows that if f 
is any recursive function, there is a primi- tive recursive function f. whose minimum 1 length subrecursive 
program, say i ° , satisfies f(lJl) < Jiol for j some general recursive program for f. So for f(x) = 
i00 x , there is l some primitive recursive function whose shortest subrecursive program is 100 times 
longer than one of its general recursive This research was supported in part by National Science Foundation 
Grant GJ-579. -]-  programs. Furthermore, Blum shows that the computational complexity: say run-time, 
of j is nearly the same as that for i except on a finite set. Blum's result seems to indicate that general 
recursiv.~ Erogramming languages have a decided advantage over subrecursive languagec. He argues this 
by saying "in order for programs to be of economical size, the programming language must be pow- erful 
enough to compute arbitrary general recursive functions" In this paper Bium's result is examined further, 
and it is simply shown that there is a language for ~ (or for ~i ) such that any program which can be 
significantly compressed without drastically degrading computational efficiency must be a compu- tationally 
complex program. The same re- sults apply all through the known subre- cursive hierarchies, ~ , and 
they apply to the interesting languages such as Meyer &#38; Ritchie [18]. The result also shows that 
there is a trade-off relationship be- tween size and computational complexity (measured without an a.e. 
condition). Such facts can be construed to mean that for the purposes of working in the usable levels 
of the elementary functions, there is a subrecursive language capable of ex- pressing all elementary 
functions and there is a size measure on that language such that the usable functions cannot be sig- 
nificantly compressed without degrading efficiency. These results indicate some of the uses  of hierarchies. 
The classes ~ _ ~i are not of interest because their functions will be used in computing but because 
they serve to measure the capabilities of lan- guages and computing systems. Moreover, the specific 
principles on which the hier- archies ~ are constructed provide a fundamental description of recursive 
func- tions. Each function f E ~ can be re- presented in a normal form, f( ) = E[f ( )] where E[ ] 
is an ele- mentary operator and f ( ) is an element of a sequence of functions defining a sub- recursive 
hierarchy. % The complexity of f( ) has two components: its heiqht re- presented by e and its width 
represented by the elementary operator E[ ] (defined below). In the sections that follow, two speci- 
 fic programming languages, G and P , t The notation "f( )" is used to indi- cate a function when the 
number of argu- ments is unimportant and when a single letter f might be construed as an integer or an 
algorithm. Operators from functions to functions are denoted by E[ ]. So E[f( )] (x) is the value of 
the image of f( ) at x . -~-  will be defined and used to investigate the size results and to outline 
the deve- lopment of subrecursive hiera~2chies. In addition, the subject will be treated from the viewpoint 
of abstract computational complexity. Hopefully such a treatment provides an easily intelligible overview 
of the subject, laying bare tire methods and open problems. § 2 Programming Languages  General Recursive 
Language. The main results will be developed first for specific computing systems (lan- guage and machine) 
and later for acceptable indexings and Blum measures. The particu lar programming languages used are 
based on Shepherdson &#38; Sturgis [26] and Cleave [5]. The language G , for General recursion, is defined 
as follows: <constant> ::= oIiI... InI... <letter> ::= alblcl...Ix~yJz <Letter> ::= AIBIC[...IXIYIZ 
<variable> ::= <Letter>l<Letter><constant>%% <binary operator> ::= +i x <unary operator> :: = +iI~l 
<term> ::= <variable>i<constant>i<term> <binary op><term>I<term><unary op> I  (<term>) <assignment> 
::= <variable>÷<term> <conditional> ::= if<variable>=0 then go to <label> else go to next statement. 
<label> ::= <constant>I<letter>i<letter> <label> <statement> ::= <assignment>; I <conditional>; <program> 
::= <statement>i<label><state ment>i<program><program> The conditional is usually abbreviated to "if 
then <label> " leaving the "go to" and--~go to next statement:" understood. For convenience, the conditional 
expres- sion is used informally. The rule is <conditional exp.> ::= if <logical> then <term> else <term> 
where <logical> infor- mally represents a true or false state- ment.  Examples: The following are G-programs. 
 Z÷0 Z÷ 0 S ÷X N ÷ 1 1 if S = 0 then 2 S ÷ X X ÷X + 1 K ÷ 1 S ÷ S -' 1 1 if S =: 0 then 2 if Z = 0 
then 1 K ÷K + 1 N ÷N K S ÷ S -" 1 if Z = 0 then 1  The first program doubles the contents of X , 
the second computes X! . Notice that programs halt when they attempt to branch to an unlabeled statement. 
Also recall %% This notation takes liberties with BNF by allowing subscripts. x± = if x<y then 0 else 
x-y. YIt is assumed that the reader knows the semantics of such a language from sources such as [26], 
[i0] or [25]. It is inter- preted on a register machine (named for the fact that the computer words which 
are the interpretations of the variables, can be used for arithmetic directly without the intervention 
of special registers). Subrecursive Lan~ua@e The subrecursive language relies heavily on its semantics. 
Consider the sequence of functions defined by Def. 2.1 f0 (x) = x+l and (x) fn+l(X) = f (x) n  where 
for any function f : ~ ÷ ~, the iterate of f is defined by f(0) (x) = x, f(n+l) (x) = f(f(n) (x) ). 
These functions have a particularly simple structure in terms of the standard high level iterative, 
such as the PL/i DO,END pair. For in- stance, for an arbitrary G-program ~ let the code DO N END exit 
 be interpreted as S÷N 1 if S = 0 then exit S ÷ S -" 1 go to 1 where S does not appear in the program 
~. Thus for instance DO N N÷N + 1 END will double the contents of N. The functions f () are computed 
in a n  canonical manner by the programs: f0 is X ÷ X + 1 and fn+l is DO X f n  END. The syntax 
for the subrecursive language P is obtained by adding a "clock" to programs in G. Specifically <clock> 
: := (<constant>,<constant>) <P-program> ::= <clock>;<G-program>. The language P is interpreted on a 
J- limited register machine as defined in Cleave [5]. Briefly the machine uses a special clock register 
J inaccessible to the program. When the program starts executing, J is given a positive value; n, and 
on every step J is decreased by one until either the program halts or J reaches -3-  0. In the later 
case the program halts ab- normally, the output being whatever is in the output register at termination. 
 A P-program with clock (n,p) will start on input x with J = f(P) (x) (or n  J = fn(P) (max{xl'''''Xn}) 
on input = <x I ..... Xn > ~ n). Let ~0,~l,...,#n,... be a standard enumeration (more generally an 
acceptable indexing in the sense of Rogers[23]) of all G-programs and e0,el,...,en,.., an enumer- ation 
of all P-programs. Let ~#i(x) and cei(x) be the number of steps taken by ~i and ~i respectively on 
input x. Let #i(x)+ abbreviate the fact that ~i halts on input x, then ~i(x)+ means it does not halt. 
So ~i(x) = if ~i(x)+ then (number) of steps) else (undefined). By convention let ~i = <(ni'Pi'Si > (so 
that 8 i = ~j for some j). Then notice ~I (x) min{ - (Pi) (x) ~i (x) } = rn. ,  l The symbol sigma, 
~, represents a measure of complexity on {$i } or {ai }- The list E$ = {~$i } is a complexity measure 
in the sense of Blum [4] (a Blum measure). § 3 Subrecursive Hierarchies Algebraic Approach One of the 
oldest and most influential subrecursive hierarchies is the Grzegorczyk hierarchy first presented in 
 [12] in 1953. This hierarchy has since been defined in several different ways, see [i], [2], [7], [18], 
[21]. Crucial to the definition is the concept of the set of functions elementary in f , ~ (f) . The 
definition is sketched intuitively below so that the reader unfamiliar with the con- cept can see approximately 
what is invol- ved. Let ~ be the set of rational num- bers, ~ = {0,±1,±2,±1/2,±3,±1/3,±2/3,...}. Let 
~Q be the field of rational functions under + and . Notice that the field is closed not only under 
+ and but also under the operation of substitution of functions for variables. Denote the operation 
of substitution by 0 ~s. Now extend the field ~ by closing under the infinitafy rin9 operations S(Xl,...,Xn,Y) 
= q(xl,.o.,Xn,i) i=0 [y] p(x i ..... Xn,Y) = H q(xl,. .,Xn,±) I=0 for i an integer variable. For brevity 
let B be any set of func- tions and 0 l,...,0p any operators B n + B , then [B;01,...,0 p] is the least 
 class containing B and closed under 0. 1  The class of clementary functions over the rationals ~ , 
is [~;0s,~,~] (a super- field of ~ ). The class of elementary functions over ~ , denoted simpl~. ~ , 
is obtained by relativizing 6~, to ~ . Succinctly defined, the class ~ is given by letting b_l(X) = 
0 , b o(x) = x + 1 , bl(X,y ) = x + y , b 2 (x,y) = x.y, b3(x,y ) = x y , B i = {b_l, .... b i} Then 
~ = [B2;0s,Z,H] = [B3;0s,Z] and ~(f) = [B2,f;0s,Z,H ] It is an open question of considerable interest 
whether ~ can be obtained from ~ using only 0s and a sequence of new base functions, i.e. by a sequence 
of transcendental elements over the field The algebraic way of extending the class to the larger class 
~i is to use a  sequence of "transcendental extensions" of ~ by functions h i A sequence of such extending 
functions, ho,hl,.., will be called a spine for a hierarchy up to if U ~ (hi) = . For the sequence i=0 
f of Def .2.1 T 1 Theorem 3.1: ~(fn ) c ~(fn+l ) for all n > 2 Letting ~n = ~(fn ) for n > 3 %Grzegorczyk 
used a different sequence of functions, go(x,y) = y+l , gl(x,y) = x+y g2(x,y) = (x+l).(y+l) and for n 
> 2 gn+l(0,y) = gn(Y+l,y+l ) and gn+l(X+l,y) = gn+l(X,gn+l(x,y)) His classes ~o c ~i c ~2 c ~3 =~ are 
de- fined by 0S and limited recursion from gi ( ) For i < 3 the ~i are not of interest here because 
they are not of the form ~ (f) Theorem 3.2: U 6n =~i n=3 These theorems are proved by routine rate 
of growth arguments. A function f is said to majorize a class ~ (written f > ~ ) iff for all g 6 ~ there 
is a p such that g(xl,...,x n) < fn(p) (max{x l,...,x n}) The notation f <~ means there is a g 6~ and 
f(x) < g(x) for all x . It is shown by an inductive analysis of the definition of ~(fn ) that fn majorizes 
6 (fn) It follows that no one argument function in ~ (fn) can grow as fast as fn+l(X) = fn(X) (x) Thus 
 fn+l ~ ~n Containment, ~n ~ ~n+l , is shown by giving an elementary scheme for defining fn from fn+l 
" A more intuitive approach to this step is discussed later. To prove the equality of Theorem 3.2, 
Grzegorczyk used a formulation of ~i in terms of iteration, due to R.M. Ribinson [22]. The functions 
fn mirror the depth of nested iteration and this makes the argument straight forward. Once this theorem 
is available and the computational approach to ~n developed, as below, it becomes an easy matter to 
relate other hierarchies to ~I . The Grezegorczyk hierarchy ~n was first given a computational interpretation 
by Cleave [5] and later by Meyer &#38; Ritchie [18]. It was related to the Kleene subre- rursive hierarchy 
[15] and to the depth of nesting of primitive recursion by Art [i] and [2]. The class ~I is but the 
first level in the oldest subrecursive hierarchy, P4ter's [19] n-fold recursive functions ~n . It was 
natural to ask whether Grzegorczyk's approach could be extended to ~n . Rob- bin [21] answered the question 
for Grze- gorczyk's hierarchy and Constable [7] ans- wered the question for Cleave's computa- tional 
version. In terms of the algebraic approach, an extension procedure is quite naturally sug- gested. 
Simply consider a transfinite sequence of "transcendental elements'!. Thus for an ordinal ~ let ~n ÷ 
~ be a fundamental sequence to e , e.g. n ÷ ~ , 2 n + ~ , etc. Then new 'Ilonger" sequences are defined 
by the condition f (x) f~ (x) for ex X  Given the standard fundamental sequences ~4- for ordinals 
e < e it is shown in Con- o stable [7] that for ~ = ~(f ) ~ < e ° Theorem 3.3: ~e c ~8 if ~ < 8 < e 
O Robbin [21] showed that % Theorem 3.4: U ~ = ~n e<n In both of these results, the properness condition, 
f ~ ~8 if e < 8 , is shown by a simple application of the growth rate arguments that Grzegorczyk used. 
The cri- tical lemma is that f is strictly in- creasing for all e and all x . To prove that ~ ~ ~8, 
a computational analysis is used rather than a syntactic analysis of recursion schemes. (The syn- tactic 
method would result from a direct attempt to generalize Grzegorczyk's me- thods.) A computational approach 
appears necessary when the functions reach the complexity of f The next section will consider the relationship 
between the Ex- tended Grzegorczyk classes ~ ~ and mea- sures of computational complexity. Computational 
Approach The computational method of analyzing hierarchies depends on two basic principles, They are 
stated first for the time measure, , and later generalized to restricted Blum measures. Given f( ) , 
let ~f be a specific G-program for f( ) Principle I: If g E ~(f) , then there is a program ~g for g 
and an elemen- tary operator E[ ] such that %% ~g(X) < E[~f( )] (x) for all x This principle asserts 
that the com- puting system T~ operates in an elemen- tary manner, is, if g() can be de- fined by a sequence 
of elementary oper- ations, then the computing system can mimic those operations so that the cost is 
within an elementary operation of the cost of some specific algorithm for f(). This principle is true 
for all existing models of computing systems, such as one- tape or multi-tape Turing machines or Register 
machines. Indeed it is a good criterion by which to judge the system, "does it do elementary arithmetic 
in an elementary manner?" % Robbin used a different set of functions, Wo(X) = 2 x and W +l(X) = w(X) 
(i) %% E[ ] is an elementary operator if E[f( )] E ~(f()) for all f( ) 6 ~ .  -5- Principle II; If 
~i < ~(f) , then ~i £ ~(f) This principle asserts that if there is a way to compute g( ) which is bounded 
by an elementary in f amount of time, then the function is elementary in f . This is less obvious than 
I. It was first noticed by Kleene for the notion of "pri- mitive recursive in". Indeed, it is a direct 
consequence of the Kleene Normal Form Theorem (NFT) [14] or [24] which as- serts that any ~i 6 ~ satisfies 
 ~i(x) = U(~yT(i,x,y,)) x E ~n where U( ) 6 ~ and the "T-predicate" is elementary. Principle II follows 
from the fact that although the operation of mini- mum, ~ , is not elementary, the operation of limited 
minimum, ~ < , is. Therefore showing that ~i < ~(fY implies that ~i 6 ~(f) , since all the operations 
in- volved are elementary in f . The fundamental fact behind the NFT is that the operation of the computing 
system can be~described in an elementary manner. It is difficult to imagine a real computing system which 
does not posses an elementary description. See Cobham [6] for a discus- sion of this point. The two 
principles apply to the analysis of the Extended Grzegorczyk hierarchy, ~ in the following manner. Suppose 
each f has the property Operator Honesty Property: There is an al- gorithm, f , for f( ) and an elementary 
operator E2[ ] such that ~f(x) < E 2[f( ) ] (x) for all x . Then ovserve that for such f g E~(f)implies 
o~x ) < EI[E2[f( )]] (x) for all × (by Honesty ann I). So g 6~f) implies ~i < ~(f) " Now by II ~i 
< ~(f) implies ~i 6 ~(f) Hence Theorem 3.5: For f as above, g E 6(f) iff ~g < ~(f) As long as f has 
the (operator) Hon- esty Property and principle II holds, the question of membership in ~e = 6(f~) 
is reduced to a question of estimating bounds. A crucial step in proving ~ c 68 is the verification 
of honesty. Once this is ac- complished, then the hierarchy can be ana- lured by the simple technique 
of comparing growth rates, in particular showing that f majorizes ~e  It is easy to see that the run-time 
functions ~i satisfy a stronger honesty condition. First define Def. 3.1: f is h-honest iff ~¢i = f 
 and c~i(x) < h(~i(x)) for all x . f is elementary-honest iff h 6 ~ . The c~i are elementary honest. 
This allows Theorem 3.6: If f has the (operator) Honesty Property, then g E ~(f) iff ~g £ ~ (f) The 
proof follows by noticing that a%g < ~(f) and that honesty for a~g implies that there is a ~j = a~i 
and o~j < ~(f) Abstract Computational Approach The abstract approach to computational complexity can 
be used to cast the pre- vious observations in a more general set- ting. The abstraction begins with 
an acceptable indexing, {~i } , as the gene- ralization of a particular general recur- sive computing 
system. See Rogers [23] for a treatment of these indexings. Given {~i } , a Blum measure of computational 
com- plexity is defined as a list of functions = {~i } such that there is a 0,l-valued recursive function 
M , and the following axioms are satisfied: Axiom I: ~i(x)+ iff ~i(x)+ Axiom 2: M(i,x,y) = 1 iff ~. 
(x) = y 1  Example: The list E = {o~ i} is a Blum measure. The kinds of classes of interest here 
are the complexity classes of Hartmanis &#38; Stearns [13] and their "everywhere" coun- terparts. Def. 
3.2: ~t = {total ~iJ~i(x) _< t(x) a.e.x} ~$ = {total ~iJ~i(x) ! t(x) for all x}  The a.e. (almost 
everywhere, i.e. except for a finite set) classes, ~t ' are most common in the literature of complexity 
theory, but the "everywhere" classes, ~t ' will also be useful here. Following Blum, call the pair <#i,~i 
> a machine class. Call the machine class elementary if the following additional ax- ioms are satisfied 
for #i and ~. total functions. 3 -6-  Axiom 3; If ~i 6 6(#j) then there is an elementary operator 
E[ ] and a ~k = ~i such that ~k(X) <_ E[~j( )] (x) for all x . Axiom 4: ~i < ~(~j) implies ~i 6 ~(~j) 
 Axiom 5: #i are elementary honest, i.e. there is an h E ~ such that for all i there is a ~q( ) = ~i 
( ) , and if #i(x)+ then ~q(X) < h(~i(x) )  Def. 3.3: Given an elementary machine class (emc), <~i,~i 
> , call an ordinally indexed sequence of recursive functions, {h e } , an (elementary) spine iff (i) 
each h is strictly increasing  a  (ii) each h is elementary operator  a honest  (iii) ha(x) < hE(x) 
for all x > N a if e < 8 Theorem 3.7: If {h e } is an (elementary) spine, then g 6 6 (h e ) iff :~g 
= g and @g E ~,, (h e ) Def. 3.4: Call an (elementary) spine nor- mal iff ha+l(X) = h (x) (x) for all 
x . a  Note, supplying the initial value ho(X) = x + 1 generates the normal Grze- gorczyk sping up 
to Theorem 3.8: If {h a} is a normal spine over an emc, then ~(h ) c ~(hs) for 3 < a < 8 The proof 
of this theorem requires pro- perties (i) -(iii) of fa ' Axiom 4 (prin- ciple II) and the standard techniques 
of growth rate analysis. Given this theorem the question of whe- ther an Extended Grzegorczyk type hierarchy 
exists up to an ordinal a is reduced to the question of whether a normal spine exists up to a Theorem 
3.9: If h ° 6 ~i and {h a} is a normal spine, then U ~ (he) = ~i a<~ Def 3.5: Call {h e } e < y an e 
o -stan- dard spine if h (x) = h (x) for e ÷ e e a n  x the standard fundamental seq~Lence to e < Eo 
 Theorem 3.10: If h O E ~ 1 and {h e } is a normal eo-Standard spine, then  u e) = e<0~ Interesting 
relationships exist between elementary classes, ~(f) , and g-comple- xity classes over an emc. For instance 
r if f is strictly increasing and f > ~ , then f will majorize £ (f) . In fact a genera- lized Ritchie 
theorem holds. Theorem 3.11: If f is strictly increas- ing, elementary operator honest over an emc and 
f > ~ , then ~(p) c %(p+l) and = Cor. 3.12: If {he} is an elementary spine and ~ = ~(he) then if h 
>~ , S ' e then U ,~h (p) = ~e p=0 e All of these results follow by applying the general principles 
I and II (axioms 3 and 4) as they have been applied in the literature for the special cases. The dif- 
ficult matter of showing that relatively long spines exist is put aside. Another relationship between 
complexity classes and Grzegorczyk type classes is given by the Union Theorem of McCreight &#38; Meyer 
[17]. Putting ~n = ~(he+n ) and co ~e = n--U0~n the theorem asserts Theorem 3.13: For {hc~} a normal 
spine over an emc, and ~e = ~(he ) there are t and u s such that ~e =~ and e e From the recent work 
of McCreight &#38; Meyer [17] a very interesting type of spine emerges. It could be considered a "mini- 
mal" spine. First it follows from Blum [4] that any complexity class ~ named by an honest t can be 
extended by apply- ing a "jump function" h( ) to t , i.e., ~ c ~hot " The situation can be arranged 
 so that (i) tn(X) < tn+l(X) a.e. x and ~t c n ~tn+l (ii) tn+l(X) < hl(tn(X)) a.e.x hl( ) hl( ) 
E ~ , hl ( ) strictly increas- ing and h2(tn(X)) < tn+l(X) a.e.x;  (iii) each t is h honest for h E 
~ . n At the limit stage the union theorem  -7- Guarantees that U ~t = ~ for some u n=0 n increasing 
u . The McCreight &#38; Meyer [17] honest theo- rem guarantees that there is a measured set of functions 
F which can name every complexity class. In particular then there is an honest ~ such that ~u = ~ o 
 The h in (ii) is taken to be an h for which F is h-honest. It appears possible that for u's con- structed 
from an increasing sequence of the type t n , ~ can be made strictly increasing. If this is the case, 
let t t = strictly increasing ~ . Then for each ordinal y a mfnimal spine up to y can be selected simply 
by choosing funda- mental sequences for ordinals < y . In particular there exists an e -standard O 
minimal spine. Let ~ be the hierarchy produced by the minimal spine. Unfortunately as the author has 
shown, even if minimal spines constructed via the McCreight-Meyer procedure do exist, they are so fine 
that Theorem 3.14: If t o E ~ , then for every constructive ordinal y ~<y ~e § 4 Size of Programs 
 According to Blum [3] the notion of pro- gram size can be abstractly defined b spa- cifying a size function 
I] : ~ ÷ ~Y which satisfies condition i: I I : ~ ÷ ~ is recursive condition 2: Iyl -I is finite for 
all y condition 3: there is a recursive function b such that b(y) is a bound on the cardinality of Iyl 
-I . Given a programming language (formalism) {~i } , the size of a program (index) i is simply Iil 
, the value of the size function. As an example of a size function consi- der the following inductive 
definition o# the length of a G-program. in (<Letter>) = 1 , in(<Letter> n) = in(<variable>) = n + 
1 . If t is a term, say t = (a<operator>b) where a and b are terms, then in(t) = in(a) + in(b) + 1 For 
assignment statements, in(<variable>÷<term>) = In(<variable>) + in(<term>) + L . If L is a label formed 
by concatenating the labels L 1 and L 2 then in(L) = in(Ll) + in(L2) , and in(<letter>) = 1 , in(n) 
= n . Finally in(if<variable> = 0 then <label>) = in(<variable>) + in(<label>) + 2 The , so d : (I~j 
" I~il) > 0  length function, In( ) , is a valid size I~jl > I~il II be the function. From here on 
let and s + d = Pi " in( ) size function, p , say a p  The results of the hierarchy section Observe 
that for fixed the limit of the usable levels  show that "clock-bounded" formalisms simi determing 
to satisfy of ~ , the value q required  lar to P can be defined for all classes decreases monotonically 
 , more generally for any class ~t In f~P) (x) < f(q) (x) the clocks f~P) ( ) can be n there is an particular, 
as n increases. Therefore used to define a c.b. (clock-bounded) lan-(x)" for all np such that f~P) < 
fnp(X) guage for ~ . The programs have the form <clock,G-program> where the clock is x . In the clock 
formalism for ~(f n ) ~o,~i, .... be an enumeration (3,p) Let P ]In , the programs  of these programs 
(say E-programs), and with the size measure let e i = <(3,Pi),Si > where 8i = ~j for P of ~f3(p ) cannot 
be shrunk by any G-pro-  some G-program ~j A reasonable size function on E-program gram without loss 
of efficiency. The same results apply to any level of the hierarchy is defined earlier. l if3 = Pi 
÷ I if ~ These ideas can also be used to formu- (notice there is a c , c = If31 , such princi- late 
a conservation or "trade-off"  q is the G-pro- p of the IZil 3 + c = l~il where ple. Notice that if 
the level U~3(p ) can be enume- gram which first computes f~P)(x)" and Ritchie hierarchy, then behaves 
like i. .) Then by Blum's re- l rated, say po,Pl, .... sult there is a G-program Because ~ is recursively 
enumerable which can and because all E-programs halt, it is poe-shrink the size of some Pi by s , even 
 sible to enumerate the shortest E-programs for ~ Let mo,ml,.., be an enumeration for s >> p . Moreover 
this can be done (thus mo(), without loss of efficiency except on a of the shortest programs  finite 
set S . According to Thm, 4.1, ml( ) .... is an enumeration of ~ ). Ac-Blum's s~tement cannot be strengthened 
[3], for each function to hold everywhere. Stated in other terms cording to Blum f(x) = x + s s 6 ~ 
there is some m.1 Theorem 4.2: Programs in a fixed level p mi( ) = ~j( ) and of the (generalized) Ritchie 
hierarchy for and ~j such that ~ cannot be shortened with respect to f(I#jl) ~ Imil 3 Without loss 
of genera-  II~ more than p without loss of effi- lity assume f(l~j I) = Imil 3 , i.e. ciency at least 
on a finite set S . For I~jl + s = }mil 3 Say that ~j shrinks any s there are programs which can be 
with a loss of efficiency shortened by s mi b[ s , i.e. the shorter pro-  equal to (s -p) Call an 
E-program p-complex iff p is gram must be (s-p)-complex at least on a S .  the least j such that ~ii(x) 
< f~J) (x) finite set Thus when computational complexity is for all x .  measured by an everywhere 
condition, a con- Theorem 4.1: Suppose that the program #j servation principle holds between size and 
loss of effi-efficiency. shrinks m i by s without ciency, then m i is at least s-complex. Acknowledgments 
 The proof is simple. Since m. is the The author would like to thank Dr. Allan shortest E-program 
and #j is efficient, Borodin for his helpful discussions about this paper, especially for his help and 
 the only way ~j can shrink m i is by  independent conclusions on minimal spines. Thus the clock must 
 removing the clock. Special thanks go to Pat Hauk for her ex- be of size s , so s ~ Pi That is, cellent 
typing work. I~jl + s = Imil 3 = Pi + l~il If  l~jl < 18ii then <(3,pi),~j> would be a shorter E-program 
for mi( ) because x . Thus ~¢j(x) < f~Pi) (x) for all -8-  References Effectively Generated Class 
of Func- i]. Axt, Paul "Enumeration and the tions by Enumeration," Collog, Math. Grzegorczyk hierarchy," 
6, (1958), pp. 67-78. Z. Math Logik Grund.Math 9 (1963), 53-65.  16]. McCarthy, John "A Basis for 
a 2]. Axt, Paul "Iteration of primitive Mathematical Theory of Computation," recursion," abstract 597-182, 
Notices Computer Programming and Formal A.M.S., Jan. 1963. Systems, Amsterdam, 1963, pp. 30-70. McCreight, 
 3]. Blum, M. "On the Size of Machines," 17]. E. M. and A. R. Meyer Information and Control, II, (1967), 
"Classes of computable functions d~- 257-265. fined by bounds on computation," ACM Symp. on Theory of 
Computing, 4]. Blum, M. "Machine-Independent 1969, 79-88. Theory of the Complexity of Recur- sive Functions," 
JACM, 14, (1967), 18]. Meyer, A. R. and D. M. Ritchie 322-36. "The complexity of Loop programs," Proc. 
22 National ACM Conf. (1967), 5]. Cleave, John P., 465-470. "A Hierarchy of  Prlmltlve Recurslve Functlo 
Zeitschr. F. Math Logik and Grund. 19]. P~ter, Roze Recursive Functions, ..... ns ,"  D. Math., 9, 
(1963), 331-345. 3d ed., New York, 1967. 6]. Cobham, Alan "The Intrinsic Com-20]. Ritchie, Robert W. 
"Classes of putational Difficulty of Functions," Predictably Computable Functions, Logic, Methodology 
and Philosophy of Trans." A.M.S., 106, 1963, pp. 139- Science, Amsterdam, 1965. 173. 7]. Constable, 
Robert L. Extending and 21]. Robbin, Joel Subrecursive hier- Refining Hierarchies of Computable archies, 
Ph.D., Diss, Princeton, 1965. Functions. Comp. Sci. Tech. Report 22]. #25, Univ. of Wisc., 1968. Robinson, 
R.M. "Primitive recur- sive functions," Bull AMS, 53, (1947), 8]. Constable, Robert L. "Subrecursive 
915-942. programming languages for ~n,,, 23]. Comp. Sci. Tech. Report 70-53, Rogers, H. "G6del numberings 
of Cornell Univ., 1970. partial recursive functions," J.SL, 23, 3, (1958), 331-341. 9]. Constable, Robert 
L. and Allan B. Borodin "On the efficiency of pro-24]. Rogers, Hartley Jr. Theory of Re- grams in subrecursive 
formalisms," cursive Functions and Effective Com- Comp. Sci. Tech. Report 70-54, putability, New York, 
1967. Cornell Univ., 1970. 25]. Scott, Dana Some Definitional i0] . Elgot, C. C. and A. Robinson Suggestions 
for Automata Theory, "Random-Access Stored Program Ma-J. Compts., &#38; Syst. Sci., i, (1967), chines, 
An Approach to Programming pp. 187-212. Languages," J.A.C.M., ii, (1964), 26]. pp. 365-399. Shepherdson, 
J. C. and H. E. Sturgis "Computability of Recursive Func- ii] . Fabian, Robert J. Hierarchies of tions," 
J.A.C.M., i0, 1963, pp. 217- ~eneral recursive functions and 255. ordl~ recursion, Ph.D. Diss~ Case Inst. 
of Tech., 1965. 12] . Grzegorczyk, A. "Some Classes of Recursive Functions," Rozprawy Matematcyzne, 
(1953), 1-45. 13] . Hartmanis, J. and R. E. Stearns "On the Computational Complexity of Algorithms," 
Trans. AMC, 117, 5, (1965), 285-306. 14] . Kleene, S.C. Introduction to Metamathematics, Princeton, 
1952. 15]. Kleene, S. C. "Extension of an -9-  
			