
 Sharp Dichotomies for Regret Minimization in Metric Spaces* Robert Kleinberg Aleksandrs Slivkins Abstract 
The Lipschitz multi-armed bandit (MAB) problem gen­eralizes the classical multi-armed bandit problem 
by as­suming one is given side information consisting of a pri­ori upper bounds on the di.erence in expected 
payo. between certain pairs of strategies. Classical results of Lai-Robbins [28] and Auer et al. [3] 
imply a loga­rithmic regret bound for the Lipschitz MAB problem on .nite metric spaces. Recent results 
on continuum­armed bandit problems and their generalizations imply v lower bounds of t, or stronger, 
for many in.nite met­ric spaces such as the unit interval. Is this dichotomy universal? We prove that 
the answer is yes: for every metric space, the optimal regret of a Lipschitz MAB al­gorithm is either 
bounded above by any f . .(log t), or v bounded below by any g . o( t). Perhaps surprisingly, this dichotomy 
does not coincide with the distinction between .nite and in.nite metric spaces; instead it de­pends on 
whether the completion of the metric space is compact and countable. Our proof connects upper and lower 
bound techniques in online learning with classical topological notions such as perfect sets and the Cantor-Bendixson 
theorem. We also consider the full-feedback (a.k.a., best­expert) version of Lipschitz MAB problem, termed 
the Lipschitz experts problem, and show that this problem exhibits a similar dichotomy. We proceed to 
give nearly matching upper and lower bounds on regret in the Lip­schitz experts problem on uncountable 
metric spaces. These bounds are of the form T(t. ), where the expo­nent . . [ 1 , 1] depends on the metric 
space. To charac­ 2 terize this dependence, we introduce a novel dimension­ality notion tailored to the 
experts problem. Finally, we show that both Lipschitz bandits and Lipschitz ex­perts problems become 
completely intractable (in the sense that no algorithm has regret o(t)) if and only if the completion 
of the metric space is non-compact. *Full version of this paper is available at www.arxiv.org. Computer 
Science Department, Cornell University, Ithaca, NY 14853. Email: rdk at cs.cornell.edu. Supported by 
NSF awards CCF-0643934 and IIS-0905467, an Air Force OF.ce of Scienti.c Research grant, a Microsoft Research 
New Faculty Fellowship, and an Alfred P. Sloan Foundation Fellowship. Microsoft Research, Mountain View, 
CA 94043. Email: slivkins at microsoft.com. 1 Introduction Multi-armed bandit (henceforth, MAB) problems 
have been studied for more than .fty years as a clean ab­stract setting for analyzing the exploration-exploitation 
tradeo.s that are common in sequential decision mak­ing. In the stochastic MAB problem, an algorithm 
must repeatedly choose from a .xed set of strategies (a.k.a. arms ), each time receiving a random payo. 
whose dis­tribution depends on the strategy selected.1 The per­formance of MAB algorithms is commonly 
evaluated in terms of regret: the di.erence in expected payo. be­tween the algorithm s choices and always 
playing one .xed strategy. In addition to their many applications which range from experimental design 
to online auctions and web advertising another appealing feature of multi-armed bandit algorithms is 
that they are surpris­ingly e.cient in terms of the growth rate of regret: for .nite-armed bandit problems, 
algorithms whose regret at time t scales as O(log t) have been known for more than two decades, beginning 
with the seminal work of Lai and Robbins [28] and extended in subsequent work such as [3]. Many of the 
applications of MAB problems especially the computer science applications such as online auctions, web 
advertising, or adaptive routing require considering strategy sets which are very large or even in.nite. 
For in.nite strategy sets the O(log t) bound does not apply, while for very large .nite sets the O(·) 
notation masks a prohibitively large constant. Indeed, without making any assumptions about the strategies 
and their payo.s, bandit problems with large strategy sets allow for no non-trivial solutions any MAB 
algorithm performs as badly, on some inputs, as random guessing. This motivates the study of bandit problems 
in which the strategy set is large but one is given side information constraining the form of the payo.s. 
Such problems have become the subject of quite intensive study in recent years, e.g. [7, 1, 4, 24, 25, 
30, 6, 15, 13, 11, 5, 14, 23, 22, 21]. The Lipschitz MAB problem is a version of the stochastic MAB problem 
in which the side information consists of a priori upper bounds on the di.erence in 1More precisely, 
the payo. of each arm is an independent sample from a .xed distribution with bounded support. expected 
payo. between certain pairs of strategies. This models situations where the decision maker has access 
to some similarity information about strategies which ensures that similar strategies obtain similar 
payo.s. Abstractly, the similarity information may be modeled as de.ning a metric space structure on 
the strategy set, and the side constraints imply that the expected payo. function µ is a Lipschitz function 
(with Lipschitz constant 1) on this metric space. The Lipschitz MAB problem was introduced by Kleinberg 
et al. [27].2 Preceding work [1, 5, 11, 24, 31] has studied the problem in a few speci.c metric spaces 
such as a one-dimensional real interval. The prior work considered regret R(t) as a function of time 
t, and focused on the asymptotic dependence of R(t) on, loosely speaking, the dimensionality of the metric 
space. Various upper and lower bounds of the form R(t) = T(t. ) were proved, where the exponent .< 1 
depends on the metric space. In particular, if the metric space is the interval [0, 1] with the standard 
metric d(x, y)= |x - y|, then there exists an algorithm with regret R(t)= O (t2/3), and this bound is 
tight up to polylog factors [24]. More generally, for an arbitrary in.nite metric space (X, d) one can 
de.ne an isometry invariant . = .(X, d) . [ 12 , 1] such that there exists an algorithm with regret R(t)= 
O (t. ), which is tight up to polylog factors if .> 1 ; see [27]. 2 The following picture emerges. Although 
algo­rithms with regret R(t)= O(t. ),. < 1 are known for most metric spaces, existing work unfortunately 
provides no examples of in.nite metric spaces admit­ting bandit algorithms satisfying the Lai-Robbins 
regret bound R(t)= O(log t), although this bound holds for all .nite metrics. In fact, for most metric 
spaces that have been studied (such as the unit interval) this pos­sibility is excluded by known lower 
bounds of the form R(t) . o(t. ), where . = 12 . Therefore we ask, v Is O( t) regret the best possible 
for an in.nite metric space? Alternatively, are there in.nite metric spaces for which one can achieve 
regret O(log t)? Is there any metric space for which the v best possible regret is between O(log t) and 
O ( t)? Our contributions. To make the above issue more concrete, we put forward the following de.nition. 
Definition 1.1. Consider the Lipschitz MAB problem on a .xed metric space. A bandit algorithm is f(t)­tractable 
if for any problem instance I the algorithm s 2Megiddo and Hazan [22] consider a somewhat related (but 
technically very di.erent) setting which combines full feedback, contextual hints , convex payo.s, and 
(essentially) a similarity metric space on the contexts. 3 regret is R(t)= OI(f(t)). The problem is 
f(t)­tractable if such an algorithm exists. We settle the questions listed above by proving the following 
dichotomy. Theorem 1.1. Consider the Lipschitz MAB problem on a .xed metric space (X, d). Then the following 
dichotomy holds: either the problem is f(t)-tractable for every fv. .(log t), or it is not g(t)-tractable 
for any g . o( t). In fact, the former occurs if and only if the completion of X is a compact metric 
space with countably many points. It is worth mentioning that the regret bound R(t)= OI(log t) is the 
best possible, even for two-armed bandit problems, by a lower bound of Lai and Robbins [28]. Thus our 
upper bound for Lipschitz MAB problems in compact, countable metric spaces is nearly the best possible 
bound for such spaces, modulo the gap between f(t) = log t and .f . .(log t) . Furthermore, we show that 
this gap is inevitable for in.nite metric spaces: Theorem 1.2. For every in.nite metric space (X, d), 
the Lipschitz MAB problem on (X, d) is not (log t)­tractable. We turn our attention to the full-feedback 
version of the Lipschitz MAB problem. For any MAB problem there exists a corresponding full-feedback 
problem in which after each round, the payo.s from all strategies are revealed.4 Such settings have been 
extensively studied in the online learning literature under the name best experts problems [9, 10, 32]. 
In particular, for a .nite set of strategies one can achieve a constant regret [26] when payo.s are i.i.d. 
over time. In addition to the full feedback, one could also consider a version in which the payo.s are 
revealed for some but not all strategies. Speci.cally, we de.ne the double feedback, where in each round 
the algorithm selects two strategies: the bet for which it receives the payo., and the free peek . After 
the round, the payo.s are revealed for both strategies. By abuse of notation, we will treat the bandit 
setting as a special case of the experts setting. The experts version of the Lipschitz MAB problem, called 
the Lipschitz experts problem, is de.ned in the obvious way: a problem instance is speci.ed by a triple 
(X, d, P), where (X, d) is a metric space and P is a Borel probability measure on the set [0, 1]X of 
payo. functions on X (with the Borel s-algebra induced by 3Notation OI(f(t)) means Cf(t) for some constant 
C = C(I). 4Formally, an algorithm can query any .nite number of arms.  the product topology on [0, 1]X 
) such that the expected payo. function x . Ef.P[f(x)] is a Lipschitz function on (X, d). In each round 
an algorithm is presented with an i.i.d. sample from P. The metric structure of (X, d) is known to the 
algorithm, the measure P is not. We show that the Lipschitz experts problem exhibits a dichotomy similar 
to the one in Theorem 1.1. We formulate the upper bound for the double feedback, and the lower bound 
for the full feedback, thus avoiding the issue of what it means for an algorithm to receive feedback 
for in.nitely many strategies. Theorem 1.3. The Lipschitz experts problem on a .xed metric space (X, 
d) is either 1-tractable, even with double feedback, or it is not g(t)-tractable for any g . v o( t), 
even with full feedback. The former occurs if and only if the completion of X is a compact metric space 
with countably many points. Theorems 1.1 and 1.3 assert a dichotomy between metric spaces on which the 
Lipschitz MAB/experts problem is very tractable, and those on which it is somewhat tractable. Let us 
consider the opposite end of the tractability spectrum and ask for which metric spaces the problem becomes 
completely intractable. We obtain a precise characterization: the problem is completely intractable if 
and only if the metric space is not pre-compact. Moreover, our upper bound is for the bandit setting, 
whereas the lower bound is for full feedback. Theorem 1.4. The Lipschitz experts problem on a .xed metric 
space (X, d) is either f(t)-tractable for some f . o(t), even in the bandit setting, or it is not g(t)­tractable 
for any g . o(t), even with full feedback. The former occurs if and only if the completion of X is a 
compact metric space. Consider the full-feedback Lipschitz experts prob­ v lem. In view of the t lower 
bound from Theorems 1.3, we are interested in matching upper bounds. Gupta et al. [20] observed that 
such bounds hold for every met­ric space (X, d) of .nite covering dimension: namely, v the Lipschitz 
experts problem on (X, d) is t-tractable. (Their algorithm is a version of the naive algorithm from [24, 
27].) Therefore it is natural to ask whether there exist metric spaces for which the optimal regret v 
in the Lipschitz experts problem is between t and t. We settle this question by proving a characterization 
with nearly matching upper and lower bounds in terms of a novel dimensionality notion tailored to the 
experts problem. Theorem 1.5. For any metric space (X, d), there exist an isometry invariant b = b(X, 
d) such that the full­feedback Lipschitz experts problem on (X, d) is (t. )­ b+1 tractable for any .> 
, and not (t. )-tractable for b+2 b-1 any .< . Depending on the metric space, b(X, d) b can take any 
value on a dense subset of [0, 8). The lower bound in Theorem 1.5 holds for a re­stricted version of 
full-feedback Lipschitz experts prob­lem in which a problem instance (X, d, P) satis.es a fur­ther property 
that each function f . support(P) is it­self a Lipschitz function on (X, d). We term this version the 
uniformly Lipschitz experts problem (with full feed­back). In fact, for this version we obtain a matching 
upper bound. Theorem 1.6. Consider the uniformly Lipschitz ex­perts problem with full feedback. Fix an 
uncountable metric space (X, d). Let b = b(X, d) the isometry in­variant from Theorem 1.5. Then the problem 
on (X, d) 1 is (t. )-tractable for any .> max( b-1 , ), and not (t. )­ b 2 1 tractable for any .< max( 
b-1 , ). b 2 Connection to point-set topology. The main technical contribution of this paper is an interplay 
of online learning and point-set topology, which requires novel algorithmic and lower-bounding techniques. 
In particular, the connection to topology is essential in the (joint) proof of the two main results (Theorem 
1.1 and Theorem 1.3). There, we identify a simple topological property (well-orderability) which entails 
the algorith­mic result, and another topological property (perfect­ness) which entails the lower bound. 
Definition 1.2. Consider a topological space X. X is called perfect if it contains no isolated points. 
A topological well-ordering of X is a well-ordering (X, -) such that every initial segment thereof is 
an open set. If such -exists, X is called well-orderable. A metric space (X, d) is called well-orderable 
if and only if its metric topology is well-orderable. Perfect spaces are a classical notion in point-set 
topology. Topological well-orderings are implicit in the work of Cantor [8], but the particular de.nition 
given here is new, to the best of our knowledge. The proof of Theorems 1.1 and 1.3 (for compact metric 
spaces) consists of three parts: the algorithmic result for a compact well-orderable metric space, the 
lower bound for a metric space with a perfect subspace, and the following lemma that ties together the 
two topological properties. Lemma 1.1. For any compact metric space (X, d), the following are equivalent: 
(i) X is countable, (ii) (X, d) is well-orderable, (iii) no subspace of (X, d) is perfect.5 Lemma 1.1 
follows from classical theorems of Cantor-Bendixson [8] and Mazurkiewicz-Sierpinski [29]. We provide 
a proof in the full version of the paper. To reduce the Lipschitz MAB problem to complete metric spaces 
we show that the problem is f(t)-tractable on a given metric space if and only if it is f(t)-tractable 
on the completion thereof. Same is true for the double­feedback Lipschitz experts problem, and the only 
if direction holds for the full-feedback Lipschitz experts problem. Then the main dichotomy results follow 
from the lower bound in Theorem 1.4. Accessing the metric space. We de.ne a ban­dit algorithm as a (possibly 
randomized) Borel measur­able function that maps a history of past observations (xi,ri) . X × [0, 1] 
to a strategy x . X to be played in the current period. An experts algorithm is similarly de.ned as a 
(possibly randomized) Borel measurable function mapping the observation history to a strategy x . X to 
be played in the current period. (Or, in the case of the double feedback model, a pair of strategies 
representing the bet and free peek .) The observa­tion history is either a sequence of elements of [0, 
1]X in the full feedback model, or a sequence of quadru­ nn ples (xi,ri,xi,r) . (X × [0, 1])2 in the 
double feedback i model. These de.nitions abstract away a potentially thorny issue of representing and 
accessing an in.nite metric space. For our algorithmic results, we handle this is­sue as follows: the 
metric space is accessed via well­de.ned calls to a suitable oracle. Moreover, the main algorithmic result 
in Theorems 1.1 and 1.3 requires an oracle which represents the well-ordering. We also pro­vide an extension 
in Section 6: an .(log t)-tractability result for a wide family of metric spaces including, for example, 
compact metric spaces with a .nite number of limit points for which a more intuitive oracle ac­cess 
su.ces. These are the metric spaces with a .nite Cantor-Bendixson rank, a classic notion from point-set 
topology. Related work and discussion. Algorithms for the stochastic MAB problem admit regret guarantees 
of the form R(t)= O(f(t)), which are of two types depending on whether the constant in O() is allowed 
to depend on the problem instance. For instance, ucb1 [3] admits an instance-speci.c guarantee R(t)= 
O(log t), whereas the best-known instance-independent v guarantee for this algorithm is only R(t)= O( 
kt log t), where k is the number of arms. Accordingly, a lower 5Absent compactness, (ii) .. (iii) and 
(i).(ii), but (ii) .(i). bound for the instance-independent version has to show that for any algorithm 
and a given time t, there exists a problem instance whose regret is large at this time, whereas for the 
instance-speci.c version one needs a much more ambitious argument: for any algorithm there exists a problem 
instance whose regret is large in.nitely often. In this paper, we focus on instance­speci.c guarantees. 
Apart from the stochastic MAB problem considered in this paper, several other MAB formulations have been 
studied in the literature (see [10] for a survey). Early work [17, 16] has focused on Bayesian formulations 
in which Bayesian priors on payo.s are known, and goal is to maximize the payo. in expectation over these 
priors. In these formulations, an MAB instance is a Markov Decision Process (MDP) in which each arm is 
repre­sented by a Markov Chain with rewards on states, and the transition happens whenever the arm is 
played. In the more di.cult restless bandits [33] formulations, the state also changes when the arm is 
passive, ac­cording to another transition matrix. In the theoreti­cal computer science literature, recent 
work in this vein includes [18, 19]. Interestingly, these Bayesian formula­tions have an o.ine .avor: 
given the MDP, one needs to e.ciently compute a (nearly) optimal mapping from states to actions. Contrasting 
the Bayesian formulations in which the probabilistic model is fully speci.ed, the adversarial MAB problem 
[4, 2, 21] makes no stochastic assumptions whatsoever. Instead, it makes a very pes­simistic assumption 
that payo.s are chosen by an ad­versary that has access to the algorithm s code but not to its random 
seed. As in the stochastic MAB problem, the goal is to minimize regret. For any .xed (.nite) number of 
arms, the best possible regret in this setting v is R(t)= O( t) [4]. For in.nite strategy sets, one 
often considers the linear MAB problem in which strategies lie in a convex subset of Rd, and in each 
round the payo.s form a linear function, e.g. [30, 6, 14, 21]. It is an open question whether the ideas 
from the Lipschitz MAB problem extend to the above formula­tions. The adversarial version of the Lipschitz 
MAB problem is well-de.ned, but to the best of our knowl­edge, the only known result is the naive algorithm 
from [24]. One could de.ne the stochastic version of the linear MAB problem (in which the expected payo.s 
form a .xed time-invariant linear function), which can be viewed as a special case of the Lipschitz MAB 
prob­lem. However, this view is not likely to be fruitful be­cause in the Lipschitz MAB problem measuring 
a payo. of one arm is useless for estimating the payo.s of distant arms, whereas in prior work on the 
linear MAB problem inferences about distant arms are crucial. For Bayesian MAB problems with limited 
similarity information, it is not clear how to model this information, mainly be­cause in the Bayesian 
setting similarity between arms is naturally represented via correlated priors rather than a metric space. 
 Organization of the paper. Preliminaries are in Section 2. We present a joint proof for the two main 
results (Theorems 1.1 and 1.3). The lower bound is proved in Section 3 and the algorithmic results are 
in Section 4. Coupled with the topological equivalence (Lemma 1.1), this gives the proof for compact 
metric spaces. A complementary (log t)-intractability result for in.nite metric spaces (Theorem 1.2) 
is in Section 5. The .(log t)-tractability result via simpler oracle access (for metric spaces of .nite 
Cantor-Bendixson rank) is in Section 6. The boundary-of-tractability result (The­orems 1.4) is in Section 
7. The full-feedback Lipschitz experts problem in a (very) high dimension (including Theorems 1.5 and 
1.6) is discussed in Sections 8 and 9. Some of the proofs are moved to appendices. In Appendix A we reduce 
the problem to that on complete metric spaces. All KL-divergence arguments (which un­derlie our lower 
bounds) are gathered in Appendix B. 2 Preliminaries. This section contains various de.nitions which make 
the paper essentially self-contained (the only exception be­ing ordinal numbers which are used in Section 
9.2). In particular, the paper uses notions from General Topol­ogy which are typically covered in any 
introductory text or course on the subject. Lipschitz MAB problem. Consider the Lips­chitz MAB problem 
on a metric space (X, d) with pay­o. function µ. The payo. from each arm x . X is an independent sample 
from a .xed (time-invariant) dis­tribution with support in [0, 1] and expectation µ(x) such that |µ(x) 
- µ(y)|= d(x, y) for all x, y . X. For S . X denote sup(µ, S) = supx.S µ(x) and similarly argmax(µ, S) 
= argmaxx.S µ(x). Given a bandit algo­rithm A, let P(A,µ)(t) be the expected reward collected by the 
algorithm in the .rst t rounds on the problem instance (X, d, µ). The regret of algorithm A in t rounds 
is R(A,µ)(t) = sup(µ, X) t -P(A,µ)(t). Given a Lipschitz experts algorithm A and a problem instance (X, 
d, P), the notations P(A, P)(t) and R(A, P)(t) denoting ex­pected reward and regret are de.ned analogously. 
Metric topology. Let (X, d) be a metric space. An open ball in (X, d) is denoted B(x0,r)= {x . X : d(x, 
x0) <r}, where x0 . X is the center, and r = 0 is the radius. A Cauchy sequence in (X, d) is a sequence 
such that for every d> 0, there is an open ball of radius d containing all but .nitely many points of 
the sequence. We say X is complete if every Cauchy sequence has a limit point in X. For two Cauchy sequences 
x = x1,x2,... and y = y1,y2,... the distance d(x, y) = limi.8 d(xi,yi) is well-de.ned. Two Cauchy sequences 
are declared to be equivalent if their distance is 0. The equivalence classes of Cauchy sequences form 
a metric space (X*,d) called the completion of (X, d). The subspace of all constant sequences is identi.ed 
with (X, d): formally, it is a dense subspace of (X*,d) which is isometric to (X, d). A metric space 
(X, d) is compact if every collection of open balls covering (X, d) has a .nite subcollection that also 
covers (X, d). Every compact metric space is complete, but not vice-versa. Let X be a set. A family 
F of subsets of X is called a topology if it contains Ø and X and is closed under arbitrary unions and 
.nite intersections. When a speci.c topology is .xed and clear from the context, the elements of F are 
called open sets, and their complements are called closed sets. Throughout this paper, these terms will 
refer to the metric topology of the underlying metric space, the smallest topology that contains all 
open balls (namely, the intersection of all such topologies). A point x is called isolated if the singleton 
set {x} is open. A function between topological spaces is continuous if the inverse image of every open 
set is open. Set theory. Let S beaset. A well-ordering on a set S is a total order on S with the property 
that every non-empty subset of S has a least element in this order. Each set can be well-ordered. (More 
precisely, this statement is equivalent to the Axiom of Choice.) In Section 9.2 use ordinals, a.k.a. 
ordinal numbers, are a classical concept in set theory that, in some sense, extend natural numbers beyond 
in.nity. Understand­ing this paper requires only the basic notions about or­dinals, namely the standard 
(von Neumann) de.nition of ordinals, successor and limit ordinals, and trans.nite induction. The necessary 
material can be found in any introductory text on Mathematical Logic and Set The­ory, and also on Wikipedia. 
3 Lower bounds via a perfect subspace In this section we prove the following lower bound: Theorem 3.1. 
Consider the Lipschitz experts problem on a metric space (X, d) which has a perfect subspace. v Then 
the problem is not g-tractable for any g . o( t). In fact, a much stronger result holds: there exist 
a distribution P over problem instances µ such that for any experts algorithm A we have v (3.1) (.g 
. o( t)) Pr R(A,µ)(t)= Oµ(g(t)) =0. µ.P Let us construct the desired distribution over prob­lem instances. 
First, we use the existence of a perfect subspace to construct a useful system of balls. Definition 
3.1. A ball-tree on a metric space (X, d) is a complete in.nite binary tree whose nodes are pairs (x, 
r), where x . X is the center and r . (0, 1] is the radius , such that: nn if (x, r) is a parent of 
(x,rn) then d(x, xn)+ r< r ,  for siblings (x, rx) and (y, ry), rx + ry <d(x, y).  2 In a ball-tree, 
each tree node (x, r) corresponds to a ball B(x, r) so that each child is a subset of its parent and 
any two siblings are disjoint.6 Lemma 3.1. For any metric space with a perfect sub­space there exists 
a ball-tree. Proof. Consider a metric space (X, d) with a perfect subspace (Y, d). Let us construct the 
ball-tree recur­sively, maintaining the invariant that for each tree node (y, r) we have y . Y . Pick 
an arbitrary y . Y and let the root be (y, 1). Suppose we have constructed a tree node (y, r), y . Y 
. Since Y is perfect, the ball B(y, r/4) nn contains another point y. Y . Let r= d(y, yn)/2 and n de.ne 
the two children of (y, r) as (y, rn) and B(y,rn). Now let us use the ball-tree to construct the dis­tribution 
on payo. functions. Consider a metric space (X, d) with a .xed ball-tree T . For each i = 1, let * Di 
be the set of all depth-i tree nodes, and let r = i min{r :(x, r) . Di} be the smallest radius among 
these * nodes. Note that r = 2-i v. Choose a number ni large i 1 * enough that g(n) < rn for all n>ni, 
and let 8ii di = n -1/2 . For each tree node w =(x0,r0) de.ne a i function Fw : X . [0, 1] by (3.2) {min{r0 
- d(x, x0),r0/2} if x . B(x0,r0), Fw(x)= 0 otherwise. It is easy to see that Fw is a Lipschitz function 
on (X, d). A leaf in a ball-tree is an in.nite path from the root: w =(w0,w1,w2, ...), where w . Di for 
all i.A lineage in a ball-tree is a set of tree nodes containing at most one child of each node; if it 
contains exactly one child of each node then we call it a complete lineage. For each complete lineage 
. there is an associated leaf w(.) de.ned by w =(w0,w1, ...) where w0 is the root and for i> 0, wi is 
the unique child of wi-1 that belongs to .. Let us use a lineage in the ball-tree to de.ne a probability 
measure P. on payo. functions via the following sampling rule. 6De.ning internal nodes as balls rather 
than (x, r) pairs could lead to confusion later in the construction because a ball in a metric space 
a set of points, and as such does not necessarily have a unique center or radius. First every node w 
independently samples a random sign sign(w) .{+1, -1}, assigning probability (1 + di)/2 to +1 if w . 
. n Di, and choosing the sign uniformly at random otherwise. Now de.ne a payo. function p associated 
with this sign pattern as follows: 1 p =+ Lsign(w)Fw. By construction, p is a 2 w.T \D0 Lipschitz function 
taking values in [0, 1]. Let PT be the distribution over problem instances P. in which . is a complete 
lineage sampled uniformly at random; that is, each node samples one of its children independently and 
uniformly at random, and . is the set of sampled children. This completes our construction. Remark. Let 
. be a complete lineage in the ball-tree, and let w(.)=(w0,w1,w2, ...) be its associated leaf, where 
wi =(xi,ri) for all i. Suppose for some i we have x . B(xi,ri/2) and x . B(xi+1,ri+1). Then the expected 
payo. function µ. = E[p] associated to the * measure P. satis.es µ.(x)= 1 + Lij=1 ri di/4. 2 Lemma 
3.2. Consider a metric space (X, d) with a ball­tree T . Then (3.1) holds with P = PT . To prove this 
lemma, we de.ne a notion called an (E, d, k)-ensemble, which is a collection of k payo. distributions 
that are nearly indistinguishable from the standpoint of an online learning algorithm. To this end, we 
consider a more general setting than the one in the Lipschitz experts problem. In the feasible experts 
problem, one is given a set X (not necessarily a metric space) along with a collection D of Borel probability 
measures on the set [0, 1]X of functions p : X . [0, 1]. A problem instance of the feasible experts problem 
consists of a triple (X, D, P) where X and D are known to the algorithm, and P .D is not. Definition 
3.2. Consider a set X and a (k + 1)-tuple J P =(P0, P1,..., Pk) of Borel probability measures on [0, 
1]X , the set of [0, 1]-valued payo. functions p on X. For 0 = i = k and x . X, let µi(x) denote the 
expectation of p(x) under measure Pi. We say that JP is an (E, d, k)-ensemble if there exist pairwise 
disjoint subsets S1,S2,...,Sk . X for which the following properties hold: 1. for every i and every event 
E in the Borel s-algebra of [0, 1]X , we have 1 - d< P0(E)/Pi(E) < 1+ d, 2. for every i> 0, we have 
 sup(µi,Si) - sup(µi,X \ Si) = E. Theorem 3.2. Consider the feasible experts problem J on (X, D). 
Let P be an (E, d, k)-ensemble with {P1,..., Pk}.D and 0 < E,d < 1/2. Then for any t< ln(17k)/(2d2) and 
any experts algorithm A, at least half of the measures Pi have the property that R(A, Pi)(t) = Et/2. 
Remarks. For space reasons, the proof of this theorem has been moved to the appendix. The proof of Theo­rem 
3.1 uses Theorem 3.2 for k = 2, and the proof of Theorem 1.5 will use it again for large k. Proof of 
Lemma 3.2: Consider the ball-tree T . For each i = 1, recall that Di is the set of all depth-i * nodes 
in T , and that r = min{r :(x, r) . Di} is i the smallest radius among these nodes. Let P be the set 
of all probability measures induced by the lineages of T . For each complete lineage . and tree node 
w in T , let w1,w2 denote the children of w, let i denote n their depth, and let wdenote the unique element 
of {w1,w2}n .. The three lineages .0 = . \{wn},.1 = .0 .{w1},.2 = .0 .{w2} de.ne a triple of probability 
measures JP =(P.0 , P.1 , P.2 ) that constitute a (E, di, 2)­ * ensemble where E = ri di/4. Let us .x 
an experts algorithm A. By Theorem 3.2 there exists a(w) .{P.1 , P.2 } such that for any ti satisfying 
1/d2 <t< ln(34)/(2d2), i i v * 1 * R(A,a(w))(ti) = Eti/2= ri diti/8 > 8 ri t, d-2 Recalling the de.nition 
of ni = , we see that i v 1 * i · g(ti) <r ti <R(A,a(w))(ti). 8 i For each i, let us de.ne Ei to be the 
set of input distributions P. such that . is a complete lineage whose associated leaf w(.)=(w0,w1,...) 
satis.es wi = a(wi-1). Interpreting these sets as random events under the probability distribution PT 
, we have proved the following: there exists a sequence of events Ei, i . N and a sequence of times ti 
.8 such that for 1 each i we have (i) Pr[Ei| s(E1, ..., Ei-1)] = and (ii) 2 R(A, P)(ti) >i · g(ti) for 
any P .Ei. Now, let us .x an experts algorithm A. For each complete lineage ., de.ne C. := inf{C =8 : 
R(A, P.)(t) = Cg(t) for all t}. Note that R(A, P.)(t)= Oµ(g(t)) if and only if C. < 8. We claim that 
Pr[C. < 8] = 0 where the probability is over the random choice of complete lineage .. Indeed, if in.nitely 
many events Ei happen, then event {Cµ <C}does not. But the probability that in.nitely many events Ei 
happen is 1, because for every positive integer n, Pr n8 Ei = T8 Pr Ei ni-1 Ej =0. i=ni=nj=n 4 Tractability 
via well-orderable metric spaces In this section we prove the main algorithmic result. Theorem 4.1. Consider 
a compact well-orderable met­ric space (X, d). Then: (a) the Lipschitz MAB problem on (X, d) is f-tractable 
for every f . .(log t); (b) the Lipschitz experts problem on (X, d) is 1­tractable, even with a double 
feedback.  We present a joint exposition for both the bandit and the experts version. Let us consider 
the Lipschitz MAB/experts problem on a compact metric space (X, d) with a topological well-ordering -and 
a payo. function µ. For each strategy x . X, let S(x)= {y j x : y . X}be the corresponding initial segment 
of the well-ordering (X, -). Let µ * = sup(µ, X) denote the maximal payo.. * Call a strategy x . X optimal 
if µ(x)= µ . We rely on the following structural lemma: * Lemma 4.1. There exists an optimal strategy 
x . X such that sup(µ, X \ S(x *)) <µ * . Proof. Let X* be the set of all optimal strategies. Since µ 
is a continuous real-valued function on a compact space X, it attains its maximum, i.e. X* is non-empty, 
and furthermore X* is closed. Note that {S(x): x . X*} is an open cover for X* . Since X* is compact 
(as a closed subset of a compact set) this cover contains a .nite subcover, call it {S(x): x . Y *}. 
Then the -­maximal element of Y * is the --maximal element of X* . The initial segment S(x *) is open, 
so its complement Y = X \ S(x *) is closed and therefore compact. It follows that µ attains its maximum 
on Y , say at a point * ** y . Y . By the choice of y we have x -y *, so by the * choice of x we have 
µ(x *) >µ(y *). * In the rest of this section we let x be the strategy from Lemma 4.1. Our algorithm 
is geared towards * .nding x eventually, and playing it from then on. The idea is that if we cover X 
with balls of a su.ciently * small radius, any strategy in a ball containing x has a signi.cantly larger 
payo. than any strategy in a ball that overlaps with X \ S(x *). The algorithm accesses the metric space 
and the well-ordering via the following two oracles. Definition 4.1. A d-covering of a metric space (X, 
d) is a subset S . X such that each point in X lies within distance d from some point in S. An oracle 
O = O(k) is a covering oracle for (X, d) if it inputs k . N and outputs a pair (d, S) where d = dO(k) 
is a positive number and S is a d-covering of X consisting of at most k points. Here dO(·) is any function 
such that dO(k) . 0 as k .8. Definition 4.2. Given a metric space (X, d) and a total order (X, -), the 
ordering oracle inputs a .nite collection of balls (given by the centers and the radii), and returns 
the --maximal element covered by the closure of these balls, if such element exists, and an arbitrary 
point in X otherwise. Our algorithm is based on the following exploration subroutine EXPL(). Algorithm 
4.1. Subroutine EXPL(k, n, r): inputs k, n . N and r . (0, 1), outputs a point in X. First it calls the 
covering oracle O(k) and receives a d-covering S of X consisting of at most k points. Then it plays each 
strategy x . S exactly n times; let µav(x) be the sample average. Let us say that x a loser if µav(y) 
- µav(x) > 2r + d for some y . S. Finally, it calls the ordering oracle with the collection of all closed 
¯ balls B(x, d) such that x is not a loser, and outputs the point xor . X returned by this oracle call. 
Clearly, EXPL(k, n, r) takes at most kn rounds to complete. We show that for su.ciently large k, n and 
* su.ciently small r it returns x with high probability. * Lemma 4.2. Fix a problem instance and let 
x be the optimal strategy from Lemma 4.1. Consider increas­ing functions k, n, T : N . N such that r(t) 
:= 4J(log T (t)) /n(t) . 0. Then for any su.ciently large t, with probability at least 1 - T -2(t), the 
subroutine * EXPL(k(t),n(t),r(t)) returns x . Proof. Let us use the notation from Algorithm 4.1. Fix 
t and consider a run of EXPL(k(t),n(t),r(t)). Call this run clean if for each x . S we have |µav(x) - 
µ(x)|= r(t). By Cherno. Bounds, this happens with probability at least 1 - T -2(t). In the rest of the 
proof, let us assume that the run is clean. ¯¯ Let B be the union of the closed balls B(x, d), x . S* 
. Then the ordering oracle returns the --maximal ¯ point in B if such point exists. We will show that 
* ¯ x . B . S(x *) for any su.ciently large t, which will imply the lemma. * ¯ We claim that x . B. Since 
S is a d-covering, ** there exists y . S such that d(x ,y *) = d. Let us ** .x one such y . It su.ces 
to prove that y is not a loser. Indeed, if µav(y) - µav(y *) > 2 r(t)+ d for some y . S then µ(y) >µ(y 
*)+ d = µ *, contradiction. Claim proved. Let µ0 = sup(µ, X \S(x *)) and let r0 =(µ * -µ0)/7. Let us 
assume that t is su.ciently large so that r(t) < r0 and d = dO(k(t)) <r0, where dO(·) is from the de.nition 
of the covering oracle. ¯ We claim that B . S(x *). Indeed, consider x . S and y . X \ S(x *) such that 
d(x, y) = d. It su.ces to prove that x is a loser. Consider some y * . S such that * d(x ,y *) = d. 
Then by the Lipschitz condition µav(y *) = µ(y *) - r0 = µ * - 2r0, µav(x) = µ(x)+ r0 = µ(y)+ r0 = µ0 
+2r0 = µ * - 5r0 µav(y *) - µav(x) = 3r0 > 2r(t)+ d. Proof of Theorem 4.1: Let us .x a function f . 
.(log t). Then f(t)= a(t) log(t) where a(t) .8. Without loss of generality, assume that a(t) is non­decreasing. 
(If not, then instead of f(t) use g(t)= ß(t) log(t), where ß(t) = inf{a(tn): tn = t}.) For part (a), 
de.ne kt = lJg(t)/ log tj, nt = lkt log tj, and rt =4J(log t)/nt. Note that rt . 0. The algorithm proceeds 
in phases of a doubly exponential length7 . A given phase i =1, 2, 3,... lasts 22i for T = rounds. In 
this phase, .rst we call the exploration subroutine EXPL(kT ,nT ,rT ). Let xor . X be the point returned 
by this subroutine. Then we play xor till the end of the phase. This completes the description of the 
algorithm. Fix a problem instance I. Let Wi be the total reward accumulated by the algorithm in phase 
i, and let Ri =22i µ * - Wi be the corresponding share of regret. By Lemma 4.2 there exists i0 = i0(I) 
such that for any 22i phase i = i0 we have, letting T = be the phase duration, that Ri = kT nT = g(T 
) with probability at least 1 - T -2, and therefore E[Ri] = g(T )+ T -1 . 22i0 For any t>t0 = it follows 
by summing over i . {i0,i0 +1,..., Ilog log tl} that RA, I(t)= O(t0 + g(t)). Note that we have used the 
fact that a(t) is non­decreasing. For part (b), we separate exploration and exploita­tion. For exploration, 
we run EXPL() on the free peeks. For exploitation, we use the point returned by EXPL() in the previous 
phase. Speci.cally, de.ne kt = nt = v l tj, and rt =4J(t1/4)/nt. The algorithm pro­ceeds in phases of 
exponential length. A given phase i =1, 2, 3,... lasts for T =2i rounds. In this phase, we run the exploration 
subroutine EXPL(kT ,nT ,rT ) on the free peeks. In each round, we bet on the point returned by EXPL() 
in the previous phase. This completes the description of the algorithm. By Lemma 4.2 there exists i0 
= i0(I) such that in any phase i = i0 the algorithm incurs zero regret with probability at least 1 -eO(i). 
Thus the total regret after t> 2i0 rounds is at most t0 + O(1). 7The doubly exponential phase length 
is necessary in order to get f-tractability. If we employed the more familiar doubling trick of using 
phase length 2i (as in [4, 24, 27] for example) then the algorithm would only be f(t) log t-tractable. 
 5 The (log t)-intractability for in.nite metric spaces: proof of Theorem 1.2 Consider an in.nite metric 
space (X, d). In view of Theorem 1.4, we can assume that the completion X* * of X is compact. It follows 
that there exists x . X* * such that xi . x for some sequence x1,x2, ... . X. Let ri = d(xi,x *). Without 
loss of generality, assume 1 that ri+1 <ri for each i, and the diameter of X is 1. 2 Let us de.ne an 
ensemble of payo. functions µi : X . [0, 1], i . N, where µ0 is the baseline function, and for each i 
= 1 function µi is the counterexample in which a neighborhood of xi has slightly higher -d(x,x ) payo.s. 
The baseline is de.ned by µ0(x)= 1 * , 28 and the counterexamples are given by µi(x)= µ0(x)+ .i(x), ri 
where .i(x)= 3 max (0, - d(x, x *)). 43 13 Note that both µ0 and .i are -Lipschitz and ­ 84 Lipschitz 
w.r.t. (X, d), respectively, so µi is 7 -Lipschitz 8 w.r.t (X, d). Let us .x a MAB algorithm A and assume 
that it is (log t)-tractable. Then for each i = 0 there exists a constant Ci such that R(A,µi)(t) <Ci 
log t for all times t. We will show that this is not possible. Intuitively, the ability of an algorithm 
to distinguish between payo. functions µ0 and µi, i = 1 depends on the number of samples in the ball 
Bi = B(xi,ri/3). (This is because µ0 = µi outside Bi.) In particular, the number of samples itself cannot 
be too di.erent under µ0 and under µi, unless it is large. To formalize this idea, let Ni(t) be the number 
of times algorithm A selects a strategy in the ball Bi during the .rst t rounds, and let s(Ni(t)) be 
the corresponding s-algebra. Let Pi[·] and Ei[·] be, respectively, the distribution and expectation induced 
by µi. Then we can connect E0[Ni(t)] with the probability of any event S . s(Ni(t)) as follows. Claim 
5.1. For any i = 1 and any event S . s(Ni(t)) it is the case that 1 (5.3) Pi[S] < = P0[S] 3 2 .- ln(Pi[S]) 
- 3 = O(r ) E0[Ni(t)]. ei Claim 5.1 is proved using KL-divergence techniques, see Appendix B for details. 
To complete the proof of the theorem, we claim that for each i = 1 it is the case -2 that E0[Ni(t)] = 
O(r log t) for any su.ciently large i -2 t. Indeed, .x i and let S = {Ni(t) <rlog t}. Since i -2 Ci log 
t>R(A,µi)(t) = Pi(S)(t - r log t) ri , i 8 1 it follows that Pi(S) <t-1/2 < for any su.ciently 3 1 large 
t. Then by Claim 5.1 either P0(S) < or the 3 consequent in (5.3) holds. In both cases E0[Ni(t)] = -2 
 O(r log t). Claim proved. i Finally, the fact that µ0(x *) - µ0(x) = ri/12 for every x . Bi implies 
that ri -1 R(A,µ0)(t) = E0[Ni(t)] = O(r log t) 12 i -1 which completes the proof since r .8 as i .8. 
i 6 Tractability via more intuitive oracle access In Theorem 4.1, the algorithm accesses the metric 
space via two oracles: a very intuitive covering oracle, and a less intuitive ordering oracle. In this 
section we show that for a wide family of metric spaces including, for example, compact metric spaces 
with a .nite number of limit points the ordering oracle is not needed: we provide an algorithm which 
accesses the metric space via a .nite set of covering oracles. We will consider metric spaces of .nite 
Cantor-Bendixson rank, a classic notion from point topology. Definition 6.1. Fix a metric space (X, d). 
If for some x . X there exists a sequence of points in X \{x}which converges to x, then x is called a 
limit point. For S . X let lim(S) denote the limit set: the set of all limit points of S. Let lim(S, 
0) = S, and lim(S, i)= lim(lim(··· lim(S))), where lim(·) is applied i times. The Cantor-Bendixson rank 
of (X, d) is de.ned as sup{n : lim(X, n)= Ø}. Let us say that a Cantor-Bendixson metric space is one 
with a .nite Cantor-Bendixson rank. In order to apply Theorem 4.1, we show that any such metric space 
is well-orderable. Lemma 6.1. Any Cantor-Bendixson metric space is well-orderable. Proof. Any .nite metric 
space is trivially well­orderable. To prove the lemma, it su.ces to show the following: any metric space 
(X, d) is well-orderable if so is (lim(X),d). Let X1 = X \ lim(X) and X2 = lim(X). Suppose (X2,d) admits 
a topological well-ordering -2. De.ne a binary relation -on X as follows. Fix an arbitrary well-ordering 
-1 on X1. For any x, y . X posit x -y if either (i) x, y . X1 and x -1 y, or (ii) x, y . X2 and x -2 
y, or (iii) x . X1 and y . X2. It is easy to see that (X, -) is a well-ordering. It remains to prove 
that an arbitrary initial segment Y = {x . X : x -y} is open in (X, d). We need to show that for each 
x . Y there is a ball B(x, E), E> 0 which is contained in Y . This is true if x . X1 since by de.nition 
each such x is an isolated point in X. If x . X2 then Y = X1 .Y2 where Y2 = {x . X2 : x -2 y}is the initial 
segment of X2. Since Y2 is open in (X2,d), there exists E> 0 such that BX2 (x, E) . Y2. It follows that 
BX (x, E) . BX2 (x, E) . X1 . Y . The structure of a Cantor-Bendixson metric space is revealed by a 
partition of X into subsets Xi = lim(X, i) \ lim(X, i + 1), 0 = i = n. For a point x . Xi, we de.ne the 
rank to be i. The algorithm requires a covering oracle for each Xi. Theorem 6.1. Consider the Lipschitz 
MAB/experts problem on a compact metric space (X, d) such that limN (X)= Ø for some N. Let Oi be the 
covering oracle for Xi = lim(X, i) \ lim(X, i + 1). Assume that access to the metric space is provided 
only via the collection of oracles {Oi}N . Then: i=0 (a) the Lipschitz MAB problem on (X, d) is f-tractable 
for every f . .(log t); (b) the Lipschitz experts problem on (X, d) is 1­tractable, even with a double 
feedback.  In the rest of this section, consider the setting in Theorem 6.1. We describe the exploration 
subroutine EXPLn(), which is similar to EXPL() in Section 4 but does not use the ordering oracle. Then 
we prove a version of Lemma 4.2 for EXPLn(). Once we have this lemma, the proof of Theorem 6.1 is identical 
to that of Theorem 4.1 (and is omitted). Algorithm 6.1. Subroutine EXPLn(k, n, r): inputs k, n . N and 
r . (0, 1), outputs a point in X. Call each covering oracle Oi(k) and receive a di ­covering Si of X 
consisting of at most k points. Let S = .n Sl. Play each strategy x . S exactly n times; l=1 let µav(x) 
be the corresponding sample average. For x, y . S, let us say that x dominates y if µav(x) - µav(y) > 
2 r. Call x . S a winner if x has a largest rank among the strategies that are not dominated by any other 
strategy. Output an arbitrary winner if a winner exists, else output an arbitrary point in S. Clearly, 
EXPL(k, n, r) takes at most knN rounds to complete. We show that for su.ciently large k, n and su.ciently 
small r it returns an optimal strategy with high probability. Lemma 6.2. Fix a problem instance. Consider 
increas­ing functions k, n, T : N . N such that r(t) := 4J(log T (t)) /n(t) . 0. Then for any su.ciently 
large t, with probability at least 1 - T -2(t), the subroutine EXPLn(k(t),n(t),r(t)) returns an optimal 
strategy. Proof. Use the notation from Algorithm 6.1. Fix t and consider a run of EXPLn(k(t),n(t),r(t)). 
Call this run clean if for each x . S we have |µav(x) - µ(x)|= r(t). By Cherno. Bounds, this happens 
with probability at least 1 - T -2(t). In the rest of the proof, let us assume that the run is clean. 
 Let us introduce some notation. Let µ be the payo. * function and let µ = sup(µ, X). Call x . X optimal 
* if µ(x)= µ . (There exists an optimal strategy since (X, d) is compact.) Let i* be the largest rank 
of any optimal strategy. Let X* be the set of all optimal strategies of rank i* . Let Y = lim(X, i*). 
Since each point x . Xi* is an isolated point in Y , there exists some r(x) > 0 such that x is the only 
point of B(x, r(x)) that lies in Y . * We claim that sup(µ, Y \ X*) <µ . Indeed, consider C = .x.X* 
B(x, r(x)). This is an open set. Since Y is closed, Y \ C is closed, too, hence compact. Therefore there 
exists y . Y \ C such that µ(y)= sup(µ, Y \ C). Since X* . C, µ(y) is not optimal, i.e. µ(y) <µ * . Finally, 
by de.nition of r(x) we have Y \ C = Y \ X* . Claim proved. * X* Pick any x . . Let µ0 = sup(µ, Y \ 
X*). Assume that t is large enough so that r(t) < (µ * -µ0)/4 * and di* <r(x *). Note, the di* -covering 
Si* contains x . * Finally, we claim that in a clean phase, x is a winner, and all winners lie in X* 
. Indeed, note that * x dominates any non-optimal strategy y . S of larger or equal rank, i.e. any y 
. S n(Y \X*). This is because µav(x *) - µav(y) = µ * - µ0 - 2r> 2. The claim follows since any optimal 
strategy cannot be dominated by any other strategy. 7 Boundary of tractability: Theorem 1.4 In this section 
we prove Theorem 1.4. In Appendix A we reduce the theorem to that on complete metric spaces. We will 
use a basic fact that a complete metric space is compact if and only if for any r> 0, it can be covered 
by a .nite number of balls of radius r. Algorithmic result. We consider a compact met­ric space (X, d) 
and use an extension of the naive al­gorithm from [24, 27]. In each phase i (which lasts for ti round) 
we .x a covering of X with Ni < 8 balls of radius 2-i (such covering exists by compactness), and run 
a fresh instance of the Ni-armed bandit algorithm ucb1 from [3] on the centers of these balls. (This 
algo­rithm is for the basic MAB problem, in the sense that it does not look at the distances in the metric 
space.) The phase durations ti need to be tuned to the Ni s. In the setting considered in [24, 27] (bounded 
covering di­mension) it su.ces to tune each ti to the corresponding ti in a fairly natural way. The di.culty 
in the present setting is that there are no guarantees on how fast the Ni s grow. To take this into account, 
we .ne-tune each ti to (essentially) all covering numbers N1, ..., Ni+1. Let Rk(t) be the expected regret 
accumulated by the algorithm in the .rst t rounds of phase k. Using the o.-the-shelf regret guarantees 
for ucb1, it is easy to see [24, 27] that * (7.4) Rk(t) = O(JNk t log t)+ Ek t = Ek max(tk,t), where 
t * =2 Nk log Nk . k72 72 kk Let us specify phase durations ti. They are de.ned very di.erently from 
the ones in [24, 27]. In particu­lar, in [24, 27] each ti is .ne-tuned to the corresponding covering 
number Ni by setting ti = t *, and the analysis i works out for metric spaces of bounded covering dimen­sion. 
In our setting, we .ne-tune each ti to (essentially) all covering numbers N1, ..., Ni+1. Speci.cally, 
we de­.ne the ti s inductively as follows: ** ti = min(ti ,t i+1, 2 Li-1 tj). j=1 This completes the 
algorithm, call it A. Lemma 7.1. Consider the Lipschitz MAB problem on a compact and complete metric 
space (X, d). Then RA(t) = 5 E(t) t, where E(t) = min{2-k : t = sk} and sk = Lk ti. In particular, RA(t)= 
o(t). i=1 Proof. First we claim that RA(sk) = 2 Ek sk for each k. Use induction on k. For the induction 
base, note that RA(s1)= R1(t1) = E1t1 by (7.4). Assume the claim holds for some k - 1. Then RA(sk)= RA(sk-1)+ 
Rk(tk) = 2 Ek-1 sk-1 + Ek tk = 2 Ek(sk-1 + tk)=2 Eksk, claim proved. Note that we have used (7.4) and 
the facts that tk = t * and tk = 2 sk-1. k For the general case, let T = sk-1 + t, where t . (0,tk). 
Then by (7.4) we have that * Rk(t) = Ek max(tk,t) = Ek max(tk-1,t) = Ek T, RA(T )= RA(sk-1)+ Rk(T ) = 
2Ek-1sk-1 + EkT = 5EkT. Lower bound: proof sketch. For the lower bound, we consider a metric space (X, 
d) with an in.nitely many disjoint balls B(xi,r*) for some r* > 0. For each ball i we de.ne the wedge 
function supported on this ball: {min{r* - d(x, xi),r* - r} if x . B(xi,r*) G(i,r)(x)= 0 otherwise. 
The balls are partitioned into two in.nite sets: the or­dinary and special balls. The random payo. function 
is then de.ned by taking a constant function, adding the wedge function on each special ball, and randomly 
adding or subtracting the wedge function on each or­dinary ball. Thus, the expected payo. is constant 
throughout the metric space except that it assumes higher values on the special balls. However, the algo­rithm 
has no chance of ever .nding these balls, because at time t they are statistically indistinguishable 
from the 2-t fraction of ordinary balls that randomly hap­pen to never subtract their wedge function 
during the .rst t steps of play. Lower bound: full proof. Suppose (X, d) is not compact. Fix r> 0 such 
that X cannot be covered by a .nite number of balls of radius r. There exists a countably in.nite subset 
S . X such that the balls B(x, r), x . S are mutually disjoint. (Such subset can be constructed inductively.) 
Number the elements of S as s1,s2,..., and denote the ball B(si,r) by B(i). Suppose there exists a Lipschitz 
experts algorithm A that is g(t)-tractable for some g . o(t). Pick an increasing sequence t1,t2,... . 
N such that tk+1 > 2tk = 10 and g(tk) <rk tk/k for each k, where rk = r/2k+1 . Let m0 = 0 and mk = Lk 
4ti for k> 0, and i=1 let Ik = {mk +1,...,mk+1}. The intervals Ik form a partition of N into sets of 
sizes 4t1 , 4t2 ,.... For every i . N, let k be the unique value such that i . Ik and de.ne the following 
Lipschitz function supported in B(si,r): {min{r - d(x, si),r - rk} if x . B(i) Gi(x)= 0 otherwise. If 
J . N is any set of natural numbers, we can de.ne a distribution PJ on payo. functions by sampling independent, 
uniformly-random signs si . {±1} for every i . N and de.ning the payo. function to be p = 12 + Li.J Gi 
+ Li .J siGi. Note that the distribution PJ has expected payo. 1 function µ =+ Li.J Gi. Let us de.ne 
a distribution 2 P over problem instances PJ by letting J be a random subset of N obtained by sampling 
exactly one element jk of each set Ik uniformly at random, independently for each k. Intuitively, consider 
an algorithm that is trying to discover the value of jk. Every time a payo. function pt is revealed, 
we get to see a random {±1} sample at every element of Ik and we can eliminate the possibility that jk 
is one of the elements that sampled -1. This .lters out about half the elements of Ik in every time step, 
but |Ik| = so on average it takes 2tk steps 4tk before we can discover the identity of jk. Until that 
time, whenever we play a strategy in .i.Ik B(i), there is a constant probability that our regret is 
at least rk. Thus our regret is bounded below by rktk = kg(tk). This rules out the possibility of a g(t)-tractable 
algorithm. The following lemma makes this argument precise. Lemma 7.2. PrP.P [R(A, P)(t)= Oµ(g(t))] = 
0. Proof. Let j1,j2,... be the elements of the random set J, numbered so that jk . Ik for all k. For 
any i, t . N, let s(i, t) denote the value of si sampled at time t when sampling the sequence of i.i.d. 
payo. functions pt from distribution PJ . We know that s(jk,t) = 1forall t. In fact if S(k, t) denotes 
the set of all i . Ik such that s(i, 1) = s(i, 2) = ··· = s(i, t) = 1 then conditional on the value of 
the set S(k, t), the value of jk is distributed uniformly at random in S(k, t). As long as this set S(k, 
t) has at least n elements, the probability that the algorithm picks a strategy xt belonging to B(jk) 
at time 1 t is bounded above by , even if we condition on the n event that xt ..i.Ik B(i). For any given 
i . Ik \{jk}, we have PJ (i . S(k, t)) = 2-t and these events are independent for di.erent values of 
i. Setting n =2tk , so that |Ik| = n2, we have PJ [ |S(k, t)|= n ] = LR.Ik, |R|=n PJ [ S(k, t) . R ] 
22-n 2 = (n )(1 - 2-t)n < (n · (1 - 2-t)n-1)n n (7.5) < exp (n(2 ln(n) - (n - 1)/2t)) . As long as t 
= tk-v1, the relation tk > 2t im­plies (n - 1)/2t >n vso the expression (7.5) is bounded above by exp 
(-nn +2n ln(n)), which equals exp (-8tk + 2 ln(4)tk4tk ) and is in turn bounded above by exp(-8tk /2) 
. Let B(j>k)= B(jk+1) . B(jk+2) . ..., and let N(t, k) denote the random variable that counts the number 
of times A selects a strategy in B(j>k) during rounds 1,...,t. We have already demonstrated that for 
all t = tk, (7.6) Pr (xt . B(j>k)) PJ .P = 2-tk+1 + Lc>k exp (-8t£ /2) < 21-tk+1 , where the term 2-tk+1 
accounts for the event that S(£, t) has at least 2tk+1 elements, where £ in the index of the set Ic containing 
the number i such that xt . B(i), if such an i exists. Equation (7.6) implies the bound · 21-tk+1 EPJ 
.P [N(tk,k)] <tk . By Markov s inequality, the probability that N(tk,k) >tk/2 is less than 22-tk+1 . 
By Borel-Cantelli, almost surely the number of k such that N(tk,k) = tk/2 is .nite. The algorithm s expected 
regret at time t is bounded below by rk(tk - N(tk,k)), so with probability 1, for all but .nitely many 
k we have R(A, PJ )(tk) = rktk/2 = (k/2)g(tk). This establishes that A is not g(t)-tractable. 8 Lipschitz 
experts in a (very) high dimension In this section we discuss the full-feedback Lipschitz ex­perts problem 
in (very) high dimensional metric spaces. We posit a new notion of dimensionality which is well­suited 
to describe regret in such problems, and analyze the performance of a simple algorithm in terms of this 
notion. Fix a metric space (X, d). For a subset Y . X and d> 0, a d-covering of Y is a collection of 
sets of diameter at most d whose union contains Y . A subset S . X is a d-hitting set for Y if Y ..x.S 
B(x, d). (So if S is a hitting set for some d-covering of Y then it is a d-hitting set for Y .) Let Nd(Y 
) be the minimal size (cardinality) of a d-covering of Y , i.e. the smallest number of sets of diameter 
at most d su.cient to cover Y . The standard de.nition of the covering dimension is log Nd(Y ) (8.7) 
Cov(Y ) = lim sup . d>0 log(1/d) Covering dimension and its re.nements have been es­sential in the study 
of the Lipschitz MAB problem [27]. However, for the full-feedback Lipschitz experts prob­lem the metrics 
with bounded covering dimension are too easy . We need to consider a much broader class of metrics that 
satisfy a non-trivial bound on what we call the log-covering-dimension: log log Nd(Y ) (8.8) LCD(Y ) 
= lim sup . d>0 log(1/d) To give an example of a metric space with a non­trivial log-covering dimension, 
let us consider a uniform tree a rooted tree in which all nodes at the same level have the same number 
of children. An E-uniform tree metric is a metric on the leaves of an in.nitely deep uniform tree, in 
which the distance between two leaves is E-i, where i is the level of their least common ancestor. It 
is easy to see that an E-uniform tree metric such that the branching factor at each level i is exp(E-ib(2b 
- 1)) has log-covering dimension b. For another example, consider the space of all prob­ability distributions 
over a given metric space (X, d) un­der the Wasserstein W1 metric, a.k.a. the Earthmover distance. It 
is not hard to show that the log-covering di­mension of this space is at most the covering dimension 
of (X, d). Indeed, if (X, d) has diameter D and is cov­ered by balls of radius E/2 centered at points 
x1,...,xM , then the Wasserstein metric is covered by balls of ra­dius E centered at the distributions 
whose support is contained in {x1,...,xM } and whose probabilities are rational numbers with denominator 
I2DM/El. See the full version for details, as well as a matching lower bound on the log-covering dimension 
of the Wasserstein metric. To see how the log-covering dimension is relevant to the Lipschitz experts 
problem, consider the follow­ing simple algorithm, called NaiveExperts(b).8 The algorithm is parameterized 
by b> 0. It runs in phases. Each phase i lasts for T =2i rounds, and outputs its * best guess x . X, 
which is played throughout phase i i + 1. During phase i, the algorithm picks a d-hitting set for X of 
size at most Nd(X), for d = T -1/(b+2). By * the end of the phase, x as de.ned as the point in S i with 
the highest sample average (breaking ties arbitrar­ily). This completes the description of the algorithm. 
It is easy to see that the regret of NaiveExperts is naturally described in terms of the log-covering 
di­mension. The proof is based the argument from [24]. We restate it here for the sake of completeness, 
and to explain how the new dimensionality notion is used. Theorem 8.1. Consider the full-feedback Lipschitz 
ex­perts problem on a metric space (X, d). For each b> LCD(X), algorithm NaiveExperts(b) achieves regret 
R(t)= O(t1-1/(b+2)). Proof. Let Nd = Nd(X), and let µ be the expected payo. function. Consider a given 
phase i of the algorithm. Let T =2i be the phase duration. Let d = T -1/(b+2), and let S . X the d-hitting 
set chosen in this phase. Note that for any su.ciently large T it is the case that Nd < 2d-b . For each 
x . S, let µT (x) be the sample average of the feedback from x by the end of the phase. Then by Cherno. 
bounds, (8.9) Pr[|µT (x) - µ(x)| <rT ] > 1 - (TNd)-3 , where rT = J8 log(TNd) /T < 2d. Note that d is 
chosen speci.cally to ensure that rT = O(d). We can neglect the regret incurred when the event in (8.9) 
does not hold for some x . S. From now on, let us assume that the event in (8.9) holds for all x . S. 
Let ** x be an optimal strategy, and x = argmaxx.S µT (x) i be the best guess . Let x . S be a point 
that covers * x . Then ** µ(x ) = µT (x ) - 2d = µT (x) - 2d ii = µ(x) - 4d = µ(x *) - 5d. Thus the total 
regret Ri+1 from phase i +1 is * Ri+1 = 2i+1 (µ(x *) - µ(x )) = O(dT )= O(T 1-1/(2+b)). i Thus the total 
regret summed over phases is as claimed. 8This algorithm is a version of the naive algorithm [24, 27] 
for the Lipschitz MAB problem. A similar algorithm has been v used by [20] to obtain regret R(T )= O( 
T ) for metric spaces of .nite covering dimension. 8.1 The uniformly Lipschitz experts problem We now 
turn our attention to a restricted version of the full-feedback Lipschitz experts problem in which a 
problem instance (X, d, P) satis.es a further property that each function f . support(P) is itself a 
Lipschitz function on (X, d). We show that for this version, NaiveExperts obtains a signi.cantly better 
regret guarantee, via a more involved analysis. In fact, (as we will see in the next section) for a wide 
class of metric spaces, including E-uniform tree metrics, there is a matching upper bound. Theorem 8.2. 
Consider the uniformly Lipschitz ex­perts problem with full feedback. Fix a metric space (X, d). For 
each b> LCD(X) such that b = 2, NaiveExperts(b-2) achieves regret R(t)= O(t1-1/b). Proof. The preliminaries 
are similar to those in the proof of Theorem 8.1. For simplicity, assume b = 2. Let Nd = Nd(X), and let 
µ be the expected payo. function. Consider a given phase i of the algorithm. Let T =2i be the phase duration. 
Let d = T -1/b, and let S be the d-hitting set chosen in this phase. (The speci.c choice of d is the 
only di.erence between the algorithm here and the algorithm in Theorem 8.1.) Note that |S|= Nd, and for 
any su.ciently large T it is the case that Nd < 2d-b . The rest of the analysis holds for any set S such 
that |S|= Nd. (That is, it is not essential that S is a d-hitting set for X.) For each x . S, let .(x) 
be the sample average of the feedback from x by the end of the * phase. Let y = argmax(µ, S) be the 
optimal strategy i * in the chosen sample, and let x = argmax(., S) be the i algorithm s best guess 
. The crux is to show that ** (8.10) Pr[ µ(y ) - µ(x ) = O(d log T )] > 1 - T -3 . ii Once (8.10) is 
established, the remaining steps is exactly as the proof of Theorem 8.1. Proving (8.10) requires a new 
technique. The obvious approach to use Cherno. Bounds for each x . S separately and then take a Union 
Bound does not work, essentially because one needs to take the Union Bound over too many points. Instead, 
we will use a more e.cient version tail bound: for each x, y . X, we will use Cherno. Bounds applied 
to the random variable f(x) - f(y), where f ~ P and (X, d, P) is the problem instance. For a more convenient 
notation, we de.ne .(x, y)=[ µ(x) - µ(y)]+[ .(y) - .(x)] , Then for any N . N we have (8.11) Pr [ |.(x, 
y)|= d(x, y) J8 log(TN)/T ] > 1 - (TN)-3 .  The point is that the slack in the Cherno. Bound is scaled 
by the factor of d(x, y). This is because each f . support(P) is a Lipschitz function on (X, d), In order 
to take advantage of (8.11), let us de.ne the following structure that we call the covering tree of the 
metric space (X, d). This structure consists of a rooted tree T and non-empty subsets X(u) . X for each 
internal node u. Let VT be the set of all internal nodes. Let Tj be the set of all level-j internal nodes 
(so that T0 is a singleton set containing the root). For each u . VT , let C(u) be the set of all children 
of u. For each node u .Tj the structure satis.es the following two properties: (i) set X(u) has diameter 
at most 2-j , (ii) the sets X(v), v .C(u) form a partition of X(u). This completes the de.nition. By 
de.nition of the covering number Nd(·) there exist a covering tree T in which each node u .Tj has fan-out 
N2-j (X(u)). Fix one such covering tree. For each node u . VT , de.ne (8.12) s(u) = argmax(µ, X (u) n 
S) .(u) = argmax(., X (u) n S), where the tie-breaking rule is the same as in the algorithm. Let n = 
Ilog 1 l. Let us say that phase i is clean if d the following two properties hold: (i) for each node 
u . VT any two children v, w .C(u) we have | .(s(v),s(w)) |= 4d.  (ii) for any x, y . S such that d(x, 
y) = d we have |.(x, y)|= 4d.  Claim 8.1. For any su.ciently large i, phase i is clean with probability 
at least 1 - T -2 . Proof. To prove (i), let j be such that u .Tj. We consider each j separately. Note 
that (i) is trivial for j>n. Now .x j = n and apply the Cherno.-style bound (8.11) with N = |Tj| and 
(x, y)=(s(v),s(w)). Since |Tl|= 22lb |Tl-1| for each su.ciently large l, it 2lb = C + 4 2jb follows that 
log |Tj |= C + Lj , where l=1 3 C is a constant that depends only on the metric space and b. It is easy 
to check that for any su.ciently large phase i (which, in turn, determines T , d and n), the slack in 
(8.11) is at most 4d: d(x, y) J8 log(TN)/T = 3 d(x, y) Jlog(N)/T = 42-j V2bj /2bn =4d 2-(n-j)(b-2)/2 
= 4d. Interestingly, the right-most inequality above is the only place in the proof where it is essential 
that b = 2. To prove (ii), apply (8.11) with N = |S| similarly. Claim proved. From now on we will consider 
clean phase. (We can ignore regret incurred in the event that the phase is not clean.) We focus on the 
quantity .*(u)= .(s(u),.(u)). Note that by de.nition .*(u) = 0. The central argument of this proof is 
the following upper bound on .*(u). Claim 8.2. In a clean phase, .*(u) = O(d)(n - j) for each j = n and 
each u .Tj . Proof. Use induction on j. The base case j = n follows by part (ii) of the de.nition of 
the clean phase, since for u .Tn both s(u) and .(u) lie in X(u), the set of diameter at most d. For the 
induction step, assume the claim holds for each v .Tj+1, and let us prove it for some .xed u .Tj . Pick 
children u, v .C(u) such that s(u) . X(v) and .(u) . X(w). Since the tie-breaking rules in (8.12) is 
.xed for all nodes in the covering tree, it follows that s(u)= s(v) and .(u)= .(w). Then .*(w) + .(s(v),s(w)) 
= .(s(w),.(u)) + .(s(u),s(w)) = µ(s(w)) - µ(.(u)) + .(.(u)) - .(s(w)) + µ(s(u)) - µ(s(w)) + .(s(w)) 
- .(s(u)) =.*(u). Claim follows since .*(w) = O(d)(n - j - 1) by induction, and .(s(v),s(w)) = 4d by 
part (i) in the de.nition of the clean phase. To complete the proof of (8.10), let u0 be the root ** 
 of the covering tree. Then y = s(u0) and x = .(u0). ii Therefore by Claim 8.2 (applied for T0 = {u0}) 
we have ** ** O(dn) = .*(u0)=.*(yi ,x ) = µ(y ) - µ(x ). iii 9 Lipschitz experts: regret characterization 
As it turns out, the log-covering dimension (8.8) is not the right notion to characterize regret for 
arbitrary metric spaces. We need a more re.ned version, similar to the max-min-covering dimension from 
[27]: (9.13) MaxMinLCD(X) = supY .X infZ LCD(Z) where the in.mum is taken over all open non-empty subsets 
Z . Y . Note that in general MaxMinLCD = LCD(X). The equality holds for homogenous metric spaces such 
as E-uniform tree metrics. We prove that Theorems 1.5 holds with b = MaxMinLCD(X). Theorem 9.1. Fix a 
metric space (X, d) and let b = MaxMinLCD(X). The full-feedback Lipschitz experts b+1 problem on (X, 
d) is (t. )-tractable for any .> , b+2 and not (t. )-tractable for any .< b-1 . b  For the lower bound, 
we use a suitably thick version of the ball-tree from Section 3 in conjunction with the (E, d, k)-ensemble 
idea from Section 3, see Section 9.1. For the algorithmic result, we combine the naive experts algorithm 
(NaiveExperts) with (an extension of) the trans.nite fat decomposition technique from [27], see Section 
9.2. The lower bound in Theorem 9.1 holds for the uniformly Lipschitz experts problem. It follows that 
the upper bound in Theorem 8.2 is optimal for metric spaces such that MaxMinLCD(X)= LCD(X), e.g. for 
E­uniform tree metrics. In fact, we can plug the improved analysis of NaiveExperts from Theorem 8.2 into 
the algorithmic technique from Theorem 9.1 and obtain a matching upper bound in terms of the MaxMinLCD. 
Thus (in conjunction with Theorem 1.3) we have a complete characterization for regret: Theorem 9.2. Consider 
the uniformly Lipschitz ex­perts problem with full feedback. Fix a metric space (X, d) with uncountably 
many points, and let b = MaxMinLCD(X). The problem on (X, d) is (t. )-tractable 1 for any .> max( b-1 
, ), and not (t.)-tractable for any b 2 1 .< max( b-1 , ). b 2 The proof of the upper bound in Theorem 
9.2 proceeds exactly that in Theorem 9.1, except that we use a more e.cient analysis of NaiveExperts. 
 9.1 The MaxMinLCD lower bound (Theorem 9.2) d-1 If MaxMinLCD(X)= d, and .< , let us d b-1 .rst choose 
b<c<d such that .< b . Let Y . X be a subspace such that c = inf{LCD(Z): open, nonempty Z . Y }. We will 
repeatedly use the following packing lemma that relies on the fact that b< LCD(U) for all nonempty U 
. Y . Lemma 9.1. For any nonempty open U . Y and any r0 > 0 there exists r . (0,r0) such that U contains 
more than 2r -b disjoint balls of radius r. Proof. Let r<r0 be a positive number such that every covering 
of U requires more than 2r -b balls of radius 2r. Such an r exists, because LCD(U) >b. Now let P = {B1,B2,...,BM 
} be any maximal collection of disjoint r-balls. For every y . Y there must exist some ball Bi (1 = i 
= M) whose center is within distance 2r of y, as otherwise B(y, r) would be disjoint from every element 
of P contradicting the maximality of that collection. If we enlarge each ball Bi to a ball B+ of i radius 
2r, then every y . Y is contained in one of the balls {B+ | 1 = i = M}, i.e. they form a covering of 
Y . i Hence M = 2r -b as desired. Using the packing lemma we recursively construct an in.nite sequence 
of sets B0, B1,... each consisting of .nitely many disjoint open balls of equal radius ri in Y . Let 
B0 = {Y } and let r0 =1/4. If i> 0, let ri <ri-1/4 be a positive number small enough that for every ball 
B = B(x, ri-1) .Bi-1, the sub-ball = I2r -b i B(x, ri-1/2) contains ni l disjoint balls of radius ri. 
Let Bi(B) denote this collection of disjoint balls and let Bi = B.Bi-1 Bi(B). For each ball B = B(x, 
r) .Bi, de.ne a bump function supported in B by {min{r - d(x, si), r/2} if x . B GB(x)= 0 otherwise. 
 Let B8 = .8 Note that B8 is analogous to the i=0Bi. ball-tree de.ned in Section 3. For a mapping s 
: B8 . {±1}, de.ne a function p : X . [0, 1] by (9.14) p(x)= 12 + LB.B8 s(B)GB(x). The sum converges 
absolutely because every x . X belongs to at most ball in Bi for each i, so the absolute value of the 
in.nite sum in (9.14) is bounded above by L8 < 1/3. Moreover, one can verify that our i=0 ri construction 
ensures that p(x) is a Lipschitz function of x with Lipschitz constant 1. If Q is any subset of B8, one 
can de.ne a problem instance of the full-feedback Lipschitz experts problem: a distribution PQ on payo. 
functions p by sampling s(B) . {±1} uniformly at random for B .Q and performing biased sampling of s(B) 
. {±1} with E[s(B)] = 1/3 when B .Q, and then de.ning p using (9.14). Note that the distribution PQ has 
expected 1 payo. function µ = 2 + LB.Q GB/3. In proving the lower bound, we will consider the distribution 
P on Lipschitz experts problem instances PQ where Q is a random subset of B8 obtained by sampling one 
ball B0 .B0 uniformly at random, and also sampling one element Q(B) .Bi(B) uniformly at random and independently 
for each B .Bi-1. By analogy with the notion of complete lineage de.ned in Section 3, we will refer to 
any such set Q as a complete lineage in B8. Given a complete lineage Q, we can de.ne an in.nite nested 
sequence of balls B0 . B1 . · ·· by specifying that Bi+1 = Q(Bi) for each i. If µ is the expectation 
of a random payo. function p sampled from PQ, then µ achieves its maximum value 1 + 1 L8 i=0 ri at the 
unique point x * .n8 At any 26 i=0Bi. point x . Bj, we have *)-µ(x) = (1 L8 )-(1 L8 ) 1 µ(x = rj. 6 
i=j ri4 i=j+1 ri6 We now .nish the lower bound proof as in the proof of Lemma 3.2. For each complete 
lineage Q and ball B .Bi-1, let B1,B2,...,Bni be the elements of Bi(B). Consider the sets Q0 = Q\Q(B) 
and Qj = Q0.{Bj } for j =1, 2,...,ni. The distributions (PQ0 , PQ1 ,..., PQni ) 11 constitute an (E, 
d, k)-ensemble for E = rk, d = , and 62 -b k = ni. Consequently, for ti = r , the inequality i ti < ln(17k)/2d2 
holds, and we obtain a lower bound 1-b (b-1)/b R(A, PQj )(ti) > Eti/2 = O(ri ) = O(ti ) for at least 
half of the distributions PQj in the ensemble. Recalling that .< b-1 , we see that the problem is not 
b t.-tractable.  9.2 The MaxMinLCD upper bound: proofs for Theorem 9.1 and Theorem 9.2 First, let us 
incorporate the analysis from Section 8 via the following lemma. Lemma 9.2. Consider an instance (X, 
d, P) of the full­ * feedback Lipschitz experts problem, and let x . X be * an optimal point. Fix subset 
U . X which contains x , and let b> LCD(U). Then for any su.ciently large T and d = T -1/(b+2) the following 
holds: (a) Let S be a d-hitting set for U, |S|= Nd(U). Consider the feedback of all points in S over 
T rounds; let x be the point in S with the largest sample average (break ties arbitrarily). Then Pr[µ(x 
*) - µ(x) <O(d log T )] > 1 - T -2 . (b) For the uniformly Lipschitz experts problem and b = 2, property 
(a) holds for d = T -1/b. Trans.nite LCD decomposition. We rede.ne the trans.nite fat decomposition from 
[27] with respect to the log-covering dimension rather than the covering dimension. Definition 9.1. Fix 
a metric space (X, d). Let ß de­note an arbitrary ordinal. A trans.nite LCD decompo­sition of depth ß 
and dimension b is a trans.nite se­quence {S.}0=.=ß of closed subsets of X such that: (a) S0 = X, Sß 
= Ø, and S. . S. whenever .<.. (b) if V . X is closed, then the set {ordinals . = ß: V intersects S. 
} has a maximum element. (c) for any ordinal . = ß and any open set U . X containing S.+1 we have LCD(S. 
\ U) = b.  The existence of suitable decompositions and the connection to MaxMinLCD is derived exactly 
as in Propo­sition 3.15 in [27]. Lemma 9.3. For every compact metric space (X, d), MaxMinLCD(X) is equal 
to the in.mum of all b such that X has a trans.nite LCD decomposition of dimension b. In what follows, 
let us .x metric space (X, d) and b> MaxMinLCD(X), and let {S.}0=.=ß be a trans.nite LCD decomposition 
of depth ß and dimension b. For each x . X, let the depth of x be the maximal ordinal . such that x . 
S.. (Such an ordinal exists by De.nition 9.1(b).) Access to the metric space. The algorithm requires 
two oracles: the depth oracle Depth(·) and the covering oracle Cover(·). Both oracles input a .nite collection 
F of open balls B0,B1,...,Bn, given via the centers and the radii, and return a point in X. Let B be 
the union of these balls, and let B be the closure of B. A call to oracle Depth(F) returns an arbitrary 
point x . B n S., where . is the maximum ordinal such that S. intersects B. (Such an ordinal exists by 
* De.nition 9.1(b).) Given a point y . X of depth .,a * call to oracle Cover(y, F) either reports that 
B covers S., or it returns an arbitrary point x . S. \ B. A call * to Cover(Ø, F) is equivalent to the 
call Cover(y, F) for * some y . S0. The covering oracle will be used to construct d-nets as follows. 
First, using successive calls to Cover(Ø, F) one can construct a d-net for X. Second, given a point * 
 y . X of depth . and a collection of open balls whose * union is B, using successive calls to Cover(y, 
·) one can construct a d-net for S. \ B. The second usage is geared towards the scenario when S.+1 . 
B and for ** some optimal strategy x we have x . S. \ B. Then by De.nition 9.1(c) we have LCD(S. \ B) 
<b, and one can apply Lemma 9.2. The algorithm. Our algorithm proceeds in phases i =1, 2, 3,... of 2i 
rounds each. Each phase i outputs ** two strategies: xi ,y . X that we call the best guess i and the 
depth estimate. Throughout phase i, the * algorithm plays the best guess x from the previous i-1 * 
phase. The depth estimate y is used as if its depth i-1 is equal to the depth of some optimal strategy. 
(We show that for a large enough i this is indeed the case with a very high probability.) In the end 
of the phase, an algorithm selects a .nite set Ai . X of active points, as described below. * Once this 
set is chosen, x is de.ned simply as a point i in Ai with the largest sample average of the feedback 
* (breaking ties arbitrarily). It remains to de.ne y and Ai itself. Let T =2i be the phase duration. 
Using the covering oracle, the algorithm constructs (roughly) the v T .nest r-net containing at most 
2 points. Speci.cally, the algorithm constructs 2-j -nets Nj, for j =0, 1, 2,..., until it .nds the largest 
j such that Nj contains at most v T 2 points. Let r =2-j and N = Nj. For each x . X, let µT (x) be the 
sample average of the feedback during this phase. Let * * .T (x)= µT - µT (x), where µ = max(µT , N 
) T * De.ne the depth estimate y to be the output of the i oracle call Depth(F), where F = {B(x, r): 
x .N and .T (x) <r}. Finally, let us specify Ai. Let B be the union of balls (9.15) {B(x, r): x .N and 
.T (x) > 2(rT + r) }, where rT = J8 log(T |N |)/T is chosen so that by Cherno. Bounds for each x .N we 
have (9.16) Pr[|µT (x) - µ(x)| <rT ] > 1 - (T |N |)-3 . T -1/b Let d = for the uniformly Lipschitz experts 
problem, and d = T -1/(b+2) otherwise. Let QT =2d-b be the quota on the number of active points. Given 
* a point y whose depth is (say) ., algorithm uses i-1 the covering oracle to construct a d-net N n for 
S. \ B. De.ne Ai as N n or an arbitrary QT -point subset thereof, whichever is smaller.9 (Very high-level) 
sketch of the analysis. The proof roughly follows that of Theorem 3.16 in [27]. Call a phase clean if 
the event in (9.16) holds for all x .Ni and the appropriate version of this event holds for all x . Ai. 
(The regret from phases which are not clean is negligible). On a very high level, the proof consists 
of two steps. First we show that for a su.ciently large i, * if phase i is clean then the depth estimate 
y is correct, i in the sense that it is indeed equal to the depth of some optimal strategy. The argument 
is similar to the one in Lemma 4.2. Second, we show that for a su.ciently large * i, if the depth estimate 
y is correct (i.e. its depth i-1 is equal to that of some optimal strategy), and phase i * * is clean, 
then the best guess x is good, namely µ(x ) i i is within O(dlogT ) of the optimum. The reason is that, 
* letting . be the depth of y , one can show that for a i-1 su.ciently large T the set B (de.ned in (9.15)) 
contains S.+1 and does not contain some optimal strategy. By de.nition of the trans.nite LCD decomposition 
we have LCD(S. \U) <b, so in our construction the quota QT on the number of active points permits Ai 
to be a d-cover of S. \ U. Now we can use Lemma 9.2 to guarantee the * quality of xi . The .nal regret 
computation is similar to the one in the proof of Theorem 8.1. References 9The interesting case here 
is |N '|= QT . If N ' contains too many points, the choice of Ai is not essential for the analysis. [1] 
Rajeev Agrawal. The continuum-armed bandit prob­lem. SIAM J. Control and Optimization, 33(6):1926 1951, 
1995. [2] Peter Auer. Using con.dence bounds for exploitation­exploration trade-o.s. J. Machine Learning 
Research, 3:397 422, 2002. Preliminary version in 41st IEEE FOCS, 2000. [3] Peter Auer, Nicol`o Cesa-Bianchi, 
and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235 
256, 2002. Preliminary version in 15th ICML, 1998. [4] Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, 
and Robert E. Schapire. The nonstochastic multiarmed bandit problem. SIAM J. Comput., 32(1):48 77, 2002. 
Preliminary version in 36th IEEE FOCS, 1995. [5] Peter Auer, Ronald Ortner, and Csaba Szepesv´ari. Improved 
Rates for the Stochastic Continuum-Armed Bandit Problem. In 20th Conference on Learning Theory (COLT), 
pages 454 468, 2007. [6] Baruch Awerbuch and Robert Kleinberg. Online lin­ear optimization and adaptive 
routing. Journal of Computer and System Sciences, 74(1):97 114, Febru­ary 2008. Preliminary version appeared 
in 36th ACM STOC, 2004. [7] Je.rey Banks and Rangarajan Sundaram. Denumerable-armed bandits. Econometrica, 
60(5):1071 1096, 1992. ¨ [8] G. Cantor. Uber unendliche, lineare Punktmannich­faltigkeiten, 4. Mathematische 
Annalen, 21:51 58, 1883. In G. Cantor, Gesammelte Abhandlungen math­ematischen und philosophischen Inhalts, 
Berlin: Teub­ner, 1932; reprinted in 1980; reprint ed., Hildesheim: Olms, 1966. [9] Nicol`o Cesa-Bianchi, 
Yoav Freund, David Haussler, David P. Helmbold, Robert E. Schapire, and Man­fred K. Warmuth. How to use 
expert advice. J. ACM, 44(3):427 485, 1997. [10] Nicol`o Cesa-Bianchi and G´abor Lugosi. Prediction, 
learning, and games. Cambridge University Press, 2006. [11] Eric Cope. Regret and convergence bounds 
for immediate-reward reinforcement learning with contin­uous action spaces, 2004. Unpublished manuscript. 
[12] Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. John Wiley &#38; Sons, New York, 
1991. [13] Varsha Dani and Thomas P. Hayes. Robbing the bandit: less regret in online geometric optimization 
against an adaptive adversary. In 17th ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 937 943, 2006. 
[14] Varsha Dani, Thomas P. Hayes, and Sham Kakade. The Price of Bandit Information for Online Optimiza­tion. 
In 20th Advances in Neural Information Process­ing Systems (NIPS), 2007. [15] Abraham Flaxman, Adam Kalai, 
and H. Brendan McMahan. Online Convex Optimization in the Bandit Setting: Gradient Descent without a 
Gradient. In 16th  ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 385 394, 2005. [16] J. C. Gittins. 
Multi-Armed Bandit Allocation Indices. John Wiley &#38; Sons, 1989. [17] J. C. Gittins and D. M. Jones. 
A dynamic allocation index for the sequential design of experiments. In J. Gani et al., editor, Progress 
in Statistics, pages 241 266. North-Holland, 1974. [18] Sudipta Guha and Kamesh Munagala. Approximation 
algorithms for partial-information based stochastic con­trol with Markovian rewards. In 48th Symp. on 
Foun­dations of Computer Science (FOCS), pages 483 493, 2007. [19] Sudipta Guha, Kamesh Munagala, and 
Peng Shi. Ap­proximation algorithms for restless bandit problems. In 20th ACM-SIAM Symp. on Discrete 
Algorithms (SODA), pages 28 37, 2009. [20] Anupam Gupta, Mike Dinitz, and Kanat Tangwongsan. Private 
communication, 2007. [21] Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In 20th ACM-SIAM 
Symp. on Discrete Algorithms (SODA), pages 38 47, 2009. [22] Elad Hazan and Nimrod Megiddo. Online Learning 
with Prior Information. In 20th Conference on Learn­ing Theory (COLT), pages 499 513, 2007. [23] Sham 
M. Kakade, Adam T. Kalai, and Katrina Ligett. Playing Games with Approximation Algorithms. In 39th ACM 
Symp. on Theory of Computing (STOC), 2007. [24] Robert Kleinberg. Nearly tight bounds for the continuum-armed 
bandit problem. In 18th Advances in Neural Information Processing Systems (NIPS), 2004. Full version 
appeared in the author s thesis (MIT, 1995). [25] Robert Kleinberg. Online Decision Problems with Large 
Strategy Sets. PhD thesis, MIT, Boston, MA, 2005. [26] Robert Kleinberg, Alexandru Niculescu-Mizil, and 
Yo­geshwer Sharma. Regret bounds for sleeping experts and bandits. In 21st Conference on Learning Theory 
(COLT), pages 425 436, 2008. [27] Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-Armed Bandits 
in Metric Spaces. In 40th ACM Symp. on Theory of Computing (STOC), pages 681 690, 2008. [28] T.L. Lai 
and Herbert Robbins. Asymptotically e.cient Adaptive Allocation Rules. Advances in Applied Math­ematics, 
6:4 22, 1985. [29] S. Mazurkiewicz and W. Sierpinski. Contribution `a la topologie des ensembles d´enombrables. 
Fund. Math., 1:17 27, 1920. [30] H. Brendan McMahan and Avrim Blum. Online Geo­metric Optimization in 
the Bandit Setting Against an Adaptive Adversary. In 17th Conference on Learning Theory (COLT), pages 
109 123, 2004. [31] Sandeep Pandey, Deepak Agarwal, Deepayan Chakrabarti, and Vanja Josifovski. Bandits 
for Taxonomies: A Model-based Approach. In SIAM Intl. Conf. on Data Mining (SDM), 2007. [32] V. Vovk. 
A game of prediction with expert advice. J. Computer and System Sciences, 56(2):153 173, 1998. [33] P. 
Whittle. Restless bandits: Activity allocation in a changing world. J. of Appl. Prob., 25A:287 298, 1988. 
 A Reduction to compact metric spaces In this section we reduce the Lipschitz MAB problem to that on 
complete metric spaces. Lemma A.1. The Lipschitz MAB problem on a metric space (X, d) is f(t)-tractable 
if and only if it is f(t)­tractable on the completion of (X, d). Likewise for the Lipschitz experts problem 
with double feedback. Proof. Let (X, d) be a metric space with completion (Y, d). Since Y contain an 
isometric copy of X, we will abuse notation and consider X as a subset of Y . We will present the proof 
the Lipschitz MAB problem; for the experts problem with double feedback, the proof is similar. Given 
an algorithm AX which is f(t)-tractable for (X, d), we may use it as a Lipschitz MAB algorithm for (Y, 
d) as well. (The algorithm has the property that it never selects a point of Y \ X, but this doesn t 
prevent us from using it when the metric space is (Y, d).) The fact that X is dense in Y implies that 
for every Lipschitz payo. function µ de.ned on Y , we have sup(µ, X) = sup(µ, Y ). From this, it follows 
immediately that the regret of AX , when considered a Lipschitz MAB algorithm for (X, d), is the same 
as its regret when considered as a Lipschitz MAB algorithm for (Y, d). Conversely, given an algorithm 
AY which is f(t)­tractable for (Y, d), we may design a Lipschitz MAB algorithm AX for (X, d) by running 
AY and perturbing its output slightly. Speci.cally, for each point y . Y and each t . N we .x x = x(y, 
t) . X such that d(x, y) < 2-t . If AY recommends playing strategy yt . Y at time t, algorithm AX instead 
plays x = x(y, t). Let p be the observed payo.. Algorithm AX draws an independent 0-1 random sample with 
expectation p, and reports this sample to AY . This completes the description of the modi.ed algorithm 
AX . Suppose AX is not f(t)-tractable. Then for some problem instance I on (Y, d), letting RX (t) be 
the expected regret of AX on this instance, we have that supt.N RX (t)/f(t)= 8. Let µ be the expected 
payo. function in I. Consider the following two problem instances of a MAB problem on Y , called I1 and 
I2, in which if point y . Y is played at time t, the payo. is an independent 0-1 random sample with expectation 
µ(y) and µ(x(y, t)), respectively. Note that algorithm AY is f(t)-tractable on I1, and its behavior on 
I2 is identical to that of AX on the original problem instance I. It follows that by observing the payo.s 
of AY one can tell apart I1 and I2 with high probability. Speci.cally, there is a classi.er C which queries 
one point in each round, such that for in.nitely many times t it tell apart I1 and I2 with success probability 
p(t) . 1. Now, the latter is information-theoretically impossible. To see this, let Ht be the t-round 
history of the algorithm (the sequence of points queried, and outputs received), and consider the distribution 
of Ht under problem instances I8 and I. (call these distributions q1 and q2). Let us consider and look 
at their KL­divergence. By the chain rule (See Lemma B.1), we can 1 show that KL(q1,q2) < . (We omit 
the details.) It 2 follows that letting St be the event that C classi.es the instance as I1 after round 
t, we have Pq1 [St] - Pq2 [St] = KL(q1,q2) = 1 . For any large enough time t, Pq1 [St] < 2 1 , in which 
case C makes a mistake (on I2) with constant 4 probability. Lemma A.2. Consider The experts MAB problem 
with full feedback. If it is f(t)-tractable on a metric space (X, d) then it is f(t)-tractable on the 
completion of (X, d). Proof. Identical to the easy ( only if ) direction of Lemma A.1. Remark. Lower 
bounds only require Lemma A.2, or the easy ( only if ) direction of Lemma A.1. For the upper bounds (algorithmic 
results), we can either quote the if direction of Lemma A.1, or prove the desired property directly for 
the speci.c type algorithms that we use (which is much easier but less elegant). B KL-divergence techniques 
Our proof will use the notion of Kullback-Leibler diver­gence (or KL-divergence), de.ned as follows. 
Definition B.1. Let O be a .nite set with two proba­bility measures p, q. Their Kullback-Leibler divergence, 
or KL-divergence, is the sum KL(p; q)= Lx.O p(x) ln (p(x) ) , q(x) with the convention that p(x) ln(p(x)/q(x)) 
is inter­preted to be 0 when p(x)=0 and +8 when p(x) > 0 and q(x)=0. If Y is a random variable de.ned 
on O and taking values in some set G, the conditional Kullback-Leibler divergence of p and q given Y 
is the sum KL(p; q | Y )= Lx.O p(x) ln (p(x | Y =Y (x)) ) , q(x | Y =Y (x)) where terms containing log(0) 
or log(8) are handled according to the same convention as above. The de.nition can be applied to an 
in.nite sample space O provided that q is absolutely continuous with respect to p. For details, see [25], 
Chapter 2.7. The following lemma summarizes some standard facts about KL-divergence; for proofs, see 
[12, 25]. Lemma B.1. Let p, q be two probability measures on a measure space (O, F) and let Y be a random 
variable de.ned on O and taking values in some .nite set G. De.ne a pair of probability measures pY ,qY 
on G by specifying that pY (y)= p(Y = y),qY (y)= q(Y = y) for each y . G. Then KL(p; q | Y ) = 0 and 
KL(p; q)= KL(p; q | Y )+ KL(pY ; qY ). An easy corollary is the following lemma which ex­presses the 
KL-divergence of two distributions on se­quences as a sum of conditional KL-divergences. Lemma B.2. Let 
O be a sample space, and suppose p, q are two probability measures on On, the set of n-tuples of elements 
of O. For a sample point J. . On, let .i denote ii its .rst i components. If p,qdenote the probability 
measures induced on Oi by p (resp. q) then KL(p; q)= Ln KL(pi; qi | .i-1). i=1 Proof. For m =1, 2,...,n, 
the formula KL(pm; qm)= Lm KL(pi; qi | .i-1) follows by induction on m, using i=1 Lemma B.1. The following 
three lemmas will also be useful in our lower bound argument. Here and henceforth we will use the following 
notational convention: for real num­bers a, b . [0, 1], KL(a; b) denotes the KL-divergence KL(p; q) where 
p, q are probability measures on {0, 1}such that p({1})= a, q({1})= b. In other words, KL(a; b)= a ln 
(a ) + (1 - a) ln (1-a ) . b 1-b Lemma B.3. For any 0 <E<y = 1, KL(y - E; y) <E2/y(1 - y). Proof. A 
calculation using the inequality ln(1 + x) <x (valid for x> 0) yields KL(y - E; y)=(y - E) ln (y-7 ) 
+ (1 - y + E) ln (1-y+7 ) y 1-y < (y - E) (y-7 - 1) + (1 - y + E) (1-y+7 - 1) y 1-y -7(y-7) + 7(1-y+7) 
72 == y 1-yy(1-y) . Lemma B.4. Let O be a sample space with two proba­bility measures p, q whose KL-divergence 
is .. For any event E, the probabilities p(E),q(E) satisfy q(E) = p(E) exp (-.+1/e ) . p(E)  A consequence 
of the lemma, stated in less quantitative terms, is the following: if . = KL(p; q) is bounded above and 
p(E) is bounded away from zero then q(E) is bounded away from zero. Proof. Let a = p(E),b = q(E),c = 
(1 - a)/(1 - b). Applying Lemma B.1 with Y as the indicator random variable of E we obtain . = KL(p; 
q) = KL(pY ; qY ) = a ln (a ) + (1 - a) ln (1-a ) b 1-b = a ln (a ) + (1 - b) c ln(c). b Now using the 
inequality c ln(c) =-1/e, (valid for all c = 0) we obtain . = a ln(a/b) - (1 - b)/e = a ln(a/b) - 1/e. 
The lemma follows by rearranging terms. Lemma B.5. Let p, q be two probability measures, and 1 suppose 
that for some d . (0, ] they satisfy 2 . events E, 1 - d< pq((EE)) < 1+ d Then KL(p; q) <d2 . Proof. 
We will prove the lemma assuming the sample space is .nite. The result for general measure spaces follows 
by taking a supremum. For every x in the sample space O, let r(x)= qp((xx)) -1 and note that |r(x)| <d 
for all x. Now we make use of the inequality ln(1 + x) = x - x2, valid for x =-12 . 1 KL(p; q)= Lx p(x) 
ln (p(x) ) = Lx p(x) ln () q(x) 1+r(x) = -Lp(x) ln(1 + r(x)) x =-Lx p(x)[r(x) - (r(x))2] < - (Lx p(x)r(x)) 
+ d2 (Lx p(x)) = - (Lx q(x) - p(x)) + d2 = d2 . Proof of Theorem 3.2: LetO = [0, 1]X . Us­ing Property 
1 of an (E, d, k)-ensemble combined with Lemma B.5, we .nd that KL(Pi; P0) <d2 . Let A be an experts 
algorithm whose random bits are drawn from a sample space G with probability measure .. For any positive 
integer s< ln(17k)/2d2 , s let pdenote the measure . × (Pi)s on the probability i space G × Os . By the 
chain rule for KL-divergence ss (Lemma B.2), KL(p; p) < sd2 < ln(17k)/2. Now let i 0 Es denote the event 
that A selects a point x . Si at i s time s. If p(Es) = 1 then Lemma B.4 implies ii 2 ss ln(17k)/2+1/e 
p (Es) = p (Es) exp- 0iii s p(Es) ii 4 = 1 exp (- ln(k) + ln(17) - 2 ) >. 2 ek The events {Eis | 1 = 
i = k} are mutually exclusive, so s 4 fewer than k/4 of them can satisfy p0(Eis) > k . Conse­ s quently, 
fewer than k/4 of them can satisfy pi (Eis) = 21 , a property we denote in this proof by saying that 
s is satisfactory for i. Now assume t< ln(17k)/2d2 . For a uniformly random i .{1,...,k}, the expected 
number of satisfactory s .{1,...,t} is less than t/4, so by Markov s inequality, for at least half of 
the i . {1,...,k}, the number of satisfactory s .{1,...,t} is less than t/2. Property 2 of an (E, d, 
k)-ensemble guaran­tees that every unsatisfactory s contributes at least E to the regret of A when the 
problem instance is Pi. There­fore, at least half of the measures Pi have the property that R(A, Pi)(t) 
= Et/2. B.1 Proof of Claim 5.1 Recall that in Section 5 we de.ned a pair of payo. functions µ0,µi and 
a ball Bi of radius ri such that µ0 = µi on X \ Bi, while for x . Bi 33 we have = µ0(x) = µi(x) = µ0(x)+ 
ri = . Thus, 8 44 by Lemma B.3, KL(µ0(x); µi(x)) <ri 2/3 for all x . X, and KL(µ0(x); µi(x))=0 for x 
. Bi. Represent the algorithm s choice and the payo. observed at any given time t by a pair (xt,yt). 
Let O= X × [0, 1] denote the set of all such pairs. When a given algorithm A plays against payo. functions 
µ0,µi, tt this de.nes two di.erent probability measures p0,pi on the set Ot of possible t-step histories. 
Let .t denote a sample point in Ot . The bounds derived in the previous paragraph imply that for any 
non-negative integer s, s+1 s+1 12 (B.1) KL(p ; p | .s) <r P0(xs+1 . Bi). 0 i 3 i Summing equation 
(B.1) for s =0, 1,...,t - 1 and applying Lemma B.2 we obtain tt 12 (B.2) KL(p0; p ) <r Lt P0(xs . Bi) 
i3 is=1 12 = r E0(Ni(t)), 3 i where the last equation follows from the de.nition of Ni(t) as the number 
of times algorithm A selects a strategy in Bi during the .rst t rounds. The bound in Claim 5.1 now follows 
by applying Lemma B.4 with the event S playing the role of E, P0 playing the role of p, and Pi playing 
the role of q.  
			