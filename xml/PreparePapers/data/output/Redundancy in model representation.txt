
 Proceedings of the 1996 Winter Simulation Conference ed. J. M. Charnes, D. J. Morrice, D. T. Brunner, 
and J. J. Swain REDUNDANCY IN MODEL REPRESENTATION A BLESSING OR A CURSE? Richard E. Nance C. Michael 
Overstreet Ernest H. Page Systems Research Center Computer Science Department C3 Modeling &#38; Simulation 
Center Vhginia Polytechnic Institute Old Dominion University and State University Norfolk, VA Blacksburg, 
VA 24061-0251 USA ABSTRACT With the intent of dispelling the prevailing negative connotations associated 
with redundancy, we argue that redundancy can effect benefits in model speci­fication as opposed to model 
execution. Sources of redundancy are classified as accidental or intentional, and several examples are 
given for each. The com­parative benefits and detriments are dkcussed briefly, and for the most interesting 
source of redundancy that induced by a modeling methodology, we demon­strate that automated elimination 
of redundancy can axtually improve the execution time. Although the set of models investigated is small, 
these results are encouraging for researchers in modeling methodolo­gies using automated model diagnosis. 
BACKGROUND As computing technology has advanced, the prob­lems perceived as solvable have grown more 
challeng­ing, and the consequences have been models of ever­increasing size and complexity. Often, model 
devel­opment efforts focus on the edge of what is currently technically feasible. The need for control 
and disci­pline in the specification of such models, accompanied by a recognition of the needs of humans 
for assistance in performing such complex t~ks, have led to the emergence of modeling methodologies and 
supporting environments. Recognition of the importance of mod­eling methodologies and computer-assisted 
support is evident in the prescriptive modeling community through efforts such as ANALYZE (Greenberg 
1983; 1987; 1993), GAMS (Bisschop and Meeraus 1982; Brooke, Kendrick and Meeraus 1992) and Structured 
Modeling (Geoffrion 1987, 1992a, 1992b). Within the discrete event simulation community, the maturation 
of research in methodology-based support environ­ments is seen in KBSim (Rothenberg 1989), KnowI­edge 
Based Simulation (KBS) (Baekaran and Reddy 1984), MODSYN (Rozenblit and Huang 1991), and 23529-0162 USA 
the Vkual Simulation et al. 1995). VSl?T~ from research projects a commercial product. guage vendors 
have tance for simulation supporting SLAM II The consequences Mitre Corp. 7525 Colshire Drive McLean, 
VA 22102-3481 USA Environment (VSET~) (Balci is distinct in that it has evolved originating in 1983 
to become Concurrently, simulation lan­expanded their software assis­activities, e.g., SLAM SYSTEM and 
Arena supporting SIMAN. of this more expansive view of what modeling support is needed are summarized 
in (Nance 1994) with particular attention given to the Conical Methodology, the first attempt to provide 
life-cycle support to simulation a.ctivitiee (Nance 1981, 1987). A major consequence is a shift from 
program­centric modeling para.dgrns, where a simulation pro­gramming language (SPL) is considered as 
the only representational form, to model-centric paradgms in which the modeling process encompasses multiple 
ab­straction levels and the focus is directed toward the transformation of model representations through 
it­erative specification. Model specification is that set of activities per­formed by a modeler (or modeling 
team) to create model representations that can can be communicated to humans. A model specification that 
is executable is considered a model implementation. Note that model specification can employ multiple 
representa­tions, each at a different level of abstraction. One or more model specification languages 
can be used in these activities. While a model implementation (in a SPL or any other executable form) 
is a model specification, the reverse is not true. Since a model specification describes what behavior 
is to be exhib­ited whereas an implementation describes how that behavior is to be produced, the former 
is inherently more abstract than the latter. The term redundancy typically induces nega­tive connotations 
 somethhg that is unnecessary and exacts a penalty by its inclusion, e.g., superfluous constraints in 
a mathematical program, unexecuted and obsolete code in a simulation program. How­ever, both examples 
pertain to the model execution, 701 iVance, Overstreet, and Page not the model specification. Maintaining 
unused stor­age and compiling unexecuted code is wasteful, but redundancy can prove beneficial in model 
specifica­tion. The objectives of this paper are to identify how redundancy is created in simulation 
model spec­ifications, describe the beneficial influences of redun­dancy, and demonstrate that the objectionable 
influ­ences might not be as perceived. 2 REPRESENTATIONAL REDUNDANCY Redundancy can take several forms; 
the precise form of interest here is representational redundancy, which we define as the inclusion of 
any symbols in a model specification that are not required to fulfill the objec­tives for which the model 
is developed. Symbols can refer to icons in a graphical specification, textual strings used as attribute 
identifiers, or objects follow­ing the object-oriented pardlgm. Methods that are never invoked or procedures 
that remain unexecuted provide additional examples. From thk point, all uses of the term redundancy are 
intended to be limited to the representational form. Careful distinctions must be drawn at this point: 
symbols external to the model specification but in­cluded to attain model development objectives are 
not redundant. An example is the use of embedded assertions to assist in testing and validation with 
the intent of assuring model correctness as an objective. In contrest, symbols internal to the model 
specifica­tion to support the attainment of objectives such as model reuse do exemplify redundancy. Given 
the usual negative associations with redun­dancy, atypical reaction is that simulation models de­veloped 
in practice provide few examples. We main­tain that such a view can be overly optimistic. In a related 
paper (Nance, Overstreet and Page. 1996), we identify four major sources of redundancy in model specifications, 
and offer a number of examples. Be­cause of space constraints, only a few examples are given herein, 
with the potential sources classified as accidental or intentional. 2.1 Accidental Redundancy The most 
prevalent examples of accidental redun­dancy are those that are tool-induced. In partic­ular, SPLS commonly 
use defaults on certain func­tions that force attributes to be carried along even if not used. Consider 
the TALLY and ACCUMU-LATE statements in Simscript 11.5. Counters are re­quired for computing the ten 
statistics available in each and are maintained even if the statistic is not ac­cessed. A similar default 
decision of 12 parameters for a GPSS transaction imposes accidental redundancy if less than 12 are actually 
used. Redundancy can be induced accidentally by the modeling methodology. Use of an object-oriented methodology 
can cause attributes imparted to the inheriting (created) objects to be redundant. For example, the class 
vehicle with an attribute num­ber.of.ades, originally intended to dktinguish trucks from cars, might 
be expanded through concatenation to define the class motorized vehicles, which is as­signed the attribute 
type with enumerated values mo­torcycle, car, light truck, bus, heavy truck, and tan­dem. The inherited 
attribute number-o fmxles might be superfluous but remain in the model description. 2.2 Intentional 
Redundancy A common occurrence of redundancy can be attributed to the objective of reusability. For example, 
the reuse of an aircraft object to represent a satellite would cause several attributes related to maneuverability 
and speed changes to become redundant. However, the value of modifying the reused object simply does 
not argue for doing so. Potentially, the most prevalent intentional redun­dancy can be observed in simulations 
using animation of output behavior. A host of attributes are attached to objects to jazz up the output, 
in the attempt to facilitate validation or promote model acceptance and credibility. Judged strictly 
from the objectives of the study they are unnecessary. One could assign the cause of redundancy here 
as stemming from the desire to utilize application domain knowledge to make the model reflect reality 
beyond that which is required. Methodology-induced redundancy is clearly the most interesting. Intentionally 
includlng redundant description in the form of attributes, methods or even objects as part of the proper 
way to construct models seems counter-intuitive. However, the use of multiple descriptions to combat 
complexity is argued by Pad­manaban et al. (1995). Incorporating descriptions from multiple domain experts 
is required to provide more information than a single description (Pad­manaban, Benjamin, Mayer 1995, 
p.719). Clearly, the inability to partition these multiple descriptions must lead to redundancy. The 
Con&#38;ion Specification (CS) (Overstreet and Nance 1985), especially in its use within the Conical 
Methodology, forces even more obvious redundancy through its insistence on the declaration of relational 
attributes that relate one object to another. An in­dkative attribute, which conveys some useful infor­mation 
about the object (given the study objectives), can also serve a relational role, and often each of two 
interacting objects is assigned an attribute with the Redundancy in Model Representation: two attributes 
being so strongly dependent that one is unnecessary. Fortunately, automated model sim­plification techniques 
can be applied to recognize the dependency and eliminate the redundancy. 3 BALANCING THE NEGATIVES AND 
THE POSITIVES The argument is put forth in th~ paper that, con­trary to the usual definition of the term, 
redundancy, at least with respect to model representation, is not entirely bad. Of course, neither is 
redundancy en­tirely meritorious. So, can the negativea and posi­tives be properly balanced? An obvious 
answer to this question seems to be yes and that this bal­ancing is the purview of the modeler such 
balanc­ing, after all, is the essence of modeling. But upon closer examination this answer seems insufficient. 
As noted in Section 2, the modeler is not the sole mech­anism for inducing representational redundancy. 
The tools that the modeler employs, as well as the mod­eling methodology itself, may be contributors 
to re­dundancy. Does a modeler have dominion over these factors apart from being free (generally) to 
select from a variety of methodologies and tools? The answer is not clear. An example of tool-induced 
redundancy, in the form of default statistical collection routines, in Sim­script 11.5 and GPSS is given 
in Section 2.1. Tool­induced redundancy through the use of defaults is commendable as long as: (1) the 
defaults are reason­able, and (2) overridhg the defaults is not prohibitive in time and effort. The tool 
developer s motive is laudable: provide convenience to the modeler. That convenience should not be attained 
by making depar­tures from the defaults costly however. In both of the languages noted above the defaults 
are clearly reason­able. On the other hand, overriding default behaviors in these languages can be difficult. 
Animation introduces some controversy as well. Some see it as a costly selling (marketing) gimmick; while 
others believe that it is essential to validation and model credlbilit y and acceptance. The answer probably 
lies in the degree to which the animation developer attempts to mimic reality. Beyond a given point, 
no benefit is likely to accrue. Redundancy created in the attempt to accomplish study objectives such 
as reusability is rarely to be criticized. The savings in reuse for instance clearly offset any costs 
incurred from storage loss or added computation. The inclusion of redundant documenta­tion within the 
simulation model internal documen­tation to promote maintainability aa a study objec­tive seems eminently 
justifiable. On the other hand, redundant documentation could potentially increase A Blessing or a Curse? 
 the cost of maintenance since a single modification in design might require multiple changes in the 
doc­umentation. Redundancy in the representation emanating from the model development methodology probably 
requires the most careful defense. For what purpose are the instances of redundancy created? Is the redundancy 
limited to specifications that are not executable? How great is the penalty on execution performance 
if re­dundancy is produced in the implementation? In the section that follows we provide a demonstration 
of how methodology-induced representational redun­dancy can be circumvented to permit efficient model 
execution. 4 EXECUTION IMPROVEMENT: AN UN-EXPECTED BENEFIT The role of the CS, as with any specification 
language, is to operate at a level of abstraction above the im­plementation details; While the CS does 
not spec­ify a particular time-flow mechanism (e.g., activity scan or event scheduling), such mechanisms 
are eaa­ily provided. Shce the actions to be taken whenever a condition is satisfied can be prescribed 
in a level of detail similar to a programming language such as C, we have experimented with dh-ect execution 
of action clusters to measure the performance benefits of diag­nostic analysis through elimination of 
met hodology­induced redundancy. The transformation required for direct execution of action clusters 
(DEAC) is minor, and a variet y of algorithms for DEAC simulations can be defined; see (Page 1994, pp. 
189-194). Examplea of CS model specifications may be found in many of the references cited herein. The 
most re­cent extension of the CS, to provide a more complete specification for parallel execution, is 
given in (Page 1994). In most of these sources, model specification is effected in the context of model 
development un­der the Conical Methodology. For medhm-to large­scale models, the processes of model definition 
and model specification are intimately connected as the model evolves through successive elaboration 
and re­finement. Selection of the four models used here is based on three criteria (1) published in the 
liter­ature, well known or easily understood; (2) not so lengthy as to require excessive space, and (3) 
pro­vide among them a range in size and complexity for examining that factor. The Single Server System 
is too widely used to give a single reference. The Har­bor Model appears in (Buxton and Laskl 1963 and 
Schriber 1974). The MVS Computer Systems is from (Balci 1988). The Machine Repair has appeared in several 
published works, going back to (Nance 1971). The DEAC algorithm uses the Action Cluster In­ Nance, Overstreet, 
and Page cidence Graph (ACIG) described in (Overstreet 1982, Overstreet and Nance 1985, Overstreet and 
Nance 1986, Nance and Overstreet 1987a, Nance and Over­street 1987b, Puthoff 1991). Space limitations 
re­strict complete d~cussion of the graph, but the ACIG distinguishes between models actions whose occur­rence 
is bssed strictly on the value of the simula­tion clock (called time-based actions), actions whose occurrence 
is based only on the values of model at­tributes other than the simulation clock (called state­bssed), 
and those actions which depend on both time and state (called mixed). In essence, model behavior is driven 
by testing to see if the condition controlling an action is true, and executing the action if so. Inef­ficient 
implementations may make many unnecessary tests of model conditions. Figure 1 presents the DEAC algorithm 
used in these studks. This algorithm assumes a CS with no mixed ACS. A list, d, of scheduled alarms tained 
as well as a list of stat~based action C, whose conditions should be tested within rent context of model 
execution. Note that cution of the termination AC causes an exit simulation proper. is main­clusters, 
the cur­the exe­from the WMe the ACIG (which tests) for any street 1982), fying ACIGS algorithmic construction 
of a minimal would produce the minimal number of model specification is unsolvable (Over­ we have identified 
techniques for simpli­which, though not guaranteeing mini­ mality, are effective and their benefits are 
illustrated in thk section. The eliminated edges in the ACIG represent mod­ eling relationships that 
are specified following the CM so that concepts can be captured in a communicative form without regard 
to issues of efficiency, either in representation or execution. Redundancy abounds, but by tionships 
penalty ing from in both recognizing redundant or unnecessary rela­ prior to the implementation, no execution 
is incurred. Note that eliminations rang­ 50% to 7870 portend considerable savings programming effort 
and execution time. 4.1 Execution Results For each of four models, we execute versions based on two ACIGS. 
The naive version (called before below) uses all state-based ACS ~ successors for each AC and provides 
a base case for comparison. The second version (called after below) incorporates the benefits of analysis 
by reducing the successor sets for individual Action Clusters based on analysis. Table 1 presents data 
about each of the models, the effectiveness of the analysis techniques, and the effect of this analysis 
on performance. The first set of data show the simplification of Let A be the list of scheduled alarms. 
Let C be the set of state-based clusters whose conditions should be tested immediately. Let ui~ be the 
set of statebased successors for action cluster ai (where 1< i < I ACS I ). Initially Vui, set ai~ (from 
ACIG) C=@ A = (initialization AC, initialization clock time) Simulate while (true) do clock + time given 
by FIRST(A) while (clock = time given by FIRST(A)) do let u. be the AC corresponding to FIRsT(d) ; remove 
FIR.ST(d) perform actions of a. add u.. toC while (C #0) remove a. + FIRST(C) if condition of v= is true 
perform actions of UC add UC.to C endlf endwhlle endwhile endwhile Figure 1: DEAC Algorithm for a CS 
without Mixed ACS Redundancy in Model Representation: the ACIGS for each of the four sample models. 
The number of edges which can be removed (that is, are redundant) obviously depends on model structure; 
in some models, it is possible that no edges could be deleted. For these models, from 50% (6 of 12 for 
the single server queue) to 7870 (91 of 116 for the MVS computing system) are eliminated. Table 1 also 
includes counts of the total number of condkion tests made during a typical run of each version of each 
of the four models. These data also indicate one aspect of the differences among the mod­els: the frequency 
counts on number of tests vary by two orders of magnitude. A significant indication of the benefit of 
the anal­ysis is the Percent True Tests data. The analysis (data flow and expert system) is an attempt 
to deter­mine a priori that certain tests need not be performed since they must come out false. So the 
percent of the tests which evaluate to true is a measure of the efficiency (or lack of wasted effort) 
of the implemen­tation. Thus improving the percent of true tests for 8.5% to 19.3% (as is the case for 
the Harbor Model) indicates a more efficient implementation. The last set of data in Table 1 present 
execution time data for each version of the four models. All runs are on a SPARCstation 5, running Solaris 
OS with each run consisting of 20 replications of each model (with different random number seeds so be­haviors 
are not identical. The count and percentage data are from a single run (not the 20 replications); behaviors 
of each replication are similar and show lit­tle variation in counts or percentages. Not included in 
this table is an actual count of tests which evaluated to true for the different versions of each model 
since for one model all versions must generate exactly the same count: correct implemen­tation would 
require that any version perform actions whenever the model is in a state where the condition for the 
action is true. Each version for a single model must have identical counts for true testy only the count 
of false tests can vary. ThkI is the case with these runs. Much of the data of Table 1 are represented 
in Ta­ble 2 as a percentage improvement. It compares the two versions of each model by computing Ibef 
ore af terl /before x 100 for each metric. This shows, for example, that the speed-up varies from 27.3% 
to 53.2% among the four models, and that more than twice as many tests (220.5%) evaluate to true for 
the optimal compared to the base case for the Machine Repair model. From this small number of models, 
it is inappro­priate to draw general conclusions on the percent im­provements likely with these technique 
thus we in­clude no averages since it is unlikely these data rep- A Blessing or a Curse? 705 Table 1: 
Performance Measures Skg. MVS Mach. Metric Vers. S. Q. Sys. Har. Rep. ACIG Before 12 116 67 29 Edges 
After 6 25 26 10 Total Before 12K 1,121K 30K 30K Tests After 6K 263K 14K 9K % True Before 17.7 8.7 8.5 
11.2 Tests After 33.3 33.9 19.3 35.9 Time Before 2.2 215.7 4.6 6.2 (sees) After 1.6 68.8 2.9 2.9 Table 
2: Improvement of Optimal over Base: Ibefore -afterl/before x 100 Single MVS Mach. Metric Serv. Q Sys 
Harbor Repair Exec. Time 27.3 68.1 37.0 53.2 Num. Tests 50.0 76.5 53.3 69.1 % True 88.1 289.7 127.1 220.5 
 resent average behavior. But since these models are not preselected in anticipation of these techniques 
working well with them, we do surmise that this ap­proach is generally effective with a wide class of 
mod­els. A comment on the effectiveness of our analysis for these four models: the techniques dkl find 
ev­ery edge which was valid to delete in the ACIG of each model. That is, for each of the remaining edges, 
at some point in an execution, the test it suggested might need to be performed dld evaluate to true 
at least once. Put another way, if the test had not been performed (to check to see of another action 
should occur), the implementation would have be~en invalid. We do not expect the analysis to thk effective 
for all models, but the completeness in these four ca.wx is encouraging. 5 CONCLUDING SUMMARY We continue 
to explore techniques and benefits of static analysis of model specifications. In this pa­per, we have 
demonstrated how one assumed neg­ative aspect of redundancy, namely poor execution, can sometimes be 
ameliorated by analysis, so that the redundancy sometimes useful in model specifications to support analysis 
need not result in poor run-time performance. iVance, Overstreet, and Page REFERENCES Balci, O. 1988. 
The implementation of four concep­tual frameworks for simulation modeling in hlgh­level languages, In: 
Proceedings of the 1988 Win­ter Simulation Conference, 287-295. Balci, O., A. I. Bertelrud, C. M. Esterbrook, 
and R. E. Nance. 1995. A picture-based object-oriented visual simulation environment, In Proceedings 
of the 1995 Winter Simulation Conference, 1333-1340, Arlington, VA. Baskaran, V. and Y. V. Reddy. 1984. 
An interactive environment for knowledgebased simulation, In: Proceedings of the 1984 Winter Simulation 
Con­ference, 645-651. Bisschop, J. and A. Meeraus. 1982. On the devel­opment of a general algebraic modeling 
system in a strategic planning environment, Mathematical Programming Study, 20:1-29. Brooke, A., D. 
Kendrick and A. Meeraus. 1992. GAMS: A user s guide, release 2.25, San Fkancisco, CA: The Scientific 
Press. Buxton, J. N. and J. G. Laskl. 1963. Control and simulation language, Computer Journal, 5, 194 
199. Geoffrion, A.M. 1987. An introduction to structured modeling, Management Science, 33:547-588. Geoffrion, 
A. M. 1992a. The SML language for struc­tured modeling levels 1 and 2, Operations Re­search, 40:38-57. 
Geoffrion, A. M. 1992b. The SML language for struc­tured modeling: levels 3 and 4. Operations Re­search, 
40:58-75. Greenberg, H. J. 1983. A functional description of ANALYZE, ACM llansactions on Mathematical 
Software, 9(1):18-56. Greenberg, H. J. 1987. ANALYZE rulebase, In Pro­ceedings of NATO ASI: Mathematical 
Models for Decision Support, 229-238, Berlin: Springer-Verlag. Greenberg, H. J. 1993. A computer-assisted 
analysis sgstem for mathematical programming models and solutions: a user s guide for ANALYZE, Boston, 
MA: Kluwer. Nance, R. E. 1971. On time flow mechanisms for discrete event simulation, Management Science, 
18(1):59-73, September. Nance, R. E. 1981. Model representa.tion in discrete event simulation: the conical 
methodology, Tech­ nical Report CS81OO3-R, Department of Computer Science, Virginia Tech, Blacksburg, 
VA. Nance, R. E. 1987. The conical methodology a framework for simulation model development, meth­odology 
and validation, Simulation, 19(1) :38-43. Orlando, FL: The Society for Computer Simula­tion. Nance, R.E. 
and C. M. Overstreet. 1987a. Diagnos­tic Assistance Using Digraph Representations of Discrete Event Simulation 
Model Specifications, Transactions of the Society for Computer Simula­tion, 4(1):33-57, January. Nance, 
R.E. and C. M. Overstreet. 1987b. Explor­ing the forms of model diagnosis in a simulation support environment, 
In Proceedings of the 1987 Winter Simulation Conference, Atlanta, GA, De­ cember 1416, 590-596. Nance, 
R. E. 1994. The conical methodology and the evolution of simulation model development, Annals of Operations 
Research 53:1-46. Nance, R. E., C. M. Overstreet, and E. H. Page. 1996. Redundancy in model specifications 
for discrete event simulation, work in progress. Overstreet, C. M. 1982. Model specification and anal­ysis 
for d~crete event simulation, Ph.D. Disserta­tion, Department of Computer Science, Virginia Tech, Blacksburg, 
VA, December. Overstreet, C. M. and R. E. Nance. 1985. A spec­ification language to assist in analysis 
of discrete event simulation Models, Communications of the ACM, 28(2):190-201, February. Overstreet, 
C. M. and R. E. Nance. 1986. World view based discrete event model simplification, In Modelling and Simulation 
Methodology in the Ar­tificial Intelligence Era, Elsevier Science Publish­ers (North-Holland), 165-179. 
Padmanaban, N., P. C. Benjamin and R. J. Mayer. 1995. Integrating multiple descriptions in simula­tion 
model design: A knowledge based approach, In Proceedings of the 1995 Winter Simulation Con­ference, 714719, 
Arlington, VA. Page, E. H. 1994. Simulation modeling methodol­ogy principles and etiology of decision 
support, Ph.D. Dissertation, Department of Computer Sci­ence, Vkginia Tech, Blacksburg, VA, September. 
Puthoff, F. A. 1991. The model analyze~ proto­typing the diagnosis of discret+event simulation model 
specification, M.S. Thesis, Department of Computer Science, V@inia Tech, Blacksburg, VA, September. Rothenberg, 
J. 1989. The nature of modeling, RAND Note N-3027-DARPA. Rozenblit, J. W. and Y. M. Huang. 1991. Rule-based 
generation of model structures, in Multifaceted Modeling and System Design, ORSA Journal on Computing 
3(4):330-344. Schriber, T. J. 1974. Simulation using CPSS, John Wiley and Sons.  Redundancy in Model 
Representation: AUTHOR BIOGRAPHIES RICHARD E. NANCE is the RADM John Adol­phus Dahlgren Professor of 
Computer Science and the Director of the Systems Research Center at Vh­ginia Tech (VPI&#38;SU). Dr. Nance 
is also Chairman of the Board of Orca Computer, Inc. He received B.S. and M.S. degrees from N.C. State 
University in 1962 and 1966, and the Ph.D. degree from Pur­due University in 1968. He has served on the 
facul­ties of Southern Methodist University and Vhginia Tech, where he was Department Head of Computer 
Science, 1973-1979. Dr. Nance has held research ap­pointments at the Naval Surface Weapons Center and 
at the Imperial College of Science and Technology (UK). Within ACM, he has chaired two special inter­est 
groups: Information Retrieval (SIGIR), 1970-71 and Simulation (SIGSIM), 1983-85. He has served as Chair 
of the External Activities Board and several ACM committees. He is the US representative to IMP TC7. 
The author of over 100 papers on discrete event simulation, performance modeling and evalua­tion, computer 
networks, and software engineering, Dr. Nance has served on the Editorial Panel of Com­munications of 
the ACM for research contributions in simulation and statistical computing, 1985-89, as Area Editor for 
Computational Structures and Tech­niques of Operations Research, 1978-82, and m De­partment Editor for 
Simulation, Automation, and In­formation Systems of IIE Transactions, 1976-81, He served as Area Editor 
for Simulation, 1987-89 and as a member of the Advisory Board, 1989-92, ORSA Journal on Computing. Dr. 
Nance was the founding Editor-in-Chief of the ACM llansactions on Model­ing and Computer $lmulation, 
1990-1995. He served as Program Chair for the 1990 Winter !Xmulation Conference. Dr. Nance received a 
Distinguished Ser­vice Award from the TIMS College on Simulation in 1987. In 1995 he was honored by an 
award for Distinguished Service to SIGSIM and the Simulation Community by the ACM Special Interest Group 
on Simulation. He is a member of Sigma Xl, Alpha Pi Mu, Upsilon Pi Epsilon, ACM, HE, and INFORMS. C. 
MICHAEL OVERSTREET is an Associate Professor of Computer Science and Graduate Pro gram Director for Computer 
Science at Old Dominion University. He is immediate past chair of the Special Interest Group in Simulation 
(SIGSIM) of ACM. He received his. B.S. from the University of Tennessee in 1966, an M.S. from Idaho State 
University in 1968, and an M.S. and Ph.D. from Vhginia Polytechnic In­  stitute and State University 
in 1975 and 1982. He has been a visiting research faculty member at the Kyushu Institute of Technology 
in Japan. Hls current A Blessing or a Curse? research interests are in model specification and anal­ysis, 
dk.tributed simulation, high performance net­working, remote instruction technologies, and static code 
analysis in support of software maintenance tasks. He is currently a principal investigator in tasks 
funded by the National Science Foundation, DARPA, and ICASE at NASA Langley. Dr. Overstreet is a mem­ber 
of ACM, and IEEE CS. ERNEST H. PAGE is a Member of Technical Staff at the C3 Modeling and Simulation 
Center and Mitre Corp. in McLean, VA. He received his Ph.D. in Computer Science in 1994 from V@inia Polytech­nic 
Institute and State University (VPI&#38;SIJ). He re­ceived B.S. and M.S. degrees in Computer Science 
from VPI&#38;SU in 1988 and 1990. His research in­terests include discrete event simulation, parallel 
and distributed systems, and software engineering. He is a member of ACM, ACM SIGSIM, IEEE CS, SCS, and 
Upsilon Pi Epsilon.  
			