
 Uniform Closure Properties of P-Computable Functions* Erich Kaltofcn Rensselaer Polytechnic Institute, 
Dept. of Computer Science Troy, New York 12181 and Mathematical Sciences Research Institute Berkeley, 
California 94720 Preliminary Report 1. Introduction Valiant [1] introduced the notion of a family of 
19- computable polynomials as those multivariate polynomials of polynomially-bounded degree and straight-line 
compu-tation length. He raised the question of whether p-computable families would be closed under natural 
mathematical operations and showed that this is true for taking repeated partial derivatives in a single 
variable, whereas by taking repeated partial derivatives in many variables one can obtain the general 
permanent from a polynomial-sized formula. In [2] we have introduced straight-line programs as a means 
of representing polynomials. Therefore our algo-rithms require that the p-computable outputs can be computed 
from the p-computable inputs in at least ran-dom polynomial-time. We call families satisfying this additional 
requirement uniformly closed. The main result in [2] can now be stated concisely as that every family 
of p-computable polynomials is uniformly closed under the greatest common divisor operation. It is easy 
to show that Valiant's closure properties are also uniform. In this paper we establish uniform closure 
of families of p-computable polynomials for two more important opera-tions, factorization and extracting 
the numerator and denominator of a rational function. * This material is based upon work supported by 
the National Sci- ence Foundation under Grant No. DCR-85-04391 and by an IBM Faculty Development Award. 
Part of work on §3 and §4 was done while the author was visiting the Tektronix Computer Research La- 
boratory in Beaverton, Oregon. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copyin5 is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1986 ACM 0-89791-193-8/86/0500/0330 $00.75 The factorization problem 
of polynomials in straight- line representation was first solved for the case in which the factors were 
to be produced in sparse format [3]. Unfortunately, even sparse polynomials can have factors with super-polynomially 
more non-zero terms [4] and therefore those algorithms computing the sparse faetoriza- tion can take 
more than polynomially-many steps in the input size and degree. Uniform closure for this problem, of 
course, guarantees that the straight-line representation of the factors can be found in random polynomial-time 
in the input degree and program length. The key idea of our solution, in addition to the contributions 
in [4] and [3], is to employ Hensel lifting but to replace the p-adic expansion of the coefficients by 
the expansions into homogeneous parts of the minor variables. We thus lift all minor variables simultaneously 
and avoid the variable by variable lifting loop that would compound programs of exponential size. It 
is clear that unformity can be only achieved for coefficient fields over which bivariate polynomial factori- 
zation is in polynomial-time. As the algorithms in [5] and [6] for rational coefficients might indicate, 
uniformity is not any more an easy matter. Another sophisticated tool used to establish uniformity are 
the effective Hilbert irreducibility theorems [7] and [8]. For rational coeffi-cients we can prove even 
binary random polynomial-time for our algorithm provided the size of the coefficients of the input polynomial 
is also polynomially bounded. If the coefficient field is of positive characteristic p and the multiplicity 
of an irreducible factor is divisible by p, there is an additional problem. We can, however, com-pute 
a straight-line computation for the appropriate pk-th power of such a factor. Let us for a moment come 
back to the question of fac- torizing into sparse polynomials. The examples causing l super-polynomial 
blow-up for the size of the answer have the property that many other factors are very sparse. In general, 
one may wish to retrieve the sparse factors as such and leave the dense factors in straight-line format. 
Fortunately, Zippel's conversion algorithm (of. [2], §6) allows to do just that. More precisely, given 
a bound t we can now probabilistically determine in polynomial-time in t from the straight-line factorization 
the sparse format of all irreducible factors with no more than t terms, this without any restriction 
on characteristic and multiplicities. Moreover, the running time is always poly- nomial even if we were 
unlucky in our choice of evalua- tion points. We think that this finally settles the ques-tion of sparse 
factorization in a very satisfactory manner. We now turn to the computation of numerator and denominator 
of p-computable rational functions. We note that our definition of such a family requires that there 
is a polynomial bound for the length of the straight-line computations, which also contain divisions, 
and a polynomial bound for the degrees of the reduced numerator and denominator of the rational functions 
computed. Strassen [9] raised the question whether the numerators and therefore also the denominators 
were p-computable. Here we show that computations of polynomial-length for the numerator and denominator 
can be found in random polynomial-time and as one consequence also settle this open problem of more than 
a decade. The main idea for our solution comes mostly from our uniform closure result for GCDs [2] put 
together with the theory of Padd approximations. Another impor- tant consequence of the p-computability 
of the numerator and denominator of rational functions is that it can be used to parallelize p-computable 
rational functions in general. First we note that Hyafil [10] and Valiant et al. [11] have shown how 
to evaluate p-computable polynomi- als in parallel, that is, in polynomial-size and poly-logarithmic 
depth. We now can apply this parallelization to our straight-line program for the numerator and denominator 
and therefore establish that every p-computable rational function can be evaluated in parallel in polynomial 
size and poly-logarithmic depth. This paper is organized as follows. Section 2 contains the result on 
polynomial factorization. Section 3 intro- duces the properties of Pad6 approximants used in section 
4, which contains the construction for numerator and denominator. Section 5 concludes by raising open 
ques-tions. Notation: We use the same notation as in [2] and [3], but for the convenience of the reader 
we shall repeat it here. By Q we denote the the rational numbers and by GF(q) the finite field with q 
elements. F usually denotes a field and char(F) its characteristic. A polyno- mial f E F [Xl ''''' Xn 
] is homogeneous of degree d if e I . ef (~1 ..... Xn ) = E C ........ X 1 "'~n n , el-f '''+e,-d eel..... 
e. E F. The coefficient of the highest power of x 1 in f E (F[z 2 .... , znl)[Zl] is reterred to as the 
leading coefficient of f in zl, ldcfxl(f ). Two polynomials f 1 and f 2 are associates, f 1 ~ f 2, if 
f 1 = cf 2 with 0 # c E F. For F = Q the binary size of the monomial coeffi- cients of f as fractions 
of integers with a common denominator, the combined coefficient size, is denoted by cc-size(f ). A straight-line 
program over a domain D is formally a quadruple P = (X, V, C, S) where X is the set of inputs, V the 
set of program variables, C the computation sequence, and S the set of scalars occurring in the computation 
sequence. The length of C is the length of P, len(P). Each program variable v computes an element in 
D. A polynomial f E F[Zl ,--., Xn],°r a rational function f / g E F{zl .... , x n),isgivenbya straight-line 
program P if P = ({xl .... , z n }, Y, C, S ) computes f or f / 9 over F(x I ,..., z n) and S C F. The 
program P is defined at ¢:{x 1 ,..., Xn} -~ F if no zero-division occurs when evaluating P at ¢(zi) in 
place of z i. The element size of P, el-size(P), denotes the number of bits it takes to represent all 
elements in S. By M (d) we denote a function dominating the time for multiplying polynomials in F Ix] 
of maximum degree d. Notice that for arbitrary fields the best known upper bound for M (d) is O (d log(d 
)loglog(d)) [12]. The car-dinality of a set R is denoted by card(R ). We note that for a non-zero polynomial 
f the probability Prob(f (al,...,an) = 0 I aie R) ~< deN(f)eard(R ) ' see [13]. 2. Straight-Line Faetorization 
We now describe the algorithm for finding the straight-line factors of a p-computable polynomial. The 
algorithm is derived from the One-Variable Lifting algo- rithm in [3], with the homogeneous parts of 
the minor variables replacing the monomials of the single variable with respect to which is lifted. We 
will compute those homogeneous parts by straight-line programs. The main reason why the answer is polynomial 
in length is that we only need to add on to the intermediate programs. This is because subsequent homogeneous 
parts can be com-puted from previous ones and Strassen's technique of obtaining a homogeneous program 
need not be applied at each iteration. Algorithm Factorization Input: f C F[z 1 ,..., xn] be given by 
a straight-line program P of length l, a bound d /> deg(f ), and an allowed failure probability e << 
1. Output: Either "failure", that with probability < e, or e i /> 1 and irreducible h i E F[x I ,..., 
x n], 1 x< i ~< r, given by a straight-line program Q of length len(Q) = O(d21 + d M(d2)logd) r e such 
that with probability > 1 -e, f = ni=lhi'. In ease p = char(F) divides any e i, that is e i = pC' e~ 
with ~ not divisible by p, we return ~ in place of e i and Q will compute h~ ' Step R (Random Points 
Selection): From a set R C F with card(R) > 6 max(21+l, 4d 2 d + d 3) e select random elements a 1 ,..., 
an, b 2,..., b n. IfF = GF(q) with q small we can instead work over GF(q p ), p a prime integer > d. 
By Theorem 6.1 in [7] no addi-tional factors occur. Test whether P is defined at ¢(z i) = ai, 1 <~ i 
~< n. For F = Q we call algorithm Zero-Division Test in [2] such that the probability of "failure" even 
if P were defined at ¢ is less than e/6. If P turns out to be (prob- ably) undefined at ¢ we return "failure". 
Otherwise, P is definitely defined at ¢ and we compute the dense representation of f 2 = f (zl + al, 
z2, b3Zl + a3,..., bnXl + an). This can be done by evaluation and interpolation simi-larly to the Sparse 
Conversion algorithm in [2]. If F = Q, a bound for the cc-size(f ) must be added to the input parameters 
and we must again make the probabil- ity that "failure" occurs due to the use of modular arith- metic 
during evaluation less than e/6. Step F (Factorization): Factor f ~ = gi), i=1 0i,2 fi F [zt, z2] irreducible 
and pairwise not associated. Notice that by theorem 2.1 of [3] f and ] 2 have with high probability the 
same factorization pattern, that is irreducible factors of f map to pairwise non-associated irreducible 
factors of f z of the same total degrees. For the remainder of the algorithm we will assume that this 
is the ease. If char(F) -= p > 0 divides any of the ei, say e i = p~' ~/ with ~ not divisible by p, we 
replace e i by ~,. and ~/i,2 by ~/~2' This replacement guarantees that none of the multiplicities are 
divisible by the characteristic. Now set ~i,0(gl) ~-gi,2(Xl, b2z I + a2) e F(Xl). Check whether GCD(oi,0, 
Oj,o) ~ 1 for 1 ~< i < j ~< r and whether deg(~i,z) = deg(Oi:o) for 1 ~< i ~< r. If not return "failure". 
Let f(xl,...,xn)=f (xl+al,Xe+b2xl+ae,...,xn +bn zl +an ) =H hi(z,...,zn)", i=1 and assume that h i are 
the irreducible factors that correspond to gi,2" Notice that the assumptions on the preservation of the 
total degrees of the factors throughout the evaluation process also imply that ldcfz,(]- ) e F. (*) Furthermore, 
let P be a straight-line program computing f-We write d d f(~, ..... ~.) = ~ E Tj,m(~2,...,~.)*?, j=0 
m =0 such that f-~,m e FIx 2 ,..., Xn] is homogeneous of degree j. We remark that d can now be set to 
dec(f) rather than a bound for it. We will need a straight-line program computing Tj,m -If we replace 
z i by x i z~ +l , 2 i <~ n, in fi then fj,m is the coefficient of xi{ d+D+m . Therefore by evaluating 
at x! and interpo- lating as in the Polynomial Coefficients algorithm [2] we can find a straight-line 
program Q0 for Ti,m of length len(Q0) = O(d21 + M(d2)logd). Notice that we need to randomly pick (d +1) 
2 points at which we interpolate and we must make sure that the straight-line program fi is defined at 
those points. If that is not the case, or if for F = Q we cannot confirm by the Zero-Division Test algorithm 
[2] that a point is good, that with probability < e/ (6(d +1)2), we return "failure". For more details 
we refer to step P in the cited Polynomial Coefficients algorithm. Step H (Hensel Lifting Loop): FOR 
k ~-0 ,..., d-1 DO step L. Step L (Lift by One Degree): Let d~ d~ h~(~,,...,~,) = ~ ~ci,j,,,(x2,...,xn) 
~'~, m=O j=O d i = dec(hi), where ci,j,m(z 2 .... , Xn) e FIx 2 ..... x n ] is homogeneous of degree 
j. At this point we have a straight-line program Qk over F(x 2 ,..., x,~) that computes c i,j,m tbr 1 
~< i ~< r,0 <~ j <~ k,O ~< rn <~ d i. Notice that Ci,o, m E F is the coefficient of z~ in gi,0, and that 
by (*) c i,j,d, = 0 for j > 0. We will extend Qk to Qk+l that also computes Ci,k+l, m . It is useful 
to introduce the following polynomials k dl di o,,k E ~ ci,i,m~, O,,k+~ ~ c,,k+l,,.~ j=O rn=O m=O Now 
consider the congruence r Notice that l~(oi,~ + Oi,k+lff '~ ]mod(xl .... ,zn) k+z. ('~) Expanding the 
LHS we get el-1 e -I ~ 01,0 '" "dr:0 ~ tl~i Oi,k+l I~ gj,O) i=l j=l i¢i S--rood .... , i=l By our loop 
invariant for Qk i=l d-I r = ~rm(z 2 ..... Zn)Zl n mod(z2,...,z,) k+2' rq=O where rm E FIx2 .... , xn] 
is homogeneous of degree k+l. Notice that the degree in z 1 is d-1 by the assumption (*). We need a program 
Qr over F('-', ci,i,m '"" f-j,m' "") that computes r m. If Qr encodes a tree-like multiplication scheme 
that can be done in len(Qr) = O(M(d 2) logd). By our assumption that we lift a true factorization, (:~) 
is el--1 e-I solvable in gi,k +z and hence g 1,o "'" gr,O must divide r. Let dl+"'+d,-1 7. P = E Pm(X2,"', 
X,) X~n = %-1 e -1' m=0 gl,O "" "gr~o Pm ~ FIZZ,..., xn]. As before, we need a straight-line program 
Qp over F (' ", rm, "" ") that computes all Pro" A simple encoding of polynomial division takes len(Qo) 
= 0 (M(d)). Now consider P +______.2" +...+ er Or ,k +1 e lOl,~ __ g 1,0' " "Or,0 g 1,0 gr ,0 It is clear 
that ei ei,i,~+ 1 are the coefficients of the univariate partial fraction decomposition of P/ (gl,0"" 
"gr,O) carried out over the field F (x 2 .... , z n ). One way to compute these coefficients by a straight-line 
program Qk+z with len(Qk+z) = O(M(d)) is to once and for all find 0i ,0 E F [x 1] with 1 01,0 Or ,0 = 
+...+ , deg(0i,0) < d i, g 1,0' " "Or ,0 g 1,0 Or ,0 and encode the polynomial remaindering 0i ,0 P mod 
Oi ,0 Oi,k+l = , 1 ~ i~< r. ei We must be able to divide by e i and here we need the fact that the multiplicities 
must not be divisible by char(F). We finally link the programs Qk, Q r, Q p, and Qk+l properly together 
to obtain the program Qk+l. len(Qk+l) ~ len(Q k ) + C M(d2)logd, where C is an absolute constant. From 
this relation we can infer the length of Q Step T (Final Translation): From Qd we obtain Q which computes 
h i (Xl-a 1, x2-b2(zl-al)-a 2 ..... xn-b n (Xl--al)--an) by adding in front of Qd instructions for translating 
the x i appropriately. [] We now analyze the failure probabilities of the Fae-torization algorithm. The 
only way an incorrect program Q can be produced is that the factorization patterns of f and f 2 disagree. 
By theorem 2.1 in [3] this happens with probability < 4d 2 d + d 3 <e. card(R ) "Failure" can occur 
in six separate circumstances. First, P may be undefined at ¢, that with probability < 2t+1/card(R) < 
e/ 6 by an argument similar to that used in Lemma 4.3 of [2]. Second, for F = Q we might fail to recognize 
that P is defined at ¢, but we make this possibility happen with probability < ~/6. Third, for F = Q 
the computation of f 2 may fail with probability < E/6. Fourth, "failure" can occur if for some i 4= 
j, GCD(gi,0' gi,0) ~ 1, or deg(gi,0) < deg(~i,2). Let 7r i (82) = ldcfzL(gi,2(xl, fl2xl + ~2) and let 
~i,s (a2, Z2) = resultant~,(~i,~(x~, &#38;~ + ~), ~s,~(~, &#38;~ + ~2)) over F[a2, 32, xl]- It is easy 
to see that 0 ¢ ri oi,y E F[a2, ,32] and 7ri(b2) ai,y(a2, b2) ¢ 0 implies that the above events are impossible. 
Now, deg(~ri) ~ d i and deg(ai, j) ~ 2d i dj and therefore the probability that the above events occur 
for any i ¢ j is less than d~ 2d~ d~ card(R) + E card(R) i=l l~<i<j<~r (dl+'"+dr ) 2 d 2 e card(R ) card(R 
) 6" Notice that if P were division-free, this event would be the only one where failure could occur. 
Fifth, we may not find good interpolation points in order to produce Q0" If we try at most (d +1) 4 points, 
the probability that at least (d +1) 2 = d * points are good can be estimated like in the proof of [2], 
Theorem 5.1. We shall repeat the argument here. An individual point was not picked earlier with probability 
/> 1 -(d+1)4/ card(R) > I -e/ 12. _P is not defined at an individual point substituted for z I with probability 
< 2t+1/ card(R) < e/ 12. Hence a suitable point can be found in a block of d* points with probability 
> 1 (c*) d" _ 2._ * = -> 1 d*' ~ 6' because (1/ e*)d*-I > 2d*-1 >1 d* for e* < 1/2. Now the probability 
that a good point occurs in all of the d* blocks of points is > (1 -e *)d* * --~, >l-e and therefore 
failure happens with probability < e / 6. Sixth and last, for F = Q we may not recognize that we have 
good interpolating points, that for all (d +1) 2 points together with probability < e/ 6. We have esta-blished 
the following theorem. Theorem 2.1: Algorithm Factorization does not fail with probability 1 -e. In that 
case it reduces the prob- lem in polynomially many steps as a function in len(P ) and d to factoring 
bivariate polynomials. Its answer will be correct with probability 1 -e. It requires polynomi- ally many 
randomly selected field elements. For F = Q or F = GF(q) the algorithm has binary polynomial com- plexity 
also in log(l/ e ), el-size(P ), and cc-size(f ). [] We now formulate two corollaries to this theorem. 
The first refers to computing the sparse factorization of f and follows from [2], §6. Corollary 2.1: 
If in addition to the input parameters of the Factorization algorithm we are given t > 0, for F = Q or 
F = GF(q) we can find in polynomially many binary steps and random bit choices in len(P ), d, log(-~), 
el-size(P), cc-size(f ), and t sparse polynomials that with probability > 1 -e consti-tute all irreducible 
factors of f with no more than t monomials. [] Notice that the above running time is always polyno- mial 
independently whether the correct sparse factors were produced or whether other factors are dense. This 
makes this corollary superior to all previous work on sparse factorization. The second corollary deals 
with pos- sibly non-uniform closure. Corollary 2.2: Let F be a field of characteristic 0. Then any family 
of factors of a family of p-computable polynomials over F is p-computable. [] Notice that this corollary 
applies even to fields in which arithmetic is recursive but over which polynomial factorization is undecidable 
[14]. It also shows that a polynomial degree bound is necessarily required. We note that x 2' -1 can 
be computed with O (d) instructions but it is known that over the complex numbers there exist factors 
that require fl(2 d~ 2/ x/d-) computation length [15] and [16]. It would be nice to give such an example 
where the factors are irreducible polynomials over Q. 3. Pad6 Approximants We now review those properties 
of Pad6 approximants that we need in §4. However, we will not prove any of these properties and instead 
refer to [17] for an in depth discussion and the references into the literature. Let f (x) = c0+clx+c2x2+ 
"'' e F[[x]], c0¢0, d,e~>0, be given. Going back to Frobenius 1881 a rational func- tion p (x)/ q (x) 
is called a (d, e )-Padg approximant to f if deg(p) <~ d, deg(q) ~< e, f (x) q(x) _ p(x) ~ Omodxd+e (1") 
 It turns out that for any pair (d, e ) there always exists a solution to (1-) and that furthermore the 
ratio p/ q is unique. This ratio forms the entry in row d and column e of an infinite matrix referred 
to as Pad6 table. Already Kronecker 1881 realized that the entries in the d +e anti-diagonal of the Pad6 
table are closely related to the Euclidean remainder sequence of /_i(X) = X d+e+l, f0(~) = £O-~-ClZ-}-...-.-gd+eX 
d÷e Consider the extended Euclidean scheme s i(x)f_l(x) + t i(x)fO(x) = fi(x), I~(~) = f,-2(~) mod /~_~(~), 
i ~> 1. Then for the smallest index i with deg(fi) ~ d we have deg(ti) <~ e and fi / ti is the (d, e)-Pad~ 
approximant to f . Furthermore, GCD(fi, ti) = x k for some k /> 0. Thus any algorithm for computing the 
extended Euclidean scheme results in one for the (d, e)-Pad~ approximant. Note that the assumption c 
0 ¢= 0 is unessential by changing the lower bound for d. The classical Euclidean algorithm gives a O 
((d +e )2) method for computing the (d, e)-Pad~ approximant. The ingenious algorithm by Knuth [18] that 
was improved by SchSnhage [19] and applied to polynomial GCDs by Moenck [20] allows to compute the triple 
(fi, s i, ti) with deg(fi) ~< d, deg(fi_l) > d, in O (M (d +e ) log(d +e )) operations in F. 4. Numerators 
and Denominators of Rational Functions We now describe the algorithm that transforms a straight-line 
computation for a rational function of known degree to orte for its (reduced) numerator and denomina- 
tor. The key idea is that by substituting x m + b m Xl for z m, 2 <~ m <~ n,we can make the problem aunivariate 
problem in x I over the field F(x 2 ,..., xn), as was already done in [2]. We then recover the fraction 
from its Taylor series approximation by computing the Pad~ approximant in f (x 2 ,..., xn )[[Xl] ]. Since 
that approxi-mant is unique it must be the reduced numerator and denominator. Algorithm Rational Numerator 
and Denominator Input: A straight-line program P over F (x 1 ,..., x n ) of length 1 that computes f 
/ g, f , g E F[zl ,.-., xn] relatively prime, and d ) deg(f ), e ) deg(g), and a failure allowance c 
<< 1. We shall make the assumption that d, e ~ 2 t since the latter is always a bound. Output: Either 
"failure" (that with probability < e ) or a straight-line program Q over F (x I ,..., x n) of length 
O(l M(d+e)) such that Q computes f and g correctly with probability > 1 -e. Step T (Translation): From 
a set R C F with 2(2C,+2) I M(d+e) card(R ) > select random elements al ,..., %, b2 ,"', bn" Here the 
constant C a depends on the polynomial multiplica- tion algorithm used. If F is a finite field with too 
small a cardinality, we can work in an algebraic extension of F instead. Since the results can be computed 
by rational operations in F they remain invariant with respect to field extensions. Test whether P is 
defined at ¢(x m ) = a m , 1 ~ m ~ n. For F = Q we call the algorithm Zero-Division Test in [2], §3, 
such that the probability of "failure" occurring even ifP is defined at ¢ is less thane. If in this test 
P turns out to be (probably) undefined at ¢ we return "failure". Now we translate the inputs of P as 
x 1 ~ Yl "~ hi, Xm Ym + bmYl, 2 ~ m ~ n. Let P be the straight-line program computing f/ g- where ~(v~ 
..... ~.) = h (y l +a l,y 2 +b 2Y l, . . . ,yn +bn y l) for h E F [xl, . . . , xn ]. Now P is defined 
at ¢(Yl) = 0. Also with high probabil- ity ldefyl(f ) e F. (*) Step S (Power Series Approximation): Compute 
a straight-line program Q 1 over F (y 2 ,..-, Yn ) such that for the coefficients of the power series 
f --c0(Y2 .... ' Yn) -1- el(Y2 ..... Un)~]' "]'-' '" "t- ed +e (y 2, . . . , yn )Y l d +e -I-" " ", (~) 
algorithm of [2], §4. Notice that len(Q 1) C 1 l M(d +e ), where C 1 is a constant solely depending 
on the multiplication algorithm used. Step P (Pad~ Approximation): Compute a straight-line program Q2 
over F (Y2 ,'--, Yn ) that with high probabil- ity computes the (d, e )-Pad~ approximation p / q, p, 
q e F(y 2 .... , Y,)[Yl] to (t). From §3 we know that this can be accomplished by an extended Euclidean 
algorithm. Essentially, we perform such an algorithm on the coeffi- cient vectors (e i )0~<i ,<d +e and 
that of yl d+e +1. In order to test elements in F (y2 ,..., yn) for zero we evaluate the program computing 
these elements at ¢(Ym ) = am, 2 m ~ n. The details of this method for the classical subresultant algorithm 
can found in [2], §5. If we use the asymptotically fast Knuth-Sch~nhage procedure (see also [21] for 
a full description of the algorithm) then len(Q2) ~< Cll M(d+e) + C2M(d+e)log(d+e ) C a l M(d +e ), ($) 
where C 2 and C a are again constants solely depending on the polynomial multiplication procedure used. 
Notice that the produced straight-line program may be incorrect (that with small probability) since we 
may have incorrectly certified an element to be zero. Once we have a straight-line program for polynomials 
fi and t i e F(y 2 .... , Yn)[Yl] in the extended Euclidean scheme we must find k /> 0 such that GCD(fi, 
t i) = yl k over F(y z ,..., Yn)[Yt]" This we can again accom-plish probabilistically by evaluating the 
coefficients in y 1 of f i and t i . If we make ldcfy,(p ) = 1, then with high probability p is an associate 
of ]- in F[Yl ,..., Yn]" This is because of (*) and because Padd approximants are unique. Step T (Back-translate): 
The program Q is obtained by putting assignments for the back-translations yl ~ Xl--al, ym ~ Xm --brn(Xl-al),2~ 
m ~ n, in front of Q2. Q We shall now analyze the overall failure probability of the Rational Numerator 
and Denominator algorithm. "Failure" is only returned if P is not defined or is not recognized to be 
defined at ¢. However, several events must take place in order that the correct answer is returned. First, 
ldcfy~(T) E F that justifies the normali- zation of p in step P. By lemma 5.1 in [2] this happens with 
probability d e 1 --> 1--- card(R ) 4 Second, all zero-tests peribrmed by evaluating at ¢(Ym ) = a m,2 
~ m ~ n , must give the correct answer. This is be done by directly applying the Polynomial Coefficients 
true if the Knuth-SchSnhage algorithm performed over C i are computed by Q1 for all 0 ~ i ~ d+e. This 
can F (Y2 ,"., Yn) takes the same course as the algorithm performed over F on the elements obtained by 
evaluating at 0. In other words, no non-zero element that is tested or by which is divided must evaluate 
to 0. Since the algorithm takes no more than C 2 M(d +e ) log(d +e ) steps, the degree of any unreduced 
numerator and denominator of these elements is by (:~) no more than 2C31M(d+e) A (pessimistic) estimate 
for the number of elements to be tested and by which is divided, including the determina- tion of k, 
is C31 M(d +e ) + (d +e ) < (C3+1) / M(d +e ). Therefore the probability that all tests lead to the same 
result at ¢ and that all division are possible at ¢ is no less than (C3+1) l M(d +e ) 2 C3t M(d+e) I->i---. 
card(R ) 2 Hence a correct program Q is output with probability > I --3/ 4e. In case F = Q one more additional 
possibility of returning an incorrect result must be accounted for, namely that the Zero Test algorithm 
in [2], §3, might not recognize a non-zero evaluation at ¢ properly. However, the probability of such 
an event can be controlled, say we allow it to happen only with probability no more than '4'(C2+1 ) M(d 
+e) log(d +e)" Then all tests succeed with probability > 1 -(/ 4 and a correct program is output with 
probability > 1 -c. In summary, we have the following theorem. Theorem 4.1: Algorithm Rational Numerator 
and Denominator does not fail and outputs a program Q that computes f and g with probability > 1 -2e. 
It requires polynomially many arithmetic steps as a function of len(P), d, and e. For F = Q this is also 
true for its binary complexity which also depends on el-size(P ). The algorithm needs polynomially many 
randomly selected field elements (bits for F = Q). [] We now formulate three corollaries to the theorem. 
The first corollary deals with distinguishing straight-line programs that compute polynomials from those 
that do not. It is clear that if we have the bounds d and e we only need to probabilistically inspect 
the degree of g after we have a straight-line program for it. But what if we do not have a-priori degree 
bounds? What we do then is to run our algorithm for d = e = 2 k , k = 1, 2, 3,'". Let f k and gk he the 
numerator and denominator whose computation is produced. For randomly chosen a m ,..., a n E F we then 
probabiHstically test whether   /k(a...., a.) --/Ca,..., a,,) = g gk(al ..... an) If the test is 
positive, with high probability f = fk and g "~ gk" We have the following corollary, which also extends 
the result in [7], Remark 5.6, on probabilistically guessing the degree of a polynomial given by a straight-line 
program. Corollary 4.1: Let f / g be given by a straight-line program P over F (zl ..... x, ). Then we 
can in random polynomial-time in len(P) and deg(f ) ÷ deg(g) deter-mine deg(/ ) and deg(g) such that 
with probability > 1 -e no failure occurs and the answer is correct. In par- ticular, we can decide whether 
f / g e F[z 1 ,..., z n]. [] For simplicity we state the next corollaries over infin-ite fields although 
this can be avoided as mentioned in step D. The next one resolves Strassen's question on computing the 
numerator and denominator of a rational function without divisions. By L D (r l,'", rm [ s 1,'", 8n ), 
ri, s I E D, we denote the non-scalar or total complexity of comput- ing r i from s I over D, see e.g. 
[9]. Corollary 4.2: Let F be a infinite field. Then LF I .........](f ,g ] xl,"',xn)= O(MCdeg(fg)) 2 
LF( .......z.)Cf / 9 l ~1,...:,)), where M (d) is the corresponding complexity of multiply- ing d-degree 
polynomials. In the non-scalar case M(d) = O(d). [] The third corollary concerns the paralletization 
of a straight-line computation for a rational function. From [11] we get. Corollary 4.3: Let P he a straight-line 
program of length I over F(x 1 ,..., xn), F infinite, that computes f / 0 where deg(f ), deg(g) ~< d. 
Then there exists a straight-line program Q of depth O ((log d ) (log d + log/)) and size (l d) °0} that 
also computes f/g. [] 5. Conclusion The question arises what major unresolved problems in the subject 
of polynomial factorization remain. One theoretical question is to remove the necessity of random choices 
from any of the problems known to lie within pro- babilistic polynomial-time, say factorization of univariate 
polynomials over large finite fields. Another problem is to investigate the parallel comulexity of polynomial 
fac- torization, say for the NC model [22]. Kronecker's reduc- tion from algebraic number coefficients 
[23] and [24], Berlekamp's factorization algorithm over small finite fields [25], Kaltofen's deterministic 
Hilbert irreducibility theorem [6], §7, and Weinberger's irreducibility test for Q[x] [26] all lead to 
NC solutions by simply applying known NC methods for linear algebra problems. It is open whether factoring 
in Q[z] or irreducibility testing in Fp[x], p large, or in Q[x, y] can be accomplished in NC. In connection 
with the Faetorization algorithm presented here, we also mention an open question. Assume that a straight-line 
program computes a polyno-mial whose degree is exponential in the length of the pro-gram. Are then at 
least its factors of polynomially bounded degree p-computable? A positive answer to this question would 
show that testing a polynomial for zero in a suitable decision-tree model is polynomial-time related 
to computing that polynomial. In general the theory of straight-line manipulation of polynomials may 
be extend- able in part to unbounded input degrees, but even for the elimination of divisions problem 
[9] the answer is not known. Nonetheless, in this paper we were able to contribute to Valiant's algebraic 
counterpart of the theory of P vs. NP in the positive, that is establish a polynomial upper bound for 
a major problem in computational algebra. In fact, it comes to us as a small surprise that p-computable 
polynomials are closed under factorization. And we have, finally, put to rest the problem of computing 
the sparse factorization of a multivariate polynomial. .Acknowledgement: A conversation with Allan Borodin 
during this conference last year triggered the construction of the Rational Numerator and Denominator 
algorithm. Tom Spencer very recently pointed out the possible connection between the factorization ques- 
tion and the relative power of decision vs. computation problems. References 1. L. Valiant, "Reducibility 
by algebraic projections," L'Enseignemsnt math6matique, vol. 28, pp. 253-268, 1982. 2. E. Kaltofen, 
"Greatest common divisors of polynomials given by straight-line programs," Math. Sei. Research Inst. 
Preprint, vol. 01918-86, Berkeley, CA, 1986. Preliminary version under the title "Computing with polynomials 
given by straight-line pro- grams I: Greatest common divisors" in Proc. 17th ACM Syrup. Theory Comp., 
pp. 131-142, 1985. 3. E. Kaltofen, "Computing with polynomials given by straight-line programs lI; Sparse 
factorization," Proc. 26th IEEE Syrup. Foun- dation.s Comp. Sci., pp. 451-458, 1985. 4. J. yon zur Gathen 
and E. Kaltofen, "Factoring sparse multivari- ate polynomials," J. Comp. System Sci., vol. 31, pp. 265-287, 
1985.  5. A. K. Lenstra, H. W. Lenstra Jr., and L. Lov~sz, "Factoring polynomials with rational coefficients," 
Math. Ann., vol. 261, pp. 515-534, 1982.  6. E. Kaltofen, "Polynomial-time reductions from multivariate 
to bi- and univariate integral polynomial factorization," SIAM J. Comp., vol. 14, pp. 469-489, 1985. 
 7. J. yon zur Gathen, "Irreducibility of multivariate polynomials," J. Comp. System Sci., vol. 31, 
pp. 225-264, 1985. 8. E. Kaltofen, "Effective Hilbert irreducibility," Information and Control, vol. 
65, p. in press, 1985. 9. V. Strassen, "Vermeidung yon Divisionen," J. reins u. angew. Math., vol. 264, 
pp. 182-202, 1973. 10. L. Hyafil, "On the parallel evaluation of multivariate polynomi- als," SIAM J. 
Comp., vol. 8, pp. 120-123, 1979. 11. L. Valiant, S. Skyum, S. Berkowitz, and C. Rackoff, "Fast paral- 
lel computation of polynomials using few processors," SIAM J. Comp., vo]. 12, pp. 641-644, 1983. 12. 
A. SchSnhage, "Schnelle Multiplikation von Polynomen liber KSrpern der Charakteristik 2," Acta Inf., 
vol. 7, pp. 395-398, 1977. 13. J. T. Schwartz, "Fast probabilistic algorithms for verification of polynomial 
identities," J. ACM, vol. 27, pp. 701-717, 1980. 14. A. FrShlich and J. C. Shepherdson, "Effective procedures 
in field theory," Phil. Trans. Roy. Sot., Ser. A, vol. 248, pp. 407-432, 1955/56. 15. R. Lipton and 
L. Stockmeyer, "Evaluations of polynomials with superpreconditioning," Proc. 8th ACM Syrup. Theory Comp., 
pp. 174-180, 1976. 16. C. P. Schnorr, "Improved lower bounds on the number of multiplications/divisions 
which are necessary to evaluate polyno- mials," Theoretical Cutup. Sei., vol. 7, pp. 251-261, 1978. 
17. R. P. Brent, F. G. Gustavson, and D. Y. Y. Yun, "Fast solution of Toeplit~ systems of equations and 
computation of Pad~ approximants," J. AIgorithnu, vol. 1, pp. 259-295, 1980. 18. D. E. Knuth, "The analysis 
of algorithms," Acres du eongr~6 international de6 Math}maticiene, vol. 3, pp. 269-274, Nice, France, 
1970. 19. A. SchSnhage, "Schnelle Kettenbruchentwicklungen," Aeta Inf., vol. 1, pp. 139-144, 1971. 
20. R. Moenck, "Fast computation of GCDs," Proc. 5th ACM Syrup. Theory Comp., pp. 142-151, 1973. 21. 
S. R. Czapor and K. O. Geddes, "A comparison of algorithms for the symbolic computation of Padd approximants," 
Pros. EURO- SAM '84, Springer Lee. Notes Comp. Sci., vol. 174, pp. 248-259, 1984. 22. S. A. Cook, "A 
taxonomy of problems with fast parallel algo- rithms," Inf. Control, vol. 64, pp. 2-22, 1985. 23. B. 
M. Trager, "Algebraic factoring and rational function integra- tion," Pros. 1976 ACM Syrup. Symbolic 
Algebraic Comp., pp. 219-228, 1976. 24. S. Landau, "Factoring polynomials over algebraic number fields," 
SIAM J. Comp., vol. 14, pp. 184-195, 1985. 25. J. yon zur Gathen, "Parallel algorithms for algebraic 
problems," SIAM J. Comp., vol. 13, pp. 802-824, 1984. 26. P. J. Weinberger, "Finding the number of factors 
of a polyno- mial," J. Algorithmz, vol. 5, pp. 180-186, 1984.    
			