
 Spatial Gossip and Resource Location Protocols * David Kempe Jon Kleinberg Alan Demers Dept. of Computer 
Science Dept. of Computer Science Dept. of Computer Science Cornell University, Ithaca NY Cornell University, 
Ithaca NY Cornell University, Ithaca NY 14853 14853 14853 kempe@cs.cornell.edu kleinber@cs.cornell.edu 
ademers@cs.cornell.edu ABSTRACT The dynamic behavior of a network in which information is chang­ing continuously 
over time requires robust and ef.cient mecha­nisms for keeping nodes updated about new information. Gossip 
protocols are mechanisms for this task in which nodes communi­cate with one another according to some 
underlying deterministic or randomized algorithm, exchanging information in each commu­nication step. 
In a variety of contexts, the use of randomization to propagate information has been found to provide 
better reliability and scalability than more regimented deterministic approaches. In many settings consider 
a network of sensors, or a cluster of distributed computing hosts new information is generated at individual 
nodes, and is most interesting to nodes that are nearby. Thus, we propose distance-based propagation 
bounds as a perfor­mance measure for gossip algorithms: a node at distance d from the origin of a new 
piece of information should be able to learn about this information with a delay that grows slowly with 
d, and is independent of the size of the network. For nodes arranged with uniform density in Euclidean 
space, we present natural gossip algorithms that satisfy such a guarantee: new information is spread 
to nodes at distance d, with high probabil­ity, in O(log1+e d) time steps. Such a bound combines the 
desir­able qualitative features of uniform gossip, in which information is spread with a delay that is 
logarithmic in the full network size, and deterministic .ooding, in which information is spread with 
a delay that is linear in the distance and independent of the network size. Our algorithms and their 
analysis resolve a conjecture of Demers et al. We show an application of our gossip algorithms to a basic 
resource location problem, in which nodes seek to rapidly learn of the nearest copy of a resource in 
a network. * Supported by an NSF Graduate Fellowship. Supported in part by a David and Lucile Packard 
Foundation Fel­lowship, an ONR Young Investigator Award, NSF ITR/IM Grant IIS-0081334, and NSF Faculty 
Early Career Development Award CCR-9701399. Permission to make digital or hard copies of all or part 
of this work for personal or classroom use is granted without fee provided that copies are not made or 
distributed for pro.t or commercial advantage and that copies bear this notice and the full citation 
on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires 
prior speci.c permission and/or a fee. STOC 01, July 6-8, Hersonissos, Crete, Greece. Copyright 2001 
ACM 1-58113-349-9/01/0007 ...$5.00. 1. INTRODUCTION Gossip algorithms The dynamic behavior of a network 
in which information is chang­ing continuously over time requires robust and ef.cient mecha­nisms for 
keeping nodes updated about new information. For ex­ample, we may have a network of sensors measuring 
properties of the physical world, and performing computations on the collective set of measurements in 
a distributed fashion (see e.g. [4, 6, 8, 9]). As measured values change, we would like for them to be 
propa­gated through the network rapidly. Or we may have a distributed network of computing hosts that 
need to be informed about signif­icant changes in the load on machines, or the appearance of new resources 
in the network [15]; again, we would like such informa­tion to be spread quickly through the network. 
For reasons of reliability and scalability, we do not want cen­tral control for updates to reside with 
a small set of nodes. Rather, we seek mechanisms by which nodes communicate in a relatively homogeneous 
fashion with one another, so as to spread informa­tion updates. Gossip protocols [3, 7] are mechanisms 
of this type in which nodes communicate with one another according to some underlying deterministic or 
randomized algorithm, exchanging in­formation in each communication step. In a variety of contexts, the 
use of randomization for such tasks has been found to provide better reliability and scalability than 
more regimented deterministic approaches (see e.g. [1, 2, 3, 6, 13, 15, 16]). It is useful to consider 
some of the issues that arise in a very sim­ple version of our .rst example. Suppose we have a network 
of N vv  sensors positioned at the lattice points of a N × N region of the plane, monitoring conditions 
about the underlying environment. We assume that there is an underlying mechanism that supports an abstraction 
of point-to-point communication: in a single virtual step, any node can send a message to any other node, 
regardless of the distance separating them in the plane. All the algorithms we develop here are built 
on top of such a point-to-point communica­tion mechanism; for our purposes, the fact that this point-to-point 
communication may actually be implemented by multi-hop trans­mission of packets is abstracted away. Here 
is a basic problem we may wish to solve in such an envi­ronment: If a sensor node x detects abnormal 
conditions, it will generate an alarm message m that needs to be propagated to all other nodes in the 
network. Consider the following two different approaches to this problem. Uniform gossip. In each step, 
each node u chooses a node v uni­formly at random, and forwards to v all the alarm messages it knows 
about. A well-known result states that with high probability, all nodes will receive a copy of a given 
message m within O(log N) steps of its initial appearance [7, 10, 14]. Neighbor .ooding. In each step, 
each node u chooses one of its closest neighbors v in the plane, according to a round-robin ordering, 
and forwards to v all the alarm messages it knows about. Clearly, any node v that is at distance d from 
the origin of a message m will receive a forwarded copy of m within O(d) steps of its initial appearance. 
However, the time it takes for all nodes to obtain a given message under v this scheme is T( N). Both 
of these algorithms follow the gossip paradigm: in each time step u picks some other node v (either deterministically 
or at ran­dom) and communicates with v. We will refer to this as u calling v. Moreover, both algorithms 
are very simple, since each node is essentially following the same local rule in each time step, inde­pendently 
of message contents. In the protocols we consider, the analysis will use only information that u passes 
to the node v it calls, ignoring any information that u may obtain from v. In other words, all our protocols 
work in the push model of communication. In this discussion, it is crucial to distinguish between two 
con­ceptual layers of protocol design: (i) a basic gossip algorithm, by which nodes choose other nodes 
for (point-to-point) commu­nication; and (ii) a gossip-based protocol built on top of a gossip algorithm, 
which determines the contents of the messages that are sent, and the way in which these messages cause 
nodes to update their internal states. We can view a gossip algorithm as generating a labeled graph H 
on the N nodes of the network; if u commu­nicates with v at time t, we insert an edge (u, v) with label 
t into H. When we consider more complex gossip-based protocols be­low, it is useful to think of a run 
of the underlying gossip algorithm as simply generating a labeled graph H on which the protocol then 
operates. The propagation time The two algorithms discussed above have quite different perfor­mance bounds, 
with uniform gossip .lling in the set of points exponentially faster than neighbor .ooding. The neighbor 
.ood­ing algorithm, however, exhibits a desirable feature that uniform gossip is lacking: messages are 
propagated to nodes with a delay that depends only on their distance from the origin of the message, 
not on the total number of nodes in the system. In the examples above, and in applications exhibiting 
any kind of spatial locality, this can be very important: when an alarm is triggered, we may well want 
to alert nearby nodes earlier than nodes further away; similarly, as resources appear in a network, we 
may want nodes to learn more quickly of the resources that are closer to them. With uniform gossip, it 
is likely that a node adjacent to the source of an alarm will only be alerted after news of the alarm 
has traveled extensively through the network. Our work was initially motivated by the following question: 
Is there a gossip algorithm preferably a simple one that exhibits the best qualitative features of 
both uniform gossip and neighbor .ooding, by guaranteeing that a message can be propagated to any node 
at distance d from its originator, with high probability, in time bounded by a polynomial in log d? The 
crucial point is that such a bound would be poly-logarithmic, yet independent of N. To make this question 
precise, we introduce the following de.nition. We will say that a function fA(·) is a propagation time 
for a given gos­sip algorithm A if it has the following property: Whenever a new piece of information 
is introduced at u, there is a high probability1 that some sequence of communications will be able to 
forward it to v within O(fA(d)) steps. 1When we write with high probability here, we mean with prob­ability 
at least 1 - (log(d +1))-., where . may appear in the constant of the expression O(fA(d)). Our question 
can now be phrased as follows: Is there a gossip algorithm with a propagation time that is polynomial 
in log d? A gossip algorithm with good propagation time Our .rst result is an af.rmative answer to this 
question. Rather than the lattice points of the plane, we consider a more general setting that of a point 
set with uniform density in RD . We will make this notion precise in the next section; essentially, it 
is a point set in RD with the property that every unit ball contains T(1) points. THEOREM 1.1. Let P 
be a set of points with uniform density in RD . For every e> 0, there is a randomized gossip algorithm 
on the points in P with a propagation time that is O(log1+e d). In this Theorem, the O(·) includes terms 
depending on e and the dimension D. However, the propagation bound is independent of the number of points 
in P , and in fact holds even for in.nite P . The algorithm achieving this bound is equivalent to one 
proposed by Demers et al. [3], who considered it in the context of concerns different from ours. We .x 
an exponent . strictly between 1 and 2. In each round, each node u chooses to communicate with a node 
v with probability proportional to d-u,vD., where du,v denotes the distance between u and v. Demers et 
al. had conjectured that this algorithm would propagate a single message to all nodes in a D­dimensional 
grid of side length N with high probability in time polynomial in log N; a special case of Theorem 1.1 
(obtained by choosing a .nite grid of side length N for our metric space) yields a proof of this conjecture. 
We also show how our algorithms and their analysis can be used to provide a partial resolution to open 
questions about the behavior of Astrolabe, a network resource location service developed by van Renesse 
[15]. Astrolabe relies on an underlying gossip mechanism, and by generalizing the setting in which we 
cast our algorithms, we are able to give bounds on the rate at which messages spread through this system. 
Alarm-spreading and resource location Following our discussion above, the inverse-polynomial gossip al­gorithm 
provides a transport mechanism on which to run a va­riety of protocols. Perhaps the most basic application 
is a simple version of the alarm-spreading example we discussed at the outset. Suppose that at each point 
in time, each node u can be in one of two possible states: safe or alarm. In each time step, u calls 
another node v according to an underlying gossip algorithm, and transmits its current state. If u is 
in the alarm state, then v will also enter the alarm state when it is called by u. All nodes remain in 
the alarm state once they enter it. By using the inverse-polynomial gossip al­gorithm from Theorem 1.1, 
we obtain the following guarantee for this protocol: if x isanode in P , and some node at distance d 
from x undergoes a transition to the alarm state at time t, then with high probability x will enter the 
alarm state by time t + O(log1+e d). A more interesting problem than the simple spreading of an alarm 
is that of resource location. As before, we have a set of points P with uniform density. As time passes, 
nodes may acquire a copy of a resource. (For example, certain nodes in a sensor network may be receiving 
data from an external source; or certain nodes in a cluster of computers may be running the server component 
of a client-server application.) At any given time, each node u should know the identity of a resource-holder 
(approximately) closest to it; we wish to establish performance guarantees asserting that u will rapidly 
learn of such a resource. If at every time step, all nodes forward the names of all resource holders 
they know about, then the propagation bounds from The­orem 1.1 immediately imply that nodes will learn 
of their closest resource within time O(log1+e d), where d is the distance to the closest resource. The 
disadvantage of this protocol is that the mes­sage sizes grow arbitrarily large as more resources appear 
in the network. Resource location: Bounding the message size Naturally, protocols that require the exchange 
of very large mes­sages are not of signi.cant interest for practical purposes. For problems in which 
there are natural ways of aggregating infor­mation generated at individual nodes, it is reasonable to 
hope that strong guarantees can be obtained by protocols that use messages of bounded size (or messages 
that contain a bounded number of node names). We focus on the above resource location problem as a fundamen­tal 
problem in which to explore the power of gossip-based protocols that use bounded messages, in conjunction 
with the algorithm from Theorem 1.1. The problem has both a monotone and a non-monotone variant. In the 
monotone version, a node never loses its copy of the resource once it becomes a resource-holder. For 
this version of the problem, we consider the following simple gossip protocol. Each node u maintains 
the identity of the closest resource-holder it knows about. In a given time step, ucalls a node v according 
to the gossip algo­rithm from Theorem 1.1 and transmits the identity of this resource­holder. Finally, 
the nodes update the closest resource-holders they know about based on this new information. Note that 
the protocol only involves transmitting the name of a single node in each com­munication step; moreover, 
u transmits the same value regardless of the identity of the node it calls. Despite its simplicity, we 
can show that this protocol satis.es strong performance guarantees in the monotone case. In one dimension, 
it has the following property. Let r and u be two nodes at distance d.If r holds the closest copy of 
the resource to u during the time interval [t,t'], and if t' - t= .(log1+e d), then with high probability 
uwill learn ' about rby time t. In higher dimensions, it has the following approximate guar­antee. Again, 
let rand ube two nodes at distance d.If rac­quires a resources at time t, then with high probability 
node uwill know of a resource-holder within distance d+ o(d) by time t+ O(log1+e d). In the the non-monotone 
version of the problem, a node may lose a resource it previously held. Designing gossip protocols in 
this case is more dif.cult, since they must satisfy both a positive re­quirement that nodes rapidly 
learn of nearby resources and a negative requirement that nodes rapidly discard names of nodes that 
no longer hold a resource. We provide an algorithm for the one-dimensional case, establishing that precise 
formulations of the positive and negative requirements can be maintained with a delay that is polynomial 
in log d. Weaker versions of the positive and negative requirements, incorporating an approximation guarantee, 
can be obtained in higher dimensions. 2. SPATIAL GOSSIP De.nitions We will present our gossip algorithms 
and analysis for nodes posi­tioned at points in RD; for two such nodes xand y, we de.ne their distance 
dx,y using any Lk metric. Below, we will discuss how the results can be generalized to other settings. 
Let Bx,d = {y | dx,y = d} denote the ball around x of radius d. We say that an (in.nite) set of points 
P in RD has uniform density, with parameters ß1 and ß2, if every ball of radius d = 1 contains between 
ß1dD and ß2dD points of P. (This includes balls not centered at points of P.) As stated, our de.nition 
only makes sense for in.nite point sets. However, we can easily extend it to .nite point sets, and our 
algorithms and analysis apply to this case as well with essentially no modi.cations. For simplicity, 
however, we will focus on in.nite point sets here. As we discussed in the introduction, the gossip algorithms 
we study are designed to produce communication histories with good propagation behavior. A useful model 
for stating and proving prop­erties of such communication histories is that of temporal networks and 
strictly time-respecting paths in them, proposed in [5, 11] as a means to describe how information spreads 
through a network over time. A directed temporal network is a pair (G,.), where G =(V,E) is a directed 
graph (possibly with parallel edges), and . : E . Ia time-labeling of edges. A strictly time-respecting 
path P = e1,... ,ek from uto vis a path in Gsuch that .(ei) < .(ei+1) for all 1 = i<k. Hence, strictly 
time-respecting u-v paths are exactly those paths along which information from u can reach v. For a given 
run R of a gossip algorithm A, the associated tem­poral network HR is the pair ((V,E),.), where V is 
the set of all nodes in the system, and E contains an edge e =(u,v) labeled .(e)= t if and only if u 
called v at time t in R. Note that there may be an in.nite number of parallel copies of the edge (u,v), 
with different labels however, no two parallel copies can have the same label. For a subset V' . V of 
nodes, and a time interval I, we use HR,V ',I to denote the temporal network ((V',E'),.|E' ), with E' 
= {e . E n (V' × V') | .(e) . I}. That is, HR,V ',I is the communication history of the run R, restricted 
to a speci.c time interval and a speci.c group of participating nodes. Throughout, ln denotes the natural 
logarithm, and ld the base-2 logarithm. The Gossip Algorithms We consider gossip algorithms based on 
inverse-polynomial prob­ability distributions. The algorithms are parameterized by an ex­ponent . satisfying 
1 <.< 2. Let x y be two nodes at = distance d = , and let p(.) denote the probability that x calls dx,yx,y 
(.) y. Then, we let px,y := cx(d+1)-D. ,i.e. the probability that yis called decreases polynomially 
in the distance between xand y. cx (.) is chosen such thaty px,y = 1. cx might be the normalizing con­stant 
for the distribution; however, we want to retain the freedom to choose cx smaller, to model the fact 
that messages might get lost with constant probability. We make the restriction that c:= infx cx is strictly 
greater than 0. We denote the resulting gossip algorithm by A. . Let us quickly verify that the probability 
distribution is indeed well-de.ned at each point x, i.e. that cx can be chosen strictly greater than 
0. Notice that the total probability mass at point x is at most 8 D-1 -D. Dß2z · (z+1)dz z=0 8 D(1-.)-1 
= Dß2z dz<8, z=1 because .>1 and D>0. The main result of this section is a proof of Theorem 1.1, giving 
poly-logarithmic bounds on the propagation time of A. when 1 < .<2. We state the result in the following 
form. THEOREM 2.1. Fix a .with 1 <.<2, and de.ne the function 1 fA. (d)= a·(ld(d+1)) 1- ld (.) ld ld(d+1). 
Then, acan be cho­ sen such that for every ball B of diameter d> 1, every time t, and nodes x, x ' . 
B, the temporal network HR,B,[t,t+.fA.(d)) con­tains a strictly time-respecting x-x ' path with probability 
at least 1-(ld(d +1))-. . Intuitively, this theorem states that information from any node x can reach 
any node x ' with high probability within time poly­logarithmic in their distance. Also, it guarantees 
that the informa­tion stays within a small region containing both x and x ' on its way from x to x ' 
. The proof is by induction on the distance between the nodes x and x ' . We will show that during a 
certain time interval I, a node u close to x will call a node u ' close to x ' , and then we will use 
induction to guarantee paths from x to u before I, and from u ' to x ' after I. The following de.nitions 
formally capture the random events that we are interested in. For given x and x ' , let EH,x,x ' denote 
the event that the tempo­ral network H contains a strictly time-respecting x-x ' path. Let E (U, U ' 
,I) be the set of all potentially available labeled edges from U to U ' with labels from the interval 
I; that is, E (U, U ' ,I) contains one element for each (u, u ' ,t), where u . U, u ' . U ' , and t .I 
is a time. Let .be any total order on E (U, U ' ,I). Let F denote the event that e is the smallest edge 
from E (with H,E,e respect to .) contained in H, and F the event that Hcon­ H,E,. tains no edge from 
E . Notice that the events F are disjoint H,E,e for different e, and F=F H,E,. E E,e. e. H, Let s = 
1 min{ß1, 1}·4-D. First, we prove a lemma bounding 2 from above the probability of the event F H,E,.. 
D. LEMMA 2.2. Let S and S ' be sets of size at least s(k +1) 2 both contained in a ball Bk of radius 
at most k, and let I be a time interval of length at least 2D. lnt. Let E =E(S, S ' ,I), and cs2 H=HR,Bk,I 
. Then, Pr[F ]=1/t. H,E,. Proof. Any two points u . S and u ' . S ' are at distance at most 2k, so at 
any time t . I, u calls u ' with probability at least cu(2k +1)-D. =c(2k +2)-D.. Hence, for any .xed 
u .S and t . I, Hcontains a u-S ' edge labeled t with probability at least c|S ' |(2k +2)-D. . As the 
random choices are independent for all u .S and t .I, the probability Pr[F ] that Hcontains no S-S ' 
edge e with H,E,. label .(e).I is at most '-D.|S||I|-c|S ' ||S||I|(2k+2)-D. (1-c|S |(2k +2))=e 22-D. 
2D. -csln t =e cs2 =1/t. The central (inductive) idea explained above is captured in the following Lemma. 
We let r = 1 be the (claimed) exponent 1- ld (.) in the propagation bound, and de.ne g(k):= max{0, 2(ld(k 
+ 1))r -1}. .< 1is a constant (to be determined only for the proof of Theorem 2.1), and . = 2D. ld 1 
. cs2 . LEMMA 2.3. Let x and x ' be at distance k, Bk a ball of radius k containing x and x ' , and [t, 
t ' )a time interval of length at least .g(k). Let Hk =HR,Bk,[t,t ' ) be the corresponding temporal net­work. 
Then, the probability of the event EHk,x,x ' that there is a strictly time-respecting x-x ' path in Hk 
is at least 1-.g(k). Proof. For k =0, the ball Bk consists only of one point x,so x =x ' , and as the 
empty path is a time-respecting x-x ' path, such a path exists with probability 1=1-.g(0). For k =1, 
we let k ' =Lk./2 -1J(notice that k ' <k), and B and B ' balls of radius k ' with x .B .Bk, and x ' .B 
' .Bk. Let s = t +.g(k ' ), s ' = s +., I =[s, s ' ), E = E (B, B ' ,I), ' and H=HR,B,[t,s), H =HR,B 
' ,[s ' ,t ' ). Because s -t =.g(k ' ), we can apply the induction hypothesis to H, and conclude that 
Pr[EH,x,u]=1-.g(k ' ), for any u .B. Using the assumption that t ' -t =.g(k), we obtain that t ' -s ' 
= t ' -t -.g(k ' )-. = .(g(k)-g(k ' )-1).If k ' =0, then 2g(k ' )+1=1=g(k), and otherwise, ' ./2rr 2g(k 
)+1=4(ldk)-2+1=2(ldk)-1=g(k). In either case, 2g(k ' )+1=g(k), and therefore t ' -s ' =.g(k ' ), so we 
can apply the induction hypothesis to H ' as well, to show that Pr[EH ' ,u ' ,x ' ]=1-.g(k ' ), for any 
u ' .B ' . Whenever there is an edge e =(u, u ' ) . E , and strictly time­ ' '' respecting paths P and 
P from x to u in Hand from u to x in '' ' H, the concatenated path PeP is a strictly time-respecting 
x-x ' '' path in Hk. Because the time-intervals [t, s), [s, s ) and [s ,t ) are disjoint, and all random 
choices made by A. are independent, the three events EH,x,u, F and E' are independent for Hk,E,e H ' 
,u ' ,x .xed x, x ' and e =(u, u ' ). Using that the events F are Hk,E,e disjoint for distinct e, we 
obtain that ' Pr[EHk,x,x ] =Pr[EH,x,u nF nE'' ] Hk,E,e H ' ,u ,x e=(u,u ' ).E =Pr[EH,x,u]·Pr[EH ' ,u 
' ,x ' ]·Pr[F ] Hk,E,e e=(u,u ' ).E =(1-.g(k ' ))·(1-.g(k ' ))·Pr[F ] Hk,E,e e=(u,u ' ).E =(1-.g(k ' 
))2 ·(1-Pr[F ]) Hk,E,. = 1-2.g(k ' )-Pr[F ] Hk,E,. If k ' =1, then k ' =Lk./2 -1J= 41 (k./2 +1) = 14 
(k +1)./2 , D. so both B and B ' contain at least ß1(k ' )D = ß14-D(k +1) 2 points. Otherwise, k ' =0, 
and B and B ' contain exactly one point (x or x ' , resp.). As Lk./2 -1J =0, we know that k./2 < 2,so 
D. = k./2 -D (k +1)./2 +1 < 3, and 4(k +1) 2 = 1. There­ D. fore, B and B ' contain at least 1 min{ß1, 
1}·4-D(k +1) 2 2 = s points in either case. Because I has size |I|= s ld 1 ln 1 , c. c. we can apply 
Lemma 2.2, with B, B ' , Bk, and I, to obtain that Pr[F ] = .. Using 2g(k ' )+1 = g(k)(which we showed 
Hk,E,.above), we now conclude that Pr[EHk,x,x ' ]=1-.g(k), complet­ing the proof. The Theorem now follows 
quite easily. Proof of Theorem 2.1. Choose . =(ld(d +1))-r-. , a =4r · 2D. cs2 , and let t ' =t +.fA. 
(d). By substituting the de.nitions of the function g and the con­stants, we can verify that t ' -t = 
.fA. (d) = .g(d). (In this calculation, we use that 2.r =. +r, which holds because r =1 and . =1.) We 
can therefore apply the above Lemma 2.3 to x and x ' (and thus with k = d), to obtain that with probability 
at least r 1-.(ld(d +1))=1-(ld(d +1))-., the temporal network H contains a strictly time-respecting x-x 
' path, complet­ R,B,[t,t ' ) ing the proof. We can get rid of the ld ld(d +1)term by increasing the 
expo­nent r slightly. A more general setting In the proofs of Theorem 2.1 and Lemma 2.3, we only used 
rel­atively few properties of the metric space RD . In fact, we can generalize the results to hold for 
point sets without an underlying metric, provided only that we have an appropriate notion of what a ball 
is. Speci.cally, let X be a set of points, ß and µ> 1 two designated constants, and Da collection of 
.nite subsets of X, called discs, that satisfy the following axioms. 1. For every x .X, there is a disc 
D .Dwith x.D. 2. For any two discs D1,D2, there is a disc D .D1 .D2. 3. If D1,D2,... are discs with 
|Di|=b and x .Di for all i, then there exists a disc D with Di . D for all i, and |D|=ß·b. 4. If D is 
a disc with x .D and |D|> 1, then there is a disc  ' '' D .Dwith x .D and |D|>|D |= 1 |D|. µ We can 
think of the collection of discs as serving the role of balls in a metric space with point set X. With 
this interpretation, the above axioms are satis.ed by point sets of uniform density in RD, with the constant 
ß chosen to be exponential in D. However, they are also satis.ed by certain other natural metric spaces 
and set systems, including a version of van Renesse s Astrolabe system [15] that we discuss below. For 
a given disc collection, we can de.ne probabilities p(.) for the inverse polynomial gossip algorithms 
A.. For points x,y .X, let b be the minimum cardinality of any disc D .Dcontaining both xand y. By the 
.rst two axioms, such a disc exists, and there­ (.) fore, b is well-de.ned. Now, de.ne px,y := cxb-., 
where cx is again a normalizing constant at point x. From the third axiom, we obtain that for any point 
x, at most ßbpoints y can lie in a disc D that also contains x and has size |D|=b. Therefore, at most 
ßb points can contribute b-. or more to the total probability mass at point x. Hence, the total probability 
mass yp(.) at any point xis at x,y 88 b-. = ß. =x most (ßb-ß(b-1)) ·b-. = ß , and in b=1b=1 .-1 particular 
.nite, so the distribution is well-de.ned. For this distri­bution, we can state the propagation guarantee 
of A. as follows. THEOREM 2.4. Let 1 <.< 2. Let x,x ' .X be two points, and Da disc of size bcontaining 
both xand x ' . Then, the temporal network HR,D,[t,t+.fA.(b)) contains a strictly time-respecting x­x 
' path with probability at least 1 -(ld(b+1))-., for every time t. In other words, x ' will learn of 
information originating at xwith a propagation delay that is poly-logarithmic in the size of the small­est 
disc containing both of them. The proof of this Theorem closely follows the proof of Theorem 2.1, and 
we omit it here. Other values of the parameter . It is natural to ask about the behavior of our inverse-polynomial 
gossip algorithms for different values of the exponent .. We have found that the set of possible values 
for .can be divided into three parts with qualitatively distinct behavior. For . = 1, we do not actually 
obtain a well-de.ned probability distribution for in.nite point sets; for a .nite point set, the propagation 
time cannot be bounded as a function of the distance alone (i.e. independent of the size of the system). 
For 1 <.<2, we have the behavior analyzed above; and for .> 2 we prove that the propagation time is at 
least .(de) for an exponent e>0 depending on .. This leaves only the transitional case . =2, which turns 
out to have very interesting behavior; we are able to prove that for every e>0, the gossip algorithm 
A. with . =2 has a propagation time that is O(de), but do not know whether it has a propagation time 
that is polynomial in log d. We note that all these results for varying values of .also hold in the more 
general setting of disc collections, with bounds in terms of distances replaced by bounds in terms of 
disc sizes. Astrolabe Astrolabe is a network resource location service that uses a gossip mechanism for 
spreading information [15]; we refer the reader to this paper for more detail than we are able to provide 
here. One reasonable model of the structure of an Astrolabe system is as fol­lows: computing nodes are 
positioned at the leaves of a uniform­depth rooted tree T of constant internal node degree; there is 
an underlying mechanism allowing for point-to-point communication among these leaf nodes. It is desirable 
that information originating at a leaf node x should be propagated more rapidly to leaf nodes that share 
lower common ancestors with xthan to those that share higher common ancestors. The gossip mechanism in 
Astrolabe can be modeled using disc collections as follows: The underlying point set X is equal to the 
leaves of the tree T, and there is a disc D corresponding to the leaves of each rooted subtree of T. 
It is easy to verify that the four axioms described above hold for this collection of discs. Hence, if 
leaf nodes communicate according to the gossip algorithm in The­orem 2.4, then a piece of information 
originating at a leaf node x will spread to all the leaves of a k-node subtree containing x, with high 
probability, in time polynomial in log k. For reasons of scal­ability, the gossip algorithm actually 
used in the Astrolabe system is essentially equivalent to A. with . =2; and so, by the result mentioned 
above, information will spread through a k-leaf subtree, with high probability, in time O(ke) for every 
e>0. 3. RESOURCE LOCATION PROTOCOLS In the introduction, we discussed the basic resource location problem. 
We have nodes in RD as before; as time passes, nodes may acquire copies of a resource, and we wish for 
each node to rapidly learn the identity of a resource-holder (approximately) clos­est to it. (By abuse 
of terminology, we will sometimes interchange the terms resource-holder and resource. ) Our protocols 
for resource location will rely on an underlying algorithm for gossip on point sets of uniform density 
in RD;wedo not make any assumptions about this algorithm other than versions of the probabilistic propagation 
guarantee which we proved A. to have in the previous section. The most basic required guarantee can be 
expressed as follows: There is a monotonically non-decreasing time-bound fA(d) such that for any ball 
B of diameter d, any two nodes x,x ' .B, and any time t, the temporal network HR,B,[t,t+fA(d)) contains 
a time-respecting path from xto x ' with high probability. This asserts that information from a source 
x with high prob­ability reaches a destination x ' suf.ciently fast via a path not involving any node 
too far away from either x or x ' (as can be seen by choosing B to be the smallest ball containing both 
x and x ' ). The nature of the high probability guarantee may depend on the algorithm, and will directly 
affect the guarantees provided by the resource location protocol. In the preceding section, we estab­lished 
that this guarantee holds for inverse polynomial distributions with exponents . .(1,2), with fA(d).O(.log1+e 
d), giving us high probability guarantee 1-(ld(d+1))-. .  Monotone Resource Location We begin by considering 
the monotone case, in which any node that is a resource-holder at time tis a resource-holder for all 
t ' =t. Our protocol should guarantee that within short time , a node learns of its closest resource 
(once it becomes available), and subsequently will never believe any resource further away to be its 
closest re­source. An approximation guarantee would be to require that a node learns of a resource that 
is not too much further away from it than its closest resource. A simple protocol for the line If resources 
never disappear, and all points lie on a line (i.e. the dimension is D =1), a very simple protocol will 
ensure that each node learns of its closest resource quickly (as quanti.ed by fA(d)), with high probability. 
The protocol is as follows: Each node x locally maintains the node Nx(t), the closest node which xknows 
to hold a copy of the resource at time t. Initially, at time t =0, Nx(0)is set to a null state .. When 
a resource appears at a node xat time t, Nx(t ' )=x for all t ' =t. In each round t, each node xselects 
a communication partner according to the algorithm A, and sends the value Nx(t). Let Mt be the set of 
all messages that xreceived in a round t. Then, it updates Nx(t+1)to be the closest node in Mt .{Nx(t)}(ties 
broken in favor of Nx(t), and otherwise arbitrarily). For the line, we can prove the following strong 
guarantee about the performance of this protocol: THEOREM 3.1. Let x be any node, and xR a resource at 
dis­tance d =dx,xR . Let t ' =t+.fA(d), and assume that xR was the (unique) closest resource to x throughout 
the interval [t,t ' ]. Then, Nx(t ' )=xR with high probability, Proof. For the proof, let Bbe the smallest 
interval containing both xR and x, and consider the temporal network (G,.)=HR,B,[t,t ' ). The guarantee 
of the underlying algorithm Astates that with high probability, (G,.)contains a time-respecting path 
from xR to x. Let xR = v1,... ,vk = x be the vertices on any such time­respecting path, and e1 =(v1,v2),... 
,ek-1 =(vk-1,vk)its edges with time labels ti =.(ei). Let xi be the message that was sent from vi to 
vi+1 at time ti. By induction, we will establish that xi = xR.For i =1, this is clearly true. For the 
inductive step from ito i+1, consider the message xi received by vi+1 at time ti, and the message xi+1 
sent by vi+1 at time ti+1. Because vi+1 lies in the smallest interval containing xR and x, vi+1 lies 
on a shortest path from xR to x. Therefore, xR being the closest resource to xthroughout [t,t ' ]im­plies 
that it is also the closest resource to vi+1. By the choices of the protocol and the induction hypothesis, 
Nti)= xR, and vi+1 (as xR is still the closest resource to vi+1 at time ti+1, we obtain xi+1 =Nvi+1 (ti+1)=xR. 
At time tk-1, node x receives the message xk-1 =xR, and as t=tk-1 <t ' , xR is the closest resource to 
xfrom time tk-1 until t ' ,so Nx(t ' )=xR. Analysis of the protocol in higher dimensions In higher dimensions, 
this simple protocol may not inform nodes of their truly closest resource as quickly as .fA(d). Intuitively, 
we want the message about a node xR with a resource to quickly reach every node xsuch that xR is the 
closest resource to x. That is, we are interested in .lling in the Voronoi region of the node xR. However, 
if the Voronoi region is very long and narrow, most calls made by nodes inside the region will be to 
nodes outside the region. Hence, the time depends on the angles of the corners of the Voronoi region. 
If we wish to make guarantees avoiding such speci.c properties of the actual distribution of resources, 
we can obtain an approxi­mation guarantee by slightly strengthening the requirement on the algorithm 
A. Our stronger requirement will be that not only is there a strictly time-respecting path, but its total 
length is bounded by some function of the distance d under consideration. Intuitively, this means that 
messages with high probability do not take very long detours on their way from a source to a destination. 
More formally, for a path P with vertices v1,... ,vk, let its path distance be d(P)= k-1 dvi,vi+1 . Then, 
we can state the re­ i=1 quirement as: There is a time-bound fA(d) and a length function eA(d)such that 
for any ball B of diameter d, any two nodes x,x ' . B, and any time t, HR,B,[t,t+.fA(d)) contains a time-respecting 
path P from xto x ' of path distance d(P)=eA(d), with high probability. Below, we prove that the algorithms 
A. with ..(1,2)satisfy this property with eA(d)=d+o(d). We can now state the approximation guarantee 
of the resource location protocol that we previously analyzed for line: THEOREM 3.2. Let x be any node, 
and xR a resource at dis­ ' '' tance d =dx,xR . Let t =t+.fA(d), and xR =Nx(t ). Then, dx,x ' =eA(d)with 
probability at least 1-(ld(d+1))-. . R Hence, for suf.ciently large d, the inverse polynomial gossip 
al­gorithms A. will guarantee a (1+o(1))-approximation to the clos­est resource within poly-logarithmic 
time, with high probability. Proof. Let B be any smallest ball containing both xR and x, and consider 
the temporal network (G,.)= HR,B,[t,t ' ). With high probability, this network contains a strictly time-respecting 
xR -x path P of path distance d(P)=eA(d). Let xR =v1,... ,vk =x be the vertices of this path, ei =(vi,vi+1)its 
edges with labels ti =.(ei), and xi the message sent from vi to vi+1 at time ti. We prove by induction 
that for all i, dvi,xi = i-1 d j=1 vj ,vj+1 . Clearly, this holds for i =1, since x1 = xR = v1. For the 
step from i to i+1, notice that ti <ti+1. The protocol then ensures dvi+1,xi+1 =dvi+1,Nvi+1 (ti+1) =dvi+1,Nvi+1 
(ti+1) =dvi+1,xi . By the triangle inequality, d= d+dvi,xi , and ap­ vi+1,xi vi+1,vi plying the induction 
hypothesis to iyields that i-1 i dvi+1,xi+1 =dvi+1,vi + dvj ,vj+1 = dvj ,vj+1 . j=1 j=1 Using the behavior 
of the protocol at node x=vk and time tk,we know that k-2 dx,x ' =dx,vk-1 + dvj ,vj+1 =d(P)=eA(d), R 
j=1 completing the proof. By taking a closer look at the analysis in the proof of Theorem 2.1, we can 
show that the algorithms A. (for 1<.< 2) have the claimed property of short paths with eA. (d)=d+o(d). 
LEMMA 3.3. Let B be a ball with diameter d, t an arbitrary time, and t ' = t+.fA. (d). Then, with probability 
at least 1- (ld(d+1))-., the temporal network (G,.)= HR,B,[t,t ' ) con­tains a strictly time-respecting 
path P from xto x ' of path distance at most d+o(d)for any two nodes x,x ' .B. Proof. The path P constructed 
in the proof of Theorem 2.1 con­sists of one jump edge of length at most d, and two subpaths P and P 
' which lie inside balls B and B ' of diameter at most d./2 - 1J=d./2, and are of the same form. Hence, 
we ob-eA. (d./2 tain the recurrence eA. (d) =d +2). Using standard ld ld d substitution techniques (and 
writing n = ), we .nd that this 1- ld . recurrence has the solution n n-k+( 2 )k eA. (d)= 2. . k=0 We 
can bound this from above by splitting off the last term (k =n) n+( 2 )n-1 . of the sum, and bounding 
all other terms from above by 2, 1 ld ld d obtaining that eA. (d)=d+(ldd)1- ld (.) ·d./2, which is 1- 
ld . bounded by d+o(d), as claimed. There is an alternate way to obtain approximation guarantees for 
resource location in higher dimensions, without strengthening the assumptions on the underlying gossip 
algorithm. This is done by having nodes send larger messages in each time step. For a scaling parameter 
.>1, a node xat time tstores the iden­tity of the closest resource-holder xR, and a set Rx(t)consisting 
of all resource-holders xR ' that xhas heard about whose distance to xis at most .·dx,xR . In each time 
step, nodes communicate their sets Rx(t), and then update them based on any new information they receive. 
Here is a more precise description of the protocol: The local state of any node x consists of a set Rx(t)of 
nodes which x knows to hold a copy of the resource at time t. Initially, Rx(0) = Ø, and whenever a resource 
appears at a node xat time t, x .Rx(t ' )for all t ' =t. In each round t, each node x selects a communication 
partner according to the algorithm A, and sends the entire set Rx(t). Let Mt be the set of all gossip 
messages that x received in a round t, and M =( m.Mt m).Rx(t)the set of all resources about which xknows 
at time t. Let d =miny.M dx,y. Then, xupdates Rx(t+1):={y .M |dx,y =.d}, i.e. to be the set of all nodes 
no more than . times as far away from xas the nearest resource. The sets Rx(t)sent and locally stored 
could potentially be large, but if we believe the resources to be spaced relatively evenly, the local 
storage and messages should only contain a constant num­ber of nodes (for constant .). This protocol 
yields the following approximation guarantee: THEOREM 3.4. Let x be any node, and xR a resource at dis­tance 
d = dx,xR . Let t ' = t +.fA(d), and x ' R beanode in Rx(t ' )with minimal distance to x (among all nodes 
in Rx(t ' )). 2 Then, dx,x ' =(1+ .-1 )dwith high probability. R Hence, this Theorem shows how we can 
smoothly trade off mes­sage size against better approximation guarantees. Notice that the runtime of 
the gossip protocol is not directly affected by the desired better guarantees (only via the larger message 
size). Proof. Let B be a smallest ball containing both x and xR. Con­sider the temporal network (G,.)=HR,B,[t,t 
' ). With high prob­ability, this network contains a strictly time-respecting path P from xR to x. Let 
v1,... ,vk be the vertices of this path, ei =(vi,vi+1) its edges with labels ti =.(ei), and mi the message 
sent from vi to vi+1 at time ti. We prove by induction that for all i, Rvi (ti-1 +1)contains a 2 resource 
at distance at most (1+ .-1 )dfrom x. With i =k, this will clearly imply the theorem. The claim holds 
for i =1, since xR .Rv1 (t)and dx,xR =d. For the step from i to i+1, let xi be the node in mi = Rvi (ti) 
closest to vi, and consider two cases: 1. If xi .mi+1 =Rti+1), then the claim holds for i+1 vi+1 ( because 
it held for iby hypothesis. 2. If xi ./mi+1, then mi+1 must contain a node xi+1 such that d>.d(otherwise, 
vi+1 would have re­ vi+1,xi vi+1,xi+1 tained xi). By the triangle inequality, dvi+1,xi =d+dx,xi , and 
using the induction hypothesis to bound the distance be­tween xand xi, we get dvi+1,xi d+dx,xi dvi+1,xi+1 
== .. d+(1+ 2 )d .-1 2 = = d, ..-1 so dx,xi+1 =d+ 2 d=(1+ 2 )d. .-1 .-1  Non-Monotone Resource Location 
The situation becomes more complex if resources may disappear over time. In that case, information about 
the disappearance needs to propagate through the system as well, to ensure that nodes do not store outdated 
information. However, we do not want to send messages for every disappearing resource, since this would 
again increase the size of messages too much. Rather, we use a time-out scheme to ensure that nodes .nd 
out about the disappearance of resources implicitly. That is to say, when a node x has not heard about 
its closest resource xR for a suf.ciently long time, xconcludes that xR is no longer a resource­holder; 
xstops sending information about xR, and becomes recep­tive to learning about new resources even if they 
are further away than the one previously considered closest. To implement the tim­ing mechanism that 
we referred to above, we will assume that each node has access to the global time t. Of course, it is 
crucial to state what the time-out function h(·) should be. We still want nodes to .nd out about their 
(approx­imately) closest resources in time depending solely on their dis­tance from the resource. However, 
we now also want to require that nodes .nd out about the disappearance of their closest resource within 
similar time bounds, in particular in time depending only poly-logarithmically on their distance from 
the resource. That is, h(·)should be a function of the distance d, but not the size of the underlying 
node set. In view of this requirement, the existence of time-respecting paths might not be suf.cient 
to ensure that information about a resource actually reaches the desired destination. We have not imposed 
any bounds on the amount of time that may lie between the labels of two adjacent edges of the path (i.e. 
the time information spends at one node), and if this time is too long, the node may time out on the 
resource, i.e. decide that it does not hold a resource any more. We therefore want to require the existence 
of time-out free paths. For a time-respecting path P = v1,... ,vk, with edges ei = (vi,vi+1), the departure 
time from node i<k is d(vi)=.(ei). A time-respecting path P is called time-out free (with respect to 
a time-out function h(d))if d(vi)-d(v1) =h(dv1,vi )for all nodes vi on the path. We let THk,x,x ' denote 
the event that the temporal network Hk contains a time-out free x-x ' path. Now, the requirement on the 
underlying protocol can be stated as follows (where we write r = 1 , as before): 1- ld (.) There is a 
non-decreasing time-out function h(d)such that for any ball Bof diameter d, any two nodes x,x ' . B and 
time t, the temporal network HR,B,[t,t+.h(d)) contains a time-out free, strictly time-respecting path 
from xto x ' with probability at least 12 (ld(d+1))-r , i.e. Pr[THR,B,[t,t+.h(d)) ]= 12 (ld(d+1))-r . 
Below, we will show that the inverse polynomial gossip algo­rithms A. satisfy this property with time-out 
function h(d)= O(fA. (d)). First, however, we will see how we can exploit this property to build a protocol 
for the non-monotone resource loca­tion problem. Notice that if h ' (d) = h(d)for all d, then a path 
that is time­out free with respect to h(·) is also time-out free with respect to h ' (·). We can therefore 
always choose the time-out function larger, without decreasing the probability. We will use this fact 
to design a protocol with high-probability guarantees, even though the above guarantee is only low-probability 
in itself. The local state Sx(t) of a node x at time t is either the set {(xR,t)} consisting of a single 
time-stamped message contain­ing the name of some node xR and the time-stamp t, or the empty set Ø.If 
Sx(t)= {(xR,t)}, then xR is x s current estimate of the closest resource-holder; we will say that x believes 
in xR at time t. We say that a node x times out on xR at time t if x be­lieves in xR at time t, and xdoes 
not believe in xR at time t+1. Using the time-out function h(·), we de.ne the time-out function h ' (d)= 
h(d)· .· (12 ld(d+1))r ld ld(d+1)for the protocol, where .is again a measure of the desired probability 
guarantee. Each node executes the following protocol: If xholds a copy of the resource at time t, then 
its local state is set to Sx(t):={(x,t)}.  Otherwise, let Mt be the set of all messages received at 
time t - 1, plus the previous state Sx(t - 1).If Mt contains a message (x ' ,t) with t - t = h ' (dx,x 
' ), let x be such that x = x, and x minimizes dx,x ' among all such mes­sages. Then, let t be maximal 
such that ( t). M  x, t, and set Sx(t):={( t)}.If Mt contains no such message (x ' x, ,t), set Sx(t):=Ø. 
Send Sx(t)to a node y chosen according to A. We will show that on the line, this protocol ensures that 
nodes learn quickly about both appearance and disappearance of their closest resource, in the following 
sense. THEOREM 3.5. Let t be an arbitrary time, x and xR nodes at '''' ' distance d=dx,xR , t =t+h (d), 
and t =t+2h (d). (1) If xR did not hold a copy of the resource during any of the interval [t,t ' ], then 
xdoes not believe in xR at time t ' . (2) If xR has held the copy of the resource uniquely closest to 
x throughout the interval [t,t '' ], then xbelieves in xR at time t '' with probability at least 1-(ld(d+1))-. 
.  In terms of the analysis of systems, the negative (.rst) condition corresponds to safety, i.e. ensuring 
that wrong or outdated informa­tion will not be held for too long, while the positive (second) con­dition 
corresponds to liveness, i.e. ensuring that information will eventually reach any node. Notice that the 
safety guarantee is in fact deterministic, while the liveness guarantee is probabilistic. Proof. Property 
(1) follows directly. If xR was not a resource­holder during any of the interval [t,t ' ], then no messages 
(xR,t) for t . [t,t ' ]were generated, so no such message can have reached x. The remainder of the proof 
is concerned with Property (2). Let B be the smallest interval containing xand xR, and tj =t ' +j·h(d), 
where h(·)is the original time-out function, and j ranges from 0 r to .· (12 ld(d+1))ld ld(d+1). Now, 
.x one such j, and the associated interval I =[tj,tj+1)of length h(d). By assumption on A, there is a 
time-out free xR -x path P = v1,... ,vk (with v1 = xR and vk = x) in the temporal network -1 HR,B,I with 
probability at least 12 (ld(d+1)) 1- ld (.) . Let us sup­pose that such a time-out free path does exist. 
Let ei =(vi,vi+1), and mi the message sent along ei at time .(ei). We will show by induction that mi 
=(xR,t) for some t = .(e1)= tj, for all i. In the base case i =1, this is obvious, since xR was assumed 
to hold a resource at time d(v1) . I. For the inductive step from i to i+1, we know by induction hypothesis 
that mi = (xR,t), with t = .(e1)= d(v1). There could be two obstacles to vi+1 sending a message mi+1 
of the same form: (1) messages about other resources closer to vi+1 than xR, and (2) vi+1 timing out 
on xR at some time s . [d(vi),d(vi+1)]. For (1), notice that we assumed xR to be the unique closest re­source 
to x throughout I.As vi+1 lies on a shortest xR -x path (here, it is crucial that the points are on the 
line), xR is also closest to vi+1 throughout I. Hence, we can apply the safety property (1) proved above 
to obtain that at no time s . I, vi+1 believes in any x ' closer to vi+1 than xR. For (2), recall that 
P is a time-out free path, and therefore satis­.es s-t = s-d(xR)= h ' (d)for all s. [d(vi),d(vi+1)]. 
vi+1,xR In the protocol, message mi is therefore always available as a can­didate for the next state 
of vi+1, and since we argued above that no messages for x ' closer than xR are available, the next state 
is of the form (xR,t ') (where t ' = t). Hence, message mi+1 is actually of the form (xR,t ') with t 
' = t = d(xR). Applying this to vk = x, we obtain that at time tj+1, node x believes in xR. The time-out 
function h ' (·)is so large that for any s . [t ' ,t '' ], node x cannot time out on xR if it ever received 
a message from xR with a time-stamp t = t ' . That is, if there is a time-out free, strictly time-respecting 
xR -x path in the temporal network HR,B,[tj ,tj+1) for any j, then x believes in xR at time t '' . Because 
the intervals [tj,tj+1)are disjoint for different j, and all random choices made during the protocol 
are independent, the probability that none of the intervals contain a time-out free path is at most 1 
-r.( 12 ld (d+1))r ld ld(d+1) (1-( ld(d+1))) 2 = e -( 21 ld (d+1))-r.( 12 ld (d+1))r ld ld(d+1) =(ld(d+1))-. 
, completing the proof. In higher dimensions, we can obtain similar approximation bounds to the ones 
in the monotone case, by requiring that no resources within distance d+o(d)of xdisappear in the time 
interval under consideration, where d is again the distance of node x to its clos­est resource. The proof 
is a direct combination of the proofs of Theorems 3.5 and 3.2, and therefore omitted here. Time-out free 
paths for A. In the remainder of this section, we argue that the inverse poly­nomial gossip algorithms 
A. from the Section 2 actually satisfy the above property of producing time-out free paths, with time­out 
function h(d)= O(ld1+e(d+1)). Hence, the protocol for non-monotone resource location presented above 
will have time­out function and dissemination time bound O(ld2+e(d+1)). As in Section 2, we de.ne the 
constants s = 1 min{ß1, 1}·4-D 2 2D. and a =2r · If we restrict our attention to balls B of cs2 . diameter 
at most 64, and make the allowed time interval suf.­ciently large, we can ensure that there will be a 
time-respecting x-x ' path within B with probability at least 21 . If nothing else, x calls x ' with 
constant non-zero probability in every round, and the one edge induced by this call is a time-respecting 
and time­out free path. By making enough independent trials, the proba­bility that one will succeed (and 
x will call x ' ) will become at least 21 . Let . such that for any x and x ' at distance at most 64, 
x will call x ' within . rounds with probability at least 21 . Let g(k):=(4a +.)(ld(k +1))r ld ld(k +3), 
and de.ne C()2 ) 1 . h (d)=g (2ß2 )D ·(d +1)as our time-out function. No­ ß1 tice that h (d).O(ldr(d 
+1)ld ld(d +1)). LEMMA 3.6. Let x and x ' be at distance k, Bk a ball of di­ameter k containing x and 
x ' , and t ' = t + g(k). Then, with probability at least 1 min{1, (ld(k +1))-r}, the temporal net­ 2 
work Hk = HR,Bk,[t,t ' ) contains a time-out free x-x ' path (with respect to h (·)), i.e. Pr[THk,x,x 
' ] = 1 min{1, (ld(k +1))-r}. 2 Proof. The proof is by induction, and similar to the proof of Lemma 2.3. 
For the base case, we consider k = 64. We claim that the temporal network Hk contains a time-out free 
x-x ' path with prob­ability at least 1 min{1, (ld(k +1))-r}. In the case k =0, = 1 2 2 this follows 
because x and x ' must be identical, and the empty path is a time-out free x-x path that exists with 
probability 1.If k =1, then g(k)=., so there is an edge (x, x ' )with probability at least 1 . 2 For 
the case k> 64, we de.ne k ' =k./2 -1, similar to before notice that k -1 =k ' =641/2 -1=7. We divide 
the time ' ''' interval [t, t ] into three parts [t, s), [s, s ) and [s ,t ), by setting t +g(k '' ' 
s =), s =s +a ld ld(k +3), and write I =[s,s ).As before, B ' .Bk is a ball of radius k ' containing 
x ' . In the proof of Lemma 2.3, we argued that there was a node u close to x calling a node u ' close 
to x ' during the interval I.Now, we have to ensure in addition that the time-respecting path does not 
time out at u. As we do not know when the call from u to u ' happens, we might have to deal with paths 
that wait at node u for all of I.If u can be arbitrarily close to x, such a wait would certainly result 
in a time-out, so we want to make sure that u is suf.ciently far away from x. ( )1 We choose k '' = 2ßß12 
D ·k ' . as the lower bound on the dis­ tance from x to u. With S . Bk denoting a ball of radius k ' 
containing x, we set B =S \Bx,k '' . Then, we obtain that |B|=|S|-|Bx,k '' | ' D '' D = ß1(k )-ß2(k )1 
= ß1(k ' )D 2 D. = s ·(k +1) 2 , as was shown in the proof of Lemma 2.3. Finally, we de.ne, as be­ ' 
fore, E =E(B, B ' ,I), and H= HR,B,[t,s), H =HR,B ' ,[s ' ,t ' ). Because s -t = g(k ' ), we can apply 
the induction hypothesis to H, and .nd that 1 Pr[TH,x,u] = min{1, (ld(k ' +1))-r} 2 1 ' = (ld(k +1))-r 
2=(ldk)-r = (ld(k +1))-r , for any u .B. We want to concatenate P with a time-respecting path P ' from 
'' ' u . B ' to x . This path P need not be time-out free in itself, because all of its nodes will be 
suf.ciently far away from x, and hence not time out during the interval [s ' ,t ' ). That is, we can 
sim­ply invoke Theorem 2.1 for the existence of the path once we have ensured that the interval [s ' 
,t ' )is long enough. To bound from be­low the length of the time interval [s ' ,t ' ), we use the de.nitions 
of t ' , s ' , k ' and g, to obtain that ' ' ' t -s = t +g(k)-(t +g(k )+a ld ld(k +3)) 1 = g(k)- g(k)-a 
ld ld(k +3) 2= a ld ld(k +3)(2(ld(k +1))r -1) 3 r = a ·(ld(k +1))ld ld(k +3) 2 ' r ' = 3a(ld(k +1))ld 
ld(k +1). In the second and .fth step, we used ld ld(k ' +3) = ld ld(k+3) resp. ld ld(k ' +1) = ld ld(k 
+3), and (./2)r = 21 . In the third step, we simply dropped the . term, and in the fourth step, we 2 
used that (ld(k +1))r = ld(k +1) = 6. We just showed that t ' -s ' =3a(ld(k ' +1))r ld ld(k ' +1), so 
by Theorem 2.1, we obtain that with probability at least 1 -(ld(k ' +1))-3, there is a strictly time-respecting 
(but not necessarily time-out free) u ' -x ' '' ' path P in H for any u . By substituting y =3, and verifying 
that 1 -2 -1-ythe function 2 yy-3 is monotonically increasing for y = 3, -3 -2 we see that y = 21 y -1 
-y for all y = 3. Then, we can r substitute y =(ld(k ' +1))= ld(k ' +1) =3, and obtain that (ld(k ' +1))-3 
= 12 (ld(k ' +1))-r -(ld(k ' +1))-2r. Therefore, 1 '-r '-2r Pr[EH ' ,u ' ,x ' ] = 1- (ld(k +1))+(ld(k 
+1)) 21 -r -2r = 1- (ld(k +1))+(ld(k +1)). 2 Assume that there is an edge e =(u, u ' ) . E , a time-out 
free '' ' x-u path P in H, and a strictly time-respecting u -x path P in H ' . We want to verify that 
the concatenated path PeP ' is time-out free as well. For the subpath P, this follows from the induction 
hypothesis. Node u and all nodes on the path P ' are at distance at least k '' from x. For all these 
nodes v .P ' .{u}, the departure time is at most t ' , whereas the departure time from node x is at least 
t. Therefore, we obtain that d(v)-d(x) = t ' -t =g(k) 1 C ) ß1 D . = h·(k 2 -1) 2ß2 ( '') = hk =h (dv,x), 
so PeP ' is time-out free as well. ' ) . We thus know that for any edge e =(u,u E, the event F nTH,x,u 
nEH ' ,u ' ,x ' implies the existence of a time-out Hk,E,e free x-x ' path, i.e. the event THk,x,x ' 
. By the same argument as before, the three events F H,x,u and EH ' ,u ' ,x ' are inde­ Hk,E,e, T '' 
pendent for any .xed x, x and edge e =(u, u ). Using again that the events F are disjoint for distinct 
e, we obtain that Hk,E,e Pr[THk,x,x ' ] = Pr[TH,x,u nF nEH ' ,u ' ,x ' ] Hk,E,e e=(u,u ' ).E = Pr[TH,x,u]·Pr[EH 
' ,u ' ,x ' ]·Pr[F ] Hk,E,e e=(u,u ' ).E ( = (ld(k +1))-r ·Pr[F ]· Hk,E,e e=(u,u ' ).E ) (1- 1 (ld(k 
+1))-r +(ld(k +1))-2r) 2 =(ld(k +1))-r ·(1-Pr[F ])· Hk,E,. 1 -r -2r (1- (ld(k +1))+(ld(k +1))) 2 1 -r 
-2r = ( ld(k +1))+(ld(k +1))-Pr[FHk, ]. E,. 2 Because the length of the interval I is |I| = a ld ld(k 
+3) = 2D. cs2 ln ld((k+1)2r), we obtain from Lemma 2.2, applied to B, B ' , Bk, and I, that Pr[F ] = 
(ld(k +1))-2r, and therefore Hk,E,.Pr[THk,x,x ' ] = 12 (ld(k +1))-r, completing the proof. 4. REFERENCES 
[1] D. Agrawal, A. El Abbadi, R. Steinke, Epidemic algorithms in replicated databases, Proc. ACM Symp. 
on Principles of Database Systems 1997. [2] K. Birman, M. Hayden, O. Ozkasap, Z. Xiao, M. Budiu, Y. Minsky, 
Bimodal multicast, ACM Transactions on Computer Systems 17(1999). [3] A. Demers, D. Greene, C. Hauser, 
W. Irish, J. Larson, S. Shenker, H. Stuygis, D. Swinehart, D. Terry, Epidemic algorithms for replicated 
database maintenance, Proc. ACM Symp. on Principles of Distributed Computing, 1987. [4] D. Estrin, R. 
Govindan, J. Heidemann, S. Kumar, Next century challenges: Scalable coordination in sensor networks, 
Proc. 5th Intl. Conf. on Mobile Computing and Networking, 1999. [5] F. G¨obel, J. Orestes Cerdeira, H.J. 
Veldman, Label-connected graphs and the gossip problem, Discrete Mathematics 87(1991). [6] I. Gupta, 
R. van Renesse, K. Birman, Scalable Fault-tolerant Aggregation in Large Process Groups, Proc. Conf. on 
Dependable Systems and Networks, 2001. [7] S. Hedetniemi, S. Hedetniemi, A. Liestman, A survey of gossiping 
and broadcasting in communication networks, Networks 18(1988). [8] W. Heinzelman, J. Kulik, H. Balakrishnan, 
Adaptive protocols for information dissemination in wireless sensor networks, Proc. 5th Intl. Conf. on 
Mobile Computing and Networking, 1999. [9] J. Kahn, R. Katz, K. Pister, Next century challenges: Mobile 
networking for smart dust, Proc. 5th Intl. Conf. on Mobile Computing and Networking, 1999. [10] R. Karp, 
C. Schindelhauer, S. Shenker, B. V¨ocking, Randomized rumor spreading, Proc. IEEE Symp. Foundations of 
Computer Science, 2000. [11] D. Kempe, J. Kleinberg, A. Kumar, Connectivity and Inference Problems for 
Temporal Networks, Proc. 32nd ACM Symp. Theory of Computing, 2000. [12] J. Li, J. Jannotti, D. De Couto, 
D. Karger, R. Morris, A scalable location service for geographic ad hoc routing, Proc. 5th Intl. Conf. 
on Mobile Computing and Networking, 1999. [13] M. Lin, K. Marzullo, S. Masini, Gossip versus deterministic 
.ooding: Low message overhead and high reliability for broadcasting on small networks, UCSD Technical 
Report TR CS99-0637. [14] B. Pittel, On spreading a rumor, SIAM J. Applied Math. 47(1987). [15] R. van 
Renesse, Scalable and secure resource location, Proc. Hawaii Intl. Conf. on System Sciences, 2000. [16] 
R. van Renesse, Y. Minsky, M. Hayden, A gossip-style failure-detection service, Proc. IFIP Intl. Conference 
on Distributed Systems Platforms and Open Distributed Processing, 1998.  
			