
 Balls and Bins with Structure: Balanced Allocations on Hypergraphs P. Brighten Godfrey* Abstract In 
the standard balls-and-bins model of balanced allocations, m balls are placed sequentially into n bins. 
Each ball chooses d uniform-random bins and is placed in the least loaded bin. It is well known that 
when d = logT(1) n, after placing m = n balls, the maximum load (number of balls in a bin) is T(1) w.h.p. 
In this paper we show that as long as d = O(log n), independent random choices are not necessary to achieve 
a constant load balance: these choices may be structured in a very general way. Speci.cally, we allow 
each ball i to have an associated random set of bins Bi. We require that |Bi| = O(log n) and that bins 
are included in Bi with approximately the same probability; but the distributions of the Bis are otherwise 
arbitrary, so that there may be correlations in the choice of bins. We show that this model captures 
structure important to two applications, nearby server selection and load balance in distributed hash 
tables. 1 Introduction In the standard balls-and-bins model of randomized load balancing, m balls are 
placed sequentially into n bins. Each ball probes the current load of d uniform­random bins and is placed 
in the least loaded bin. The maximum load is the maximum number of balls in any bin at the end of the 
process. It is well known that when d = 1, this procedure results in a maximum log n load of Twith high 
probability, and Azar log log n et al [1] showed that if d> 1, the maximum load is log log n + O(1) w.h.p. 
(see also [8]). In particular, when log d d = logT(1) n, the maximum load is O(1) w.h.p. Many subsequent 
works have studied placement al­gorithms which do not probe independent and uniform­random bins. For 
example, V¨ocking [12] improved the maximum load to log log n + O(1) where 1 = fd = 2 by d ln fd using 
a placement algorithm in which the bins are split into d groups, each ball probes a random bin from each 
group, and ties are broken asymmetrically. This yields constant maximum load with d = T(log log n). Byers 
*CS Division, UC Berkeley. Supported in part by a Na­tional Science Foundation Graduate Research Fellowship. 
Email: pbg@cs.berkeley.edu. et al [2] showed that if the probed bins are picked inde­pendently as in 
the original model but with somewhat nonuniform probabilities, the maximum load can still be bounded 
by log log n + O(1). Wieder [13] characterized log d the nonuniform case when m » n. None of these placement 
algorithms addresses the fact that for some applications, probing certain sets of d bins is more costly 
than other sets. Consider, for example, a client arriving in a random location that wishes to connect 
to a lightly-loaded server. Probing the d closest servers (i.e., bins) is likely to be much more desirable 
than probing d random servers, both because the probes themselves will be cheaper, and because the client 
will ultimately receive service from a much closer server. To give applications such .exibility, Kenthapadi 
and Panigrahy [5] studied more general bin­selection processes for the case d = 2 by allowing each ball 
to choose a random pair of bins from only a subset of the possible pairs. This can be represented by 
a graph G whose nodes are bins, and whose edges are the allowable pairs. The standard result stated within 
this model is that the maximum load is log log n + O(1) log 2 when G is the complete graph. But [5] showed 
that G need not be complete: if G is almost regular with degree ne, the maximum load is log log n+O(1/e), 
which for e = T(1/ log log n) is within a constant factor of the maximum load in the standard model. 
Following the client-server example, this would allow a client T(1/ log log n) to consider pairs of servers 
among the nclosest servers while still obtaining a maximum load of O(log log n). Model and Main Results. 
The present paper studies structured choices for other values of d while allowing even more .exible choice 
of bins. Our model, which we will relate to that of [5] below, is simply to allow each ball i to probe 
an associated random set of bins Bi, whose distribution and size (i.e., d) may di.er for each ball. Note 
that this permits arbitrary correlations between the probed bins in each Bi. What restrictions on the 
distributions of the Bis are su.cient to guarantee a good maximum load? Somewhat surprisingly, when |Bi| 
= O(log n), we need only require that each Bi satis.es a balance prop­erty. In the simple case that d 
is the same for all balls, Bi is balanced when for each bin j, Pr[j . Bi] is within a constant factor 
of the fair probability, d . Our main  n theorem is that, under these conditions and for a con­stant 
a to be speci.ed, placing m = an balls in n bins results in a maximum load of 1 with high probability, 
and placing m = n balls results in a maximum load of i1/al. Although the conditions are quite intuitive, 
the di.culty in the proof is to deal with the dependencies between each ball s choices. We handle this 
by showing that the distribution of balls in bins is approximately dominated by a process of placing 
slightly more than m balls into uniform-random least-loaded bins. We also note a lower bound, that for 
any 1 = d = log n T , there exist balanced Bis for which the log log n 1 ln n maximum load is ·· (1 
+ o(1)) w.h.p. Thus, d ln ln n the power of two choices result, that the maximum load decreases to T(log 
log n) when d = 2, does not hold in our model. Intuitively, this is because correlations in the bin choices 
can be such that a ball which picks a hotspot bin shares the same d alternative choices as ln n all the 
other balls that picked the same hotspot. ln ln n Our main theorem shows that d = O(log n) alternatives 
are su.cient to spread the load of hotspots, regardless of the pattern of bin choices. Relation to Balanced 
Allocations on Graphs. The present paper s setting can be related to the model of [5] by generalizing 
balanced allocations on a graph to balanced allocations on a hypergraph G. Each hyperedge of G represents 
an allowable set of d bins, and as before each ball probes the bins in a uniform-random hyperedge. A 
special case of our theorem is that when d = T(log n), the maximum load is T(1) as long as G is almost 
regular (that is, the minimum and maximum node degrees di.er by at most a constant factor). This permits 
as few as one hyperedge incident to each node in the hypergraph, which translates to a minimum of T(log 
n) neighbors per node. Comparing this with the nT(1/ log log n) minimal degree for the case d = 2 shows 
that increasing the number of probes to d = T(log n) substantially decreases the connectivity necessary 
to obtain a maximum load within a constant factor of that in the standard balls-and-bins model. Continuing 
the earlier client-server example, which will be treated more formally later, a client arriving in a 
random location can restrict its attention to the T(log n) closest servers rather than the nT(1/ log 
log n) required when d = 2. Applications. Finally, we describe two applications of our main result. The 
.rst, nearby server selection, .eshes out the client-server example above. The second application involves 
load-balanced .le placement in dis­tributed hash tables (DHTs). We describe how a scheme of Byers et 
al [2] can, in an amenable DHT structure, be modi.ed to obtain a better balance while sending the same 
total number of messages. By structuring choices in .le placement to match the DHT s topology, each choice 
is less costly than a random choice. These ex­amples suggest that our model of correlated bin choice 
captures structure important to applications. Our main theorem and the lower bound are proved in Sections 
2 and 3, respectively. We discuss the two applications in Section 4, and conclude in Section 5. 2 Main 
Theorem We are given n bins into which will be placed m = an balls. For each ball i we are given a distribution 
Bi over sets of bins. Each ball is placed according to the following algorithm which we will call Algorithm 
Ai: 1. Let Bi be a random set of bins distributed as Bi (chosen independently of other selections). 
2. Place ball i in a uniform-random bin from among those bins in Bi with the fewest number of balls. 
 Definition 2.1. A random set of bins B is ß-balanced if, for all bins j, 11 ß = Pr[j . B] · E| j . 
B= . ßn |B| n Theorem 2.1. Let e> 0, d . (0, 1), and suppose that for each ball i, Bi is ß-balanced and 
|Bi|= 26 · (1+e)2 e2d · log n. Let ß' = (1+ e + o(1)) · ß and a = ln ß' (1-d)/1 - . Then with probability 
ln(1-(ß'-1)/(ß'2-1))= 1 - O(n-1), the maximum load is 1 after placing m = an balls, and the maximum load 
is i1/al after placing m = n balls. 2.1 Proof of Theorem. For convenience, unless otherwise stated, the 
proof and associated lemmas assume that m = an (the case m = n is an easy .nal step).We analyze Algorithm 
A by showing that it is dominated by Algorithm B: for each ball A places with structured choices, B will 
place a ball into each of k uniform-random empty bins, where the constant k will be selected later (in 
the proof of Lemma 2.2) such that mk = n. We .rst state several de.nitions and lemmas, which will be 
proved in later subsections, and then prove the theorem. The bulk of the technical material actually 
appears in the proof of Lemma 2.2. Definition 2.2. A coupling of two random allocations of balls in bins, 
D and D', is a pair of functions f, f' : [0, 1] .{0,...,m}n such that, if R is a random variable uniform 
on [0, 1], then f(R) and f '(R) are distributed as D and D ', respectively.  Definition 2.3. Given two 
random allocations D, D ' of balls in bins, D is e-dominated by D ', written D je D ', when there is 
a coupling (f, f ') of D and D ' such that Pr[f(R)j = f '(R)j .j] = 1 - e, where f(·)j denotes the number 
of balls in bin j in the allocation f(·). Let X.D denote the random allocation that results from application 
of an algorithm X to the random allocation D of balls in bins. De.ne P 1(i) and P 2(i) as the random 
allocations that result from applying algorithms A and B, respectively, i times, beginning with the allocation 
Z of zero balls in the bins. That is, Z if i =0 P 1(i)=Ai . P 1(i - 1) if i> 0 Z if i =0 P 2(i)=B . 
P 2(i - 1) if i> 0. Lemma 2.1. If D je E then Ai . D je Ai . E .i. Lemma 2.2. Ai+1 . P 2(i) jO(n-2) B 
. P 2(i) for all i .{0,...,m-1}, as long as Bi+1 is ß-balanced, |Bi+1|satis.es the bound given in Theorem 
2.1, and m = an. Proof of Theorem 2.1: We will show that P 1(i) jei ws i P 2(i) for all i, where ei = 
O . This implies the 2 n theorem as follows: since mk < n, P 2(m) has maximum load 1; since P 2(m) em-dominates 
P 1(m), P 1(m) must have the same maximum load with probability = 1 - em =1 - O(m/n2)=1 - O(n-1). We 
show P 1(i) j P 2(i) by induction on i. For the base case where i = 0, note that P 1(0) = P 2(0) trivially, 
since no balls have been placed. For the inductive step, assume that P 1(i) jei P 2(i). Then we have 
P 1(i +1) = Ai+1 . P 1(i) (by de.nition) jei Ai+1 . P 2(i) (induction and Lemma 2.1) jO(n-2) B . P 2(i) 
(Lemma 2.2) = P 2(i + 1) (by de.nition). Letting ei+1 = ei + O(n-2), we can conclude that P 1(i + 1) 
jei+1 P 2(i + 1). For the case m = n, let Dt be the allocation where each bin has exactly t balls. By 
the above result, placing an balls results in an allocation O(n-2)-dominated by D1. It is easy to see 
that beginning with D1 and placing an additional balls results in an allocation O(n-2)­dominated by D2; 
iterating this argument yields the desired result for m = n. 2.2 Proof of Lemma 2.1. Algorithm Ai is 
equiva­lent to (1) picking a random set of bins Bi, (2) picking a uniform-random permutation (b1,...,be) 
of the bins Bi, and (3) deterministically placing the ball in the .rst least-loaded bin, i.e., the .rst 
bin in the permutation among those with the minimum number of balls. Now let (f, f ') be a coupling which 
witnesses D je E. To show that Ai . D je Ai . E, we construct a coupling (g, g ') of Ai . D and Ai . 
E by coupling the randomness in D and E in the same way as (f, f '), and additionally coupling Ai s choice 
of Bi and (b1,...,be). We now show that this coupling witnesses Ai .D je AI . E. Consider any outcome 
in which Dj = Ej for all bins j. Let j* be the bin in which the ball is placed in Ai . D, that is, the 
.rst least-loaded bin in (b1,...,be). Since Dj = Ej.j, the .rst least-loaded bin for Ai .E must either 
occur at j* or at some later bin in the permutation so in Ai . E the ball is either placed in the same 
bin j* or else j* already had more balls than in Ai . D. In either case, (Ai . D)j* = (Ai . E)j* which 
further implies (Ai . D)j = (Ai . E)j.j. Finally, the assumption that Dj = Ej.j is true for a set of 
outcomes of measure = 1 - e, from which we can conclude Ai . D je Ai . E. 2.3 Proof of Lemma 2.2. For 
notational conve­nience, we use A := Ai+1 throughout this section. We prove Lemma 2.2 using several supporting 
lem­mas. First, we provide an analog of Hall s Theorem for fractional matchings with vertex weights (Lemma 
2.3), which we use to show that A . D j B . D for any .xed allocation D that obeys a smoothness property 
(Lemma 2.4). Next, we show that the fraction of bins which are empty in the set Bi chosen by algorithm 
A concentrates (Lemma 2.5), which implies that P 2(i) is smooth with high probability (Lemma 2.6). Finally, 
Lemmas 2.4 and 2.6 together imply Lemma 2.2, which we prove at the end of this subsection. Definition 
2.4. Given an undirected bipartite graph G =(V1,V2,E) and weights w(v) = 0 for each vertex v,a perfect 
weighted matching on G is a nonnegative function f : E . R for which (2.1) .v . V1,V2 f(v)= w(v), where 
f(v) :=f(e). e~v Lemma 2.3. Given a bipartite graph G =(V1,V2,E) with vertex weights w for which w(V1)= 
w(V2),a perfect weighted matching exists if and only if w(S) = w(N (S)) for all S . V1 (equivalently, 
for all S . V2), where w(S) :=v.S w(v) and N (v) is the neighborhood of v.  Proof: Follows a standard 
max .ow-min cut argument; see Appendix A. Definition 2.5. A .xed allocation D of balls to bins is ß-smooth 
when, for each bin j, 1 · 1(Dj =0) = pj = ß · 1(Dj=0) + O(n -3) · 1(Dj >0), ßfn fn where pj is the probability 
that Algorithm A places a ball in bin j given the allocation D, f is the fraction of bins that are empty 
in D, and Dj denotes the number of balls in bin j. The smoothness property says essentially that A picks 
one of the fn empty bins with probability that 1 is within a factor ß of the fair chance , i.e., , and 
fn has only a very small chance of picking an occupied bin. Thus, smoothness depends on both the allocation 
D and the placement algorithm A. Lemma 2.4. Let D be a ß-smooth allocation of ki balls. Then A . D jO(n2) 
B . D as long as k = 1 - ln ß . ln(1-(ß-1)/(ß2-1)) Proof: To demonstrate A . D je B . D, it is su.cient 
to show that there is a measure-preserving mapping f between outcomes in A . D and outcomes in B . D 
such that .j = f(.)j for all outcomes ., except on a set of measure = e (where .j represents the number 
of balls in bin j in outcome .). To show that such a mapping exists, we will construct a suitable bipartite 
graph G =(V1,V2,E) and weights w(·), and .nd a perfect weighted matching within it, as follows. We have 
a node in V1 for each subset of k bins drawn from the empty bins in D. The weight w(v) of a node v . 
V1 is the probability that the set v of bins is selected to receive balls in B . D. Each node in j . 
V2 corresponds to a single empty bin in D, and its weight w(j) is set to pj , the probability that bin 
j receives the ball in A . D. We add an additional node j* to V2 with weight w(j*) = Pr[A puts a ball 
in an occupied bin]. The graph contains an edge v . j whenever j . v, and an edge v . j* for all v. Note 
that if (v, j) . E and j j*, then outcome = v has a ball in every bin in which j has a ball. As a consequence, 
the existence of a perfect weighted matching on G with weights w implies that A.D jw(j*) B . D. Moreover 
by a union bound over the n bins and the fact that D is smooth, w(j*)= O(n·n-3)= O(n-2), as desired. 
It remains to show that a perfect weighted match­ing exists, which we accomplish by checking the suf­.cient 
condition, w(S) = w(N (S)) .S . V2, given in Lemma 2.3. Consider any subset S . V2 of the nodes. If j* 
. S, then the condition is trivially satis.ed since N (S)= V1 and w(V1)= w(V2) by construction. Thus, 
we may assume j* . S. For convenience de.ne n-ki f = to be the fraction of bins that are empty. To n 
upper bound w(S), we have ß ·|S| (2.2) w(S) = fn fn -|S| (2.3) w(S)=1 - w(V2 \ S) = 1 - , ßfn both of 
which follow from the ß-smoothness of D. Also, w(N (S)) = = Pr[one of k random bins hits S] 1 - fn - 
|S|fn fn - |S| - 1 fn · · ·  fn -|S|- (k - 1) ···. fn Note that w(N (S)) is concave in |S| and reaches 
1 for su.ciently large |S|, and both Eqns. 2.2 and 2.3 are linear in |S|. Letting s * be the value of 
|S|for which the fn upper bounds (2.2) and (2.3) are equal, it thus su.ces to show that w(S) = w(N (S)) 
when |S|/n = s *. In this case we have fn -|S| k *)k w(N (S)) = 1 -=1 - (1 - s fn * fn -|S| 1 - s w(S) 
= 1 - =1 - . ßfn ß 1-s Solving 1 - * = 1 - (1 - s *)k , we obtain k = ß ln ß * ß-1 1 - . Substituting 
s = yields the lemma. ln(1-s *) ß2-1 The above lemma showed essentially that smooth­ness is su.cient 
for Lemma 2.2. It remains to show that P 2(i) is smooth. Smoothness requires that the chance that A places 
a ball in a particular bin is nearly equal for all empty bins, but this probability is inversely pro­portional 
to the number of empty bins in Bi+1. Our strategy is therefore to show that with high probability, the 
number of empty bins in Bi+1 is close to its mean; that is, the probed set is good . We proceed by de.ning 
goodness , showing that any .xed set of bins is very likely good (Lemma 2.5), and then extending this 
to show that P 2(i) is smooth (Lemma 2.6). At the end of this section we bring together the building 
blocks into a proof of Lemma 2.2. Definition 2.6. A set of bins B is e-good if the number of empty bins 
in B is contained in tb 1 n-ki · f|B|, (1 + e) · f|B| , where f = is the (ran­ 1+en dom) fraction of 
bins that are empty in P 2(i).  Lemma 2.5. For any .xed set of bins B for which (4e+2)(1+e)2 |B|= · 
ln n and any £,e > 0, fe2 PrP 2(i)[B is e-good] = 1 - O(n-e). Proof: We use a Poissonization technique 
to convert from P 2 to a distribution wherein the bins are indepen­dent (see [9]). De.ne a new distribution 
P 3(i) which places a ball in each bin independently with probability ik/n, and let F be the (random) 
fraction of bins that are empty in P 3(i). Note that P 3(i) may have more or fewer balls than P 2(i), 
but conditioned on F = f, P 3(i) is identical to P 2(i). Moreover, E[F ]= f and Fn 1 is approximately 
Poisson, so PrP 3(i)[F = f]=O v . n e Using these facts, and de.ning for convenience d = 1+e and G = 
{B is e-good}, Pr [¬G] = Pr[¬G | F = f] P 2(i) P 3(i) PrP 3(i)[¬G] = PrP 3(i)[F = f] tt bb 1 PrP 3(i) 
F . f|B|, (1 + e)f|B| 1+e =v O(1/n) wv s = On · Pr [F . (1 ± d)f|B|] P 3(i) wv s -f|B|d2/4 + e -f|B|d2/2 
= On · e, by applying a pair of Cherno. bounds [10]. This bound is = O(n-e) as long as |B|= (4e+2)(1+e)2 
· ln n. fe2 Lemma 2.6. Pr[P 2(i) is (1 + e + o(1))ß-smooth] = 1- O(n-2) for any e> 0 as long as |Bi+1|= 
26(1+e)2 · ln n fe2 and A is ß-balanced. Proof: Recall from De.nition 2.5 that to show smooth­ness of 
P 2(i), we must bound the probability pj that A puts a ball in bin j. Here pj is itself a random variable, 
dependent on P 2(i). For convenience let B := Bi+1 be the random set of bins selected by A for ball i+1, 
let G be the event that B is e-good, and let Pj be the event that j receives the ball. For the upper 
bound, we have pj = Pr[j . B] · Pr[Pj|j . B] = Pr[j . B] · (Pr[Pj . G|j . B]+ Pr[Pj .¬G|j . B]) n n = 
Pr[j . B] · Pr[¬G|j . B] + Pr[j . B] s=1 Pr[Pj . G|j . B .|B| = s] · Pr[|B| = s|j . B] n n = Pr[¬G|j 
. B] + Pr[j . B] · 1(j empty) s=1 1+ e · Pr[|B| = s|j . B] (by def. of e-good) fs 1+ e = Pr[¬G|j . B]+ 
· 1(j empty) · f 1 Pr[j . B] · E |j . B |B|(1 + e)ß = Pr[¬G|j . B]+ · 1(j empty), fn where the last step 
follows since A is ß-balanced. By Lemma 2.5 and the fact that A picks B independently of P 2(i), for 
any bin j, PrA.P 2(i)[¬G|j . B]= O(n-6) as long as |B|= 26(1+e)2 · ln n. Thus, fe2 tb Pr Pr[¬G|j . B] 
= O(n -3) = 1 - O(n -3). P 2(i) A Combining the previous two inequalities, we obtain an upper bound on 
pj: (1 + e)(1 + o(1))ß Pr pj =· 1(j empty)+ P 2(i) fn b O(n -3) · 1= 1 - O(n -3). (j occupied) Using 
a similar technique we can obtain the lower bound, 1(j empty) Pr pj == 1 - O(n -3). P 2(i) (1 + e)(1 
+ o(1))ßfn Combining the upper and lower bounds and taking a union bound over all n bins j, we have that 
P 2(i) is (1 + e + o(1))ß-smooth with probability = 1 - O(n-2). Proof of Lemma 2.2: Let ß ' := (1+ e 
+ o(1)) · ß. Construct the coupling of A . P 2(i) and B . P 2(i) as follows. For each outcome (allocation) 
for which P 2(i) is ß '-smooth, use the coupling given by Lemma 2.4. Conditioned on such an outcome D, 
we have A . D jO(n-2) B . D. By Lemma 2.6, this covers all but a set of measure O(n-2), on which set 
algorithms A and B may be coupled arbitrarily, yielding A . P 2(i) jO(n-2) B . P 2(i). To -2)+O(n satisfy 
the constraints of these two lemmas, we require ln ß ' and |B|= 26(1+e)2 k = 1 -· ln n. ln(1-(ß '-1)/(ß 
'2-1)) fe2 The fraction f of empty bins in P 2 must in turn be = d for some d> 0, which is satis.ed as 
long as a = 1-d , as k given in the statement of the lemma. 3 Lower Bound ln n Theorem 3.1. For any 
d .1, , there exists a ln ln n1-balanced distribution of sets of bins (Bi) for which |Bi| = d and which 
results in a maximum load of ln n = 1 ·· (1 + o(1)) w.h.p. when n balls are allocated d ln ln n to the 
n bins.  Proof: We will in fact give a class of bin choices which result in the desired maximum load. 
Given an arbitrary .xed pattern of d bin indexes B =(b1,...,bd), we have ball i pick a single random 
value R .{1,n}, and set Bi = {b1 + R, . . . , bd + R}, with arithmetic mod n. It is easy to see that 
this distribution is 1-balanced. Now by reduction to a standard balls-and-bins process * with d = 1 choices, 
some value r of R will be picked ln n by · (1 + o(1)) balls w.h.p. [3]. Each of those ln ln n balls is 
therefore choosing from the same set of bins {b1+r *,...,bd+r *}, so at least one of those bins receives 
= 1 ln n ·· (1 + o(1)) balls. d ln ln n 4 Applications 4.1 Nearby Server Selection. We give an example 
application of our result to a nearby server selection problem. We have n servers (e.g., wireless base 
stations) placed randomly in the unit square in the plane, and m clients (e.g., wireless-enabled laptops) 
arrive iteratively at random locations, probe the load of a set of servers within some distance r, and 
connect to a random one of the least loaded among these. We desire to minimize the maximum load on a 
server, while keeping r small. This problem was suggested to us by [7], as a variant of a client-server 
matching problem in [4] in which clients may be moved to di.erent servers after they have connected, 
and the number of moves is minimized. Here we show that in this randomized version of the problem, T(n) 
clients can be matched to n servers with no moves. r log n Corollary 4.1. If r =T , then with proba­ 
n bility 1 - O(n-1), each client is matched with a unique server as long as m = an for some constant 
a; and each server has =i1/al clients if m = n. Proof: Divide the unit square into subsquares of size 
r log n b on each side. By a Cherno. bound, there exists n a su.ciently large b such that all subsquares 
contain r log n T(log n) servers w.h.p. By selecting r = c for n su.ciently large c, any possible disc 
of radius r centered in the unit square will include T(c2) subsquares and hence T(c2 log n) servers in 
its set of options Bi. Thus, for su.ciently large c, each Bi is large enough to satisfy the lower bound 
required by Theorem 2.1. Moreover, for any server j, accounting for edge e.ects, 1 c2 log nc2 log n ·= 
Pr[j . Bi] = , 4 nn and by the above argument, w.h.p. over the choice of tb 11 server locations, E |Bi| 
|j . Bi =T c2 log n . From this it follows that Bi is T(1)-balanced w.h.p. Thus, we can apply Theorem 
2.1 and the result follows. 4.2 Load Balance in Distributed Hash Tables. In this section we describe 
an application of our main re­sult to load balance in distributed hash tables (DHTs). Compared with a 
similar scheme of Byers et al [2], we will obtain a better balance by using more choices for each .le 
s location, while using the same number of mes­sages (within constant factors) because those choices 
align with the DHT s structure. We note in advance, however, that unlike [2], our scheme requires a deter­ministic 
overlay topology. In particular we will describe our scheme in the context of the Chord DHT [11]. In 
Chord, each node v is assigned a pseudorandom identi.er id(v) in the DHT s keyspace [0, 1]. Ownership 
of the keyspace is partitioned among the nodes such that a key k is owned by its successor that is, the 
node whose ID most closely follows k, where the keyspace is treated modularly. Each node maintains links 
to certain other nodes as a function of the IDs of the nodes. Speci.cally, each node v has links, called 
the successor list, to the T(log n) successors of id(v), where n is the number of nodes in the system. 
Node v also has links called .ngers to the owners of id(v)+ b-i for each i> 1, which results in T(logb 
n) additional links. (In the original Chord design, b = 2.) Finally, each .le o is stored in the DHT 
at the node that owns the key h(o) . [0, 1], where h is a well-known hash function. We will assume that 
n objects are placed. One challenge is to achieve a good load balance. Due to the random identi.er selection, 
some nodes own T( log n ) of the keyspace and hence can expect to receive n T(log n) objects. Even if 
all nodes had equal shares of the keyspace, the standard balls-and-bins result would log n imply a maximum 
load of T( ). log log n Byers et al [2] showed that if we have d well-known hash functions h1,...,hd 
and each ball is placed at the least-loaded among the owners of h1(o),...,hd(o), then the maximum load 
is log log n + O(1) w.h.p. even log d though some nodes (bins) are a factor T(log n) more likely to be 
considered than others. Increasing d obtains a better load balance, but at the cost of requiring more 
messages to insert and retrieve objects. Speci.cally, since mean route lengths in Chord are T(log n) 
[11], T(d log n) messages will be sent on average. Our scheme will have a single hash function h, and 
each object o will be placed in a random least-loaded node among a set of nodes B(o) chosen as the owners 
of h(o)+ b-i , for each i> 1. This maintains the essential property that each .le is located at one of 
a small number of well-known locations, but mirrors the topology of the DHT. We next analyze the messaging 
cost and maximum load of this scheme. In the interest of conciseness, we only sketch the analysis. The 
scheme can be implemented by routing an insert request to the owner x of h(o) at an expected cost of 
T(log n) messages. The node x then forwards the  log n request to the nodes B(o). Since |h(o) - x| = 
O n w.h.p., node x has a direct connection (via a .nger link) log n to a node within keyspace distance 
O of each n probe target. By using the DHT s successor list, those neighbors can reach the probe targets 
in O(1) additional hops each. Thus, O(log n) messages are sent in total. In bounding the maximum load, 
we apply Theo­rem 2.1. To deal with the imbalance in the size of the keyspace that nodes own, we will 
simply have each ob­ 1 ject ignore any node in B whose ownership is < or cn c > for some constant c. 
Note that this new strat­ n egy can only increase the maximum load. It can be shown that this will eliminate 
a constant fraction of the object s choices, leaving T(log n) choices w.h.p.; more­over, the constant 
can be made arbitrarily high by ad­justing b so that Theorem 2.1 s constraint on |B| is satis.ed. It 
is also straightforward to show that for c any node v owning a fraction . [ 1 , ] of the keyspace, cn 
n log n Pr[v . B] = T . Thus, we can apply Theorem 2.1 n to conclude that the maximum load is O(1) w.h.p. 
5 Conclusion This paper leaves several open problems. A factor log log n gap remains between our lower 
and upper bounds. Also, we conjecture that for any e> 0, it is possible to place (1 - e)n balls while 
maintaining a maximum load of 1 w.h.p., as long as d = T(log n) is su.ciently large and the probed bins 
Bi are su.ciently close to being 1-balanced. Our model requires that each ball be placed in a uniform-random 
least-loaded bin among those probed. Suppose instead that each ball arrives with an ordered list of the 
bins, and is placed in the .rst empty bin on the list (assuming there are m = n balls). What properties 
of the orderings ensure that only the .rst few bins on each list need to be probed? Note that linear 
probing in hash tables [6] is a special case of this model in which the ordered lists are given by {R, 
R +1,...,R + n - 1} (mod n) where R is uniform­random in {1,...,n}. We thank the anonymous reviewers 
for useful com­ments and corrections. References [1] Y. Azar, A. Z. Broder, A. R. Karlin, and E. Upfal. 
Balanced allocations. In Proc. STOC, 1994. [2] John Byers, Je.rey Considine, and Michael Mitzen­macher. 
Geometric generalizations of the power of two choices. In Proc. SPAA, 2004. [3] Gaston Gonnet. Expected 
length of the longest probe sequence in hash code searching. In Journal of the ACM, volume 28, April 
1981. [4] Edward F. Grove, Ming-Yang Kao, P. Krishnan, and Je.rey Scott Vitter. Online perfect matching 
and mo­bile computing. In Proceedings of the Fourth Workshop on Algorithms and Data Structures (WADS), 
1995. [5] Krishnaram Kenthapadi and Rina Panigrahy. Bal­anced allocation on graphs. In Proc. SODA, 2006. 
[6] Donald E. Knuth. Art of Computer Programming, Vol­ume 3: Sorting and Searching (2nd Edition). Addison-Wesley 
Professional, April 1998. [7] Henry Lin, Constantinos Daskalakis, Robert Kleinberg, and Kamalika Chaudhuri. 
Personal communication, 2007. [8] Michael Mitzenmacher. The Power of Two Choices in Randomized Load Balancing. 
PhD thesis, University of California -Berkeley, 1996. [9] Michael Mitzenmacher and Eli Upfal. Probability 
and Computing. Cambridge University Press, 2005. [10] Rajeev Motwani and Prabhakar Raghavan. Random­ized 
Algorithms. Cambridge University Press, 1995. [11] Ion Stoica, Robert Morris, David Karger, M. Frans 
Kaashoek, and Hari Balakrishnan. Chord: A scalable peer-to-peer lookup service for internet applications. 
In Proc. SIGCOMM, 2001. [12] Berthold V¨ocking. How asymmetry helps load balanc­ing. In IEEE Symposium 
on Foundations of Computer Science, pages 131 141, 1999. [13] Udi Wieder. Balanced allocations with heterogenous 
bins. In Proc. SPAA, 2007. A Proof of Lemma 2.3 The necessity of the condition is clear. We next show 
that a perfect weighted matching exists assuming the condition holds. Construct a graph H which includes 
the nodes and edges of G =(V1,V2,E), additional source and sink nodes s and t, an edge s . v with capacity 
w(v) for each v . V1, and an edge v . t with capacity w(v) for each v . V2. Finally, we give each edge 
in E capacity 8. It is easy to see that there is a perfect matching in G if and only if the maximum .ow 
fmax from s to t in H is w(V1). Thus for the remainder of the proof it is su.cient to show that if fmax 
<w(V1) then there exists an S . V1 for which w(N (S)) <w(S). Suppose fmax <w(V1), andlet (C1,C2) be a 
minimum cut of H with s . C1 and t . C2. We take S := C1 n V1. Since the edges of E have capacity 8, 
C1 must include N (S). Therefore the cut edges must be those from s to V1 \ S, and those from N (S) to 
t. The total capacity of these edges is w(V1)-w(S)+w(N (S)). Thus we have w(V1) - w(S)+ w(N (S)) = fmax 
< w(V1), so w(N (S)) <w(S) as desired.  
			