
 XDP: A SIMPLE LIBRARY FOR TEACHING A DISTRIBUTED PROGRAMMING MODULE David M. Arnow Dept. of Computer 
and Information Science Brooklyn College of CUNY Brooklyn, NY 11210 arnow @sci. brooklyn. cuny. edu ABSTRACT: 
XDP is a simplified interj$ace to the DP spending time on details of minor or ephemeral signifi­distributed 
programming library. I describe its use in a cance. course on workstation programming, a pragmatic course 
In this paper, I report on the classroom use of a very whose mission is to cover concurrent programming, 
simple library that supports dk-ibuted programming. Sec­ graphical user interfaces and event-driven programming 
tion 2 describes the course and explains the need for the as well as network and distributed computing. 
Using library, XDP. Section 3 describes the library itself. Section XDP, rather than the native socket 
inte~ace, makes it 4 presents a useful initial classroom example and describes feasible to cover the 
last topics, squeezed though they are some suitable exercises that use the library. In the last sec­ 
into a rather overloaded course. Finding (or building) tion I draw a few conclusions from this experience. 
 teaching tools like XDP will become increasingly essen­tial as more demands are placed on undergraduate 
CS 2. The couree: workstation programming curriculum coverage. The module appears in a course called 
Workstation 1. So many important topics, so few credits Programming . It assumes a knowledge of C, some 
Unix experience and a course in data structures. Its purpose is to Until recently, the only exposure 
to concurrent pro­introduce students to programming techniques for applica­gramming that most undergraduate 
CS majors received tion development on networks of workstations. It is struc­was in the context of an 
operating systems course. Distrib­tured in three modules. At the outset, there is a module thatuted programming 
as a topic at the undergraduate level covers process environments, file system issues, concurrent was 
even rarer. Now, however, it is generally recognized programming, and interprocess communication. It 
is essen­that concurrency, parallel computing and distributed pro­tially an overview of basic stand-alone 
Unix facilities. gramming are all appropriate and, in fact, highly desirable Another module addresses 
graphical user interfaces andat the undergraduate level. event-driven programming. A third module deals 
with net­ work programming: application of transport layer services,There is a problem however. There 
is already a con­ siderable CS core of essential courses, the total number remote process creation, distributed 
computing and the cli­of credits that a college student will take is fixed by the ent-server model. institution 
and increases in major requirements often meet The course has been taught twice and each time haswith 
stiff resistance from college governance bodies. Fur­used Stevens fine book [Stevens90] as a primary 
text. Thethermore, not only is it increasingly accepted that all CS students have access to a network 
of Sun workstations to do majors have some experience with parallelism and distrib­their assignments 
and explore issues raised in the course. uted computing but other areas, such as GUIS and human factors, 
database, optimization, logic programming and so 2.1 Distributed and network programming module on compete 
for the all too small set of required advanced undergraduate course credits. This is a pragmatic (dare 
I say hacker ?) course and the main goals of the module on distributed and network Our response as faculty 
must be to find parsimonious programming are to give students direct experience with the ways of teaching 
these areas. We must find vehicles for issues that arise when writing distributed programs that rely 
conveying the important ideas and techniques and avoid on network services. These include but are not 
limited to achieving reliability when the underlying commun- Permission to co y without fee all or part 
of this material is granted provided t[ at the oopies are not made or distributed for ication medium 
is unreliable direet commercial advanta e, the ACM eopyrigM notice and the synchronization (e.g. barriers, 
serializing pro- Y title of the publication and ts date appear, and notice is given cesses) that copying 
is by permission of the Association of Computing Machinery. To copy otherwise, or to republish, requires 
a fee parallelizing (or distributing) programs and and/ors edfic permission. SIGCSE! 95 3/95 Nashville, 
TN USA ordering events. @ 1995 ACM O-89791-6%+ti9WOOo3....50.5o Because the course targets the low-level 
semantics typically offered by network services, using a high level system such as SR [Andrews82] or 
Linda [Gelernter85] was in appropriate. The first time I taught the course the students used the BSD 
socket interface. This approach has many advantages. Our textbook discusses the interface in detail and 
the interface is ubiquitous on Unix systems. However, like so much of the Unix system, the interface 
is messy and contains many options and rules that, while per­haps required for generality, are unnecessarily 
cumbersome for the students. The problem is not so much that the stu­dents can t master these rules. 
It is that the time required for mastery limits the period during which they can be expected to work 
on interesting exercises. Worse, the inter­face serves as a distraction and the students often fail to 
focus on the important issues. A similar, though less severe, problem had been encountered with the part 
of the course that used System V IPC features in connection with concurrent programming. That problem 
had been solved by providing the students with simplified set of routines to create and initialize sema­phores 
as well as provide standard P and V operations. There are a number of distributed programming librar­ies 
available, the most widespread of which is PVM [Sunderam90]. However, even these are too high-level for 
the purpose needed here. They do not provide messages that cause interrupts nor do they provide messages 
that are unreliable (in the sense of datagrams). A lower-level library, DP, has been developed at Brooklyn 
College [Arnow95]. Its semantic level includes that of the socket interface, but it too, again in the 
interest of generality, has aspects that are distracting to students. For that reason, XDP. a simplified 
interface to DP, was written and used in the most recent offering of the course. 3. The XDP eervicee 
To make use of XDP services in a program, a student need only include the appropriate header file, link 
to the XDP library and provide a file called hosts in the current directory. An XDP computation is initiated 
by invoking the XDP program, which results in the first, or prima~, pro­cess. 3.1 Process creation and 
management Processes are created statically, at the outset of execu­tion. For each entry in the host 
file, a process will be cre­ated, if possible, on the machine described by the entry. In order for this 
to happen, every XDP program must invoke ~init ( ), typically at the outset of execution. When this is 
executed by the f~st, or primury, process, all the other seconalwy processes are created. Each secondary 
process executes the same program as the primary, and thus will also invoke xd~init ( ). For these processes, 
~init t 1 serves to establish communi­cation. Each secondary process receives the same com­mand-line 
arguments as the primary. The call to xdpinit [ J returns the actual number of processes (which will 
be less than or equal to the number of entries in the hosts file). Each process is identified by a small 
integer, ranging from O to N-1, where N is the number of processes. The Xdmmmpid ( ) function returns 
a process s id. The id of the primary will always be O. XDP processes must terminate using xc%mx~t ( 
), passing it a string indicating the reason for termination. XDP processes must not use the Unix exit 
( ).  3.2 Message sending XDP processes communicate by sending and receiving messages. To send a message 
in XDP we write: xdpwrite ( id, msgptr, msgsize, mode) where id is an integer that identifies the target, 
msgptr points to the message data, msgsize is the size of the nmes­sage, and mode is a set of flags that 
allow two orthogonal choices: First, the message can be sent reliably (XDPREL) or not (XDPUNREL). Reliability 
here means that XDP will guaran­tee the eventual sequenced delivery of the message to the target, provided 
that the underlying network and relevant host machines do not fail. Not sending the message reli­ably 
means that XDP will use the cheapest means to send the message and neither sequence nor delivery itself 
is guaranteed. The ~write ( ) never blocks. This means that upon return from xd~ite ( ), one thing is 
certain: the target has not yet received the message ! Second, the message can be sent so that it willl 
be interrupting (xDPamuaG) or not (xDPru?cv). In the case of non-interrupting messages, the message is 
queued upon arrival and does not affect the receiving process until the receiver explicitly reads the 
message with the ~recv ( ) call (see below). In the case of the interrupting message, the message s arrival 
may force the invocation of a special message-catching routine if such a routine has been desig­nated 
by the receiving process. Whether or not such a rou­tine has been designated, the interrupting message 
must be read explicitly with the xdpgetmsg ( ) call, not the xdprecv( ) call. Receiving messages. Logically, 
each XDP process has two receiving ports: one for receiving interrupting messages (marked XDPRECV) and 
another for receiving non-interrupt­ing messages (xDPGEmusG). XDP processes can receive these messages 
using one of two routines: xdprecv(src, buffer, l~mi.t, mxle) xdpgetmsg ( src, buffer, limit) In each 
case, src is a pointer to an integer in which the id of the sender will be stored. The second argument, 
buffer is the address of a buffer in which to store the message con­tents and the third argument, limit 
specifies its size. Mes­sages that exceed this limit are truncated without remark. The x~getmsg ( ) call 
is used to receive messages that generate an intermpt as such it is typically used inside an interrupt 
handler (see below). In such a context, blocking would be inappropriate, and so xdpcretmsg ( ) never 
blocks it returns immediately, with the return value XDPSUCCESS or XDPNOMESSAGE. On the other hand, by 
using a mode of XDPBLOCK or XDPNOBLOCK, the xdprecv ( ) call may or may not be forced to block until 
a message is available. Interrupting Messages. In the absence of any arrangement for immediate response 
to their arrival, interrupting mes­sages can be read in the same way that non-interrupting messages are, 
but using xdpgetmsg ( ) instead of xdprecv ( ) (and hence not being able to block). Generally, however, 
the purpose of such messages is to provoke an immediate response by or have an immediate impact on the 
recipient. That requires that the receiving process previ­ously invoke xdpcatchmsg ( ) (preferably at 
an early point of the program) passing it a pointer to a message handler, i.e., a function that will 
be invoked when an interrupting message arrives. The message handler should in turn call xdwetmsff ( 
) to retrieve the message and carry out the appropriate action concerning the datum. In the event that 
several interrupting messages arrive before the system has had a chance to invoke the message handler 
function, only one call to the message handler will be made, i.e., there is not a one-to-one correspondence 
between interrupting messages and calls to the handler. Hence, the message handler should in general 
be written on the assumption that many messages are ready to be received. As a result, the typical structure 
of a message handler is: initialization; while (xdpgetmsg (. . . ) ! .XDPNOMESSAGE) process message just 
received;  3.3 Synchronization and timeouts Critical sections. The message handler specified in a call 
to x~catchmsg ( ) may be invoked at any time and may reference global objects. To guarantee mutual exclusion, 
such access should be preceded by a call to xdpblock ( ) to disable calls to the interrupt handler and 
followed by a call to xdpunblock ( ) to re-enable them. Upon invoking xdpunblock ( ), if any interrupting 
messages arrived since the call to -lock ( ), the catching function will be invoked. The message handler 
is never invoked recursively and so there is no need to protect the function itself. Thus xdp­block ( 
) /xdpudaock ( ) are never used inside a handler, Synchronization and timeouts. Sometimes a process needs 
to wait until some condition becomes true, typically as a result of incoming interrupting messages. In 
order to do so the process can call xdppause ( ): xdmause (t, f) This call causes the invoking process 
to suspend exe­cution until an asynchronous event has taken place. Such events include arrival of an 
interrupting message, a timeout or an external signal. If t is not zero, a timeout event is set to occur 
in t milliseconds. In that case, if t?is not null, it is a function that will be invoked prior to return 
from xdp­pause (). If t=O no timeout event will take place. Since the xdppause ( ) routine returns as 
a result of any asyn­chronous event, interrupting message arrival or otherwise, so the necessary condition 
must be rechecked: while ( I desiredcondition) Xdppause(t, f);  When xdppause ( ) is used this way, 
it is usually the case that the desired condition will become true as a result of the arrival of interrupting 
messages. There is, therefore, a race condition: afier the desired condition is checked, and found to 
be false, but before xdppause ( ) is called, an interrupting message could arrive and bring about the 
desired condition. Unfortunately, when xdppause ( ) would then be called (upon returning from the message 
handler), there would be no interrupting message to terminate the xdppause ( ) the process would hang. 
Essentially this is due the global character of the desired condition: testing that condition is a critical 
section. To avoid this problem, xdpblock ( ) hcdpunblock must be used. xdpblock ( ) ; while ( I deshedconditfon) 
xdppause (t, f); xdpunblock ( ) ;  This code guarantees that the test-and-call sequence (test the condition, 
call xdppause ( ) ) is atomic. The mes­sage handler is blocked from the time the condition is tested 
through the time x~~ause ( ) is entered. In order for ~ause ( ) to ever have a chance to complete and 
to make it possible for the desired condition to become true, xdppause ( ) reenables message handler 
invocations upon enter. Upon return from xdppause ( ), the message handler status is restored to its 
state upon entry. Note that during xdppause ( ), interrupts are automatically re-enabled. 3.4 Other 
facilities To ease the development process somewhat, some utilities for XDP are available: xdphosts 
machine 1 machine2 ... machineN creates a hosts tile with the above machines, fill­ing in all necessary 
fields.  xdpsee program.name gives a ps-style list of the named program on just those machines mentioned 
in the local hosts file.  ~c~leted prograrn.name counts the number of XDP processes running the named 
program on the machines in the local hosts file that have completed.  3.5 Restrictions Stdin, stdout 
and stderr are not available to XDP pro­cesses: all input and output files must be opened by the processes. 
Doing a blocking xdprecv ( ) is not allowed in a message handler, nor is sending a XDPREL I XDPRECV mes-sendint 
( int dest, int v, int mode) { xdpwrite(dest, v, sizeof (i) , REL_INTR) ; sage. In this section we indicate 
other resrnctions, } Timing. All systems calls and standard subroutines that are implemented using the 
Unix alarm system call (or its vari­ants) are not allowed. That includes: sleep, alarm, ualarm. To give 
the application writer some of this func­tionality, there is a special XDP routine, ~alarm (t, f ) which 
arranges for function f to be invoked after t millisec­onds. Asynchronous and signal-driven i/o. Using 
the BSD select ( 1 system call or making use of the SIGIO signal is forbidden. Exec. Use of any of the 
axec variants is forbidden, unless used in conjunction with fork ( ). Fork. The fork () system call can 
be used provided that the children to not attempt to partake in the execution of xdp routines. Child 
processes (but not the parent) may do execs. 4. Examples and ssmple problems for students An straightforward 
example for illustrating some of the issues in distributed programming is the following pro­gram, WI 
ch creates a file containing all the primes from 2 to a number that is a command-line argument to the 
pro­gram. The range of integers to be checked is divided up into equal subranges. The primtuy informs 
all the second­ary processes what their subranges are. (The primary has a subrange for itself too.) Each 
process works independently for the most part, checking integers in its subrange (execut­ing search (). 
When the primary finds a prime it calls zmwprtio ( ) to add it to the list. When a secondary finds a 
prime it sends it to the primary using xclmrr~te ( ). The latter information INTERRUPTS the primary, 
forcing the invocation of f catch ( ). This in turn invokes ne~risie ( ). Termination handling is done 
as follows: secondaries send a negative integer to the primary to indi­cate they are finished. When the 
primary has received the appropriate number of such integers it knows the computa­tion has ended. #include 
<stdio. h> #include xdp . h #define REL_RECV (XDPREL IXDPRECV) #define REL_INTR (XDPREL IXDPGETMSG 
) #define NAXPRINES 90000 int p [MAXPRIMES] , nprimes=O; int mypid, nnodes, done=O, interval, maxnum; 
void I* executed by the prinuary only V newprime ( int n) { xdpblock ( ) ; /*potential race condition 
V if (nprimes<MAXPRIMES ) /* so block interrupts / p [nprimes++l = n; xdpunblock ( ) ; } void void I* 
executed by the primary only *I fcatch () { int p, src; while (xdpgetmsg (&#38;src, &#38;p, sizeof (P) 
) ! =xDpNOMESSJ@E ) if (p <O) done++; else newprime (p) ; } void search (int nl, int n2 ) { int i; for 
(i=nl; i<=n2; i++) { if (IsPrime (i) { if (mypid==O) newprime ( i ) ; else sendint ( O, i, RELJNTR) ; 
} } } void foreman ( ) { I* executed by the prinuuy only *I int i, pid, b; xdpcatchmsg ( fcatch) ; for 
(b=O, pid=l; pid<nnodes; pid++) { sendint(pid, b, REL_RECV) ; b += interval; } search (b, maxnum) ; done++; 
 xdpblocko ; while (done< nnodes) xdppause(OL, NULLFUNC) ; xdpunblocko ; ... print the list of primes 
here ... xdpexit( You re fired! ) ; ) void workero { /*executed bythe secondary only *I int b, src; 
xdprecv(&#38;src, &#38;b, sizeof (b) , XDPBLOCK) ; search (b, b+interval) ; quitvalue = -1; sendint(O,-l,REL_INTR); 
fclose(fp); xdpexit( I quit! ); } main(int ac,char *av[l) { nnodes=xdpinit(&#38;ac, &#38;a) ; maxnum 
= atoi(av[l]); mypid = xdpgetpido; interval = maxnurdnnodes; (mypid == 0) ? foremano ; workero; } Along 
with examples like this students have been given various exercises, such as: parallelize a simple quadrature 
 parallelize (Djikstra s) single source shortest path algorithm  paralkdize a given ising-model simulation 
 write a program that estimates the relative avail­able computational power on the set of machines mentioned 
in the hosts file  . using ~alazm t 1 arrange to send messages reli­ably using only the XDPTJNI?ELflag 
in mite ( ) 5. Conclusion As can be seen from the above, the student working with this library still 
must address the fundamental prob­lems of buffering, race conditions, synchronization, task decomposition, 
and reliability that must be resolved in net­work computing. By using the library, the student is relieved 
of having to create and bind addresses and carry out other messy socket layer administration. XDP is 
a new library and, so far, has not been used outside of Brooklyn College. Is this a disadvantage for 
these students? In the absence of time constraints, using the socket layer might be desirable, but even 
if there is enough time to teach it effectively, should a CS major s fust encounter with network computing 
be obscured by its idiosyncrasies? And would a student graduating to a posi­tion involving network programming 
under NT be better prepared by an XDP or a socket layer module? My admit­tedly anecdotal (based on two 
offerings) experience sug­gests that using a library to raise just the issues of interest and to hide 
those not of interest is effective. Others in my department have had similar experiences in teaching 
other advanced undergraduate electives, for example, constraint­based programming [McAloon,Tretkoff95]. 
As we in the university strive to make available a broader range of more advanced topics, we may increasingly 
have to resort to libraries and environments that are specially designed for instruction. 6. References 
[Andrews82] G.R. Andrews: The distributed programming language SR--mechanisms, design and implementation. 
So@vare Practice and Experience 12,8 (Aug. 1982). [Arnow95] D,M. Arnow: DP: A library for building porta­ble, 
reliable distributed applications. To appear in the Pro­ceedings of the Winter USENIX 95 Conference, 
New Orleans (Jan., 1995). [Gelemter85] D. Gelemter: Generative communication in Linda. ACM Transactions 
on Programming Languages and Systems 7, 1 (Jan. 1985). [McAloon,Tretkoff95] K. McAloon and C. Tretkoff 
Opti­mization and Computational Logic, Wiley, to appear in 1995. [Stevens90] W. Richard Stevens: UNIX 
Network Program­ming. Prentice-Hall (1990). [Sunderam90] V.S. Sunderam: PVM A framework for parallel 
distributed computing. Concurrency: Practice and Experience 2 (1990). 
			