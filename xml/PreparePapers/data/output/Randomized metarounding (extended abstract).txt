
 Randomized Metarounding [Extended Abstract] Robert Carr Sandia National Labs Albuquerque NM 87185 
bobcarr@ cs.sandia.gov ABSTRACT Let P be a linear relaxation of an integer polytope Z such that the 
integrality gap of P with respect to Z is at most r, as verified by a poly-time heuristic A, which on 
any positive cost function e returns an integer solution (extreme point of Z) whose cost is at most r 
times the optimal cost over P. Then for any point z" in P (fractional solution), rx" dom-inates some 
convex combination of extreme points of Z. A constructive version of this theorem is presented with appli- 
cations to approximation algorithm% and can be viewed as a generalization of randomized rounding. General 
Terms randomized rounding, integrality gap, polyhedra 1. INTRODUCTION Randomized rounding has become 
a standard technique in the design of approximation algorithms for NP-hard opti- mization problems, especially 
for packin 9 and covering prob-lems. These are problems that can be stated as integer linear program~ 
of the form max cz subject to Ax _< b or rain cz subject to Az >_ b where each component of x is 0-1 
valued and the entries of A, b and c are all non-negative. Given say, a minimization (covering) problem 
of this form, the ap- proach is to first solve the linear programming relaxation of the integer program, 
namely min ex Ax > b x > 0 z < 1 *Sandia is a multiprogram laboratory operated by Sandia Corporation, 
a Lockheed Martin Company, for the United States Department of Energy under contract DF_,-AC04- 94AL85000. 
~Supported by NSF CAREER award CCK-9875024. Permission to make digital or hard copies of all or paJ~ 
of this work for personal or classroom use is granted without fee provided that copies are not made or 
distributed fbr profit or commercial advantage and that copies bear this notice and the lull citation 
on the first page. To copy otherwise, to republish, to post on se~wc~ or to redistribute to lists, requires 
prior specific permission and/or a fee. STOC 2000 Portland Oregon USA Copyright ACM 2000 1-58113-184-4/00/5...$5.00 
Santosh Vempala t Dept. of Mathematics, M.I.T. Cambridge MA 02139   vempala @ math.mit.edu Let x" 
be the solution obtained by solving the linear pro- gram. The second step is to round this solution to 
a 0-1 solution as follows: for each variable xe, set x~ to 1 with probability x~ and set it to zero with 
probability I -x~. The resulting integral setting is not necessarily a solution to the IP, but it has 
several nice properties. In particular, the expected cost is ez ° and it approximately satisfies the 
constraints with high probability. 1.1 Path congestion. In many combinatorial situations, it is absolutely 
necessary to satisfy some (or even all) of the given constraints (e.g. a given subset of vertices must 
be connected in a solution, a solution must be a tour etc.). In such cases the method is not generally 
useful. However there are some lucky circum- stances when randomized rounding can be applied to yield 
a true solution. This is best illustrated by the problem of routin 9 with minimum congestion --we are 
given a graph, G = (V,E), and pairs of vertices (si,ti) for i = 1,...,k. A solution to the problem is 
a set of k paths such that the i'th path connects si and ti. The congestion of an edge is the number 
of paths that use the edge, and the congestion of a solution is the maximum congestion over all the edges. 
The goal is to find a solution with the minimum possible congestion. Given an instance of the problem, 
one can write down an integer linear program that ensures that there is a path between each pair si, 
ti, and which minimizes the con- gestion. The linear programming relaxation of this IP is a multicommodity 
flow problem that sets up a flow of value 1 between each si and ti and minimizes the fractional conges- 
tion, i.e. the maximum, over all the edges, of the total flow through an edge. Any solution to this LP 
can be decom- posed into a flow of value 1 between each pair st, ti. These flows have a very useful property: 
the flow between si and ti can be decomposed into a set of paths, each with some fractional flow, so 
that the sum of the fractional flows is 1. Viewing the flow as a vector in R IEI , and each path as a 
0-1 vector in R IEI, this property can be restated as The flow between si and ti can be expressed as 
a convex combination of paths between si and ti, i.e. f~ = ~ ~J xPJ J Here fi is the flow vector for 
the i'th pair, and X P~ is the inci- dence vector of edges on the j'th path Pj. Given such a path decomposition 
of the flow between si and ti, randomized rounding picks one path from the probability distribution 58 
given by the flow on the paths, i.e. the Aj's. Doing this for every si, ti pair gives us a solution to 
the problem. It is easy to check that the expected congestion of any edge is exactly its fractional congestion. 
Fhrther, since the choice of the path for each si, ti pair is made independently, a Chernoff bound implies 
that the congestion of every edge is within a constant times the expected value plus O(log n) with high 
probability [4].  1.2 Multicast congestion. Now consider the problem of finding trees (instead of paths) 
that span specified subsets of vertices (instead of only pairs) so as to minimize the net congestion. 
This is the multicast congestion problem and we will use it throughout the pa- per to illustrate the 
new techniques. We are given a graph G = (V,E) and subsets of vertices Sh... ,Sin C_ V, called multicast 
requests. The goal is to find a set of m trees so that the i'th tree spans the vertices of the i'th subset 
and the maximum number of trees that use any single edge is minimized i. As in the case of paths, one 
can write down an LP relaxation of the problem and obtain a fractional solu- tion, but it is no longer 
obvious how to round this into a set of trees with low congestion. The LP solution itself can be decomposed 
into fractional solutions for each mnlticast re- quest. If the fractional solution for each multicast 
could be written as a convex combination of trees, this would give us a simple rounding algorithm: For 
each multicast separately, (i) Find a convex combination of trees that equals the frac- tional solution 
and (ii) Pick one tree with probability equal to its convex multiplier. Then the expected congestion 
on an edge is exactly its fractional congestion. Further, the pro- cess is independent for each multicast, 
and so the deviation from the expectation can be bounded, and we get a solution that is within a constant 
times OPT plus O(log n). Of course, the proposed algorithm hinges on being able to express the fractional 
solution to a single multicast as a con- vex combination of trees. Unfortunately, this is impossible. 
If we could express any fractional solution as a combination of trees, then we could use this to solve 
the Steiner tree problem optimally. The solutions to a single multicast are Steiner trees spanning the 
vertices of the multicast. So we could solve an LP relaxation that minimizes the total cost of edges 
in the solution. Then we can write the solution obtained as a convex combination of trees. The cost of 
one of the trees must be at most the average cost, which is the value of the fractional solution. Thus 
we find one tree with cost at most the optimal cost. But the Steiner tree problem is NP-hard. Indeed 
any LP relaxation (that can be solved in polytime) must have an integrality gap. However, the LP relaxation 
of the Steiner tree problem is known to have an integrality gap of at most 2. So while it is impossible 
to express any fractional solution as a con- vex combination of integral solutions, it could be possible 
to express TWICE any fractional solution as a convex com- bination of integral solutions. Indeed, a recent 
result of [1] says that if the integrality gap of a relaxation is at most r, then for any fractional 
solution x', the vector rx ° dom-inates (i.e. is greater than or equal in every coordinate) a ~In [5], 
Raghavan and Thompson present an algorithm with an exponential (in the maximum size of a single multicast) 
time bound that finds a solution of congestion O(OPT + log n). One consequence of the main theorem in 
this paper is a poly-time algorithm with the same quality. convex combination of integral solutions[ 
If this convex de- composition can be found in polytime, then we would have a polytime algorithm for 
the multicast congestion problem that is guaranteed to find a solution within a constant times OPT plus 
O(log n). In this paper we present a polytime algorithm for finding such a convex decomposition. It is 
described in section 4 and is based on a careful application of the ellipsoid method. This leads to an 
improved approximation for the multicast congestion problem (the previous best approximation was a multiplicative 
O(logn) [6]).  1.3 Generalized congestion. As the reader might have realized, the approach just de- 
scribed is applicable in a much more general context, which we call generalized congestion. Suppose 
we are given a graph G = (V, E) and a set of requests, Rx,... , Rm. To satisfy the i'th request Ra we 
need to pick a subset of edges that satisfy some specified property P~. So, for instance the first request 
might be for a Hamilton cycle, the second request might be for a Steiner tree, the third for a 2-edge 
connected subgraph and so on. We assume that for each i, the set of solutions to the i'th request can 
be modelled as an integer program and its LP relaxation, P~ is given to us. We are also given a heuristic 
A~ which can be used to find a solution within r times the optimum of P~ for any positive cost function 
on the edges. The problem is to find a solution that satisfies each request and has the minimum possible 
congestion. The congestion of a solution is the maximum congestion among its edges; the congestion of 
an edge is the number of requests for which that edge appears in the requests' solution. The main results 
of this paper can be stated as follows: THEOREM 1. There in a polytime algorithm that find# a solution 
to any instance of the generalized congestion prob- lem with congeation O(r. OPT + log n) (with r defined 
an in Theorem ~).  THEOREM 2. Given an LP relaxation P, an r-approximation heuristic A, and any solution 
z" of P, there in a polytime algorithm that finds a set of integral solutions zl,z2,.., of P such that 
rx" >_ Z AjX:j J where Aj > 0 for all j, and Y]~j Aj = 1. 2. THE GENERIC ALGORITHM ~Let A~x > b i, x 
>__ 0 be the LP relaxation for the i'th request. I. Formulate a single linear program ]3 for the gener- 
alized congestion problem that minimizes the overall congestion, using the linear programs for each request 
as shown below. A different set of variables x~ is used for each request i. rain z A~x i > b ~ Vi = 
l,... ,m Z x~ <_ z Ve e E i x,z >_ 0 2. Solve ]5 to obtain a solution x'.  59 3. Separate the solution 
into a solution for each request, i.e. z i° for i = 1,... ,m. 4. For each request i, apply the convex 
decomposition algorithm of section 4 to z I- and obtain a set of integral solutions and a convex combination 
of them that is dominated by rz i-. 5. For each request, pick one integral solution with prob- ability 
proportional to its convex multiplier.  2.1 Examples Our first example is the multicast congestion 
problem de- scribed in the introduction. In this problem each request is for a Steiner tree. Let the 
set of vertices specified by the i'th request be Si. Then the request can be modelled by the following 
LP relaxation: z, >_ I ¥ScVs.t. sns,#~,(V\S]nSI~(i~ eE6(S) z, _ 0 Ve~E (2) There is a simple heuristic 
2 that shows that the integral- ity gap of this relaxation is at most 2. Thus we have a 2-approximation 
heuristic for each request. There is a po- tentially stronger relaxation, called the bidirected cut relax- 
ation originally proposed by Edmonds, whose integrality gap is unknown. In step 4 of the algorithm, for 
each request i, we find a con- vex combination of Steiner trees that is dominated by 2z i" . In step 
5 we pick one Steiner tree from the combination for each request. This gives us a solution to the multicast 
con- gestion problem. As a second example consider a situation where the first request is for a 2-edge 
connected spanning subgraph of the entire graph. The second request is for a path between two specified 
vertices s and t and third is for a cycle cover of the graph (i.e. a set of cycles such that each vertex 
is in some cycle). The we can write down LP re-laxations for each request. The 2-edge connected spanning 
subgraph problem has a relaxation whose integrality gap is known to be less than ~ [2], while the path 
and cycle cover problems can be solved in polynomial-time, i.e. they have LP relaxations with integrality 
gaps equal to 1. In this case, each request has a ~ or better approximation heuristic. Note that instead 
of just one request for each of the three types described above, we could have any number of requests 
of each type. For all these examples, Theorem I guarantees that the con- geztion of the solution obtained 
is at most a constant times the OPT plus O(log n). 3. THE PERFORMANCE GUARANTEE Let X~ be the random 
variable indicating whether an edge e is selected for the i th request. LEMMA 1. E[X i-] ~ r. agie°. 
 Proof. The random variable X / is 1 if the edge e is present in an integral solution selected for the 
i'th request and zero otherwise. The expected value of X- i is at most the sum of 2Take the minimum spanning 
tree on the complete graph with vertex set Si and edge weights given by the triangle inequality closure 
on the original graph. selection probabilities of integral solutions that contain e. That is, E[X~] <_ 
E $:eEzi Pr(zJ is selected for the i'th request) = E j:eEzJ _< rx7 ~J The last inequality is due to 
the fact that r~ i~ dominates the convex combination of zJ's and so each rzl- * is greater than or equal 
to the sum of the Aj's corresponding to z j's that contain e. I-I LEMMA 2. With high probability, the 
congestion of the so- lution found by the generic algorithm is O(r. OPT + log n). Proof. Fix an edge 
e. Let C(e) denote the total conges- tion on the edge e. By definition, C(e) = ~i X/" Prom Lemma 1, we 
can conclude that E[C(e)] < r. ~-~.i{zi-" } < r OPT. We will apply a Chernoff bound to show that it 
is unlikely that C(e) deviates significantly from its expec- tation. For each request i, the random variables 
X i are independent from random variables for other requests. As a consequence, we can apply a Chernoff 
bound ([3]). Set C >. max{2eE[C(e)], 2. (a + 2). log n} with ~ > 0 denoting an arbitrary constant. Then 
Prob[C(e) _> C"] < 2 -c/2 < n -°-2 Summing this probability over all edges yields that the con- gestion 
does not exceed C -O(r. OPT + log n), with prob- ability at least 1 - n -a. [] The above lemma along 
with theorem 2 implies theorem 1. 4. THE MAIN TOOL: CONVEX DECOM-POSITION The decomposition theorem 
we present in this section ap- plies to a large class of problems which have integer program- ming formulations. 
Let us first define the class of problems for which the decomposition applies. For this we need a couple 
of definitions. DEFINITION 1. A positive integer program is an integer program whose variables are constrained 
to be non-negative. DEFINITION 2. A min-IP (max-IP) problem is a mini-mization (maximization) problem 
whose set of feasible so-lutions can be described by a positive integer program. The traveling salesman 
problem (TSP) is an example of a min-IP problem. The analysis that follows can also be ap- plied, with 
slight modifications, to max-IP problems, but we will assume our problems are min-IP problems for now. 
Note that any min-IP (max-IP) problem has a linear pro- grammlng relaxation obtained by relaxing the 
integrality constraints of the integer program defining the problem. DEFINITION 3. A polynomial-timealgorithm 
-4 is an r-approximation heuristic to a min-IP problem with linear pro- gramming relaxation 7 7, if, 
for any positive objective f~ne- tion, .4 finds a solution whose cost is at most r times the cost of 
the optimal solution to 77. 60 A problem in our class is specified as the LP relaxation 7~ of a positive 
integer program IP along with an r-approximation heuristic .4 and a feasible solution x* of P. For a 
min-IP problem I, denote the integer polyhedron for the integer program by Z(I) or just Z. Let P(I) or 
just P denote the linear programming relaxation of Z(I) (as well as the polyhedron corresponding to the 
linear programming relaxation). Also denote the set of extreme points for a polyhedron P by ext(P). If 
we have an r-approximation heuristic .4 to a min-IP prob- lem I, then clearly the integrality gap between 
P(I) and Z(I) is at most r. Theorem 1 of [1] says that if x" is a feasi- ble solution to the linear program 
7~(I), then rx" dominates a convex combination of extreme points of Z(I). That is, we have rx" _> (3) 
J where ~j Aj = 1, Aj > 0 for all j, and each x j is an extreme point of Z(I). We now show how to construct 
a set of ~'/'s satisfying (3) in polynomial-time.  4.1 Constructing a Convex Combination Let x" be 
feasible for P(I). List the elements of ezt(Z) as ( x/I J E J). Let E be the index set for the variables 
in P(1). DEFINITION 4. For each non-negative objective function c, denote the solution returned by the 
r-approximation .4 by X c , In order to obtain (3), we 'wish to solve the following linear program. maximize 
~"~je J AJ subject to ~'~je# A)x~ < rx~ Ve E E (4) A# > 0 VjEJ As explained below, rx" dominates a convex 
combination of points in ext(Z) if and only if the optimal objective function value of (4) is 1. Moreover, 
the solution A" of (4) provides an explicit convex decomposition into points in ext(Z). That is, with 
J' := {j E J I A~ > 0}, one can see that > (S) jEJ I The sum in (5) is a linear combination of {x j 
]j E J'} C ext(Z) which is dominated by rx'. If )"~Ej, A~ = 1, then this linear combination is in fact 
our desired convex combi- nation. Note, however, that (4) has an exponential number of variables. We 
will demonstrate how to solve (4) in poly- nomial time by first solving its dual linear program by using 
an r-approximation .4. The dual linear program to (4) is as follows. minimize rx ° to + z subject to 
xJ'to+z > 1 VjEJ (6) w, > 0 Ve E E z > 0 THEOREM 3. The linear program (6) has an optimal so- lution 
of 1. Proof: Since w ° = 0, z* = 1 is feasible, the optimal solution to (6) is at most 1. Let to',z" 
> 0 be given such that (6)'s objective function rx'.to'+z'<l. We then have rx" to" < 1 -z °. Because 
the integrality gap between P(1) and Z(I) is at most r (where the objective function is w*), there exists 
a j E J such that x / .to ° < l-z*. Hence, to', z ° violates the inequality x~.to+z>l, which makes this 
point infeasible for (6). C] THEOREM 4. Given an r-approximation heuristic .4, the linear program (6) 
can be solved in polynomial time using the ellipsoid method. Proof: As in Theorem 3, let to', z" > 0 
be given such that (6)'s objective function rx'.to'+z" <l. We will use the r-approximation .4 as a separation 
oracle for finding an inequality of (6) that is violated by to', z'. We have rx" w" < 1 - z'. In fact, 
the integer solution x W" produced by .4 when the objective function is to* must satisfy x w to" < 1 
- z" since the cost of x w" must be within a factor of r of the cost of x'. But, then to', z" violates 
the inequality x~'.w+z> l, which means we have our desired separation oracle. Hence, (6) can be solved 
in polynomial time using the ellipsoid method, n THEOREM 5. Given an r-approximation heuristic, we 
can solve (4) in polynomial time. Proof: By Theorem 4, we can solve (6) in polynomial time. The violated 
inequalities xi . to + z > l Vj E J' our separation oracle found correspond to dual variables Aj for 
all j E J' C J in (4). There is an optimal dual so-lution using only these variables, since the inequalities 
our separation oracle found are sufficient to determine that we have the optimal solution to (6). Furthermore, 
the number ]J'] of these dual variables is polynomial in magnitude since our separation oracle was used 
only a polynomial number of times. Therefore, we can solve (4) by solving the smaller linear program 
that has only the A i variables for j E J'. Since this smaller linear program is polynomial in size, 
it can be solved in polynomial time. I::l THEOREM 6. Given an r-approximation algorithm, we can decompose 
rx* into a convex combination as shown in (3) with a polynomial number of terms and in polynomial time. 
Although (6) has an exponential number of constraints, we Proof: Theorem 5 and its proof show that we 
can solve will be able to solve it in polynomial time using the ellipsoid (4) in polynomial time by solving 
a smaller polynomial size method. version of (4). If A~ for j E J' is the optimal solution to 61 the 
smaller version of (4), we have that rx ° dominates the linear combination    ,=" > ~ :~;~ (~) jEJ 
t of elements z J in ext(Z). As pointed out in the previous proof, [J'[ is polynomial in magnitude, 
so there are a poly- nomial number of terms in (7). Since the optimal objective function value of (4) 
is 1 by Theorem 3 and duality, we have that jEJ' Hence, the linear combination (7) is our required 
convex combination, and can be found in polynomial time. C] 5. REFERENCES [i] R. Cart and S. Vempala. 
Towards a 4/3 approxima- tion for the asymmetric traveling salesman problem. In SODA Conference Proceedings, 
2000. [2] J. Cheriyan, A. Sebo, and Z.Szigeti. Improving on the 1.5-approximation of a smallest 2-edge 
connected span- ning subgraph. In IPCO Conference Proceedings, 1998. [3] T. Hagerup and C. Rub. A guided 
tour of chernoff bounds. Information Procensing Letters, 33(6):305-308, 1990. [4] P. Raghavan and C. 
Thompson. Randomized rounding: a technique for provably good algorithms and algorith- mic proofs. Combinatorica, 
7(4):365-374, 1987. [5] P. Raghavan and C. Thompson. Multiterminal global routing: a deterministic approximation 
scheme. Algo- rithmica,6:73-82, 1991. [6] S. Vempala and B. Voecking. Approximating multicast congestion. 
In ISAA G Proceedings, 1999. 62   
			