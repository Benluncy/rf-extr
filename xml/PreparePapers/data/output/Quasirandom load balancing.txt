
 Quasirandom Load Balancing Tobias Friedrich* Martin Gairing Thomas Sauerwald Abstract We propose a 
simple distributed algorithm for balancing indivisible tokens on graphs. The algorithm is completely 
deterministic, though it tries to imitate (and enhance) a random algorithm by keeping the accumulated 
rounding errors as small as possible. Our new algorithm approximates the idealized pro­cess (where the 
tokens are divisible) on important net­work topologies surprisingly closely. On d-dimensional torus graphs 
with n nodes it deviates from the idealized process only by an additive constant. In contrast to that, 
the ran­domized rounding approach of Friedrich and Sauerwald [8] can deviate up to O(polylog n) and the 
deterministic algo­rithm of Rabani, Sinclair and Wanka [23] has a deviation 1/d of O(n ). This makes 
our quasirandom algorithm the .rst known algorithm for this setting which is optimal both in time and 
achieved smoothness. We further show that also on thehypercube our algorithmhas a smaller deviationfrom 
the idealized process than the previous algorithms. To prove these results, we derive several combinatorial 
andprobabilistic results that webelieve tobe ofindependent interest. In particular, we show that .rst-passage 
probabil­ities of a random walk on a path with arbitrary weights canbe expressed as a convolution ofindependentgeometric 
probability distributions. 1 Introduction Loadbalancingisan importantrequisiteforthee.cient utilization 
of computational resources in parallel and distributed systems. The aim is to reallocate the load such 
that at the end each node has approximately the same load. Load balancing problems have various applications, 
e.g., for scheduling [25], routing [4], and numerical computation [26, 27]. Typically, load balancing 
algorithms iteratively ex­change load along edges of an undirected connected graph. In the natural di.usion 
paradigm, an arbitrary amount of load can be sent along each edge at each step [21, 23]. For the idealized 
case of divisible load, a popular di.usion algorithm is the .rst-order-scheme by Subramanian and Scherson 
[24] whose convergence rate is fairly well understood by Markov chain theory [17]. However, for many 
applications the assumption of divisible load may be invalid. Therefore, we consider the discrete case 
where the load can be decomposed in indivisibleunit-sizetokens. Itisavery naturalquestion by how much 
this integrality assumption decreases the *Max-Planck-Institut f¨ur Informatik, Saarbr¨ucken, Germany 
University of Liverpool, Liverpool, United Kingdom Simon Fraser University, Burnaby, Canada e.ciency 
of load balancing. In fact, .nding a precise quantitative relationship between the discrete and the idealized 
case is an open problem posed by many authors, e.g., [7, 8, 10, 11, 18, 21, 23, 24]. A simple method 
for approximating the idealized process was analyzed by Rabani et al. [23]. Their ap­proach is to round 
down the fractional .ow of the ide­alized process. One drawback of this deterministic ap­proach is that 
it can end up in rather unbalanced states (cf. Theorem 3.1). To overcome this problem, [8] ana­lyzed 
a new algorithm based on randomized rounding. Onmanygraphs,thisalgorithmapproximatesthe ideal­ized case 
much better than the deterministic approach of Rabani et al. [23]. A natural question is whether this 
randomized algorithm can be derandomized with­out sacri.cing on itsperformance. Weanswerthisques­tion 
to the positive, by introducing a quasirandom load balancing algorithm which rounds up or down deter­ministically 
such that the accumulated rounding errors on each edge are minimized. Our approach follows the concept 
of quasirandomness as it deterministically imi­tates the expected behavior of its random counterpart. 
That is,ouralgorithm imitatesthepropertythatround­ing up and down the .ow between two vertices occurs 
roughly equally often by a deterministic process which minimizes these rounding errors directly. Our 
Results. We focus on two network topolo­gies: hypercubes and torus graphs. Both have been intensively 
studied in the context of load balancing (see e.g., [8, 9, 13, 22, 23]). We measure the smooth­ness of 
the load by the so-called discrepancy (see e.g. [7, 8, 11, 23]) which is the di.erence between the maximum 
and minimum load among all nodes. For d-dimensional torus graphs we prove that our quasirandomalgorithmapproximatesthe 
idealizedpro­cess up to an(additive) constant. Moreprecisely,for all initial loaddistributionsand timesteps,the 
load of any vertex in the discrete process di.ers from the respec­tive load in the idealized process 
only by a constant. This istobecompared with adeviationofO(polylogn) 1/d) for the randomized rounding 
approach and O(nfor the deterministic approach of [23]. Hence despite our approach is deterministic, 
it also improves over its ran­domcounterpart.Startingwith an initialdiscrepancy of K,the idealizedprocessreachesaconstantdiscrepancy 
after O(n2/d log(Kn)) steps(cf.Corollary 4.2). Hence the same holds for our quasirandom algorithm, which 
makes it the .rst known algorithm for the discrete case which is optimal both in time and discrepancy. 
 For the hypercube we prove a deviation of our quasirandom algorithm from the idealized process of T(logn). 
For this topology we also show that the devi­ation of the random approach is O(logn)while the one of 
the deterministic approach of [23] is even O(log2 n). Again, using the results of the idealized process, 
our quasirandom algorithm is at least as good as the ran­domized rounding algorithm and asymptotically 
better than the algorithm of[23]. The results regardingthede­viationbetweendiscreteand idealizedprocessaresum­marized 
in Table 1. Our Techniques. Instead of analyzing ourquasir­andom algorithm directly, we examine a new 
generic class of load balancing algorithms that we call bounded error di.usion (BED). Roughly speaking, 
in a BEDal­gorithm the accumulated rounding error on each edge is bounded by some constant at all times. 
This class includes ourquasirandom algorithm. The starting point of [23] and [8] as well as our paper 
is to express the deviation from the idealized case by a certain sum of weighted rounding errors (equation(4.1)). 
In this sum, the rounding errors are weightedby transitionprobabilities of a certain random walk. Roughly 
speaking, Rabani et al. [23] estimate this sum directly by adding up all transition proba­bilities. In 
the randomized approach of [8], the sum is bounded by Cherno.-type inequalities relying on in­dependent 
rounding decisions. We take a completely di.erent approach andprovethatthetransitionproba­bilites between 
two .xed vertices are unimodal in time (cf. Theorem 5.9 for the hypercube). This allows us to boundthesumby 
itsmaximal summand(Lemma4.3) forBEDalgorithms.The intriguing combinatorialprop­erty of unimodality is 
the heart of our proof and seems to be the main reason why we can outperform the pre­vious approaches. 
Though intuitively one would expect unimodality to hold on these symmetric graphs, direct proofs tend 
to be hard. The reason is that explicit formulas seem to be intractable and typical approximations are 
way too loose to compare consecutive transition probabilities. For the d-dimensional torus, we reduce 
the question of unimodality in time of the transition probabilities to a recent combinatorial result 
by Cooper and Spencer [3] for a random walk on the 2d-dimensional in.nite grid. Then we use a local central 
limit theorem to approxi­matethetransitionprobabilitiesby a multivariate nor­mal distribution which is 
known to be unimodal. Onhypercubestheabovemethodfailsasseveralin­equalitiesforthetorusgraph are onlytruefor 
constant d. However, we can employ the additional symmetries to prove unimodality of the transition probabilities 
di­rectly. Somewhat surprisingly, this intriguing property was unknown before, although random walks 
on hyper­cubes have been intensively studied [5, 14, 19]. We prove this unimodality result by .rst establish­ing 
aperhapsunexpected resultconcerning.rst-passage probabilities on paths with arbitrary transition proba­bilities: 
If the loop probabilities are at least 1/2, then each .rst-passage probability distribution can be ex­pressed 
as a convolution of independent geometric dis­tributions. In particular, this implies that these proba­bilities 
are log-concave. Reducingthe random walk on a hypercube to a random walk on a weightedpath, we ob­tain 
that the transition probabilities on the hypercube are unimodal. Estimating the maximum probabilities 
via a balls-and-bins-process, we .nally obtain a tight bound for the hypercube. We believe that especially 
our probabilistic results for paths are of independent interest, as random walks on the paths are among 
the most extensively studied stochastic processes. Moreover, many analyses of ran­domized algorithms 
can be reduced to such random walks(see e.g. [20,Thm.6.1]). Related Work. Aiello et al. [1] and Ghosh 
et al. [11] studied balancing algorithms where in each round at most one token is transmitted over each 
edge. Due to this restriction, these algorithms take substantially more time, i.e., they run in time 
at least linear in the initial discrepancy K. Nonetheless, the best known boundsonthediscrepancy areonlypolynomial 
in n for the torus and O(log5 n) for the hypercube [11]. In the approach of Els¨asser et al. [7] certain 
interacting ran­dom walks are used to reduce the load deviation. This randomized algorithm achieves a 
constant discrepancy onhypercubes andtorusgraphs,however,the algorithm is more complicated and less natural 
than ours. More importantly, it is a factor O(log n) slower than our al­gorithm(undertheassumptionthatthe 
initialdiscrep­ancy K is polynomial). In another common model, nodes are only allowed to exchange load 
with at most one neighbor in each round, see e.g., [8, 10, 23]. In fact, the afore-mentioned random approach 
of [8] was analyzed in this model. However, the idea of randomly rounding the fractional .ow such that 
the expected error is zero naturally extends to our di.usive setting. Similar concepts of quasirandomness 
have been used for random walks [3], external mergesort [2], and broadcasting [6]. The latter work presents 
a quasirandom algorithm which is able to broadcast a piece of information as fast as its random counterpart 
 Graph class Deviation between discrete and idealized process Algorithm Reference Hypercube O(log2 n) 
O(logn) O(log3 n) O(log2 n loglogn) D R Theorem 3.1 &#38; [23, Corollary 5] Theorem 3.3 &#38; Theorem 
3.2 O(logn) O(logn) Q Theorem 5.1 d-dim. torus O(n 1/d ) O(polylogn) O(n 1/d ) O(n 1/d ) D R Theorem 
3.1 &#38; [23, Theorem 8] Theorem 3.4 &#38; [23, Theorem 8] O(1) O(1) Q Theorem 6.1 Table 1: Summary 
of the bounds on the deviation between the discrete and idealized process on d-dim. torus graphs and 
hypercubes for the deterministic algorithm of [23] (D), the di.usive variant of the randomized rounding 
approach of[8](R), and our newquasirandom algorithm(Q).The upperboundfor(R)onhypercubes requires additionally 
that K is polynomial in n. on the hypercube and on random graphs. However, [6] could not show a signi.cant 
performance improvement of the quasirandom protocol. In this respect the load­balancing algorithmpresentedhere 
isthe .rstexample of aquasirandom algorithm whichprovably outperforms its random counterpart. Organization 
of the paper. In Section 2, we giveadescriptionof ourbounded errordi.usion(BED) model. For a better comparison, 
we presents some re­sults for the previous algorithms of [8] and [23] in Sec­tion 3. In Section 4, we 
introduce our basic method which is used in Sections 5 and 6 to analyze BED al­gorithms on hypercubes 
and torus graphs, respectively. Forbetter readabilitywe omit some of theproofs. They will appear in the 
full version of this paper. 2 Model and algorithms We aim at balancing load on a connected, undirected 
graph G =(V,E) with n nodes. We will often assume that V = {1,2,...,n}. Denote by deg(u) the degree of 
node u . V and let. =.(G) = maxu.V deg(u) be the maximum degree of G. The balancing process is governed 
by an ergodic, doubly-stochastic di.usion matrix P with 1 .if {u,v}.E 2. . . deg(u) Pu,v =1- 2. if u 
= v. .0 otherwise . Let x(t) be the load-vector of the vertices at step t (or more precisely, after the 
completion of the balancing procedure at step t). The discrepancy of such a(row) vector x is maxi,j(xi 
-xj), andthe discrepancy at step 0 is called initial discrepancy K. The idealized process. In one round 
each pair (i,j)of adjacent vertices shifts divisible tokens between (t)(t-1)P i and j. We have the followingiteration, 
x= x (t) (0)Pt and inductively, x= x. Equivalently, for any edge {i,j}. E and step t, the .ow from i 
to j at step (t-1) (t-1) t is Pi,jxi -Pi,jxj . The discrete process. There are di.erent ways how to handle 
non-divisible tokens. We de.ne the followingbounded error di.usion (BED)algorithm. Let (t) Fdenote the 
integral .ow from i to j at time t. As i,j (t)(t)(t)(t-1) (t) Fi,j = -Fj,i, we have xi = xi -'j: {i,j}.E 
Fi,j. (t)(t-1) (t-1) (t) Let e:= (Pi,jx- Pi,jx) - Fbe the i,j ij i,j error allocated to i as a result 
of rounding on edge (t) {i,j}in round t. Note that for all vertices i, x= i (t) (x(t-1)P)i+'j: {i,j}.E 
ei,j.Let now. =.(t)measure the accumulated rounding errors (deviation from the (t) idealized process), 
that is, 't : .(t) for all s=1 ei,jt . N. We say that an algorithm is a BED algorithm if .= O(1). Our 
new quasirandom di.usion algorithm chooses (t)(t)(t) for Pi,jxthe .ow Ffrom i to j to be i . Pi,jxj i,j 
(t)(t)(t)(t)(t) either Fi,j = lPi,jxi -Pi,jxj J or Fi,j = IPi,jxi - (t)(t) Pi,jxj l dependinghow 'st 
=1 ei,j is minimized. This yields a BED algorithm with . : 1/2 and can be implemented with .log2 .. storageper 
edge. Notethat one can imagine various other natural(deterministic or randomized) BED algorithms. To 
do so, the algorithm onlyhas to ensure that the errorsdo not add up to more than the threshold .. With 
above notation, the deterministic algorithm (t)(t)(t) of Rabani et al. [23] uses F= lPi,jx- Pi,jxJ, i,j 
ij (t)(t) provided that Pi,jx. Pi,jxj . In other words, the i .ow on each edge is always rounded down. 
This gives . =T(T)after T time steps. A simple randomized rounding di.usion algorithm (similar the randomized 
rounding algorithm of [8] for (t)(t) balancing circuits) chooses for Pi,jxi . Pi,jxj the (t)(t) .ow Fas 
the randomized rounding of Pi,jx- i,j i Pi,jxj (t) , that is, it rounds down with probability (t)(t)(t)(t) 
(Pi,jx- Pi,jx)- lPi,jx- Pi,jxJ. This typ­ ij ij v ically achieves an error . of order T after T time 
steps. Handling Negative Loads. Unless there is a lower bound on the minimum load of a vertex, negative 
loadsmay occurduring thebalancingprocedure. Inthe following, we describe a simple approach to cope with 
this problem. Consider a graph G for which we can prove a deviation of at most . from the continuousprocess. 
Let x(0) be the initial load vector with an average load of x¯. Then atthebeginning of thebalancingprocedure, 
each node generates . additional (virtual) tokens. During the balancing procedure, these tokens are regarded 
as common tokens, but at the end they are ignored. First observe that since the minimum load at each 
node in the continuous process is at least ., it follows that at each step, every node has at least a 
load of zero in the discreteprocess. Sinceeach nodehasa load of x¯+O(.) at the end, we end up with a 
load distribution where the maximum load is still ¯x+O(.)(ignoringthe virtual tokens). 3 Bounds for previous 
algorithms For a better comparison with previous algorithms, this section gives some lower and upper 
bounds for other discrete di.usion processes. For the deterministic al­gorithm of Rabani et al. [23] 
we observe the following general lower bound on the discrepancy. Theorem 3.1. On all graphs G with maximum 
de­gree ., there is an initial load-vector x(0) with discrep­ancy .diam(G) such that for the deterministic 
algo­rithm of[23], x(t) = x(t-1) for all t . N. Proof. Fix a pair of vertices i and j with dist(i,j)= 
(0) by diam(G). De.ne an initial load-vector x (0) x:=dist(k,i)· .. k Clearly, x(0) hasdiscrepancy.diam(G). 
We claim that (1) (0) x= x. Consider an arbitrary edge {r,s}. E(G). Then, 1 11 (t)(t)(t)(t) Pr,sx-Pr,sx= 
x-x.= . rs rs 2. 2. 2 Hence the .ow on any edge {r,s}. E(G) is rounded down to 0 and the load-vector 
remains unchanged. The claim follows. Note that similar lower bounds for the related balancing-circuit 
model have been derived in [8]. For the randomized rounding di.usion algorithm described inSection2 one 
can show thefollowing upperboundfor graphs with good expansion. Theorem 3.2. Onallgraphs with secondlargest 
eigen­value in absolute value .2 = .2(P), the deviation be­tween the randomized rounding di.usion algorithm 
and the idealized process is at most O(.loglogn) with prob­ 1-.2 ability at least 1 - n-1, if the initial 
discrepancy is polynomial in K. Moreover, the randomized rounding di.usion algorithm reduces an initial 
discrepancy K to O(.loglogn) within O(log(Kn)) rounds with probabil­ 1-.2 1-.2 -1 ity at least 1-n. 
Notethatfortheinterestingcasewhen. = O(1)and G is an expander(graphsfor which1/(1-.2)= O(1)), the deviation 
is bounded by O(loglogn). For hypercubes, weget an upperbound of O(log2 nloglog n). The corre­sponding 
lower bound of O(log n)isgiven inthefollow­ing Theorem 3.3. Note that this implies that on hyper­cubes 
the quasirandom approach is provably not worse than the randomized rounding di.usion algorithm. Theorem 
3.3. There is an initial load vector of the d-dimensional hypercube such that the deviation of the randomized 
rounding di.usion algorithm and the ideal­ized process is at least O(logn)with probability 1-o(1). For 
the torus graph the following Theorem 3.4 shows that the deviation between the randomized roundingdi.usion 
algorithm andthe continuousprocess is not a constant(in contrast to our newquasirandom di.usion model). 
Theorem 3.4. There is an initial load vector of the d-dimensional torus graph with n vertices such that 
the di.erence between the randomized rounding di.usion algorithm and the idealized process is O(polylogn)with 
probability 1-o(1). 4 Basic method to analyze our quasirandom algorithm Tobound runtime anddiscrepancy 
of aBED algorithm, we always bound the deviation between the continuous model and the discrete model 
which is an important measure on its own. For this, let xl (t) denote the load (t) on vertex lin step 
t inthediscrete model and .denote l the load on vertex l in step t in the continuous model. As derived 
in Rabani et al. [23], this can be written as (t)(t) 't-1(t-s) (4.1) x-.= ' (Ps -Ps ). ll s=0 [i:j].E 
ei,j i,l j,l where[i : j]refers to an edge {i,j}. E with i<j. It willbesu.cienttobound equation(4.1) 
asthe idealized process is well understood by means of the following result. Theorem 4.1. (e.g., [23, 
Thm. 1]) On all graphs with second largest eigenvalue in absolute value .2 = .2(P), the idealized process 
with divisible to­kens reduces an initial discrepancy K to e within 2 ln (Kn2 ) rounds. 1-.2 e As .2 
=1 - T(log-1 n) for the hypercube and -2/d) .2 =1-T(nfor the d-dimensional torus [10], one immediately 
gets the following corollary. Corollary 4.2. The idealized process reduces an initial discrepancy of 
K to 1 within O(n2/d log(Kn)) rounds on the d-dimensional torus and within O(logn log(Kn))rounds on the 
hypercube. An important observation for all examined graph classes will be the unimodality or log-concavity 
of certain transitionprobabilities. Afunction f: N . R=0 is log-concave if f(i+1)2 = f(i)· f(i+2)for 
all i . N.A function f: N . R is unimodal if there is a t1 . N such that f|x=t1 as well as f|x=t1 are 
monotone. Note that log-concavityimplies unimodality and that(in contrast tounimodality)log-concavityispreserved 
undercertain operations, e.g., under convolution [15]. Our interest in unimodality is based on the following 
lemma. Lemma 4.3. Let f: X . R be non-negative with X . R. Let A0,...,An . R and t0,...,tn . X such that 
··· and |'b Ai| k for all 0 ab n. t0 tni=a If f has l local extrema, then ' n Ai f(ti) = (l+1)k· maxx.X 
f(x). i=0 Random Walks. To examine the di.usion pro­cess, it will be useful to de.ne a random walk based 
on P. For any pair of vertices u,v, Pt is the proba­ u,v bility that a random walk guided by P starting 
from u is located at v at step t. In Section 5 it will be useful to set Pu,v(t):= Pu,v t and to denote 
with fu,v(t)for u= v the .rst-passage probabilities, that is, the probability that a random walk starting 
from u visits the vertex v at step t for the .rst time. 5 Analysis on the hypercube In this section weprovethefollowingboundfordi.usion 
on the d-dimensional hypercube with n =2d vertices. Theorem 5.1. For all initial load vectors on the 
d-dimensional hypercube with n vertices, the deviation between the idealized process and a discrete process 
with accumulated rounding errors at most . is O(.logn)at all times. Moreover, there are load vectors 
for which this deviation is at least log n for all time steps. With Theorem 4.1 it follows that any BED 
algo­rithm (and in particular our quasirandom algorithm) reduces the discrepancy of any initial load 
vector with discrepancy K to O(logn) within O(logn log(Kn)) rounds. Log-concave passage time on paths. 
To prove Theorem 5.1, we .rst consider a discrete-time random walk on apath P =(0,1,...,d)starting at 
node0. Our analysis should be compared with Keilson s analysis of the continuous-time process [15]. We 
make use of a special generating function, called z-transform. The z-transform of a function g: N . R=0 
is de.ned by '8-i G(z)= · z. We will use the fact that a i=0 g(i)convolution reduces to multiplication 
in the z-plane. Our analysis also uses the geometric distribution with parameter p, which is de.ned by 
Geo(p)(t)= (1- p)t-1p for t> 0 and Geo(p)(0) = 0. It is easy to check that Geo(p) is log-concave. Moreover, 
the '8-i z-transform of Geo(p)isGeo(p)(i)· z= p i=1 z-(1-p). For each node i .P, let µi be the loop probability 
at node i and .i be the upward probability, i.e., the probability to move to node i+1. Then, the downward 
probability at node i is 1 -µi -.i. We can assume that .i > 0 for all i . P\{d}. We are interested in 
the .rst-passageprobabilities f0,d(t). Observe that (5.2) f0,d(t)=(f0,1 * f1,2 * ··· * fd-1,d)(t). In 
the following, we will show that f0,d(t)islog-concave. Indeed, we show a much stronger result: Theorem 
5.2. Consider a random walk on apath P = (0,1,...,d) starting at node 0. If µi = 1 for all nodes 2 i 
.P, then f0,d can be expressed as convolution of d independent geometric distributions. As the geometric 
distribution is log-concave we imme­diately get the following corollary. Corollary 5.3. Consider a random 
walk on a path P =(0,1,...,d) starting at node 0. If µi = 1 for all nodes i .P, then f0,d(t)is log-concave 
in t. Beforeproving the theorem, we will showhow to obtain f0,d(t)by a recursive argument. Suppose, we 
are at node i . P\{d}. The next step is a loop with probability µi. Moreover, the next subsequent non-loop 
move ends at i + 1 with .i probability and at i-1 with probability 1-.i -µi . 1-µi 1-µi .i Thus, for 
all i . P\{d}, fi,i+1(t)= · Geo(1- 1-µi 1-.i -µi µi)(t)+ · (Geo(1- µi)* fi-1,i * fi,i+1)(t), with 1-µi 
.i 1-µi corresponding z-transform Fi,i+1(z)= · + 1-µi z-µi 1-.i -µi 1-µi · ·Fi-1,i(z)·Fi,i+1(z). Rearranging 
terms 1-µi z-µi yields .i (5.3) Fi,i+1(z)= , z -µi -(1-.i -µi)·Fi-1,i(z)  for all i . P \{d}. So Fi,i+1(z)is 
obtained recursively with F0,1(z)= .0 . Finally the z-transform of z-(1-.0 ) (5.2) is F0,d(z)= F0,1(z)·F1,2(z)· 
... ·Fd-1,d(z). In the following, we state some properties of Fi,i+1(z)for i . P \{d}. Lemma 5.4. Except 
for singularities, Fi,i+1(z) is monotone decreasing in z. Lemma 5.5. Fi,i+1(z)has exactly i+1 poles which 
are all in the interval (0,1). The poles of Fi,i+1(z) are distinct from the poles of Fi-1,i(z). Lemma 
5.6. Let (bj,i)ij=0 be the poles of Fi,i+1(z) and de.ne Pi(z)= ni (z -bj,i). Then j=0 Pi-1(z) Fi,i+1(z)= 
.i · . Pi(z) We are now ready to prove Theorem 5.2. Proof of Theorem 5.2. By Lemma 5.6, we get d-1d-1 
Pi-1(z) F0,d(z)= Fi,i+1(z)= .i · Pi(z) i=0 i=0 nd-1 d-1i=0 .i 1-bi,d-1 == Kd · ,Pd-1(z) z -bi,d-1 i=0 
where(bi,d-1)d-1 are the poles of Fd-1,d(z) as de.ned i=0 nd-1 .i in Lemma 5.6 and Kd = . By Lemma 5.5, 
i=0 1-bi,d-1 1-bi,d-1 bi,d-1 . (0,1)for all i. Nowforeach i the term z-bi,d-1 is the z-transform of the 
geometric distribution with parameter 1-bi,d-1, i.e., Geo(1-bi,d-1)(t). Thus, f0,d(t) can be expressed 
as the convolu­tion of d independent geometric distributions f0,d(t)= Kd · [Geo(1- b0,d-1)* Geo(1- b1,d-1)* 
... * Geo(1- bd-1,d-1)](t). Moreover, since f0,d is a probability dis­tribution over t and the convolution 
of probability dis­tributions is again a probability distribution, we have Kd =1. The theorem follows. 
Unimodal transition probabilities on the hypercube. Projecting the random walk of the d­dimensionalhypercube 
to a random walk on apathwith d nodes, Theorem 5.2 implies the following. Theorem 5.7. Let u,v . V be 
two vertices of a d­dimensional hypercube. Then fu,v(t)is log-concave. Proof. We will use the following 
projection of a ran­dom walk on a hypercube to a random walk on a path (also known as Ehrenfest-chain 
[12]). More precisely, instead of a random walk on {0,1}d we consider the induced random walk on the 
smaller state space [0,d]. The induced randomwalk isobtainedfromthemapping x .|x|1, so, vertices in {0,1}d 
with the same number of ones are equivalent. It is easy to check that this new random walk is a random 
walk on a path with vertices d-k 0,1,...,d that moves up with probability .k =, 2k d down with probability 
µk = and loops with proba­ 2k bility 12 . Now .xtwoverticesu,v ofthe d-dimensionalhyper­cube. By symmetry, 
we may assume that u =0d = 0. Conditioned on the event that the projected random walk reaches a vertex 
with |v|1 ones at step t for the .rst time, every vertex with |v|1 ones is equally likely to be visited. 
This gives f0,v(t)= f0,|v|1 (t)/( d ), and the |v|1 log-concavity of f0,|v|1 (t)(by Theorem 5.2) implies 
the one of f0,v(t), as needed. Lemma 5.8. For any transition matrix P with non­negative eigenvalues, 
Pu,u(t)is monotonedecreasing for any u . V. Proof. Let A be the adjacency matrix of G, and let D be the 
diagonal matrix with Di,i = deg(i). Let v1,...,vn are the eigenvectors of D1/2AD-1/2 of unit­length with 
corresponding eigenvalues .1,...,.n. With these notations, the spectral representation oftransition probabilities(cf. 
[17,p.15])gives n deg(v) Pt n .t u,v = kvkuvkv. deg(u) k=1 For u = v, vkuvkv 0. Since by assumption, 
all n eigenvalues are non-negative, it follows that Pt is u,u monotonously decreasing in t, as desired. 
From Theorem 5.7 and Lemma 5.8 we derive: Theorem 5.9. Let u,v . V be two vertices of a d­dimensional 
hypercube. Then, Pu,v(t)is unimodal. Proof. Recall that Pu,v can be expressed as a convolu­tion(cf. [12]) 
of P and f as follows, Pu,v = fu,v * Pv,v. By Theorem 5.7, fu,v(t) is log-concave. Since the con­volutionof 
any log-concavefunctionwith any unimodal function isagainunimodal, itremainstoprovethatPv,v is unimodal. 
For loopprobabilitiesat least1/2, all eigenvalues of P are non-negative. Hence Pv,v is monotonedecreasing 
by Lemma 5.8. The claim follows. With more direct methods, one can prove the fol­lowing supplementary 
result that gives further insights into the distribution of Pu,v(t). Remark 5.10. If u and v are vertices 
with dist(u,v) d/2, then Pu,v(t) is monotone increasing. Analysis of the discrete algorithm. We are 
now ready to prove our main result for hypercubes. Proof of Theorem 5.1. For convenience, we label each 
vertex of the hypercube by a bit vector v =(vi)d of i=1 length d, such that the labels of neighboring 
vertices di.er by exactly one bit. By symmetry, it su.ces to bound the deviation at the vertex 0 = 0d 
. Hence by equation(4.1) wehavetobound (t)(t)(t-s) x-.'t-1 ' 00 s=0 [i:j].E ei,j (P0,i(s)-P0,j(s)) 't-1(t-s) 
s=0 ' [i:j].E ei,j P0,i(s)+ 't-1(t-s) ' [i:j].E ei,j P0,j(s). s=0 Combining Theorem 5.9 and Lemma 4.3 
we have (t)(t) 't-1(t-s) x-.2 ' 00 [i:j].Es=0 ei,j P0,i(s) t-1 (5.4) 4. ' [i:j].E max s=0 P0,i(s). To 
bound the last term, we view the random walk as the following process. In each step t . N we choose a 
coordinate i .{1,...,d}uniformly at random. Then with probability 1/2 we .ip the bit of this coordinate; 
otherwise we keep it (equivalently, we set the bit to 1 with probability 1/2 and to zero otherwise). 
Now wepartition the random walk sdistribution at step t according to the number of di.erent coordinates 
chosen(not necessarily .ipped) until step t. Consider P0,x(t). Since(i) the k chosen coordinates must 
contain the .rst |x|= |x|1 onesand(ii) all k chosen coordinates must be set to the correct value, we 
have P0,x(t)= and the .rst claim of the theorem follows. The second claim follows by the following simple 
construction. De.ne a load vector x(0) such that (0) (0) xv = d for all vertices v with v1 = 0, and xv 
=0 otherwise. Then for each edge {i,j}. E with0 = i1 = j1 the fractional .ow at this edge at step 1 is 
(0) (0) 1 (Pi,jx-Pi,jx) =+2 . Since in the .rst round no ij rounding errors have been occured so far, 
each edge is allowedto round up anddown arbitrarily. Hence we can (1) let all these edges round towards 
j, i.e., F:= 1 for i,j each such edge {i,j}.E.Byde.nition,this impliesfor the corresponding rounding 
error, e(1) = 2. Moreover, i,j wehavethefollowing loaddistributionafterstep 1. We (1) (1) have xv = 0 
for all vectors v if v1 = 0, and xv = d otherwise. Similarly, the fractional .ow for each edge (0) (0) 
{i,j}.E with0 = i1 = j1 is (Pi,jx-Pi,jx) = - 1 . ij 2 (1) (s) (2) -1 Since e= 2, |'2 |will be minimized 
if e= i,j s=1 ei,j i,j 1 2 . Now it follows by de.nition of our quasirandom algorithm that the .ow on 
each such edge {i,j}. E will be -1. This implies that we end up in exactly the same situation as at the 
beginning: the load vector is the same and also the sum over the previous rounding errors along each 
edge is zero. We conclude that there is an instance of the quasirandom algorithm for which x(t) = x(tmod2) 
which gives the claim. 6 Analysis on the d-dimensional torus In this section we prove the following bound 
for di.u­sion on the d-dimensional torus with n vertices. For v simplicity, we assume d n . Z. 'd Pr 
[exactly k coordinates chosen in t steps]· 2-k· k=0 (d-|x|).(d). Using this to estimate P0,i(s), we can 
k-|x|k bound equation(5.4) by (t)(t) |x-.| 00 t-1 4. ' [i:j].E max s=0 P0,i(s) n n 8 4. logn max P0,i(s) 
s=0 i=1 8 =4. log n 'd (d) max'd l=0 ls=0 k=0 Pr [exactly k coordinates chosen in s steps] · 2-k(d-l).(d) 
k-lk 4. logn 'dl=0 maxd 2-k(d-l)(d).(d) k=0 k-llk The fraction in the last term corresponds to the prob­ability 
of a hyper-geometric distribution and is 0 for k<l and in general is trivially bounded above by 1. This 
allows us to conclude that (t)(t) 'd 2-x |x-. | 4.d 8.d d d Theorem 6.1. For all initial load vectors 
on the d-dimensional torusgraph with n vertices, the deviation between the idealized process and a discrete 
process with accumulated rounding errors at most . is O(.) at all times. 2/d) With Theorem 4.1 and (1 
- .2)-1 = T(nit followsthatanyBED algorithm(and inparticularour quasirandom algorithm) reduces the discrepancy 
of any initial load vector with discrepancy K to O(1) within O(n2/d log(Kn))rounds. Proof of Theorem 
6.1. Bysymmetry ofthe torusgraph, wehave Pi,j = Pi-j,0. Hence we set Pi = Pi,0. We will .rst reduce the 
random walk on the .nite d-dimensional torus to a random walk on the in.nite grid Z2d . To this end, 
let Pi,j be the transition probability from i to j on Z2d de.ned by Pi,j =1/(2d) if |i - j|1 =1 and 0 
otherwise. The additional dimensions are used to encode the loops of G by projecting the .rst d v coordinates 
of Z2d to {1,..., n }d . vv Let Pi = P0,i. We 0 0 x=0 set H(i) :=(i1 + nZ,...,id +nZ,Z,..., Z) . Z2d 
 s for i =(i1,...,id). V. We observe Ps = ' P ik.H(i)k for all s and i . V. We will also frequently use 
that Z2d = H(i)is a disjoint union. i.V Let ARR = {±el |l .{1,...,d}}. Z2d with el beingthel-th unitvector. 
Itagainsu.cesby symmetry to bound the deviation at the vertex 0 = 0d . From equation(4.1) weget t-1 (t)(t)(t-s) 
x-.= nn n e(Psi -Ps ) 00 i,i+zi+z s=0 i.Vz.ARR t-1 (t-s) ss nnn nn = ePP . i,i+zk - ls=0 i.Vz.ARR k.H(i) 
l.H(i+z) ss Note that ' Pl = ' Pl+.(z) with .(z)= l.H(i+z)l.H(i)(z1,...,zd,0,..., 0) . Z2d for z . V 
and therefore we obtain (t)(t) x-. 00 t-1 nn nn (t-s) (P ss ) (6.5) = ek -P . i,i+zk+.(z)i.Vz.ARR k.H(i)s=0 
The inner sum can be easily bounded by a constant for any .xed k . Z2d by a local central limit theorem 
from [16, p. 14]. Therefore we can ignore k =0 in the remainder of the proof and proceed by .xing a C1 
k 2 cuto.point T(k):= ln2 ( k 22 ) of the inner sum for some su.ciently small constant C1 > 0. For sT(k), 
the summands of equation(6.5) canbeboundedby T(k) (t-s) ss nnnn (P ) e i,i+zk -Pk+.(z)i.Vz.ARR k.H(i) 
s=0 T(k) ss nn nn(P ) (6.6) k + P . k+.(z)i.Vz.ARR k.H(i) s=0 It isknown(seee.g.[16,p.29])thatforrandomwalks 
on in.nite grids there is a constant C2 > 0 such that s k 2 - z 2 P C2 exp( -v ) for all s> 0, k . Z2d 
, k s z . ARR. Plugging this into equation(6.6) we obtain that T(k) (t-s) ss nnnn (P ) e i,i+zk -Pk+.(z) 
i.Vz.ARR k.H(i) s=0 T(k) k 2 - z 2 nn nn 2C2 exp-v s i.Vz.ARR k.H(i) s=0 T(k) k 2 -1 nn =2dC2 exp-v 
 . s k.Z2d s=0 Boundings byT(k), we obtainthatfor su.ciently small C1 > 0, T(k) ss nn nn (t-s)(P ) ek 
-P i,i+zk+.(z) i.Vz.ARR k.H(i) s=0 T(k)  ) ( k 2 -1) nn v = Oexp( -ln( k 2) C1 k 2 k.Z2d s=0 T(k) 
-(2d+4) nn = O k 2k.Z2d s=0 k -(2d+2) 2 n = O= O(1). ln2( k 2) k.Z2d To bound the summands of equation 
(6.5) with s T(k), we approximate the transitionprobabilities ofZ2d with the multivariate normal distribution 
d d -d k 2 k :=2 exp . PPt pt t 2 This is done by a local central limit theorem from [16, p. 14], ss 
(P ) -Ps Ps ) (P k -Pk+.(z)k - Pk+.(z) -(2d+1)/2). = k -2 O(s 2 Hence t-1 (t)(t)(t-s) nn nn x-.= e 00 
i,i+z i.Vz.ARR k.H(i)s=0  (PPs -(2d+1)/2) (6.7) + k -2 O(s. Psk - Pk+.(z))2 B A A A C k 2 For sT(k)= 
2 we can bound the sum of ln2 ( k 2 ) term B by t-1 nnn n (t-s) -(2d+1)/2) e k -2 O(s i,i+z2 i.Vz.ARR 
k.H(i)s=T(k) t-1 -(2d+1)/2 = Od n k -2 n s 2 k.Z2ds=T(k) n k -2T(k)-(2d-1)/2 = O 2 k.Z2d ln2d-1( 
k 2) n = O= O(1), k 2d+1 k.Z2d 2 where the last equality follows from the observation -(d+e) ' k = 
O(1) for constants d 1 and =k.Zd 0.2 e> 0. To .nally bound the sum of term A in equa­tion(6.7) we usetwofactsfrom 
[3]. They showed that Ps Ps only has a constant number of local ex- Pk - Pk+.(z) -(2d+1) trema and can 
be bounded by O( k ). As for 2 (t) BED algorithms we have |'t | ., applying s=1 ei,j Lemma 4.3 yields 
t-1 (t-s)() nn nn Ps Ps e i,i+z Pk - Pk+.(z) i.Vz.ARR k.H(i)s=0 t-1 nnn (Ps Ps ) = O . max k - Pk+.(z) 
s=0 P i.Vz.ARR k.H(i) nn n . k -(2d+1) = O i.Vz.ARR k.H(i) k -(2d+1) = O .d n = O(.). k.Z2d Combiningour 
upperbounds onthe sums ofterm Aand (t)(t) B in equation(6.7) we can concludethat x-.= 00 O(1)+O(1)+O(.)= 
O(.), meaningthat thedeviation between the idealized and our process at any time and at any vertex is 
at most O(.). 7 Conclusions We propose and analyze a new deterministic algorithm forbalancingindivisibletokens.Byachieving 
aconstant discrepancy in optimal time on all torus graphs, our algorithm improvesuponallpreviousdeterministicand 
random approaches with respect to both running time anddiscrepancy. Forhypercubes weprove adiscrepancy 
of T(logn) which is also signi.cantly better than the deterministic algorithm of Rabani et al. [23] which 
achieves a discrepancy of O(log2 n). On a concrete level, it would be interesting to extend these results 
to other network topologies. From a higher perspective, our new algorithm provides a striking example 
of quasirandomness in algorithmics. Devising and analyzing similar algorithms for other tasks such as 
routing, scheduling, synchronization, etc. remains an interesting open problem. References [1] W.Aiello,B.Awerbuch,B.M.Maggs,andS.Rao. 
Approximate loadbalancing ondynamicand asyn­chronous networks. In 25th Annual ACM Sym­posium on Theory 
of Computing (STOC 93), pp. 632 641, 1993. [2] R. D. Barve, E. F. Grove, and J. S. Vitter. Simple randomized 
mergesort on parallel disks. Parallel Computing, 23:601 631,1997. [3] J. Cooper and J. Spencer. Simulating 
a random walk with constant error. Combinatorics, Probabil­ity &#38; Computing, 15:815 822, 2006. [4] 
G. Cybenko. Load balancing for distributed mem­ory multiprocessors. Journal of Parallel and Dis­tributed 
Computing, 7:279 301, 1989. [5] P. Diaconis, R. Graham, and J. Morrison. Asymp­totic analysis of a random 
walk on a hypercube with manydimensions. Random Structures and Al­gorithms, 1:51 72, 1990. [6] B. Doerr, 
T. Friedrich, and T. Sauerwald. Quasirandom rumor spreading. In 19th Annual ACM-SIAM Symposium on Discrete 
Algorithms (SODA 08), pp. 773 781, 2008. [7] R. Els¨asser, B. Monien, and S. Schamberger. Dis­tributing 
unit size workload packages in heteroge­nous networks. Journal of Graph Algorithms &#38;Ap­plications, 
10:51 68, 2006. [8] T. Friedrich and T. Sauerwald. Near-perfect load balancing by randomized rounding. 
In 41st An­nual ACM Symposium on Theory of Computing (STOC 09), pp. 121 130, 2009. [9] J. Gehrke, C. 
Plaxton, and R. Rajaraman. Rapid convergenceof a local loadbalancing algorithmfor asynchronous rings. 
Theoretical Computer Science, 220:247 265,1999. [10] B. Ghosh and S. Muthukrishnan. Dynamic load balancing 
by random matchings. Journal of Com­puter and System Sciences, 53:357 370, 1996. [11] B. Ghosh, F. T. 
Leighton, B. M. Maggs, S. Muthukrishnan, C. G. Plaxton, R. Rajaraman, A. W. Richa, R. E. Tarjan, and 
D. Zuckerman. Tight analyses of two local load balancing algo­rithms. SIAM Journal on Computing, 29:29 
64, 1999. [12] G. Grimmet and D. Stirzaker. Probability and Random Processes. Oxford University Press, 
3rd edition, 2001. [13] G. Jan and Y. Hwang. An e.cient algorithm for perfect load balancing on hypercube 
multipro­cessors. The Journal of Supercomputing, 25:5 15, 2003. [14] S. Karlin, B. Lindqvist, and Y.-C. 
Yao. Markov chains onhypercubes: Spectral representations and several majorization relations. Random 
Structures &#38; Algorithms, 4:1 36, 1993. [15] J. Keilson. Markov Chain Models -Rarity and Exponentiality. 
Springer Verlag, 1979. [16] G. Lawler. Intersections of random walks. Proba­bility and its Applications. 
Birkh¨auser, 1991. [17] L. Lov´asz. Random walks on graphs: A survey. Combinatorics, Paul Erd.os is Eighty, 
2:1 46,1993. [18] L. Lov´asz and P. Winkler. Mixing of random walks and other di.usions on a graph. Surveys 
in combinatorics, pp. 119 154, 1995. [19] B. Morris and A. Sinclair. Random walks on trun­cated cubes 
and sampling 0-1 knapsack solutions. SIAM Journal on Computing, 34:195 226,2004. [20] R. Motwani and 
P. Raghavan. Randomized Algo­rithms. Cambridge University Press, 7th edition, 1995. [21] S. Muthukrishnan, 
B. Ghosh, and M. H. Schultz. First-and second-orderdi.usive methodsfor rapid, coarse, distributed load 
balancing. Theory of Computing Systems, 31:331 354,1998. [22] C. Plaxton. Load balancing, selection sorting 
on thehypercube. In 1st ACM Symposium on Parallel Algorithms and Architectures (SPAA 89), pp. 64 73, 
1989. [23] Y. Rabani, A. Sinclair, and R. Wanka. Local divergence of Markov chains and the analysis of 
iterative load balancing schemes. In 39th Annual IEEE Symposium on Foundations of Computer Science(FOCS 
98), pp. 694 705, 1998. [24] R. Subramanian and I. D. Scherson. An analy­sis of di.usive load-balancing. 
In 6th ACM Sym­posium on Parallel Algorithms and Architectures (SPAA 94), pp. 220 225, New York, NY, 
USA, 1994. ACM. [25] S. Surana, B. Godfrey, K. Lakshminarayanan, R. Karp, and I. Stoica. Load balancing 
in dy­namic structured peer-to-peer systems. Perfor­mance Evaluation, 63:217 240, 2006. [26] R. D. Williams. 
Performance of dynamic load bal­ancing algorithms for unstructured mesh calcula­tions. Concurrency: Practice 
and Experience, 3: 457 481, 1991. [27] D. Zhanga, C. Jianga, and S. Li. A fast adaptive load balancing 
method for parallel particle-based simulations. Simulation Modelling Practice and Theory, 17:1032 1042,2009. 
			