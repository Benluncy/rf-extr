
 iSlideShow: A Seamless and Dynamic Slideshow System with Content­based Transitions Jiajian Chen Jun 
Xiao*, Yuli Gao* Georgia Institute of Hewlett-Packard Technology Laboratories Figure 1: Two consecutive 
frames animated by a water-dropping transition in the person-highlighting mode. The transition is generated 
based on the ROIs, which are detected face areas in the red circles in this example. 1 Introduction 
We present a photo slideshow system that automatically analyzes thematic information about the photo 
collection and utilizes such information to generate compositions and transitions in two modes: story-telling 
mode and person-highlighting mode. In the story-telling mode the system groups photos by a theme-based 
clustering algorithm and photos in each theme cluster are seamlessly tiled on a slide. Multiple tiling 
layouts are generated for each theme cluster and the slideshow is animated by intra­cluster transitions. 
In the person-highlighting mode, the system first recognizes faces from photos and creates photo clusters 
for individuals. It then uses face areas as ROI (Regions of Interests) and creates various content-based 
transitions to highlight individuals in a cluster. With an emphasis on content awareness, our system 
creates slideshows with more fluid, dynamic and visually pleasing structure compared to existing tiling 
slideshows [Chen06] and photo-to-video [Hua04] systems. Finally, the rendering of the slideshow is implemented 
in GPU, which significantly decreases the creation time of the slideshow and improves its quality. 2 
 Story-Telling Mode In the story-telling mode we group photos to theme clusters by computing the time, 
color and face distance among photos. We use BRIC layout engine to compute the tiling layout [Atkin08]. 
We compute a sequence of layouts for each theme cluster with increasing number of photos, and use intra-cluster 
transitions to animate these layouts, as shown below. Alpha blending is used to remove photo boundaries 
in the result tiling slideshow.  Figure 2: A 4-photo theme cluster animated by intra-cluster transition 
that simulates zooming and panning e-mail: jchen30@mail.gatech.edu *e-mail: Jun.xiao2@hp.com, yuli.gao@hp.com 
 3 Person-Highlighting Mode and Content Based Transitions with ROIs In the person-highlighting mode 
we first detect a list of ROIs such as faces and associate them with each photo. To animate two consecutive 
frames, we use OpenGL to render the photos as textures to screen quads. To produce the transition that 
changes with ROIs, we treat the pixels inside and outside ROIs differently by distorting (offsetting) 
the texture coordinates of pixels in the photo. The normalized texture coordinate of a pixel in a photo 
is (x,y), where 0<=x,y<=1. In the 2D space, the distortion is a 2×1 vector, which is defined as follows. 
.. .-.. .xxc . )ei. Distortion () , = x =t xy .. f. .=(t f ... yyc . .-.y . .. . . (xc, yc) is the ROI 
center. The vector f is the distortion speed for that pixel (x,y). We choose the following f to obtain 
the water­dropping effect in Figure 1. . ..d 5 The direction of f is (x-xc, y-yc), d ( ) ..( 0 ) is the 
Euclidean distance between sin kd d <r .p f =. r0 . .. the pixel and the ROI center. ro is . ( )( p otherwise 
) sin kd the ROI radius. We execute the following steps in the GPU shader: 1. For each pixel in the 
current photo, use D(x,y)=tf (t:0.1) to compute the offset vector D, and then add it to its texCoord. 
 2. Repeat (1) with reversed time (t: 1.0) for the next photo. 3. Linearly blend the two resulting photos 
based on transition time to achieve the final effect.  Choosing a proper distortion function can create 
effects such as spotlighting and water-flowing. If the normalized ROIs in two consecutive photos are 
not aligned, we can either scale and align ROIs (as shown above), or move the ROIs on the photos. The 
movement of ROI creates an effect that a camera focus is fluidly moving toward the highlighting area 
from frame to frame. The moving trajectory could be a curve or line, and the inter-frame ROI size can 
be decided by a linear interpolation. 4 References ATKINS, C. B. Blocked recursive image composition. 
In ACM Multimedia 2008. CHEN, J. C., CHU, W. T., KUO, J. H., WENG, C. Y. AND WU, J. L. Tiling Slideshow. 
In ACM Multimedia 2006. HUA, X. S., LU, L. AND ZHANG H. J. Photo2Video - A System for Automatically Converting 
Photographic Series into Video. In ACM Multimedia 2004. Copyright is held by the author / owner(s). SIGGRAPH 
Asia 2009, Yokohama, Japan, December 16 19, 2009. ISBN 978-1-60558-858-2/09/0012  
			