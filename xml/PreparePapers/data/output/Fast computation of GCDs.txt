
 FAST COMPUTATION OF GCDs R.T. Moenck Department of Computer Science University of Toronto f An integer 
greatest common divisor i.e., ao,al,...,ak, l~k (GCD) algorithm due to SchSnhage is genera- lized to 
hold in all euclidean domains where "degree" of (ai) > "degree" of (aj), which possess a fast multiplication 
algo- O~i~j~k and A = ao, B = a I gives GCD rithm. It is shown that if two N preci- sion elements 
can be multiplied in (A,B) = a k. O(N log a N), then their GCD can be com- This remainder sequence 
is defined by puted in O(N log a+l N). As a consequence, the successive divisions: a new faster algorithm 
for multivariate polynomial GCD's can be derived and with a 0 = alq I + a 2 that new bounds for rational 
function manipulation. a 1 a2q 2 + a 3 (1) INTRODUCTION ) The problem of computing greatest ak_ 1 = 
ak.qk common divisors has recently received con- where a k is the GCD of A and B. siderable attention. 
There are several reasons for this: The Extended Euclidean Algorithm can i) The polynomial GCD routine 
is one of also be defined for members of euclidean the most critical in any symbolic mathema- domains 
by defining two sequences of tical system. inverses {s i} and {ti}, 2) The GCD process is intimstely 
con- nected with many fields of mathematics, where s o = i, s I = 0 including continued fractions, 
diophantine equations, bigradients, sturm sequences t o = 0 and t I = 1 and elimination theory. 3) 
GCD's are interesting by themselves from an algorithms viewpoint. The multi- and s 2 = s O slq I variate 
polynomial problem was originally thought to be exponential. But work by t 2 = tq -tiq I Collins [6] 
and Brown [4] has shown it to where ql is defined in eq (i). be polynomial. Fast integer GCD's were 
 first considered by Knuth [2] and improved In general the following recurrance by Sch~nhage El] to 
give a relations hold: O(N log 2 N log log N) algorithm. si+ I = si_ I -siq i[ This paper generalizes 
the work of l~i~k. SchSnhage to euclidean domains with a fast ti+ 1 ti- 1 tiq i J multiplication algorithm. 
Consequences of this extension in the context of multiva- Thus the extended euclidean algorithm riate 
polynomial GCD's and rational func-is then defined by the 3 recurrance tion manipulations are explored. 
relations: I The Extended Euclidean Algorithm ai+l = ai-i -aiqi I l~i~k For a euclidean domain D, Euclid's 
(2) si+ I = si_ 1 siq i algorithm computes the GCD of two elements A,B by computing the remainder 
sequence ti+ I = ti_ I -tiq i J (RS) of A and B, and at the k th step ak+ 1 = 0. t 6 = 6xS+9x4+14x3+llx+6 
 i=7: a 7 = 2x+3 q7 = llx+ll s 7 = 10xS+gx4+gxS+16x2+3x t 7 = 7x6+SxS+4x4+4x3+lSx2+14x+5 i=8: a 8 
= 5 s 8 = 9x6+12xS+5x3+14x2+2x+7 t 8 = 8x7+Sx6+lOxS+6x4+9x5+4x2+6x+2 II Notions of Precision In order 
to standardize notation for the various domains of interest, we shall require of the degree function 
d(A) of the domain that: d(A×B) = d(A) + d(B). In particular, we have: if A is an integer and N d(A) 
= N [l°gzlAlJ if A is a polynomial and deg (A) = N. This means that for all the quotients {qi } as defined 
in eq (1). d(qi) ~ I, l~i~k (4) This leads to the following: Fact I: Euclid's algorithm requires (N~-i)/2 
operations irrespective of the efficiency of multiplication in the domain. Proof: l~e shall assume 
a model which per- ~--{+,-,*,÷} of single precision ele- ments. An independence argument shows that multiplication 
(and hence division) of an element with degree i by an element of degree 1 requires i steps. It is 
apparent that there exist remainder sequences for which d(a i) ~ N -i, 0;i~k where d(a 0) = N. This 
follows from considering the production of the sequence in reverse order (i.e., ak,...,al,a0). Thus the 
number of steps required to compute Euclid's algorithm is the time to compute the sequence {ai} , i.e., 
 k Tc(N,k) = [ (N-i) = Nk -k2/2 i=0 in particular Tc(N,N-1) = (N2-1)/2. It can be shown that the following 
relation holds true a i = sia 0 + tia I, 0~i~k. (3) Example l: To avoid awkward coefficients we shall 
consider examples in Z17[x ]. The remainder sequence defined by the two polynomials: A = x 8 + 1Sx 
S + x 4 + 2x 5 + 14x + 2 B = x 7 + 5x S + 16x 4 + 1Sx 3 + 5x + 4 is computed as follows using an Extended 
Euclidean algorithm. x8+isxS+x4+2x3+14x+2 0 1 0 x7+3xS+16x4+iSx3+Sx+4 x 0 1 14x6+16xS+sx4+2x3+12x2+10x+2 
 llx+2 1 16x 6xS+Sx4+iSxS+2x2+14x 8x+13 6x+15 llx2+2x+l Sx4+12x3+10x2+ISx+2 8x+9 3x2+6x+10 14x3+llx2+16x+4 
 14xS+13x2+16x+16 4x+2 10x3+10x2+Sx+10 7x4+Tx3+Sx2+13x+16 Sx2+4x+4 13x+16 llx4+8x3+2x2+x+7 z=0: a 
0 = qo = s O = t o = i=l: a I = ql = S 1 = t I = 1=2: a 2 = q2 = s 2 = t 2 = x=3: a 3 = q3 = s 3 = t 
3 = i=4: a 4 = q4 = s 4 = t 4 = x=5: a 5 = q5 = s 5 = t S = x=6: a 6 = q6 = s 6 = Since GCD's are important 
in many forms of computation, we are interested in faster methods than that provided by Euclid's algorithm. 
 III The R Matrices Equation (3) allows us to use a matrix notation due to Sch~nhage [I] : . (s) si+ 
1 ti+l Using this notation and relation (3) we have the relation a 0 We can extend the matrix notation 
to matrices R i'j, 0_<i<_j_<k as follows = . (7) aj+l ai+l The elements of the matrix RJ,i can be 
thought of as elements of the sequence of inverses of the remainder sequences which begin with a i and 
ai+ I. The following relation for 0_<i_<£_<j_<k can be shown RJ,0 = Rj,~,R ~,i (8) and in particular 
 RJ,0 = Rj,£,R£,0 (9) It follows from relations (2) that R j,i J (~ i ) , for j>i. = IT -q~ £:i IV 
"Normal" Remainder Sequences Frequently the quotients {qi } in the RS of eq (3) are small. In fact, 
if we are dealing with integer GCD's, it can be shown that the quotients are almost always "small". 
For example, assuming random inputs of u and v, the quotient [u/v] will be less than 1000 approxi- 
 mately 99.856 per cent of the time [3]. Similarly it can be shown that for polynomials, the degree 
of the quotient is most frequently i. Remainder sequences of such form are called "normal" [4]. This 
suggests that many of the O(N 2) steps in the computation of Euclid's algo- rithm are wasted, since at 
each step only a small amount of new information is produced. It should be noted that if the matrix 
 R k'0 can be calculated, then the GCD is obtained by a simple matrix-vector multi- plication. Namely 
 : , . (10) ak+ I a I Equation (2) shows that the elements of the R matrix depend solely on the sequence 
of quotients {qi } produced by the remainder sequence. This suggests a method for computing the GCD. 
Using the framework suggested in [5] we shall try for a "divide and rule" algorithm, i.e., we shall segment 
one problem into two parts and solve each part separately. The seg- mentation would be to use the factorization 
 of the matrix R k'0 given in eq (9), namely R k'0 : Rk'k/2*R k/2'0 (ii) If we assume that the degrees 
of the elements of the sequences {s i} and {t i} in eq (2) grow in some uniform manner, then the elements 
of the matrices R k'k/2 and R k/2'0 will have approximately the same degree. This will allow for balanced 
degree multiplication to make most efficient use of a fast multiplication algorithm. In particular we 
can show by induction on the degrees of the elements that: Lemma I: The degree of the elements of R 
I'~ is ~imj. We can also show a relationshiD between elements of the remainder sequence, namely Lemma 
2: d ) < (i-j) for <_. (aj _ d(ai) o_<1~_<] V The Ouotients As pointed out in the previous section, 
the quotients {qi ) contain the key to the R matrices. What we wish to know is how to obtain the quotients 
with little effort. In fact only a limited amount of the divisor and dividend need be investigated in 
order to uniquely determine the quotient. Lemma 3: Consider u = q.v + r. The quo- tient q (with d(q) 
= k ) is uniquely determined by the leading degree k oortion of the divisor v and the degree 2k portion 
of the dividend u. Proof: Let d(u) = n and d(v) = m :> ~q) : n -m. Let u = u I x D(n-2k) + u 2 v 
= v I x D(m-k) + v 2 where D(i) is some element of the domain st. d(D(i)) = i. Then d(u I) = 2k,  d(v 
1) = k, d(u z) < (n-Zk) and d(v2) < (m-k). Let O be the quotient of u 1 and v 1 i.e., u 1 = v 1 × Q + 
R 1 => d(R1) < k. Now consider the product of 0 and v sub-tracted from u. If this is of degree less than 
m, then we know that Q fits the conditions of a quotient of u and v. From algebra we know such quotients 
are unique. i.e., consider R = u -Qv = [UlXD(n-2k)+u2] -Q x [VlXD(m-k)+v2] = [Ul×D(n-2k)-QXVl×D(m-k)] 
+ [u2-qxv2]. Since k = n - m it follows that m-k = 2m-n = n-2(n-m) = n -2k. So R = [Ul-OVl]D(m-k ) + 
[u2-Qxv2]. Since d([Ul-QVl] ) < k and d(Qv2) < (m-k) + k = m and d(u2) < n -2k = m -k.  Thus it follows 
that d(R) < (m-k) + k = m and that Q is the unique quotient of u and v. Therefore we know that we 
can compute the quotient with incomplete information about the divisor and dividend. VI The Algorithm 
PGCD Using the above results we can now state an algorithm to compute the GCD of two elements A,B of 
a Euclidean domain D. As stated above we shall use the relation Rk,0 = Rk'k/2*Rk/2'0 (ii) We shall 
use two algorithms, one which  computes the matrices R N/2'0 called PGCD (partial GCD) and another algorithm 
EGCD which computes the matrices R N'0 using PGCD to compute RN/2'0,R 3N/4'N/2, R 7N/8'3N/4 etc. Algorithm: 
PGCD (A,B) Input: elements of the domain A,B with d(A) = N, d(B) = M Output: the matrix RN/2,0 = (SN/2 
tN/2 ) SN/2+l tN/2+l \aN/2+l  asis: --~n If d(A) begin Compute d(B) _< d(B) the quotient Q of and 
A B; otu o 2) end Recursion: R 1 = PGCD (A2,B2) where A 2 is the leading [N/21 part of i.e., A d(A2) 
= [N/2] B 2 is the leading part of B i.e., d(B2) = M -[N/Z]. This gives R 1 = R N/4,0 3) Multiplication: 
 where d(A') ~ d(A) - N/4 = 3/4N, d(B') ~ d(B) -N/4 = M -N/4 by lemma 2. 4) Test: If d(A') -d(B') < d(B') 
then return R I. (Do we have enough context  to determine the next quotient?) 5) Recursion: R 2 = PGCD 
(A½,B~) where A½ is the leading 2/3 of A' i.e., d(A½) = NI2 and B~ is the leading part of B' i.e., 
d(B~) = d(B') N/2. This gives R 2 = R N/2,N/4  6) Return: (R2*Ri). Analysis: For the purpose of analysis 
of the algorithm we shall assume that the remainder sequence is normal and d(A) = 2 n = N, d(B) = 2 
n -1 = M.  Let P(2 n) be the time to compute PGCD for such inputs. Let M(N) be the time to multiply 
two N degree elements (assumed O(N foe a N) ). This gives the time for P(2 n) as p(2 n) = 2P(2 n-l) 
+ 12.M(2 n) i.e., there are two recursive calls on PGCD, one matrix-vector and one matrix-matrix- product. 
Then n p(2 n) = 2n.p(2) + c.12,2 n ~ i a i=l = o(2nn a+l) = O(N log a+l N). This gives a bound on 
the time for part of the GCD computation. Example 2: We shall compute PGCD for the two polynomials given 
earlier in the exam- ple of the Extended Euclidean algorithm. i.e., A = x 8 + iSx 5 + x 4 + 2x 3 + 
14x + 2 B = x 7 + 3x 5 + 16x 4 + 15x 3 + 5x + 2 recursion level: 0 R : PGCD (A,B) ; 1 R 1 = PGCD (x4+15x+l,x3+3x+16); 
 2 Rii = PGCD (x2,x) 2 = R I = B' 16x x3+3x÷16 = ( x3÷3x+16 \14x2+16x+l) 2 R12 = PGCD (x2+3,14x+16) 
1 = (0 6x+15) i 2 Return ~0 1 )(0 1 )] 1 6x+1S 1 16x i 16x 1 1 R 1 = 6x+15 llx2+2x+i/  = (14x6÷16x5÷3x4+2x3÷12x2÷10x÷~ 
6xS+5x4+15x3+2x2+14x 1 1 R 2 = PGCD (14x4+16x3+3x2+2x+12, 6x3+Sx2+lSx+2) 2 R21 = PGCD (14x2+16x+3,6x+5) 
1 = (0 9x+4)I 2 = R I : " B' B \ Sx2+12x+3 2 R22 = PGCD (6x2+Sx+lS,Sx+12)  9x÷8 9x÷4 = ( I 9x+4 ) 
9x+8 13x2+6x+i5 1 Return [R2*R I] 3x2+6x+10 14x3+llx2+16x+4 1 0 R = \10x3+10x2+8x+10 7x4~7x3+5x2+13x+16 
j VII The Algorithm EGCD Now usin~ eq (ii) we obtain a general form of the GCD algorithm as follows: 
 Algorithm: EGCD (A,B); Input: the elements of the domain A,B where d(A) = N, d(B) = M Output: the Matrix 
R k'0 = ( sk tk \ / Sk+l tk+l asis: If d(A) -d(B) ~ d(B) --~n begincompute the quotient Q of A  and 
B return (~ _~) end 2) Call PGCD: R I = PGCO (A,B) yielding R 1 = R N/2'0 3) Multiplication: (~:) = 
R1 (~) 4) Test: 16 d(B') = 0 then return R I. 5) Recursion: R 2 = EGCD (A',B') yielding R 2 = R N'N/2. 
6) Multiplication: Return (R2-R I) Example 3: Applying EGCD to our example polynomials A and B we get: 
recursion level: 0 R = EGCD (A,B); 1 R 1 = PGCD (A,B) = ( 3x2+6x+10 14x3+llx2+16x+4 6) \10x3+10x2+8x+10 
7x4+7x3+Sx2+13x+l (By the previous example) A' 5x4+12x3+10x2+lSx+2 / 1 R 2 = EGCD (A',B') = PGCD (A',B') 
 2 R21 ( 1 13x+15 )/By a development, --~similar to the ] 4x+i x2+Sx+I5 \above. I  2 (A"I = A 5x2+4x+41 
2 R22 = EGCD (5x2+4x+4,2x+3) = (0 1 ) 1 6x+6 Return [R22*R21 ] 4x+l x2+Sx+15 ) 1 R 2 = \7x2+13x+7 6xS+2x2+14x+3 
 1 Return [Rz*Ri] 10xS+gx4+gx 7x6+8xS+4x4+4x3 \ +16x2+Sx +iSx2+14x+5 0 R = 9x6+12xS+Sx 3 8x7+5x6+lOxS+6x 
4 +14x2+2x+7 +9x3+4x2+6x+2 / Analysis: If we assume a normal remainder sequence, the elements of matrix 
 R 1 = R N/2'0 are of degree ~ N/2 (by lemma I). The degrees of the partial remainders A' and B' are 
bound by d(A') s N/2 and d(B') s N/2 -1 (by lemma 2). Similarly the maximum of the degrees of the elements 
of matrix R 2 = R N'N/2 is N/2 by lemma I. Let E(2 n) be the number of steps to compute EGCD for d(A) 
= 2 n and d(B) = 2 n -I, then E(2 n) = p(2 n) + E(2 n-l) + c12.M(2 n) = E(2 n-l) + k2nn a+l + cl2.2n.n 
a = E(2) + k n [ 2ii a+l i=l n + c12 ~ 2ii a i=l n : _< E(2) + (kna+l+12cn a) 2 i i=l = E(2) + (kna+l+12cna)(zn+l-1) 
a+l N). = O(N log 2 VIII Abnormal Remainder Sequences Until now we have based the analysis on normal 
remainder sequences. However, abnormal sequences do exist and must be accounted for. An abnormal sequence 
will manifest itself at the basis steps of the algorithms where a division must be per-formed. If the 
sequence is normal, the division will involve only a couple of small elements of the domain and so can 
be performed using the classical algorithm. However, if the sequence is abnormal, then a division with 
larger elements must be performed. The time for this division may affect the analysis of the algorithm. 
 If we assume that division is at least log reducible to multiplication in the domain (i.e. that division 
requires at most R(N) = O(N log a+l N) steps) then we can reanalyse the PECD algorithm as follows: 
 p(2 n) = 2n-mp(2 m) + c12.2 n ~ i a i=m where we assume that the degree of the quotients required is 
2TM. Using our assumption about the reducibility of division we have p(2 n) = 2n-m(2mm a+l) + c,12.2n(na+l-m 
a+l) Since m < n this gives: P(2 n) = o(2nn a+l) = O(N log a+l N). Knuth [3] describes an algorithm 
due to Cook for integer division which operates in the same time as integer multiplication. So the time 
will not change for integers. In thepolynomial case Strassen [ll] describes an algorithm for dividing 
polynomials in time directly proportional to the time for multiplication. Since the division algo- 
 rithm need only be log reducible, the algo- rithm described in [5] would also suffice. Thus the analysis 
is unaffected by abnormal remainder sequences. IX Summary This means that we can state the following: 
 Theorem l: For a Euclidean domain D the extended GCD of two elements of the domain A,B (where d(B) < 
d(A) = N ) can be com- puted in O(N log a+l N) steps, if multi- plication in the domain requires O(N 
log a N) steps and division is log reducible to multiplication. This leads immediately to: Corollary 
l: (SchSnhage) The GCD of two N digit integers can be computed in O(N log 2 N log log N) steps. Corollary 
2: The GCD of two univariate polynomials over a finite field can be computed in O(N log z N) steps. 
 This result assumes that polynomial multiplication requires O(N log N) total operations. However an 
alternative measure is one proposed by Ostrowski [12] which i47  counts only "active" multiplications, 
i.e. ones involving two variables or partial results. Under this measure polynomial multiplication requires 
only 2N + 1 mul- tiplications and so GCD's can be computed in O(N log N) multiplications. It is the 
impact of these corollaries which we shall investigate further. Multivariate Polynomial GCD's One consequence 
of these results is a new upper bound on computing multivariate polynomial GCD's. The problem here is 
to compute the GCD of two polynomials of degree N in each of V variables, and with coefficients S digits 
in length. The currently most efficient algorithm is one due to Brown [4] and Collins [6] which requires 
O(S2(N+i)V+vs(N+i) V+I) steps. Using the dense-polynomial dense-integer model of computation, it is easy 
to ~ee that to inspect such a polynomial requires S(N+i) V steps. That is, Fact 2: The number of steps 
required to compute the GCD of two such polynomials is at least S(N÷i) V. The proof follows trivially 
from indepen-dence considerations. The Brown-Collins algorithm follows the familiar pattern of algorithms 
which are based on homomorphisms. Namely, ~Bound the number of homomorphic images required. 2) Extract 
the next homomorphic image. 3) Solve the problem in the image domain. 4) "Invert" the homomorphic image 
of the answer. 5) Test whether sufficient image answers have been computed. If not then go to step 
2.  We know that such iterative processes may have their computation times intrinsi- cally bound by 
their mode of computation [7]. This suggests that any improvement on these algorithms would be found 
in per- forming some of thecomputation in paral- lel, or at least non-iteratively. We can reformulate 
the skeleton into a parallel algorithm as follows: Compute bounds on the number of required images. 
2) Extract all the homomorphic images required (simultaneously). 3) Solve the problem in all the image 
domains. 4) "Invert" all the homomorphic images (simultaneously). Here we have excluded the final step 
 of the first form. If we make a sufficient gain by computing and inverting homomor- phisms in Darallel 
then the parallel version of the algorithm mizht pay off. The two common forms of homomorDhism are : 
 i) The "modular" homomorDhism: for the domain of integers involving computation modulo a prime P where: 
a) computing the homomorphic imaEe corres- ponds to extracting the residue of an integer with resnect 
to a prime. b) inverting the mad corresponds to com- puting the Chinese Remainder Algorithm (CRA) for 
residues with respect to a prime. 2) The "evaluation" homomorphism: for a polynomial domain P[x] involving 
computa- tion modulo a polynomial x - b where: a) computin~ the image corresoonds to evaluating a polynomial 
at a point. b) inverting the map corresponds to inter- polating a polynomial at a Doint. XI Some Further 
Considerations Recently several fast algorithms have been developed to perform these processes. In [5], 
[9], [1O] and [ii] it has been shown that: I) N residues of an N precision inte- ger with respect to 
single digit primes. 2) The CRA for N residues with respect to N single digit primes. Z) The evaluation 
of an N th degree polynomial at N points. 4) The interpolation of an N th degree polynomial from N + 
1 points. All can be computed in at most O(N log 2 N) total operations in the polynomial case and O(N 
log 2 N log log N) total steps in the integer case. These will be useful "subroutines" in our algorithm. 
 Another consideration which must be borne in mind is the occurrance of "unlucky" homomorphisms. When 
these occur the answer derived in the image domain does not agree with the solution in the problem domain. 
This is caused by the effect of the homomorphism rather than any fault of the algorithm in the image 
domain. For example, if we wish to compute the GCD of two polynomials: A(x) = x 2 3x + 7, B(x) = x -i. 
 Then using the Euclidean algorithm and dividing over the integers we get x -2 x -1 I x 2 -3x + 7 2 
 X -X 2x + 7 2x+ 2 i.e., the polynomials are relatively prime. Whereas working modulo 5 (i.e., in an 
image domain) we get A(x) ~ A'(x) = x 2 + 2x + 2, B(x) -= B'(x) = x + 4 dividing again we get x+ 3 
 x + 4 ] x2 + 2X + 2 2 x + 4x 3x + 2 3x + 2 i.e., x + 4 mod 5 is the GCD of A(x) and B(x) . Note that 
the difference in the ans- wers is due to the homomorphism. Brown [4] shows that such situations occur 
only for a finite number of homomorphisms and that the probability of such occurrence is inversely proportional 
to the size of the prime used in the modular homomorphism. This implies that such situations occur infrequently 
and hence their name of unlucky homomorphism. They are detected by the degree anomaly which is illustrated 
above. Now we can proceed to develop our GCD algorithm. XII Algorithm MGCD First we note that we must 
consider the content and primitive part of the polynomials separately. This follows from Gauss's lemma: 
 GCD(A,B) = GCD(cont(A),cont(B)) *GCD (pp (A) ,pp (B)) where cont(F) is the content of the polynomial 
F (i.e., the GCD of its coefficients) and pp(F) is its primitive part, i.e., A(x) = pp(A).cont(A). Now 
we can state Algorithm: MGCD (A,B,r) Inputs: two multivariate polynomials A,B and an integer r (a depth 
of recursion indicator to show which homomorphism to apply). Outputs: their GCD G. Basis: If A and 
B are univariate an~ave coefficients in a finite field, then invoke algorithm EGCD to compute G; r = 
 2) Compute Contents: a = cont(A); b c = gcd(a,b); 3) Compute Primitive A" = A/a; B' = r -i; return 
G; = cont(B); Parts: B/b; 4) Bound Homomorphism: = # of homomorphic images; choose {m i} a set of moduli 
such that m. x (A') and m. x (B') 1 1 If r = 0 then {m i} are Fourier primes {pi } else m i = x r 
-b i, b.cZ Pj S) Parallel Evaluation: A i = A' mod m i % i~i~£ B. B' mod m. J i 1 6) Recursion: For 
i = i until ~ do G i = MGCD(Ai,Bi,r+I); 7) Check for Unlucky Moduli: Examine {G i} for degree anomalies 
which indicate unlucky moduli. Choose a new modulus, reevaluate and invoke algorithm MGCD to get G i 
to replace the invalid one. 8) Parallel CRA: Use Chinese Remainder Algorithm on the coefficients of 
the Gi's to compute G'. 9) Add Content: G = cG'; r = r -I; return (G). This algorithm would be invoked 
by a call of the form MGCD(A,B,0). XIII Analysis of MGCD We shall consider the analysis in two parts. 
The first part for the case of modular homomorphisms and the second for evaluation homomorphisms. Let 
M(S,N,V) be a function bounding the number of steps to compute the GCD, and M(V,N) bound the portion 
of the algorithm involving single precision arithmetic. For the sake of simplicity we will drop log log 
S terms from the analysis of the portions of the algorithmdealing with integers. i) Modular Homomorohisms 
 Step 2) Involves computing (N+I) V integer GCD's which requires O(S log 2 S (N+I) V ) steps by Corollary 
i. 3) Involves exact division of the GCD of the content in O(S log S(N+i) V) steps. 4) Brown [4] shows 
that the number of homomorphic images can be bounded by: ~ 4S + 2. The inspection requires O(S (N+i)V). 
5) Using the fast algorithms mentioned in the previous section, the evaluation can be performed in O((N+I)Vs 
log 2 S). 6) The recursive call is bounded by a function: O[SH(V,N) ).  71 Involves comparing O(S) polynomials 
with O((N+I) V) single precision coefficients. In addition, some reevaluation and recomputation may be 
necessary. This gives a bound of 81 O(S(N+i) V) + O(M(V,N)) steps. The parallel integer CRA allows time 
for this step to be the 9) O(S log 2 S(N+I) V) steps. The coefficients can be multiplied GCD of the content 
in by O(S log S(N+i) V) steps. This means that a bound for the Modular phase of the algorithm is M(S,N,V) 
= O(S log 2 S log log S(N+i) V + SM(V,N) ). ii) Evaluation Homomorphisms According to corollary 2 the 
univariate 2 GCD requires O(N log N) steps. 2) Involves taking GCD of the (N+i) V-1 univariate coefficient 
polynomials of degree N. Using algorithm EGCD this requires O((N+i) V log 2 N) steps. 3) The contents 
are divided out using Fourier division (since the division  is exact) in O((N+I) V log N) steps. 4) 
Brown [4] shows that the bound on the number of evaluations is ~ ~ 2N + I. 51 The evaluation of the 
O((N+I)V-i)- polynomial coefficients requires O((N+i) V log 2 N) steps. 6) The recursive calls require 
O(NM(V-1,N)) steps. 7) Involves inspecting O(N) polynomials with O((N+i) V-l) coefficients. This together 
with some reevaluation and recomputation requires O((N÷I) V) steps. 8) Interpolating O((N÷i) V-I) polynomial 
at O(N) points can be performed in O((N+i) V log 2 N) steps. 9) The addition of the content can be performed 
in O((N÷I) v log N) steps. Thus the total time for the evaluation portion of the algorithm can be performed 
in M(V,N) = O((N+i) V log 2 N + NM(V-I,N))  since M(I,N) = O(N log 2 N) we have by induction that M(V,N) 
= O((N+i)Vv log 2 N) and in turn this gives M(S,V,N) = O(S log 2 S log log S(N+I) v + VS(N+i) V log 
2 N) = O((N+i)Vs(Iog 2 S log log S 2 + V log N))  and this allows Theorem 2: The GCD of two polynomials 
in the model can be in O((N+i)Vs(Iog 2 S log log S + V log 2 N)) steps. Recall that the bound for the 
Brown and Collins Algorithm was 0 (S 2 (N+iIV+vs (N+i)V+iI . XIV Rational Function Manipulation In 
[8] Horowitz discussed several iterative algorithms for performing rational function manipulation. He 
investigated algorithms for adding, multiplying and differentiating univariate rational func- tions with 
numerator and denominator of degree N and coefficients S digits long. He produced new algorithms based 
on homo- morphism methods which had bounds of O(N2S+NS21 operations. The bounding steps of these algorithms 
involve polynomial GCD's and multiplication or residue compu- tation and chinese remainder computation 
 all as O(N21 processes. It is apparent that these algorithms may be recast in the parallel mold given 
in section X. This gives: Theorem 3: The addition, multiDlication and differentiation of univariate 
rational functions of degree N in numerator and denominator and coefficients S digits in length can 
be performed in O(NS(iog 2 S + log 2 N)) steps. XV Conclusion We have seen that Euclid's algorithm 
 requires ~ N2/2 steps to comoute the GCD of two N precision elements because of its iterative nature. 
Development of a more efficient method for GCD computation shows that the GCD can be computed from the 
sequence of quotients of a remainder sequence rather than the remainder sequence itself. We have also 
seen that the quotient of two elements can be computed from incomplete information about the elements. 
This allows the development of a GCD algo- rithm which operates in O(N log a+l N) if multiplication 
requires O(N log a N) and division is at least log reducible to multiplication. When the algorithm 
is used for polynomial domains, it can be used to synthesize a multivariate polynomial GCD algorithm 
which operates in O((N+I)VS(Iog 2 S + V log 2 N)) steps. The algorithm also allows more efficient algo- 
rithms for rational function manipulation. BIBLIOGRAPHY [1] A. Sch~nhager, Schnelle Berechnung yon Kettenbruchentwicklugen, 
Acta Informatica I, 139-144 (1971). [2] D. Knuth, "Mathematical Analysis of Algorithms", Stanford Comp. 
Sci. Tech. Report, STAN-CS-71-206, March 1971. [3] D. Knuth, Art of Computer Programming, Vol. II, Addison-Wesley. 
 [4] W.S. Brown, On Euclid's Algorithm and the Computation of Polynomial Greatest Common Divisors, JACM, 
Vol. 18, No. 4, Oct. 1971, 478-504. [5] R. Moenck and A. Borodin, "Fast Modular Transforms via Division", 
Proc. 13th Annual Symp. on Switching and Automata Theory, 1972. [6] G.E. Collins, Computing Time Analysis 
for Some Arithmetic and Algebraic Algorithms, Proc. of 68 Summer Institute on Symbolic Mathematical Computation. 
 [7] A. Borodin and I. Munro, "Evaluation of Polynomials at Many Points", Information Processing Letters, 
Vol. I, No. 2, July 1971. [8] E. Horowitz, Algorithms for Rational Function Arithmetic Operations, Proc. 
4th Annual ACM Symp. on the Theory of Computing, 1972. [9] E. Horowitz, "A Fast Method for Interpolation 
Using Preconditioning", IPL, Vol. 2, No. 3. [i0] E. Horowitz and L. Heindel, "On Decreasing the Computing 
Time for Modular Algorithms", Proc. of 12th Symp. on Switching and Automata Theory, Oct. 1971. [ii] 
V. Strassen, Die Berechnungs- komplexitat yon elementarsym~trischen Funktionen und von Interpolations- 
koeffizienten, University of Zurich, Preprint. [12] A. Ostrowski, On Two Problems in Abstract Algebra 
Connected with Horner's Rule, Studies presented to R. yon Mises, Academic Press, New York, 1954, 40-48. 
  
			