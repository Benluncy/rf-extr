
 Planar Separators and Parallel Polygon Triangulation (Preliminary Version) Michael T. Abstract We show 
how to construct a O(fi)-separator de­composition of a planar graph in O(n) time, and how to triangulate 
a simple polygon deterministi­ cally in parallel in O(log n) time using O(n/ log n) processors on a CRCW 
PRAM. Both of these re­ sults are based on exploiting more of the tree structure of these problems. 1 
Introduction Let G = (V, E) be an n-node graph. An ~(n)­separutor is an ~(n) -sized subset of V whose 
re­moval disconnects G into two subgraphs G1 and Gz whose respective sizes are at most 2n/3 [21]. Typically, 
separator tiding is used to drhe divide­and-conquer algorithms [3, 22], where one finds an f(n)-separator 
of G, dividing G into G1 and Gz, and then recurses on each G;. Such a recursive decomposition is called 
an f(n) -sepurutor decom­ position of G [3]. Often, in order to optimize the r tinning time of the marry 
step in such a divide-and-conquer al­ gorithm, one desires that the ~(n) -separators be as small as possible. 
Of course, if G is a tree, then this is easy, for there is a node, called the centroid, that is itself 
a separator [5]. If, on the other hand, G is a planar graph, then in what is now a classic result in 
computational graph theory, Lipton and Tar­jan [21] show that G has an O(@)-separator that can be fotmd 
in O(n) time. This, of course, imme­diately leads to an O(n log n)-time algorithm for constructing an 
O (@)-separat or decomposition of a planar graph, a result that has been used to solve *This research 
wss supported by NSF Grant CCR­9003299 and by NSF/DARPA Grant CCR-8908092. Au­thor s address: Dept. of 
Computer Science, The Johus Hopkins University, Baltimore, MD 21218. Em~ goodrkh@cs.jhu.edu. Permission 
to oopy without fee all or part of this material ie granted provided that tha copies are not made or 
distributed for diract commercial advantage, the ACM copyright notice and tha title of the publication 
and its date appear, and notica is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 24th ANNUAL 
ACM STOC -5/92/ViCTORIA, B. C., CANADA @1992 ACM ().89791-51 2-7\92\OO04/0~07...$J .50 Goodrkh a number 
of problems in VLSI layout, computa­ tional geometry, and computational graph theory (e.g., see [3, 6, 
22]). In this paper we show how to construct an O(@)-separator decomposition of a planar graph Gin O(n) 
time. Our method is based on exploiting more of the tree structure present in the prob­ lem. Interestingly, 
our approach also leads to im­ proved methods for finding many-way separators in parallel. In this case, 
the problem is to find a small-sized separator that divides G into O (n ) disjoint subgraphs, each of 
size O (nl- ). We show that a many-way 0(n1i2+ )-separator can be found in O (log n) time using O(n/ 
log n) processors on a CREW PRAM, assuming one is given a breadth­ first spanning (BFS) tree as part 
of the input (oth­ erwise, it requires O(log n) time using 0(n3) pro­ cessors on a CRCW PRAM). This contrasts 
with the fastest previous algorithm, due to Miller [23], which finds an O (@)-sized binary (cycle) separa­ 
tor in these same bounds. Note that one could iteratively use Miller s method to find a separator similar 
to ours, but this would require O (log2 n) time. There is also a parallel separator-finding method due 
to Gazit and Miller [14] that has a more efficient processor bound than our method, but it runs in O(log3 
n) time (hence, would re­ quire 0(log4 n) for a separator decomposition). Ou 0(n3) processor bound might 
seem excessively high, but, by following an approach similar to that used in the sequential algorithm 
by Chazelle [6], we show how to use this inefficient algorithm to design an optimal parallel method for 
polygon tri­ angulation the problem of augmenting a simple polygon P with diagonals so that each internal 
face in the resulting planar subdivision is a tri­ angle [13]. This is also a problem with many ap­ plications 
(e.g., see [6, 16, 18]). Our method runs in O (log n) time using O (n/ log n) processors on a (deterministic) 
CRCW PRAM. This matches the work bound of the best sequential method, due to Chazelle [6], and improves 
the previous paral­ lel method, due to Clarkson, Cole, and Tarjan [7], which rtms in O (log n log log 
n) time and has an ex­ petted O(n) work bound on a randomized CRCW PRAM. It also improves the previous 
best deter­ ministic methods, which run in O (log n) time using O(n) processors [15, 25]. As mentioned 
above, our triangulation method is based on an approach similar to that used in the sequential method 
of Chazelle [6]. Specifically, we use a divide-and-conquer approach to construct a sdvnap of P, that 
is, a partitioning of P into sub­polygons of size O(TZ$), for some $<1, which are then refined to form 
a triangulation. Our method differs from Chazelle s approach in some impor­tant ways, however. For example, 
Chazelle is able to use the sequential contour tracing paradigm to traverse polygonal chains while performing 
local ray shooting operations, whereas our method de­pends upon the design of a parallel method for global 
ray shooting operations (this is where many-way separators come in). Another impor­tant difference is 
that ours is based on an ne-way divide-and-conquer paradigm, whereas Chazelle s method is based on the 
simpler binary divide­and-conquer paradigm. This allows us to achieve our O (log n) running time, but 
this also requires that the marry step in our divide-and-conquer method be more complicated than that 
of a slower binary approach. We present our results in the sections that fol­low. 2 Separator Decomposition 
Suppose we are given an n-node triangulated plane graph G. In this section we present our linear­time 
method for constructing an O(#Zi)-separator decomposition of G. 2.1 The Lipton-Tarjan Approach Before 
we give our method, however, let us review the approach taken by Lipton and Tarjan [21]. Let T be a rooted 
BFS tree on G. Let L(i) denote the set of nodes at level i in 2 , and let ~(e) de­note the fundamerital 
cycle determined by 2 and some non-tree edge e. It is easy to see that any L(i) is a separator, since 
2 is BFS tree, and any $(e) is a separator, since 2 is a spanning tree for an embedded planar graph. 
Lipton and Tarjan s separator theorem [21] can be viewed as an elegant method for pitting these two kinds 
of separators against each other in order to find an O (@)-sized separator. For completeness, we present 
a simplified ver­ sion of their ap roach here. Let Z1 be the level in ?.-1T such that ~~=o ]L(i)l < n/2 
but ~$=o lL(i)l z n/2. Search up T at most @ levels from 11 to locate a level 10<11 (which must exist) 
such that IL(lO)I ~ @ Similarly, search down T from 11 at most @ levels to locate a level 12 ~ 11 such 
that IL(12)I s @ Cut Tat the levels 10 and /2, di­viding it into three pieces , G1, G2, and G3. If the 
middle piece, G2, is of size at most 2n/3, then we re done. So suppose IG2 I > 2n/3. Crest e a new root 
r and join r to all the roots of subtrees created when we cut T at l.. This creates a spanning tree T2 
of G2 that has depth at most 2@. Lipton and Tarjan show that there is a fundamental cycle %(e) in G2 
(whose size must be O(@)) that separates G2 into two graphs of size at most 2n/3. Adding this cycle to 
the nodes in L(lo) and L(12) gives us an O(@-separator for G, and all this can easily be implemented 
in O(n) time. This approach, of course, results in a running time of O(nlog n) for constructing a separator 
decomposition of G.  2.2 Our Approach We show how to reduce the running time for find­ing such a separator 
decomposition to O(n). We achieve this improvement by retaining more infor­mation from recursive call 
to recursive call, so as to implement each level of the recursion in o(n) time. To achieve this we augment 
T and G with a few data structures. For each level i in the BFS tree T we store the nodes of L(i) in 
a dynamic search tree 13(i), ordered from left to right in the order that their corresponding nodes in 
T would be visited in an in­order traversal of T. We also maintain a dynamic search tree 1? that is built 
upon the 13(i) s, stored by increasing level numbers. In each internal node p in 13(i) (or l?) we store 
the number of the leaf descendants of ~. This allows us to locate the level /1 in O(log n) time, and, 
from there, to locate the levels 10 and /2 in O(W) additional time. Having found 10 and 12, we must cut 
T (and G) at 10 and /2. We can perform these cuts implic­itly simply by marking each node in L(lo) U 
L(12) as deactivated, an operation that can be imple­mented in O(IL(lO) U L(12)I + log n) = O(W) time 
by traversing I?(lo) and 13(12). This is not sufficient for us to be able to efficiently perform the 
recursive calls, however, for, in addition the actual separa­tion of G, we must also construct the necessary 
data structures for Gl, G2, and G3. In particu­lar, we must create binary trees 131, B2, and 133, and 
we must triangular e each of G1, G2, and G3. Creating the binary trees is clearly the easier of these 
two operations, since it can be done simply by performing O(1) split operations in l?. As for the triangulations 
of G1, G2, and G3, we construct them while performing the cuts at 10 and /2. Let us concentrate on the 
operation for 10, since the operation for 12 is similar. When we visit a node vi in L(lo) (in our traversal 
through 13(lo)) we split ~i into two (non-adjacent) nodes v: and v?, so that v: retains all of vi s adjacencies 
to nodes on levels 10 1 and /., and v? retains all of Vi s adjacencies to nodes on levels 10 and 10 
+ 1. Then, for each edge e = (v;, v;) (respec­ tively, e = (v: , t$)), we contract e (resp., e ) so as 
to identify its two incident verticesl. We con­sider the v; and v? nodes to be dummy nodes, which do 
not contribute to the number of vertices in a subgraph, so that this gives us a triangulation for the 
portion of G above 10 (i.e., G1 ) and gives us a triangulation and a BFS tree for each connected component 
in the portion of G below 10 (which will be divided into G2 and G3). Assuming that the ad­jacency list 
for any node v in G is represented as three doubly-linked lists-the adjacencies to nodes on the same 
level as o, adjacencies to nodes on the level above v s level, and adjacencies to nodes on the level 
below v s level we can perform these splits in O(IL(1O) U L(lz)l) = (#Z) time. We also have the following 
combinatorial lemma, which will be useful in our analysis. Lemma 2.I: The total number of triangles in 
G1, Gz, and G3 is at most the number in G. Proof: Omitted. 0 We =e not done, however, if the number of 
nodes in one of the connected components of G2 is greater than 2n/3, for in this case we must also implement 
the second step that of finding a sepa­rating fundamental cycle Y(e) in G2, i.e., a funda­mental cycle 
that minimizes the maximum number 1In implementing the contraction of an edge e , we relabel edges incident 
to the resulting vertex u so that there is only one child-to-parent edge in T from u . of nodes either 
inside or outside the cycle [21]. To facilitate the efficient discovery of such an ~(e) we maintain a 
rooted spanning tree D for the graph­theoretic dual of G, where each edge of D is the dual of a non-tree 
edge in G. For each node v in D we let e(v) denote the edge in G that is dual to the edge from u to its 
parent in D. Jn the full ver­sion of this paper we show how to set up a link-cut tree representation 
[24] of T in O(n) time so that, given any node v in D, we can compute the num­ber of nodes strictly inside 
F(e(v)), on %(e(v)), and strictly outside Y(e(o)) in O (log n) time. We also show how to use this and 
a link-cut tree rep­resentation for D to drive a centroid-based binary search [17] on D to locate the 
cycle %(e(v)) that minimizes the macinmm number of nodes either inside or outside the cycle in 0(log2 
n) time. This, together with the nodes in L(lo) and L(12), then, gives us our separator. Of course, in 
order to repeat this computa­tion in the recursive calls, we must also construct link-cut tree data structures 
for the trees in G1, Gz, and Gz. Our implementation, which we give in full version, is based upon using 
the link-cut tree representations for T and D and construct­ing the trees for G1, G2, and G3 by perform­ing 
the built-in operations of cutting a tree at an edge and linking two trees by an edge. Each of these 
operations takes O (log n) time and we per­form O(1) such operations per node in our separa­tor. We may, 
therefore, characterize the running time of our separator decomposition algorithm by T(n) = T(nl) + Z 
(n2) + bn3 log n + clog2 n, where b and c are constants, n/3 g nl S nz < 2n/3, n = ~1 + n2 + n3, and 
n3 is O(A). This implies that T(n) is O(n), and gives us the following the­orem: Theorem 2.2: Given an 
n-node embedded planar graph G, one can construct an O (@)-separator decomposition of G in O(n) time. 
In the full version of this paper we give a num­ber of applications of this theorem to improve the running 
time of problems in computational graph theory and VLSI layout. We also generalize this theorem to derive 
an efficient algorithm for finding an O(@) -separator decomposition of a weighted graph. 3 Many-Way 
Separators Interestingly, our tree-based approach to finding planar separators also carries over into 
the parallel setting. In this section we give our method for finding small-sized separators that divide 
G into many similarly-sized subgraphs. 3.1 Many-way Trees Since our method produces a separation of G 
into many subgraphs it gives rise to a decomposition tree that is not binary. So, before we describe 
our method, let us make a few observations about such trees. Let T be a balanced rooted tree whose degree 
may be non-constant. We distinguish two types of such trees. For each node o in T we let nV denote the 
number leaves in T that are descendants of v (including v itself if it is a leaf). We say that T is a 
globally f(n) -way tree if each node o has at most ~(n) children, and we say that T is a locally f(n)-way 
tree if each node v has at most ~(no) chil­dren. Note that the height of a globally f(n)-way tree is 
O (log n/ log ~(n)), whereas the height of a locally ~(n)-way tree is determined by the recur­rence h(n) 
= h(n/~(n)) + 1. For example, given a constant O < e < 1, if F1 is a globally nc-way tree and 172is a 
locaUy nc-way tree, then F1 has height 0(1/e) = O(1) whereas F2 has height @(log log n). An important 
property of a balanced tree T is that it allows for a canonical representation for intervals. In particular, 
let the leaves of T be num­bered left-to-right 1,2, . . . . n, and let each internal node o of T be associated 
with the interval [a, b] that spans v s descendants. As in the (binary) seg­ment tree data structure 
of Bentley and Wood [2], we say that an interval [c, dl covers a node v if [c, dl contains the interval 
for v but does not con­tain the interval for v s parent. An interval [c, dl can therefore be represented 
by the union intervals in T that it covers. Note that any interval [c, dl can cover at most O (f(n) log 
n/ log ~(n)) nodes in a globally ~(n)-way tree and at most a number in a locally ~(n)-way tree that is 
determined by the recurrence g(n) = g(n/f(n)) + 2f(n). Continuing our example, note that an interval 
[c, dl can cover at most O (nc) nodes in either 1 1 or -F2. 3.2 Constructing Many-way Separators Let 
T be a BFS spanning tree for G, and let O < c < 1/2 be a given constant. We begin our method for constructing 
an O (n112+6)-sized many­way separator for G in parallel by determining g the size of each L(i), and 
building a binary tree B on top of the levels of T. This can easily be done in O (log n) time using O 
(n/ log n) processors, by list ranking [1, 9] and parallel prefix [19, 20] proce­dures. Let Si denote 
the number of nodes on levels 12, ,..., i, and note that 1? allows us to perform binaxy searches on the 
Si values. We allocate O(n ) processors to the task of finding each level i such that the interval (si_l, 
~i] contains a multiple of [nl cl. Call such levels starter levels. We then assign 0(n112) processors 
to each starter level i to locate the levels i and if nearest to i and between i and its neighboring 
starter levels such that i and i cent ain at most 2 [~ nodes. Call these levels the cutter levels. Note 
that such levels must exist within a distance of @/2 of each starter level, by a simple pigeon-hole argument. 
Next, we discon­nect G along each of the cutter levels. This de­composes G into O(nc) subgraphs G1, G2, 
..., G~, such that each Gi either has size O (nl e) or depth O (n112). We conclude by then performing 
an ac­celerated centroid decomposition [10] on the dual graph of each Gi whose size is above [nl- l. 
This implicitly forms a separator decomposition tree l?i of G;. The separator for G; is determined by 
the fundamental cycle associated with each node o in Bi such that v s descendants have a combined size 
above [nl- l. Unioning the nodes on these cycles with the nodes on the cutter levels, then, gives us 
our separator. Let us, therefore, summarize with the following Iemmw Lemma 3.1: Supposed one is given 
an n-node embedded planar graph G, a 333?S spanning tree T on G, and a parameter O < e < 1/2, Then one 
can construct an O (nl/2+c)-size separator of G that di­vides G into O(nc) subgraphs of size O (nl e). 
This construction can be implemented in O (log n) time using O (n/ log n) processors on a CREW PRAM. 
Proof: We give the details of our implementation in the full version. 0 Note that we may iteratively 
apply this theo­rem to forma globally O (nc)-way separator decom­position tree T for a planar graph G 
in O(log n) Figure 1: A Jordan Tessellation and its dual graph (excluding the external face). time using 
0(n3) processors on a CRCW PRAM (where the high processor bound come from com­puting BFS spanning trees), 
for any constant O < E < 1/2. At each node v in T we store the (at most ) O (m112+e) nodes that make 
up the separa­tor for the subgraph associated with v. 3.3 Application: Point Location in a Jordan Tessellation 
 Suppose we are given an m-edge Jordan tessella­tion J of the plane, that is, a subdivision of !3?2 with 
non-intersecting curves. Suppose further that each edge in the Jordan tessellation is a piece-wise linear 
curve, and let n denote the total number of linear pieces in J. (See Figure 1.) Given a point p, a horizontal 
ray-shooting query for p is to deter­mine the first point of J, called the shadow of p, that is hit by 
a horizontal ray emanating from p. We assume that we have the following ray-shooting oracle: Ray-shooting 
oracle. There is an oracle that allows us to perform a horizontal ray shoot against a single Jordan cume 
in O (log n) time using p(n) processors (p(n) is a measure of the complexity of the Jordan curves that 
make up J). Ina fashion analogous to a sequential structure used by Chazelle [6], in this subsection 
we show how to use the parallel separator decomposition lemma (3.1) to design a data structure that allows 
for arbitrary horizontal ray shooting queries to be performed in O(log n) time using 0(p(n)m112+ ) processors. 
Let D be the graph-theoretic dual of J (see Fig­ure 1). Apply the separator decomposition lemma of the 
previous subsection to D to produce a glob­ally m -way separator decomposition tree T for D, for some 
constant O < e < 1/2. The height of this tree is 0(1/e) = O(l). In addition to the sep­arator stored 
at each node o, we also store at o the O (ml/2+ ) Jordan curves that are dual to the nodes of D stored 
at v. Given a ray 7, we perform a ray shoot for F as follows. Using 0(p(n)m1i2+ ) processors we per­form 
a ray shoot against all the Jordan curves stored at the root of T. This takes O (log n) time, by assumption, 
and returns the shadow of the head of F on each curve stored at the root of T. We then compute the shadow 
point nearest to the head of F, and determine the subregion we traverse just before hitting this point. 
This takes an ad­ditional O(log m) time using O (m112+ ) processors (without using concurrent writes), 
and it informs usofthechild wofoinTatwhich wemaynow recurse to complete the ray shoot for F. If w is 
not a leaf, then we repeat this test at w. Since there are O(1) levels in T, this procedure clearly runs 
in O (log n) time. Therefore, we have the following theorem: Theorem 3.2: Suppose one is given an m-edge 
planar Jordan tessellation J. Suppose further that there exists an oracle that can perform a ray shoot 
agm nst an single Jordan curve in J in O (log n) time using p(n) processors. Then one can con­struct 
a data structure for J in O(log n) time using 0(m3) processors on a CRCW PRAM that allows O (p(n) m112+ 
) CREW PRAM processors to per­form ray shooting queries in J in O(log n) time, where e is any constant 
such that O < c < 1/2. This theorem plays an important role in our method for polygon triangulation, 
which we de­scribe next.  4 Polygon Triangulation Suppose we are given a simple polygonal chain P. 
Following elegant conventions used by Chazelle [6], we view the edges of P as having two distinct sides 
and we view P as being embedded in a sphere. A sdmzap of 1 is the planar (i.e., spherical) subdi­vision 
that is determined by adding edges, called chords, from some distinguished vertices to their Figure 2: 
A 5-granular conformal submap and its dual tree. shadow points, defined by performing horizontal ray 
shooting operations from each distinguished vertex in both directions. Because of the two-sided nature 
of P s boundary, a horizontal ray only hits one side of an edge. Indeed, we store the shadow points on 
P in two lists, the shadows on the left side and the shadows on the right side, both of which are ordered 
along P. By adopting the con­vention that P is embedded in a sphere, we view horizontal ray shooting 
operations that miss P as actually wrapping around the sphere and hitting P from the other side. (See 
Figure 2.) As in [6], our approach to constructing a trizm­gulation of P is to construct a submap of 
P and then refine that submap into a tmpezoidal map, that is, the decomposition formed by adding an edge 
from each vertex of P to its shadows on P s boundary. We may then apply the algorithm of Goodrich [15] 
to convert this trapezoidal map into a triangulation. 4.1 Polygonal Submaps So, let us begin our discussion 
by describing the specific kind of submap we construct in the first phase of our algorithm. Let S be 
a submap of P, and let D be the graph-theoretic dual of S. Because of the two-sided nature of P, there 
are no edges in D that correspond to adjacencies that cross the boundary of P; hence, D is a tree. Fol­lowing 
the terminology of Chazelle [6], we say that S is conformal if D has degree at most 4. Each region R 
in S (and its associated node in D) is as­signed a weight, where the weight of a region R is the maximum 
number of (non-null) edges on any arc in R. S is 7 -gmnulaT if each of its regions has weight at most 
7 and contracting any edge in D incident upon a node of degree 3 would create a node with weight more 
than 7. As the following lemma shows, conformality and granularity imply an even distribution of regions: 
Lemma 4.1 (Chazelle [6]): A 7-granuZar con­formal submap of an n-edge polygonaf curve C has O(n/7 + 1) 
regions and each region is bounded by O(7) edges. We concentrate on submaps whose granularity is a function 
of n, namely, we are interested in n6­granular conformal submaps, where 6 is some con­stant such that 
O < 8 < 1. In addition to the adjacency information for the nodes, edges, and segments in such a submap, 
we require that it be augmented with a few important data structures. In particular, we say that an n$-gramdar 
conformal submap is ftdly augmented if it has the following data structures associated with it: A (binary) 
centroid decomposition tree for D. We have a binary centroid decomposition of D, the dual spanning tree 
D of S.  A ray-shooting data structure. We have a data structure that allows for horizontal ray shooting 
in S to be performed in O(log n) time using 0(n$2 ) processors.  A chain-cutting data structure. We 
have a data structure that allows for chain-cutting operations to be performed in O (log n) time using 
O (nG) processors, for some constant 0<6<1. Given a subchain P of P, a cut­ting of P is a partitioning 
of P into O(n ) chains JI, J2,..., J1 SUCh that each Ji has an associated fully augmented n$-granular 
con­formal submap, where ni = l~i 1.  Given an n-edge simple polygon P, the first phase in our algorithm 
is to construct a fklly aug­mented n$-granular conformal submap of P, for some constant O < J < 1, in 
O(log n) time using O(n/ logn) processors. Our method is based on an nC-way divide-and-conquer merge 
where O < e <1 is a constant to be determined in the analysis2. 2S0 as to releave the suspense a bit, 
let us foreshadow here that e = 1/80 and 6 = 7/10 will prove to be acceptable values for these algorithmic 
parameters. 4.2 Merging Submaps So, suppose we have a polygonal curve P that has been divided into m 
= O(n ) subcurves P1, P2,..., Pm, such that, for each Pi, we have a fully augmented n$-granular conformal 
submap S;, where ~ = lPi 1. In this section we describe how to merge all the submaps into a single submap 
in paralle13. For each endpoint p of a chain Pi, we per­form a horizontal ray shoot with respect to each 
of the O (ne ) other chains to determine the shadow point(s) for p with respect to P. The segments horn 
all such p s to their shadows define the chords in this new submap, S , of P. For any such point p, this 
takes O(log n) time and, since each P; has a fully augmented submap, and requires  O(nf ) processors 
for each of the O(n ) ray shooting queries for p. Thus, since there are O(nl-$+6) such endpoints, this 
step requires @-6+s +26 (1) ) processors in total. We then sort the shadow points with respect to their 
ordering around P to deter­mine all the adjacencies. This can be implemented in O(log n) time using O(nl-$+ 
) processors [8] (which is clearly dominated by (l)). Lemma 4.2: The number of Jordan curves bounding 
any region in S is O(n ). Proof: Omitted. 0 At this point in the algorithm we have a submap consisting 
of O (nl 6+c) regions, where each region R is bounded by O (nC) chains of weight O (ns) each (because 
of the granukrit y of the recursively-computed submaps). This submap may not be conforrnal, however. 
For notational sirnplicit y, we use n to bound m~{ni : i=l,2 ,..., m}, even though this quantity is O(nl 
). This convention will have only a marginal, albeit pessimistic, ef­fect on our processor bounds, but 
it will allow us to avoid complicating the exponents in our analysis with a lot of in­consequential 1 
-6 terms. 4.3 Achieving Conformality So we must refine the submap S to make it be con­formal. Let R be 
a region in the submap. By the chain-cutting structure, we can divide each chain in R into O(ne) subchains, 
Cl, C2, ..., of size 0(n6) each, such that each such sub chain C; has a fully augmented n62-granular 
submap built upon it. In fact, we make yet another application of chain­cutting, so as to divide each 
subchain Ci into O(nc) smaller chains, c1, cz,. ... of size O (n6z ) each, such that each cj has a fully 
augmented nss-granular submap built upon it. This, of course, implies that each region R has been partitioned 
into O(nsc) chains, each of which has a centroid decomposi­tion tree and a ray-shooting data structure 
to go with it. For each cj we wish to determine if there is a vertex on cj that can horizontally see 
some edge on Ck, for each other ck. We cd each such chord a valid chord. To locate all the valid chords, 
we per­ form a globally O(n )-way search down the cen­troid decomposition tree Bj, for Cjt to drive a 
search for a visible edge on ck, which we perform for each Ck in pardel. Of course, Bj k a binary tree, 
so we implement this by searching e log n lev­els down the decomposition tree for Cj and per­forming 
a probe for each of the O(nc) nodes on that level. The probe that we must perform in this case is that 
we have a horizontal chord ab, deter­ mined by a centroid in Bj, and we wish to fkd the first edge in 
R that is hit by the ray ;b (with a as the head). Given such a chord ab, we perform a ray shooting query 
against each of the O (n36) sub­chains in l?. Each such ray-shooting query requires O(logn) time using 
0(n64 ) processors (because of the ray-shooting structure that accompanies each Ck). By a local test 
with respect to this shadow point, which we describe in detail in the full ver­sion, we can determine 
which node in the decompo­sition tree from which to continue our search for a visible edge of Ck (whkh 
we determine for each Ck in pmdel). Thus, in searching down Bj for some Ckj we must perform O (1) rounds 
of such tests, where a single round consists of O (nc) ray shooting queries being performed in parallel. 
The total overhead in setting up these searches requires only O(log n) time, and after performing these 
O(1) probes, each of which requires O (log n) time, we will reach a leaf in Ii?j. Performing these internal-node 
probes for all the O(n3c) chains in R requires 0(n&#38;4+4C) pro­cessors. Upon reaching a leaf node v 
in Bj in the search for a valid chord to Ck$ we must then per­form a ray shooting query for each vertex 
on the chain associated with v. There are O(n$s ) vertices on this chain, and each requires O (n$4+3C) 
proces­sors to answer its query. Therefore, we can im­plement the leaf-level searches for all the 0(n3 
) chains in R in O(log n) time using 0(n&#38;s+64+6 ) processors. This implies that we can implement 
all the searches (for both the internal-node and the leaf-node ray shooting queries) in O(log n) time 
us­ ing O (n$s+64 + C) processors. Performing the ray shooting queries for all the regions in S , therefore, 
requires O(log n) time using  o(nl-6+@+64+q (2) processors in totaL Lemma 4.3: Adding all valid chords 
to S using the above method creates a submap S l that is con­formal and contains at most O(nl-6+3 ) edges. 
Proofi Omitted in this extended abstract. 0 4.4 Achieving n6-Granularity Having constructed a conformal 
submap S , we must then turn it into an n6-granular submap S. We do this by recursion on a centroid decomposi­tion 
of the dual tree D of S . That is, we find a centroid edge e in D 1 , disconnect D1 at e, recur­sively 
contract the two subtrees this creates, and then (by a local test) determine if we should con­tract e. 
After a preprocessing step that computes a centroid decomposition of D in O(log n) time [10], this can 
easily be implemented in O(log n) time, using 0(nl-6+3 ) (3) processors. So, we now have an n6-granular 
conformal submap. We have only to augment it with the necessary data structures. 4.5 Augmenting the 
Submap Recall that our submap must be augmented with a centroid decomposition tree for D, a ray-shooting 
data structure, and a chain-cutting data structure. Now that we have D, the dual tree for S, the fist 
of these k fairly straightforward to construct in O(logn) time using 0(nl-6/ logn) (4) processors [10]. 
The second structure, used for ray shooting queries, requires a little more effort, however. Each chain 
in S consists of O(n6) edges; hence, by the chain-cutting structure, each such chain can be partitioned 
into O(n ) subchains of size O(n6) each, such that each sub chain has a fully aug­ mented n62-granular 
conformal submap. Jn fact, each such sub chain can be further partitioned into O(n ) chains of size O(n6) 
each, such that each has a fully augmented nfs-granular conformal submap. This implies that we can perform 
a ray-shooting query against any Jordan chain in S in O(log n) o(n64+2c time using p(n) = ) processors. 
Actu­ally, if one desires a more formal characteriza­tion of the running time of a query, then one can 
let T (n) denote its running time, where Z q(n) < Z q(nf) + b log n, for some constant b > 0, which implies 
that Tq(n) is O(log n). We would like to apply Theorem 3.2, but that requires that we view S as a Jordan 
Tessellatio~ hence, we must merge the list of shadow points on the left side of P with the list of shadow 
points on the right side of P so as to produce a dual graph for S (viewed as a Jordan Tessellation). 
Because S is an nf-granular conformal submap, G has size 0(nl-6); hence, applying Theorem 3.2 to construct 
a ray shooting data structure for S (in O(log n) time) requires O(ns(l+) (5) processors. This structure 
allows ray shooting queries to be answered in O(log n) time using  ()(n(N)/2+64+3c) (6) processors, 
also by Theorem 3.2. Note that in or­der to satisfy the induction invariant for the ray shooting query, 
we must choose the appropriate values for c and $ so that (6) is O(n62 ). Assuming suck values can be 
chosen (which we show below), this completes our construction of an n6-granular conformal submap of P. 
Let us, therefore, analyze the time and pro­cessor bounds for this method. The time bounds are determined 
by the recurrence relation Z (n) = Z (nl-C) + blogn, for some constant b >0, which implies that Z (n) 
is O(log n). If we desire that our merging procedure uses only O (nl a ) proces­sors for some constaut 
O < a < 1, then the pro­cessor bounds specified above imply the following constraints for c aud &#38; 
1 6+62+26 < 1 (7) 1 $+63+64+8c < 1 (8) 3(1 6) < 1. (9) Moreover, we need to satisfy the induction invari­ 
ant that the ray shooting data structure accompa­nying our submap requires only O (nfa ) processors, 
which, by the above claim, implies that (1 -6)/2+64+ 3E <62. (lo) There are, in fact, an infinite number 
of possible assignments for c and 6 that satisfy Equations (7)­(10). For example, one possibility is 
to set e = 1/80 and 6 = 7/10. Thus, we have the following: Lemma 4.4: Suppose one is given an n-vertex 
polygomd chah P partitioned into O(n ) subchm ns P1, P2,. ... Pm, such that each Pi has an associ­ated 
fully augmented n! -granular submap (where ni = lPil), for some positive constants 6 and e that satisfy 
Equations (7)-(1 O). Then one can construct a fully augmented n6-granukr conformal submap for P in O(log 
n) time using O(nl-m) processors, for some constant a >0. Using this lemma to drhe our divide-and­conquer 
algorithm, then, gives us the following the­orem: Theorem 4.5: Given an n-vertex polygonal chain P, one 
can construct a fully augmented n6­gramdar conforrmd submap for P, for some pos­itive constant O < $ 
< 1, in O (log n) time using O(n/ logn) processors, by the above n -way divide­and-conquer algorithm. 
Proofi We have already established the time bound. If we let TV(n) denote the work per­formed by our 
algorithm then W(n) < Z W(ni) + bnl-a log n, for some constants b >0 and O < a < 1, where n; is O(nl 
C). For the base case, when n is below some constant, then we construct a fully augment ed n6-granular 
submap for P using the se­quential algorithm of Chazelle [6]. This implies that W(n) is O(n). Having 
established the work bound to be O(n), we may then make a simple ap­ plication of Brent s Theorem [4] 
to establish the processor bounds4. 0 5 The Trapezoidal Map Of course, we wish to construct a trapezoidal 
map, not merely an n6-granukr conformal submap. That is, we desire the subdivision of P determined by 
the chords produced by a horizontal ray shoot­ing operation from each vertex on P. In this sec­tion we 
show how to use the procedures outlined above to refine such a submap into a trapezoidal map. Our method 
runs in O(log n) time using O(n/ logn) processors on a CRCW PRAM. We begin by constructing a fully augmented 
n6­granular conformal submap S using the algorithm of the previous section. In fact, let us view this 
as a preprocessing step. Each region R in S con­ . sists of O(1) polygonal chains Cl, Cz, ..., CI, each 
of which contains O (nf) edges. Because we have constructed a folly augmented submap, we can ap­ply the 
chain-cutting structure to partition each such C i into O(nC) subc.hains of size 0(n6) each, such that 
each sub chain has an associated n62­ granular conformal submap. We may therefore ap­ply Lemma 4.4 to 
construct an n$a-granular confor­mal submap of R. Our algorithm, then, iteratively applies chain-cutting 
and Lemma 4.4 to the newly created regions until we have a trapezoidal map for P. If we view this iterative 
algorithm as a recursive procedure, then we may characterize the running time as Z (n) = Z (n6) + O(log 
n), which implies that T(n) is O(log n). Also, the work bound is characterized by W(n) = ~ W(w) + nl-a 
logn, for some constants b >0 and O < a < 1, which implies that W(n) is O(n). Thus, we have the fol­lowing 
theorem: Theorem 5.1: Given an n-vertex simple polygon P, one can triangulate P in O(log n) time using 
4The caveats for applying Brent s Theorem to establish our processor bound can be satisfied by an ad-hoc 
method based on the recurrence relation for W (n) or by applying the duration-unknown task scheduling 
method of Cole and Vihkin [9] or Cole and Zajicek [11]. ­ O(n/ logn) processors on a CRCW PRAM. Proofi 
Apply the above algorithm to produce a trapezoidal map of P, and then apply the result of [15] to refine 
this into a triangulation. 0 Jn the full version of this paper we explore some interesting applications 
of this theorem in parallel computational geometry [16]. References [1] R.J. Anderson and G.L. Miller, 
Deterministic Parallel I&#38;t Ranking, AEWC 88, 81-90. [2] J.L. Bentley and D. Wood, An Optimal Worst 
Case Algorithm for Reporting Intersections of Rectangles, IEEE Thww. on Computers, C­29(7), 1980, 571-576. 
[3] S.N. Bhatt and F.T. Leighton, A Framework for Solving VLSI Graph Layout Problems, J. Comp. and Sys. 
Sci., 28(2), 1984, 300-343. [4] R.P. Brent, The Par&#38;1 Evaluation of General Arithmetic Expressions, 
J. ACM, 21(2), 1974, 201-206. [5] B. Chazelle, A Theorem on Polygon Cutting with Applications, 23rd FOC!S, 
1982,339-349. [6] B. ChazeUe, TAangulating a Simple Polygon in Linear Time, Di8c. and Comp. Geom., 6, 
1991, 485-524. [7] K.L. Clarkson, R. Cole, and R.E. Tarjan, Ran­domized Parallel Algorithms for Trapezoidal 
Dia­grams, Proc. 7th A CM Symp. on Computational Geometry, 1991, 152-161. [8] R. Cole, Parallel Merge 
Sort, SIAM J. Com-Ptd., 17(4), 1988, 770-785. [9] R. Cole and U. Vishkin, Approximate Parallel Scheduling, 
Part 1 The Basic Technique with Ap­plications to Optimal Parallel List Rankiig in Logarithmic Time, SIAM 
J. Comput., 17(1), 1988, 128-142. [10] R. Cole and U. Vishkin, The Accelerated Cen­troid Decomposition 
Technique for Optimal Par­allel Tree Evaluation in Logarithmic Time, Al­gorithmic, 3, 1988, 329-346. 
[11] R. Cole and O. Zajicek, An Optimal Parallel Al­ gorithm for Building a Data Structure for Planar 
Point Location, J. Par. and Dist. Comput., 8, 1990, 280-285. [12] G.N. l?rederickson, Fast Algorithms 
for Short­est Paths in Planar Graphs, with Applications,* SIAM J. Comput., 6, 1987, 100&#38;1022. [13] 
M.R. Garey, D.S. Johnson, F.P. Preparata, and R.E. Tarjan, Triangulating a Simple Polygon, IPL, 7(4), 
1978, 175-179. [14] H. Gazit and G.L. Miller, A Parallel Algorithm for Finding a Separator in Planar 
Graphs, 28th FOCS, 1987, 238-248. [15] M.T. Goodrich, Wlkiangulating a Polygon in Par­allel, J. of Algorithms, 
10, 1989, 327-351. [16] M.T. Goodrich, S. Shauck, and S. Guha, Parallel Methods for Visibility and Shortest 
Path Prob­lems in Simple Polygons, Proc. 6th ACM Symp. on Computational Geometry, 1990, 73-82. [17] M.T. 
Goodrich and R. Tamassia, Dynamic !llees and Dynamic Point Location,n 29rd STOC, 1991, 523-533. [18] 
L. Guibas, J. Hershberger, D. Leven, M. Sharir and R. Tarjan, Linear Tme Algorithms for Vis­ibtity and 
Shortest Path Problems Inside simple Polygons, Proceedings of the Second Symposium on Computational Geometry, 
1986, 1-13. [19] C. Kruskal, L. Rudolph, and M. Snir, Whe Power of Parallel Pretlx, Proc. 1985 IEEE ht. 
Conf. on Pamllel Proc., 180-185. [20] R.E. Ladner and M.J. Fischer, Parallel Preilx Computation, J. ACM, 
1980, 831-838. [21] R.J. Lipton and R.E. Tarjan, A Separator The­orem for Planar Graphs, SIAM J. AppL 
Math., 36(2), 1979, 177 189. [22] R.J. Lipton and R.E. Tarjan, Applications of a Planar Separator Theorem, 
SIAM J. Comput., 9(3), 1980, 615-627. [23] G.L. Miller, Finding Small Simple Cycle Separa­tors for 2-Connected 
Planar Graphs, J. Comp. and Sya. Sci., 32, 1986, 265-279. [24] D.D. Sleator and R.E. Tarjan, A Data Structure 
for Dynamic ~ees, J. C.S.S., 26,362-391,1983. [25] C.K. Yap, Parallel !lliangulation of a Polygon in 
Two CaUs to the Trapezoidal Map, Algom th­mica, 3, 1988, 279-288.  
			