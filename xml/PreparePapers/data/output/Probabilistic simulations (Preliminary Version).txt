
 PROBABILISTIC SIMULATIONS (Preliminary Version) Nicholas Pippenger IBM Research Laboratory San Jose, 
CA 95193 power to be brought to bear on our problems. Specif- ically, we shall use game-theoretic and 
information-theoretic ideas (which are in turn based I. Introduction The results of this paper concern 
the question of on probability theory). how fast machines with one type of storage media can In this 
paper, all machines will have a one-way simulate machines with a different type of storage read-only 
input tape and a one-way write-only output media. Most work on this question has focused on the tape. 
By "simulation", we shall mean on-line simu- question of how fast one deterministic machine can lation. 
In addition to their input and output tapes, simulate another. In this paper we shall look at the machines 
may have one or more storage media (which question of how fast a probabilistic machine can may be multidimensional 
or tree-structured), each simulate another. This approach should be of inter- with one or more access 
heads. By an "£-dimensional est in its own right, in view of the great attention machine" or a "tree 
machine", we shall mean a that probabilistic algorithms have recently machine whose storage media are 
all £-dimensional or attracted. It has, however, two additional claims to tree-structured, respectively. 
More specifically, interest. Firstly, a result concerning a probabilis- an £-dimensional storage medium 
will have cells tic question can lead to an improved result concern- ing a traditional deterministic 
question. Specif-corresponding to points in {0, i, ..., }£ and 3 £ ically, we shall give an improved 
simulation of shifts. The distance (minimum number of shifts deterministic time-bounded multidimensional 
needed to travel between) two cells a = saveUB.lll, machines by deterministic space-bounded machines; 
..., a£) and a' = (a'l, ..., a'£) is given by the the proof is probabilistic although the final result 
 metric is not. Secondly, the use of probabilistic methods d(a, a') = maxl<j< ~ laj -a'jl. opens the 
way to allied disciplines and allows their A tree-structured storage medium will have cells * Permission 
to copy without fee all or part of this material is granted corresponding to points in {0, I} and 3 shifts. 
The provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the distance between two cells a and a' is given by the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy metric otherwise, or to republish, requires a fee and/or specific permission. d(a, a') = tall 
+ lla'II -211£cp(a, a')II, @ 1982 ACM 0-89791-067-2/82/005/0017 $00.75 where IIall denotes the length 
of a and £cp(a, a') 17 denotes the longest common prefix of a and a'. By a "probabilistic machine", 
we shall mean one that may flip coins but that always gives correct outputs. By the "running time" 
of such a machine, we shall mean the maximum (over all inputs) of the average (over coin flips) of 
the number of steps. (Babai [I] has suggested the term "Las Vegas" for probabilistic algorithms that 
always give correct outputs, as distinguished from "Monte Carlo" algo- rithms, which may give incorrect 
outputs.) There is an alternate way of defining probabilis- tic machines and their running times that 
is often convenient. A "probabilistic machine" is one that may flip coins, always gives either correct 
outputs (success) or an initial segment of the correct outputs (failure), and succeeds with probability 
at least 1/2. The "running time" of such a machine is  the maximum (over inputs and coin flips) of 
the number of steps. The equivalence (to within constant factors) of these definitions can be shown by 
routine methods. We shall present probabilistic simulations for the situation of a probabilistic machine 
(called the "host") simulating a deterministic machine (called the "guest"), but these simulations have 
immediate corollaries in which the guests may also be probabi- listic. We shall present simulations for 
the situ- ation in which the guest has a single access head on a single storage medium, but these simulations 
have immediate corollaries in which the guest may have any number of access heads on any number of storage 
media. Finally, we shall assume that the number of steps taken by the guest in known in advance to the 
 18 host. This assumption can be eliminated by routine methods (see Galil [4]). 2. An _Up_p_er Bound 
for Tree Machines Our first result concerns the simulation of multidimensional machines by tree machines. 
A multi- dimensional machine running in time T can obviously be simulated by a deterministic tree machine 
running in time O(T log T). Reischuk [14] improved this to T exp O(log T).  Theorem i: A multidimensional 
machine running in time T can be simulated by a probabilistic tree machine running in time O(T). Proof: 
Let the guest run for T = 2 ~ steps. Let y = (Yi' "''' y~) be a uniformly distributed random point in 
{0, ..., T-I} £ (obtained from ~ independent unbiased coin flips). The position of the head of the guest 
can be regarded as a point a = (al, ..., a~) ill {0, ..., T-i} ~. Let b = a + y (that is for iNjN~, 
let b.j = aj + yj modulo T). For iNjE~, let bj, 1 (most significant) .... , bj,l (least significant) 
in {0, I} be the binary digits of b.. J Define the map fy:{O, ..., T-i}~+{O, i}~ by fy(a) = hl,l...b~, 
I ... hl, ...b~, ~. Let the symbol stored in cell a of the guest be stored at cell f (a) in the host. 
Let g denote the Y metric of the guest and let h denote the metric of the host. At each step the guest 
shifts from a cell a to a cell a' satisfying g(a, a') ~ I. A simple calculation shows that aVey h(fy(a), 
fy(a')) ~ 2Z0~j<g~(j+l)2-tJ/~J This sum is 0(i), independently of T. Thus the host, in average time 
0(I), can shift from fy(a) to fy(a') when the guest shifts from a to a'. This allows the host, in average 
time O(T), to simulate T steps by the guest.O It is natural to ask if one could use a deterministic 
storage mapping function f instead of the random storage mapping function f in this Y proof. De Millo, 
Eisenstat and Lipton [3] have shown that one cannot: for any function f: {0, ..., T-i}2~{0, i}*, there 
exist points a and a' such that g(a, a') N i but h(f(a), f(a')) = ~(log T). The idea of using a random 
storage mapping func- tion f instead of a deterministic storage mapping Y function f is due to Carter 
and Wegman [2], who introduced it in the context of hashing functions, which map a large random-access 
storage medium into a smaller one. We have adapted their idea to the context of multidimensional and 
tree-structured storage media, exhibiting an appropriate random storage mapping function and formalizing 
the result in terms of simulations. It is sometimes of interest to regard randomization as a resource: 
to count the number of coin flips used by a probabilistic machine. In this simulation, the number is 
particularly small; with care, T steps by the guest can be simulated with O(log T) coin flips by the 
host. Theorem i has consequences for the problem of simulating a time-bounded machine by a space-bounded 
machine. (In the remainder of this section, all machines are deterministic and all simulations are off-line.) 
Hopcroft, Paul and Valiant [7] showed that a one-dimensional machine running in time T can be simulated 
by a machine running in space O(T/log T). (Space is a sufficiently robust complexity measure that it 
is unnecessary to specify the stor- age media of space-bounded machines.) Paul and Reischuk [12] showed 
that a tree machine can be simulated in space O(T/log T) and that a multidimen- sional machine can 
be simulated in space 0(T log log T/log T). By combining Reischuk's simulation of a multidimensional 
machine by a tree machine (cited above) with Paul and Reischuk's simulation of a tree machine by a 
space-bounded machine, a multidimen- sional machine can be simulated in space T (exp O(log T))/log 
T. The next result shows that it can be simulated in space O(T/log T). Corollary I.I: A deterministic 
multidimensional machine running in time T can be simulated off-line by a deterministic machine running 
in space O(T/log T). This corollary is obtained by combining Theorem 1 with Paul and Reischuk's simulation 
of a tree machine in space 0(T/log T) (cited above), and observing that the space-bounded machine can 
exhaus- tively search for a storage mapping function that does at least as well as the expectation (a 
sequence of O(log T) coin flips can certainly be represented in space O(T/log T).  3. Ra~ Reduction 
for Multidimensional Machines This section describes a result that will be needed in the following 
section. By the range of a computation we shall mean the maximum distance moved by any head away from 
its original position at any step of the computation. A machine running in time T always runs in range 
T, but for some types of machine it is possible to substantially reduce this range bound without substantially 
increasing the time bound. Paul and Reischuk [12] showed that a tree machine running in time T can be 
simulated by a tree machine running in time O(T) and in range O(log T). It would be of interest (as will 
be seen in the next section) to obtain the analogous result for multidi- mensional machines: that a £-dimensional 
machine running in time T can be simulated by a £-dimensional machine running in time O(T) and in range 
O(Ti/~). The closest approximation to this which has thusfar been obtained is time T exp O((log T) I/2) 
and range T I/£ exp O((log T)i/2), which can be obtained as a corollary to a result o S Loui [9]. For 
probabilistic simulations we can improve these bounds significantly. Theorem 2: An £-dimensional machine 
running in time T can be simulated by a probabilistic £-dimensional machine running in time O(T(log 
T) I/£) and in range  O((T log T)I/~). The proof of this theorem will be obtained by combining three 
simulations that involve a new type of machine, which will be called a mulilaver machine. A multilayer 
machine is a machine having one or more multilayer storage media (which may be  20 tree-structured 
or multidimensional). Each cell of a multilayered storage medium is capable of holding an unlimited number 
of symbols, one on each of an unlimited number of layers. The layer to be read or written is selected 
in a direct-access fashion by writing the index of the desired layer on a special one-dimensional l~v3r 
selection tape. Since direct access to layers is much more power- ful than local access to cells, multilayer 
machines are interesting only when access to layers is restricted in some way, as measured by one or 
more of three new resources that will be introduced here for this purpose. By the change of a computation 
we shall mean the number of times that a new layer is selected. By the breadth of a computation we shall 
mean the number of different layers written upon during the computation. Finally, by the ~ of a computation 
we shall mean the maximum number of layers written upon in any one cell during the computation. Propositio 
A 2.1: An i-dimensional machine running in time T can be simulated by a probabilistic multilay- er machine 
running in time O(T), range O(T I/£) and change O(Ti-i/£). Proof: Let the guest run for T = 2 £p steps. 
Let R = 2 p. Let y be a uniformly distributed random point in {0, ..., R-i} £. The position of the 
head of the guest  can be regarded as a point a in {0, ..., T-i} £. Define the maps ey: {0.... , T-i}£+{0, 
..., T/R} £ and fy: {0 .... , T-I)£~{0, ..., R-i} £ by a + y = ey(a)R + fy(a).  Let the symbol stored 
at cell a of the guest be stored at cell fy(a) of layer ey(a) of the host. It is easy to check that 
T steps by the guest can be simulated by the host in average time O(T), range R =  O(T 1/~) and average 
change O(T/R) = O(Tl-1/g).m Proposition 2.2: An g-dimensional multilayer machine running in time T, 
range R = 0(T I/~) and change C = 0(T I-I/£) can be simulated by a probabilistic g-dimensional multi[ayer 
machine running in time 0(T), range 0(TI/~), height 0(log T/log log T) and breadth 0((log T)~-i). 
Sketch of Proof: We shall begin with a simulation that meets the time, range and height bounds. We shall 
then indicate how to modify this stmulation to also meet the breadth bound. For each layer e of the 
guest that is written upon, let Ye be an independeut uniformly d~stributed random point in (0 .... , 
R-I} ~. Let the symbol stored at cell a (in {0, ..., R-I} ~) of layer e of the guest be stored at cell 
a + Ye (in {0 .... , 2R-i} ~) of layer e in the host. The value of Ye for each layer e that is written 
 upon can be kept in a directory (on a single addi- tional layer) comprising C = O(T l-I/g) records 
of length c = O(log T). If the directory uses universal hashing [2], it will fit in volume O(Cc) = O(T) 
and thus in range O(T1/~); it can be accessed once in expected time o(Tl/g), and thus it can be accessed 
C times in expected time O(T). With probability at  least 7/8, the time spent accessing this directory 
will be O(T). Consider the height of the resulting computation. Let Pa,e denote the probability that 
cell a of layer e of the host is nonblank. It is easy to see that Z < T/R ~ = 0(I) e Pa,e - for each 
cell a. It follows that the probability that cell a has H nonblank layers is O(1)H/H!. Thus by choosing 
 H = O(log T/log log T) we can ensure that with probability at least 7/8, each of the O(T) cells of the 
host has at most H nonblank layers, so that the height bound is met. To modify the simulation so that 
the breadth is also small, partition the cells of the host into £-cubes of side L = Llog T], using a 
grid whose origin is a uniformly distributed random point in {0, ..., L-i} ~. Let qb,e denote the probability 
that some cell in cube b of layer e of the host is nonblank. It is not hard to see that Ee qb,e ~ (CL~ 
+ T~L£-i)/R~  = O(L ~-1 ) for each cube b. It follows that the probability that cube b has B nonblank 
layers is O(L~-i)B/B!. Thus by choosing = O(r, g-t) we can ensure that with probability at least 7/8, 
none of the O(T) cubes have more than B nonblank layers.  Within each cube, the layers of the host can 
be reassigned so that at most B layers of the host are nonblank (so that the breadth bound is met). The 
host will change layers whenever it shifts from one cube to another. It is easy to see that this will 
happen an average of 0(T/L) = 0(T/log T) times. For each cube, the reassignment of layers can be kept 
in a directory (on a single additional layer) comprising B = O((log T) £-I) records of length b = O(log 
T). If the directories use universal hashing [2], they will each fit in volume 0(Bb) = 0((log T) £) 
and thus in range 0(log T); they can be accessed once in expected time 0(log T), and thus they can be 
 accessed 0(T/log T) times in expected time O(T). With probability at least 7/8, the time spent accessing 
these directories will be O(T). It is easy to check that with probability at least 1 -1/8 -1/8 -1/8 
-i/8 = 1/2, the host runs in time O(T), range O(Ti/£), height O(log T/log log T) and breadth 0((log 
T)£-i).D Proposition 2.3: An g-dimensional multilayer machine running in time T, range R, height H and 
breadth B can be simulated by a probabilistic g-dimensional machine running in time 0(T(H log B) I/£) 
and range O(R(H log B)i/£). Proof: For each cell of the guest, the symbol in each layer can be kept 
in a directory comprising H records of length O(log B). If these directories use universal hashing [2], 
each directory will fit in volume O(H log B), and thus in range O((H log B)i/~); these directories 
will thus fit in range O(R(H log B)i/£). Each directory can be accessed once in expected time O((H log 
B)I/£), and thus these directories can be accessed T times in expected time O(T(H log B)i/£).D These 
three simulations can be combined by routine methods to yield a simulation fulfilling Theorem 2. 4. 
An Upper Bound for Multidimensional Machines The results of this section concern the the simulation 
of £-dimensional machines by k-dimensional machines, where k < £. Hennie [6] showed that a deterministic 
one-dimensional machine requires time ~(T 2"I/£) to simulate an £-dimensional machine running in time 
T. Pippenger and Fischer [13] showed that an £-dimensional machine can be simulated by a deterministic 
one-dimensional machine in time 0(T2-I/£). Grigor'ev [5] observed that Hennie's argument yields the 
result that a deterministic k-dimensional machine requires time ~(T l+I/k-I/£) to simulate an £-dimensional 
machine running in time T. Loui [9] showed that an £-dimensional machine can be simulated by a deterministic 
k-dimensional machine in time o(Tl+i/k-I/£(log T)m), where m depends on k and and m ~ as k ~- or ~. 
We shall obtain a significant- ly faster probabilistic simulation. Theorem 3: An g-dimensional machine 
running in time T and in range R can be simulated by a probabilistic k-dimensional machine running in 
time O(TR£/k-i).  Proof: Let the guest run for T = 2 ~ steps in range R = 2 kp. Let y = (Yi' "''' Y£) 
be a uniformly distributed random point in {0, ..., R-I} £ (obtained from k£p independent unbiased coin 
flips). The position of the head of the guest can be regarded as a point a = (al, ..., ag) in {0, ..., 
R-I} ~. Let b = a + y in {0, ..., R-I} £ (that is, for iSjS£, let b. = l aj + yj modulo R). For i~jS£, 
let bj, 1 (most significant), ..., bj,kp (least significant) in {0, l}be the binary digits of b.. For 
ISiSk and iSjK£p, 3 define c. . in {0, i} by the identity 1,3 Cl,l...Ck, 1 ..- Cl,£p.-.Ck,£p = bl,l...b£, 
1 ... bl,kp..-b£,kp in {0, I} k£p. Let Q=2 gp. For l~iSk, let c. in {0, 1 ..., Q-l} be the number with 
binary digits ci, 1 (most significant), ..., ci,£p (least significant). Define the map fy: {0, ..., 
R-i}£+{0, ..., Q-I} k by fy(a) = (el, ..., Ck). Let the symbol stored in cell a of the guest be stored 
in cell fy(a) of the host. Let g be the metric of the guest and let h be the metric of the host. At 
 each step, the guest shifts from a cell a to a cell a' satisfying g(a, a') ~ i. A simple calculation 
shows that Lj/kj-Lj/~j aVey h(fy(a), fy(a')) ~ Z0~j~k£ p 2 This sum is 0(R£/k-l), independently of 
T. Thus the host, in average time 0(R£/k-l), can shift from fy(a) to fy(a') when the guest shifts from 
a to a'.  23 This allows the host, in average time O(TR£'k'i), to / simulate T steps by the guest.O 
 If in Theorem 3 we use the trivial bound RST, we obtain only the poor result that an £-dimensional machine 
running in time T can be simulated by a probabilistic k-dlmensional machine running in time O(T£/k). 
If, however, we first apply Theorem 2, we obtain the following result. Corollary 3.1: An £-dimensional 
machine running in time T can be simulated by a probabilistic k-dimensional machine running in time 
0(Tl+i/k-i/£(log T)i/k). This simulation improves Loui's in two respects. Firstly, it is faster: the 
factor (log T) m in Loui's result exceeds (log T) k3 when £=k+l. Secondly, it is simpler: it makes no 
use of recursion, and the processes of range reduction and dimension reduction are separated, whereas 
they are intertwined in Loui's simulation, since a certain amount of each must he accomplished at each 
level of the recursion. Loui's simulation, of course, has the merit of being deterministic. 5. A Lower 
Bound for Multidimensional Machines The purpose of this secion is to extend Hennie's [6] and Grigor'ev's 
[5] lower bounds from deterministic hosts to probabilistic ones. Theorem 4: A probabilistic k-dimensional 
machine requires time ~(T l+I/k-I/£) to simulate an g-dimensional machine running in time T. For the 
proof of this theorem, we shall need a proposition concerning random variables If C and B are random 
variables, we shall let C~B (read "C determines B") denote the event that C assumes a value with which 
only one value of B is compatible Proposition 4: If C is a random variable assuming c distinct values, 
and if Bi, ..., B N are mutually independent uniformly distributed random variables assuming bl, .. 
, b N distinct values respectively, then EiSnS N P(C~Bn) log b n S log c. Sketch of Proof: The proof, 
which is information-theoretic in nature, is based on the following inequalities. Firstly, if B is a 
 n uniformly distributed random variable assuming b n distinct values, then P(C+Bn) log b n ~ I(C; Bn) 
, where I(C; Bn) denotes the mutual information between C and B . Secondly, if B I ... B N are n ' 
' mutually independent random variables, then Zi~nSN I(C; Bn) S I(C; B), where B = (Bi, ..., BN). Thirdly, 
 l(C; B) S H(C), where H(C) denotes the entropy of C. Finally, if C assumes c distinct values, then 
H(C) ~ log c, which completes the proof.[] Proof of Theorem 4: Let the guest G be an £-dimensional machine 
with a single access head on a single £-dimensional storage medium. Let each input symbol read by G command 
it to write a 0 or 1 in the cell currently scanned by the head, write as an output the symbol currently 
scanned by the head, or shift the access head in one of the 3 £ possible ways. Let the host H be a 
probabilistic k-dimensional machine that simulates G. Let U be the number of x,y steps taken by H when 
the input is the finite string x and the coin flips are as specified by the appro- priate initial segment 
of the infinite binary string y. We shall show that max ave = ~2(Tl+I/k- i/£), x y,q where the maximum 
is over all input strings x of length T and the average is over all infinite binary strings y (with the 
usual uniform probability distribution q). Let p be an arbitrary probability distribution on the input 
strings of Length T. Then max ave U ~ ave ave U x y,q x,y x,p y,q x,y = ave ave U y,q x,p x,y inf 
ave U y x,p x,y (This inequality has a simple game-theoretic inter- pretation: in a two-person zero-sum 
game, if one player must announce a probability distribution on his moves, after which the other player 
must announce his move, it cannot be a disadvantage to be the second player.) Thus it will suffice to 
exhibit a probability distribution p on the input strings of length T such that inf ave U = ~(Tl+i/k'i/£). 
y x,p x,y A random input string x of length T is chosen according to the probability distribution p as 
 follows. First, choose N = 2 £p independent uniformly distributed random variables Yi' "''' YN in {0, 
i}.  Second, choose M = 2 (£-l)p independent uniformly distributed random variables Xi, ..., X M in 
{i, ..., N}. The string x will be the concatenation of a "storage phase" x 0 and M "retrieval phases" 
Xl, ..., x M. Let R = 2 p. The storage phase, of length (2N-1) + (R-i), causes the values of Yi' "''' 
YN to be written in the cells {0, ..., R-I) £ and returns the head to the origin. For lSm~M, the m-th 
retrieval phase, of length (R-i) + 1 + (R-i), causes YX to be written as m  an output and returns the 
head to the origin. The length of x is thus T = (2N+R-2) + M(2R-i) = 8(N). For lNmSM, let the random 
variable W denote the  m number of steps taken by H between reading the first symbol of x and writing 
the m-th output. We shall m show that E(~l<m~ M W m) = ~(Nl+I/k'i/~). Since M = ~(NI-i/£), it will 
suffice to show that E(Wm) = ~(Nl/k). We have E(Wm) = Ew> 0 P(Wm>W) = lw> 0 [l-P(Wm~W)], so it will 
suffice to show that P(Wm~W ) = o(wk). We also have P(Wm~W ) = El~n< N P(Wm~W]Xm =n) P(Xm=n) = El~n~ 
N P(Wm~WlXm=n)/N, so it will suffice to show that Zl~n< N P(Wm~W[Xm=n) = o(wk). For iNmNM, let the 
random variable Z denote the  m configuration of H just before reading the first symbol of x and, for 
wZ0, let Z denote that m m,w portion of Z accessible within w steps. m If X =n, the event W Nw implies 
the event  m m Z ~Y . Thus it will suffice to show that m,w n ~l~n~N P(Zm,w~YnlXm=n) = o(wk)'  The 
event Zm, w ~Yn depends only upon Yi' ..", YN and Xl, ..., Xm_l, and the event Xm=n is independent of 
these random variables. Thus P(Zm,w~YnlXm=n ) = P(Zm,w~Yn ), and it will suffice to show that ~l~n~N 
P(Zm +Y ) = o(wk)" ~w n Since H is a k-dimensional machine, Z assumes exp m,w O(w k) distinct values. 
Thus Propostion 4 completes the proof.n The information-theoretic argument used in the  proof of Proposition 
4 is related to arguments used by Paul [ii] and others in the context of deterministic machines. The 
principal difference is that we use Shannon's information measure [15] rather than Kolmogorov's [8]. 
 The game-theoretic argument used in the proof of Theorem 4 is related to arguments used by Yao [16] 
in the context of decision trees. The inequality we use is the easier and more general half of yon Neumann's 
 minimax theorem [I0]. 6. References [1] L. Babai, "Monte Carlo Algorithms in Graph Isomorphism Testing 
, preprint. [2] J. L. Carter and M. N. Wegman, "Universal Classes of Hash Functions", J. Comp. and Sys. 
Sci., 18 (1979) 143-154. [3] R.A. DeMillo, S. C. Eisenstat and R. J. Lipton, "Preserving Average Proximity 
in Arrays", Comm. ACM, 21 (1978) 228-231. [4] Z. Galil, "Two Fast Simulations which Imply Some Fast 
String Matching and Palindrome Recognition Algorithms", Info. Proc. Let., 4 (1976) 85-87. [5] D. Yu. 
Grigor'ev, "Imbedding Theorems for Turing Machines of Different Dimensions and Kolmogorov Algorithms", 
Soy. Math. Dokl., 18 (]977) 588-592. [6] F.C. Hennie, "On-Line Turing Machine Computa- tions", IEEE 
Trans. on Comp., 15 (1966) 35-44. [7] J.E. Hopcroft, W. J. Paul and L. G. Valiant, "On Time versus Space", 
J. ACM, 24 (1977) 332-337. [8] A. N. Kolmogorov, "Three Approaches to the Quantitative Definintion of 
Information", Prob. of Info. Trans., 1 (1965) 1-7. [9] M. C. Loui, "Simulations among Multidimen- sional 
Turing Machines", [EEE Symp on Found. of Comp. Sci., 22 (1981) 58-67. [i0] J. von Neumann, "Zur Theorie 
der Gesellschaftsspiele", Math. Ann., i00 (1928) 295-320. [Ii] W. J. Paul, "Kolmogorov Complexity and 
Lower Bounds", Found. Comp. Theory, 2 (1979) 325-334. [12] W. J. Paul and R. Reischuk, "On Time versus 
Space, II", J. Comp. and Sys. Sci., 22 (1981) 312-327. [13] N. Pippenger and M. J. Fischer, "Relations 
among Complexity Measures", J. ACM, 26 (1979) 361-381. [14] R. Reischuk, "A Fast Implementation of a 
Multidimensional Storage into a Tree Storage", Automata, Lang. and Prog., 7 (1980) 531-542. [15] C. 
E. Shannon, "A Mathematical Theory of Communication", Bell Sys Teoh. J., 27 (1948) 379-423, 623-656. 
 [16] A. C. Yao, "Probabilistic Computations--Toward a Unified Measure of Complexi- ty", IEEE Symp. on 
Found. of Comp. Sci., 18 (1977) 222-227.  
			