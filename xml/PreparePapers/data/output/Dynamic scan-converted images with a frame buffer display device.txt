
 DYNAMIC SCAN-CONVERTED IMAGES WITH A FRAME BUFFER DISPLAY DEVICE J. H. Jackson Bell Laboratories Columbus, 
OH 43213 ABSTRACT least 3 times per second to provide the feedback A color interactive display system 
which pro-duces images of three-dimensional polygons and labels on a frame buffer display device is being 
developed. The entire image is scan converted and written into the frame buffer whenever it is modified. 
Since an entire image cannot be written into the frame buffer faster than 4.6 frames per second for the 
particular device chosen, an illusion of continuous motion cannot be supported. However, a rate of 3 
frames per second has been found sufficient to provide feedback to continuous user input. In order to 
achieve this frame rate for a rea-sonably complex picture, the display device has been microprogrammed 
to accept run length encoded data and text, and the instruction set of the computer has been extended 
by microprogramming special-purpose instructions which perform visible surface calculations. These microprograms 
currently can process a scene which consists of up to 170 polygons at 3 frames per second. KEY WORDS 
AND PHRASES: interactive computer graphics, raster displays) visible surface algorithms) frame buffers, 
run length encoding CR CATEGORIES: 8.2 1. INTRODUCTION An interactive three-dimensional color graphics 
system is being developed for use in the Network Operations Center (NOC) operated by A. T. &#38; T. Long 
Lines. It is being added to an existing real-time computer sys-tem which collects and displays data used 
to analyze traffic patterns in the long distance telephone switch- ing network. NOC personnel interactively 
analyze this data and recommend controls to be applied to the switching network to adapt it to abnormal 
traffic con-ditions. The volume of data which NOC personnel must analyze is so large that thresholds 
often must be set to select subsets of the data which form recognizable traffic past.terns. The thresholds 
which are applied to graphic data are adjusted dynamically until a recogniz-able picture is obtained. 
Experiments in the labora= tory have shown that displays must be updated at necessary for this operation. 
In addition to the dynamic adjustment of threshold values) color coding is very useful for revealing 
traffic patterns in the data. The desire for color suggests that a raster display device, rather than 
a vector display device) be used in this application. A frame buffer display device) rather than a scan-converting 
display device, was chosen to display the output. Because visible surface calculations must be performed 
externally to this display device) and because a large volume of data must be written to the device per 
frame) such a device appears to be unsuitable for producing dynamic displays. This paper describes the 
techniques which are being applied in an attempt to overcome this apparent incompatibility. 2. SCENE 
CHARACTERISTICS The system is designed to produce both perspective and orthographic projections of three-dimensional 
scenes which consist of polygons and labels. A two- dimensional display is then simply an orthographic 
pro-jection of such a scene with all polygons and labels parallel to the screen. Because the polygons 
are filled areas) priorities must be assigned to them so that one of them can be chosen to be displayed 
in an area of the image where the projections of several polygons overlap. This representation of a two-dimensional 
scene effectively assigns the highest prior- ity to the polygon which is nearest the observer in any 
such area. 2.1 Polygons Each polygon is described by a sequence of coplanar vertices and is visible 
only from the side from which the first three vertices appear in a counterclockwise order. One side of 
each polygon is invisible in order to reduce the time required to generate the image of a polyhedron 
by eliminating most of the computation which is associated with its back faces. A polygon which is described 
by two vertices is interpreted to be a line segment, and a polygon which is described by only one vertex 
is interpreted to be a point. Both line segments and points are visible from all directions and are assigned 
a fixed thickness in the image, rather than in the scene, to avoid suppression of their images due to 
aliasing. Permission to copy without fee all or part of this material is the title of the publication 
and its date appear, and notice  granted provided that the copies are not made or distributed is given 
that copying is by permission of the Association for  for direct commercial advantage, the ACM copyright 
notice and Co~utlng Machinery. To copy otherwise, or to republish, &#38;#169;]980 ACM 0-8979]-02]-4/80/0700-0]63 
$00.75 163 requires a fee and/or specific permission. 2.2 Labels Each label is one line of text which 
is displayed hor-izontally at a fixed scale and is not hidden by polygons. With these restrictions, a 
simple character generator can display the label. The position of a label is a three-dimensional point 
which is transformed and projected in the same manner as a vertex of a polygon. The lower left hand corner 
o£ the first character in the label is positioned at the projection of this point. In this way, a point 
may be labeled such that the label will move with the point as vari-ous coordinate transformations are 
applied to it in successive frames. 2.3 Lighting model The identically colored adjacent faces of a polyhedron 
can be distinguished only if they are displayed as though they are illuminated from a concentrated light 
source. To allow for such faces, a single source of parallel light is modeled, and all polygons (other 
than lines and points) are assumed to be ideal diffusers. Shading calculations are then simple because 
the image of every polygon is uniformly colored. Further-more, the hue and saturation of the light reflected 
from each polygon depend only on the color code assigned to the polygon, and not on the color of the 
light source (as they would if specularly reflected light were modeled). The application programmer can 
specify both the direction o£ the light source and the percent of illumination from this source. (The 
remain-ing illumination is assumed to be from ambient light).  3. PROCESSES AND PROCESSORS As has been 
mentioned above, a major incentive for dynamic displays is the desire to provide feedback to the setting 
of threshold values which control which data are displayed. Since the data do not tend to be organized 
by area, this feedback is not limited to a local area of the screen. For this reason, the display system 
is designed to update the whole screen each time that an image is produced, rather than to update only 
the portions of the screen in which changes occur. This design is also easier to implement for a double 
buffered frame buffer, which was employed to prevent the user from confusing the display update sequence 
with the dynamics of the image. The four major processes which are performed to pro-duce an image are 
depicted in Figure I. These processes are: Ph Description of the picture (any one of several application 
programs), P2: Coordinate transformation, clipping, and subdivi-sion of polygons into trapezoids, P3: 
Scan conversion and visible surface calculation, and P4: Decoding of run length encoded data and charac-ter 
generation. Run length encoded data, rather than pixel data, are sent to the display device both tO avoid 
expanding these data as part of P3 (which would greatly increase its execution time) and to ensure that 
the computer's bus is not consumed by the transfer of these data. Only one process is needed to both 
decode these run length encoded data and to generate characters because the characters for each frame 
are generated after the images of polygons have been written into the frame buffer. This sequence prevents 
labels from being overwritten by polygon data. Ideally, each of these processes could be performed in 
parallel by separate processors. The processes then would form two pipelines: one involving PI, P2, P3, 
and P4 which produces images of polygons, and one involving Pl, P2, and P4 which adds the labels to the 
image. For economic reasons, however, Pl and P2 were both implemented on one processor, P3 was microprogrammed 
for the same machine, and P4 was microprogrammed for the display device. The major drawback to this type 
of implementation is that coor-dinate transformation must be performed sequentially with visible surface 
calculations. I I Processor P1 ] Macrocode Application Polygons I ~ Labels Processor Cll~ng, Macrocode 
Transformation, Subd v s on Trapezoids ~ TransformedLabels Processor Scan C:r3version, Microcode Visible 
Surface 1  Calculation I  I .unL.n Pdo ,. Character Generation ~ Pixels Figure 1. Organization of Processes 
 4. TRANSFORMATION AND CLIPPING All coordinate transformations, other than perspective projection, are 
applied to polygon vertices and label positions in an order specified by a sequence of calls to display 
procedures (4) in the application program. The resulting data are then clipped behind a plane which is 
parallel to the screen and just in front of the observer, projected, and finally clipped inside planes 
perpendicular to the screen which intersect the edges of a clipping window by a modified re-entrant polygon 
clipping algorithm (6). With this sequence, each clipping operation is simple because it is per-formed 
relative to a clipping plane which is perpendic- ular to an axis of the screen coordinate system. If 
any dipping operation were performed earlier in the sequence, it would be considerably more complicated 
because it would be performed relative a clipping plane with no special orientation. Then, unless a large 
portion of the data in the scene did not project within the dipping window (which is not expected), clipping 
operations would consume much more 164 processing time. 5. SUBDIVISION OF POLYGONS Perhaps the most 
obvious method of formatting data for P3 is to represent each transformed and clipped polygon as a color 
and a list of edges. This represen-tation has been used previously by Watkins (7), Bouk-night (I), and 
others. However, when polygons are represented in this way, the visible surface algorithm must maintain 
a somewhat complicated data structure which allows it to associate pairs of edges on each scan line. 
Furthermore, interpolation of depth values involves a division operation, which is difficult to microprogram. 
An alternative method is to subdivide each polygon into primitive polygons, each with a fixed number 
of sides. Romney (5) and Myers (3), for example, subdi-vided polygons into triangles. The reassociation 
pro-cess is then much simpler, as shown in Figure 2. The edges of the triangles are identified in this 
figure as the "left", "right"~ and "spare" edges. These edges may be identified easily by sorting them 
first in the Y (vertical) direction, and then in the X (horizontal) direction. Whenever either the left 
or right edge ter- minates on a scan line but the other does not, the spare edge is simply substituted 
for the edge which terminated. If both edges terminate on the same scan line, the entire triangle is 
removed from consideration.  Le~~ s Spar~eRight Right Left~ RightLeft pare Scan Line Order Right Spare 
Figure 2. Association of Triangle Edges The partial derivative of the Z (depth) coordinate with respect 
to the X coordinate (with Y constant) may be computed once for an entire triangle. This value may then 
be stored as part of the description of the trian-gle and used by the visible surface algorithm to inter-polate 
Z coordinates. The interpolation performed with this value involves only multiplication and addi-tion, 
and, consequently, is easier to microprogram than an interpolation which involves a division operation. 
5.I Trapezoid primitives Subdividing polygons into triangles, however, increases the complexity of scan 
line calculations. Figure 3a shows a concave polygon subdivided into triangles, whereas Figure 3b shows 
the same polygon subdivided into trapezoids with parallel edges parallel to the scan lines. (The triangle 
in Figure 3b is considered to be a trapezoid with a zero length parallel edge.) The com-plexity of the 
calculation of a scan line increases as the number of elements which intersect the scan line increases. 
Scan line A intersects 4 triangles in Figure 3a, whereas it intersects only two trapezoids in Figure 
3b. Similarly, scan line B intersects 6 triangles in Figure 3a, whereas it intersects only one trapezoid 
in Figure 3b. These examples illustrate that subdivision into triangles generally produces more intersections 
per scan line than does subdivision into trapezoids. In fact, subdivision into trapezoids produces the 
minimum number of intersections, which is equal to the number of intersections of the scan line with 
the original polygon. Line B a. Subdivision Into Triangles i LineB b. Subdivision Into Trapezoids Figure 
3. Methods for Subdividing Polygons Subdivision into trapezoids requires no more storage than does subdivision 
into triangles for polygons with 4 or more vertices. The maximum number of triangles which are formed 
from an n-vertex polygon is n-2, whereas the maximum number of trapezoids is n-h-l, where h is the number 
of horizontal edges. If one assumes that the number of horizontal edges in the image is insignificant, 
the maximum number of tra-pezoids per polygon is greater than the maximum number of triangles. However, 
each trapezoid can be represented by only its two nonhorizontal edges, whereas all three edges of each 
triangle must be stored. The storage required for a trapezoid is com-pared with that required for a triangle 
by Figure 4. (The pointers in the formats are needed to organize the trapezoids or triangles into the 
list structure described in Section 5.2 below.) From this figure, the ratio of storage for a trapezoid 
to that for a triangle is seen to be 2/3. Then, the storage required to sub-divide an n-vertex polygon 
into trapezoids is no greater than that required to subdivide it into trian-gles if n is at least 4. 
If n equals 3, however, subdi- vision into triangles requires less storage. In order to avoid complicating 
scan line calculations, each polygon is subdivided into trapezoids, rather than into triangles. The advantages 
of associating edges before visible surface calculations are performed and simplifying interpolation 
of depth coordinates are then gained without increasing scan line complexity. 165 Trapezoid Triangle 
Le"£1~Z_~.,.., It II Cok~r J Z~y 128"x(Left) 128*x(Right) 128"d~Jdy(Leff) 128"dx/dy(Right) 128"dx/dy(Left) 
--z(Left) 128"dx/dy(Right) 128"dx/dy(Spare) --dz/dy(Left) -- z(Left) --  --az/Ox -- z(Spare) -- --dz/dy(Leff) 
-- dz/dy(Spare) -- Oz/0x -- Figure t). Formats for Trapezoids and Triangles 5.2 Scene structure Although 
the entire image is scan converted to pro-duce each frame) the trapezoids and labels which represent 
parts of the scene which have not changed since the previous frame need not be recomputed. For this reason) 
the scene is organized into "seg-ments", which are similar to the "frames" in Newman's display procedures 
(4). However) each seg-ment for our raster display is implemented by linking together the trapezoids 
and labels which describe the segment) rather than as a display buffer. The data structure which represents 
all of the seg-ments which comprise the image is depicted in Figure 5. The data structure is accessed 
either by segment or by scan line. The two arrays shown are provided for this purpose. Each segment is 
represented by a list of labels) a list of trapezoids (linked by the third pointer in each trapezoid 
block)) and a pointer which associates a procedure which regenerates the segment with the segment, Each 
element of the scan line array is the head of a doubly linked list which con-tains all trapezoids whose 
uppermost edge has a Y coordinat~ either equal to that of the corresponding scan line or between that 
of the corresponding scan line and that of the next scan line. Whenever the procedure associated with 
the segment is called to regenerate it) the corresponding label and trapezoid lists are emptied. The 
forward and back-ward links in the list associated with each scan line facilitate this operation. Each 
label which is gen-erated by the procedure is then inserted at the begin-ning of the label list. Each 
trapezoid which is gen-erated by the procedure is inserted both at the begin-ning of the trapezoid list 
and at the beginning of the appropriate scan line list. In this way, only trapezoids and labels which 
belong to a segment which has changed since the previous frame are recomputed. SegmentArray Label Label 
Labels Trapezoids Procedure I Label Label Tra~ii~s~ Pr°cedure~ I S Trapezoid Trapezoid I I  Trapezoid 
Trapezoid Figure 5. Scene Structure 5.3 Mapping image coordinates to scan conversion coordinates The 
coordinate system with respect to which the image is defined is shown in Figure 6a. The origin of the 
coordinate system is at the center of the image in the plane of the image, and the image occupies an 
area 255 pixels wide by 255 pixels high. This image resolution) rather than a 256 x 256 resolution) was 
chosen to ensure that the length of a closed interval between coordinate values can be stored in an S-bit 
byte. The resolution of the display device9 however) is 512 pixels/line by 256 lines. A horizontal resolution 
of 512 pixels/line) rather than 256 pixels/line) was chosen for two reasons. First) a horizontal resolution 
of 256 pixels/line would permit only 36 characters to be displayed per line, whereas the chosen resolution 
per-mits 73 characters per line. Secondly) the additional horizontal resolution reduces aliasing along 
the edges of polygons which form angles greater than 45 degrees with the horizontal. This effect appears 
to reduce aliasing in the entire image) since human stereoscopic vision has conditioned us to be more 
sensitive to nearly vertical edges than to nearly horizontal edges. The vertical resolution was limited 
to 256 lines) rather than 512 lines) both to reduce the computation time for the image and to avoid the 
slight flicker which is present with the higher resolution. Figure 6b shows the coordinate system into 
which image coordinates are mapped by the system when trapezoids and labels are formed. This coordinate 
sys-tem was chosen to offset the image by half a pixel in the X and Y coordinates as shown in Figure 
6c. This offset causes truncation of coordinate values to integers to effectively round each point to 
the nearest pixel. 166 -5- Y = 0.5- Y = 127.5--T-- L Y = -t27.5--Y = 255.5 - I X = -127.5 X = 127.5 
X = 0,5 X = 510,5 -2~_~ Z< 2 ~ O<Z<2 3z a. Image Coordinates b. Scan Conversion Coordinates 0.5 Pixels 
i Screen Area -~1~i LL____ Image Given to IL ...... ;[__~ o,S:; inx ~1°: verter  o,P,x,is~ ~ ~tsP,x°is 
c. Offset of Image to Accomplish Rounding Figure 6. Mapping of Image Coordinates to Scan Conversion Coordinates 
 6. VISIBLE SURFACE ALGORITHM Visible surface calculations are performed by a microprogram which was 
written to add two instruc-tions to the processor 's instruction set. One of these instructions initializes 
the microprogram to generate a new image, whereas the other produces the next scan line in the image. 
The former instruction accepts a background color code as an operand and empties a list of active trapezoids 
(i. e., trapezoids which inter-sect the current scan line) which is stored in the RAM which contains 
the microcode. The latter instruction accepts the address of a buffer into which run length encoded data 
for the scan line is to be placed and a pointer from the scan line array as operands. It then produces 
the scan line by the following procedure: 1. Enter new trapezoids into the active list of tra-pezoids. 
 2. Adjust the left X, left Z and right X values of each active trapezoid to the proper values for this 
scan line9 and remove each trapezoid which has been completed from the active list. 3. Sort the active 
trapezoids by left X (bubble sor% since the order is likely to be the same as on the previous scan line). 
 4. Generate run length encoded data for the scan line.  The last of these steps examines the sorted 
active trapezoid list to subdivide the scan plane (i. e. the plane perpendicular to the image plane which 
contains the scan line) into "spans". The scan plane is subdi-vided parallel to the Z axis at each X 
coordinate which is the X coordinate of the left or right edge of an active trapezoid. Spans are formed 
from left to right so that each span may be processed as it is pro-duced to yield run length encoded 
data in the proper order. As each span is produced, it is classified as being one of the four types shown 
in Figure 7a by the following tests: 1. If the span intersects no trapezoids, it is classi-fied "empty". 
 2. Otherwise, if the span intersects only one tra-pezoid, it is classified "single". 3. Otherwise, 
if the same trapezoid is in front of all others which intersect the span at both the left and right edges 
of the span, the span is classified "multiple". 4. Otherwise, the span is classified "intersecting". 
 A trapezoid whose left edge intersects the right edge of a span is not considered to intersect the 
span. , , t i Empty Single Multiple Single Intersecting Single a. Example Scan Plane i , i i , Pi,e, 
b. Special Case of Intersecting Span Figure 7. Types of Span s Each of the first three types of spans 
produces only one color in the image. The empty span produces the background color, the single span produces 
the color of the trapezoid which intersects it, and the multiple span produces the color of the trapezoid 
found to be in front at both the left and right edges of the span. The intersecting span, however, may 
produce more than one color in the image. This type of span is processed by further subdividing it to 
form spans of the other three types. An intersecting span results from at least two polygons intersecting 
elsewhere than at their edges. Since this event is not expected to be common in our application, no attempt 
is made to process it effi-ciently. Instead, the processing is designed to capital-ize on microcode used 
elsewhere in the visible surface algorithm and to avoid a division operation. The intersecting span is 
subdivided by using a half interval method with the span classification tests listed above to find the 
span whose left edge is the left edge of the intersecting span and whose right edge is as far right as 
possible such that the new span is not an intersecting span. Mter the span formed in this manner has 
been processed, normal 167 -7- checkerboard pattern. The time required by P4 was derived from measurements 
of time required to pro-cess various run lengths and the geometry of the image, whereas the other times 
were measured directly. Although P3 executes faster than P% the two processes together require more time 
than P4 because they are not completely overlapped. o P3 and P4 3 Frames, sec. P4 0.3- P3 o E k- O.1-- 
 0.0 i i J i i i 100 200 300 400 500 Number of Trapezoids Figure ll. Two-dimensional Measurements Figure 
12 shows the time required for P3 and P4 to process scenes similar to that shown in Figure 10. These 
scenes were produced by varying the number of values of both independent variables from I to II. The 
time required by P4 was not measured because the geometry of the image is complicated. However, the other 
measurements indicate that P3 is responsible for most of the time consumed by P3 and pie. The time required 
for P3 to process each of these scenes increases rapidly with the number of trapezoids chiefly because 
the average depth of these scenes increases with the number of trapezoids. These measurements show that 
the time required by P3 is very sensitive to the average depth in the scene. This sensitivity might be 
reduced significantly by modifying the algorithm for P3 to utilize depth coherence between scan lines. 
8. CONCLUSION The system being developed uses a frame buffer display device. The particular device selected 
is able to rewrite its image memory at only #.6 frames/second. Since considerations external to the disptay 
device itself have caused us to not utilize the individual pixel capability of the frame buffer display, 
a better choice of display device might be one which decodes run length encoded data and generates charac- 
ters as part of its video refresh process. Such a display device could run considerably faster and might 
cost less because a much smaller memory than a 3.0 P3 and P4 2.0 P3 6 I-1.O 7 O.O 16o 2~o a60 4~o soo 
Number of Trapezoids Figure 12. Three-dimensional Mesurements frame buffer could store the image. In 
order to utilize a faster display device, images must be updated at a higher rate. By designing the system 
for two (smaller) processors, one which exe-cutes P1 and P2, and another which executes P3, coordinate 
transformation may be performed in paral-lel with visible surface calculations. Beyond this, an additional 
processor might be allocated to P1, and multiple processors might be allocated to P2 and P3. For example, 
each segment which is formed by P2 might be assigned to a separate processor, and por-tions of P3 for 
various parts of the image might be assigned to separate processors, as has been suggested by Kaplan 
and Greenberg (2). REFERENCES (1) Bouknight W. 3. An improved procedure for gen-eration of half-tone 
computer graphics represen-tations. University of Illinois, Coordinated Sci-ence Laboratory, Report R-432, 
September 1969. (2) Kaplan, M., and Greenberg, D. P. Parallel pro-cessing techniques for hidden surface 
removal. SIGGRAPH '79, 300-307. (3) Myers, A, J. An efficient visible surface algo-rithm. Computer Graphics 
Research Group, Ohio State University, 3uly 1975. (4) Newman, W. M. Display procedures. Comm. ACM 14, 
10 (October 1971), 651-660. (5) Romney 9 G. W. Computer assisted assembly and rendering of solids. Dept. 
of Computer Science, University of Utah, TR 4-20, 1970. (6) Sutherland, I. E., and Hodgeman, G. W. Re-entrant 
polygon clipping. Comm. ACM 17, 1 (3anuary 1974), 32-42. (7) Watkins, G. S. A real-time visible surface 
algo-rithm. Computer Science Dept., University of Utah, UTECH-CSc-70-101, 3une 1970.  169   
			