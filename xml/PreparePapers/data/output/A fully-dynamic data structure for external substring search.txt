
 A Fully-Dynamic Data Structure for External Substring Search* (Extended Abstract) Paolo Ferraginat Abstract. 
We address the issue of efficiently searching on external dynamic data structures for strings, intro­ 
ducing the External Dynamic Substring Search prob­ lem. Consider a set A of (external) text strings kept 
into secondary storage. The set A can be dynamically changed by inserting or deleting strings, and on-line 
searched to find all the occurrences of an arbitrary pat­ tern string as a substring of the text strings 
in A. We introduce the SB-Tree data structure for A, which is the first fully-dynamic data structure 
allowing the External Dynamic Substring Search problem to be solved with provably good worst-case and 
amortized 1/0 bounds. It requires optimal space and makes the on-line search alphabet independent also 
into main memory. The SB-tree can also be used to solve a natural exten­ sion of our problem to parameterized 
strings (p-strings) within the same bounds. 1 Introduction Every year computers get faster, but the 
need to solve bigger and bigger problems is still relevant. Given this trend, the design of external 
data structures having provably good worst-case complexity is an important topic. A variety of dynamic 
data structures for search­ing have been designed to make optimal use of sec­ondary storage, taking 1/0 
time logarithmic in the size of the input. B-trees [6] and their variations [11] are well known examples. 
Other data structures have been successfully devised for external range searching prob­lems in computational 
geometry (e.g., see [17, 24]) and for external graph algorithms [10]. This work has been partially supported 
by MURST of Italy. tDipartimento di Informatica, University di Piss, Italy. E­ mail: ferragin@di unipi. 
it * DiPartimento di Sistemi e Informatica, Unlversit~ di Firenze, Italy. E-mail: grossi@di.unipi.it 
 Permission to copy without fee all or part of this material is granted provided that the copies are 
not made or distributed for dwct commercial advantage, the ACM copyright notice and the title of the 
publication and Its date appear, and notice is given that copyin is by permission of the Association 
of Computing Machinery,?o copy other-we, or to republish, requires a fee and/or specific permission. 
STOC 95, Las Vegas, Nevada, USA 01995 ACM 0-89791-718-9/95/0005,$3.50 Roberto Grossi$ In this paper, 
we address the issue of efficiently find­ing all the occurrences of a pattern string as a substring of 
many text strings. This is an important and basic low-level operation in large-scale genorne and textual 
databases [15, 23], with applications to molecular biol­ ogy, text editing and software maintenance [5]. 
We introduce the External Dynamzc Substrzng Search problem (shortly, EDSS). Let X be an ordered alpha­ 
bet, and A = {61,. . . . 6K} be a set of text strings drawn from X, whose total length is lV = ~~1 16,]. 
The strings in A are external, because they are kept into secondary storage. Moreover, the set A can 
be dy­namically changed by inserting or deleting strings, and on-line searched to find all the occurrences 
of an arbi­trary pattern string P, of length p, as a substring of the text strings in A. We assume the 
standard model of computation in which each secondary storage access transfers a single page containing 
B units of data. Fol­lowing [12], we shall analyze separately the two main components of the running 
time of our solution: (1) the number of pages that are accessed into secondary stor­age, called disk 
accesses, and (2) the CPU time, called computing time. Compared to other applications into secondary 
stor­age, the design of a fully-dynamic data structure for the EDSS problem presents two major diffic 
ulties. First, we have to manage arbitrarily long strings that cannot fit in O(1) pages of size B, and 
this can mess things up. Second, searching strings in A and updating them can be highly inefficient, 
since each character-by-character comparison of two strings has a computational cost that is proportional 
to the sum of their length. In contrast, external data structures for computational geometry can rely 
on grouping O(B) points per page. Further­more, any two points can be compared in O(1) time. In words, 
the crucial point in solving the EDSS problem is: HOW can we route the search in the data struc­ture, 
once a page has been retrieved, having the goal to minimize the total number of disk accesses ? Our main 
contribution is the SB-Tree data structure, which is the first fully-dynamic data Structure allow­ing 
the EDSS problem to be solved with provably good worst-case and amortized 1/0 bounds. The SB-tree for 
the set A (in short, SBTA) can be stored using op­timal @(lV/B) pages into secondary storage. Since it 
 Search(P) Insert(Y) Delete(Y,l #Pages Generalized suffix tree plog~ 1X1+ Occ mBII1/ mBIXl N F Patricia 
(PAT) tree plog~ 121 +Occ m(m + B) Iogz 121 mll logz 1)11 % Complete inverted file plog~ IEI +Occ $ Sufix 
array * + log2 ; % Dynamic suffix array (P~ 10% +$)10% plOgB N + F m1%2m 10!4 v m 1%2 m M g v SB-tree 
(worst-case) % -I-logB N m(B + log2 ~) m(B + log2 g) % W3-tree (amortized) w + logB N m logB(N + m) m 
logB N N z Table 1: Worst-case disk accesses and storage pages, where p is the pattern length, occ is 
the number of occurrences, N is the total length of the text strings, m is the length of Y, and B is 
the page size. only needs a constant number of pages into main mem-It means that we might access further 
O(B) pages to ory, its size is not limited by the size of main memory. update the pointers of the nodes 
having at least one The searching and updating bounds for the SB-tree are child in PG. given in Table 
1. We remark that our search algorithm Let us consider now some of the most powerful data is alphabet 
independent [16], and requires an optimal structures proposed for the main memory model, and number of 
disk accesses for unbounded alphabets. We discuss the drawbacks arising when adapting them to also point 
out that our algorithms have small constant the EDSS problem. The (generalized) sufix tree [2, 18, factors 
in their bounds, hence are expected to run fast 22, 25] is a powerful compacted trie, widely employed 
in practice. 1 in pattern matching (e.g., see [4]). Surprisingly enough, its good worst-case performance 
may degenerate when applied to solve the EDSS problem:Previous work. As far as we know, several elegant 
Since the outdegree of a node can be 0(1X I), its childdata structures in the literature [2, 13, 18, 
20, 21, 22] pointers (i.e., sibling arcs) might not fit into 0(1) pages,could be adapted to solve the 
EDSS problem, as shown but they should be stored in a B-tree. That would causein Table 1. Unfortunately, 
either they would not have an O(logB [Xl) disk access overhead for each branch outgood theoretical worst-case 
bounds, or they would not of a node. support efficient dynamic operations (some of them Comparing the 
arc s label after a branch requires fur­have a good average-case behavior for practical pur­ther accesses 
to the pages containing the correspondingposes). Much of their inefficiency is due to the ma­substring. 
 jor, and reasonable, requirement of occupying optimal The search for P might visit O(p) nodes in distinct@(# 
) pages since N is very large. (It means that the pages, and all the occ occurrences found in its leavesmajority 
of the pages must contain @(B) data. ) Basi­might be stored in O(occ) distinct pages as well. cally, 
most of those data structures have a tree topol­ The suffix links might be updated after having beenogy 
and thus inevitably inherit the drawbacks already pointed out in the literature. Indeed, good average-case 
 set. Recall that a suffix link for a node storing a string solutions have been proposed to group @(B) 
nodes per aX, with a E E and X c E*, is a pointer to the node page under node insertions only [20, Sect.6.2.4] 
(deIe­ storing X. There can be up to 1~1 suffix links pointing tions make the analysis extremely difficult). 
Those so­ to the same node for a given X. Now, the insertion or lutions cannot avoid a path of k nodes 
to be stored into the deletion of a string, of length m, determines the in­ sertion or the deletion of 
O(m) nodes. For each of those O(k) distinct pages, in the worst case. In addition, the split of a page 
PG (after the overflow caused by a single nodes, a page could be split or merged to handle over­node 
insertion) or the merge of PG with another page flow and underflow. Consequently, O(B) nodes should (after 
the underflow caused by a single node deletion) change page, causing the 0(1 2[ ) suffix links pointing 
 could make @(B) nodes move from one page to another. to them to be updated (because otherwise they would 
become dangling). Hence the overall number of disk 1For example, searching a pattern of length p < 100 
takes less accesses would be O(mB[ 2] ) in the worst case. than 19+ (occ/1001 disk accesses in the worst 
case, with N = 240 and B N 100 (see Theorem 7). We hope to present extensive The Patricia tree [20, Sect 
.6.3] and the PAT tree [9] experimental results in a future paper. are data structures having a good 
average-case behavior into main memory [13]. However, the 0(1 21) outdegree is implicitly handled by 
creating a binary digital tree of depth 0(log2 [XI) for each node. Moreover, they do not use suffix links, 
hence the insertion or deletion of a string of length m could visit 0(m2 ) nodes and cause O(m) page 
overflows or underflows, in the worst case. The complete inverted file [8] suffers from the same problems 
as the suilix tree, being a graph obtained by merging the edge-isomorphic subtrees of the suffix tree. 
Moreover, only a static version can be used to list all the occ pattern occurrences. The sufix array 
[21] is a space-efficient data struc­ture that allows alphabet-independent searches. It is inherently 
static and the number of disk accesses is not optimal by the additive term 0(log2 $$). It can be dy­namited 
with the dynamic sufix array [12], which can be adapted to work into secondary storage, requiring O(N1~ 
) pages. The practical need for a data structure into secondary storage with good 1/0 performance has 
produced also an empirical variation of the B-tree, called the prefix B-tree [7, 10], in which the keys 
are lexicographically ordered strings. Unfortunately, such a data structure does not have a good worst-case 
behavior even though its structure is a B-tree. It allows prefix searches only, and it is based upon 
heuristics to choose the keys, in order to fit the longest common prefix (separator) be­tween two consecutive 
keys into a single page. Note that the length of the separator can be O(N) in the worst case, thus the 
worst-case performance of the prefix B­tree becomes very poor. Our techniques and results. From a high 
level point of view, our SB-tree is a B+-tree in which the keys are the suffixes of the strings in A, 
lexicograph­ically ordered (see Section 4). Our techniques can be summarized as follows. (a) We introduce 
the blind trie data structure, which allows each node in the SB-tree to store O(B) charac­ters and pointers 
to strings, independently of the to­tal length of the pointed strings (see Section 3). In its essence, 
a blind trie is a compacted trie similar to the Patricia tree. As a compacted trie, the strings are drawn 
from Z and stored into its leaves, As a Patri­cia tree, we can trace a downward path from the root, matching 
only a single character per arc, rather than a whole substring. This turns out to be crucial for ef­ficiently 
routing a visit in the SB-tree. In this way, we proceed as if we had a compacted trie, but with­out having 
the drawback of accessing a page for each branch. Moreover, we show that blind tries allow a set of lexicographically 
ordered strings to be dynamically updated (through concatenate, split, insert and delete operations). 
(b) We search for a pattern string going deeper and deeper in the SB-tree trying to match a prefix of 
increas­ing length. We are able to maintain invariants during the visit, so that we are guaranteed to 
extend the pre­fix of the pattern, matched so far, without rescanning. A similar idea is used for the 
insertion of a new string by performing an unusual upward visit of the SB-tree. However, to avoid the 
problems mentioned for the suf­fix tree, we do not use suffix links but simply a pointer from the i-th 
to the (i+ 1)-st suffix of each string in A (see Section 4). We believe that our techniques are interesting 
in their own, and may find application to other problems. As an example, consider the parametrized pattern 
match­ing problem, introduced by Baker [5], :for finding pro­gram fragments in a software system that 
are identi­cal except for a systematic change of parameters. The program fragments are represented as 
parameterized strings, called p-strings. In [5], it is given a generaliza­tion of the suffix tree, called 
p-sufix tree, to perform ef­ficiently on-line searches of p-strings. Since then, other algorithms have 
been designed to work omrp-strings, re­quiring a significant effort due to the dynamic nature of p-strings 
[3, 19]. Consider now the natural extension of the EDSS problem to p-strings, called External Dynamic 
Param­etrized Substring Search problem (shortly, EDPSS), It is simple to use our SB-tree for the EDPSS 
problem, thus achieving the same bounds as the ones in Table 1. This turns out to be the first algorithm 
that uniformly treats both strings and p-strings without loss of effi­ciency. Briefly, we obtain the 
following results: (1) The SB-tree is the first fully-dynamic data struc­ture that has a provably good 
worst-case and amortized complexity in solving the EDSS and the EDPSS prob­lems. The search is optimal 
and alphabet independent, for unbounded alphabets, with small hidden constants. (2) Fixing B = O(1) 
and using the SB-tree into main memory, we improve over the on-line search of general­ized suffix trees 
[2, 18] (resp., p-suffix trees [5]) when they are storing a dynamic set of strings (resp., p­strings) 
over unbounded alphabets. Indeed, we reduce the searching time from O(plog N+OCC) to O(p+log N+ OCC). 
Such a result has been previously achieved for strings only, in the static case, using suffix arrays 
[21]. (3) Fixing B = O(1) and using the SB-tree into main  memory, it is also possible to implement 
clynamic suffix arrays [12] in linear space without using names. Again, we obtain an alphabet independent 
search, and the up­dates run within the same time bounds as in [12].  2 Preliminaries Given a string 
X over an ordered alphabet 2, we use X [i : j] to denote the substring of X from position z to -j. If 
j < i, then X [i : j] is the empty string. We use lcp(X, Y) to indicate the length of the longest common 
prefix between any two strings X and Y, and S6 to denote the standard lexicographic order among strings. 
We introduce three special characters $, Q, # @ E such that $<L Cl<L C <L #, for each cC~ (we assume 
Q <L @). For any string X Z+, we go through the convention that X@[Z] = @ and X$[Z] = $, when i > 1X1. 
From our definitions, it follows that lcp(X, Y) = lcp(X@, Y@) = lcp(X$, Y@) and we have: Fact 1 Given 
three strings P, X, Y c E+, (a) if X@ <L P$ then lcp(X, P) < IPI; (b) if P$ <L X@ <6 Y@ then lcP(X, 
P) 2 lcP(Y, P); (C) if Y@ <L X@ <L P$ then lc~(x, P) > lc~(y, P).  Let S = {XI,.. ., X~} be a set of 
strings over E, ordered according to S6. A position j E [1, d + 1] in S is defined to be between X3 1 
and Xj, for j c [2, d]; it isbefore Xl forj=1,and after X~for3=d+ 1.The positions 1 and d + 1 are therefore 
called the leftmost and rightmost position in S, respectively. Note that each Xj E S is associated with 
two neighbor positions, namely j and j + 1. Finally, we denote the greatest string xd c S and the smallest 
string Xl c S by maz S and min S, respectively. In the rest of the paper we assume that the reader is 
familiar with the B-tree data structure [11]. We work under the following assumptions. Every string X 
is al­located into a segment of contiguous pages of secondary storage, each of size B, and is represented 
only by the pointer to its starting location in secondary storage. Thus the page containing the i-th 
character X [i] can be located by simple arithmetic operations in O(1) com­puting time. 3 Blind Tries 
The blind trie BTs for an ordered set S = {Xl,..., Xd} of (possibly equal) strings is, in its essence, 
a Patricia j= tree [20] built on the augmented set S = {Xj : 1~ . . . . d} u {#} of distinct strings, 
where the shorthand Xl denotes XJ Cl. Note that S is ordered and the right­ most string in this order 
is given by Xd+l = #. The blind trie BTs satisfies the following proper­ ties: (1) Each arc is labeled 
with a character from E u {@, #}. (2) Each internal node has at least two children and its outgoing arcs 
are labeled with differ­ ent characters< ordered according to ~ 6. (3) For each string Xj c S, there 
is exactly one leaf v that main­ tains (a pointer) W(v) = ~~, and has associated the two neighbor positions 
j, j + 1 corresponding to X3. (4) Each leaf v stores the integer Zen(v) = IW(V)I (if W(v) = #, then len(v) 
= +@). (5) Each inter­nal node u stores the integer len(u) = lcp(W(2), W(f)), where 1, j are any two 
leaves having lowest common an­cestor u. Moreover, the characters W(l) [len(u) + 1] and W(f) [len(u)+l] 
label the two arcs departing from u and belonging to the paths reaching 1 and j, respectively. We adopt 
the notation W(u) for a generic internal node u E BTs so that W(u) = W(~)[l : len(u)] for an arbitrary 
leaf ~ descending from u. Moreover, arc (parent(u), u) has implicitly associated the substring W(f)[len(paren(u)) 
+ 1: Zen(u)]. Note that, given X ~ S, we ~an find the unique leaf j c BTs such that W(f) = X without 
disk accesses. Namely, since both W(j) and X can be seen as pointers to the same location into secondary 
storage, we need only to compare in O(1) time those two pointers instead of performing character-by-character 
comparisons. We also need the following definition. Given a leaf j c BTs and an integer 4 c [0, lerz(.f)], 
the hit node for the pair (f, ~) is the unique node u along the path from the root of BTs to j, such 
that Zen(u) >1 and /en(parent(u)) < t. The definition of hit node in blind tries corresponds to the equivalent 
notion of extended locus in compacted tries [22]. The blind trie data structure can support several dy­namic 
operations: Concatenate(BTS, BTSI, lcp, c, c ) is used for concate­nating two blind tries BTs and BTs, 
to produce a larger blind trie BTSusI for the set S U S . The strings in S should be lexicographically 
smaller than the ones in S . The other parameters are the length lcp = lcp(X, Y), where X = max S and 
-Y = min S ; and t~e two mismatching characters c = X [lcp + I] and C = Y[lcp+l], with c <L c (possibly 
c = @ <L C = @). Split(BTS, Xj) takes in input the blind trie BTs and a string Xj E S. It outputs the 
two blind tries built on {Xl,..., x$} and {Xj+l,..., Xd}, respectively. Insert(X, BTs, Z, lcp, CX, CZ) 
adds the string X to S, according to SAL, by inst ailing a new leaf .f in BTs, with W(f) = X. The other 
parameters are one string Z c S ~uch that lcp = lcp(Z2 X) = maxYeS{lcp(Y, X)}, Cx=X[lcp +1]and cz=Z[lcp 
+1]. Delete(X, BT~) removes the string X e S, by cancel­ing the leaf f BTs such that W(f) = X, and possibly 
removing also the parent of f if it becomes unary. Lemma 2 Assuming that the blind tries are already 
in main memory, Concatenate, Split, Insert and Delete re­quire O(d) computing time and no disk access. 
We remark that the power of a blind trie BT5 lies mainly in its ability to store the essential information 
 Ofs= {xl,..., Xd} with only O(d) characters and integers, independently of the total length ~~=1 IX3 
\ of the strings in S, even if they are in secondary storage. Note that the total number of nodes in 
BT5 is at most 2d + 1, while it might be ~~=1 1X31 >> d. Blind Branching. Operation Max-Lcp-Leaf(P, BTs), 
for nonempty P[l : p], finds the leaf 1 c BTs such that W(l) has the longest common prefix with P. That 
is, lcp(W(l), P) = max~~s {lcp(X, P)}. We append $ t? the end of P, so that P$ is not a prefix of any 
string of S. We visit recursively a downward path II from the root of BT5. During the visit of a generic 
node u c It, if there is an outgoing arc labeled with P$ [Zen(u)+ 1], then we follow it. Otherwise, we 
go into an arbitrarily chosen leaf 1, among the ones descending from u, such that W(l) # #. That leaf 
1 is returned by Max-Lcp-Leaf. This simple visit exhibits a very useful property. Lemma 3 Max-Lcp-Leaf(P, 
BT5) retrieves the leaf 1 ~ BT5 such that lcp(W(l), P) = maxx=s {lcp(X, P)}, re­quiring at most 2d comparisons 
and no disk access. Proofi Assume by contradiction that there exists an­othe: string .~ # W(l) of S, 
such that lcp(W(l), P) < lcp(X, P). Thus, lcp(W(l), X) = lcp(W(Q, P). Let u E BT5 be the lowest common 
ancestor between 1 and the leaf storing .~. By Property (5) of blind tries, len(u) = lcp(W(l), X) < p; 
hence, W(u) is a proper prefix of P. Therefore, M ax-Lcp-Leaf(P, BT5 ) must tra­verse u and branch into 
a child u of u, using the char­acter P$[len(u) + 1] = X[len(u) + 1] # W(l) [len(u) + 1]. However, 1 cannot 
be a descendant of u , contradicting the fact that 1 is reached during the visit of BTs. The bound 2d 
on the total number of comparisons, easily derives from the size of the blind trie. l We remark that 
M ax-Lcp-Leaf finds the leaf 1 without actually computing lcp(W(l), P). Extending the search of a string 
P. Operation Extend-Search(P, BTs, t) finds the correct position j c [1, d+ 1] of P[l : p] into the ordered 
set S. That is, j+is the sma~lest ~mong the positions i such that ~P$ <L X,, where X, G S (note that 
j ~ d + 1, since X~+l = #). In addition, Extend-Search takes in input an integer I z O, under the hypothesis 
that there exists X E S such that lcp(X, P) 2 /. The procedure computes also the length lcp = maxXe5 
lcp(X, P) z L. The integers t and lcp are crucial to perform efficiently an incremental search through 
a sequence of related blind tries (see Section 5). Therefore, the output of Extend-Search is the pair 
(~, [cp). First we execute Max-Lcp-Leaf(P, BT5 ), to find the leaf 1 such that lcp(W(l), P) = lcp (Lemma 
3). Second, we actually compute lcp without rescanning, using the fact that lcp ~ 1. Lemma 4 The length 
lcp = maxxes icp(X, P) can be computed wzth at most [~] + 1 disk accesses and lcp e + 1 comparisons. 
Proofi Since /cp(W(l), P) = lcp ~ /, the comparison between IV(l) and P$ can start from the (1+ 1)-th 
char­acter and proceed until the first mismatching character W(l) [lcp + 1] is encountered. Such a character 
is kept into main memory for later use. We do lcp / + 1 com­parisons, and hence we need to retrieve 
only the pages containing the substring W(l) [/ + 1: lcp+ 1]. Since each page of secondary storage contains 
B characters, the total number of retrieved pages is at most [%1 + 1, Indeed, in the worst case, W(l) 
[lcp + 1] could be the first character in the last retrieved pag,e. 0 Next, we choose a leaf .z to give 
the correct posi­tion j of P into S. Indeed, we detect the hit node u ~ BTs for the pair (i, lcp), where 
lcp = lcp(W(l), P) (by Lemma 3). There are two cases on u to choose z. In the first case, Zen(u) = lcp. 
Therefore no character labeling an arc outgoing from u can match the char­acter c = P$ [lcp + 1]. If 
c is the greatest among the characters labeling the arcs outgoing from u, then we go to the rightmost 
leaf f descending from u (it cannot be W(f) = #), and take z as the leaf to the right of ~. If c is the 
smallest, then z is the leftmost leaf de­scending from u. Otherwise, we find two consecutive children 
U1, Uz of u, whose arcs have respectively labels C1,CZ e XU {@, #} such that c1 <L c <L CZ. We take z 
as the leftmost leaf descending from U2. In the second case, ten(u) > icp. Therefore, all the strings 
associated with the leaves descending from u share the same prefix of length len(u), with len(u) > lcp 
> len(parent(u)) (by Property (5)). By Lemma 3, lcp is the length of the longest common prefix between 
P and any other string of S. Thus it suffices to compare the two mismatching characters c = P$ [lcp + 
I] and c = W(Z) [lcP + 1] to find z, where C is already in main memory (Lemma 4). If c <~ c , then all 
the leaves descending from u correspond to the strings of S that are lexicographically greater than P$. 
We take z as the leftmost leaf descending from u. Similarly, if c <~ c, then we go to the rightmost leaf 
~ descending from u (it cannot be W(f) = #), and take 2 as the next leaf to the right of j. Once that 
z has been determined, we know its two neighbor positions j and -j + 1, for some j c [1, d + 1]. Then 
we output J as the position for P. Theorem 5 Let P be a string in 2+, and BTs be the blind trie for a 
set of strings S = {X:l, . . . . Xd} ~ ~+. Fix an integer ( z O satisfying lcp(X, P) > /, for some string 
X c S. Then Extend-Search (P, BTs, /) correctly finds the position j E [1, d + 1] of P in S and computes 
lcp = maxxe~ lcp(X, P), with at most [%1 + 1 disk accesses and 3d + lcp L + 1 comparisons. Corollary 
6 Extend-Search can also establish whether lcp=lcp(Xj-l, P) orlcp=lcp(Xj, P) (p~ssibly both). It also 
finds the mismatching characters Xj-l[lcp+l] orij[lcp+ l], respectively. 4 The SB-Tree for Strings WJe 
describe now our main data structure for a set A = {s1,..., 6K } ~ 2+ of text strings, whose total length 
is iV = ~fll 1611. Define the set SUF(A) = {S1, . . . ,SN} as the sequence of the suffixes d[j : 161] 
of the strings b E A, with 1 ~ j ~ Idl, ordered according to <L. we also add to SUF(A) two special strings 
So, SN+l @ Z* such that So <L X <L SN+I, for each X C ~+. we use interchangeably the term string of SUF(A) 
and pointer to it, unless explicitly specified. The SB-Tree data structure for the set A (in short, SBTA 
) is the generalization of a B+-tree, of order t< B, built on the ordered set SUF(A) according to <L. 
Each leaf f G SBTA is associated with a set of strings Sf ~ SUF(A), with t < lSfl < 2t, ordered accord­ing 
to <~. The property is that the strings found in the leaves of SBTA, in left to right order, give a partition 
of SUF(A). The page for f has a pointer parent(f) to its parent node, and two pointers next(f) and prev( 
f ) to its next and previous leaf in SBTA, re­spectively. In f we also maintain the integer lcp(X, Y) 
and the mismatching characters X@ [lcp(X, Y) + 1] and Y@[lcp(X, Y) + 1], for X = maz Sf, Y = min Snemt(f) 
and X = max L$pre.( f ), y = man Sf. (Recall that the special character @ is needed to manage easily 
the case in which X is prefix of Y.) To efficiently select a string in Sf, we store the blind trie BTf, 
built on the set Sf, in the page for f. For each string X E Sf, we define a pointer SUCC(X) as follows. 
Since X = 6[j : 161] for some 6 E A and 1 s -j s 161, we make SUCC(X) point to the leaf f E SBTA such 
that c$[j + 1: 161] E Sf, (if j = [61 then SUCC(X) = nil). Each internal node r E SBTA has g children, 
with t < g ~ 2t, and stores the pointer parent(n) to its parent (for n # root). Also x is associated 
with an or­dered set of strings S. G SUF(A), where IS. [ = 2g. Let L(n) = min S. and R(T) = maz S= be, 
respec­tively, the smallest (leftmost ) and the greatest (right­most ) string in Sm, according to <L. 
Then, S7 con­tains the 2g strings ST = {L(m, ), R(mi ) }i=l,..,g, where xi is the i-th child of z. That 
is, ST is formed by the smallest and the greatest strings contained in its chil­dren. Clearly, R(m, )@ 
<~ L(nZ+l )@ implies that S. is ordered. Again, to efficiently select a string in ST, we store the blind 
trie BTn, built on S=, into the page allocated for T. It can be shown that the height h of SBTA is h 
~ logt N = @(logB N) [12], since we have a branching factor g ~ t= @(B). Indeed, we want to fit each 
node of SBTA into a single page of secondary storage. Therefore, we have to guarantee that the total 
space re­quired by all the information (e.g., blind trie, pointers to strings, parent pointer, etc. etc.. 
) in each node is at most B, since a page contains B units of data. A few relevant properties of SBTA 
are needed later: (PI) Given an internal node n and a string X c S., there exists a child r of x such 
that either X = L(7r ) = m2nSn/ or X = R(m ) = mazS=~. (P2) For each m, we have that L(T) is the smallest 
(resp., R(m) is the greatest) string stored in the leaves of SBTA descending from r. (P3) Let P ~ Z+ 
be an arbitrary string, and n be some internal node. There always exists a child T of n such that maxx~sw 
lcp(X, P) < maxx=s=, lcp(X, P). 5 Searching for a pattern P Given a pattern string P[l : p], we show 
how SBTA can be efficiently used to retrieve all the OCC(P) ~ SUF(A) strings having P as prefix. Our 
search algo­rithm returns the occ pointers to the starting locations of the strings in OC 6 (P) into 
secondary storage, where Occ = 1OCC(P)I. The main goal of searching for P is to find the suf­fixS3GSUF(A), 
with 1~j sN+1,suchthat Sj-l@ <L P$ <L Sj@. If lcp(Sj, P) = p, the two spe­cial characters $ <L @ ensure 
that S~ is the leftmost string of SUF(A) having P as a prefix (Fact la), and OCC(P) is a contiguous portion 
of SUF(A) (Fact lb). Thus we can retrieve all the pointers to the strings in OCC(P) by simply scanning 
rightward the consecutive leaves of SBTA, starting from the one containing S3. We go rightward as long 
as lcp(S,, S.+l ) ~ p, where j ~ r < N. The integer lcp(Sr, S.+l ) is always known. Indeed, if both S., 
Sr+l E Sf, then the lcp between all the pairs of consecutive strings of Sf can be determined using BTf 
in O(B) computing time and no disk access (Property (5) of blind tries); else, S. = max Sf and Sr+l = 
min Snext(f), so that the lcP is maintained in f. lVe focus therefore on finding Sj. We need to route 
the search of P through the internal nodes of SBTA, starting from its root. In each traversed node, a 
straightforward use of blind tries would scan P from scratch, requiring 0( ~ logB N) disk accesses in 
total. 698 Instead, our routing hinges on the incremental approach described for the Extend-Search operation 
(Theorem 5), as well as on Properties (Pi)-(P3). Assume to have reached a node ~%at level i of SBTA, 
and to have matched the first /?, characters of P, for i=l ,..., h. Initially, node rl is the root and 
11 = O. Let LL(T,) be the string that precedes .L(~,) in the ordered set SUF(A). Similarly, let RI?(T; 
) be the one following l?(~i). Note that, if either t = 1 or m, lies on the leftmost path of SBTA, then 
LL(r, ) is undefined (since L(m,) = SO) and thus we assume LL(mt) = SO too. Similarly, if either i = 
1 or n, lies on the rightmost path of SBTA, then RR(n,) = SN+l. For z = 1,.. ., h, we maintain the following 
invariant on r%, 4!1: Invariant-A(ml, et): (Al) There exists a string X c S=, satisfying lcp(x, P) > 
/i; (A2) LL(m,)@ <~ P$ <L RR(mz)@; (A3) lcp(R(nl), P) ~ /cp(RR(7r1), P). Invariant-Al ensures that we 
may apply Theorem 5 (possibly) to extend the matched prefix of P, of length J2,,computing ~1+1 = maxx~sm, 
lcp(X, P). The left part (LL(TZ )@ <~ P$) of Invariant-A2 guar­antees that P cannot be prefix of any 
string in SUF(A) strictly before L(n, ) since we have lcp(LL(m, ), P) < p (Fact la). The right part (P$ 
<L RR(T, )@) of Invariant-A2 along with Fact lb guarantee that every string X c SUF(A) following RR(m,) 
is such that lcP(X, P) S lcp(RR(m, ), P). Invariant-A3 strengthens such a rela­tion, allowing us to infer 
that lcp(X, P) s lcp(R(n-,), P) for any X following R(7rl ). In conclusion, the right part of Invariant-A2 
and Invariant-A3 guarantee that, if P is not a prefix of R(7r2), then P cannot be the prefix of any string 
of SUF(A) following R(m, ). Invariant-A(ml, PI ) is trivially satisfied. Thus, given r~, let ST, = {Xl, 
..., X29), with t 5 g s 2t. We need to perform a g-way decision in order to route the search from ~, 
to its proper child ~,+1, accord­ ing to Property (P3). We apply Algorithm Extend­ Search(P, BTm&#38;,l,), 
described in Section 3, to find the correct position k E [1, 2g + 1] of P into the ordered set &#38;,, 
and to compute P,+l = maxx=sw, lcp(X, P) (The­ orem 5). Therefore, we distinguish among three main cases, 
depending on the position k found by Extend- Search. Recall that Xl = L(mt) and Xz~ = R(ni). . Rightmost 
(k = 2g + 1): In this case no oc­currence of P does exist, and we stop the searching process. Indeed, 
since P$ >L R(m, )@, we have that lCp(R(Ti), P) < p by Fact la. Hence, by the right part of Invariant-A2 
and Invariant-A3, P cannot be the pre­fix of any string of SUF(A) following R(ml ). More­over, by Fact 
lc, P cannot be the prefix of any string of SUF(A) preceding R(ni ). Leftmost (k = 1): If li+l = /cp(L(:rri), 
P) < p then no occurrence of P does exist. Indeed, using the left part of Invariant-A2, we derive that 
P cannot occur to the left of L(nl ). Moreoverl by Fact lb, P cannot occur to the right of L(n, ). Otherwise 
(Li+l = p), we may concllude that L(mz) must be the leftmost string in SUF(A) having P as prefix (recall 
that LL(ni )@ <L P$). Therefore, we set SJ = L(m, ), and take m,+l, . . . . ~h as the nodes along the 
leftmost path in SBTA descending from n,. Clearly, L,+l = . . . = th = p. Note that Invariant-A(~T, LT) 
is preserved for every r = z + 1,. ... h, since LL(mr) = LL(n,_l) and L(mr) = L(n.-l). . Otherwise (1 
< k < 2g + 1): In this case, by Property (PI ) on K, and xk, there exists a child mi+l of mi such that 
either (a) xk = L(m,+l ) or (b) xk = R(? r,+l ). Case (a) means that xk is the smallest string of s ~L+l, 
and X&#38;l is the greatest string into the left sib­ling of n,+l. Note that, by Property (P2), the suf­fixes 
Xk_l and X~ are consecutive also in SUF(A). Now, if L+l < p then P does not occur, and we stop the search. 
It follows from Fact lb,c, since lcp(x&#38;l , P), lcp(xk, P) < 1,+1 < p. Otherwise (L t+l = p) we terminate 
the inductive search since xk must be the leftmost string in SUF(A) having P as pre­fix (i.e,, sj = X~ 
), Invariant-A is mairltained as done for the Leftmost case. In case (b), we have X~ l = L(ni+l ) and 
continue the induction with T,+l and 1,+1. By Property (P2), we are guaranteed that S1 is contained in 
some of the descending leaves of n~+l. Thus, when we reach a leaf ~h of SBTA (i.e., z = h), either Extend-Search(P, 
BTT,,, Lh) finds the sufix S3 or it discovers that P does not occur as prefix of any string in SUF(A) 
(by Theorem 5). Note that Invariant-A(x,+l, /,+1) is preserved. In­ deed, Invariant-Al is satisfied because 
both X&#38;l and xk belongs to S~,+,, and either /,+1 := lcp(X~-1, P) or g,+l = lcp(X~, P) by Corollary 
6. Moreover, since .~&#38;l @ <L P$ <L xk @, then Invariant-A2 k a,k50 ver­ ified. Finally, Invariant-A3 
holds by Fact 1b, because P$ <~ xk@ <L RR(n,+l)@. We remark that, by Property (P3), the downward visit 
of SBTA determines a non-decreasing sequence 4,+1 >l~,fori=l, o.., h, Therefore, as long as we go deeper 
and deeper into SBTA, we possibly extend the matched prefix of P without rescanning it. Theorem 7 It 
is possible to search correctly for all the occ occurrences of P with at most 3 Iogt N + ~ -t­ r~l = 
o(-+logB N) disk accesses and O(p+occ+ B logB N) time. Proof: The correctness can be proved by induction 
on i = 1, ..., h using Invariant-A(n-,, 1,). We have already shown that the basis holds for i = 1. The 
inductive step is based on the case analysis discussed above. We analyze now the total number of disk 
accesses and the computing time. In the z-th inductive step, we need one disk access to retrieve node 
r% from secondary storage. By Theorem 5 (with d < 4t = (3(B)), Extend­Search(P, BTm,, ~i) computes the 
correct position k of P in S.,, and the integer ti+l, with at most [~] + 1 disk accesses and at most 
12 t+&#38;+l ~i + 1 comparisons. We remark that it must be /,+1 ~ (?, by Invariant-Al. Therefore, the 
number of disk accesses needed to reach S3 is at most ~~=l([~a+~ ~ l + 2) s 3h + ~, where h ~ Iogt N. 
The scanning of the leaves of SBTA, to retrieve the occurrences in OCC(P), requires further [%1 disk 
accesses because at least tsuffixes are con­tained into each leaf of SBTA. Since the processing of each 
retrieved page requires O(B) comparisons, the tot al computing time is O(p + occ + B logB N). 0 The number 
of disk accesses required by our Search procedure is optimal for an unbounded alphabet 2, since it matches 
the 0( ~ + ma%{ Q&#38;, logB N}) lower bound that can be proved by a simple adversary argu­ment. Corollary 
8 Let x c SBTA and / ~ O satisfy Invariant-A (n, t). Even if P does not occur, the cor­rect position 
of P in SUF(A) and the length lcp = maxX~Su~(A) lcp(X, P) can be found with O(logB N + ~) disk accesses 
and O(B logB N+lcp 1) computzng time.  6 Updating the SB-tree Inserting or deleting a string in SBTA 
is more involved than searching. Due to lack of space, in this section we sketch only the main ideas 
underlying the insertion of a string Y[l : m] to produce SBT AU{Y}. We insert the suflix Y[z : m] by 
induction, for i = 1,2,. ... m. We could apply Corollary 8 for all i, search­ing P = Y[i : m] in the 
SB-tree. But this would require 0( # + mB logB (N + m)) disk accesses. Instead, we provide an incremental 
insertion procedure that reduces the number of disk accesses to O(m(B + logz ~)). Let SBT, be the SB-tree 
SBTA after the in­sertion of Y [1 : m], ....Y[i 1 : m], and let SUFZ = {S:,..., Sfi+t} be the ordered 
set of strings in SUF(A) U {Y[l : m],. . . . Y[i 1 : m]}, contained into the leaves of SBTZ. Define 
headi as the longest prefix of Y [i : m] which is also prefix of some string in SUF,, and h. = Iheadi 
1. Inserting Y[i : m] consists of three main phases. Phase 1: We find the position k of Y[i : m] in SUF%, 
such that S~_l Q <~ Y[i : m]$ <L Sj@, and the leaf f containing S$ (i.e., S~ C Sf). Phase 2: We insert 
Y[z : m] in the set Sf of the strings according to ~ L. Phase 3: If a page overflow is generated (i.e., 
lSf I > 2t), then we must split f and propagate the split upwards, as long as an overflow is created. 
Fi­nally, we have to check whether or not the pointers L() and R() in the upward path from f to the root 
should be updated. If so, we maintain them properly. Phase 1. We work by induction. The basis (i = 1) 
consists in searching P = Y[l : m] in SBTI = SBTA to find headl, as stated in Corollary 8 (setting m 
= root and / = O). In this way, we find also the two consecutive strings S~_l, S; G SUFI between which 
Y[l : m] has to be inserted, producing SBT2. We remark that at least S~_l or S; has headl as prefix (by 
Corollary 6). In the inductive step i > 1, we exploit the fact of having already inserted Y [i 1: m] 
in SBTZ_l to pro­duce SBTZ. Assume to have correctly maintained the succ pointers for all the strings 
in SUFZ, except for Y[i 1 : m]. Recall that (1) we have found the pair (S~l~, S~-l) in SUF,-I such that 
S~l~@ <L Y[i -1: m]$ <L S~-l @, along with hertd,-l, and (2) one string Z E {S~I~, S~-l } has head,.-l 
as prefix. For the sake of discussion, assume that Z = 6[j : 161] SUF,_l, Note that succ(ti[j : [61]) 
is defined. We show how to find (S~_l, S;) and headi in order to preserve the induction and insert Y[i 
: m] into its proper leaf j. Clearly, at the end we should set succ(Y[i I : m]) = f (and succ(Y[m : 
m]) = nil when z = m). We use the following lemma, originally proved for suffix trees. Lemma 9 (McCreight 
[22]) The second sujjix of headi_l is a prefix of head%. Let a be the second suffix of head% l (if head, 
l is empty then a is also empty). We use a and possibly the succ pointers, to choose a leaf 1 such that 
there exists a string in S1 having Q as prefix. From 1 we start an upward visit of SBTi, maintaining 
an invariant that allows us to determine the lowest common ancestor between 1 and the (unknown) target 
leaf ~. Then, we go downward locating f and (S~_l, Sk ). We are able to show that visiting a generic 
node, either we further extend a (to find head, ) or we take the next node in the visit. In this way, 
we limit the number of disk accesses and do not rescan Y [i : m]. Formally, let a = 6[j + 1: j + h,_l 
 1]. By Lemma 9, a is a (possibly empty) prefix of head!, that is, a = Y[i : z + la] 1] (recall that 
[al = max{O, hi-l l}). If a is empty then 1 is the current leaf, that is, the one containing 6[jI, 16[]. 
Otherwise, succ(f[j : [6[]) # nil, because j + 1<161, and it points to the leaf containing ti[~ + 1: 
]6[]. Therefore we take 1 = succ(6[j : 16[]), and retrieve it with one disk access. Next, we use the 
blind trie BT1, and carry out Extend­Search(Y[z : m], BT1, Ial), to extend Y[z : z + Ia[ 1] among the 
strings in the set S1. Note that it suffices to scan only the characters in Y[i + Ia[ : m] by The­orem 
5. In case that Extend-Search returns a position in S1 being neither the leftmost nor the rightmost one, 
we have found (S~_l, S;) and head, (by Theorem 5 and Corollary 6). Therefore, we set ~ = 1 and go to 
Phase 2. Otherwise, we deal with the case in which Extend-Search returns the leftmost position in SJ. 
(The other case for the rightmost position is symmetrical, and not discussed.) We execute two further 
steps in order to find the correct leaf ~. Upward Step: We walk upward from 1 until we reach the lowest 
common ancestor between the (known) 1 and the (unknown) leaf f. Downward Step: From such a lowest common 
ancestor, we go downward to reach f. In both steps, we extend a longer and longer prefix of Y[z : m] 
to find head,. Let pref,, with Ial ~ pre f, s h,, be the length of the prefix of Y[i : m] matched so 
far. We describe the two steps. Upward Step: Since Extend-Search has returned the leftmost position in 
Sz (see above), the leaf f should be found to the left of 1 (inclusive). Let m be the current node, and 
S= be its associated set of strings. We main­t ain the following invariant on r: Invariant-B(n): We know 
Z G ST such that (Bl) Z = L(m ) for some child node n of m; (B2) Y[i : rn]$ <~ Z@; (B3) lcp(YIz : m], 
Z)= prefi. Initially, n = parent(l), # = 1, Z = 6[j + 1: 161] and pref, = ICEI= max{O, h,_l 1}. (Recall 
that @ and $ are needed to guarantee that if Y[z : m] = Z then Y[i : m] $ <L Z@.) Invariant-B implies 
that each node n along the upward path from 1 to r , satisfies Y[z : m]$ <L L(m )@ and lcp(YIz, m], L(7r 
)) S P~eft (by Fact lb). That is, each string S c SUF, to the right of L(# ) has lcp(Y[i, m], S) S pref,, 
and thus Y[z : m] has to be inserted in some position to the left of L(n ) in SBTi. We maintain Invariant-B 
as follows. We execute Extend-Search(Y[i : m], BTT, pref, ), thus finding the correct position of Y[z 
: m] in the set ST. We update pre f, setting it to maxxes= lcp(X, Y[i : m]), which is computed by the 
Extend-Search operation. If Extend- Search returns the leftmost position, then Invariant-B is preserved 
by setting m = n and n =: parent(n) (and we repeat the Upward Step). Otherwise, r is surely the lowest 
common ancestor of 1 and f, and Extend-Search finds the correct position of Y[i : m] in $= and the string 
S c Sr such that lcp(S, Y[i : ml) = rnaxxc.s. lcP(X, Y[i : rn] ) (Theorem 5). Then, we set pre f, = lcp(S, 
Y[z : m]) and go to the Downward Step. . Downward Step: After the executicm of the Upward Step, node 
n is an ancestor of f, and S is one of the strings in &#38; having the longest common prefix with Y[i 
: m]. We show that Invariant-A(r, pre fi) is satisfied (see Section 5), so that we may apply Corollary 
8 to SBT,, with P = Y[i : m] and 1 = pre~i. Invariant-Al is valid since S c S7 satisfies lcp(S, Y[z : 
m]) ~ L = pref,. Invariant-A2 and A3 hold since L(m)@ <~ Y[z : m]$ <L R(T)@ and, by Fact lb, lcp(l?(r), 
Y[i : m]) ~ /cp(RR(n), Y[z : m]). Thus, applying Corollary 8 we reach the leaf f finding (S~_l, S;) and 
head,. Phase 2. Let f be the leaf and (S~_l, S;) be the pair found in Phase 1, where S; G Sf. We show 
now how to insert Y[i : m] into Sf in order to produce SBTi+l and SUFi+I. If S~_l c Sf, by Corollary 
6, we know which one between S~_l and S;, say S;, has the longest common prefix, head%, with Y[i : m]. 
We know also the mismatch character c of S; (i.e., c = S~@[h, + l]). Then, we execute Insert (Y[z : m], 
BTf, S;, hi, Y[i + h,], c). lf %-l 6 me~(f) hen> 0 nsert cO]crectlY [z : 1 into sf, we need to compute 
lcp = lcp(S~, Y[t : m]) and c = s; @[/cP + 1]. We proceed as follows without doing further disk accesses. 
Recall that, we have maintained in the leaf f the integer lcpl = lcp(S~ _l, S;) and the character c1 
= S; [lcpl + 1] (see Section 4). By a case analysis it is possible to show that, if hi > lcpl and c1 
# Y@[i + icpl], then lcp = Zcpl and c = c1. Otherwise, lcp = h, and c = S~ @[h, + 1], which is known 
by Corol­lary 6 since actually lcp(S~, Y[z : m]) = h,. Finally, we execute Insert (Y[z : m], BTf, Sj, 
lcp, Y[t + lcp], c). Phase 3. Due to lack of space, we only remark that this phase could access O(B) 
pages for each split node, because of the update of the parent and succ point­ ers. To guarantee a good 
worst-case performance dur­ ing a sequence of splits on an upward path in SBTA, the parent pointers of 
sibling nodes are organized like a 2-3 tree [1]. The nodes of the 2-3 tree are pages of sec­ ondary storage. 
In this way, a Split of a node n requires 0(log2 B) disk accesses in order to update the parent pointers 
to m. Moreover, 0(log2 B) disk accesses are sufficient to retrieve the parent of a given node. (The same 
bounds hold for the Concatenate operation. ) We remark that 2-3 trees are used only for the parent point­ 
ers, while each node remains directly connected to its children, so that we can still branch with only 
one disk access. The overall number of pages to store SBTA still remains @(N/B). Theorem 10 A string 
Y[l : m] can be inserted into A in O(Bm logz ~) computing time with O(m(B + log2 ~)) worst-case disk 
accesses. It is possible to delete Y[l : m] from A in O(B m log2 }) computing time with O(m(B + logz 
~)) worst case disk accesses. A more complex amortization argument, based upon a proper redistribution 
of keys among sibling nodes, al­lows us to reduce the overall number of disk accesses without using 2-3 
trees (details in the full paper). Theorem 11 It is possible to insert or delete Y[l : m] with O(m logB 
(N + m)) or O(m log~ N) amortized disk accesses, respectively. Our SB-tree can be easily used to solve 
efficiently also the EDPSS problem within the same bounds as those in Theorems 7, 10 and 11. As byproduct, 
fixed B = 0(1), we may use the SB-tree into main memory to do on-line searches in (parameterized and 
classical) pattern matching problem [2, 5, 12]. We achieve faster and alphabet-independent searches taking 
O(p+log iv+ OCC)time instead of O(P log N+ OCC),when the alphabet is unbounded. Acknowledgments. We thank 
R. Giancarlo, F. Luc­ cio and R. Sprugnoli for their useful comments. References [1] AHO, A. V., HOPCROFT, 
J. E., AND ULLMAN, J. D. The design and analysis of computer algordhms. Addison-Wesley, 1974. [2] AMIR, 
A., FARACH, M., GALIL, Z., GIANCARLO, R., AND PARK, K. Dynamic dictionary matching. Journal of Computer 
and System Science 49 (1994), pp. 208 222. [3] AMIR, A., FARACH, M., AND MUTHUKRISHNAN, S. Al­phabet 
dependence in parameterized matching. lnjor­mation Processing Letters 49 (1994), pp. 111 115. [4] APOSTOLIC, 
A. The myriad virtues of subword trees. In Combinator~al Algorithms on Words (1985), A. Apostolic and 
Z. Galil, Eds., NATO ASI Series F: Computer and System Sciences, Springer-Verlag, pp. 85 96. [5] BAKER, 
B. S. A theory of parametrized pattern matching: Algorithms and applications. In ACM Sym­posium on Theory 
of Computing (1993), pp. 71 80. [6] BAYER, R., AND MCCREIGHT, C. Organization and maintenance of large 
ordered indexes. Act a Injormatica 1, 3 (1972), pp. 173 189. [7] BAYER, R., AND UNTERAUER, K. Prefix 
B-Trees. ACM Trans. Database Syst., 2 (1977), pp. 11 26. [8] BLUMER, A., BLUMER, J., HAUSSLER, D., Mc-CONNELL, 
R., AND EHRENFEUCHT, A. Complete in­verted files for efficient text retrieval and analysis. Jour­nal 
of the ACM 34, (1987), pp. 578 595. [9] CHIANG, Y., GOODRICH, M. T., GROVE, E. F., TAMASSIA, R., VENGROFF, 
D. E., AND VITTER, J. S. External-memory graph algorithms. In ACM-SIAM Symposium on Discrete Algorithms 
(1995), pp. 139­ 149. [10] COMER, D. The ubiquitous B-Tree. Computing Surveys 11 (1979), pp. 121-137. 
[11] CORMEN, T. H., LEISERSON, C. E., AND RIVEST, R. L. Introduction to Algorithms. MIT Press, 1990. 
 [12] FERRAGINA, P., AND GROSSI, R. Fast incremental text editing. In A CM-SIAM Symposium on Discrete 
Algo­rithms (1995), pp. 531 540. [13] FLAJOLET, P., AND SEDGEWICK, R. Digital search trees revisited. 
SIAM Journal on Computmg 15 (1986), pp. 748 767. [14] FRENKEL, K. A. The human genome project and in­formatics. 
Communication of the A CIVI 34, 11 (1991), pp. 41 51. [15] GALIL, Z. Open problems in stringology. In 
Combina­torial Algorithms on Words (1985), A. Apostolic and Z. Galil, Eds., NATO ASI Series F: Computer 
and Sys­tem Sciences, Springer-Verlag, pp. 1 8. [16] GONNET, G. H., BAEZA-YATES, R. A., AND SNIDER, 
T. New indices for text: PAT trees and PAT ar­rays. In Information Retrieval: Data Structures and Algorithms 
(1992), W.B. Frakes and R.A. Baeza-Yates, Eds., Prentice-Hall, pp. 66-82. [17] GOODRICH, M. T., TSAY, 
J.-J., VENGROFF, D. E., AND VITTER, J. S. External-memory computational geometry. In IEEE Foundations 
of Comp. Sci. (1993), pp. 714 723. [18] GUSFIELD, D., LANDAU, G. M., AND SCHIEBER, B. An efficient algorithm 
for all pairs suffix-prefix problem. Information Processing Letters 41 (1992), pp. 181-185. [19] IDURY, 
R. M., AND SCHAFFER, A. A. Multiple match­ing of parameterized patterns. In Combinatorial Pat­tern Matching, 
(1994). [20] KNUTH, D. E. The Art of Computer Programming. Addison-Wesley, 1973, vol. 3: Sorting and 
Searching. [21] MANBER, U., AND MYERS, G. Suffix arrays: a new method for on-line string searches. SIAM 
Journal of Computing 22, 5 (1993), pp. 935-948. [22] MCCREIGHT, E. M. A space-economical suffix tree 
con­struction algorithm. Journal of the ACM 23, 2 (1976), pp. 262 272. [23] SALTON, G., AND MCGILL, M. 
Introduction to Modern Information Retrieval. McGraw-Hill, New York, 1983. [24] SUBRAMANIAN, S., AND 
RAMASWAMY, S. The P-range tree: A new data structure for range searching in sec­ondary memory. In ACM-SIAM 
Symposium on DM ­crete Algorithms (1995), pp. 378 387. [25] WEINER, P. Linear pattern matching algorithm. 
In Proc. IEEE SWAT (now, FOCS) (1973), pp. 1-11. 702 
			