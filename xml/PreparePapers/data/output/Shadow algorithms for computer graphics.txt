
 SHADOW ALGORITHMS FOR COMPUTER GRAPHICS Franklin C. Crow University of Texas at Austin Austin, Texas 
 ABSTRACT Appel [3] and then Bouknight and Kelley [5] have Shadows are advocated for improved comprehension 
demonstratedsolutions to the shadow problem which and enhanced realism in computer-synthesized are discussed 
in this paper in the context of a images. A classification of shadow algorithms de­ classificationscheme 
for shadow algorithms. lineates three approaches: shadow computation Three classes of solution are currently 
identifi­ during scanout; division of object surfaces into able (there may be further undiscovered classes). 
shadowed and unshadowed areas prior to removal of Appel, Bouknight and Kelley have shown solutions hidden 
surfaces; and inclusion of shadow volumes of one class and algorithms suggesting the other in the object 
data. The classes are related to two classes have been proposed but not yet imple­ existing shadow algorithms 
and implementations mented. within each class are sketched. A brief compari­ son of the three approaches 
suggests that the last The first class of algorithm,demonstrated by approach has the most appealing characteristics. 
Appel, Bouknight and Kelley, detects shadow boun­ daries as the image is produced by a raster-scan. KEY 
WORDS AND PHRASES: computer graphics, hidden- The edges of cast shadows are found by projecting surface 
removal, shadows, shading, raster displays potential shadowing polygon edges onto the surface being scanned. 
Shadow edges thus formed are then CR CATEGORIES: 8.2 projected onto the image plane. Upon crossing a 
shadow edge, the color of a scan segment is changed appropriately. INTRODUCTION A second class of algorithm 
involves two passes A major deficiency in most computer-synthesized through a hidden-surface algorithm,or 
perhaps a shaded images to date has been the lack of sha­ single pass through each of two differing algo­ 
dows. Although shadows are unneeded when the rithms. The first pass distinguishes shadowed and light 
source is coincident with the eyepoint, a unshadowed surfaces and divides partially shadowed fact which 
was used to advantage in many early surfaces by determininghidden surfaces from a implementations,many 
of the more pressing appli­ viewpoint coincident with the light source. The cations for realistic images 
(eg. spacecraft dock­ colors of shadowed surfaces are then modified and ing and aircraft landing simulators) 
require sun­ a second pass operates on the augmented data from lit images. Quite realistic images of 
scenes the observer's viewpoint. which should contain shadows are now made, but the success of these 
images relies on the assump- The third class of shadow algorithminvolves cal­ tion of a diffuse light 
source such as a cloud­ culating the surface enclosing the volume of space masked sun. swept out by the 
shadow of an object, its umbra. The umbra surface is then added to the data and There are situations 
in which shadows can be im­ treated as an invisible surface which, when pier­ portant. A cast shadow 
may make an important ced, causes a transition into or out of an object piece of equipment virtually 
invisible under ac­ shadow. tual conditions even though it shows clearly in a simulation without shadows. 
Applications of A more complete explanation of the three classes computer graphics to architectural siting 
prob­ follows with suggested implementationsin each lems and environmental impact investigations class. 
These will be preceded by remarks on could require the calculation of shadows for modeling of the light 
source and followed by an evaluating the need for airconditioningor the attempted comparison of the practical 
difficulties availabilityof solar energy. Most importantly, in implementing the three approaches. shadows 
provide valuable positional information; the shadow cast by one object on another can clarify otherwise 
ambiguous spatial relation- MODELING THE LIGHT SOURCE ships. Moreover, shadows pose an interesting problem; 
they should receive more attention than Light sources are generally modeled as either they have been 
getting. points or directions. However, an actual light Permission to make digital or hard copies of 
part or all of this work or personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies bear this notice and the full 
citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior 242 specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
 source has a finite size, a perhaps irregular shape and a definite position in space relative to the 
objects to be represented. Light sources of finite size cast shadows involving an umbra and penumbra. 
The umbra is that part of the shadow space which receives no light from the source; the penumbra, that 
part which receives light from some part of the source but not all of it. Thus there is a dark central 
area to any such shadow sur­ rounded by a border area in which a smooth change from shadowed to unshadowed 
takes place. For an irregularly shaped light source the penumbra could be approximated by a linear variation 
in shade over a strip of fixed width around the periphery of any umbra. Calculating a penumbra can be 
ex­pected to significantly increase the effort neces­ sary to represent shadows. Therefore, a point 
light source or one infinitely far removed (speci­ fied by a direction only) will be assumed. Shadow 
boundaries are determined by projecting the silhouette of one object onto another. The type of projection 
which may be used is dependent on the position of the light source. The easiest light source for which 
to calculate shadows is one that is infinitely far removed since shadow boun­ daries may be found by 
an orthographic projection. On the other hand, the calculation of shadow boun­ daries for a light source 
which has a position in the object space varies in difficulty with the lo­ cation. If the source lies 
outside the field of view, shadow boundaries can be calculated by using the same sort of perspective 
projection used for image display. However, when the light source lies within the field of view, different 
methods must be used. Since the conventional perspective transformation is accurate only for a limited 
 field of view, either the space must be divided into sectors radiating from the light source, in which 
the perspective transform can operate, or more complicated three-dimensionalgeometric meth­ ods must 
be used. Projective transforms provide convenience and efficiency. However, it is always possible to 
 define shadow boundaries in the object space by using the light source position and the object silhouette 
to define a surface and then calculat­ ing the intersection of that surface with other objects. CLASS 
ONE: SHADOW COMPUTATIONDURING SCANOUT Appel [2,3] and then Bouknight and Kelley [5] have shown methods 
for rendering shadows which calcu­late shadow boundaries while scanning the image. Appel detects shadow 
boundaries by extending his notion of quantitativeinvisibility. Quantitative invisibility is a count 
of the number of surfaces hiding a vertex (polygonal objects are assumed). Therefore, a line segment 
is visible only if all points on it have a quantitative invisibilityof zero. Changes in quantitative 
invisibilityalong a segment are detected by Appel's hidden surface algorithm and only the visible portions 
are drawn. This method yields a line drawing. Shadowed surfaces are determined during a scanning procedure 
which is also used to shade the line drawing. The scan is executed by generating "cut­ting" planes through 
the eyepoint which intersect  Figure 1: ABE defines a "cutting plane" in Appel's algorithm. Edges of 
polygon 1 are projected onto polygon 2 to form shadow boundaries which are then projected onto the image 
plane. the picture plane in equally-spacedhorizontal lines (fig. 1). A set of scan segments is defined 
by the intersection of visible lines and a cutting plane. The quantitativeinvisibilitywith respect to 
the light source (previously computed for all visible vertices) is then used to determine those segment 
parts which lie in shadow. Further detail is available in Appel's publications [1,2,3]. Bouknight and 
Kelley developed a similar method for shadow detection [4,5]. However, they en­ joyed an advantage in 
that their hidden-surface algorithmwas already based on a scanning process. A secondary scan was used 
to detect shadow boun­ daries calculated by projecting edges upon the surfaces being scanned. The primary 
scan followed a raster pattern in image space which generated the secondary scan, the corresponding 
path across the visible surface in object space. Therefore, shadow edges occurred where edges of other 
poly­ gons projected onto a secondary scan segment. A procedure for finding all polygons which could 
 cast shadows on a given polygon was used to dimin­ ish the edge-projectioncomputation. This routine 
 transformed all polygons to a pseudo-spherical coordinate space with its origin at the light source. 
Polygons were then tested for overlap and a linked list was formed for each polygon, enab­ ling the 
other polygons which might cast shadows on it to be easily found (In figure 1, polygon 2 would be linked 
to polygon 1). An expansion of this overlap test leads to the second class of algorithms as will be 
seen below. The general approach exemplifiedby Bouknight- Kelley can be analyzed as two basic operations: 
 (1) the shadow priority ordering of polygons and  (2) the calculation of projected shadow boundar­ies. 
It is worth noting that these two opera­tions are independent of the hidden surface algo­rithm used for 
display and this could be applied to virtually any polygon-based algorithm.  Many variations on the 
Bouknight and Kelley algo­ rithm can be developed. For example, the compu­ tation for their pseudo-spherical 
overlap test grows as the square of the number of polygons. It would thereforebe advantageous to divide 
the viewable object space into sectors radiating from the light source position. This would allow all 
 polygons in a sector to be sorted to a shadow priority order without reference to other sec­ tors. 
Shadow priority determination requires a special sort such as the one used by Newell et al [9]. The 
behavior of this algorithm (also obey­ ing an N-squared growth law) is discussedby Sutherland et al 
[12]. Under favorable conditions, sectorization can change the N-squared growth law of the Bouknight- 
 Kelley (or Newell et al) priority scheme to a linear growth law. The growth of the sectored scheme 
is proportionalto S (N/S)**2 where S is the number of sectors and N is the number of poly­ gons (as 
long as the general distribution of poly­ gons in space remains similar). If N/S is held constant by 
increasing the number of sectors pro­ portionallywith the number of polygons, the priority stage obeys 
a linear growth law. How­ ever, this growth rate is complicatedin the limit by the fact that when sectors 
become so small that a high percentage of polygons overlap sector boun­daries, the effectivenumber of 
polygons increas­es. This is due to the fact that a polygon over­ lapping two sectors must be considered 
in both. However, the potentiallinear growth rate makes this an attractive approach both here and in 
the design of sectorable algorithms in general. The second basic operation, the calculation of shadow 
boundaries, requires a process akin to clipping. The polygon under considerationmust be used as a window 
against which polygons of a high­er priority are clipped. The growth rate of this operation is proportional 
to the product of the number of edges in shadowed polygons and the num­ber of edges in higher priority 
polygons, again an N-squared growth rate. However, sectorization can again provide an overall linear 
growth rate under favorable conditions. (It should be noted that the linked list used here by Bouknight 
and Kelley is in some sense an optimized sectorization.) Two factors can substantiallyreduce the constant 
of proportionalityin the growth law: (1) shadow cal­ culation need only be carried through for visible 
polygons and (2) the calculation may terminate when a polygon is discovered to be completely shadowed. 
 In closing this section, it should be reemphasized that in all shadow algorithms, a large amount of 
 computation can be saved by considering only the silhouette of a shadowing object instead of each of 
its polygons individually. This restricts searching to only those edges which cause visible shadow 
boundaries. A SECOND CLASS: THE TWO-PASS APPROACH It would appear that a hidden-surface algorithm 
could be used to detect which surfaces are hidden from the light source as easily as those which are 
hidden from the eye. However, to be useful, the algorithm must yield information which can be used 
to generate an image, as seen from the eyepoint, in a subsequent pass. This restriction limits the 
class of applicable algorithms. Sutherland, Sproull and Schumaker proposed that hidden-surface algorithms 
could be divided into object-space algorithms and image-space algorithms [12]. This distinction turns 
out to be important since the determination of shadow boundaries must be made in object space so that 
the resulting in­ formation can be merged into the data to be sent to the display algorithm. Thus image-spacealgo­ 
rithms which depend on the limited resolution of the display medium to ease the determination of hidden 
surfaces are inappropriate for this appli­ cation. The algorithms characterizedby Sutherland et al 
[12] as operating strictly in object space all suffer from discouraginggrowth laws (computation increasingwith 
the square of the amount of data). Furthermore,where polygons are considered, they are not treated as 
entities but broken into indi­vidually treated sides. To create shadows, the polygons must be treated 
as entities so that they may be divided by shadow boundaries and returned to the data base as smaller 
polygons to be fed to the display algorithm. Eliminating the object­space algorithms leaves the algorithm 
shown by Newell, Newell and Sancha [9]. This algorithm provides many useful techniques for splitting 
 polygons and determining overlap but the eventual determination of what part of which surfaces are 
hidden is done by overwriting in image space. Sutherland has proposed another algorithm which is more 
applicable to the problem [11]. Using clip­ping techniques, a binary sort is executed sending polygons 
and parts of polygons lying on one side of a line out on one stream and those lying on the other side 
off on a different stream. Such a pro­cess is, of course, exactly what is needed for determining divisions 
between shadowed and unsha­dowed parts of surfaces. Furthermore, Suther­land's algorithm holds the promise 
of a reason­ able growth rate. Since the algorithmoperates by recursive subdivision of the viewed space 
via a 2-dimensional binary sort of the data, an N log N growth law may be achievable. Sutherland also 
proposed improvementsbased on considering only "contour" edges in the subdiv­ision process. Contour edges 
are those edges which separate frontfacing and backfacing polygons at those places where the surface 
curves behind itself or else edges which lie at the extremes of the surface, for surfaces which don't 
close on themselves [1]. Thus any area lying within the bounds of a set of contour edges for a single 
sur­face can be treated as a unit assuming that the bounded surface is the frontmost surface in the bounded 
area. Clark has proposed a general scheme for approach­ing hidden-surfacealgorithms which involves re­cursive 
descent through a hierarchical data des­cription [7]. The combination of this approach with Sutherland's 
notion of clipping to contour edges appears to hold promise for an interesting shadow algorithm. If environmental 
restrictions are imposed so that objects must be broken into linearly separable sub-objects and groups 
of such objects may also be linearly separated, then an algorithm may be implemented along the following 
lines. The first step of this algorithm would use sort­ing techniques akin to those of Newell, Newell 
and Sancha to establish a front to back priority ordering of the surfaces under consideration. The hierarchical 
approach proposed by Clark may be superimposed to first order otjects or groups of objects, then to establish 
an order within such objects or groups. Newell has recently suggested an algorithm for sorting objects 
to a depth prior­ity which could be applied here [10]. Note that, for purposes of shadow detection, 
the silhouette of an object may be used to define a "blot", or anti-window,under a perspective pro­jection. 
Anything lying within the blot and far­ther from the light source is clearly in shadow. Therefore, the 
algorithm can proceed by augmenting a collection of blots using the silhouette of each convex sub-object 
in turn. Moving away from the light source, surfaces hidden by the blot are marked as shadowed. Other 
surfaces contribute the unshadowed portion of their silhouettes to the collection and are themselves 
clipped into shadow­ ed and unshadowed portions. Finding object silhouettes for polygonal objects is 
eased by a data structure providing links be­tween adjacent polygons. Such a structure is de­tailed in 
[6,8]. Since the silhouette is formed solely from the contour edges and all contour edges on a convex 
surface must lie on the silhou­ette, the determinationof the silhouette consists of finding the closed 
loop of contour edges. Strings of contour edges may be formed straight­ forwardly. First, all polygons 
must be tagged as frontfacing or backfacing from the light source point of view. Secondly, the neighbor 
polygons for each frontfacing polygon must be checked; where backfacing adjacent polygons are found, 
the associated edge must be tagged as a silhouette edge. Lastly, silhouette edges may be linked to­ 
gether by using the adjacent frontfacing polygons to search for additional silhouette edges connect­ 
ed to a known silhouette vertex. For a convex object, a single such string of edges will form the silhouette 
(fig. 2).  By using the scheme proposed by Clark, the calcul­ ation of some object silhouettesmay be 
avoided. Following the hierarchical division of the data (groups, objects, sub-objects), tests using 
 "bounding boxes" may be used to determine which groups may overlap from the light source point of 
view. The bounding box is defined by the range of the object vertices over height and width (fig. 3). 
Any time the bounding box of an object is found to lie totally within the silhouette of an object of 
higher priority, the first object is in shadow. Similarly, if the bounding box of a convex object (consistingof 
a single sub-object) fails to over­ lap any others then the object is clearly not in­volved in any shadows. 
In these cases, there is no reason to compute the silhouette. The shadow algorithmmay be driven by 
the hierar­ chical organizationof the data. Thus groups of objects may be processed in priority order, 
clos­ est group first. Within each group, objects will be treated in priority order and within each 
ob­ 245 ject, sub-objects will be treated in priority order. Overlap tests can first determine whether 
groups may interact. If so, the bounding boxes must be passed to the next lower level of the hierarchy. 
Overlap tests are then applied to the objects within the group and finally to the sub­objects of each 
object. If the bounding box of a sub-object overlaps none of the bounding boxes passed down through the 
hierarchy, it may be ig­nored. Otherwise its silhouette is computed.  Having computed the silhouette 
of the highest priority sub-object for which it was required, intra-object shadow boundaries may be computed. 
This can be done by clipping the polygons of lower priority sub-objects to the silhouettes of higher 
priority sub-objects. If any lower priority sub-object is completely shadowed, it may be tagged as such 
and ignored in subsequent overlap tests. Partially shadowed sub-objects are clipped into shadowed and 
unshadowed portions; partial silhouettes are then computed based only on the unshadowed portion. Completely 
unshadowed sub-objects merely have their silhouettes calcul­ated. As the algorithm works its way down 
the priority­ordered list of objects, a minimal set of convex blots is built up, each blot with an associated 
bounding box. As lower priority objects are treated, they will first be clipped by the higher priority 
blots then the remaining polygons will be used to compute partial silhouettes to be added to the set 
of blots. It may be useful to include a provision to absorb a set of blots into a single one in the case 
where a lower priority sub-object is large enough to provide an envelop­ing silhouette. However, the 
overhead in check­ing for this case may well prove to outweigh the benefits. Where several groups of 
objects overlap, an ex­tremely large set of blots is likely to have been built up by the time lower priority 
groups are treated. To avoid undue growth of computation, the set of blots and untreated data should 
be sectored so that spatially separate areas may be treated independently. Using the information provided 
by the bounding boxes, sectorizationbe­comes trivial. It may even be advantageous to resector several 
times as the collection of blots develops. Also, sectoring based on the bounding boxes of lower priority 
objects would al­low blots which will no longer be needed to be dis­carded. Of course this approach 
depends heavily on a well­conditioned environment (convex sub-objects). It is not clear whether (1) the 
algorithm could be easily extended to the general case and (2) whether data generation and object modelling 
techniques could be forced to always deliver such well-condi­tioned data. In general, the testing sequences 
described above will increase in cost with the square of the number of objects involved. However, the 
division of the data into a hierarchical arrangement and the use of sectoringwhen the number of blots 
getslarge should minimize the number of necessary tests. Again it must be pointed out that if the light 
source lies in or near the field of view from the eye position, the space will have to be sectored for 
shadow de­termination so that perspectiveprojections may be used. This approach counts heavily on the 
ease of determiningbackfacing and frontfacing polygons and on overlap tests both of which are much more 
easily done after a perspective transform. Once the shadowed polygons have been determined, any hidden-surface 
algorithm may be used to gener­ate the eyepoint image from the augmented data. Therefore, an advantage 
to the two-pass approach is that the process of defining shadows is totally in­dependent of the later 
process of picture genera­tion; the shadow process may run concurrently in pipeline with the picture-generationprocess. 
Note that, given two processors, there is little point in making the shadow detection algorithm more 
ef­ficient than the display algorithm if they are to be run separately and concurrently. Also, given 
a static environment and a fixed light source, sha­ dows need be computed only once for a large num­ber 
of eyepoint positions. In that situation, the efficiency of the shadow algorithm becomes much less important. 
 THE THIRD CLASS: PROJECTED SHADOW POLYGONS Shadows may be defined by the projection of edges onto surfaces 
as in the first and second classes or they may be defined by the volume of space they encompass. The 
last class of shadow algorithm in­cludes shadow volumes in the hidden-surface compu­tation by adding 
their surfaces to the data. As­suming a polygonal object, the shadow surface is given by planes defined 
by contour edges and the light source position. Each such edge defines a polygon whose boundaries are 
the edge itself, the two lines defined by the light source position and the endpoints of the edge and 
the bounds of the field of view (fig. 4). The sense of the polygon must be maintained so that the near 
surface of a shadow volume (frontfacing polygons) may be dis­ tinguished from the far surface (backfacing 
poly­ gons). Thus the polygons facing the light source plus the set of projected shadow polygons for 
an object define its shadow volume. Shadow polygons may be treated just like the rest of the data when 
applied to a scanning hidden-sur­ 246  face algorithms; only the shading for visible sur­faces must 
handled differently. Shadow polygons are themselves invisible, thus they do not count in the determinationof 
visibility. However, the depth order of shadow surfaces and visible surfaces determines shadowing. A 
frontfacing shadow surface puts anything behind it in shadow while a backfac­ing shadow surface cancels 
the effect of a front­facing one. For example, a post or column might cast a shadow surface consisting 
of a single poly­gon pair. Any surface lying between those two sha­dow polygons would be in shadow while 
surfaces ly­ing in front of or behind both polygons would be shaded normally. If the frontmost shadow 
surface is backfacing, then everything in front of it is in shadow; if the rearmost shadow surface is 
frontfacing, then ev­erything behind it is in shadow. These cases can occur where the eyepoint is in 
shadow or a surface casts a shadow over a large part of the field of view. Therefore, surfaces are shadowed 
whenever they lie in front of a backfacing frontmost shadow polygon or the surface depth count is such 
that more frontfacing than backfacing shadow polygons have been pierced. Shadow boundaries are formed 
where a visible surface intersects a shadow poly­gon. Modificationof a scanning hidden-surfacealgorithm 
 to handle shadow polygons involves changing only the inner loops where shading must be calculated. 
 Two properties of shadow polygons may be used to simplify computation. First, shadow polygons are 
invisible. Therefore, scan lines involving only shadow polygons may be ignored. Second, shadow polygons 
formed by projection of contour edges can­not intersect one another (as long as a single light source 
is used). Therefore the depth order­ ing of such polygons is constant. Using a scanning algorithm of 
the Bouknight variety (see [4,12] for detailed views of this type of al­gorithm) shadow polygons may 
be treated just as other polygons through the y-sort and x-merge pro­cedures. Scanning algorithms generally 
require maintaininga depth-sorted list of all scan seg­ments which would be pierced by a ray from the 
eye­ point through the current position on the scanline. Shadow polygons will frequently cause quite 
lengthy scan segments greatly increasing the average depth complexity over an image. As Sutherland 
et al [12] pointed out, increased depth complexity may well severely hamper the performance of scanning 
algo­ rithms. Shadow polygons, however, need be considered only under certain circumstancesduring the 
production of scan segments. The fact that shadow polygons may not intersect allows profitable use of 
scanline to scanline coherence. The depth ordering of sha­dow polygons will change only when new polygons 
are added or old ones deleted as the scan moves down the image. Thus the process of rebuilding and up­dating 
the depth-sorted list of shadow polygons can be largely eliminated. The list need only be built where 
object segments occur. Therefore, a scanline with no object segments can be ignored. Since the depth 
ordering doesn't change, it will only be necessary to calculate the depth to a shadow sur­ face when 
it must be compared to the depth of a visible surface. The priority list of shadow polygons need only 
be searched when the visible surface in the image changes. Once it is discovered which shadow poly­gons 
bound the currently visible surface (in depto then only those polygons need be checked for pos­sible 
intersections. Therefore, although there may be considerable depth complexity due to shadows, a depth 
complexity of two to three shadow surfaces should be all that really affect computing time. However, 
many of the images made today have an av­erage depth complexity of less than three. Thus a significant 
increase in the time needed for the scanning process may result from the addition of shadow polygons. 
However, this effect may prove to be less significant as more highly complex en­vironments are attempted. 
 A COMPARISON OF THE THREE CLASSES Comparisons can be made with respect to the addi­tional difficulty 
involved in representing shadows using each of the above approaches. Three bases 247 for comparison 
are used: the additional data stor­ age required; the additional computation required; and the difficulty 
of the necessary additional software. A scanning hidden-surfacealgorithm is assumed for this discussion. 
 At first glance only the second and third classes of algorithm appear to require additional data storage. 
The two-pass approach requires that sur­ faces be split along shadow boundaries, or at least that shadow 
boundaries be included in the data; the shadow polygon approach requires the storage of perhaps numerous 
shadow polygons. However, neither of these two classes requires the entire scene description to be available 
for the hidden­ surface calculation; backfacing surfaces and data lying outside the field of view may 
be discarded. On the other hand, the first class of algorithm requires that all object data be available 
in its original form at all times so that projected shadow boundaries may be calculated during scanout. 
use as temporary Therefore, the space left over for storage by later stages of the hidden-surface It 
must be con­ algorithm is severely reduced. cluded that the two-pass approach requires least additional 
storage, shadow polygons require some­what more and calculation of shadows during scanout  requires 
by far the most. Assuming that it will always be more efficient to use only silhouettes for calculating 
shadow bound­aries, the projected shadow polygon approach ap­ pears to cause the smallest increase in 
necessary computation. The definition of shadow polygons is straightforwardonce silhouette edges are 
found, and the additional computation in the scanning pro­cess is minimized by taking advantage of the 
spec­ial properties of shadow polygons. Furthermore, both other approaches require methods which obey 
less desirable growth laws. Shadow calculation during scanout requires additional computation to determine 
which surfaces may cast shadows on each other and then requires the calculation of the lines separating 
shadowed and unshadowed areas by operations on the object-space data. Bouknight and Kelley reported 
roughly doubled computation time to include shadows in very simple scenes. The two-pass approach, in 
its turn, requires an addi­tional solution of the hidden-surfaceproblem. However, since only silhouette 
edges need to be considered, the first pass should be simplified. The complexity of the additional 
software required also appears to be smallest for the projected sha­dow polygon approach. Algorithms 
of both thefirst and second classes require significant new soft­ ware. However, it could be argued that 
once a suitable hidden-surface algorithm is available for the two-pass approach, the software for the 
first pass is just a subset of that needed for the second pass and thus no additional software is needed. 
 situation in which a scanning hidden-sur- Given a face algorithm is available, it appears that the 
shadow polygon approach offers the best solution. However, starting from scratch, there is no clear­cut 
best choice. Certainly there is much to be learned by implementingan algorithm of any class.  ACKNOWLEDGEMENTS 
The ideas expressed herein arose, for the most part, in conversations with colleagues while at the University 
of Utah. In particular, Ivan Suth­ erland suggested to me the notion of projected shadow polygons and 
also provided valuable com­ments on an earlier draft of this paper. REFERENCES The Notion of Quantitative 
Invisi­bility and the Machine Rendering of Solids, Pro­ceedings ACM 1967 National Conference. [1] Appel, 
A., [2] Appel, A., Some Techniques for Shading Machine Renderings of Solids, 1968 SJCC, AFIPS Vol. 32. 
 [3] Appel, A., On Calculating the Illusion of Re­ality, IFIP 1968. [4] Bouknight, W. J., A Procedure 
for the Genera­ tion of 3-D Half-Toned Computer Graphics Present­ations, CACM, Vol. 13, no. 6, Sept. 
1970. W. J. and Kelley, K., An Algorithm  [5] Bouknight, for Producing Half-Tone Computer Graphics 
Present­ations with Shadows and Moveable Light Sources, 1970 SJCC, AFIPS Vol. 36. Bui Tuong Phong and 
Crow, F. C., Improved Ren­ [6] dition of Polygonal Models of Curved Surfaces,  Proc. of the 2nd USA-Japan 
Computer Conf., 1975. [7] Clark, J. H., HierarchicalGeometric Models for Visible Surface Algorithms, 
CACM, Vol. 19 no. 10, Oct. 1976. The Aliasing Problem in Computer­ [8] Crow, F. C.,  Synthesized Shaded 
Images, Dept of Computer Science University of Utah, UTEC-CSc-76-015,March 1976. (abridged version to 
appear in CACM) [9] Newell, M. G., Newell, R. G. and Sancha, T. L.  A Solution to the Hidden-Surface 
Problem, Proceed­ings of the 1972 ACM National Conference. [10] Newell, M. G., The Utilization of Procedural 
Models in Digital Image Synthesis, Department of Computer Science, University of Utah, UTEC-CSc­76-218, 
Summer 1975. [11] Sutherland, I. E., Polygon Sorting by Sub­division: A Solution to the Hidden-SurfaceProblem, 
 Unpublished, 1973. [12] Sutherland, I. E., Sproull, R. F. and Schu­maker, R. G., A Characterizationof 
Ten Hidden- Surface Algorithms, Computing Surveys, Vol. 6, No. 1, March 1974.  248 
			