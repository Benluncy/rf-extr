
 PUTTING THE HUMAN FACTOR INTO SYSTEMS DEVELOPMENT Ben Shneiderman Department of Computer Science 
University of Maryland College Park, MD 20742 Abstract: As the community of computer users expands 
beyond experienced professionals to encompass novice users with little technical training, human factors 
considerations must play a larger role. "Computer shock" and "terminal terror" cannot be cured, they 
must be prevented by more careful human engineering during the system design phase. This paper offers 
four approaches to including human factors considerations during system design. These approaches focus 
on increasing user involvement and emphasize extensive pilot testing. Human factors cannot be added 
as refinements to a completed design; they must be a central concern during the initial requirements 
analysis and through every design stage. &#38;#169; 1981 ACM 0-89791-044-3/81/0600/0001 $00.75 See Page 
ii for Copyright Statement Introduction Every project manager, system designer, and programmer/analyst 
wants to build "quality" into their system. The traditional attributes of quality have been high reliability, 
ease of maintenance, correctness, on-time delivery, good cost effectiveness, and efficient use of hardware 
resources. In recent years, there has been a growing recognition that human factors considerations are 
an important component of quality. Everyone in the computer community has become aware of the importance 
of ease of use, user friendliness, simplicity, flexibility, and elegance in the design of interactive 
information and computer systems. Unfortunately, we are only beginning to measure these vague qualities 
and to ensure that they emerge during the system development process. There is no foolproof path to 
quality human engineering in interactive systems, but these four related approaches may be useful: 
-Create like an inspired inventor -Think like a clever scientist - Manage like a shrewd executive 
 -Test like an energetic astronaut. It goes without saying that you also need the loving care of a parent, 
the wisdom of a prophet, the coordination of a symphony conductor, and the imagination of an artist, 
but these skills are beyond the scope of this paper. Create like a__n inspired inventor The absence 
of firm guidelines for interactive systems design presents a challenge and a grand opportunity for dramatic 
new ideas. The successful designer will not be content with the first set of commands that come to mind, 
but will explore a wide variety of approaches. Why stick to command languages with complex syntactic 
forms which are hard to learn and remember. Why not try menu selection, graphic displays, form-fill-in, 
cursor movement, touch panels, voice input/output, joysticks, or dual displays (Martin, 1973; Mehlmann, 
1981). When you try to find six ways of providing the necessary functionality, you begin to understand 
your problem better and may come up with multiple front ends to satisfy different user communities. If 
you have many ways of solving a problem then you can begin to consider what the attributes of a good 
solution are. In any case, the process of brainstorming can provide clearer insights. But just dreaming 
up multiple ideas is not enough. Thomas Edison stressed that invention is 1% inspiration and 99% perspiration. 
To put yourself in the position where you can create six alternative designs, you must do a great deal 
of background work to understand the problem. Interviewing users, writing requirements, consulting with 
management, and learning about previous efforts in this application domain are necessary precursors for 
the creative act. Once you come up with the half dozen approaches, much work remains to be done in filling 
out the details and following through to deal with negative side effects of a clever design. Edison had 
working light bulbs for many years before he found the right combination of materials to make a bright 
and durable bulb. Think like a clever scientist Interactive systems designers are increasingly aware 
of the value of thinking like an experimental scientist. The reductionist approach of scientific research 
requires that individual issues be treated first, before examining more complex interactions. A good 
scientist will consider independent variables that can be changed, separately from dependent variables 
that are to be measured. For example, in designing and interactive system a crucial independent variable 
may be the display rate, which might have several possible levels -30, 60, or 120 characters per second. 
A good designer will evaluate the impact of the independent variable levels on the dependent variables, 
which might be human performance time, user error rates, and user satisfaction. Performance time and 
error rates are relatively easy to measure and user satisfaction can be assessed by questionnaires (Norman 
and Anderson, 1981). The competent designer can informally consider how certain user groups (novice 
users, infrequent knowledgeable users, and frequent users) and tasks (menu selection, command language, 
text editing display, or fill-in-the-blanks) might be effected by differing display rates. For frequent 
users of menu selection higher display rates are more important than for novice users of fill-in-the-blanks. 
If there is a high volume of information displayed then higher display rates will speed task performance 
and probably increase user satisfaction, but a slower rate may reduce errors. Of course, the designer 
has to consider the interaction of the display rate variable with response time delays and hardcopy vs. 
softcopy devices. It's not simple, but the methodical thought processes of the experimental scientist 
can provide worthwhile insights and relatively low cost in time and resources (Shneiderman, 1980). 
Mana@e like a shrewd executive Designing a sophisticated interactive system requires the coordination 
of many people's efforts. Successful designers know that an interactive system may change the job requirements 
for clerical workers and managers. When administrators have immediate access to detailed performance 
information, the role of middle level managers changes. When clerical staff can make decisions based 
on complete up-to-date information, the role of team leaders changes. Because of these basic upheavals, 
personnel at all levels must be interviewed and kept informed about progress in the design of an information 
system. Igersheim (1976) demonstrated by survey that user involvement in the design process is a powerful 
correlate of success. User involvement not only leads to better design, but creates an atmosphere of 
interest and enthusiasm for the interactive system (Bjorn-Andersen, 1980). A second key management 
point is that project development milestones are useful in focusing attention on the development process. 
User representatives and management should be called upon to review and sign-off on the requirements, 
the specifications, the final design, and several implementation stages. These milestones give participants 
an opportunity to note progress and express concerns, thus furthering the goal of increasing user involvement. 
 The third management strategy should be to have evaluation mechanisms such as pilot studies early in 
the design phase and acceptance tests later in the implementation phase. A pilot study might involve 
typewritten or handdrawn versions of the screen displays to test comprehensibility. A pilot study can 
 be done informally with two or three representative users or more elaborately with an on-screen mock-up 
involving dozens of trained subjects. Data collection can range from informal comments with stopwatch 
timing to extensive problem solving situations with computerized collection of performance times and 
error rates. Informal anecdotal information and subjective questionnaires are also valuable. Acceptance 
tests should be more rigorous. For example, the following criteria might be applied to in-house development 
projects or to software development contracts: An acceptance test with __ typical users must be conducted 
with the enclosed benchmark set of tasks. After __ minutes of training, these users must successfully 
accomplish percent of these tasks within minutes. More elaborate acceptance criteria would be necessary 
for many systems which serve diverse classes of users or require extensive training time. The presence 
of such an acceptance criteria would compel the design team to think very carefully about the human factors 
issues and would naturally stimulate multiple early pilot studies. Pilot tests among alternative designs 
and rigorous acceptance criteria are the norm in industrial design of consumer goods, aircraft, or automobiles, 
and in architecture. Test like a__q energetic astronaut Critical testing of components and the complete 
system are the key to success in any design process. Each component of the interactive system is a candidate 
for testing, from the type font of the characters, to the keyboard arrangement, to the task sequencing, 
and to the physical environment (Embley and Nagy, 1981). Every system message, every menu selection frame, 
every screen display format, every cursor movement technique, and every on-line tutorial should be tested. 
This level of thoroughness is required to produce a high quality system. Not every test has to involve 
dozens of subjects or days of effort. Some issues such as type font choice or system message wording 
(Shneiderman, 1981) can be tested in a few minutes with a small number of subjects. Critical issues such 
as task sequencing, command language syntax, query language styles (Reisner, 1977), or on-line tutorial 
aids (Relles, 1979) may require many more subjects and several days of testing. Good designers assume 
every component will be tested, but they must exercise their judgment of how much effort to expend on 
testing each component. Good design and thorough testing can take substantial time and resources during 
the design phase, but the savings during the implementation phase and the system lifetime more than pay 
for the higher initial costs. A well-designed system is easier and faster to implement and leads to higher 
user performance after installation. Faster task performance, lower error rates, and higher user satisfaction 
should be paramount in the designer's mind. Reducing testing to speed the design phase is a poor economy. 
If commercial aircraft manufacturers are willing to spend great effort in testing wind-tunnel models 
and in building full-scale mock-ups, then interactive system designers should be willing to test alternate 
screen displays of keyboard layouts. If NASA is willing to spend $70 million for a shuttle simulator, 
then interactive systems project managers should be willing to build prototype versions for testing. 
 ]0 Conclusions The human factors aspects of contemporary interactive systems can be substantially 
improved. While academic and industrial researchers pursue basic guidelines and fundamental theories, 
system developers can improve their designs by focusing greater attention on the human factors issues. 
Just talking about human factors is not enough, some individual or team must be assigned the responsibility 
for the human interface design and be given the resources to carry out their work. Collaboration with 
human factors professionals or experimental psychologists can be useful, but these consultants must be 
brought into the project at the earliest possible stage. It is not possible to add the human factors 
to a system after the basic design is complete. Eventually, every system design professional will have 
training in human factors and experimental methods. Eventually, it will be considered normal to carry 
out numerous design and pilot studies. When that day arrives, interactive systems will more effectively 
serve, rather than frustrate users. Novices will look forward to using computers, frequent users will 
see the ]] computer as a powerful tool which aids them in doing a day's work, and system designers 
will feel proud of their contribution. Acknowledgements: Control Data Corporation grant 80M15 provided 
partial support for this paper and the University of Maryland Computer Science Center provided computer 
resources. John Gannon offered useful comments on a draft of this paper. References Bjorn-Andersen, 
Niels, (Editor), The Human Side of Information processing, North-Holland Publishing Company, Amsterdam, 
(1979). Embley, David and Nagy, George, Behavioral aspects of text editors, ACM Computing Surveys 13, 
i, (March 1981), 33-70. Igersheim, Roy H., Managerial response to an information system, Proceedings 
of the National Computer Conference 4_~, AFIPS Press, Montvale, N.J., (1976), 877-882. Martin, James, 
Desi@n of Man-Computer Dialoques, Prentice-Hall, Inc., Englewood Cliffs, N.J., (1973). ]2 Mehlmann, 
Marilyn, When Peogle Use Computers: A__n Approach to Developing an Interface, Prentice-Hall, Inc., Englewood 
Cliffs, N.J., (1981). Norman, Kent L. and Anderson, Nancy S., Psychological factors in computer assisted 
instruction: Development of a computer interaction satisfaction scale, Conference Proceedings of the 
Association fo__/_ Development of Computer-based Instructional Systems, (1981), 54-61. Reisner, Phyllis, 
Use of psychological experimentation as an aid to the development of a query language, IEEE Transactions 
on Software Engineering, SE-3, 3, (1977), 218-229. Relles, Nathan, The design and implementation of 
user-oriented systems, Ph. D. Dissertation, University of Wisconsin -Madison, (1979). Shneiderman, Ben, 
Software Psychology: Human Factors in Computer and Information Systems, Winthrop Publishers, Cambridge, 
MA, (1980). Shneiderman, Ben, System message guidelines: Positive tone, constructive, specific and user 
centered, in preparation, (1981). ]3 
			