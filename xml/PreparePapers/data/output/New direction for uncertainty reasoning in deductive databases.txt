
 New Directions For Uncertainty Reasoning In Deductive Databases U. Giintzerl W. Kiei31ing2 H. Thonel 
lWilhelm-Schickard-Institut, Universitat Tubingen, Sand 13, D-74oo Tubingen 1 21nstitut fiir Informatik, 
Ludwig-Maximilians-Universitat, Theresienstr. 39, D-8oOO Miinchen 2 Abstract This paper contributes 
a novel approach to non­monotonic uncertainty reasoning, which is ubiquitous in many real-life applications. 
Founded on the paradigm of conditional probabilities we develop a rule-based cal­culus and prove that 
it is sound, even in the presence of incomplete information. Thus the merits of doing consistent judgments 
in uncertain domains and the advantages of modularity and incrementality of rule­based application development 
come together. We also can offer mechanisms to trace down inconsistencies that may be hidden in very 
large collections of uncertain rules. As next-generation applications will have to han­ dle vast amounts 
of uncertain data, an integration into databases is mandatory. We give a direct implementa­tion of our 
calculus on top of a database system with a DATALOG-interface. In this way we extend current database 
technology towards providing new applica­ tions with new suitable primitives and with a database platform 
for coping with uncertainty. 1. Introduction Databases have been very successful over the years in managing 
large amounts of certain data, multi-user ac­cess and high-level query languages to ease application 
development. Such languages like SQL, declarative rule­based languages like DATA LOG ([U1l 89], [CGT 
89]) or object-oriented query languages cannot deal with uncer­tain knowledge, though. Permission to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fae and/or specific permission. 01991 ACM 0-89791 -425-2 
/91/0005 /0178 . ..$1 .50 As stressed in [Lag 90] recently, next-generation ap­plications, such as the 
identification of features from satellite images, require reasoning under uncertainty to deduce conclusions 
from several inter-related partial or alternative results. This points out the need for a fun­damental 
theory that can deal with non-monotonic un­certainty. Medical diagnosis, fault analysis, genetics or 
robot vision are other important application domains falling into this category. While the database community 
so far has brought limited attention to this problem (see e.g. [BMP 90]), it has been a major area of 
research within AI for many years. The variety of solution proposals dif­fers tremendously in the basic 
foundations, like Demp­ster/Shafer evidence theory, default reasoning, fuzzy logic systems, only to name 
a few ([Ric 86], [Sha 76], [HeHo 87], [Zad 86]). Statistical expert systems are an­other main line to 
attack the problem. For the efficient solution of small, well-defined problems or for selected subproblems 
within a larger task a variety of techniques based on statistics and graph-theoretical methods have proven 
useful ([Hun 75] ,[LaSp 88]). Our emphasis here, however, is on large and dynamically growing applica­tions 
requiring a general-purpose rule-based approach, where changes can be accommodated in small incre­ments 
understandable by the human user. The success of expert systems in uncertain domains has been very modest 
until now, with little impact on commercial data processing. The reasons for this are twofold. First, 
the inference mechanisms used often led to unpredictable, uninterpretable or counterintuitive conclusions 
or depend on unreasonable assumptions (independence of events, complete information avail­able). Second, 
only main-memory implementations ex­ist presently. However, there have been gained many fundamental insights 
into the nature of uncertainty, to mention in particular [Pea 88]. On the other hand, now­adays we know 
how to manage declarative, rule-based certain knowledge efficiently in a database environment (e.g. LDL 
[NaTs 89],[Zan 88] or commercial systems like Declare [KiGu 90]). Similar to the situation back in the 
mid 80 s, where ideas from AI and databases merged to give birth to deductive database technology, a 
confluence of the virtues of AI-and DB-technology in the area of uncertainty reasoning is intended. 
The rest of this paper is organized as follows: Sec­tion 2 faces the reader with some startling phenomena 
inherent in uncertainty reasoning, pointing out the dif­ficulties. In section 3 we introduce our solution 
of un­certain rules with conditional probabilities. The pre­sented novel calculus is proved to be sound. 
Several examples show that it treats the mentioned phenomena correctly, like rule-chaining or explaining-away. 
Section 4 then describes how to implement this calculus on top of a deductive DB-system with a DATALOG 
interface and discusses questions of optimization and consistency support. In conclusion, section 5 summarizes 
our con­tributions and points out areas of future work. 2. Reasoning Phenomena Under Uncertain y Some 
introductory examples demonstrate a typical derivation strategy applied in human processing of im­perfect 
information: the combination of two rules by chaining, which yields sometimes strange conclusions. Example 
(Barking cats) For illustrative purpose, as­sume that 70% of all domestic animals are dogs and 90% of 
all dogs can bark: domestic.animals z dogs dogs % bark Putting these assumptions together by multiplying 
certainties we may come to the conclusion that (at least) 63% of all domestic animals can bark. This 
conclusion seems to be true. But now, consider the following situ­ation: 1.0 cats +domestic~nimals 0.63 
domestic-animals + bark With the same naive chaining method we come to the conclusion that 63% of all 
cats can bark, what is obvi­ously strange. Thus, there must be hidden parameters distinguishing bet ween 
the above cases, influencing the certainty of the conclusion. Here, the hidden parame­ters are evident. 
We didn t represent the information which we implicitly assumed: All dogs are domestic an­imals, and 
cats and dogs are difler-ent domestic animals. Nevertheless, a reasoning system mustn t come to the wrong 
conclusion above. In the next example ([Pea 88]), we like to combine causal and diagnostic information. 
Example (Sprinkler) sprinkler-was-on ~ Ground-is-wet (causal) It-rain edlastmight z Ground-is-wet (causal) 
Ground-is-wet ~ It~ainedJastmight (diagnostic) Ground-is-wet > Sprinkle rwasan (diagnostic) When we combine 
the first causal and the first diagnostic rule in a naive way again, we get that Sprinkler-was-on implies 
 It-r ainedJastmight with 90 percent. Here we do not combine the causal and diagnostic knowledge properly. 
By utilizing the given knowledge we would at least expect that the special cause SpTinkleT-was-on doesn 
t support the general cause It-rainedlastmight . The non-monotonic nature in uncertainty reason­ing 
will be demonstrated in the following example ([Pea 88]). Example (Burglary) Imagine, Mr. Holmes receives 
a phone call at work from his neighbor, who states that he hears an alarm from the direction of Mr. Holme 
s house. Mr. Holmes believes that a burglary is the cause for the alarm sound and decides to rush home. 
In his car he turns on his radio and listens to the news telling that an earthquake had occurred. Now 
Mr. Holmes reduces his initial belief in a burglary, since the alarm may be triggered by the earthquake. 
The radio announcement reduces the likelihood of a burglary; i.e. the second event earthquake explains 
away burglary as cause for the alarm sound. This non­monotonic reasoning phenomenon is caused by consid­ering 
different contexts. In the first situation, only the simple event alarm is relevant, whereas then two 
events alarm and earthquake must be considered. While the simplicity of material implications has proved 
viable in predicate logicl, it immediately breaks down in uncertain domains. In going from logic im­plications 
to uncertain implications, we loose the fea­ture of modularity and incrementality ([Pea 88]), that 1Quoting 
Tarski ([Tar 66]): ... daf$ die auf diesem einfachen Implikatiombegriff begriindete Logik sich als eine 
zufriedenstel­lende Basis fii-die k;mpliziertest;n und subtilsten mathemati­schen Uberlegungen erw~esen 
hat. is the impact of new evidence can neither be imparted in stages nor separately. Naive approaches 
to reason with uncertainty fail because uncertainty is combined slop­pily. But we must not give up the 
rule-based paradigm indispensably needed for the construction of large and dynamic applications. 3. A 
New Probabilistic Calculus We investigate the problem of uncertainty reasoning be­tween entire sets of 
events. This sort of reasoning seems to be prevailing in practice; uncertain reasoning about individuals 
seems to be the exception and will be taken care of in a companion paper. As we have to deal with uncertain 
correlations between sets, probabilistic reasoning is the prime paradigm to consider, because probability 
theory is highly developed and rests on a firm ground. Since we aim at a rule-based calculus with an 
intuitive meaning to everybody, we must make the right choice what is the primitive of our language. 
Con­ditional probabilities turn out to be an adequate candi­date. Definition 3.1 Let A, B be sets of 
events and lei AB denote the intersection of A and B. The conditional probability of B given A is defined 
as P(BIA) = ~, if P(A) >0. Note that P(BIA) is only partially defined. The equiv­alent rule-based interpretation 
is: P(BIA) A+B That is, given A, P(BIA) among the events in A are also events in B. If we have both A~ 
B and B~ A, x we can also write A ~ B. We often want to combine rules. This can be modeled by a graph 
representation: A strong clue that conditional probabilities are suit­able to describe the previous non-monotonic 
phenomena adequately is due to the following: given P(AIB), then P(AIBC) can take any value between O 
and 1. In other words, the additional evidence C may diminish or am­plify the confidence in A. Conditional 
probabilities are psychologically meaningful to most people and there­fore provide an excellent guidance 
for decisions, based on the numerical probabilities. But since precise con­ditional probabilities are 
often hard to get or not avail­able, working with intervals makes much more sense in practice. Definition 
3.2 Let Cl, C2,.. ., Ck be the set of events. Cl and its complement ~, 1<1< k, are called ba­sic events. 
We consider conjunctive events A= A1. ..A~, B= B1... B~, where n,m~ 1 and A,j Bj are basic events, and 
P(A) >0, An uncertain rule consists of an upper and a lower bound for a conditional probability y: Azq 
B ifl O<zl <P(BIA) <zz <1. If lower and upper bound coincide we simply write A&#38;+B. The axioms of 
our calculus are given by a collection 72 of uncertain rules, respecting the laws of probability theory. 
Note that we do not impose an a priori causal or diagnostic interpretation on the implication arrow + 
. This is left to the application completely. Given a knowledge base for an application involving un­certainty 
in form of such axioms 72, among a set of events cl, ..., ck, we want to draw other uncertain conclusions, 
not explicitly listed in 7? . This will be accomplished by a collection of inference rules, which achieve 
to combine few pieces of influence into new evidence. Definition 3.3 Let %?be a set of uncertain rules, 
A and B be conjunctive events. ~ &#38; A ! B iff A ~ B can be generated, given %?, by the following inference 
rules in a jinite number of steps. Inference Rules (A, B,C and D denote conjunctive events, F denotes 
a basic event.) (1) Chaining (C): {A ZFC, Ay<Tc} 1 AEC, 21 =xl+yl, .22=min(l, zz+yz) (2) Sharpening (S): 
{A 3B, A3B} I A3B, ZI = max(xl, Vi), 22 = min(~2, YZ) (3) Conjunction left (CL): {AX3B, Xl>o, A%Bc} +AB%C, 
.21= ~, zz = min(l, ~) (4) Conjunction right (CR): {A SB, AByfiC} l A2~BC, ?zI=zl.yl,%z=zz.yz (5) Weak 
conjunction left (WCL): {A-l?, z1>O, ByUC} I AB%C, 2 1 = &#38; .Tl(zl, yl), % 2= &#38; , ~3(z1, y2), 
where Tl(a, b) = max(O, a+ b 1), Ts(a, b) = min(a, b) (6) Weak conjunction right (WCR): {AxqB, DYZC, 
D= Bor D.~, A#C} + A ~Bc, i~(yl=l AD=13)then.zl= zle/sezl=O, if(y2=OAD=B)thenz2 =Oelsez2 =x2 (7) Negation 
(N): {A fi F} 1 A~~, z~ = 1 x2, .22 = 1 XI (8) Weak conjunction right with negation (WCRN): ~1,~2 $1, 
~z {A ~F, vl>t), F~C, yl>o, A#C} + A~~c, ,21= O,22 = min(l, (l yl) .=) (9) Annulment (A): {A~B, A l 
? B} I AQ+. B We denote all uncertain rules that can be generated out of a set of axioms 7? by applying 
these inference rules as deduced rules. Already deduced rules can be used as premises for deducing further 
rules. Definition 3.4 Let 7? be a set of axioms, A and B be conjunctive events. %? ~ AX~B iff xl < P(BIA) 
< X2 follows from 72 and the laws of probability. As an indispensable property of any rule-based un­certainty 
calculus, we now show its soundness within a well-understood mathematical framework. Theorem 3.5 (Soundness) 
l~n I A UB then~ ~A~SB . Proofi By induction on the number of steps in a deduc­tion it suffices to show 
that each rule is valid within probability theory. For instance, take the chaining rule: We have P(CIA) 
= P(CFIA) + P(C~lA). Since we have Z1 < P(CFIA) < X2 and YI < P(C~lA) < yz, we get Z1 +yl < P(CIA) < 
min(l, zz + yz). I or the remaining inference rules we leave the proof to the reader. w One of the most 
important uses of any rule-based cal­culus is rule chaining. Concretely, we want to answer the question: 
Given an uncertain relationship between A and B, and an uncertain relationship between B and C, what 
is the relationship between A and C? This amounts to making transitive conclusions under uncer­t ainty. 
Theorem 3.6 (Rule chaining RC) Let R be a set of axioms or deduced rules, A and C conjunctive events, 
B a basic event. 741,742 xl , X2 ~C}. Y2 Then 72, l A~C with 7?={A~BJB Y1, ~ Tl(w, $a) ifvl>O 21 = U1 
ifvl =0 andzl =1 o otherwise. { min(l, uz+T. (1 yI), l ui+r. yl, ~) withr=~ ifvl >0 andyl >0 Z2 = min(l, 
l ul+~) ifvl>Oandyl=O 1 U1 ifvl=O andz2=0 { 1 otherwise, Note that the rule-chaining theorem can also 
be ap­ plied when B = C is not given. Only U1, V1 and xl are needed to compute the lower bound Z1; the 
up­per bound Z2 can be computed, for instance, with the formula min(l, 1 U1 + ~), if vl >0. Proof of 
theorem 3.6: (By deduction in the calculus.) (1) {A-B, V1 >0, B ~C} ~.AB qc, al=+ .Tl(Ul, ~l), ~2=: 
~3(vl, $2)  (2) {A s B, AB <c} ~X A UBC, as=ul.al,ad=uz.az  (3) n ~~;N A %7?C, a,= O,  afj=min(l, 
(l-yl). ~) if vl >0 and yl > 0 (4) {A UBC, A q%c} IT Aauc, aT=as+as, aS=min(l, aA+afj) (5) {AugB} 1; 
Aaq17, ag=l uz, alo=l ul  (6) {Aa~~, BZ~C} ~~ A %%C, all= o, alz= alo  (7) {A flBC, Aa*17C} &#38; 
A 3 c,  als= as+all, alq= min(l, aq+alz) Now we get: z $.Y cats ~ bark. if Z1 = 1 then als= ul else 
a15= O, if X2 = O then alG= O eise alG= uz [9) {Aav BC, A %%C} l= Aaw C, ~17= a15+a5, U18= mh(l, a16 
+a6) (10) {A w BC, Aa~ %C} l~Aa5 C, U19=U15+ all, ~20=mk(l, a16+a12) Applying the sharpening rule and 
basic arithmetic we finally get the result. _ As an important observation, it is now clear that sound 
rule chaining necessarily requires hi-directional inference ( ~ ): also the back-arrows A ~ B and B 
WC are essential. Our introductory examples now behave as follows: Example (Barking cats) The set of 
axioms, i.e. the base rules %? , are: {dome.stic~dogs, dogs%bark, cats~domestic} Applying the rule chaining 
theorem (RC), we get: {domestic~dogs, dogs%bark} ~~domest;;6Fbark We can give a plausible interpretation 
of these results using Venn diagrams: domestic animals domestic animals Observe that the three sets 
can overlap as much as possible (positive correlation, see right picture), which yields cats ~ dogs or 
overlap as little as pos­ sible (negative correlation, see left picture), yielding cats n dogs = 0. The 
functions Tl(a, b) and T3(a, b), given in the set of inference rules, precisely account for negative 
or positive correlation, resp. (T l and T3 are known as T-norms [BoDe 86]). As it turns out, the information 
specified in the base rules is not sufficient to conclude anything about the barking behavior of cats 
which is reflected in our calcu­ 0.0,1.0 lus by the conclusion cats + bark. So imagine that you learn 
today that cats aren t dogs and that the dogs are the only barking animals for sure. Then you can in­crementally 
update your knowledge base by adding two rules: R := ~ U {cats% dogs, dogs ~bark } It comes to no surpri~e 
duce erroneous results. sible explanations in shown above. form that Even our calculus better there of 
correlation does are beh not also avior pro­plau­as Example (Sprinkler) { Sprinkle.r.was.on ~ 1.0 Gmund&#38;-wet, 
 Ground>s-wet ~It-rainedJastmight } 0.0,1.0 ~~ Sprinkler-was-on ~~1 It-rainedJastmight .!. Again we avoid 
the erroneous conclusion that the ac­tivities of the sprinkler imply rain. Instead our calculus admits 
honestly that nothing can be concluded about the probability of rain given the sprinkler event. Ev­erything 
else, computing preciser estimates than what is implied by the input rules, would amount to a decep­tion 
of the user. As direct corollary from the rule chaining theorem, we get the following important special 
cases for our cal­culus, which again proves its consistency in treating un­certain reasoning. Corollary 
3.7 (Certain chaining) Let 7? be a set of axioms or deduced rules: I?={ A&#38;B, B&#38;C}. Then 7i!~~A&#38;C, 
Proof Apply the rule chaining theorem with U1 = U2 = Zl=zz=l.m Corollary 3.8 (Product rule) Let 7? be 
a set of az­ioms or deduced rules: n={A~ B, B WC}. Then X ~~A -~C. Proofi Apply the rule chaining theorem 
with VI = V2 = yl=yz=l. m Coming back to our initial attempts with naive rule chaining we now see that 
this is sound in this special case. Let us draw our attention to the question, how our calculus deals 
with non-monotonic behavior. Theorem 3.9 (Multiple events) Let X? be ihe foL lowing set of axioms or 
deduced rules: 1, 2 ~={A .1,.2 ~B, ul>Oorvl>O, A XC, BYZC}. Then R 1 AB XC, ZI = max(~ 1 .Tl(ul, xl), 
: .Tl(vl, yl)), zz = min(~ ~1 . T3(UI, XZ), :. ~3(wl,y2)). al= * . T1(U1, ZI), a2= * oT3(UI, Z2) (2) 
{BVSA, VI >0, By~C} ~~ABa4C, aa= * .Tl(vl, yl), a4= + . T3(14, yz)  (3) {AB %C, AB %C} &#38;ABZ<C, 
 zl= max(al, a3), .zZ= min(az, aq) Substituting we get the result. _ The use of this formula is required 
in the following situations: Definition 3.10 A and B are mutually supportive for C zff P(CIAB) > rnax(P(CIA), 
P(CIB)). C r s a more probable explanation of A than B ifl P(CIA) > P(BIA). B explains away C ifl P(CIAB) 
< P(CIA). Example (Burglary) For A= alarm, B= earthquake, C= burglary assume 0.06 n ={ A~B, A3c, B&#38;c}. 
 Given A (alarm is reported), C is a more probable ex­planation than B. Now given also B (earthquake 
is reported after alarm), we get: Since [0.17, 0.29] < [0.95, 0.95] B explains away C; i.e. , your expectation 
of burglary is sharply reduced and hence A and B are definitely not supporting events. Example (Symptoms) 
Let A and B be symptoms for a disease C and suppose 0.64 n ={A~B, Aqc, B-%c}. We get: 7? 1 ABO Y C. 
Thu~, in case of positive correlation we have P(CIAB) = 0.56> max(O.36, 0.40), meaning A and B are mutually 
supportive of C, whereas in case of negative correlation they aren t, Continuing the example, as­sume 
we somehow get to know that -with everything 0.67 else unchanged -BC + A. This allows us to infer: Note 
that we have inferred a l-point interval again. As now 0.50> max(O.36, 0.40), we safely know that A and 
B are mutually supportive of C. As this example demonstrates, it is often desirable to have some sort 
of correlation information available. In the absence of concrete measurements, in many cases the assumption 
of conditional independence is helpful. Definition 3.11 A is independent of C under con di­tion B, denoted 
by I(A, B, C), zfl P(AIBC) = F (AlB). As shown in [Pea 88], there are sound inference rules, which are 
conjectured to be complete, to generate new conditional independence out of a given set. The com­bination 
of independence information and conditional probabilities is done by the following inference rules. Invariance 
11: {B 3C, I(A, B, C)} 1 AB 3C Ql,sz Invariance 12: { ABx~C, I(A, B, C) } l B+C The two more rules are 
obviously sound because I(A, B, C) ~ I(C, B, A). They generate more precise intervals than, e.g. , weak 
conjunction left. Example (Generic trait) (cf.[AnHo 90]) In the fol­lowing figure, we can imagine that 
node D represents the proposition that a patient haa a certain symptom. Nodes B and C represent assertions 
that the patient has either of two diseases that may cause the symptom, which we may call disease B and 
disease C. Node A represents the proposition that the patient has a genetic trait that predisposes him 
to both diseases. - /w\ o   @\@/ D  Assume that %! = { I(C, A, B), 1(~, A, B), I(A, BC, D), l(A,~C, 
D), Then we can generate the following rules: 0.3,0.8 Note that rule chaining via B and c has produced 
a sharp (l-point ) interval again. At this point it s worth contemplating a bit about the way our calculus 
copes with transitive uncertainty. As we just demonstrated, with sufficient correlation information, 
precise intervals will be deduced. This clearly distinguishes our approach from other correlation-techniques 
(e. g. implemented in INFERNO [Qui 83]), where accumulated intervals have a tendency to diffuse towards 
[0, I]. 4. Extending Deductive Database Technology Unlike other approaches for uncertainty reasoning, 
our calculus, in addition to its semantical virtues, can be implemented directly with deductive database 
technol­ogy. To capture the semantics of an application domain, the knowledge engineer has to determine 
the following factual knowledge: (1) The relevant sets of events c1, . . . . C~: On a deduc­tive DB these 
are database relations, on an object­oriented DB it might be classes or relations. (2) Basic conditional 
probabilities between those sets of events. (3) Conditional independence information.  The result of 
this knowledge acquisition process, which can be done in a modular and incremental man­ ner, is a set 
of axioms 7? as described previously. Now, 7? plus the set of sound inference rules can be imple­ mented 
directly on a deductive database system with a DATALOGfun+set rule interface. We define three base relations 
as follows: X1,X2 br(A, B,xl, x2) :-A+Bc R ir(A, B, C) :* I(A, B,C) e%? bar(c, Char) :+ Char = ~, C 
is a basic event. The relation bar is symmetric, too. New conditional probabilities, which can be deduced 
by our inference mechanism ( deduced rules ) are implemented by a vir­tual relation dr(A, B, Xl, X2) 
:-R 1 Ax&#38;B The attribute types for dr are chosen as (1) Xl, X2 c [0,1] (of type real or better type 
infinite precision if available).  (2) A, B are of type set of strings: This allows us conve­niently 
to remove redundant conjunctions. E.g. ,  if A = CICZC1, B = C3C3C1 then A ---+ B is rep­resented as 
dr({Cl, C2}, {Cl, C3}, 0.3, 0.8). This set implementation also accounts for associatity, com­mutativity 
and idempotence of conjunctions. The identity C, = ~ is controlled by means of the bar­relation. For 
instance, D = C1~C2 is recognized as {Cl, C,, Ck} and D = C~Csm as {}. The evaluable predicate union(A, 
B, S) is used to implement the intersection of conjunctive events. For the above example AB is mapped 
onto union (A, B, S), where S becomes {C1, C2}U{CI, C3} = {CI, C2, C3}. Then dr can be defined by the 
following nonlinearly recursive DATALOGfUn+set program in LDL-notation ([NaTs 89]). 2 dr(A, B, Zl, Z2) 
+ br(A, B, Zl, Z2) % axioms dr(A, C, Zl, Z2) e dr(A,BC,Xl,X2), union(B,C,BC), bar(B,Bbar), dr(A,BbarC,Yl,Y2), 
union(Bbar,C,BbarC), C~{}, Z1 = Xl + Yl, Z2 = min(l.O, X2+ Y2). dr(A, B, Zl, z2) ~ dr(A, B, Xl, X2), 
dr(A, B, Yl, Y2), Z1 = max(Xl, Yl), Z2 = min(X2, Y2). dr(AB, C, Zl, z2) ~ dr(A, B, Xl, X2), union(A, 
B, AB), Xl >0.0, dr(A, BC, Yl, Y2), union(B, C, BC), C%{}, Zl=#, z2 min(l.0, ~). dr(A, BC, Zl, z2) 
+ dr(A, B, Xl, X2), union(A, B, AB), dr(AB, C, Ylj Y2), union(B, C, BC), Z1=X1. Y1, z2=jy2. y 2. dr(AB, 
C, Zl, z2) ~ dr(l?, A, Xl, X2), union(A, B, AB), Xl >0.0, dr(B, C, Y1, Y2), intersection(A, C, {}), Z1 
= max(O.0, .X*), Z2 = min(l.O, ~). dr(A, BC, Zl, z2) e dr(A, B, Xl, X2), union(B, C, BC), dr(B, C, Yl, 
Y2), intersection(A, C, {}), if(yl=l.o then Z1=XI else Zl=o.1)), if(y2=0. O then Z2=0. O else Z2=X2). 
dr(A, BC, Zl, z2) A dr(A,B,Xl,X2), union(B,C,BC), bar(B,Bbar), dr(Bbar, C,Yl, Y2), intersection(A, C, 
{}), Zl=o.o, Z2=X2. dr(A, Bbar, Zl, Z2) &#38; dr(A, B, Xl, X2), bar(B, Bbar), Z1=l.O X2, Z2= 1. O X1. 
dr(A, BbarC, Zl, z2) ~ dr(A, B, _ U2), dr(B, A, Vl, .), bar(ll, Bbar), dr(B,C,-,X2), dr(C,B,Yl,-), union(Bbar,C,BbarC), 
intersection(A, C, {}), V1 >0.0, Y1 > 0.0, Z1 = 0.0, Z2 = min(l.O, (1.O Yl) . ~l:~~). 2Actually, some 
of the stated evaluable functions have to be defined as external predicates, using C . dr(A, B, Zl, 
Z2) + As always with recursive DATALOG-programs, mas-dr(A,B,Xl,X2), dr(B,A,O.0,0.0), Z1=O.0, Z2=0.O. 
sive use of sophisticated optimization techniques must dr(AB, c, z1, z2) t be made to achieve safety 
of execution ([SaVa 89]) and dr(A, B, Zl, Z2), union(A, B,AB), ir(A, B, C). sufficient efficiency for 
practical use. A complete discus­dr(B, C, Zl, Z2) ~ sion of this matter would take us beyond the scope 
of this paper, so we want to point out only some aspects here. dr(AB, C, Zl, Z2), union(A, B, AB), ir(A, 
B, C). User queries: The Optimization-Challenge Recall that our set of relevant events is Cl,.. ., ck. 
Let A, (l<i<n) and Bj (1 <j<m) be basic events; i.e. any (1) The LDL-program in the form given above 
won t of these Cl or n (1 <1< k). Typically one then would terminate because of unsafety of execution. 
Safety like to ask questions like: P(B1 . . . B~ IA1 . . . An) =? and dramatic efficiency gains can 
be accomplished (m, n ~ 1). Since our calculus deals with intervals, of by a variation of the optimization 
technique known course we would like to know the sharpest possible in-as push selection by certainty 
([SSGKAB 89]): terval to the previous question. This means, a standard If dr(U, ~ Xl, X2) and dr(U, V, 
Yl, Y2) are deduced user query actually has the format: during the fixpoint iteration, then these two 
tuples can be replaced by one, namely Give me the sharpest interval[Zl, z2] for Z1, Z2 dr(U, ~ max(Xl, 
Yl), min(X2, Y2)). Al... An + Bl . . . B~ that can be deduced. That is the aggregation should be applied 
as soon Some of these queries can be answered efficiently right as possible and itshould discard its 
two inputs. away: Actually, the optimizer has to push the aggregation (1) If{ A,,..., An}~{B,, . . ..B~}. 
then[Zl, Z2]=[l,l]. on g into dr, violating stratification, but not local stratification ([ShNa 87]). 
3 (2) If A, = ~ for some i,j, then [Zl, Z2] = [0, O]. (2) The given DATALOG-program is nonlinearly re- 
In general, however, this query must be answered by cursive. Whether some special transitive closure 
the given DATALOG-program for dr has a fixpoint se-operators (like closed semiring or generalized tran­generating 
deduced rules from the axioms 72. Since sitive closure), can be applied, needs to be exam­mantics, we 
can realize this inference mechanism by a ined. Since some of the functions occurring are not then becomes 
an aggregate query: associative, this might be not the case. (This might also imply that no equivalent 
linear recursive solu­hq(A, B, <Z1>SZ2>) t dr(A, B, Zl, Z2). fixpoint iteration for dr. The query to 
be posed to dr tion can be found in general). q(A, B, X, Y) e hq(A, B, SetZl, SetZ2), aggregate (max, 
SetZl, X), (3) The use of heuristics for pruning the search space, aggregate (rein, SetZ2, Y). like ([SKGB 
89]) must be explored. Besides such standard queries with the binding pat­ (4) The cost of set unification 
is of,concern, too. While tern (b = bound, f= free) of dr(b, b, f, f) one can imagine LDL employs a costly 
general-purpose algorithm, more fancy queries, directly implement able with the full special solutions 
using bit vector implementations power of DATALOG systems. For example, queries like are promising here. 
tell me the names of those sets of events, which are implied by A with more than 7570 . This corresponds 
This optimization challenge will be investigated more to the binding pattern dr(b, f, b, b). closely 
in a forthcoming paper. Example (Burglary) The set of axioms given earlier Consistency Support translates 
into If the numbers in br are statistical measured conditional br = {({ alarm }, { earthquake }, 0.06, 
0.06), probabilities or come from scientific models for interac­ ({ earthquake }, { alarm }, 0.7, 0.7), 
tion, no inconsistencies can arise. But often numbers are ({ alarm }, { burglary }, 0.95, 0.95), subjective 
probabilities; e. g. , expert opinions or spec­({ earthquake }, { burglary }, 0.2, 0.2)} ulative estimates 
of the knowledge engineer. So any au­tomatic support for maintaining the consistency of the The user 
query alarm~nd.earthquake~ burglary is 3Thk is once more a very practical case indicating that transformed 
into the query: DATALOG-systems should be freed from rigorous stratification ? q ({ alarm , earthquake 
}, { burglary }, X, Y). checks. base rules is of big practical importance. In general, not every potential 
inconsistency of the base rules can be detected by a compile time analysis easily. But the implementation 
of our calculus gives a detection mech­ anism for inconsistencies at run-time almost for free. coratradiction( 
P,Q) e dr(P,Q,Xl,X2), dr(P,Q,Yl,Y2), X2< Y1OTY2<X1. Since our calculus is sound, this contradiction can 
only happen because of an inconsistency in the base rules. Now suppose that during the fixpoint iteration 
two tuples in dr= with (A, B, U1, U2), (A, B,V1, V2) and U2 < V1 are deduced. Then application of sharpening 
during the next iteration round produces a tuple (A, B, V1, U2) with V1 > U2. So a simple trigger during 
fixpoint iteration, watching for tuples (P, Q, Xl, X2) with Xl > X2, is enough for detection. Example 
(Flying.animal) (cf.[Pea 88]) We know, that birds can fly with the exception of penguins, os­triches, 
etc. Therefore, we estimate that between 70% and 90% of all birds can fly. Typically, almost all birds 
are feathered animals , and almost all feathered ani­mals are birds , at least more than 95% of each. 
And finally, we assume that feathered animals do not fly , for instance, we estimate that less than 10% 
of all feath­ered animals can fly, Our set of axioms 7? is depicted graphically below: feathe~ed-anirnal 
0.s15,1.o bird w 0.0,0.1 0.7,0.9 \/ flyin~-animal In the above statements, there is a contradiction, 
which can easily be detected with our rule chaining mechanism: 0.95,1.0 0.7,0.9 {feathered~nima[ ~ ~ 
95 ~ ~ bird, bird 4 flyingsnimal] ,. ~~ feathered-animal ° 6z f~ying_animal. In contrast to the assumption 
in the knowledge base that feathered animals do not fly , we have deduced that many feathered animals 
can fly , at least more than 65?t0 of them. Sumrnarizing, we can detect consistencies even in the case 
of cycles as above. A powerful consistency main­ tenance component should offer a strategy to resolve 
inconsistencies by picking suitable victims for removal from 2? . Last but not lead, we can give support 
for keeping the knowledge base 7? minimal by detecting outdated base rules. This situation indicates 
that the information in a base rule is subsumed by deducible knowledge from other sources and hence might 
be a candidate for re­moval from 7? , but only after all inconsistencies have been resolved before. Otherwise 
it might happen that dr(P, Q, Yl, Y2) has been derived by means of some other base rule which has to 
be retracted. System Architecture We conclude this discussion by showing the gross ar­chitecture for 
implementing sound and non-monotonic uncertainty reasoning on a deductive database system (which may 
be part of an object-oriented DBMS as well). user certain and uncertain ++++ reasoning interface , --------------------------------------------, 
w= \/ Gsl --------------2+--------*----Q~~~J~G  Ezzl LEz2il Figure 5.1: The DUCK-system architecture 
(Deduction with UnCertain Knowledge) Depicted relations (ck.sses) Cl,... ck are supposed to be those 
appearing in 7? . If, as normally, these re­lations have their own tuples (objects), the question naturally 
comes up how to combine standard deductive queries on the instances of Cl,... , ck with the uncertain 
queries on the CI,.. ., Ck themselves. As it turns out, a combination of both is achievable by another 
sound in­ference rule, the uncertain modus ponens, which will be described in detail elsewhere. This, 
among other things, provides us with a method for dealing with exceptions. 5. Summary and Outlook We 
have presented a novel calculus for non-monotonic uncertainty reasoning. This approach, relying on con­ 
ditional probabilities, exhibits several salient features: (1) It provides a sound inference mechanism 
for rule­based uncertainty, while maintaining the virtues of modularity and incrementality of rule-based 
appli­cation development.  outdated(P,Q,Xl, X2) t br(P,Q,Xl,X2), dr(P,Q,Y1,Y2), (2) Sound inferences 
under uncertainty are feasible xl <Yl orx2> Y2. even in the presence of incomplete information, Thus 
it can be employed for expert systems in diag­nosis (like in medicine) or pattern recognition (like analysis 
of satellite data). (3) The consistency of the knowledge base can be mon­itored and acquisition of new 
base rules be opti­mized. (4) The calculus lives naturally in a database envi­ronment. The direct mapping 
onto a DATALOG­interface integrates uncertainty reasoning into databases and commercial data processing. 
 Having solved several problems with our calculus so far, naturally a range for further investigations 
is wide open, predominantly in the area of efficiency. Certainly a comfortable user language for manipulating 
the base rules and for posing queries must be designed. The lan­guage should be a natural extension of 
existing popular database languages.  References [AnHo 90] K.A. Anderson and J.N. Hooker: Bayesian Logic. 
Working Paper 1-90-91, Carnegie Mellon University, Pittsburgh, 1990. [BMP 90] D. Barbara, H. Garcia-Molina 
and D. Porter: The Management of Probabilistic Data. Proc. EDBT, Venice, 1990. [BoDe 86] P.P. Bonissone 
and K.S. Decker: Selecting Uncertainty Calculi and Granularity: An Experi­ment in Trading-off Precision 
and Complexity. In Uncertainty in Al, L.N. Kanal and J.F. Lemmer (cd.), Elsevier, North Holland, 1986, 
pp. 217-247. [CGT 89] S. Ceri, G. Gottlob and L. Tanca: Logic Pro­gramming and Databases. Springer, New 
York, Berlin, Heidelberg, 1989. [HeHo 87] D.E. Heckermann, E.J. Horvitz: On the Ex­pressiveness of Rule-based 
Systems for Reasoning with Uncertainty. Proc. 6th Nat. Conf. on AI, Washington, 1987, pp. 121-126. [Hun 
75] E. Hunt: Artificial Intelligence. Academic Press, New York, 1975. [KiGu 90] W. Kiet31ing and U. Guntzer: 
Deduktive Datenbanken auf dem Weg zur Praxis. lnfor­matik Forschung u. Entwicklung, Vol. 5, No. 4, Springer, 
1990, pp. 177-187. [Lag 90] Lagunita Beach Report: Database Systems: Achievements and Opportunities. 
Report of the NFS Invitational Workshop on Future Directions in DBMS Research, Palo Alto, 1990. [LaSp 
88] S.L. Lauritzen and D.J. Spiegelhalter: LG cal Computation with Probabilities on Graphical Structures 
and their Application to Expert Sys­tems. Journ. Royal Statistical Society B, 50(2), 1988, pp. 157-224. 
[NaTs 89] S. Naqvi and S. Tsur: A Logical Language for Data and Knowledge Bases. Computer Science Press, 
New York, 1989. [Pea 88] J. Pearl: Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, San 
Mateo, 1988. [Qui 83] J.R. Quinlan: INFERNO: A cautious ap­proach to uncertain inference. The Computer 
Journal 26.1983, pp. 255-269. [Ric 86] E. Rich: Artificial Intelligence. McGraw-Hill, 5th cd., 1986. 
[SaVa 89] Y. Sagiv and M.Y. Vardi: Safety of data­log queries over infinite databases. Proc. ACM SIGA 
CT-SIGART-SIGMOD Symp. on Principles of Database Systems, Philadelphia, 1989, pp. 160­ 171. [Sha 76] 
G. Shafer: A mathematical theory of evidence. Princeton University Press, Princeton, 1976. [ShNa 87] 
O. Shmueli and S. Naqvi: Set Grouping and Layering in Horn Clause Programs. Proc. dth. Int. Conf. on 
Logic Programming, 1987. [SKGB 89] H. Schmidt, W. Kie51ing, U. Giintzer and R. Bayer: DBA*: Solving Combinatorial 
Problems with Deductive Databases. Proc. GI/SI-Conf. on Datenbanksysteme in Buro, Technik und Wissen­schafi 
, Zurich, 1989. [SSGKAB 89] H. Schmidt, N. Steger, U. Guntzer, W. Kiefiling, R. Azone and R. Bayer: Combining 
De­duction by Certainty with the Power of Magic. Proc. Ist Int. Conf. on Deductive and Object-Oriented 
Databases, Kyoto, 1989, pp. 205-224. [Tar 66] A. Tarski: Einfuhrung in die mathematische Logik. Vandenhoeck 
@ Ruprecht, Gottingen, 1966. [Ull 89] J. Unman: Principles of Database and Knowledge-Base Systems. Vols 
1 and 2, Computer Science Press, New York, 1989. [Zad 86] L.A. Zadeh: A Simple View of the Dempster-Shafer 
Theory of Evidence and its Implication for the Rule of Combination. AI Magazine 7, 2, 1986, pp. 85-90. 
[Zan 88] C. Zaniolo: Design and implementation of a logic based language for data intensive applica­tions. 
Proc. 5th Int. Symposium on Logic Pro­gramming, 1988, pp. 1666-1687. 
			