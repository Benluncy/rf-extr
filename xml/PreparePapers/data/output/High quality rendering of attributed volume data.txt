
  yields the object boundary at . Besides the incorrect loca­tion of the boundary it is important to 
realize that the value of depends of the sample positions, which themselves de­pend on the viewing parameters 
and therefore introduces aliasing in animated sequences. We also notice a discon­tinuity of the gray 
values along the ray at the position where the neighbourhood for the interpolation changes. Although 
an analytical solution to compute the correct boundary might exist (at least for linear interpolation) 
for simplicity reasons we have implemented a bisection algorithm that ap­proximates through bisecting 
the line between and ing different values for enables control of accuracy versus speed. This scheme 
also works correctly for higher order interpolation methods like cubic-splines as long as they are well-behaved 
and do not produce multiple extrema on the intensity profile between successive sample points. Depending 
on the segmentation different situations for the location of the object boundary occur (fig.3), . exactly 
one boundary exists if the intensity ranges of adjacent objects are in touch; . if the intensity ranges 
form a gap there are two surfaces. The one we take depends on the viewing direction (nor­mally the backfacing 
surface is not interesting). The area between the surfaces is unclassified; . in cases where the intensities 
of the objects overlap, e.g. manual segmentation, the boundary is not unique. This situation is detected 
as follows, 1. if the gray value at position is inside the intensity range of object  and at position 
  is outside take the boundary of object  2. if as well as are inside try if the thresh­old of 
object forms a boundary, i.e. is inside and is outside 3. if neither threshold produce a boundary, 
as is the case for manually segmented objects, we calcu­late the g s using interpolated attribute values 
(see section 2.5), which then produce a unique boundary. Figure 3: Depending on the intensity ranges 
assigned to the objects different surface boundaries exist. For manually segmented objects the boundary 
is not unique, because the intensity ranges overlap (right). 2.4 Detecting thin and small objects The 
combination of discrete attribute voxels and threshold­ing interpolated intensities at the sample positions 
along the viewing can produce very small and thin objects which might get lost if the sampling rate is 
too large. This results in seri­ous aliasing artifacts, which prominently occur in animated sequences. 
Our new method computes the correct attribute value at any arbitrary subvoxel position and therefore 
en­ables classical oversampling (fig. 4). As the Nyquist fre­quency is not known a tradeoff between computation 
time and the accuracy of small structures has to be made. We found a sample point distance that is about 
the pixel size of the resulting image is a practical solution.  Figure 4: The classification driven 
attribute computation enables oversampling so that even small and thin objects are rendered correctly. 
2.5 Interpolating attribute values Although the described methods work well for normal sit­uations there 
still remains a number of problematic situa­tions, where the attribute value cannot be determined using 
additional threshold classification. These situations occur especially where objects have been segmentated 
manually, however, the affected regions are generally small, so only a few voxels are involved. Therefore 
our approach here is to generate interpolated values from the discrete attribute val­ues themselves. 
To check if a sample position is inside of a specific object we 1. create a binary subvolume where each 
voxel in the 2 x 2 x 2 neighbourhood of the sample position is set to if the attribute value in the 
corresponding at­tribute volume is the same we are testing. Otherwise the voxel is marked "0 ; 2. compute 
a tri-linear interpolated value of the binary volume at the sample position; 3. if the interpolated 
value is less than 0.5 the position is outside of the object, otherwise it is inside.  Figure 5 shows 
some of the surfaces generated by the 256 possible configurations of 8 neighboured binary voxels. This 
scheme can be easily extended to a larger neighbour­  hood, e.g. 4 x 4 x 4 for higher order interpolation 
and the calculation of the gradient for the surface normal. 2.5.1 Extension for multi-modality volume 
data The described method for determining the attribute value of a given sample position in subvoxel 
resolution can be eas­ily extended for multi-modality data such as the Visible­Human-Dataset (see section 
3.1) which provides colored anatomical cross-sectional images together with registered CT scans of the 
frozen cadaver. This allows the segmenta­tion of bony structures from the CT volume while all other structures 
are better segmentable from the anatomical data. The classification of different objects depends then 
on dif­ferent volumes. We therefore changed the basic algorithm in section 2.2 in the following way: 
1. determine all distinct attribute values in the neighbour­hood; 2. compute an interpolated intensity 
value for each of these attribute values from their respective classifica­tion volume; (For each different 
volume this value is computed only once independant how many attributes refer to it.) 3. increase the 
counter if the interpolated value fits into the intensity range of the respective object;  The remainder 
of the algorithm is the same. This simple ex­tension is not restricted to two volumes but allows a different 
volume for the classification of each distinct object. Calculating surface color One interesting aspect 
of the Visible-Human-Dataset is that in contrast to tomographic data, which provide no color in­formation, 
one can use the rgb-tuples to improve the realism of the surface appearance. Instead of assigning an 
artificial color to an object description, which is then attenuated by a light reflection model, each 
distinct surface location can be shaded individually using its respective color. Again for high quality 
rendering the rgb-values have to be interpo­lated. However, if one interpolates the color directly at 
the surface boundary a mixture of the colors of the adjacent ob­jects results. To get a more realistic 
color we can shift the interpolation center along the surface normal underneath the surface (fig. 6). 
  3 RESULTS We integrated the methods into our VOXEL-MAN visual­ization system and applied them to 
different segmented vol­umes. The first example is the standard MR volume of a head used by many groups, 
which we segmented into over 200 constituents [2] (fig.7). The superior quality of our approach is shown 
in fig. 8 where the classical discrete scan-conversion technique gen­erates staircase artifacts on the 
surface especially on objects boundaries while the attribute reclassification scheme pro­duces smooth 
renderings at any scale. As long as the size of a voxel is about the same size as a pixel of the resulting 
projection the difference between the classical ray-casting approach and our new method is not noticeable. 
However, if we compute a magnified view the discrete nature of the attribute voxels becomes prominent 
(fig 9).  The difference in image quality is also demonstrated in fig. 10 showing a magnified view of 
the bony structures taken from CT data of a cadaver. The next example illustrates the new quality on 
3D­views of blood vessels reconstructed from MR- and CT­angiography acquisitions (fig. 11). Our technique 
also en­ables endoscopic views even of very small structures like bi­furcations of cerebral arteries 
as shown in fig. 12. 3.1 Visible-Human The Visible-Human-Dataset provided by the NLM has gained much 
attention in the past years [8, 12]. For the first time colored digital cross-sectional images of human 
anatomy in a resolution unatainable of today s tomographic scanner technology are available. We reduced 
the slice reso­lution by a factor of three to get a managable volume size and segmented different parts 
of the body using ellipsoids in RGB-space for the classification of the objects [14, 10]. For the visualization 
we adapted the reclassification scheme to deal with ellipsoids: to determine the interpolation fac­tor 
 as described in section 2.3 the 2nd order surface of an ellipsoid requires the solution of a quadric 
equation. AS de­scribed in section 2.5.1 the interpolation of the color value directly at the object 
boundary yields in the case of the skin surface a strange appearance caused by the blue background of 
the data (fig. 13 left). We therefore emperically shifted the interpolation center beneath the surface 
until skin (fig. 13 right) and muscular structures (fig. 14) unveiled a very natural nearly photo-realistic 
appearance. The multi-modality capability of our approach is demon­strated in fig. 15 where we took the 
skull from CT and muscles and vascular structures from the RGB-volume. 3.2 Artificial object For the 
simulation of very small manually segmented objects we have created a volume containing a one voxel thin 
heli­cal structure. The object voxels are 26-connected and no partial-volume-effect has been modeled 
to demonstrate the attribute interpolation scheme. Serious artifacts are visible using a straight forward 
ray-casting implementation (fig. 16 top left). Although the classical discrete scan-conversion al­gorithm 
produces a mathematically correct result (top right) the voxel-like surface is probably not what one 
would expect from natural objects like blood vessels. The lower left image shows the reconstruction using 
the reclassification method in combination with the binary attribute value interpola­tion, and the lower 
right image is computed with B-spline interpolation and a slightly lower threshold to improve con­nectivity. 
 To demonstrate the quality aviechable for natural ob­jects we rendered the structures in fig. 7 with 
thresholding turned off for attribute determination and gradient calcula­tion. It turns out that the 
appearance of areas with high curvature such as the surface of the brain are very much alike, however, 
low curvature structures show certain arti­facts (fig. 17). Hence the described reclassification scheme 
is still the superior method. 3.3 Computational costs What are the additional computational costs of 
our new method in contrast to classical ray-casting? 1. floating-point calculation for ray-traversal 
to maintain subvoxel resolution in contrast to digital-differential­analyzer techniques which can be 
implemented using integer-arithmetic only; 2. tri-linear (or higher order) interpolation of the gray­values 
at each sample position; 3. examination of the 8 neighbours; 4. calculation of the surface location 
between sample points. (For opaque surface this is only done once per pixel).  If we take volume-rendering 
with non-transparent objects and early ray termination as the basis only 3. applies as additional effort. 
Table 1 lists typical computation times for some of the figures. As our new approach generates superior 
image quality for segmented data computation times are not directly compa­rable, for instance the endoscopic 
view of the blood vessels in fig. 12 cannot be created with classical ray-casting. For the images shown 
here we found that the determination of the attribute value requires approximately 40-60%, interpo­lation 
25%, ray-casting 14%, gradient calculation 2.5% and  surface location computation 2% of the total CPU 
time. Im­age computation time will therefore mostly benefit from re­ducing attribute calculation costs. 
  4 CONCLUSION AND FUTURE WORK We have developed a new method for the precise location of object boundaries 
segmented from tomographic volume data. The method is based on the partial-volume-effect and reclassifies 
the sample positions along the viewing rays by interpolating the original gray-values and searching for 
the best fitting attribute value in the neighbourhood. The boundary is then determined between successive 
sample points using linear interpolation or bisection. This in turn enables a more accurate calculation 
of the surface normal using the gray-level-gradient. Our method also detects re­gions which result from 
manual segmentation or other un­usual conditions in which case we apply an interpolation scheme on the 
attribute values. We have demonstrated the new quality achievable with a number of different datasets. 
Small and thin objects like blood-vessels as well as endo­scopic views can be rendered in high resolution 
using the oversampling ability of the technique. In the case of the colored Visible-Human cross-sections 
nearly photo-realistic images result. The described techniques form the kernel of the VOXEL-MAN visualization 
system. Our future work will include . the improvement for manually segmented regions, where the proposed 
interpolation of the attribute values is only a first step; the extension of the scheme to other segmentation 
methods. So far we have only incorporated threshold­ing for scalar volume data and ellipsoids for the 
colored Visible-Human images; quantitative measurements about the accuracy of the method. References 
[l] Robert A. Drebin, Loren Carpenter, and Pat Hanra­han. Volume rendering. Comput. Graphics, 22(4):65­74, 
1988. [2] Karl Heinz Höhne, editor. VOXEL-MAN, Part 1: Brain and Skull, Version 1.0. Springer-Verlag 
Electronic Me­dia, Heidelberg, 1995. (ISBN 3-540-14517-6). [3] Karl Heinz Höhne and Ralph Bernstein. 
Shading 3D­images from CT using gray level gradients. IEEE Trans. Med. Imaging, MI-5(1):45-47, 1986. 
 261  [4] Karl Heinz Höhne and W. A. Hanson. Interactive 3D­segmentation of MRI and CT volumes using 
morpholog­ical operations. J. Comput. Assist. Tomogr., 16(2):285­294, 1992. [5] Arie Kaufman, editor. 
Volume Visualization. IEEE Computer Society Press, Los Alamitos, CA, 1991. [6] Marc Levoy. Display of 
surfaces from volume data. IEEE Comput. Graphics Appl., 8(3):29-37, 1988. [7] William E. Lorensen and 
Harvey E. Cline. Marching Cubes: A high resolution 3D surface construction algo­rithm. Comput. Graphics, 
21(4):163-169, 1987. [8] National Library of Medicine. The Vis­ible Human Project. World Wide Web: [9] 
Andreas Pommert, Ulf Tiede, Gunnar Wiebecke, and Karl Heinz Höhne. Surface shading in tomographic volume 
visualization: A comparative study. In First Conference on Visualization in Biomedical Computing, Proc. 
VBC 90, pages 19-26. IEEE Computer Society Press, Los Alamitos, CA, 1990. [10] Thomas Schiemann, Ulf 
Tiede, and Karl Heinz Höhne. Segmentation of the Visible Human for high quality vol­ume based visualization. 
Med. Image Anal., 1(4):263­270, 1997. [ll] Lisa M. Sobierajski and Arie E. Kaufman, Volumetric ray tracing. 
In ACM/IEEE Volume Visualization Sym­posium Proceedings, October 1994, pages 11-18. ACM Press, 1994. 
[12] Victor Spitzer, Michael J. Ackerman, Ann L. Scherzinger, and David Whitlock. The Visible Hu­man 
male: A technical report. J. Am. Med. Inf. Ass., 3(2):118-130, 1996. [13] Ulf Tiede, Karl Heinz Höhne, 
Michael Bomans, Andreas Pommert, Martin Riemer, and Gunnar Wiebecke. In­vestigation of medical 3D-rendering 
algorithms. IEEE Comput. Graphics Appl., 10(2):41-53, 1990. [14] Ulf Tiede, Thomas Schiemann, and Karl 
Heinz Höhne. Visualizing the Visible Human. IEEE Comput. Graph­ics Appl., 16(1):7-9, 1996. [15] Roni 
Yagel, Daniel Cohen, and Arie Kaufman. Dis­crete ray tracing. IEEE Comput. Graphics &#38; Appl., 12(5):19-28, 
1992.  
			