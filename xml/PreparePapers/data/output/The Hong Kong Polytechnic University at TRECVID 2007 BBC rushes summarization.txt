
 The Hong Kong Polytechnic University at TRECVID 2007 BBC Rushes Summarization Yang Liu1, Yan Liu1, 
Yan Zhang1, 2 1Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong 
Kong 2Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, P. R. China 
lyhn12003@yahoo.com.cn, csyliu@comp.polyu.edu.hk, zhang-y-05@mails.tsinghua.edu.cn ABSTRACT In this 
paper, we propose the framework and methodology for BBC rushes summarization task of TRECVID 2007. We 
divide the entire task into three sub-tasks: shot segmentation; noise shot detection and removal; video 
summarization. We first segment the rushes to a set of video shots based on the accumulative difference 
between the consecutive frames. In the second sub-task, we classify the noise video shots to several 
categories and detect them individually using different feature space. A novel audio­based method has 
been proposed to detect the video shots including clapper board noise. Thirdly, we extract the most representative 
video clips from the useful video shots and remove the redundant ones by comparing the similarity. We 
analyze the performance of these methods, and demonstrate them in the BBC rushes summarization task. 
Categories and Subject Descriptors I.2.10 [Artificial Intelligence]: Vision and Scene Understanding Video 
analysis. General Terms Algorithms, Experimentation Keywords BBC rushes summarization, Video rushes editing, 
Audio transient, Clapper board noise detection. 1. INTRODUCTION In TRECVID 2007, our group takes part 
in the BBC rushes summarization task. As a promising research area, rushes summarization has received 
significant attention in the multimedia literature recently. P. Over et al. provide state-of-the­art 
introduction to the research background, problem statement, data preparation and result evaluation in 
[1]. The remainder of this paper is organized as follows: Section 2 proposes the framework of our rushes 
summarization system. The methodology, with a particular focus on our novel audio-based noise detection 
algorithm is presented in detail in Section 3. We Permission to make digital or hard copies of all or 
part of this work for personal or classroom use is granted without fee provided that copies are not made 
or distributed for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires 
prior specific permission and/or a fee. TVS 07, September 28, 2007, Augsburg, Bavaria, Germany. Copyright 
2007 ACM 978-1-59593-780-3/07/0009 $5.00. demonstrate the performance of our system and methodology 
on the data of the task in Section 4. We close the paper with conclusions and further work. 2. FRAMEWORK 
OF RUSHES SUMMARIZATION Figure 1 shows the framework of our rushes summarization system. The entire procedure 
is composed of three important parts: shot segmentation; noise shot detection and removal; video summarization. 
The inputs of the system are raw data of BBC rushes and the outputs are the summary of the rushes in 
the form of video clips. Figure 1. Framework of rushes summarization system. 2.1 Shot Segmentation In 
this step, we segment the raw data of the BBC rushes to a set of video shots based on the accumulative 
difference of the consecutive frames. We combine the pixel-based method and histogram-based method [2]-[4] 
to detect the boundary between the video shots. First we calculate the differences in color values of 
corresponding pixels in two successive frames. We use Diff _ pi () to define the absolute sum of the 
pixel differences between frame i and i-1. AverDiff _ pn () is the average value of the absolute sum 
of the pixel differences for the former n-1 frames: AverDiff _ pn () = 1 .n Diff _ pi ( ) (1) n -1 i=2 
Similar to the above rules, we define Diff _ hi () as the absolute sum of the histogram differences between 
frame i and frame i-1 and AverDiff _ hn () as the average value of the absolute sum of the histogram 
differences for the former n-1 frames. We declare frame n as a cut boundary when the following two conditions 
are satisfied: pn 1 p pn -1) Diff _ () >w AverDiff _( (2) hn 1 h hn -1) Diff _ () >w AverDiff _( w1 and 
w1h are two weight factors which can adjust cut p thresholds. For a gradual transition, we give other 
two weight factors: 2 wp 2 12 12 and , which satisfy >>. When the wh w >> w 1, ww 1 pp hh following 
two conditions are satisfied simultaneously at several consecutive frames: 12 _ pn ( ->Diff _ pn >w AverDiff 
_ pn -1) w AverDiff 1) () ( pp (3) 12 _( -> _ () >w AverDiff _ hn -1) w AverDiffh n 1) Diffhn ( hh We 
declare these consecutive frames as a gradual transition. 2.2 Noise Detection and Removal In this section, 
we classify the segmented video shots to two categories: useful video shots and noisy video shots. In 
general, there are three kinds of noises in unedited rushes or films: rainbow bands, gray (black, white) 
frame, and clapper board noise as shown in Figure 2. Almost all rushes distributed by TRECVID 2007 for 
the BBC rushes summarization include at least one kind of noisy video shot. The length of the noisy video 
shot to the length of the entire rushes varies from 2% to 5%. (a) (b) (c) Figure 2. Three kinds of noises: 
(a) rainbow bands; (b) gray frame; (c) clapper board noise. Figure 3 illustrate the noisy shot detection 
procedure using clapper board noise. We first obtain audio information and video information from the 
segmented video shots. Then we extract features from visual and audio information. We classify the video 
shots to useful clips and noisy clips based on the extracted features. 2.3 Video Summarization After 
removing noisy clips, all remaining shots are useful. Therefore, the purpose of this step is extracting 
the most representative clips from these useful shots to compose final summaries original rushes. In 
each shot, we firstly segment the shot into some clips which have fixed length based on the length requirement 
(at most 4% of the original video) of the BBC rushes summarization task. We then pick up two frames from 
each clip. These two frames have maximal and minimal Diff _ hi () in the clip respectively. It means 
that these two frames can represent the most motional and static information of this clip. Clapper Board 
Noise Useful Shots Figure 3. Flowchart of noisy video shot detection After extracting these most representative 
frames, we array them in temporal order and give them new sequence numbers. Then we employ a similarity 
metric to detect and eliminate duplicate frames. Similar to section 2.1, we use histogram difference 
as the judging criterion. The average histogram difference of all the Diff _ hi() (i=1, 2, , N) is defined 
as follow: 1 N AverDiff .hi (4) _ h = Diff _() N -1 i=2 while N is the total number of representative 
frames. We declare that the frame i is redundant and should be removed from the representative frame 
sequence if Diff _ hi() satisfies: 3 Diff _ hi () <w AverDiff _ h (5) h while wh3 is an adjustable weight 
factor. After redundant information removal, the remaining frames in the sequence are most representative 
and informative. For each representative frame, we find the former 12 frames and latter 12 frames of 
it, and then compose these 25 frames to a one-second clip. According to the research in [5], a scene 
should be about 3 sec long to get completely analyzed by a normal person. But the minimum length of one 
video clip can be shortened further if the user only wants to browse it. So in this task, we link these 
one-second video clips in the time order to generate the final summary. 3. KEY TECHNOLOGY IN NOISE DETECTION 
In this section, a key technology of the rushes summarization system, noise detection based on visual 
information and audio information, is proposed. As mentioned in section 2.2, there are three main kinds 
of noises in the shots: rainbow bands, gray (black, white) frame, and clapper board noise. Rainbow bands 
and gray frames can be easily detected by their special characteristics in color histogram information. 
In these two kinds of video clips, the colors are concentrated in very few values (Figure 2 (a) and (b)), 
so their color distributions are skew and variance of their color histograms is relatively bigger than 
that of ordinary images. This useful visual feature can be utilized to detect rainbow bands and gray 
frames from segmented shots. The clapper board noise occurs far more frequently than rainbow bands and 
gray frames. Unfortunately, recognizing the video clips with clapper board is relatively hard because 
of the variety of the boards modality and its visual similarity with the normal scene. A novel audio 
feature based method is proposed in this section to detect clapper board noise from segmented shots. 
3.1 Audio Characteristics with/without Presence of Clapper Board In video or film production, the clapper 
board is a device used to (a) synchronize video and audio and (b) to identify the takes. The clapper 
board sound often appears at the beginning of a scene or a shot and is generated by the action knock 
. An important and unique characteristic lies in the phenomenon that the acoustical energy is greatly 
increased after the knocking as shown in Figure 4 (a). (a) Clapper Board    (b)Non-Clapper-board 
Figure 4. Audio features of clapper board transient sound and non-clapper-board sound. From the raw material 
distributed by TRECVID 2007, we found that more than 95% of film sequences only contain stationary sounds 
as shown in Figure 4(b). The remaining 5% might include clapper board-like sound, such as sound accompanied 
by collision, sound by knocking desks, and so on. The similarity lies in that these kinds of sounds appear 
in the quiet environment. Fortunately, energy of some sounds does not increase as quickly as clapper 
board transient sound, which is possible to be discriminated. It should be mentioned that a small portion 
of non-clapper-board sounds have the property of sudden and great increase of acoustical energy, which 
brings the error of classification. 3.2 Robust Clapper Board Transient Detection Based Approach Based 
on characteristic of sounds in film editing, an audio based approach is proposed, which adopts a robust 
clapper board transient detection method. When the decoded audio signal is acquired from bit stream, 
audio sequence will be divided into multiple segments with the length of N sample points. For each segment, 
a clapper board transient detection method is implemented to decide whether it contains a clapper board 
transient. If the decision indicated the presence of clapper board transient, the whole audio sequence 
(the film sequence) is determined as a clapper board noise. Otherwise the next segment is checked. If 
all segments have no clapper board transient sound, the audio sequence (the film sequence) is determined 
as one without clapper board. The flowchart of proposed method is shown in Figure 5. Figure 5. Flowchart 
of clapper board Transient detection based approach The key to solving the problem is the part of clapper 
board detection algorithm, which will be exhaustively described as follows. Denote the samples of a segment 
as x, x,...., x. The 12 N segment is uniformly divided into 32 sections as Bl, =1, 2,...,32 : l B= {x 
, x ,...., x} lN-31 N-30 N ll l (6) lN N= ,l=0,1, 2,...,32 l 32 Energy of each section and total segment 
are computed: N Ei =. xn 2 E0 =.xi 2 (7) nB =1 . i i The aim becomes to find the section called Sudden-Increase 
section (SI section) whose energy is greatly larger than the last section. The section with greatest 
increase which implies in the appearance of clapper board transient sound has two important properties. 
 Energy is relatively large  Energy is larger than the previous one On the basis of the characteristics, 
the SI section belongs to a small set composed of sections satisfying the following properties:  1 S= 
{|lE > E and E>E} (8) ll-1 l 0 32 In the selected sections, the energy ratio and peak-energy ratio are 
computed individually for feature extraction. The energy ratios of sections are calculated. The ratio 
by energy of selection section divided by previous section is a heuristic method. For robustness, another 
ratio is computed by dividing Eby E. The aim is to ll-2 prevent the average effect to reduce the peak 
energy. The equations for the ratio computation are shown as follows: EE 1 l ,2 l (9) r = r = ,l .S l 
El-1 l El-2 The first feature is calculated by: f =max{ 1, 2 (10) rr } 1 ll Another feature is peak-to-energy 
ratio (PER) proposed in reference [6]. It is another technique for robustness. In each selection section, 
the maximum absolute value is found and the ratio is computed by: 2 max x 3 xBi . li (11) rl =E l -1 
The second feature is calculated by: f =max rl 3 (12) 2 By two features, the decision is made by a linear 
classifier: Df12 = .Tx (, f ) (13) [, , ], x= [ f1, f2,1] . = abc Weighted parameters a, b and c is decided 
by the training sets and the minimum classification error principle. The whole flowchart of clapper board 
transient detection is described in Figure 6:   4. EXPERIMENTAL RESULTS ANALYSIS In this section, we 
first demonstrate the results of the proposed noise shots detection and then provide the rushes summarization 
performance of the entire system. We also discuss the influence of different video segmentation methods 
to the final rushes summarization result. The test bed of this section can be found in [1]. 4.1 Noisy 
Shot Detection In this section, we evaluate our detection algorithm based on two experiments. To demonstrate 
the efficiency of the proposed algorithm, we cut some non-clapper-board clips manually as the input in 
experiments of this section. As shown in Figure 7, the position, size and style of clapper boards are 
not similar so that it is not easy to be detected by visual information. Detection results based on audio 
information are shown in Table 1. Classification accuracy of scene 1-3 reaches 92.35%. Errant classification 
results are from the existence of other sorts of transient signals, such as collision sounds, sudden 
shouting, click sounds by lighter, and so on. Another reason for classification error is that few clapper 
board transient signals are not as strong as normal ones. Some extreme cases are shown in Figure 8. Clapper 
boards of scene 4-6 are nearly indiscriminable by visual information. The detection result of these scenes 
is listed in Table 2. The classification accuracy is encouraging. Only 1 shot is misclassified. The Computational 
time of clapper board detection is listed in Table 3. The average computational time of experiment 1 
and 2 is different. This is because that the computational time depends on the length of clips. Scene 
1 Scene 2 Scene 3 Figure 7. Three different kinds of clapper board noises. Table 1. Classification accuracy 
of proposed method in scene 1, 2 and 3. Real events Detected as Clapper board noise Non-clapper­board 
shots Clapper board noise 72 5 Non-clapper-board shots 10 109 Scene 4 Scene 5 Scene 6 Figure 8. Clapper 
board noises which can hardly be detected by using visual information. Table 2. Classification accuracy 
of proposed method in scene 4, 5 and 6. Real events Detected as Clapper board noise Non-clapper­board 
shots Clapper board noise 6 0 Non-clapper-board shots 1 12 Table 3. Computational time of clapper board 
detection The Number of Clips Average Time (secs) Sum Time (secs) Experiment 1 196 0.297 58.18 Experiment 
2 19 0.189 3.595 The overall detection result including scene 1-6 is revealed by Table 4: Total classification 
rate is 92.56%. Two other important items called recall R and precision P also can be used to evaluate 
the performance of this noise detection algorithm. Correct Detection Correct Detection (14) R = , P = 
Total Noise Shots Correct Detection + False Detection Table 4. Classification accuracy of proposed method 
in all scenes. Real events Detected as Clapper board noise Non-clapper­board shots Clapper board noise 
78 5 Non-clapper-board shots 11 121 The results of recall and precision are listed in Table 5. Table 
5. Recall and Precision of proposed method in all scenes. Recall Precision 87.64% 93.97% All the experimental 
results above show that the proposed method is robust for detecting different scenes and videos, some 
of which are very difficult to detect by the visual information. And the classification accuracy also 
demonstrates the high efficiency of our algorithm.  4.2 Rushes Summarization Our summarization results 
are listed in the following table. Table 6. Final results of BBC rushes summarization task. 7 evaluation 
criterions Mean of 42 rushes of hkpu Mean of 42 rushes of all participants DU (secs.) 31.37 50.54 XD 
(secs.) 28.5 9.33 TT (secs.) 62.17 93.17 VT (secs.) 33.33 51.86 IN (0-1) 0.4 0.49 EA (1-5) 3.12 3.19 
RE (1-5) 3.83 3.65 From the first 4 criterions in Table 6, we could see that the length of our 42 summaries 
is much shorter than the average length of 42 summaries from all 22 participated groups. For the last 
two criterions, the performance of our system is approximately equal to the average level of all the 
participated groups. The fifth criterion (IN) shows that the fraction of inclusions found in our summaries 
is a little lower than the average value. This is because the second step of our system, noise detection 
and removal, is highly depending on the first shot segmentation step. Unfortunately, the performance 
of our first pre-process step is not as high as we expected. Some clapper board segments are not detected 
as a cut or a gradual transition. Oppositely, they are included into the normal shots. But in the second 
step, these normal shots which may include important information are detected as the clapper board noise 
clips, therefore the important information included in these shots are missed. The next experiment can 
explain this problem clearly. We firstly segment the original videos manually, and then these manually 
segmented shots are used as the inputs of step 2. New results of three sample rushes are listed in Table 
7. It demonstrates that IN values of these three rushes enhance 0.2, 0.14, and 0.03 respectively if the 
shot segmentation is performed manually. One thing that must be mentioned here is that the old IN values 
are judged by the NIST evaluators and the new IN results are judged by us according to the inclusions. 
They are not official results, but also can support the reason analysis we proposed above. Another possible 
reason is that there are several rushes that do not have cut boards in the shot cut or transition. Table 
7. Comparison of old and new IN results. Rushes number Old IN value New IN value MRS145918 0.22 0.42 
MRS134704 0.44 0.58 MRS157464 0.72 0.75  5. CONCLUSION AND FUTURE WORK In this paper, we described 
our system designed for BBC rushes summarization task in TRECVID 2007. The system is composed of three 
sections: shot segmentation, noise detection and removal, and video summarization. The final summarization 
results demonstrate that our system performed well in the whole task but still needs to improve in some 
aspects such as criterion IN. The biggest contribution proposed in this paper is a new audio feature 
based method for noise detection task. We have shown the high recognition accuracy of our proposed method 
in the experiments. We will explore rushes summarization from several aspects in the future. We intend 
to enhance the video shot segmentation accuracy because it affects the noisy shot removal directly. Secondly, 
we will explore some speech recognition techniques to improve the clapper board noise detection performance 
under some extreme cases. Last but not the least, how to determine the most representative and attractive 
video clips from the useful video shots according to the human s perception is worthy for further investigation. 
 6. ACKNOWLEDGMENTS This work is supported by grant A-PH11 of the Hong Kong RGC Direct Allocation. 7. 
REFERENCES [1] Over, P., Smeaton, A.F., and Kelly, P. The TRECVID 2007 BBC rushes summarization evaluation 
pilot. In Proceedings of the TRECVID Workshop on Video Summarization (TVS'07), Augsburg, Germany, September 
28, 2007, ACM Press, New York, NY, 2007, 1-15. [2] Kikukawa, T., and Kawafuchi, S. Development of an 
automatic summary editing system for the audio visual resources. Transactions of the Institute of Electronics, 
Information and Communication Engineers, 1992: J75-A (2). [3] Zhang, H.J., Kankanhalli, A., and Smoliar, 
S.W. Automatic Partitioning of Full-Motion Video. Journal of Multimedia Systems 1, 10-28. 1993. [4] Ma, 
Y.F., Sheng, J., Chen, Y., and Zhang, H.J. MSR-Asia at TREC-10 Video Track: Shot Boundary Detection Task. 
Video TREC. 2001. [5] Pfeiffer, S., Lienhart, R., Fischer, S., and Effelsberg, W. Abstracting Digital 
Movies Automatically. Journal of Visual Communication and Image Representation, 7, 4 (Dec.) pp: 345-353. 
1996. [6] Yan, J. X, Dou, W. B., and Dong, Z. W. Time-Domain Detection Method of Transient Signals in 
Audio Coding. Journal of Electronics&#38; Information Technology, vol. 28, no. 2 (Feb. 2006), (in Chinese) 
 
			