
 Bounding Variance and Expectation of Longest Path Lengths in DAGs Je. Edmonds* Abstract We consider 
the problem of computing bounds on the variance and expectation of the longest path length in a DAG from 
knowledge of variance and expectation of edge lengths. We focus primarily on the case where all edge 
lengths are non-negative and the DAG has a single source and sink node. We present analytic bounds for 
various simple DAG structures, and present a new algorithm to compute bounds for more general DAG structures. 
Our algorithm is motivated by an analogy with balance of forces in a network of strange springs. 1 Introduction 
Consider a directed acyclic graph (DAG) G with a sin­gle source node s and a single sink node t, in which 
each edge i = (a, b) has a non-negative weight xi. Such DAGs are commonly used to represent timed precedence 
constraints between jobs or events (e.g. timed marked graphs [10, 1], PERT charts [5], task graphs [7] 
and precedence constraint diagrams [8]). The edge weights in such a DAG correspond to delays between 
jobs or events. Hence, we will refer to edge weights and edge delays interchangeably. The starting time 
of the job associated with the source node s is assumed to be 0. The starting time of every other job 
b ( = s) is de.ned to be maxa . P arent(b)(starting time of a + x(a,b)). If all edge delays are constant, 
the starting time of the job associated with b can be determined by computing the longest path length 
from s to b in G [3, 9]. If, however, the edge delays are random, the starting time of a job is determined 
by a random variable. Let XG be the random variable denoting the starting time of the job associated 
with the sink node t of DAG G. If the joint probability distribution of the xi s is known, techniques 
for computing the distribution of the sum and maximum of random variables [6, 4] can be used to obtain 
the dis­tribution of XG. Monte Carlo simulations [11] can also be used to study the distribution of XG 
in such cases. However, specifying the joint probability distribution of all xi s amounts to specifying 
all joint moments of xi s. In a practical setting, this often involves making *York University, Canada. 
je.@cs.yorku.ca. Supported in part by NSERC Canada. IIT Bombay, India. supratik@cse.iitb.ac.in Supratik 
Chakraborty idealized assumptions. An interesting question to ask, therefore, is how well can we characterize 
XG given only the .rst few moments of each xi. Such a characteriza­ tion must hold across all joint distributions 
of xi s that preserve the .rst few moments of every xi. This has potential applications in statistical 
timing analysis and performance analysis, and motivates our current work. We are interested in studying 
bounds on the mo­ ments of XG as a function of G and moments of each individual xi. Speci.cally, suppose 
we know the mean mi and variance vi, but not the complete distribution, of the delay xi of each edge 
i = (a, b) in G. We wish to establish bounds on the mean, mG, and variance, vG, of XG, where the random 
variables xi can be dependent in arbitrary ways (including being independent). This problem was studied 
earlier in [2], where a dynamic pro­ gramming algorithm for computing conservative bounds on mG and vG 
was proposed, and experimentally val­ idated against a few distributions. Unfortunately, the approach 
in [2] neither computes tight bounds of mG or vG, nor helps in identifying probability distributions 
of xi s that lead to maximum or minimum values of mG and vG. In this paper, we try to address these de.cien­ 
cies partly. Speci.cally, we identify tight upper bounds of mG and vG and also probability distributions 
that achieve these bounds. The corresponding problems for lower bounds still remain open. Let P be the 
set of paths from s to t in G. Each path p . P can be thought of as the set of edges i = (a, b) along 
the path. The starting time XG of the job associated with the single sink node t is delayed by the fact 
that jobs along every st path must complete t t sequentially. In other words, XG = Maxp.Pi.p xi . Two 
extreme examples of DAGs are series and parallel graphs. A DAG G is a series graph if it consists of 
 only one st path. In this case, XG =i xi. A DAG G is a parallel graph if it consists only of multiple 
st­edges. In this case, XG = Maxixi. These extreme cases have been studied earlier in di.erent contexts, 
e.g. in the study of linear combinations of random variables, and in the study of order statistics [4]. 
The situation for series-parallel graphs is, however, more complicated than one would expect. The problem 
for a general DAG with a single source and single sink node is even more complicated, and is the primary 
focus of this paper.  Our contributions can be summarized as follows: 1. We introduce a special kind 
of probability distribu­tion called cake distribution for edge delays. This allows us to independently 
control the mean and variance of path delays while ensuring that the mean and variance of edge delays 
stay unchanged. 2. We present tight upper bounds of the mean and variance of XG when edge delays are 
dependent in arbitrary ways, and present techniques for comput­ing these bounds. We also identify cake 
distribu­tions of edge delays that cause these bounds to be achieved. 3. We present lower bounds of 
the mean and variance of XG that are not always achievable, but can be achieved under certain conditions. 
 4. We show a continuum of values for the mean and variance of XG. We also show that extreme values in 
this continuum can be achieved simultaneously, within small factors. 5. We show that the the maximum 
variance of XG in a series-parallel graph can be obtained by recursively applying the expressions for 
maximum variance in series and parallel graphs. However, a similar recursive application does not give 
tight bounds for the maximum mean of XG in a series-parallel graph.  The remainder of this paper is 
organized as follows. Section 2 introduces cake distributions and discusses some properties of these 
distributions. In Section 3, we present a technique for computing a tight upper bound of the variance 
of XG. We also identify edge delay distributions that cause this bound to be achieved. Section 4 presents 
tight upper bounds of the mean of XG and identi.es corresponding edge delay distributions. In Section 
5, we present lower bound results, which are, however, not necessarily tight. Section 6 discusses the 
above problems for the important special case of series­parallel graphs. Finally, we conclude in Section 
7. 2 Random variables and cake distributions A convenient way to represent a random variable xi is as 
a function fi : [0, 1] .1=0 . For clarity of exposition, we will abuse notation and use xi to denote 
both the random variable and the corresponding function. In order to choose a value for xi, we choose 
r uniformly at random from [0, 1], and then the value of the random variable xi is given by the function 
xi(r). By choosing di.erent functions [0, 1] .1=0, random variables with di.erent probability distributions 
can be speci.ed. Consider a set of random variables {x1,x2,...xn}. In general, there may be k groups 
in the set such that variables within the same group are dependent, while all variables in one group 
are independent of those in another group. In order to choose values for all the vari­ables, we choose 
a real value r uniformly randomly in [0, 1], and then derive k uniformly randomly distributed real values 
r1,r2,...rk from r, such that each rj . [0, 1]. One way of doing this is to obtain the decimal represen­tation 
of rj by choosing the (w.j)th digit in the decimal representation of r for all w ... Since r is chosen 
uniformly randomly in [0, 1], the variables r1,r2,...rk are independent and uniformly random in [0, 1] 
as well. The values of all variables in the jth group of the set {x1,x2,...xn} can now be obtained by 
evaluating the corresponding functions with rj as the argument. Al­ternatively, the functions can be 
speci.ed to take r as an argument, derive rj from it and then give the values of the corresponding random 
variables. Thus, arbitrary dependencies (including independence) of a set of ran­dom variables can be 
represented by choosing the func­tions [0, 1] .1=0 appropriately. We will assume all random variables 
are represented as functions in this way. Choosing values for a set of random variables therefore amounts 
to choosing a single real value r uni­formly randomly in [0, 1] and evaluating the correspond­ing functions. 
For a random variable xi represented in this way, the expected value of xi is the area under the curve 
xi(r) between r = 0 and r = 1. Thus, mi = Exp[xi]= x xi(r) dr. Similarly, the second moment is given 
r.[0,1] x 2 by ui = U[xi] = Exp[x]= xi(r)2 dr. Finally, ir.[0,1] 2 the variance is given by vi = Var[xi]= 
ui - mi . Suppose we wish to know how Exp[xi] and Var[xi] change when the function xi : [0, 1] .1=0 is 
changed in.nitesimally. In order to produce such an in.nitesi­mal change, we must change xi(r) by an 
in.nitesimal amount in an in.nitesimally small interval in [0, 1]. In view of this, we choose two in.nitesimals, 
dr and dx. To make things less confusing, we will assume that the domain [0, 1] of xi is divided into 
slices of width dr such that the function xi(r) has a constant value within each slice. In the following, 
when we say that xi(rr) is in­creased by dx, we mean that the value of xi(r) is in­creased by dx for 
all r in the slice [rr, rr+ dr]. We will now consider what e.ect such a change has on Exp[xi], Exp[xi]2, 
U[xi], and Var[xi]. Lemma 2.1. Increasing xi(rr) by dx increases Exp[xi] by drdx, and increases Var[xi] 
by 2.i(rr)drdx, where .i(rr)= xi(rr) - Exp[xi]. Proof. Exp[xi]: As given above, the expected value x 
of xi is xi(r) dr. Increasing xi(rr) by dx r.[0,1]  increases this area by a small rectangle of area 
drdx. Hence, Exp[xi] increases by drdx. dm2 dm Exp[xi]2: The chain rule gives that = 2m · . dx dx Hence, 
the square of the expectation Exp[xi]2 increases by 2.Exp[xi].drdx. U[xi]: The value xi(r ) increases 
by dx. Hence, by the chain rule the value xi(r )2 increases by 2.xi(r ).dx. The area under the curve 
xi(r)2, i.e., xi(r)2 dr, has this change occur in a block r.[0,1] of width dr. Hence, the second moment 
U[xi]= Exp[xi 2] increases by 2.xi(r ).drdx. Var[xi]: We know Var[xi] = U[xi] - Exp[xi]2 . Hence, the 
variance Var[xi] increases by [2.xi(r ).drdx] - [2.Exp[xi].drdx]=2..i(r ).drdx. We will have occasion 
to use Lemma 2.1 later in Section 3. One of the challenges in choosing distributions for edge delays 
xi such that the mean or variance of XG is maximised (or minimised), is the interplay between its expected 
value and its variance. Cake distributions, as de.ned below, attain independence between these two measures. 
These distributions are called cakes because the function xi : [0, 1] .1=0 de.ning the distribution looks 
like a cake with in.nitesimally thin candles on it. The cake itself is .at and accounts for the expectation 
of the distribution, but does not contribute to its variance. In contrast, each candle is in.nitesimally 
thin and either has zero height or is in.nitely high. Each in.nitely high candle, being in.nitesimally 
thin, contributes only to the variance of the distribution, but not to its expectation. As we will see, 
cake distributions are particularly useful for proving several bounds we are interested in. For purposes 
of our discussion, all cake distributions are assumed to have candles in the same prede.ned q locations 
{r| q . Q} where Q is a .nite index set. Furthermore, all candles have the same .xed width E2 , where 
E is an in.nitesimal (approaching zero). What changes from one cake distribution to the next is the height 
m of the cake and the height of each of its candles. Suppose the random edge delay xi has a cake distribution, 
where the height of the cake is mi. Let the height of the candle at location rq for edge delay xi be 
h(i,q). To help us better make the connection between candle heights and variance, we will associate 
with each v vi,q) candle the parameter v(i,q), where h(i,q) = (. More E formally, the distribution of 
xi is speci.ed by the tuple (mi, {v(i,q) | q . Q}), and is de.ned as follows. q h(i,q) if r . [r,rq 
+ E2],q . Q, h(i,q) > 0 xi(r)=mi otherwise Lemma 2.2. Let xi have a cake distribution with pa­rameters 
(mi, {v(i,q) | q . Q}). Then Exp[xi]= mi and Var[xi]= q.Q v(i,q). x Proof. Exp[xi]= xi(r) dr = (1 - E2 
.|Q|).mi + r.[0,1] q.Q E2.h(i,q). Since E is an in.nitesimal, |Q| is .nite v v(i,q) and h(i,q) = E x 
, it follows that Exp[xi]= mi. Sim­ilarly, Exp[x2]= (xi(r))2 dr = (1 - E2 .|Q|).m2 + r.[0,1] 2 q.Q E2.h(i,q) 
. For the same reasons as above, it now follows that Exp[x2]= m2 + q.Q v(i,q). Therefore, 2 Var[xi] = 
Exp[(xi)2] - m= q.Q v(i,q). Suppose our goal is to distribute the variance vi of each edge delay xi among 
the di.erent candle locations in a way that maximizes Var[XG]. If G is a series graph, i.e. XG = i xi, 
then the desire is for each xi to put its entire candle height in the same location. On the other hand, 
if G is a parallel graph, i.e., XG = Maxixi, then the desire is for the xi s to put their candle heights 
in di.erent locations, so that none of the non-zero candle heights are subsumed by others. If G is an 
arbitrary graph, there is a complex balance between these two desires in order to maximize XG. What is 
clear, however, is that a number of di.erent candle locations may be needed. In the extreme, the number 
of non-zero candle locations will be at most the number of edges in the DAG G. For now, however, p we 
will have one candle location rfor each st-path p . P . In other words, the index set Q referred to above 
is identi.ed with the set P of st-paths in G. p The height h(i,p) of the candle at location rfor edge 
delay xi will be non-zero only if edge i is in the path p (henceforth denoted i . p). This ensures that 
each tt path p dominates XG(r) = Maxp.Pi.p xi(r) when r is within its own candle, i.e. between rp and 
rp + E. It also ensures that Var[xi]= p3i v(i,p), where p 3 i denotes p .{p | p . P .i . p}. Lemma 2.3. 
Suppose each edge i in DAG G has a cake distribution with parameters (mi, {v(i,p) | p . P }). It follows 
that the resulting distribution of XG is also a cake distribution with parameters (mG, {v(G,p | p . tt 
P }), where mG = Maxp.Pi.p mi and v(G,p) = tt2 v v(i,p) for each p . P . i.p Proof. By de.nition, XG 
= Maxp.Pi.p xi. Tracing out XG(r) for each r . [0, 1], we see that XG itself has a cake distribution. 
Speci.cally, when r is not in p a candle, i.e. r . [r,rp + E] for p . P , we have xi(r)= mi for all edges 
i, by de.nition of a cake tt distribution. Therefore, XG(r) = Maxp.Pi.p mi  p for r . [r,rp + E] and 
p . P . Hence the height of the tt overall cake is mG = Maxp.Pi.p mi . v pv(i,p) For r . [r,rp + E], 
we have xi(r)= h(i,p) = E for every edge i in p, and xi(r) = 0 for every edge i . p. This gives the height 
of the candle at rp for XG tt as h(G,p) = XG(rp) = Maxq.Pi.q h(i,p) . By our construction, the cake distribution 
for xi (corresponding q to edge i) has a candle of zero height at location rif edge i is not in the path 
q. Also, all h(i,p) s are non­negative for i . p. It follows that h(G,p) = i.p) h(i,p). Translating between 
heights h(G,p) and parameters tt vv v(G,p) v(i,p) v(G,p) gives = or equivalently, Ei.pE tt2 v v(G,p) 
= i.p v(i,p) . It follows from Lemma 2.2 and Lemma 2.3 that tt Exp[XG]= mG = Maxp.Pi.p mi and Var[XG]= 
tt2 v p.P v(G,p) = p.Pi.p v(i,p) . 3 A tight upper bound of Var[XG] We now consider an arbitrary DAG 
G with a single source and single sink node, and present an algorithm, motivated by balance of forces 
in a system of strange springs , to compute a tight upper bound of Var[XG]. We also show that cake distributions 
of edge delays allow us to achieve this bound in an arbitrary DAG. Let µi be a real number in (0, 1] 
associated with edge i in G such that for every st-path p . P , i.p µi = 1. That such an assignment of 
µi s exists can be shown by arranging the nodes in G along a straight line of length 1. Let .a denote 
the location of node a along this line. We .x the source node s at location .s =0 and the sink node t 
at location .t = 1. All other nodes are placed between these two end points in a linear/topological ordering 
of the DAG. In other words, for every edge i = (a, b), we ensure that 0 = .a < .b = 1. If we now choose 
µi = .b - .a for every edge i = (a, b), we obtain the desired assignment of µi s. The above argument 
also shows that there are multiple (in fact, in.nite) ways of assigning µi s such that 0 <µi = 1 and 
i.p µi = 1 for every st-path p . P . In the following, we will use µzi to denote a vector of assignments 
of µi to edges i in G such that the above constraints are satis.ed. Similarly, we will use xzi to denote 
a vector of probability distributions of random variables xi corresponding to edges i in G, such that 
Var[xi]= vi and Exp[xi]= mi. The following result, though simple, will prove particularly useful in several 
subsequent proofs. Let yzi and z i be vectors of non-negative real values such that yi 0 = zi = 1 and 
i zi = 1. Let S = izi . v 2 Lemma 3.1. MiniS =yi. zi i t Proof. Let zzbe a vector of assignments that 
minimizes i S subject to the constraints 0 = zi = 1 and i zi = 1. dS t Then, the derivative must be zero 
at zi = z, where dzi i dzi is a change that respects the constraints on zi s. t Since = 1, there must 
be at least one i such that i zi zt> 0. Let Et = Min [{zt| zt > 0}], and let j be such i ii t that z= 
Et. We now choose E such that 0 <E<Et and j t a k distinct from j, and increase zby E and decrease k 
t zby E. This ensures that = 1 and 0 = zi = 1 ji zi dS yk yj for all i. We can now compute as - i+ i)2 
. dzi (zk)2 (zj yk yj Setting this to zero gives i= i In other words, (z)2 (z)2 . kj v ziv zi tj tj z= 
yk · v . Since 1 = k z= yk · v , kyj kk yj vv tyj tyi we get zj = v yk]. Hence zi = v yk], for all i. 
[ k [ k v yi [ k yk] Plugging this in gives S = i = i yi · v = izyivv i yi·yk, as required. ik The primary 
result of this section can now be stated as follows. vi Theorem 3.1. Max iVar[XG] = Min i, where xi µi 
iµi the values µzi are constrained so that every µi lies in (0, 1] and for every st-path p . P , i.p 
µi =1. * Furthermore, there is an algorithm that computes µz i vi vi such that * = Minµii . iµ iµi i 
To prove Theorem 3.1, we will .rst present an algorithm based on balance of forces in a system of strange 
* springs that allows us to compute µzi . We will then show that MaxiVar[XG] is bounded above and below 
xi vi by iµ * . i * Computing µzby a spring algorithm: For purposes i of this discussion, we view nodes 
in the DAG as balls of unit mass, and edges in the DAG as strange springs connecting the balls. The balls 
corresponding to the source node s and sink node t are .xed at a distance 1 apart, and are not allowed 
to move. Balls corresponding to all other nodes are free to move. These are initially arranged in a straight 
line between s and t in a linear ordering of the DAG, as discussed above. Using the notation introduced 
earlier, let .a be the location of the ball corresponding to node a, where .s = 0 and .t = 1. The spring 
corresponding to edge i = (a, b) exerts an outward repelling force on the balls corresponding to nodes 
a and b. The strange part about these springs is that the force Fi pushing a and b apart is given vi 
by Fi = where vi, the variance of xi, is the (µi)2 , analogue of the spring constant, and µi = .b - .a 
is the separation between the two ends of the spring. The inverse square law dependence of forces on 
separation is reminiscent of electrical force laws between charged particles or gravitational force laws 
between bodies with gravitational mass. However, we choose to use the analogy with springs since not 
every ball directly exerts force on every other ball in our setting, unlike charged particles or bodies 
with gravitational mass. Once we let go of all the balls except those corresponding to s and t in our 
setting, the spring forces set the balls in motion along the straight line joining s and t. If we dampen 
the movements, the potential plus kinetic energy of the system must decay until all balls come to rest 
in a state in which the potential energy of the system is minimized. The force on every ball, except 
those corresponding to s and t, must be balanced in  * this state. For each edge i = (a, b), the value 
of µ i can then be read o. as the distance .* b - .* when the a system comes to rest. We will call the 
above technique for obtaining µz* the spring algorithm . In practice, i non-linear constraint solving 
techniques must be used to solve the set of constraints corresponding to zero net force on each ball 
other than s and t, while ensuring .a <.b for each edge (a, b) in G. Lemma 3.2. Let µz* be the values 
obtained from the i spring algorithm when the spring system comes to rest. vi vi Then * = Min µii . iµ 
iµi i Proof. The .rst step is to prove that there is a one-to­one mapping between the domain of values 
µzi allowed by Theorem 3.1 and those allowed by the spring algorithm. In one direction, note that the 
values µzi produced by the algorithm have the property that for every st-path p . P , i.p µi = 1. This 
is because the µi s are lengths of edges along a path spanning from .s =0 to .t = 1. Also no µi produced 
by the algorithm can be negative. This is because initially .b >.a for every edge i = (a, b). For .b 
to subsequently become less than .a, the spring system must go through a state where .a is arbitrarily 
close to .b, and hence µi is arbitrarily close to 0. However, given the force laws of our springs, the 
force of the spring corresponding to edge (a, b) must then increase without bounds, pushing a and b apart. 
Conversely, if the values µzi have the property that for every p . P , i.p µi = 1, then the positions 
.a of nodes de.ned by .a = µi is i. any path from s to a well-de.ned. To see this, consider any two paths 
p and p' from s to a. We claim that µi = l µi. i.pi.pTo see why this is so, let p'' be some path from 
a to ' t. Note that both (p, p'') and (p,p'') are paths from s to t and hence are in the set of paths 
P . Hence, ttt tttt t µi + ll µi =1= l µi + ll µi . i.pi.pi.pi.pThis implies µi = i.pl µi. i.p The remaining 
step is to prove that the µz* returned i by the spring algorithm ensures that the value V = vi z* is 
minimized. The derivative of V at µ is iµi i obtained by considering an in.nitesimal legal change in 
z* z* µi . A legal change in µ is achieved by moving the ball i corresponding to some node a from its 
current position .a to .a + E in the direction of the ball corresponding * to the sink node t. This increases 
µ for each edge i i . In(a), where In(a) denotes the set of edges (b, a) * entering a. Similarly, the 
legal change decreases µil for each edge i' . Out(a), where Out(a) is the set of edges (a, b') leaving 
a. From the force equation * vi for our springs, increasing µ by E decreases * by iµ i vi vi *)2 .E. 
Note that * is also equal to the force Fi (µ (µ )2 ii exerted by the spring corresponding to edge i when 
* the separation is µi . Hence, the overall derivative is dV = - Fi + Fil . Since the net force Ei.In(a) 
il.Out(a) on every ball other than those corresponding to nodes s and t is 0 when the system of springs 
comes to rest, we must have Fi (total force pushing a towards i.In(a) t)= Fil (total force pushing a 
towards s). il.Out(a) dV * z Therefore, = 0 at µi . Since the legal change in E µz* moves the ball corresponding 
to a towards the ball i corresponding to t, by the inverse square law of forces for our springs, Fil 
increases and Fi il.Out(a) i.In(a) z* reduces due to the legal change in µi . Therefore, dV = - Fi + 
Fil increases with E, Ei.In(a) il.Out(a) giving rise to a positive second derivative of V at µzi * . 
dV Since we have already shown above that = 0 at µz* i , E vi z* it follows that V = iµi is minimized 
at µi . For a more physical interpretation of the same vi proof, notice that iµi is the potential energy 
of the system. Since energy is force times distance, the potential energy of a spring is obtained by 
integrating the force Fi needed to push one end of the spring from x µi in.nity to its current location, 
namely µi=8 Fidµi = x µi vi vi (µi)2 dµi = . Therefore, the total potential µi=8 µi vi energy of the 
system is iµi . As stated, the algorithm .nds a state of minimum potential energy. Lemma 3.3. There exists 
an algorithm whose input is a DAG G, and variance vi and mean mi of each edge i in G, and whose output 
is a cake distribution (mi, {v(i,p) | p . P }) for each xi such that Var[XG]= vi q.P v(G,q) = * , and 
for every edge i in G, iµ i Var[xi]= p.P v(i,p) = vi and Exp[Xi]= mi. Proof. Recall the spring algorithm 
and consider the * spring system in its .nal state of rest. Let µ = .* - .* i ba be the length of the 
spring for edge i = (a, b) and vi Fi = * be the force in this spring. Note that (µ )2 i * .p . P, µ = 
1 and that for each node a . i.pi  G \{s, t}, Fi = Fil . Lemma 3.4 i. In(a) il. Out(a)then produces 
the contribution v( G,p) of each path p . P to the variance of XG such that Fi = p3 i v( G,p) . Finally, 
the contribution v( i,p) of each candle to the v(G,p)· vi variance of xi is given by v( i,p) = if i . 
p, and Fi 0 otherwise. Lemma 2.2 gives Exp[xi]= mi, and Var[xi]= p. P v( i,p) = p3 i v( i,p) . This translation 
from paths p . P to paths p 3 i going through edge i is possible because v( i,q) is zero unless the path 
p includes edge i. Plugging in the value for v( i,p) gives Var[xi]= v(G,p)· vi vi = · p3 i v( G,p) . 
The requirement given p3 iFi Fi vi by Lemma 3.4 simpli.es this to Var[xi]= Fi · Fi = vi, as required. 
Lemma 2.2 also gives the variance of XG to be Var[XG]= p. P v( G,p) . For each path p, * we have that 
µ = 1. Hence, Var[XG]= i. pi tt tt ** p. Pi. p µi v( G,p) = i µip3 i v( G,p) . The requirement given 
by Lemma 3.4 simpli.es this to tt ** vi vi Var[XG]= i µ [Fi]= i µ * = * , as re­ ii (µ )2 iµ ii quired. 
Lemma 3.4. There exists an algorithm whose input is Fi such that for each node a . G \{s, t}, Fi = i. 
In(a) Fil , and whose output is the contribution il. Out(a) v( G,p) of each path p . P to the variance 
of XG such that Fi = p3 i v( G,p) . Proof. For each node a . G \{s, t}, let ha = (a, b) be the .rst edge 
out of a in some ordering of its edges. Let H = {ha | a . G \{s, t}} be the set of these .rst edges and 
let H = G \ H be all the remaining edges in G. We now do a depth (or breadth) .rst search of the DAG 
from the source s, building the search tree. The only requirement we impose during this search is that 
the .rst edge traversed from every node a must be ha. For each edge i = (a, b). H, let pi . P be the 
path that follows the search tree edges from the source s to node a, then follows the edge i = (a, b), 
and keeps following the .rst edges hafrom node b onward until l the sink t is reached. Note this path 
must eventually .nd t because G is a DAG with t being the only sink. De.ne M to be the |H|×|H| matrix 
such that for all i, j . H, M( i,j) = 1 i. edge i is in path pj. We claim that M is invertible. This 
is because if we assume that the rows and columns are sorted based on the order in which the search .nds 
the edges in H, then the diagonal is all ones (edge i is in path pi) and the lower triangle is all zeros. 
To see why the lower triangle is all zeros, note that path pj has the property that it does not contain 
those edges from H that were found in the search later than j, i.e. for which i>j For each i, j . H, 
we compute the required value v( G,pj ) from the known values Fi using the matrix operation (v( G,p1) 
,v( G,p2) ,...,v<G,p>)T = |H| M- 1(F1,F2,...,F| H| )T . For all the remaining paths, we set v( G,p) = 
0. Note that this algorithm is polynomial-time because the number of paths/candles that have non-zero 
height is |Edges(G)-Nodes(G)+2|. What remains is to prove that for every edge i, the required statement 
Fi = p3 i v( G,p) is true. Let us start with edges i . H. The matrix operation (Fi)T = M(v( G,pj) )T 
ensured that Fi = ( p3 i, p. p) v( G,p) , H where we only consider paths p . pthat are associated H with 
an edge j . H. However, ( p3 ip . p) v( G,p) = 0, H because v( G,p) = 0 for all the other paths. Hence, 
the desired result follows. This leaves proving that for every edge i . H, the required statement Fi 
= p3 i v( G,p) is true. We prove this by induction on the distance of the edge from the source s. Recall 
H = {ha | a . G \{s, t}} is the set of .rst edges ha out of node a. As a base case of our induction, 
all edges out of s are in H, and therefore Fi = p3 i v( G,p) for all such edges i. Now, consider edge 
ha . H for some node a . G\{s, t}. By way of the inductive hypothesis, the statement has been proved 
for all edges coming into node a. All edges leaving a, except for the edge ha, are in H and hence the 
statement is true for them as well. We will now prove Fha = v( G,p) . p3 ha To do this, we use the fact 
that the spring system settled into a state of rest. Hence for each node a . G \{s, t}, Fi = Fil . This 
gives i. In(a) il. Out(a) ... . Fha = .Fi. - .Fil . i. In(a) il. Out(a)- ha ... . ... = v( G,p) . - 
v( G,p) i. In(a)p3 iil. Out(a)- hap3 il .. .. =v( G,p)- v( G,p) p3 a ( p3 a, p) 3 ha =v( G,p) p3 hi 
 This completes the proof. vi vi Lemma 3.5. Max iVar[XG] = Min i= * xi µi iµi iµ i The proof of Lemma 
3.5 follows from Lemma 3.3. To complete the proof of Theorem 3.1, we need to show the following. vi vi 
Lemma 3.6. Max iVar[XG] = Min i= * . xi µi i iµ µii  Proof. Let µzi be an arbitrary real-valued vector 
such that for every edge i in G,0 <µi = 1 and i.p µi =1 for all st-paths p . P . Our proof proceeds by 
showing vi that Var[XG] = iµi for every xzi such that Var[xi]= vi. This is obtained as a special case 
of a more general Var[xi] result which states that if Z[xzi] = Var[XG] - iµi , then Z[xzi] = 0 for all 
xzi. z Towards this goal, let xbe a vector of edge i delay distributions that maximizes Z[xzi], and 
gives the smallest Var[XG] among all vectors xzi that maximize Z[xzi]. We consider two cases below. Suppose 
Var[XG]=0 for xSince Var[x] is the zi . i Var[x ] i expectation of a square, iµi = 0. Hence, Var[x ] 
i z Z[xz] = Var[XG] - iµi = 0. Since x ii maximizes Z[xzi], it follows that Z[xzi] = 0 for all xzi. z 
Suppose Var[XG] > 0 for xi . In this case, Lemma 3.7 tells us that there exists a way of chang­ing xz 
such that either Var[XG] decreases or Z[xzi] i increases (or both). In case Z[xzi] increases, we end 
up contradicting the fact that xz maximizes i Z[xzi]. In case Z[xzi] stays the same and Var[XG] decreases, 
we get more than one vector xzi that maximize Z[xzi]. However, since Var[XG] decreases, z this contradicts 
the fact that xgives the smallest i Var[XG] among all vectors xzi that maximize Z[xzi]. Therefore, Var[XG] 
cannot be strictly positive for xzi . z It follows that Var[XG]=0 for x, and hence Z[xzi] = i Z[xz] 
= 0. The theorem follows from this result. i Lemma 3.7. If Var[XG] > 0 for a given xzi, there is a way 
of changing xzi so that either Var[XG] decreases or Z[xzi] increases or both. In order to prove Lemma 
3.7, we will .rst prove Lemma 3.8, which is almost the reverse of what we want. Nevertheless, it turns 
out that Lemma 3.8 is easier to prove since it has fewer negatives in it, and helps in proving Lemma 
3.7. Lemma 3.8. If Var[XG] > 0 for a given xzi, there is a way of changing xzi so that Var[XG] increases 
and Z[xzi] either stays the same or decreases. Proof. Our goal is to increase Var[XG]. There are two 
ways of increasing the variance of the random variable XG. We could either increase XG(r) at those points 
r . [0, 1] where XG(r) > Exp[XG], or we could decrease XG(r) at points r . [0, 1] where XG(r) < Exp[XG]. 
We will do the former. For this purpose, let DG(r)= XG(r) - Exp[XG] and let r . [0, 1] be a point at 
which .G(r ) > 0. Since Var[XG] > 0, such a point must exist. Lemma 2.1 considered the e.ect of increasing 
the edge delay xi for one edge. We will now consider the e.ect of changing a whole path of edge delays. 
Let pr tt be a winning path in XG(r ) = Maxp.Pi.p xi(r ). For each edge i . pr, we increase xi(r ) by 
µidx, where µzi is the .xed vector of values chosen in the proof of Lemma 3.6. We will now consider what 
e.ect this has Var[xi] on iµi , Var[XG], and Z[xzi]. Var[xi] i µi : By Lemma 2.1, increasing xi(r ) by 
µi.dx increases the variance Var[xi] by 2.µi..i(r ).drdx. Hence, doing this for each edge in the path 
prin­ Var[xi]2.µi..i(rr).drdx creases the sum by = iµi i.rpµi i.rp 2..i(r ).drdx. Var[XG]: By de.nition, 
pris a winning path in XG(r )= tt Maxp.Pi.p xi(r ) . Increasing xi(r ) by µi.dx for every i . princreases 
i.rp xi(r ), and hence XG(r ), by i.rp µi.dx = dx. The reason for the last simpli.cation is that µzi 
was chosen such that .p . P , i.p µi = 1. By Lemma 2.1, increasing XG(r ) by dx increases the variance 
Var[XG] by 2..G(r ).drdx. By our choice of r , we have .G(r ) > 0. Hence, Var[XG] increases, as required. 
Var[xi] Z[xzi]: By de.nition, Z[xzi] = Var[XG] - iµi . Hence, Z[xzi] changes by [2..G(r ).drdx] - t t 
i.rp 2..i(r ).drdx =2.(M - N).drdx, where M = XG(r ) - i.rp xi(r ), and N = Exp[XG] - i.rp Exp[xi]. We 
now examine the two sub-expressions M and N obtained above. M = XG(r ) - i.rp xi(r ): Because pris a 
winning tt path in XG(r ) = Maxp.Pi.p xi(r ) , there­ fore XG(r )= i.rp xi(r ). Hence, M = XG(r ) - i.rp 
xi(r ) = 0. N = Exp[XG] - i.rp Exp[xi]: As we will see in Lemma 5.1, Exp[XG] = i.p Exp[xi] for all st-paths 
p in P . It follows that N = Exp[XG] - i.rp Exp[xi] = 0. Therefore, the change in Z[xzi], i.e., 2.(M 
- N), is non-positive. Hence, Z[xzi] either stays the same or decreases, as required. We can now turn 
Lemma 3.8 around to get the result we really want, i.e. Lemma 3.7.  Proof of Lemma 3.7: Similar to the 
proof of Lemma 3.8, we choose a point r . [0, 1] such that .G(r )= XG(r ) - Exp[XG] t> 0. Let tprbe a 
winning path in XG(r ) = Maxp.Pi.p xi(r ) . Instead of increasing xi(r ) by µidx for each edge i . pr(as 
in the proof of Lemma 3.8), we now decrease each xi(r ) by these amounts. There are two cases to consider. 
In the .rst case, suppose XG(r ) does in fact de­crease. Since XG(r ) was greater than Exp[XG] (since 
.G(r ) > 0), this decreases Var[XG], and we are done. In the second case, suppose XG(r ) does not decrease 
even though we decreased xi(r ) by µidx for each edge i . pr. The proof of Lemma 3.8 then tells us that 
Z[xzi] increases by i.rp 2..i(r ).drdx. If we can now show that > 0, we will be done. We show this i.rp 
.i(r ) by proving below that there exists a point r . [0, 1] for which .G(r ) > 0 and i.rp .i(r ) > 0. 
Let R = {r . [0, 1] | XG(r) > Exp[XG]}. Since Var[XG] > 0 by assumption, R must be non-empty. Hence the 
cumulative width of all r s in R, i.e. |R|, must x 1 be > 0. Let A = · XG(r)dr denote the average of 
|R| r.R XG(r) within R. Clearly by the de.nition of R, we have A> Exp[XG]. With abuse of notation, let 
pr(r) denote tt a winning path in XG(r) = Maxp.Pi.p xi(r) , for every r . [0, 1]. If there is some r 
. R for which .i(r) > 0, then we can simply choose r to i.rp(r) be this r, and we are done. Otherwise, 
we must have .r . R, xi(r) = Exp[xi]. However, we i.rp(r) i.pr(r) show below that this leads to a contradiction. 
Assume that .r . R, xi(r) = i.rp(r) Exp[xi], if possible. Let us reconsider i.rp(r) x 1 the average A 
= · XG(r)dr. By the |R| r.R de.nition tof XG andt pr(r), this is equal to x 1 · xi(r) dr. By our assumption, 
|R| r.Ri.rp(r) tt x 1 this is at most · Exp[xi] dr. |R| r.Ri.pr(r) The last expression, in turn, is at 
most tt x 1 · Maxp.P Exp[xi] dr. Since the in­ |R| r.Ri.p tegrand no longer dependst on r, it cant be 
factored x 1 out to give · Maxp.Pi.p Exp[xi] · 1.dr. |R| r.R tt This simpli.es to Maxp.Pi.p Exp[xi] . 
Finally, Lemma 5.1 gives that this is at most Exp[XG]. Putting all the parts together, we .nd that x 
1 A = · XG(r).dr = Exp[XG]. However, |R| r.R we have already shown that A> Exp[XG]. Hence we have a contradiction! 
Well known measures of a DAG G are its height h and width w. The height h of G is de.ned to be the number 
of edges in the longest path from the source s to the sink t. The width w of G is the minimum number 
of st-paths needed to cover each edge of the graph at least once. The following lemma uses the height 
and width of a DAG to bound the maximum variance of XG. Lemma 3.9. If G has height h and width w, then 
1 v vi 2 = Max iVar[XG] = h i vi. wi xi vi Proof. By Theorem 3.1, Max iVar[XG] = Min i xi µi iµi vi = 
iµ * . Recall from the spring algorithm that for i * every edge i = (a, b) in G, µ = .* - .* , where 
.* and ibaa .* are the locations of the balls corresponding to nodes b a and b respectively, when the 
system of springs is at rest. If, instead, we put the balls at other locations and vi use the corresponding 
µi s, then the sum iµi can only increase. Let us now de.ne the location . ' of node a to be a the maximum 
number of edges in a path from s to a divided by h. The number of edges in a path from s to s is clearly 
zero giving . ' = 0, as required. By de.nition s of the height h of G, the maximum number of edges in 
a path from s to t is h. Hence, . ' = 1, as required. t For each edge i = (a, b) in G, the maximum number 
of edges in a path from s to b is at least one more than ' that in a path from s to a. Hence, µ = . ' 
- . ' = 1 . It i bah vi vi follows that Maxxii Var[XG] = Minµii = l = iµi iµ i h. i vi. This proves one 
part of the lemma. r For the other part, let P be a set of st-paths that cover each edge of G at least 
once, and let |Pr| = w. Because each edge is covered at least once, we have i µi = µi. By de.nition, 
for every path, p.Pri.p i.p µi = 1. Hence, i µi = w. By Lemma 3.1, we know that subject to the con­ vi 
v 2 straint = 1, Min i= vi . Scaling i µiµi iµi i all µi s by a factor of w gives that subject to i µi 
= w, vi 1 Minµii = v vi 2 . Reducing the µi s can iµi wi vi only increase . Hence, subject to i µi = 
w, we µi v 2 must have Min ivi = 1 vi . µi iµi wi 4 A tight upper bound of Exp[XG] We now consider the 
problem of obtaining a tight upper bound of Exp[XG] for an arbitrary DAG G with a single source node 
s and an single sink node t. For every st­path p . P , let tp be a positive real number in [0, 1] such 
that p.P tp = 1. For each edge i in G, we de.ne ti = p3i tp. Clearly, 0 = ti = 1 for all edges i. Similar 
to notation used earlier, we will use tzp and tzi to denote a vector of assignments of tp to paths p 
. P and a vector of assignments of ti to edges i in G, respectively, such that the above constraints 
are satis.ed.  Theorem 4.1. t For every DAG G, MaxtiExp[XG]= xi Maxtii Min timi +ti(1 - ti)vi,mi , where 
the i values tzi are constrained so that there exists a value tp for each path p . P such that .i, p3i 
tp = ti, 0 = tp = 1, and p.P tp =1. Proof. Our proof has two parts. In the .rst part, given an expectation 
mi and a variance vi for each edge i . G, we construct a vector of distributions xzi such that tt Exp[XG] 
= Maxtii Min timi +ti(1 - ti)vi,mi . i In the second part, we show that Max iExp[XG] = tt xi Maxtii i 
Min timi +ti(1 - ti)vi,mi . tt By de.nition, XG(r) = Maxp.Pi.p xi(r) . For each path p . P , let Rp be 
the set of r values for which p is the longest path de.ning XG, and let tp = |Rp| be the width of this 
set. For each edge i . G, let Ri = .p3iRp be the set of r s for which xi contributes to the longest path, 
and let ti = |Ri| = tp be the width of this p3i set. Clearly ti is the probability that xi is in the 
winning path and is able to contribute to Exp[XG]. We will x use Mi = r.Ri xi(r) dr to denote the amount 
that xi contributes to Exp[XG]. Part I: Given an mi and vi for each edge i . tz* G, let be the values 
that realize the maximum i tt z* Maxtii i Min timi +ti(1 - ti)vi,mi . Let tp be the corresponding values 
for all st-paths in P , such that * .i, t = t* and t* = 1. We partition the ip3ip pp probability space 
r . [0, 1] into |P | disjoint regions Rp such that for each path p . P , |Rp| = t*. This partition p 
is possible because t* = 1. For each edge i, we also pp de.ne Ri = .p3iRp, such that |Ri| = t* = ti * 
. p3ip For every distribution xzi, we then have: Exp[XG] = XG(r) dr r.[0,1] . . = Maxpl.P . xi(r). 
dr r.[0,1] i.pl . . = Maxpl.P . xi(r). dr p.P r.Rp . i.pl . = . xi(r). dr p.P r.Rp i.p = xi(r) dr 
i p3i r.Rp = xi(r) dr = Mi i r.Ri i ' Note that the inequality arises because the path p that wins when 
r . Rp may be di.erent from p in general. We now construct a distribution xzi * such that Mi t for this 
distributiont i * ** equals Min ti mi +t (1 - t )vi,mi i ii tt = Maxtii Min timi +ti(1 - ti)vi,mi i 
We consider two constructions. In the .rst construction, let Mi = ti * mi +t*(1 - t*)vi. The ii distribution 
of xi is then given by xi(r)= Mi if |Ri|mi-Mi r . Ri, and otherwise. It can be veri.ed that |Ri|Exp[xi]= 
mi and Var[xi]= mi. In the second construc­ 2 2 ' mi tion, we de.ne Mi = mi, ui = vi + m, and t =. ii 
ui The key requirement for using the second construction ' is that t* = ti . If this requirement is satis.ed, 
we i ' de.ne R ' to be some subset of Ri of size |R ' | = ti . iiThe distribution of xi is then given 
by xi(r)= Mi if |Rl | i r . R ', and zero otherwise. Again, it can be checked i ' that Exp[xi]= mi and 
Var[xi]= mi. Thus, if t* <t i , i we use the .rst construction, and use the second con­struction otherwise. 
Furthermore, it can be shown that ' if 0 = ti <t , then 0 = timi +ti(1 - ti)vi <mi. For i ' t = ti 
= 1, we have timi +ti(1 - ti)vi = mi. i Therefore, the above distribution ensures tt * ** that Mi = 
Min ti mi +t (1 - t )vi,mi . ii Hence, t Max iExp[XG] t = xi MaxiMin timi +ti(1 - ti)vi,mi . ti i z# 
Part II: Let xi be the vector of distributions that t ## # maximizes Exp[XG]. Let p , tand Mbe the ii 
z# tp, ti and Mi that arise from x . Using the same i computation of Exp[XG] as done in part I above, 
we # .nd that Exp[XG]# = Max iExp[XG]= M. Note xi ii that we have an equality instead of the inequality 
in ' part I because the path winning path p is the same as p by de.nition of Rp. We will now show that 
for every distribution xi, if Exp[xi]= mi and Var[xi]= vi, then Mi = ttx r.Ri xi(r) dr = Min timi +ti(1 
- ti)vi,mi . Since xi(r) = 0, Mi is clearly at most Exp[xi]= mi = x xi(r) dr. Similarly, r U[xi]=xi(r)2 
dr r.[0,1]  =xi(r)2 dr+xi(r)2 drr.Ri r.Ri 2 2 Mi mi - Mi =|Ri|·+ |Ri|· |Ri||Ri| M2 (mi - Mi)2 =i +ti1 
- ti  The inequality above comes from the fact that if we Lemma 4.2. 1 2 [Maxtii A(tzi)] + [Maxtii B(tzi)] 
= know that Mi of xi s mass lies within Ri and the remaining mi - Mi lies outside of this region, then 
the second moment of xi is minimized by having xi(r) constant within each of these two regions. From 
this, we get that Maxtii [A(tzi)+ B(tzi)] = [Maxtii A(tzi)] + [Maxtii B(tzi)]. Proof. It is clear that 
Maxtii [A(tzi)+ B(tzi)] = ' [Maxtii A(tzi)] + [Maxtii B(tzi)]. Let tzi be the val­ '' ues that optimize 
A(tzi ' ) and tzi be those that optimize ' '' B(tzi '' ). Let tzi be such that ti [t + t ]. Note that 
1 2 = i i all requirements on tzi are met because it is a linear 2 Var[xi] = U[xi] - m i ' '' combination 
of tzi and tzi . M 2 i + (mi - Mi)2 - m 2 i = 1 - ti ti 11 '' )1 ' 1 '' A(tzi ' )+ B(tzi = ti mi + ti 
vi 222 2 ii Since we must have Var[xi]= vi, it can be shown # i that Mi = timi + ti(1 - ti)vi. Speci.cally, 
M = v = timi + tivi Min t # i mi + t # i (1 - t # i )vi,mi . ii It follows that Max iExp[XG] = Exp[XG]# 
xi = M# = Min t # mi +t#(1 - t #)vi,mi . ii iii Therefore, t Max iExp[XG]t = xi MaxiMin timi + ti(1 
- ti)vi,mi . Parts I ti i and II together prove Theorem 4.1. We now wish to obtain simpler bounds of 
Max iExp[XG], and also provide an algorithm to ap­ xi proximate the expression for Max iExp[XG] given 
by xi Theorem 4.1. Theorem 4.2. For every DAG t G, t Max iExp[XG] = Maxitimi + ti(1 - ti)vi xi ti i 
tt vi = Maxp.P mi +Min i. i.pµi iµi Furthermore, the optimal ti s can be derived from the above formulation. 
We will .rst prove a few simple results that will even­tually lead to a proof of Theorem 4.2. We begin 
with the following observation. v Lemma 4.1. Let Ut(ti) = Min timi + ttivi,mi and V (ti) = Min timi + 
ti(1 - ti)vi,mi . Then for every ti =[A(tzi)+ B(tzi)] = Maxtii [A(tzi)+ B(tzi)] This completes the proof. 
Lemma 4.3. Maxit [ timi] = Maxp mi. ii.p Proof. .. Maxitimi = Maxi. tp . mi ti ti i ip3i = Maxtp mi 
( tp=1)p pi.p Since 0 = tp = 1 for all p . P and p.P tp = 1, the maximum value of tp mi occurs when pi.p 
tp = 1 for the path p with the maximum value of ' l i.p mi and tp= 0 for all other paths p . Therefore, 
Maxit [ i timi] = Maxpi.p mi. v vi Lemma 4.4. Maxi=Min i. ti tiviµi iµi Proof. In a primal-dual sort 
of way, it is su.cient to consider any .xed setting for zt and any .xed setting for µzi, and prove that 
 1 2 U(ti) = V (ti) = U(ti). Proof. The second inequality is obvious because (1 - ti) = 1. The .rst inequality 
follows from the fact that v vi tivi = µi ii 1 1 ti.(1 - ti) = Given these .xed zt and µzi, let us 
de.ne ai = ti ·µi. The = .ti. 4 4 following is a useful property of the ai s. The next natural step 
would be to understand which .. v of timi + tivi and mi is lesser for each ti. How­ ever, we will leave 
this until later, and presently focus ai = ti · µi = . tp . · µi ii ip3i on bounding Maxitimi + v tivi 
. Let A(tzi)= ti i v .. timi and B(tzi)= tivi. Instead of obtaining ii Maxtii [A(tzi)+ B(tzi)] directly, 
we will maximize A and = tp . µi. = tp · 1=1 B independently. pi.pp The second last equality is because 
of the restriction on µzi that i.p µi = 1 and the last equality is because of the restriction on zt that 
p ti = 1. We can now vi tivi get the bound we want. Speci.cally, = . iµi iai However, by Lemma 3.1, 
itivi = i v tivi 2 since ai tivi > 0 and i ai = 1. We are now ready to complete the proof of Theorem 
4.2. Proof of Theorem 4.2: Theorem 4.1 and Lem­mas 4.1, 4.2, 4.3, and 4.4 give Max iExp[XG] = xi t ttt 
Maxitimi + ti(1 - ti)vi = Maxp.P mi ti ii.p vi + Min i. It is interesting that the second term µi iµi 
in the above upper bound is Max iVar[XG]. xi Furthermore, Theorem 3.1 gives a spring algorithm to determine 
the optimal µz* in the proof of Lemma 4.4. i We will now use these to .nd the optimal tz* in i Lemma 
4.4, and hence in Theorem 4.2. Recall we used Lemma 3.1 in the proof of Lemma 4.4 to show that the tivi 
maximum value of sumiai is i v tivi 2. In fact, the proof of Lemma 3.1 also gives the optimal values 
of ai v as vvtivi , where v V = tivi. However, as shown in iV the proof of Lemma 4.4, the optimal value 
of v i tivi vi = iµi . Recalling that we de.ned ai = ti · µi, we * vi vi get t = * = . i (µ )2.V i * 
(µ )2 .vj * iµ j j Thus, the same spring algorithm described in Sec­tion 3 gives us the optimal µzi and 
also the optimal zt . Hence the same algorithm can be used to com­pute Max iVar[XG] exactly and also 
an upper bound xi of Max iExp[XG]. xi The values tzi are constrained so that there exists a value tp 
for each path p . P such that .i, p3i tp = ti encode that for each variable edge i, p3i tp = ti. The 
primal-dual theorem states that the optimal value for this primal is the same as the optimal value for 
the dual problem. Hence, it is su.cient to prove that the optimal value of the dual is at most one. The 
dual is stated as follows. T Max µzi · tzi Subject to MT · µzi = z1 Note that the requirements on the 
unknown variables µi are that for each path p . P , i.p µi = 1. Indeed, these are the same requirements 
on µi that we have used throughout the paper. Theorem 4.4. There exists a greedy algorithm to determine 
for each variable i, whether Mi = tt Min timi + ti(1 - ti)vi,mi is equal to timi + ti(1 - ti)vi or mi. 
This, in turn, gives a quick algorithm t to approximate Max itExp[XG]= xi MaxiMin timi + ti(1 - ti)vi,mi 
within a fac­ ti i tor of four. Proof. To convey the intuition, a reasonable start­ing point t would 
be to .ndt tzzi that maximizes Maxtii timi + ti(1 - ti)vi . However, the prob­ i lem with this tsolution 
is that fort some edges i, we will have timi + ti(1 - ti)vi = mi, and tt hence Min timi + ti(1 - ti)vi,mi 
will decrease these terms. Recalling the proof of Theorem 4.1, this oc­curs when the corresponding edge 
delay variables xi are allocated too much of the limited resource ti: specif­ 2 2 mm ii ically, ti = 
. Decreasing these ti s to may al­and tp = 1. ui ui p.P low other edge delay variables xj to have their 
tj s Theorem 4.3. Given tzi (computed from Theorem 4.2), there is a linear program to .nd the corresponding 
tzp. The dual of this linear program involves .nding the optimal µzi such that i.p µi =1 for all p . 
P . Proof. Let tzi be the vector of ti values given to us. Let tzp be the vector of tp values that we 
are looking for. Let M be a matrix such that for each path p and edge i, we M[i, p]=1 if and only if 
i . p. Finally let z1 be the vector of consisting of |P | ones. The required linear program is as follows. 
increased. This in turn may allow the overall expres­ tt sion expression sumiMin timi + ti(1 - ti)vi,mi 
to increase once again. Before discussing the .nal algorithm, we present an idealized version of it. 
The intuition behind the working of this idealized algorithm is that we start by computing an optimal 
distribution of ti s where p.P tp is bounded not by 1, but by some in.nitesimal E. This forces all ti 
s to be in.nitesimal as well, and thereby ensures that each ti is less than the threshold 2 m i of . 
Next, we slowly increase the bound on tp. ui p.P Each variable s allocation ti therefore increases in 
turn. Min tzp · z1T Each time ti (corresponding to edge delay variable Subject to M · tzp = tzim xi) 
reaches the limit 2 i that it is allowed use, this ui variable is set aside in a set S and the corresponding 
 2 Note that the objective function is tp, which we p The constraints e.ectively m hope to be at most 
one. ti is .xed to its maximum value of i . The bound ui  on continues to increase in this fashion until 
p.P tp it reaches the overall limit, i.e., tp = 1. More pformally, given values tzi for every edge i, 
let tzp be the values for which tp is minimized subject to pthe constraint .i, p3i tp = ti. This can 
easily be found by a linear program. Let Q(tzi)= pinP tp, and tt U(tzi)= timi + ti(1 - ti)vi . The code 
for the i idealized algorithm can then be presented as follows. algorithm FindExp(G, (mi,vi),i .{1 ...n}) 
Inputs: DAG G,(mi,vi) for every edge i z Returns: tzi that maximizes Exp[XG] Let q = E '' the tzi that 
optimize A and B remain the same ex­cept that each ti changes by this multiplicative factor of c. The 
.rst advantage of this fact is that the ef­fect of the step in the idealized code that .nds the tzi subject 
to Q(tzi)= q can just as well be achieved by .nding the tzi subject to Q(tzi) = 1, and then multi­plying 
the resulting tzi by q. The second, even more signi.cant, advantage is that the inner loop that con­tinually 
increases q can be changed in a way that makes old the recalculation of the tzi much easier. Let tzi 
be the current values when the inner loop starts in a given iteration of the outer loop. Note that by 
the loop invari­ tt ant, tziold maximizes timi + ti(1 - ti)vi subject i to two conditions: (i) Q(tzi)= 
qold, and (ii) .i . S, Let tzi maximize U(tzi) subject to Q(tzi)= q. 2 m i ti = . Instead of the inner 
loop increasing q from ui Let S = Ø qold, it can increase the multiplicative factor c contin­ loop new 
uously from 1. The new values, tzi are obtained as loop increasing q continuously Loop Invariants: (i) 
tzi maximizes U(tzi) subject to Q(tzi)= q. (ii) ti s for all xi s in S are .xed. * As q increases, adjust 
tzi to maintain loop invariant. /* .i . S, ti increases continually */ 2 old Mult(c, ztiold), which is 
de.ned as tzi except that for each i . S, ti is increased by a factor of c. Note that new new) q= Q(tzi 
= tp is not simply c · zin p.P tiold general, since the ti s do not change for i . S. The optimal tp 
s therefore need to be recomputed. The key, however, is that the loop invariant will still be main­ new 
tained because the resulting tzi t will give the opti-t mal values for maximizing timi + ti(1 - ti)vi 
i new subject to Q(tzi)= q. The .nal change needed m i * if (.i . S s.t. ti = ) exit loop to make the 
algorithm implementable is that the in­ ui ner loop cannot increase c continuously, but must com­ * if 
(q = 1) return(tzi) 2 m i pute a value c = 1 that either makes ti = for some end loop ui i . S, or makes 
q = 1. The former is easy because if Add i to S 2 2 mm tnew = c · t old ii = , then c = . Hence, all 
that i iui told·ui i end loop m is required is to let c = Mini.S 2 i . told ·ui i end algorithm It is 
interesting that the spring algorithm for .nding the optimal tzi actually needs to be run only once at 
the The correctness of the idealized algorithm is clear. Un­ fortunately, it is not implementable as 
is. The .rst change needed to make it more implementable is to remove the (1 - ti) in the square root. 
Lemma 4.1 proves that this changes the result by at most a fac­tor of two. The next change is to instead 
compute '' Maxtil [ timi] + Maxtill ti vi and then to let ii ii 1 ' '' =[t + t ]. Lemma 4.2 proves that 
this changes the ti 2 ii result by at most another factor of two and Lemmas 4.3 and 4.4 describe how 
to compute these values. A useful ' thing to know is that if each t is changed by a multi­ i plicative 
factor of c then both A = Maxtil [ i timi] and i Q(tzi ' ) change by the same multiplicative factor c. 
On '' the other hand, changing each t in this way changes i '' B = Maxtill ti vi by a multiplicative 
factor of i v i c. In both cases, this proves that if Q(tzi)= q changes ' by the same multiplicative 
factor c, then the tzi and beginning. 5 Lower bounds and continuum results In this section, we present 
lower bounds and continuum results for the mean and variance of XG for an arbitrary DAG G with a single 
source node s and a single sink node t. Unlike the upper bounds presented in the previous two sections, 
our lower bounds are not necessarily tight. Lemma 5.1. For every DAG G and for every vector of distributions 
xzi for the underlying edge delay variables, Exp[XG] = Maxp.Pi.p mi. Proof. Let prbe the path that maximizes 
i.p mi.  Then Exp[XG]= XG(r) dr r.[0,1] .. = Maxp.P . xi(r). dr r.[0,1] i.p .. = . xi(r). dr r.[0,1] 
i.rp = xi(r) dr r.[0,1] i.rp = Exp[xi] i.rp Therefore, Exp[XG] = Maxp.Pi.p mi. Recall the construction 
of cake distributions in Lemma 3.3 for maximizing Var[XG]. That construction ensures that Exp[XG] = Maxp.Pi.p 
mi. Hence, the maximum variance and minimum expectation can be simultaneously achieved for DAGs with 
arbitrary dependence of the distributions of xi s. There exist several cases where Min iVar[XG] = 0, 
xi although each of the xi s has non-zero variance. Note that 0 is the minimum possible value of Var[XG] 
since it is the expectation of a square. For example, consider a series graph with two edges. Suppose 
x1(r)= K if r . [0, 0.5) and 0, elsewhere. Suppose further that x2(r)= K if r . [0.5, 1] and 0, elsewhere. 
Clearly, x1 + x2 = K for all r . [0, 1]. Hence Var[XG] = 0, although the xi s themselves have non-zero 
variance. Lemma 5.2. Given two random variables x and y, sup­pose we form a third random variable z by 
.ipping a coin with probability c . [0, 1]. If the coin .ip comes up as heads, we let z take the value 
of x, otherwise we let z take the value of y. Then Exp[z]= c.Exp[x]+ (1 - c).Exp[y], Var[z] = c.Var[x] 
+ (1 - c).Var[y], and U[z]= c.U[x] + (1 - c).U[y]. Proof. Follows from simple algebra and probability. 
Theorem 5.1. For every DAG G, for all V . [Min iVar[XG], Max iVar[XG]], there exists xzi such that Var[XG]= 
V . The same continuum result holds for Exp[XG] and U[XG] (second moment) as well. xi xi Proof. Let xzi 
be the distribution of variables that min­imizes Var[XG] to Vmin, and let yzi be the distribution that 
maximizes Var[YG] to Vmax. By extending our ear­lier notation, we will use YG to denote the random vari­able 
representing the longest path length from s to t in DAG G when each edge i has the distribution yi. For 
each edge i, we now form a third random variable zi by .ipping a coin with probability c . [0, 1]. If 
the .ip gives heads, then the zi s take the values of xi s; oth­erwise the zi s take the values of yi 
s. Therefore, the random variable ZG behaves like XG with probability c and behaves like YG with probability 
1 - c. Hence, by Lemma 5.2, Exp[ZG]= c.Exp[XG] + (1 - c).Exp[YG] and U[ZG]= c.U[XG] + (1 - c).U[YG]. 
It follows that Var[ZG] = U[ZG] - (Exp[ZG])2 = c.U[XG] + (1 - c).U[YG] - (c.Exp[XG] + (1 - c).Exp[YG])2 
Note that if c = 0 then Var[ZG] = Var[XG]= Vmin, and if c = 1 then Var[ZG] = Var[YG]= Vmax. Hence by 
the mean value theorem, for every V . [Vmin,Vmax], there exists a c . [0, 1] such that Var[ZG]= V . Lemma 
5.3. There exists a vector of distributions xzi such that within a factor of three, Var[XG]= Max iVar[XG], 
Exp[XG] = Max iExp[XG] and xi xi U[XG] = Max iU[XG]. xi Proof. Let wzi be the distribution that maximizes 
the variance to Vmax = Maxwii Var[WG]. Similarly, let xzi be the distribution that maximizes the expectation 
to Mmax = Maxxii Exp[XG], and let yzi be the vari­ables that maximizes the second moment to Umax = MaxiU[YG]. 
As in the proof of Theorem 5.1, let us yi de.ne a random variable zi for each edge i such that zi is 
equal to one of wi, xi or yi based on a .ip of a fair three-way coin. Hence, by Lemma 5.2, Var[ZG] 11 
= [Var[WG] + Var[XG] + Var[YG]] = Var[WG]= 33 11 Vmax. Thus, Vmax = Var[ZG] = Vmax. By a sim­ 33 ilar 
argument, the result for the expectation and second moment of ZG can also be obtained. Lemma 5.4. Within 
a factor of three, Max iU[XG]= xi Max iVar[XG] + (Max iExp[XG])2 . xi xi Proof. A standard equation for 
variance is Var[XG]= U[XG] - Exp[XG]2 . Hence, U[XG] = Var[XG]+ Exp[XG]2 . Clearly, this is at most Max 
iVar[XG]+ xi [Max iExp[XG]]2 . By using a version of Lemma 5.3, xi one can simultaneously obtain Vmax 
within a factor of 2 a and Emax with a factor of 1 - a. This gives Emax within a factor of (1 - a)2 . 
Solving a = (1 - a)2 gives 1 =2.62. The result follows by choosing a to be this a 1 value ( ). 2.62 6 
Series-parallel graphs In the previous few sections, we looked at arbitrary DAGs with a single source 
node and a single sink node. In this section, we consider an special class of DAGs called series-parallel 
graphs. We show that the bounds and algorithms presented in earlier sections can be simpli.ed for this 
class of DAGs.  A DAG G is said to be a series graph if it consists of a single path of edges from the 
source s to the sink t. Therefore, XG = Maxp.Pi.p xi = i xi. A DAG G is said to be a parallel graph if 
it consists only of multiple st-edges. Thus, XG = Maxp.Pi.p xi = Maxixi. The class of series-parallel 
graphs is de.ned induc­tively as follows. As a base case, the graph consisting of a single st-edge is 
a series-parallel graph. Given a set of series-parallel graphs G1,G2,...,Gq, a graph G obtained by linking 
G1,G2,...,Gq sequentially, so that the sink tj of one is the source sj+1 of the next, is a series-parallel 
graph. Similarly, the graph obtained by placing G1,G2,...,Gq in parallel, so that all of them have a 
common source node s and a common sink node t, is a series-parallel graph. Theorem 6.1. If G is a series 
graph, then XG = i xi. For such a graph, Max iExp[XG]= xi Min iExp[XG]= i mi. In addition, Max iVar[XG]= 
xi xi v 2 vi. i Proof. The result about the mean follows from the linearity of expectation. By Theorem 
3.1 Max iVar[XG] xi vi = Min i. However, since i µi = 1 in a series graph, µi µi v 2 vi we know from 
Lemma 3.1 that Min i=. µi µi i vi To understand v vi 2 better, let all the vi be equal. i v 2 v v]22 
Then vi =[n. = n.v = n. i vi. i Theorem 6.2. If G is a parallel graph, then XG = Maxixi. For such a graph, 
Maxxii Var[XG]= i vi. In addition, Min i mi, Maximi + i vi approxi­mates Max iExp[XG] within a factor 
of four. xi Proof. G consists of only the source s, the sink t, and many parallel edges from s to t. 
The constraints on µzi give that µi = 1 and hence Max xii V ar[XG]= vi Minµii iµi = i vi. To reason about 
Max iExp[XG], note that G con­ xi sists of only the source s, the sink t, and many parallel edges from 
s to t. Thus each edge is contained in its own path, giving ti = p3i tp = tp. Hence, the requirement 
that p tp = 1 simpli.es to i ti = 1. This makes it even more clear how ti is a scarce resource that must 
be partitioned between the variables. Given the expectation mi, variance vi, and second moment ui = vi 
+ mi for each variable xi, let us set the availability of resource (ti) such that each variable is exactly 
at the balancing point between the two pos­ tt sible outcomes of Min timi + ti(1 - ti)vi,mi . Re­call 
from the proof of Theorem 4.1 that this balanc­ ' ing point occurs when the variable is allocated t = 
i 22 mm i ' i . Hence, let q = t = . Asinthe ui ii iui proof of Theorem 4.4, let tzi be the assignment 
of ti s tt that maximizes timi + ti(1 - ti)vi subject to i Q(tzi)= q. We claim that this maximization 
hap­ '' pens at ti = t This is because with ti = t , each i . i variable achieves the balance between 
the two possible tt outcomes of Min timi + ti(1 - ti)vi,mi , namely Mi = timi + ti(1 - ti)vi and mi. 
If we allocate a greater value of ti to some variable xi, it would not in­crease Mi; however if we allocate 
a lesser value of ti, it would decrease Mi. Hence, this allocation maximizes tt timi + ti(1 - ti)vi . 
i Now that we understand this balancing point q, let us try either side of it. If q< 1, then in reality, 
more resource is available. This will increase each ti, which in turn will increase the value of timi 
+ ti(1 - ti)vi. tt This means that Min timi + ti(1 - ti)vi,mi will evaluate to mi. Thus, we will have 
Exp[XG]= i mi. On the other hand, if q> 1, then in reality, less resource is available. This will require 
us to decrease each ti, which in turn will decrease the value of timi + ti(1 - ti)vi. However, this will 
will make ti(1 - ti)vi smaller than mi. This gives that timi + tt Exp[XG]= timi + ti(1 - ti)vi . i From 
Theorem 4.1, Lemmas 4.1, 4.2, 4.3, and 4.4 and the above analysis for parallel graphs, it follows that 
Min i mi, Maximi + i vi approxi­mates Max iExp[XG] within a factor of four. xi Theorem 6.3. If G is a 
series-parallel graph, then one can apply the rules for maximum variance in Theo­rems 6.1 and 6.2 to 
recursively to obtain Max iVar[XG]. xi Proof. We will prove this by induction on the depth of recursion 
of the series-parallel graph G. The sequential and parallel bounds, v vi 2 and i vi respectively, i clearly 
equal vi for a single edge. Now let us assume that the theorem holds for d - 1 levels of recursion, and 
con­sider a graph G with d levels of recursion. Suppose that G consists of a number of sub-DAGs G1,G2,...,Gq. 
For each sub-DAG Gj , let vj = Maxxii Var[XGj ]. By the induction hypothesis, these are equal to the 
values obtained by applying the sequential and parallel rules recursively. We now consider two cases 
depending on whether G is formed by combining these sub-DAGs se­quentially or in parallel.  Sequential: 
Suppose G is formed by linking the sub-DAGs G1,G2,...,Gq together sequentially so that the sink tj of 
one is the source sj+1 of the next. vi By Theorem 3.1, Max iVar[XG] = Min i, xi µi i.Gµi where µi = .b 
- .a is the length of the spring for edge i in the steady state of the spring system. For each sub-DAG 
Gj, all its nodes must lie between its source node sj and its sink node tj. Let µj = .tj -.sj be the 
lengths that Gj takes up in the spring system. Because the Gi s are linked sequentially between .s = 
0 and .t = 1, we have that j µj = 1. Theorem 3.1 also gives us that for each sub-DAG vi Gj, vj = Max 
iVar[XGj ] = Min ii.Gj where xi rµi rµi µri = .rb - .ra are the lengths of the springs for edge i in 
the steady state of the spring system. These nodes are spread between .rsj = 0 and .rtj = 1. If, however, 
this system was compressed so that .rtj - .rsj was no longer 1 but equal to the µj de.ned for the whole 
graph G, then the length of each edge of Gj would be compressed vi from µri to µj · µri = µi. Hence, 
i.Gj changes from rµi vi vj vi vi vj = to= = .We i.Gj µj i.Gj i.Gj µi rµi µj ·rµi vi can conclude that 
Max iVar[XG] = Min i= xi µi i.Gµi vi vj Min i= Min i. As we have seen, µi ji.Gj µi µj jµj we have the 
single constraint on µzj that j µj = 1. 2 vj v The proof that Min i= is identical µj jµj j vj to that 
in Theorem 6.1. Parallel: For the second case, suppose that G is formed by putting the sub-DAGs in parallel 
with a common source node s and a common sink node t. Because each sub-DAG Gj has .sj = 0 and .tj = 1 
in the spring system, it follows that µj = 1 and does not need to be compressed. vi It follows that Max 
iVar[XG] = Min i= xi µi i.Gµi vi Minµii ji.Gj µi = Min µij j vj = j vj . Theorem 6.4. There is a series-parallel 
graph G and values mi and vi of expectations and variances of the un­derlying edge delay variables, such 
that Max iExp[XG] xi is much less than that obtained by applying the series and parallel rules in Theorems 
6.1 and 6.2 recursively. Proof. Consider the following counter example. Let G have two disjoint and similar 
st paths, each containing n + 1 edges. For i . [0, 1], the delay variable of the .rst edge in the ith 
path will be denoted x(i,0). We let its mean be m(i,0) = m and its variance be v(i,0) = 0. For j . [1..n], 
the jth edge in the ith path will be denoted x(i,j). We let its mean be m(i,j) = E and its variance be 
v(i,0) = v. Note that when computing Min t(i,j)m(i,j) + t(i,j)(1 - t(i,j))v(i,j),m(i,j) , t(i,j)m(i,j) 
will be the minimum for the two .rst edges because v(i,0) = 0, and m(i,j) will be the minimum for the 
rest of the edges because m(i,j) = E. Hence we can easily use Theorems 3.1 and 4.1 to bound the expectation 
and variance of XG. MaxExp[XG] x(ii,j) = Maxt(ii,j) i.[0,1] j.[0,n] Min H(i,j),m(i,j) , where H(i,j) 
= t(i,j)m(i,j) + t(i,j)(1 - t(i,j))v(i,j)= t(0,0)m(0,0) + (1 - t(0,0))m(1,0) + i.[0,1] j.[1,n] m(i,j) 
= m +2nE v(i,j) Max iVar[XG] = Min i xi µi µ(i,j) i.[0,1] j.[0,n] v = 1/n i.[0,1] j.[1,n] =2n · nv =2n 
2 v Note that µ(i,0) might as well be (almost) zero because v(i,0) = 0. Since for each path i . [0, 1] 
we need j.[0,n] µ(i,j) = 1, by symmetry the other edges have 1 µ(i,j) =. n Now let us bound Exp[XG] by 
recursively applying the bounds within the series-parallel structure of G. For i . [0, 1], let Gi be 
the ith path of G and let Xi = j.[0,n] x(i,j) be the variable associated with this path. We can easily 
use Theorem 6.1 to bound the expectation and variance of Xi. Maxx(ii,j) Exp[Xi]= m(i,j) = m + nE j.[0,n] 
.. 2 v 2 v .. Maxx(ii,j) Var[Xi]= v(i,j) = 0+ nv j.[0,n] 2 = nv Having the variance and expectation of 
each Xi, we can now use these within Theorem 6.2 to compute the expectation and variance of G = Maxi.[0,1]Xi. 
MaxExp[XG] x(ii,j) tt = Min Exp[Xi],J , where i.[0,1] J = Maxi.[0,1]Exp[Xi] + Var[Xi] i.[0,1] tt = Min 
2 · (m + nE), (m + nE)+ 2 · (n2v) v = m + nE + n. 2v or 2 · (m + nE) >> m +2nE in general. 2 Max iVar[XG] 
= Var[Xi]=2nv xi i.[0,1] Note that if v and m are su.ciently large, the maximum expectation m +2nE of 
XG is much less than  v both m+nE+n 2v and 2·(m+nE) computed recursively. [9] R. Sedgewick. Algorithms 
in C (3rd edition). Dorling This proves that the recursive bound, though sound, Kindersley, 2008. may 
be very conservative. [10] M. Sereno. Approximate mean value analysis for In contrast, the maximum variance 
2n2v of XG is stochastic marked graphs. IEEE Trans. Softw. Eng., exactly equal to the amount computed 
recursively. 22(9):654 664, 1996. [11] A. Xie and P. A. Beerel. Performance analysis of 7 Conclusion 
asynchronous circuits and systems using stochastic timed Petri nets. In A. Yakovlev, L. Gomes, and In 
this paper, we presented tight upper bounds of the L. Lavagno, editors, Hardware Design and Petri Nets, 
mean and variance of the longest path length in a single pages 239 268. Kluwer Academic Pub., March 2000. 
source, single sink DAG with non-negative edge weights. We discussed a new algorithm inspired by balance 
of forces in a system of strange springs to compute the maximum variance and the maximum mean of the 
longest path. We also presented cake distributions, and showed their importance in achieving these upper 
bounds. We also presented closed-form bounds for an important class of graphs called series-parallel 
graphs. Unfortunately, our lower bound analysis is conservative, and does not provide much insight into 
the nature of distributions that can achieve such lower bounds. As part of future work, we intend to 
work on these lower bounds, and also on the more general problem of bounding the mean and variance of 
the time separation of two arbitrary events (not necessarily source and sink) in a precedence constraint 
graph. References [1] P. Buchholz and P. Kemper. Numerical analysis of stochastic marked graph nets. 
In PNPM 95: Pro­ ceedings of the Sixth International Workshop on Petri Nets and Performance Models, page 
32, Washington, DC, USA, 1995. IEEE Computer Society. [2] S. Chakraborty and R. Angrish. Probabilistic 
timing analysis of asynchronous systems with moments of de­ lays. In International Symposium on Advanced 
Re­ search in Asynchronous Circuits and Systems, pages 99 108. IEEE Computer Society, 2002. [3] T. H. 
Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms (2nd edition). The MIT 
Press, 2001. [4] H. A. David and H. N. Nagaraja. Order Statistics (3rd edition). Wiley, New Jersey, 2003. 
[5] A. Dennis, B. H. Wixom, and M. Roth. System Analysis and Design (3rd edition). Wiley-India, 2006. 
[6] W. Feller. An Introduction to Probability: Theory and Its Applications, Vol. 1 (3rd edition). Wiley 
India, 2008. [7] Y.-K. Kwok and I. Ahmad. Dynamic critical-path scheduling: An e.ective technique for 
allocating task graphs to multiprocessors. IEEE Transactions on Parallel and Distributed Systems, 7(5):506 
521, 1996. [8] P.I. Richards. Precedence constraints and arrow dia­ grams. SIAM Review, 9(3):548 553, 
1967.  
			