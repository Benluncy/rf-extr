
 EFFICIENT AND ADAPTIVE LAGRANGE-MULTIPLIER METHODS FOR CONTINUOUS NONLINEAR OPTIMIZATION Tao Wang and 
Benjamin W. Wah Department of Electrical and Computer Engineering Coordinated Science Laboratory University 
of Illinois, Urbana-Champaign Urbana, IL 61801, USA E-mail: {wangtao,wah} @manip.crhc.uiuc.edu URL: http 
://manip.crhc.uiuc.edu Keywords: Lagrange Multiplier method, global opti- mization, inequality constraint, 
dynamic weighting, MaxQ method. ABSTRACT In this paper, we address three important issues in applying 
Lagrangian methods to solve optimization problems with inequality constraints. First, we propose a Mc~Q 
method that transforms inequality constraints to equality constraints It overcomes divergence and oscillations 
that occur in the slack-variable method. Some strategies to speed up its con- vergence are also examined. 
Second, we develop a method to monitor the balance between descents in the original- variable space and 
ascents in the Lagrange-multiplier space in Lagrangian methods. During the search, we adjust this balance 
adaptively in order to improve convergence speed. Third, we introduce a nonlinear traveling trace to 
pull a search trajectory out of a local equilibrium point in a contin- uous fashion without restarting 
the search and without los- ing information already obtained in the local search. This strategy extends 
existing Lagrangian methods from a local search of equilibrium points to a global search. We imple- ment 
these three strategies in Novel (Nonlinear Optimiza- tion via External Lead) and apply it to find improved 
solu- tions for a collection of benchmark problems. 1. INTRODUCTION Many applications in engineering, 
decision science, as well as operations research are formulated as optimization prob- lems. The constrained 
nonlinear optimization problem that Research supported in part by National Science Foundation Grants 
MIP 92-18715 and MIP 96-32316. ~ission to make digital/hard copy of all or part of this work tbr personal 
or ~mom use is granted "~vithout l~e provided that copies are not made or ributed for profit or commercial 
advantage, the copyright notice, the title of the iication and its date appear, and notice is given that 
copying is by permission of M.Inc. To copy other, vise. to republish, to post on servers or to redistribute 
to 36 ~. requires prior specific permission and/or a tee. &#38;#169; 1998 ACM 0-89791.969-6/98/0002 3.50 
we study in this paper takes the following form: Minimize f(X) .subject to g(X) <_ 0 X = (xl,...,xn) 
E R'~(I) h(X) = 0 where f(X) is an objective function, g(X) = [gt (X),..-, gk(X)] 7" is a set of k inequality 
constraints, and h(X) = [hl(X),'", hm(X)] T is a set of m equality constraints. All f ( X ), g( X ), 
and h( X ) are assumed to be differentiable re'd-valued nonlinear continuous functions. Active research 
[4, 3] in the past has produced trans- formational and non-transformational methods to solve (1). Non-tran.sformational 
approaches include discarding, enu- merative, and back-to-feasible-region methods. They have difficulties 
dealing with nonlinear objective and constraints. Tran.~formational approaches, on the other hand, transform 
a problem into another form before solving it. Some well- known methods include penalty, barrier, and 
Lagrangian methods. The first two methods have difliculties when they start from an infeasible region 
or when feasible solutions are hard to find. Lagrange-multiplier inethods (or Lagrangian methods) introduce 
Lagrange multiplier variables to gradually resolve constraints through iterative updates. They are exact 
meth- ods that optimize an objective using Lagrange multipliers to meet the Kuhn-Tucker conditions [4]. 
In view of their advantages, we use them to handle constraints in this paper. 2. HANDLING INEQUALITY 
CONSTRAINTS Lagrangian methods work well with equality constraints, but cannQt deal directly with inequality 
constraints ( 1 ), ex- cept in some simple cases in which one can directly solve the first-order condition 
in closed form. In general, inequal- ity constraints are first transformed into equivalent equality constraints 
before Lagrangian methods are applied. It is important to choose suitable control parameters qi, i = 
1, ., k, because they are related to the convergence speed of our "algorithm. One way of selecting q~ 
is to make it very close to 1, i.e., q~ -4 1. At this time, the system will approach a feasible region 
slowly since p~(X) "-" 1 if g~(X) > 0, which is independent of how far the current point X is away from 
the feasible region. Thus, larger q/'s are needed for faster convergence if the current point X is far 
from the feasible region. In contrast, if we choose q~ >> l, then p~ (X) ~_ 0 as g~ (X) ---+ 0, meaning 
that LSODE converges very slowly towards the equilibrium point on the boundary of the feasible region. 
Taking these facts into account, in order to have fast con- vergence, we adapt q~ dynamically as the 
search goes to an equilibrium point, q~ is large if gI(X) >> 0, and qi is grad- ually reduced to a value 
approaching 1 when the search is close to the equilibrium point. One possible choice of q~ is: q~(~(x)) 
= ,~'o (8) 1 + ~p(-~(x)) where ,so = 2 and st > 0 are two parameters that control the shape of function 
q/(z). When 9i(X) approaches 0, qi will approach 1. Note that when ,So = "2, ~xpi(X) changes very faust 
from 1 to 0 near the equilibrium point as g/(X) .... } 0, mak- ing it difficult for LSODE to find a suitable 
step size to reach the equilibrium point. To let the gradient change smoothly, we set .So to 2.5 or 3.0, 
and s~ to satisfy qi(yi(X)) = "2 whengi(X) = 1. Thus, .s~ = -Ln[so/2-1]. When equilibrium point X* is 
within the feasible re- gion, i.e., gi(X') < O, pi(X') = O, and ~xf(X') = O, meaning that X" is an equilibrium 
point of the dynamic sys- tem given by, d X(t)dt = 0 and d --~lq(t) O, i = [, ,k. (9) Thus the trajectory 
will converge to this equilibrium point When equilibrium point X" is on the boundary of the feasible 
region, it will be asymptotically approached from outside the feasible region. This can be proved by 
showing that X" is asymptotically a regular point of the constraints pi(X) = 0 [4] because inequality 
constraint gi(X) < 0 has been equivalently transformed into equality constraint p~(.\') = o. To improve 
convergence rate, we dynamically convert inequality constraints that are very close to the boundary into 
equality constraints. Since we solve the dynamic sys- tem using LSODE, let X and No be the points of 
two suc- cessive iterations. The conversion of inequality constraint !Li(X) _< 0 occurs when the following 
two conditions are satisfied: (a) The dynamic system converges to some point X when it changes very little 
for "r iterations. (b) The dy- Figure 3: The objective and maximal violation converge in 1 MaxQ with 
~v = Tt. tannic system converges to the boundary when gj(X) is very close to zero. If dynamic conversion 
is performed on inequality con- straint e i (X) ___ 0, then the terrain of the Lagrangian func- tion 
Lq(S, t.t) will be changed and totally different. To maintain the search direction in the original variable 
space X, we have to adjust Lagrange multiplier #j. Let the cur- rent point be (X, #./) just before the 
conversion, and (X,/~:/) be the point after the conversion. The relationship between them is then derived 
as [q~ + q~(x)g~(x)r,~ o~(x)] -:~j(x) (10) As in the slack-variable method, we add an extra weight .; 
in the original augmented Lagrangian function in MaxQ, L,,(X, A,/.t) -" w f(x) + ATh(X) + IIh(X)ll:~ 
+tJp(X) + IIp(X)II~ (1 l) where w > 0 is a weight on the objective, A is the La- grange multiplier for 
equality constraints, # for inequality constraints, and p( X) = [pl ( X), p~( X), . . . , pk(X)] f, To 
show how MaxQ avoids divergence and oscillations in the slack-variable method, consider the same problem 
2.3 in [2]. The starting point is at the middle of the search space, which is the same as that used in 
the slack-wtriable method. Three cases were tested: no scaling, scaling the objective by | l) (i. e., 
w = i / 10), and scaling the objective by 15. Our re- sults show that all three cases converge with similar 
behav- ior, and the second case is shown in Figure 3. Obviously, Ma_~Qh,'ts smoother and better convergence 
as compared to the slack-variable method. 3. ADAPTIVE LAGRANGIAN METHOD In the last section, we have 
studied two methods to deal with inequality constraints. The slack-variable method is sensi- tive to 
the relative weight between the objective and the con- straints, leading to divergence, oscillations, 
or convergence. Although MaxQ is not a.s sensitive to this weight, careful weighting may help accelerate 
its convergence speed. Be-cause the relative weight for fast convergence is problem- dependent, it is 
impossible to set it in advance. Here, we 363 propose a strategy to adapt this weight based on the behav- 
ior of the search progress.  3.1. Dynamic Weight-Adaptation Strategy tbr MaxQ The basic idea is to monitor 
the progress of the search tra- jectory and adapt weight w to the search progress. We di- vide search 
time into non-overlapping windows of size N,o iterations each. In each window, we compute some met- rics 
to measure the progress of the search relative to that of previous windows. For the t t'h window (t = 
1, 2,...), we calculate the average value of v,~= (t) over all the iterations in this window, 1 tN,o 
o, = :% ~ ~.,,,=(j) (12) j=(t-l)Nw+l At the end of each window or every N,~ iterations, we decide whether 
to update w based on the performance met- rics (12). In our current implementation, we use the av- erage 
value of maximum violation Vr~a= (t). In general, other application-specific metrics can also be used. 
Based on these measurements, we adjust w accordingly. As explained before, the major problem with the 
MaxQ sometimes is its slow convergence, which can be measured by how fast its maximal violation decreases. 
Therefore, we monitor the reduction of the average value 0t of the maximal violation. If it is found 
to decrease slowly, i.e., /~t- l -?;t < ~0t_ l, where/3 is a threshold (e.g./3 : I0%), we will reduce 
weight w by half, w Â¢=:= ,v/2. Its effect is to put more weight on the constraints, thus pushing the 
trajectory more quickly to a feasible region. Note that when comparing the values between two successive 
windows t - 1 and t, both must use the same weight w; otherwise, the com- parison is not meaningful because 
the terrain may be differ- ent. Hence, "after adapting w, we should wait at lea.st two windows before 
changing it again. 3.2. Illustration of Weight Adaptation for MaxQ To use the dynamic weight-adaptation 
method, we set the time interval At = 1 for LSODE, and the window size .\r = 10. Corresponding to Figure 
3, we start from the initial weight w(t = 0) = 1/10 and the same starting point (X(0). A(0). 1,(0)). 
Figure 4 shows the resulting search profile, in which the search converges using only 756 it- erations. 
This is a significant improvement over the case without dynamic weight adaptation. It is noted that the 
solution quality in Figure 4 is the same as that in Figure 3 in the sense that both obtain the objective 
value -1 1.25 when the search converges. o.z .t~ Figure 4: The objective and maximal violation converge 
us- ing dynamic weight adaptation in MaxQ. 4. GLOBAL SEARCH Lagrangian method is a local search method 
that is easy to get stuck in a local minimum. To tackle this problem, many global search algorithms have 
been developed that focus on bringing the search out of local minima. They use either deterministic [6, 
3] or probability heuristics [5] or sam- pling [6]. These methods are normally computational ex- pensive 
and have difficulties to deal with large problems. We have developed Novel [7], a hybrid global and lo- 
cal search method for both constrained and unconstrained global optimization. It is a trajectory-based 
method that uses an external force to pull the search out of local min- ima, while using local search 
to locate local minima. Novel has three components: exploring the search space, locat-ing promising regions 
and finding local minima. In explor- ing the search space, the search is guided by a continuous terrain-independent 
trace that does not get trapped in local minima. In locating promising regions, Novel uses local gradients 
to attract the search to a local minimum, while at the same time relying on the trace to pull it out 
once lit-tle improvement can be found. Finally, Novel selects ini- tial points from regions that may 
contain promising local minima, and uses them as starting points for a local search algorithm to find 
local minima. Combining these three components, Novel redefines the overall dynamic system for nonlinear 
constrained optimiza- tion as follows: d --//A'(t ) = -~/~x L~,(X(t)..~(t). tL(t)) -,/~j * (A'(t) -Tx 
(t)) d d-'~A(t)= ~A L~(X(t), A(t),#(t)) (13) <i  ~/,(t) = ~. L~.\'(t). Air),/,(t)) where 71~ and ~lg 
are constants controlling the relative weights between local search and global exploration. The dynamic 
system is used in both the global and the local search. There are three stages in the global search phase, 
each of which outputs a trajectory based on ( ! 3). In the first stage of the global search, the user-defined 
trace function Tx (t) leads the trajectory. In the second and third 364 stages of the global search, 
the trace function Tx (t) in (13) is defined as the trajectory obtained in the previous stage. According 
to the trajectory output from the three stages, we identify a set of promising starting points and perform 
local Lagrangian searches from them. The final result is the best solution among all these Lagrangian 
searches. 5. EXPERIMENTAL RESULTS In this section we describe our experimental results on some existing 
benchmarks [2]. These benchmarks are challeng- ing because they model practical applications that have 
been studied extensively in the past. We use the same set of parameters to solve all the prob- lems, 
except that the search range is problem-specific. In practice, this is reasonable a~s search ranges are 
generally known. In case that the search range is not available, we use trial and error, starting from 
a small range and gradually increasing it until no improvement is found in the solutions. In the global 
search phase of Novel, we use three stages that produce three trajectories. From each trajectory, we 
choose 100 starting points for Lagrangian search based on their Lagrangian-function values. After 300 
searches, we report the best solution found. Table 1 summarizes the results found by Novel. Col-umn 1 
lists the problem identifications that appear in the benchmark collection [2]. Column 2 shows the best 
known solutions reported in [2], and Column 3, the solutions re- ported by Epperly [1]. Here, symbol 
'-' means that the method is unable to find a solution for the corresponding problem. Column 4 shows 
the results obtained by Novel us-ing the slack-variable method with dynamic weight adapta- tion [81. 
Without weight adaptation, more than half of these problems cannot be solved due to divergence and oscilla- 
tions described in Section 2.1. The last column shows the results obtained by Novel using MaxQ. Results 
in bold font are improved by Novel over the best known results, with improvements of up to 10%. Our results 
indicate that Novel is robust in discovering new regions and in escaping from local traps. 6. REFERENCES 
[ 1 ] T. Epperly. Global Optimization ofNonconv~r Nonolin- ear Programs Using Parallel Branch And Bound. 
PhD thesis, University of Wisconsin-Madison, 1995. [21 C. A. Floudas and R M. Pard'dos. A Collection 
of Test Problerr,~ for Constrained Global Optimization Algo- rithms, volume 455 of Lecture Notes in Computer 
Sci- ence. Springer-Verlag, 1990. 13/ R. Horst and H. Tuy. Global optimization." Determinis- tic approaches. 
Springer-Verlag, Berlin, 1993. Table 1: Results on a collection of constrained optimization benchmarks 
[21 comparing Novel using MaxQ, Novel using the slack-variable method, and Epperly's method [11. Im- 
proved solutions found by MaxQ are indicated in bold font. Symbol '-' means that the method was not able 
to find a solution for the corresponding Problem. Problem Best Known Epperly's Slack Variable MaxQ [D 
Solutions Solutions Solutions Solutions 2.1 --17.00 --17.00 --17.00 -17.00 2.2 --213.00 --213.00 --213.00 
--213.00 2.3 -15.00 -- 15.00 -- 15.00 -15.00 2.4 -- 11.00 -- 11.00 -- 11.00 -- 11.00 2.5 -268.00 --268.00 
--268.00 --268.00 2.6 --39.00 --39.00 --39.00 --39.00 2.7(l) --394.75 --394.75 --394.75 -394,75 2,7(2) 
--884.75 --884.75 --884.75 --884.75 2.7(3) --8695.00 --8695.00 --8695.00 --8695,00 2.7(4) --754.75 --754.75 
--754.75 --754.75 2.7(5) --4150.40 --4150.40 --4150.40 --4i50.40 2.8 15990.00 15990.00 15639.00 15639.00 
 3.1 7049.25 --7049,25 7049.25  3.2 -30665.50 -30665.50 --30665.50 -30665.50 3.3 -310.00 --310.00 --310.00 
-310.00 3.4 --4.00 --4,00 --4.00 -4.00 4.3 -4.51 -4.51 --4.51 --4,51  4.4 -2.217 --2.217 --2.217 -2.217 
4.5 -11.96 -13.40 --13.40 -13.40 4.6 --5.51 --5.51 --5.51 -5.51 4.7 -16.74 --16.74 -- 16.75 -16.75 5.2 
1.567 --1.567 1.567  5.4 1.86 --1.86 1.86 62 400.00 400.00 400.00 400.00 6.3 600.00 600.00 600.00 600.00 
 6.4 750.00 750.00 750.00 750.00 7.2 56825.00 --56825.00 56825.00  7.3 46266.00 --46266.00 44903.00 
7.4 35920.00 --35920.00 35920.00 [41 D. G. Luenberger. Linear and Nonlinear Programming. Addison-Wesley 
Publishing Company, 1984. [5] H. E. Romeijn and R. L. Smith. Simulated annealing for constrained global 
optimization. Journal of Global Optimization, 5(2): 101-126, September 1994. [61 F. Schoen. Stochastic 
techniques for global optimiza- tion: A survey on recent advance, s. Journal of Global Optimization, 
1(3):207-228, 1991. 171 B. W. Wah ,and Y.-J'. Chang. Trace-based methods for solving nonlinear global 
optimization problems. J. of Global Optimization, 10(2): 107-141, March 1997. 181 13. W. Wah, T. Wang, 
Y. Shang, and Z. Wu. Improving the performance of weighted Lagrange-multiple meth- ods for constrained 
nonlinear optimization. In Proc. 9th lnt 'l Conf. on Tools for Artificial Intelligence, pages 224-231. 
IEEE, November 1997. 365  
			