
 Competitive Tree-Structured Dictionaries MICHAEL T. GOODRICH* Abstract In this note we describe a general 
technique for making tree- structured dynamic dictionaries adapt to be competitive with the most efficient 
implementation, by using potential energy parameters and a simple partial rebuilding scheme. Introduction. 
On-line algorithms deal with optimizing the performance of operation sequences (e.g., see [4, 9]). Such 
algorithms are desired to be c-competitive [4], for some parameter c > O, where c is an upper bound on 
the ratio of the costs of the solution defined by the on-line algorithm and an oracle's algorithm. In 
this paper we are interested in dictionary data structures that are competitive in this same sense. Our 
Results. We present a simple adaptive tree-based dictionary structure that is balanced and competitive. 
Our approach is based on a potential energy parameter stored at each node in the tree. As updates and 
queries are performed, the potential energy of tree nodes are increased or decreased. Whenever the potential 
energy of a node reaches a threshoM level, we rebuild the subtree rooted at that node. We show that, 
in spite of its conceptual simplicity, such a scheme is constant-ratio competitive with a static oracle 
using a priori knowledge of the operation distribution. Related Prior Work. Besides general work for 
on-line algorithms (e.g., see [4, 9]) and data structures that use par- tial rebuilding [7], there has 
been some prior work on meth- ods for adapting data structures to the way in which they are being used. 
Most previous data structure competitive analy- ses have been directed at simple linked-lists structures, 
with "move-to-front" heuristics applied [9]. Work on other adap- tive data structures includes splay 
trees [ 10], which perform a sophisticated move-to-root heuristic, but perform many rota- tions with 
each access. There is also the randomized binary search tree of Seidel and Aragon [8], which performs 
ran- dom structural changes with each access and can adapt in an expected, probabilistic sense based 
on data structure usage. Energy-Balanced Binary Search Trees. A dictionary holds pairs of ordered keys 
and elements, subject to update and query operations. A common way of implementing the dictionary ADT 
is to use a binary search tree, which main- talus balance by local rotation operations. Typically, such 
rotations are fast, but if the tree has auxiliary structures, ro- tations are often slow. Standard binary 
search trees, such as AVL trees [1], red-black trees [3], scapegoat trees [2], or weight-balanced trees 
[6], maintain balance, but do not adapt themselves based on the distribution of accesses and updates. 
Splay trees [10], on the other hand, adapt (in an asymptotic sense), but perform a large number of rotations 
with each ac- cess. Finally, randomized binary search trees [8], have good expected behavior but offer 
no worst-case guarantees on per- "---arI~. of Computer Science, Johns Hopkins Univ., Baltimore, MD 21218. 
goodrich@jhu.edu. This work was supported by ARO MURI Grant DAAH04-96-1-0013 and NSF Grant CCR-9732300. 
formance. We describe a simple tree structure that achieves balance without rotations, by using a potential 
energy param- eter stored at each node and partial rebuilding [7]. Our meth- otis are somewhat reminiscent 
of scapegoat trees [2] and dy- namic search trees of Overmars [7]. Our approach does not use any explicit 
balancing rules. Instead, it uses potential la- bels on the nodes, which allow it to be adaptive, competitive, 
and arguably simpler than previous approaches. An energy-balanced tree is a binary search tree T such 
that each node maintains a parameter nv, which is the num- ber of elements stored in the subtree rooted 
at v (including v itself). More importantly, each node v in T also maintains a potential energy parameter, 
Pv. Insertions and deletions are handled as in standard (unbalanced) binary search trees, with one small 
modification. Every time we perform an update operation, which traverses a path from the root of T to 
some node w in T, we increment Pv by I for each node v in this path. If there is no node v in this path 
such thatpv > nv/2, then we are done. Otherwise, let v be the highest node in T such that Pv > nv/2. 
We rebuild the subtree rooted at v as a complete binary tree, and we zero out the potential fields of 
each node in this subtree (including v itself). This is the entire algorithm for performing updates. 
THEOREM 1. The worst-case height of the energy-balanced search tree is O(logn), and the amortized time 
for perform- ing an insert or delete in such a tree is also O(logn). Proof It is enough to show that 
nw < nv/4, for any node v with sibling w. So suppose not, Then, since the last rebalance at v and w's 
parent, z, (when the size of v and w's subtrees were equal) the number of deletions in w's subtree plus 
the number of insertions in v's subtree must have been at least 3nv/4. That is, Pz >__ 3n~/4. At this 
point in time we have nz = nw + n. < 5n~/4. Hence, Pz > 3n~/4 > (3/5)nz. But this cannot occur, since 
we would have rebuilt the subtree at z as soon as p; > nz/2. Biased Energy-Balanced Search Trees. Our 
potential energy approach can be further extended to adapt a dictio- nary to biased distributions of 
accesses and updates. We augment the tree T in this case so that each node v stores an access count, 
av, which counts the number of times that the element stored at v has been accessed. Each time a node 
is accessed in a search we increment its access count. We also now increment the potential energy parameter 
of each node on the path from v to the root. We keep the insertion algorithm the same, but now whenever 
we delete a node v, we increment the potential energy of each node on the path from v to the root by 
av. Let A~ denote the cumulative ac- cess counts for all nodes in the subtree rooted at v in T. We do 
a rebuilding step any time the potential energy of a node rises to be more than a quarter of its access 
value, i.e., when p~ > A./4. In this adapted binary search tree we rebuild the subtree so that nodes 
are nearly balanced by their ac- cess counts, that is, we try to balance children by their Av values. 
Specifically, there are several top-down approaches (e.g., see [5]), as well as a a simple linear-time 
bottom-up greedy approach that can guarantee that for any node v with parent z, Az > 3Av/2. For any non-root 
node v, we use Av to denote the size of the subtree rooted at v plus the weight of the item stored at 
v's parent z (so Az = Av + ilw, where w denotes v's sibling). LEMMA 1. For any node v with sibling w, 
Aw >_ Av /8. Proof Suppose, for the sake of proving a contradiction, that Aw < Av/8. Then, since the 
last rebalance at v and w's parent, z, (when A~ > A"/2, where -4~w and A~v denote the old values of Y~w 
and A~ respectively) the total weight of deletions in w's subtree plus the number of insertions and accesses 
in v's subtree, plus accesses ending at v's parent, must have been at least 3A~/8. That is, Pz > 3A~/8. 
At this point in time we have that Az = Aw + Av < 9Av/8. Hence, we have that p, > 3Av/8 > Az/3. But this 
cannot occur, since we would have rebuilt the subtree at z as soon as p~ > A~/4. This lemma immediately 
implies the following. THEOREM 2. An element having current access frequency a is stored at depth O(logA/a), 
where A is the current total access frequency of all nodes. LEMMA 2. Let Ai denote the total access counts 
of all nodes present in the dynamic biased energy-balanced tree (for S) after we perform the i-th operation 
in Sv. Then ~-~=1 l°gAdi is O(mlogA/ra), where ra = IS.I and fl is the total access counts for all elements 
referenced in S. Proof Let us assume for the sake of analysis that m is a power of 2, i.e., thatm = 2 
k, for some k. Note that logTAi < Z ZI°gAl ° g = - i=1 i=1 i=1 m m ^ m A 1 m = Z log "__Am + Z log --rni 
= m log m + Z og T" i=1 i=l i=1 Thus, to establish the lemma we need only bound the the last term above 
(the summation term). Note that m 2 t' 2 k 2 ~' m __ [logij  Elog v = Elog 2k < Zlog = Zk_ i=1 i=1 i=1 
i=1 k k  < = < 2.2 = 2,,. j=l j=l An oracle, which we call the biased-tree oracle, know-ing the sequence 
in advance could construct a static tree based on known access counts, so that the running time for each 
access or update at a node v is O(logA/5~), where fly denotes the total access count for the element 
at node v. THEOREM 3. The energy-balanced search tree achieves amortized performance for update operations 
at each node v that is O(logA/Sv), which is within a constant factor of the performance achievable by 
the biased-tree oracle. Proof Let S be a sequence ofn dictionary operations and let T be the static tree 
built by the biased-tree oracle. Consider a subsequence Sv of S formed by all operations that access 
or update the element at a given node v. Let Ai denote the total access counts of all nodes present in 
the dynamic adaptable energy-balanced tree (for S) after we perform the i-th opera- tion in S~. Note 
that the amortized running time for perform- ing the i-th operation in Sv using the energy-balanced tree 
is proportional to the future depth of v in the energy-balanced tree, which will be at most O(logAi/i). 
Thus, the amor- tized time required for our performing all operations in Sv m is proportional to at 
most ~"]-i=1 l ogAi/z, whereas thetotal time required of the implementation of the biased-tree ora- cle 
is proportional to mlog,4/Sv = mlog,4/ra, where m = IS~l. By Lemma 2, however, we have that ~iml logAi/i 
is O(mlogA/m), which implies that the time performance of the energy-balanced approach on S. is at most 
a con- stant factor more than the time performance achievable by the biased-tree oracle. Thus, biased 
energy-balanced search trees are efficient, competitive, and simple.  References [1] G. M. Adel'son-Vel'skii 
and Y. M. Landis. An algorithm for the organization of information. Doklady Akademii Nauk SSSR, 146:263-266, 
1962. English translation in Soviet Math. Dokl., 3, 1259-1262. [2] I. Gaiperin and R. L. Rivest. Scapegoat 
trees. In Proc. 4th ACM-S1AMSODA,pages 165-174, 1993. [3] L. J. Guibas and R. Sedgewick. A dichromatic 
frame- work for balanced trees. In Proc. 19th Annu. IEEE Sympos. Found. Comput. Sci., Lecture Notes Comput. 
Sci., pages 8-21. Springer-Verlag, 1978. [4] M. S. Manasse, L. A. McGeoch, and D. D. Sleator. Com- petitive 
algorithms for on-line problems. In Proc. 20th Annu. ACMSympos. Theory Comput., pages 322-333, May 1988. 
[5] K. Mehlhom. A best possible bound for the weighted path length of binary search trees. SlAM J Comput., 
6(2):235-239, 1977. [6] J. Nievergelt and E. M. Reingold. Binary search trees of bounded balance. SIAMJ. 
Comput., 2:33-43, 1973. [7] M. H. Overmars. The Design of Dynamic Data Structures, volume 156 of Lecture 
Notes Comput. Sci. Springer-Verlag, Heidelberg, West Germany, ! 983. [8] R. Seidel and C. R. Aragon. 
Randomized search trees. Algorithmica, 16:46 n. A.97, 1996. [9] D. D. Sleator and R. E. Tarjan. Amortized 
efficiency of list update and paging rules. Commun. ACM, 28:202-208, 1985. [10] D. D. Sleator and R. 
E. Tarjan. Self-adjusting binary search trees. J. ACM, 32(3):652-686, 1985. 
			