
 On the complexity of beta-reduction Andrea Asperti Dipartimento di Matematica P.zza di Porta S. Donato 
5, Bologna, Italy asperti@cs. unibo.it Abstract We prove that the complexity of Lamping s optimal graph 
reduction technique for the A-calculus can be ex­ponential in the number of L6vy s family reductions. 
Starting from this consideration, we propose a new mea­sure for what could be considered as the intrinsic 
com­plexity of A-terms.  Introduction Twenty years ago, L&#38;Jy [Le78] introduced the notion of redez 
famikj to formalize the intuitive idea of optimal sharing in the J-calculus (see also [Le80, AL93]). 
As a main consequence, the length of the family reduction would provide a lower bound to the intrinsic 
complexity of A-term reduction, in any possible implementation. In 1990, Lamping [Lam90] discovered a 
complex graph reduction technique that was optimal in L&#38;Ty s sense (that is, all sharable redexes 
had a unique graphical rep­resentation, and could be reduced in a single atomical step). However, Lamping 
did not establish any com­plexity relation between his algorithm and the lenght of the corresponding 
family reduction. In this paper, we prove that Lamping s technique can be exponential with respect to 
the number of redex families reduced along the computation. This fact does not con­tradict neither the 
optimality of the algorithm, nor its relevance in view of an actual implementation (as a mat­ter of fact, 
the examples where Lamping s algorithm is exponential, are also the examples where it works better with 
respect to more traditional implementation tech­niques). On the contrary, we claim that the lenght of 
the family reduction is not a reasonable lower bound to the intrinsic complexity of J-terms, and we shall 
propose a different complexity measure. Permission to make digital/hard copies of all or part of ttda 
material for peraoml or classroom use is granted without fee provided that the copies are not made or 
dtatributed for profit or commercial advantage, the copY­ right notice, the title of the publication 
and its date appear, and notice is given that ~opyright is by permission of the ACM, Inc. To copy orheruk% 
to republish, to post on servers or to redistribute to lists, requires apecitic permission andlor fee. 
POPL 96, St. Petersburg FLA USA @ 1996 ACM @89791 _769-3195\Ol ..$3 .5(3 2 Lamping s graph reduction 
technique Lamping s graph rewriting rules can be naturally clas­sified in two main groups: 1. the rules 
involving application, abstraction and sharing nodes (fan), that are responsible for ~­reduction and 
duplication (we shall call this group of rules the abstract algorithm); 2. some rules involving control 
nodes (square brackets and croissants), wh~ch are merely required for the correct application of the 
first set of rules.  More precisely, the first set of rules requires an oracle to discriminate the correct 
interaction rule between a pair of fan-nodes; the second set of rules can be seen as an effective implementation 
of this oracle. This distinction looks particularly appealing since all different translations proposed 
in the literature after Lamping [GAL92a, GAL92b, As94, As95] differ from each other just in the way the 
oracle is implemented (in the sense that all of them perform exactly the same set of abstract reductions). 
In this paper, we shall prove that Lamping s technique can be already exponential in its abstract algorithm, 
without considering the extra work required by the or­ acle. For this reason, we shall introduce here 
Lamping s tech­nique without mentioning the possible solution to the effective implementation of the 
oracle. 2.1 Initial translation Initially, in the optimal graph reduction technique, a A-term is essentially 
represented by its abstract syntax tree (like in ordinary graph reduction). There are two main differences, 
however: 1. we shall introduce an explicit node for sharing; 2. we shall suppose that variables are 
explicitly con­nected to their respective binders.  110 For instance, the graph in Figure l.(l) is 
the initial representation of the A-term M = (two 6), where two= Jz.Ay. (z(zg)) and6=Az.(m z). The triangle 
(we shall call it fun) is used to express the sharing between different occurrences of a same variable. 
All variables are connected to their respective binders (we shall always represent this connection on 
the left of the connection to the body). Since multiple occurrences of a same variable are shared by 
fans, we shall have a single edge leaving a J towards its variables. So, each node in the graph (Cl, 
J and fan) has exactly three dis­tinguished sites (ports) where it will be connected with other ports. 
 2.2 Reduction We shall now illustrate the main ideas of Lamping s optimal graph reduction technique 
by showing how a simplified version of the algorithm would work on our sample term (two @. As we shall 
see, a crucial issue will remain unresolved. This is exactly where the oracle comes in: however, since 
the complexity of the oracle is not necessary to prove the exponential nature of Lamp­ing s algorithm, 
we shall not discuss this complex topic here. Lamping s algorithm consists of a set of local graph rewriting 
rules. At a given stage of the computation, we can usually have several reducible configurations in the 
graph. In this case, the choice of next rule to ap­ply is made non-deterministically. This does not mat­ter 
that much, since the graph rewriting system is an Interaction Net in Lafont s sense [Laf90], and it satis­fies 
a one-step diamond property (that implies not only confluence but also that, if a term has a normal form, 
all normalizing derivations have the same length). In particular, we shall usually choose the next rule 
in our example of reduction according to a didactical criterion (and sometimes for graphical convenience). 
The most important of the graph rewriting rules is obvi­ously /3-reduction: (ku.itf N) + M [N/z]. In 
graph re­duction, substituting a variable z for a term iV amounts to explicitly connect the variable 
to the term N. More­over, the value returned by the application before the redex is fired (the link above 
the application) becomes the (instantiated) body M of the function. Since the portions of graph representing 
M and N do not play any role in the graph reduction corresponding to the@ rule, this reduction can be 
expressed by the completely local graph rewriting rule in Figure 2. By firing the outermost /3-redex 
in (two 6), we get the graph in Figure 1.(2). Since the next redex involves a shared ~-expression, we 
must eventually proceede to the duplication of 6. In ordinary graph reduction, this du­ (1) (2) (3) k 
A ~ (6)(4) (5) I ! / / .... ,, .. ,,, ~,, ;, / $ ...... Y 7 Yf ..... ~, A,,, $,, ; :b: t:, ., ,,? 
%... J !!? (9)(7) (8) Figure 1: Graph reduction of (two 6) Figure 2: the @-rule plication would be 
performed as a umque, global step on the shared piece of graph. On the contrary, the op­timal graph reduction 
technique proceedes in a more lazy way, duplicating the external A but still sharing its body. However, 
since the binder has been duplicated, we are forced to introduce another fan on the edge lead­ing from 
the binder to the variable. In a sense, this fan works as an %nsharing) operator (fan-out, usually de­picted 
upside-down ), that is to be paired against the fan(-in) sharing the body of the functionl. Since the 
body of the function Ax .M does not play any role in this reduction, it can be formally expressed as 
a local interaction between a fan and a }, as described in Figure 3. Let us now proceede in the analysis 
of our example. Figure 3: Fan-A interaction By applying the fan-a interaction rule, we get the graph 
in Figure 1.(3). Now, two /?-redexes have been created, and by their firing we are lead to the graph 
in Figure 1.(5). We have no more ,@redexes in the graph, and no fan-a interactions, so we must proceede 
in the dupli­cation process, but we must be very carefully here. In particular, the following graph rewriting 
rule is strictly x-w Figure 4: not optimal duplication of the application forbidden, in the optimal imlementation 
technique (al­though semantically correct ). The intuition should be clear: since the shared application 
could be involved in some redex, its duplication would imply a double exe­cution of the redex. The only 
other possible interaction is between the two fans inside the dotted region. This is another crucial 
1 Although there is no operational distinction between a fan-in and a fan-out, their intutive semantics 
is quite different; in partic­ular, keep in mind that a fan-out is always supposed to be paired with 
some fan-in in the graph, delimiting its scope and annihilat­ ing its sharing effect. The way the correct 
pairing bet ween fans is determined is a crucial point of the optimal graph reduction technique, solved 
by the oracle . Obviously, in order to give a precise definition of the abstract algorithm we should 
provide the formal definition of the oracle, that is very complex and would just obscure the intuitive 
natnre of the abstract rules. In particu­ lar, the obvious and naive idea of labeling fans does not work 
(see [Lam89]). point of the optimal graph reduction technique. As we shall see, this interaction must 
be handled in a differ­ent way form the similar interactions in Figure 1. ( 7). Note in particular that 
the two fans in Figure 1.(5) are not paire&#38;: the fan-in is a residual of the shared vari­able of 
6, while the fan-out is a residual of the shared variable of two, in the process of duplicating 6. Since 
the two fans have nothing to do with each other, they must duplicate each other, according to the rule 
in Fig­ure 5.(2). Now (see Figure l.(6)), we have a fan-out absb #b . . e dcd cd cd [1) (2) Figure 5: 
fan-annihilation rule in front of the function-port of the application. In this case, we can apply the 
following rule: Intuitively, this Figure 6: fan-@ interaction rule is correct from the point of view 
of optimal sharing since such a configuration already implies the existence of two unshakable (class 
of) redexes for the application. After firing this rule, we get the graph in Figure l.(7). In this case, 
both pairs of fans are paired: they both be~ long to the same duplication process , that has been now 
(locally) completed. So, the obvious rule, in this case, is to annihilate the paired fans, according 
to Fig­ure 5.(l). The problem of deciding which rule to apply when two fans meet each other (that is 
the question of how theii pairing is established) is the crucial point of the optimal implementation 
technique (solved by the oracle). By a double application of this rule, we get the graph in Figure 1.(9), 
that is in normal form w.r. t. Lamping s algorithm. 3 complexity Before discussing the complexity of 
Larnping s ah: stract algorithm, we should start by fixing a few pre­liminary assumptions. First of all, 
a typical feature of optimal techniques is that of anticipating work that could become usefull only later 
on in the computation. A reasonable way to take into account this extra work is that of restricting the 
analysis to A-terms whose nor­mal form is an atomic constant (or, if you prefer, a variable). This hypothesis 
also allows us to avoid some obviously degene~ate examples. Consider for instance the term P = Az.Ay. 
(y z z). If we apply P to a closed term M in normal form, M gets fully duplicated, and the cost of the 
@redex would seem proportional to the size of M. However, this reasoning does not seem convincing, since 
in duplicating M we also duplicated all its A and application nodes (its prerequisite chains, in Lamping 
s terminology), which (whenever turned to redexes), would eventually belong to distinguished fam­ilies! 
So, we just anticipated work that had to be done in any casez. Our second assumption will be to consider 
only terms of the ~-I calculus. The reason, here, is that the cor­rect handling of garbage collection 
in optimal reduction techniques is still a subject of investigation (in particu­lar, Lamping s approach 
does not seem to be completely satisfactory). We shall now provide an example of a A-term satisfying 
our assumptions, whose abstract reduction (i.e. with­ out considering the extra cost of the oracle) 
is already exponential in the number of family reductions. Since the example is quite complex, we shall 
proceede by con­sidering a few auxiliary terms. Let us start with a simple case. In Figure 7 is a pos­sible 
representation of the Church Integer two in shar­ing graphs, obtained by reducing the l-term two = kc.~y. 
(h.(z(z y)) ~w.(z w)). Let us now consider the application of two to itself. Recall that the application 
(n m) of two church integers n and m gives the church integer mn, so the expected result is (a representaion 
of) the church integer four. The reduction is shown in Figure 8. The two first reduction steps are ,d-redex. 
After these reductions we are left with the term in Fig­ure 8.(3), where the sub term Jy. (z(z y)) is 
shared by means of the two copies of the fan marked a . Now, this subterm is fully duplicated. This 
process requires: 2 steps for duplicating the A and the application; 2 steps for duplicating the fans; 
3 steps for effacing all residuals of fans marked with a . After these 7 steps we are left with the 
graph in Fig­ure 8.(4), where a new ~-redex has been put in evi­dence. Firing this redex, we obtain the 
final config­uration in Figure 8.(5). Summing up, we executed 3 2The idea of considering only those rules 
which are needed to put in evidence new redexes gives some problems due to the un­predictable disposition 
of fans inside a virtual redex: again, if all copies of prerequisite chains generated by the duplication 
are not fired along the computation, we could perform some (appar­ently) useless work. Figure 7: two 
: a representation of Church s integer two   //&#38;~ two two (1) (2) (3) (4) (5) Figure 8: the reduction 
of (two two ) /3-reductions (actually, family reductions), and 7 fan-fans marked with a is now fully 
duplicated. This du­ interactions. Note moreover that the final configuration plication requires: 2 steps 
for duplicating the A and the has the same shape of the initial one. application; 2n steps for duplicating 
fans; n+2 steps for Let us now generalize the previous example. As should effacing fans. This gives a 
total of 4 + 3n operations. be clear, the church integer 2n can be represented by the After these reductions, 
we get the configuration in Fig­graph in Figure 9, where we have exactly a sequence of ure 11. A new 
fl-redex has been created. 13y firing this the term (g n) is Figure 9: a representation of 2n fan-in 
of length n and a corresponding out of the same length. Let us now apply this term to itself. outermost 
~-redexes we get the term sequence By firing in Figure of fan­the two 10. As Figure 11: the reduction 
of (2n 2n) redex we obtain the graph in Figure 12. Now, this graph has the same shape of the graph in 
Figure 10, and we can iterate our reasoning. In particular, the duplication of the innermost part of 
the graph will now require 4 + 3* (2n) operations. Then, we shall have a new /3-redex, and by its firing, 
we shall get a graph of the same shape of Figure 12 but where the innermost sequences of fans have length 
4n (this length is doubled at every iteration of the process), while the length of the outermost se­ 
quences is decremented by one. Figure 10: the reduction of (2n 2n) Summing given by. up, the total number 
of fan-interactions is in the case of two, the portion of graph inside the two ({4+3n)+(4+3*(2n) )+(4+3 
*(4n))+. . .+(4+3 *(2n- n))) f(rl)=9+3*n+~bi i=o Finally, let us consider the number of fan-interactions. 
For each application of (6 ai), we have 1 + 4 + 3 * bi in­teractions for duplicating a,, plus bi + 3 
* b,+l operations in the reduction of (a~ ai) (recall that b~+l = bi * 2b~). Moreover, we have one single 
operation internal to two , 5 * (n 1] operations for creating all copies of 6, and bn final operations 
of fan-effacement when we apply the external parameters. Summing up, the number c(n) of fan-interactions 
(for n > 0) is given by the formula n-1 n c(n)= 10*n 4+4*~bi+ 3*~bi+bn i=O i=l n 1 = 10*n+7* ~bi+4*b. 
>4 *b. Figure 12: the reduction of (2n 2n) 2=1 Note now that 2~::01 b = b.. So, n-1 = 4n+3n*~2i =4n+3n*(2 
1)= n*(3*2n+l) i=o For n z 3, it is easy to show that 29+3 < 2s*bn. Hence: In contrast, we have executed 
just n @-reductions in the 2f(nJ < 28* b: < 24* c(n)z. main loop, plus two at the very beginning, for 
a total of n + 2 family reductions. and finally (for any n z 3) Our final problem consists in providing 
an example based on the terms above which satisfies our auxiliary assumptions mentioned at the beginning 
of this section (i.e. it should be a term of the J-I-calculus, whose nor-We can also easily prove that, 
for any n, c(n) s 2f(n~. mal form is an atomic constant). O% ;ne side we have 2ff l > 29* b~. On the 
other side, The term we consider is: g = An. (n 6 two 1 q), where ~i~O hi 5 h. and obviously n s b., 
so 6 = Az.(fiz), two = kz.Ag, (Az. (z(z y)) Aw. (m w)), I is the identity and q is some constant. If 
n is a church in-c(n) < 21 *bn < 29 *b~ < 2f(n) teger, (g n) obviously reduces to q. The term (n 6 two 
) is a real monster , from the complexity point of view. 3.1 The Bologna Optimal Higher-order As a function 
of n, it corresponds to the church integer Machine an, in the succession ao = 2; ai+l = a~i. For instance, 
a3 = 256256. Let us now consider the number of family The previous formulas have been also experimentally 
reductions. When we apply g to the Church integer O, confirmed by our prototype implementation of (a 
vari­we perform 9 family reductions (one for the application ant of) Lamping s algorithm: the Bologna 
Optimal of g, two for the application of O, three internal to two , Higher-Order Machine (BOHM)3. BOHM 
[AGN95] is and three for the extra-identities). These operations are a simple interpreter written in 
C. Its source language is constant for each input n of the function g. Let us now a sugared A-calculus 
enriched with booleans, integers, compute the cost for each application of (6 ai). This is lists and 
basic operations on these data types. The ex­1 plus the number of family reductions for (ai ai) com-tension 
of Lamping s technique to this language is essen­puted in the previous section, namely 2 + log(ai). Note 
tially based on Asperti and Laneve s work on Interaction that the succession b~ = Jog(u, ) can be equally 
defined 3 BOHM is available by anonymous ftp at ftp .cs.unibo.it, in the asb. = l; bi+l = bi*2b; . directory 
/pub/ asperti. Get the file BOHMI .O.tar.Z (compressed Summing up, the number of family reductions ~(n) 
for tar format). Systems [AL93b]. In particular, all syntactical opera­tors are represented as nodes 
in a graph. These nodes are divided into constructors and destructors, and re­duction is expressed as 
a local interaction (graph rewrit­ing) between constructor-destructor pairs. BOHM is lazy (in the sense 
that it always reduces the fumily of the leftmost outermost redex) and weak (that is, it stops computing 
as soon as the top node in the graph is a constructor). As a consequence, BOHM sup­ports lazy data structures, 
such as streams. Due to its prototyping nature, BOHM has been espe­cially designed to provide a large 
number of experimen­tal data relative to each computation (user and system time, total number of different 
kinds of interactions, storage allocation, garbage collection, and so on). The results of the computation 
of the function g of the pre­vious section are shown in figure 13. The four columns Input user tot. inter. 
fam. fan-inter. (g zero) 0.00 s. 38 9 2 (g one) 0.00 s. 64 13 18 (g two) 0.00 s. 200 18 66 (g three) 
15.90 s. 2642966 29 8292 Figure 13: The function g in the table are, respectively, the user time required 
by the computation (on a Spare-station 5), the total num­ber of interactions (comprising the oracle ), 
the length of the family reduction (app-lambda interactions), and the total number of fan-interactions. 
It is also possible to find examples of exponential ex­plosion whith respect to a /inear grow of the 
number of family reductions. An interesting case is provided by the J-term h = Jn.(n two two 1 q). Using 
the same technique of the previous section, it is easy to prove that, for this function, the number of 
family re­ductions ~(n) grows linearly in its input n (in particular, ~(n) = 9 + 3 * n), while the number 
of fan-interactions c(n) is given by the formula c(n)= 12*n 2+4*2 In particular, for any n, In the table 
of Figure14, you will find the experimental results in BOHM. In this case, we also make a compar­ison 
with two standard (respectively, strict and lazy) implementations such as CamI-Light and Yale Haskell. 
CamlLight [LM92] is a bytecoded, portable implementa­tion of a dialect of the ML language (about 100K 
for the runtime system, and another 100K of bytecode for the compiler, versions for the Macintosh and 
IBM PC are also available) developed at the INRIA-Rocquencourt (France). In spite of its limited dimensions, 
the per­formance of CamlLight is quite good for a bytecoded implementation: about five times slower than 
SML-NJ. We used CamlLight v. O.5. Yale Haskell [Ya94] is a complete implementation of the Haskell language 
developed at Yale University. The Haskell compiler is written in a small Lisp dialect similar to Scheme 
which runs on top of Common Lisp. Haskell programs are translated into Lisp, and then compiled by the 
underlying Lisp Compiler. We used Yale Haskell Y2 .3b-v2 built on CMU Common Lisp 17f. The results of 
the test should give a gist of the power of the optimal graph reduction technique. In general, the relative 
amount of fan-interaction rules with respect to the number of family reductions in a computation looks 
related to the amount of sharing in the term. So, the cases where Lamping s algorithm is exponential 
in the number of family reductions are also the cases where the performance of BOHM is so amazingly better 
with respect to convential implemen­tations. The worse cases for BOHM are when Lamping s abstract algorithm 
is /znear in the number of families. However, also in these cases, its performance is not as bad as one 
could expect: BOHM is always five to ten times better than the Yale Haskell interpreter, and it is often 
comparable with the Yale Haskell compder. As an example, in Figure 15 we give the experimental re­sults 
about the computation of the Fibonacci function, defined in the obvious way. In this case, the number 
of family reductions is the total number of constructor­destructor interactions. For Haskell, the fibonacci 
func­tion has been compiled. 4 Discussion We proved that the complexity of Lamping s algo­rithm can 
be exponential in the number of family re­ductions. We conjecture that, under our assumptions (terms 
of the M-calculus reducing to a constant), this value should also also provide an upper bound to the 
complexity of what we called the abstract algorithm. More precisely, if ~ is the number of family reductions 
required for normalizing the term, we conjecture that the total number of reductions rules required by 
Lamp­ing s abstract algorithm is alwasy less than 2f. This result looks difficult to prove, since nothing 
is known about the structure of graphs along a reduction (so, it is not clear how to use induction). 
However, in our opinion, the real issue is of a differ­ent nature. In particular, the number of family 
reduc­tions does not seem to provide a reasonable lower bound to the intrinsic complexity of a A-term. 
Intuitively, Input (h one) (h two) (h three) (h four) (h five) (h six) (h seven) (h eight) (h nine) (h 
ten) user 0.00 s. 0.00 s. 0.00 s. 0.00 s. 0.00 s. 0.02 s. 0.07 s. 0.26 S. 1.01 s. 4.04 s. BOHM tot. inter. 
67 119 204 414 1054 3274 11534 43394 168534 664554 fam. 12 15 18 21 24 27 30 33 36 39 fan-inter. 18 38 
66 110 186 326 594 1118 2154 4214 Carol-Light user 0.00 s. 0.00 s. 0.00 s. 1.02 s. ?? Haskell user 0.00 
s. 0.02 s. 0.18 S. 51.04 s. ?? Figure 14: The function h -- Input (fib 4) (fib 8) (fib 12) (fib 16) (fib 
20) user 0.00 s. 0.02 s. 0.13 s. 0.80 S. 4.78 S. BOHM tot. inter. fam. 265 75 1991 506 13822 3462 94913 
23723 650719 162594 fan-inter. 190 1485 10360 71190 488125 Carol-Light user 0.00 s. 0.00 s. 0.01 s. 0.03 
s. 0.23 S. Haskell user 0.00 s. 0.01 s. 0.06 S. 0.38 S. 3.63 S. Figure 15: Fibonacci Lamping s abstract 
algorithm does not seem to perform any useless operation. Our claim is that the total numb­ er of these 
rules, instead of the number of family reduc­tions, would provide a more reasonable and interesting measure 
of the intrinsic complexity of a A-term. More precisely, we propose to count the total number of anni­hilation 
rules between fans (plus the number of family reductions). Note that, under our assumptions, the two 
complexity measures above turn out to be equivalent (if the term reduces to a constant, all fan, application 
and ~ nodes have to be annihilated, soon or later). More precisely, consider a normalizing computation 
for a term M of the M-calculus that reduces to a constant. Let ~ be the number of family reductions in 
the derivation, d be the number of duplication rules, e be the number of fan-annihilation rules, and 
Iikf I be the total number of application, abstraction and fan nodes in M. Then, obviously, @fl+2*d 2*e-2*~=() 
So, e+j=d+~. There are several motivations to support our claim. First of all, as it was remarked in 
[GAL92a], J and application nodes can be assimilated to fans, and the ~-reduction rule can be seen as 
an annihilation rule be­tween a pair of fans. From this respect, there is no clear reason for giving 
a special status to /?-redexes. The second point is subtler. Using context semantics, it is possible 
to prove that the annihilation rules between fans are in bijective correspondence with the number of 
discriminants for different @-cycles in the kterm4. [AL93, ADLR94]. Rouglhy, a @-cycle is a particular 
kind of looping path inside the argument of an applica­tion. Now, every time we have a discriminant for 
such a cycle (i.e. the cycle is shared), we also have an extra and unavoidable operation that amounts 
to choose the proper discriminant when coming back from the loop. Following [DR95], this extra operation 
(that essentially amount to save a suitable return information in presence of a possible looping situation), 
can be easily recognised in other typical implementation techniques, such as en­ 4 The proof of the bijective 
correspondence between fan­annihilations and discriminants for different @l-cycles will be the subject 
of a forthcoming paper in collaboration with Cosimo Lan­eve. Not e that, in this way, we relate a dynamic 
notion (an in­ teraction) to a static one (et path), This result looks particularly relevant in view 
of complexity issues: computing the number of different paths of this kind is not easy, but it still 
looks simpler than directly computing the number of fan-armihilat ions. vironment machines. Our complexity 
measure has been confirmed so far by all the tests we made on many available implementations of functional 
languages.  Conclusions There are a lot of interesting open problems related to optimal reductions. 
First of all, it looks important to provide a definite upper bound to the complexity of Lamping s abstract 
algorithm in terms of family re­ductions. Secondly, we should understand the complex­ity of what we called 
the oracle . The complexity of this part of the algorithm is actually very different in all the reduction 
techniques proposed so far (see [As95] for a discussion), and it is still a subject of research. As you 
can see by the few examples in BOHM (that is now quite sophisticated from this respect), the complexity 
of the oracle is one of the crucial issues of Lamping s technique. Although, in BOHM, it is clearly not 
linear w.r. t. the number of applications of abstract rules, we have found no evidence so far of an exponential 
explo­sion of its complexity. Finally, from the implentative point of view, the big problem is to understand 
if and how Lamping s algo­rithm could be compiled. Acknowledgements We would like to thank Cosimo Laneve 
for many in­teresting discussions on the subject of this paper. References [As94] A. Asperti. Linear 
Logic, Cornonads, and Opii­mal Reductions. Fundamental In formaticae, Special Issue devoted to Categories 
in Computer Science, Vol. 22, n.1, pp.3-22. 1995. [As95] A. Asperti. 60!E = 1: @timzzinO OPtimal J-calculus 
implementations. Proc. of the Sixth Conf. on Rewriting Techniques and Applications, (RTA 95), Kaiserlautern, 
Germany. 1995. [AGN95] A. Asperti, C. Giovannetti, A. Naletto. The Bologna Opt imal Hzgher-order Machine. 
Techni­cal Report UBLCS-95-9, Laboratory for Computer Science, University of Bologna. To appear in the 
Journal of Functional Programming. [AL93] A. Asperti, C. Laneve. Paths, Computations and Labels in the 
J-calculus. To appear in Theo­ retical Computer Science, Special issue devoted to RTA 93, Montreal. June 
1993. [AL93b] A. Asperti, C. Laneve. Interaction Systems II: the practice of opitmal reductions. Technical 
Re­port UBLCS-93-12, Laboratory for Computer Sci­ence, University of Bologna. To appear in Theoret­ ical 
Computer Science. [ADLR94] A. Asperti, V. Danos, C. Laneve, L. Reg­nier. Paths in the A-calculus: three 
years of com­munications wzthoui understandings. Proceedings of LICS 94. Paris. 1994. [DR95] V. Danos, 
L. Regnier. Reversible and ir­reversible Computations: GOI and J-machines. Draft. 1995. [GAL92a] G. Gonthier, 
M. Abadi, J.J. L&#38;ry. The geom­etry of optimal lambda reduction. Proc. of the 19th Symposium on Principles 
of Programming Lan­guages (POPL 92). 1992. [GAL92b] G. Gonthier, M. Abadi, J.J. L4vy. Linear Logic without 
boxes. Proc. of the 7th Annual Sym­posium on Logic in Computer Science (LICS 92). 1992. [Laf90] Y. Lafont. 
Interaction Nets. Proc. of the 17th Symposium on Principles of Programming Lan­guages (POPL 90). San 
Francisco. 1990. [Lam89] J. Lamping. An algorithm for optimal lambda calculus reductions. Xerox PARC 
Internal Report. 1989. [Lam90] J. Lamping. An algordhm for optimal lambda calculus reductions. Proc. 
of the 17th Symposium on Principles of Programming Languages (POPL 90). San Francisco. 1990. [Le78] J.J.Levy. 
Reductions correctes et opttmales duns le lambda-calcv,l. Th&#38;se de doctorat d &#38;at, Univer­sit~ 
de Paris VII. 1978. [Le80] J. J. L&#38;y. Optzmal reductions m the lambda­calculus. In J.P. Seldin and 
J.R. Hindley, editors, To H.B. Curry, Essays on Combmatory Logic, Lambda Calculus and Formalism, pages 
159-191. Academic Press. 1980. [LM92] X. Leroy, M. Mauny. The Carol Light system, release 0.5. Documentaiton 
and user s manual. IN-RIA Technical Report. September 1992. [Ya94] The Yale Haskell Group. The Yale Haskel/ 
Users Manual. Yale University. October 1994. 
			