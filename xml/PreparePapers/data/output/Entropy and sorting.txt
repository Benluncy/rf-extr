
 Entropy and Sorting Jeff Kahn t Jeong Han Kim : Abstract We reconsider the old problem of sorting under 
par­tial information, and give polynomial time algorithms for the following tasks. (1) Given a partial 
order P, find (adaptively) a se­quence of comparisons (questions of the form, is x < y? ) which sorts 
(i.e. finds an unknown lin­ ear extension of) P using O(log(e(P))) comparisons in worst case (where 
e(P) is the number of linear ex­ tensions of P). (2) Compute (on line) answers to any comparison al­gorithm 
for sorting a partial order P which force the algorithm to use Q(log(e(P))) comparisons. (3) Given a 
partial order P of size n, estimate e(P) to within a factor exponential in n. (We give upper and lower 
bounds which differ by the factor n /n!.) Our approach, based on entropy of the comparability graph of 
P and convex minimization via the ellipsoid method, is completely different from earlier attempts to 
deal with these questions. 1 Background and results The problem of sorting unde~ partial information 
is: *Department of Mathematics, Rutgers University, New Brunswick NJ 08903. tAlso, in Center for OR, 
Rutgers. Partially supportai by grants from NSF(DMS-9003376) and AFC)SR(89-0512 and 90. 0008). :Partially 
suppor+ed by a DIMACS Graduate Assistantship. Permission to oopy without fee all or part of this material 
is granted provided that the oopiea are not made or distributed for direot commercial advantage, the 
ACM copyright notioe and the title of the publication and its date appear, and notice is given that copying 
is by permiaaion of the Aaaociation for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. 24th ANNUAL ACM STOC -5/92/VICTORIA, B. C., CANADA @1992 ACM ().89791-51 
2-71~2/0004/0J78...$J .~() given an unknown total order on a set X = {xl,..., Xn }, together with some 
of the relations xi < xj, detemnine the full order via questions of the form isXi <Xj ?W (1) In other 
words, we are given a partial order, say P, on X and want to determine some unknown linear eztension 
of P (i.e. total ordering of X compatible with P) by means of questions as in (1). We will also call 
such a procedure sorting P by compan sons. (For more detailed discussions see e.g. [7, 20, 12]). Our 
new results are summarized in the abstract, and will be elaborated upon below. We begin here with some 
Background. It ia obvious that any comparison algorithm re­quires log(e(P)) comparisons in worst case, 
where e(P) is the number of linear extensions of P. This is the information theorg lower bound (ITLB). 
(Our logarithms are base 2.) How close the ITLB is to the truth was first consid­ered by M. Fredman [7], 
who showed that sorting can be achieved with log(e(P)) + 2n comparisons, where n = 1P1. (So in particular, 
the ITLB is nearly sharp unless e(P) is quite small.) In fact, Fredman showed much more generally that 
one can choose from among any collection I of per­mutations of X using no more than log II I + 2n com­parisons. 
As he remarks, construction of hk algo­rithm requires considerable enumerative information about the 
set I : it is practicalti only if we ignore all costs other than comparisons. At about the same time, 
Fredman raised the by now well-known conjecture that if P is not a linear order, then it contains elements 
z, y with 1/3s P(Z < V)s 2/3, (2) where p(z < y) denotes the fraction of extensions in which z precedes 
y. (This conjecture was later independently proposed by Linial [20]. That the value 1/3 is best possible 
is shown by the poset with three elements and one relation.) The point of this, of course, is that it 
shows the ITLB is sharp up to a constant factor, since an algorithm which always compares z, y satis­fying 
(2) sorts with no more than log~iz e(P) = (log(3/2))-l log(e(P)) comparisons. Furthermore (also of course), 
the exact bounds of (2) are not needed for this: any result which replaces (2) by 6<p(z<y)<l 6 (3) with 
6>0 constant gives the same application (with (log(3/2))- replaced by (log(l/(l -6)))- ). Such a result, 
with 6 = 3/11, was proved in [12], and simpler proofs, with somewhat smaller 6 s, were given in [14], 
[11]. (See also [15, 8] for more on this problem.) All of the arguments [12, 14, 11] are geometric: that 
of [12] depends on the Aleksandrov-Fenchel in­equalities, while the later ones use the simpler (but less 
precise) Brunn-Minkowski Theorem (see e.g. [2]). The opening to geometry is given by the observation 
(seemingly due to Linial [20]) that the volume of the order polytope O(P) := {(01,.. .,~m) G [0, 1]~ 
: Xi <p Zj *Vi < Uj} is just e(P)/n!, and that a comparison which splits extensions (in the sense of 
(3)) is the same thing as a hyperplane vi = vj with at least L$of the volume of O(P) on each side. Though 
it does resolve the question of the ITLB s accuracy, the O(log(e(P))) comparison algorithm whose existence 
is established by [12] suffers from the same drawback as Fredman s original approach: Jind­ing the comparisons 
has to date remained computa­tionally infeasible. On the other hand, the recent probabilistic algo­rithms 
for volume computation beginning with [6] do provide a means of finding the comparisons if one al­lows 
randomization. (For example, one can identify a good comparison by simply estimating the volumes of O(P) 
and its intersections with the positive sides of the various hyperplanes vi = vj; but see [13] for a 
more efficient procedure. Note that the validlty of these algorithms still depends on the theorems men­ 
tioned above.) Results In this paper we show that it is indeed possible to sort with only O(log(e(P) 
) ) comparisons and to find the comparisons in (deterministic) polynomial time. We also give polynomial 
algorithms for (a) computing (on line) answers to any sorting algo­rithm which force it to use f2(log(e(P))) 
comparisons, and (b) estimating the number of extensions of a given P to within an exponential (in 1P[) 
factor.  Whether (b) was possible haa also been an open ques­tion for a number of years. As far as we 
know, it was first proposed by Gary Miller in the early 80 s (see e.g. [22]). The approach we take, though 
still geometric, is completely different from those mentioned above. In particular, our sorting algorithm 
will not always be making comparisons which substantially decrease the number of extensions (though clearly 
it will necessar­ily be doing this much of the time). The central notion is that of the entropy, H(P), 
of the chain polytope of P (definitions in Section 2). The main developments are as follows. We first 
establish a fairly close relationship between the ITLB and the quantity n(log n H(P)) (note H(P) < log 
n, with equality exactly when P is a chain): Theorem 1.1 For any P, n(logn -II(P)) ~ log(e(P)) ~ max{log(n!) 
-nH(P), Cn(logn H(P))}, (4) where C = (1 +710ge)- w .09. We then show, first, that there is always 
a compari­son which forces an il(l/n) increase in entropy (The­orem 1.2), and second, that any comparison 
may be answered so as to limit the increase in entropy to 0(1/n) (Theorem 1.3). For precise statements 
we write P(z < g) for the poset generated by (i.e. the transitive closure of) P and the relation x < 
y. Theorem 1.2 In any P not a chain there em st x, y incomparable such that min{17(P(z < y), H(P(y < 
z)} ~ H(P) + c/n, (5) where c = log(l + 17/112) % 0.2. Theorem 1.3 For any P and any incomparable z,y 
EP, min{17(P(z < y), II(P(y < z)} ~ H(P)+ 2/n. (6) (The 2/n in Theorem 1.3 is sharp; we don t have a 
guess as to the best c in Theorem 1.2.) To derive our algorithmic results from Theo­ rems 1.1-1.3 it 
is only necessary to point out that H(P) is computationally manageable: Theorem 1.4 The~e is a polynomial 
time algorithm for approximating H(P) to within (sag) n-2. This is so because H(P) is the minimum of 
the convex function on a polytope (a slight truncation of the chain poly­tope) for which separations 
are easy to compute and on which the variation of f is not excessive. Estimat­ing H(P) is thus a problem 
which can be handled by the methods of [10]. In section 2 we review what we need in the way of graph 
entropy, and sections 3-5 are devoted to the proofs of Theorems 1.1-1.3.  2 Entropy From now on, P is 
a partial order on the set V = {xi,..., Zn }. (We replace X by V because it will often be the vertex 
set of a graph.) Graph entropy was introduced by Ktirner [16]. There are at least three (equivalent) 
definitions two from [16], and the third due to Csisz&#38;r et. al. [4] -of whkh the last is most convenient 
for our purposes. Recall that the vertex packing polytope, VP(G), of a graph G on V is conv{ 1A : A G 
V independent}, The chain pdytope (the name is from [21]) of P is just VP(P) := VP(G(P)), where G(P) 
is the compara­bility graph of P (i.e. the graph on V with ~, * Zj iff xi and Zj are comparable in P). 
(Equivalently (be­cause G(P) is perfect; see e.g. [9, 3]) VP(P) consists of those g c [0, l]n for whkh 
~iE1 vi < 1 whenever {xi : i ~ 1] is a chain in P. This is the definition of chain po~e given in [21].) 
We also write VP(F) for VP(G(P)). For probability distribution p on V, the graph en­tropy of G with respect 
to p is H(G, p) = min p, 10g a,. (7) -k acV~(G) ~_l When p is the constant vector I/n we abbreviate this 
to H(G). As noted in [4], it is not hard to see that the min­imum in (7) is always atileved and finitq 
the rnini­rnizing vector a is a convex combination of indicator vectors of maximal independent set% and 
the ith co­ordinate of a is uniquely determined provided pi >0. (Actually the discussion of [4] is more 
general, con­cerning the entropy of a convex corner, i.e. a convex K ~ (?8+) satisfying QSIL SQEK*Q GK.) 
We write G(P) (as above) for the comparability gra~h of P, and set H(G(P)) = H(P), H~~) = H(P). We also 
write a(P) and b(P) = a(P) for the vectors achieving H(P) and H(3. It is obvious that entropy is monotone, 
that is, if F ~ G are graphs on V (containment is as sets of edges), then H(F) < H(G). (8) That it is 
also subadditive was shown by K&#38;ner [17]: Theorem 2.1 For any two graphs F, G and proba­bility distribution 
p on V, H(F U G,p) < H(p,p) + ~(G,p). (9) In particular, since H(G U ~, p) = H(p) := xi pi logpi, we 
have H(G, p) + H(G, p) ~ H(p). (lo) On the other hand, it was conjectured in [18] and proved in [4] that 
Theorem 2.2 A graph G is perfect if and only if H(G,p) + H(~,p) = H(p) foT every probability distribution 
p. In particular, since comparability graphs are perfect, we have H(P) + H(p) = log n (11) for every 
P. From this, using the fact that ~ aibi <1 whenever a c VP(G), b c VP(@, one easily deduces (see[4]) 
ai(P)bi(P) = l/n Vi. (12) There is a useful representation of a(P) based on Dilworth s ordering (from 
[5]) on the set d of maxi­mal antichains of P. Recall that for X, Y maximal antichains of P, this ordering 
sets X + Y if Vzex 3ye Y, y>pz. (Or equivalently every y G Y is ~ some z c X.) It s easy to see that 
this is a partial order. Lemma 2.3 There is a unique representation with wj > 0,~wj = 1and Al + ... 
+ AT distinct mazimal antichains of P. Proof. We first prove existence. Note that in any representation 
a= wA 1A (14) x of a := a(P) as a convex combination of (indicator vectors of) antichains A, all A s 
in the support of w must be maximal, since expanding any of these antichains gives a strictly better 
a. Given a representation as in (14), choose, if possi­ble, A, At incomparable under + with O < wA ~ 
U)AI. (If no such choice exists, then (14) is the desired rep­resentation.) Let B = min(A U A ), B = 
max(A U A )  (where min X and maxX are the sets of minimal and maximal elements of X ~ P). Then B, B 
are an­tichains, and each element of P appears the same number of times in B, Bt as in A, At. Thus with 
w! given by WC WA if C= Aor A w~ = wc +wA ifC= Bor B Wc otherwise, { ~w~lC again represents a as a convex 
combination of (necessarily) maximal antichains. This will com­plete the proof of existence provided 
we can show this procedure doesn t cycle. One way to see this is to fix a linear extension x of +, and 
order functions u : A ~ $2+ lexicographlcally : u < u if u~ < uc with C the least element (under cc) 
of A for which U&#38; # Uc. It s then clear that with w, w as above, we havew < w . We now turn to the 
proof of uniqueness. This does not even require the assumption ~ Wi = 1. We show more generally that 
Proposition 2.4 Any a : P + $?+ has a unique rep­resentation of the form with Wi > 0 and Al + . . . < 
At distinct maximal aniichains. We call this representation the laminar decomposition of a, Proof. Suppose 
we have a representation as in the Proposition. Let P+ = {z GP:a(z)>O}, A= rnin(Pt) ~ Al and a = min{a(z) 
: z c A}. Then A1=A, W1= (Y. (15) For suppose first that Al # A, and let z c A \ Al. Then x c Ai for 
some i > 1, contradicting the assumption Al < Ai. If instead, Al = A but W1 = /3 < CX,then ~~=z wi lAi 
is a laminar decompo­sition of the function at : P b W+ given by a(z) /3 ifz CA a (x) = a(x) otherwise, 
 { and the same argument again gives a contradiction. The proof by induction (on [P+ 1, say) is now completed 
by observing that for Al, WI as in (15), ~~=1 wilAi is a kninar decomposition of a if and only if ~~_2 
wilAi is a laminar decomposition of the function a~: P * W given by a(x) a if#EA a (x) = a(x) otherwise. 
{ o Remark Notice that the proof of Proposition 2,4 gives an easy algorithm for finding the laminar 
de­composition of a. Notice that, with the notation of the lemma, if we set For if not, then there is 
j strictly between cw and @ such that Xi @ Aj. Since Aai + Aj + A@i there exist z~Aj and ~~Api sothat 
Zi < x s y. Thus {Zi < ~} is a subset of the antichain Api, a contradiction. In the sequel Aj, wj, ~i 
and pi are aS given above.  3 Bounds Here we prove Theorem 1.1. We make use of the fact, proved by Stanley 
[21], that VP(P) and O(P) have the same volume, whence vol(VP(P)) = e(P)/n!. (17) The upper bound and 
first half of the lower bound in (4) are thus equivalent to ;2- ~@9 > VO1(VP(P)) ~ 2- H(P). (18) Proof. 
Let a = a(P). Then since VP(P) is a convex corner, WO1(V.P(P)) ~ ~ a~ = 2- H(P). i On the other hand, 
according to (12), b = b(F ) is given by bi = l/(nai), so that n VP(P) c L := {(~lj ....~n) : si ~ O, 
sibi ~ 1] x i=l implies WO1(V.P(P)) < WO1(L) = ~ ~ ai = $2- H(P). i c! Notice that these quite easy 
inequalities are already enough to settle the problem of estimating e(P) men­tioned in the introduction. 
To derive an O(log(e(P))) sorting algorithm from Theorem 1.2, we must show that n~(~) = O(log(e(P))~ 
(note we replace the left hand side of (4) by nH(P) using (11)). The lower bound in (18) gives such a 
bound unless e(P) is quite small; namely, if loge(P) z cn, with c >0 constant, then nlt(~) < ((c+ loge) 
/c) log(e(P)). (19) Strangely (or perhaps not, since this is where Fred­man s algorithm fails to be O(log(e(P)))), 
instances with e(P) small require more work. This is the other half of the lower bound in (4): nlf(~) 
< (1 + 7 loge) log(e(P)). (20) For the proof of this we require a few preliminaries. We write x -y if 
x, ~ are comparable in P, and denote {1, .... q} by [q]. Fix a maximum length chain CofP,sayC={xi,..., 
x1},andletT=P\C = {VI , . . .. IA}. Define K(j) = {i G [1]:%# !/j}, lK(~)l = kj f (j) = min{iE [1]: w 
> vi}, :i:ao:to+ 1 g(j) = max{i C [1] : ~i < Yj}, u(i) = {j E [t] :f(j) = i}, Iu(i)l = u~ V(i) = {j ~ 
[t] :g(j) = i}, lV(i)l = Vi Note kj >0 for all j = 1, ....t since C is a maximal chain. Lemma 3.1 If 
t < n/7 and P has no cut point (cl­ement comparable to all others), then theTe is j @ [t] such that kj 
>3 and Proof. Suppose this is false, and consider a minimal T c T for which   u Kj = [1] . j:yj ET 
 We may assume T = {yl, .... y,}. By our assumption we have igK(j) so ~ ~( i+vi)z~kj-zT. j~[r] iEK(j) 
j E[r]  But the right hand side here is at least 1 2t (since Ujc[.l Kj = [~]), while the left hand 
side is at most ~ic[~] z(~i + vi) S 4$ (since the rninirnaM of T im­plies that no i is in more than two 
of K(l), .... K(T)). This gives 6t ~ 1, contradicting the assumption t< n/7. o Lemma 3.2 Sappo$e P has 
no cutpoint and (as a set of relations) is maximal with given entropy. Then if t < n/7 there exist j 
c [t] and i c [1] such that P := P(Xi < Yj < Xi+I) satisfies e(P ) ~ (kj l)-le(P) and nH(F) ~ nlf(~ 
) + 210g(2kj + 1) . Proof. Let Yj be as in Lemma 3.1 and Kj = {~h < ... < z~}. Choose i 6 {h, ....m 
1} with e(P(z~ < yj < Zi+l)) P7 (Z~ < Yj < Zi+~) := e(P) minimum, and set P = P(~i < yj < ai+l). Then 
clearly e(P ) ~ (kj l)-le(P). On the other hand, the maximality of P implies that Pt differs from P 
only in the at most 2kj new relations involving ~j (cf. (21)), whence, according to Theorem 2,1, nH(F) 
< nH(P ) + (2kj + I)H(&#38;) .? < nH(F ) + 2 log(2kj + 1) (where H(z) := z log z (1 z) log(l z) is 
the entropy function). c1 Proof of (20). We may, of course, assume that P is maximal with given entropy. 
We retain the notation introduced above and induct on n and t, the result being obvious if either n = 
1 or t = O. We assume therefore that n > 1 and t > 0. If P has a cut~oint x, then we finish bv induction 
since n~(~) =-(n 1) H(P \ {z}) and e~P) = e(P \ {x}); so we assume th is is not the case. We next observe 
that the easy inequality e(P) z 2t allows us to as­sume t < n/7, since otherwise (20) follows from (19). 
We now have the hypotheses of Lemma 3.2, so also its conclusion. Since (inducting on t), (20) is true 
for n.H(~) + 210g(2kj + 1) (1+ 710ge) loge(P ) + 410g(kj + 1) (1+ 710ge) loge(P) +(8 (1 + 710ge)) log(kj 
 1) (1+ 710ge) loge(P). completing the proof. o There are various possibilities for extending the lower 
bounds here, of which we mention just one: Conjecture 3.3 If 1 = l(P) is the length of a longest chain 
in P, then WO1(VP(P)) ~ @/l!)2-~~@). This would improve the constant in (20) to 1 + loge. Notice it is 
tight for any union of a chain and an ant ichain.  Offense Here we prove Theorem 1.2. To put the task 
of lo­cating a good comparison in some perspective, let us first mention two curious examples: Suppose 
P consists of two disjoint and unrelated chains of size k = n/2. Comparison of the minima of the two 
chains then turns out to be a good comparison in our sense, forcing an entropy increase of about l/n. 
But comparison of the middle elements is not good it gives only an O(n-2, increase even though it splits 
the extensions perfectly. On the other hand, suppose P is the poset on {z~,..., ak, y~, yk., yk } (n 
= 2k) with relations Zi < Yj iff i = ~or i = 1. Then the comparison al :Z2 is good in our sense, but 
does a poor job of splitting extensions. For the proof of Theorem 1.2, it s more natural to work in the 
complement, showing that we can de­c~ease ~(~) by some specified amount (say c), since for this we only 
need to exhibit some b E VP(F) for which (with P the new poset). To this end, if the new covering relation 
is xi < xj, we modify the weight function on chains which gives b = b(P) by transfer­ring some fraction 
(say p) of the weight on each chain B (of P) containing Xj to a chain (of P ) obtained by replacing the 
portion of B below ~j by a chain with largest element z~. The effect of this procedure is quantified 
in Lemma 4.1 For any incomparable ~i, Xj c P and p c [0, 1], the entropy of P = P(ai < aj) satisfies 
,. nH(P ) ~ nH(P) + 10g(l + p ~ Wk/Uj) k=l Cl; -l _t-10g(l p ~ lf&#38;/Uj). k=l (assuming the right 
hand side is defined). Proof. Let s b = b(P) = ~ ZmlB~ ?n=l with Bl, ..., B, chains of P and xj E B~ 
iff m c [t]. Also, denote and for m E[t] C~=Brn\{XEP:X<Xj}. NOW fix a chain C = {zil < ... < Zi, = Xi} 
such and that ~ bq,jlbq = n ~ ~qbq,j qZXq<Xj q2q<Xj (22)  bp=fk nE E kbqi p=l k=l and consider the 
chains B~ and weights z~ given by where the inequality holds since Ak is an antichain. Therefore, (That 
is, we transfer a p-fraction of the z-weight of each B~ containing xj to the associated chain C U nH(P 
) nH(P) ~ log(l + @j ~ l/bq) Cm.) Then q:irqcc +log(l ~ ~ bq,j/bq) is easily seen to satisfy +log(l 
 /.m ~ wkbj) k=l bq + Nbj bq,j) ifcg EC 6, b: = b; = bq pbq,j if Zq@C, Xq<Xj = log(l + p~wk/aj) bj 
= bq otherwise. k=l { Clj-1 Thus by the definition of H(P), we have nH(P ) nH(P) = nH(~) nH(P~) 1 
n 2 -~(logb, -logb~) gal Also, we need the following easy lemma. a ~ Iog(l +@j/bq) q:xqcc Lemma 4.2 Given 
O < .S1,E2 < 1, choose i with ai as large as possible subject to + ~ log(l @q,j/bq) q:xq<5j LY;-1 ~ 
log(l + @j ~ l/h) wk ~ Elai q:zqEc x k=l +log(l _ ~ ~ bq,j/bq) qXq<Xj and let t be the smallest number 
for which where in the second inequality we use log(l + u V) ~ Iog(l + u) + log(l -v) for nonnegative 
real numbers u, v, and in the third inequality we inductively use log(l + u) + log(l + v) ~ log(l + u+ 
v) for all real Then for any xj c A \ {xi},numbers u, v with uv ~ O. On the other hand, using aibi = 
l/n and (12), El+ &#38;2 aj < a~ . .51 Proof. If aj s ai then we are done. Suppose aj > ai. Then by 
the choices of a; and t 2 ffj ~j-l .51Uj <~wk k=l ~i-l wk+ -x k=l < elai + JSzfli . D Proof of Theorem 
1.2 Notice first of all that we may assume P has no cut point, since if it does then the Theorem follows 
by induction using the fact that (for any cut point z) nH(P) = (n l)l?(P \ {z}) . For S1 = 1/4, .52 
= 1/3, take xi, xi as in Lemma 4.2. Also, let d := ~~&#38;l_l wh/ai s .s1. Then by Lemmas 4.1 and 4.2, 
for P = P(zj > zj) and A nlI(P ) nH(P) ~ 10g(l + p ~ wk/aj) k=l Crj-1 +bg(l /J ~ Wk/aj) > Iog(l + 
p(15 + 1;:) On the other hand, for P = P(xj > ~i) and p = 1, Lemma 4.1 and the choice of xj imply .. 
nH(P ) nH(P) ~ log(l + ~ Wk/Ui) k=l CYJ-l + 10g(l ~ Wk/Ui) k=l ~ log(l +(:+C2))+1%(1 4 completing 
the proof. o Remark As shown by the poset with three elements and one relation, the value of c in Theorem 
1.2 cannot be increased beyond 3 log 3 4 R .755. 5 Defense Here we prove Theorem 1.3. The reader may 
check that the Theorem is sharp whenever z, y are isolated elements of P. The proof of Theorem 1.3 is 
again based on the laminar decomposition of a(P). The ef­fect on this decomposition of adding a relation 
z < Y is that some of the Al s may no longer be antichains (in the new partial order). However when this 
hap­pens, because of the nature of the decomposition, at least one of Al \ {x}, Al \ {y} will be an antichain. 
The proof consists of showing that for at least one of the answers to the comparison z : y we may mod­ify 
the decomposition by such deletions to produce an at in the chain polytope of the new poset with -(l/n) 
~ loga~ ~ H(P)+ 2/n. (In most cases, the correct procedure is to replace Al by the two an­tichains Al 
\ {x}, Al \ {y}, dividing the weight WI between them.) For the proof we use xl and X2 in place of x and 
y, and retain the nOtatiOni3 Ak, Wk, c% and f?h used earlier. Proof of Theorem 1.3. Without loss of generality 
we may assume al s cq. We consider three cases. Case 1:az>f% Set P := P(z2 > *1). Then for all xk < ZI 
and xl z X2, we have Thus Al, .... A. are still antichains of P . This implies I?(P ) = H(P) . A~=A~\{xl}, 
A#=A~\{2n} ifaz~m~~l AL = A. otherwise. Since the sets defined above are antichains of P . Now de­fine 
w by I_ifcrz~m~fll Wm w; = win/2 w: = w~ otherwise. Then belongs to VP(P ) and satisfies a; ~ al/2, 
a; ~ a2/2 Therefore, and a: =akif k# 1,2. Thus w(K) + w(N) + (al + a2)/2 <1 (23) or w(L) + w(M)+ (al 
+ a2)/2 ~ 1. (24) Without loss of generality we may assume that (23)Case 3:q <a~<fl~<fl~. is true. It 
is enough to show that the vector a with Without loss of generaMy, we may assume (Zi/2 ifi=l,2 a; = ai 
otherwise { k=cq k=~z+l is in the chain polytope of Pt := P(z1 < 22). Suppose Q is a maximal chain of 
P . If {XI, x2} Q Q then it Again set P = P(z2 > *1) and is easy, by maximality of Q, to see that Q 
is a chain of P. Thus a: ~ ai for all i implies Since for all %k < xl and %1> ZZ, we have If {zl, Z2} 
G Q then set K ={XEQ:Z<p# Xl), N ={x~Q:x>p, z2}. the sets defined above are antichains of Pt. Now de- 
Note that K C U, N C Z are chains of P and fine w by Q = K UN U {zl, Z2} since there is no element z 
such that xl <p, z <p, X2. Therefore by our choices ofK and N, wehave Then the vector w (Q) = w (K ) 
+ w (N ) + al/2+ a2/2 = IO(K ) + w(N ) + al/2+ a2/2 < w(K)+ w(N)+ al/2+ az/2 <1. belongs to VP(P ) and 
satisfies a{ ~ al/2, a~ = a2/2 o and a~=akif k# 1,2. Thus Let us also just mention that in the case 
of ordi­nary sorting (i.e. starting from an antichain) or more generally, in any situation where we 
know a(P) for the initial poset P -we get the algorithmic ap­plication (that is, forcing fl(log(e(P))) 
comparisons) o without recourse to the ellipsoid algorithm, by main­taining some good, though not necessarily 
optimal,Another Proof of Theorem 1.3. Set a E VP(P ) (with P the evolving poset). U={ XEP:X<ZIJ v={z 
GP:x>x~} Acknowledgments Thanks to Leo Khachiyan for W={ ZEP:2 <X2}, z={xc P:x>x~} acting as separation 
oracle oracle. The idea that en­tropy might have something to do with comparisonand choose a chain K 
~ U of P with the weight algorithms was first suggested to us by Ravi Bop­pana s elegant lower bound 
argument in [1]. as large as possible. Similarly, choose chains L ~ V, References M ~ W and IV ~ Z with 
msximum weights. Then [1] R. Boppana, Optimal separations betweensince the chain polytope of P is VP(P), 
 concurrent-write parallel machines, Proc. 21st w(K) + w(L) + al <1 Annual ACM Symposium on Theory of 
Comput­w(~) + w(~) + az ~ 1. ing (1989), 320-326. [2] H. Buseman, Convex Surfaces, Interscience, New 
[17] York, 1985. [3] V. Chv4tal, On certain polytopes associated with graphs, J. Combinatorial 2%. B 
18 (1975), [18] 138-154. [4] I. Csiszi4r, J. K&#38;ner, L. Lov&#38;sz, K. Marton and  G. Simonyi, Entropy 
splitting for antiblocking [19] corners and perfect graphs, Combinatom ca 10 (1990), 27-40.  [5] R.P. 
Dilworth, Some combinatorial problems on partially ordered sets, Proc. AMS Symposia in  [20] Appl. Math 
10 (1960), 85-90. [6] M.E. Dyer, A.M. Frieze and R. Kannan, A ran­dom polynomial time algorithm for approximat­ 
 [21] ing the volume of convex bodies, PTOC. 21st An­ nual ACM Symposium on Theory of Computing (1989), 
375-381. [22] [7] M.L. Fredman, How good is the information the­ory bound in sorting?, Theoretical Computer 
Sci­ence 1 (1976), 355-361. [8] J. Friedman, A note on poset geometries, [9] D.R. Fulkerson, On the 
perfect graph theorem, pp. 69-77 in Mathematical Programming (T.C. Hu and S.M. Robinson, eds.), Academic 
Press, New York, 1973.  [10] M. Gr6tschel, L. Lovilsz and A. Schrijver, Geo­metm c Algorithms and Combinatorial 
Optimiza­tion, Springer-Verlag, 1988. [11] J. Kahn and N. Linial, Balancing extensions via Brunn-Minkowskl, 
Combinatorics 11 (1991), 363-368. [12] J. Kahn and M. Saks, Balancing poset exten­sions, Onfer 1 (1984), 
113-126. [13] A. Karzanov and L. Khachiyan, On the conduc­tance of order Markov chains, OTdeT 8 (1991), 
7-15. [14] L. Khachlyan, Optimal algorithms in convex pro­gramming, decomposition and sorting, in Com­puters 
and Decision Problems (Ju. Jaravlev, cd.) Moscow, Nauka, 1989, pp. 161-205 (Russian). [15] J. Kornh.ts, 
A strange pigeon-hole principle, OT­deT 7 (1990), 107-113. [16] J. K6rner, Coding of an information source 
having ambiguous alphabet and the entropy of graphs, Trans. 6th PTague Conf. information Th. etc. (1973) 
411-425 ..) 187 J. K6rner, Fredman-Kom16s bounds and infor­mation theory, SIAM J. Alg. Disc. Meth. 7 
(1986), 560-570. J. K6rner and K. Marton, New bounds for per­ fect hashing via information theory, EUTOp. 
J. Combinatorics L. Lov&#38;sz and M. Simonovits, The mtilng rate of Markov chains, an isoperimetric 
inequality, and computing the volume, Pmt. 81st IEEE Symp. Found. Comp. Sci. (1990), 346-355. N. Linial, 
The information theoretic bound is good for merging, SIAM J. Computing 13 (1984), 795-801. R.P. Stanley, 
Two poset polytopes, Disc? ete and Computational Geom. 1 (1986), 9-23. W.T. hotter, Problems and conjectures 
in the combinatorial theory of ordered sets, Ann. Dis­crete. Math. 41 (1989), 401-416.  
			