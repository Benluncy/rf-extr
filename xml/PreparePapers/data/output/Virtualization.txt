
 Virtualization, Virtually at the Desktop Karissa Miller Ringling College of Art and Design 2700 North 
Tamiami Trail Sarasota, FL 34234 941-359-7633 kmiller@Ringling.EDU ABSTRACT We have witnessed low resource 
utilization of high performance graphics workstations in our instructional computer laboratories. The 
low utilization statistics indicate that workstation consolidation could achieve great savings in infrastructure, 
networking, power consumption, and maintenance costs. In addition, we would spend less time in deployment, 
security, and fault isolation without compromising performance. The basic enabler for workstation consolidation 
in our instructional computing environment is the ability to allow multiple separate operating system 
instances and associated software packages to share a single hardware server. We have successfully utilized 
existing off the shelf products and developed tools and protocols to migrate processing tasks from the 
desktop level to the virtual desktop level running on remote hardware and returning the processing results 
back to the desktop level for display. Since all processing is done at the server level, we no longer 
need high performance graphics workstation class machines at the desktop. This allows us to offer high 
performance graphics workstation capabilities to any desktop, including lower­end commodity class desktop 
machines, notebook computers, or even thin-clients. While server consolidation through virtualization 
is not new, desktop workstation virtualization seemed a natural and novel extension of the server virtualization 
framework. Indeed, the general trend is towards applying virtualization techniques to almost all Information 
Technology infrastructure machinery, and we should expect to see more virtualization, virtually everywhere 
in higher education institutions. In this report, we will present our approach, framework, implementation 
challenges, lessons learned and next steps. Categories and Subject Descriptors C.2.4 [Distributed Systems]: 
Client/server. C.2.4 [Distributed Systems]: Distributed applications. D.2.7 [Distribution, Maintenance, 
and Enhancement]: Portability. K.6.4 [Systems management]: Centralization/decentralization. K.8.3 [Personal 
Computing]: Management/Maintenance. Permission to make digital or hard copies of all or part of this 
work for personal or classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation on the first 
page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee. SIGUCCS 07, October 7-10, 2007, Olando, Florida, USA. Copyright 2007 
ACM 978-1-59593-634-9/07/0010 $5.00. Mahmoud Pegah Ringling College of Art and Design 2700 North Tamiami 
Trail Sarasota, FL 34234 941-359-7633  mpegah@Ringling.EDU General Terms Management, Performance, Design, 
Reliability Keywords Desktop Virtualization, Virtualization, Resource Utilization, Funding, Academic 
Computing, Notebook Computer 1. INTRODUCTION In an environment where the gap between available resources 
and the demand for Information Technology (IT) resources is widening and IT organizations are continually 
asked to do more with less, server virtualization has become a viable option for server consolidation 
and has produced demonstrated cost savings results. By applying similar protocols and framework to the 
consolidation of high performance graphics workstations, desktop virtualization has the potential to 
offer a new, cost efficient paradigm shift to ease the demand for IT resources while maximizing return 
on investment. Combining the potential cost savings with other advantages such as disaster recovery, 
robustness, scalability, and security make this an attractive computing model to deploy. For the fifth 
time in the last seven years, funding Information Technology (IT) is once again topping the list of strategic 
IT issues in the EDUCAUSE annual Current Issues Survey of IT leaders [4]. Accompanying the focus on funding 
is an increasing drive for improved productivity and better use of new and existing resources. One innovative 
approach to meeting these demands is using of off the shelf solutions to extend the life and improve 
the performance of notebook computers and high performance graphic workstations. 2. RATIONALE Ringling 
College of Art and Design is entering the second year of a student notebook computer program. Notebook 
computers that were new for fall 2006 are now entering their second year of active life. At the same 
time, the students are also moving forward in their curriculum. As Ringling College continues to be the 
leader in the use of technology in the design and art curriculum, this naturally leads to greater demands 
for computing resources. Therefore, we are faced with the challenges of refreshing our hardware and the 
demand for higher performance. Rather than resort to the great expense of refreshing all of these notebook 
computers at the end of their second or third year in the field, we are investigating alternative solutions 
for addressing this issue. Over the last decade, Ringling College has maintained a better than 2 to 1 
student to high performance graphics workstation ratio and a very attractive workstation refresh cycle, 
replacing high end graphics workstations every year or two. Innovative approaches supporting this refresh 
cycle include moving this equipment from areas of highest resource utilization to those with easy demand 
on processing. For example, workstations are utilized in several different academic labs and faculty 
offices with varying performance requirements before being deployed in the administrative offices several 
years after their initial use. This refresh model often provides upgraded workstations for programs that 
are facing limited funding, offering them access to higher performance resources without great expenditures. 
While our hardware refresh model has broadly supported and enhanced use of our information technology 
resources, we are looking at taking our current desktop computing model to the next level. Moreover, 
the utilization data of the high end graphics workstations in our instructional computing laboratories 
indicates that even when a user is logged in and actively using the system, there is often low utilization 
of the workstation resources such as the total processing power. Users are not fully utilizing the memory, 
processor, network, graphics card, and other resources. The low utilization data further indicates that 
workstation consolidation is feasible and has the potential to achieve great savings in total cost of 
ownership. Furthermore, we will reduce the total cost of ownership without any performance compromise. 
Recognizing this opportunity to refine our computing model, the exciting challenge before us was finding 
a framework to successfully consolidate our high performance graphics workstations and extend the useful 
life of campus notebook computers. 3. VIRTUALIZATION 3.1 Overview Virtualization has a long history, 
starting in the mainframe environment in the 1960 s and arising from the need to provide isolation between 
users. The recent server virtualization trend started with a single expensive server class computer system 
and the need to enable multiple applications to share server resources. This supported the idea of processes 
that belong to a single application running on their own virtual environment. This approach has been 
applied in a variety of ways in recent years. A few broad categories summarize the major trends: hardware 
virtualization, operating system virtualization and application virtualization [12, 18]. Hardware virtualization 
gives different operating systems the ability to share resources by emulating the underlying hardware 
using a layer of software [18]. Operating system virtualization works at the kernel level of a single 
operating system instance, creating discrete isolated virtual machines [18]. Application virtualization 
decouples applications from the operating system, allowing them to run as network services [12]. Server 
virtualization has become wildly popular in recent years, being called a mega-trend [11] and becoming 
mainstream [5]. Projections for industry growth continue to be raised and Gartner reports that virtualization 
will be the most important technology in IT infrastructures and operations up to 2010, dramatically changing 
how IT departments manage, buy, deploy, plan and charge for their services. [7] However, deciding that 
virtualization could be an appropriate solution is just the first of many decisions. Virtualization is 
not a single, specific solution. Rather, it is a collection of approaches and specific tools that vary 
greatly. Many considerations shape a virtualization solution. Decisions regarding the best solution can 
be influenced by factors including available management tools, virtualization level, performance, density, 
platform support, migration options, resource management, and isolation and security [18]. 3.2 Desktop 
Virtualization Extending the life of campus notebook computers and consolidating high end graphics workstations 
share key characteristics that lend themselves to a solution that involves virtualization. A notebook 
computer that is aging can be used simply as display and keyboard/mouse device, connecting to a remote 
session running on a server. Even a new notebook computer in the field can be augmented by remote access 
to specific, high end applications that are aren t always needed, don t run on the native operating system, 
or have performance requirements beyond the capacity of the local system. For high end graphics workstations, 
consolidation seeks to migrate processing load from multiple high end workstations to enterprise class 
servers in the data center. As with a notebook computer, the local interface, perhaps a thin-client or 
lower-end commodity class workstation, serves as the display and mouse/keyboard device. In both cases, 
we are looking to offload the work from the local station and provide a desktop environment to users 
remotely. Rather than stack up a collection of workstations in the data center and provide remote access 
on a one-to-one basis, desktop virtualization utilizes virtualization techniques to consolidate multiple 
desktop workstations onto a single server. VMware, an industry leader in virtualization technologies, 
has created an alliance of vendors and service providers that support what they have coined the Virtual 
Desktop Infrastructure (VDI) [21]. VDI is a server-based computing offering that provides desktop environments 
as an enterprise hosted service [20]. The core of the VDI initiative is VMware s ESX server technology 
which provides hardware virtualization. Multiple separate operating system images and associated software 
packages share a single hardware server. Each instance is called a virtual machine (VM). For example, 
a VMware ESX server might host Microsoft Windows XP, Microsoft Windows Server 2003, Windows Vista, and 
Linux virtual machines at the same time. In its simplest form, each user can connect to a specific virtual 
machine using some kind of remote desktop protocol. However, having a dedicated virtual machine for each 
user is often impractical, unnecessary and cumbersome. Therefore, VDI solutions normally include some 
kind of connection broker to connect users to available VM s. Connection brokers are a part of a rapidly 
developing suite of management tools that can help minimize the support overhead of a VDI solution. Management 
tools may include services to connect users to the correct pool of VM s, determine which VM s are in 
use, locate active users, automatically reconnect disconnected remote sessions, provision additional 
VM s on demand, take VM s offline for testing, updating or troubleshooting, remotely relocate, reboot 
and reset running and offline VM s, anticipate performance issues or equipment failures, monitor performance, 
and perform load balancing. It is helpful to compare and contrast VDI with previous generations of remote 
desktop solutions. Server Based Computing (SBC) is one solution that has developed over the last 10 years, 
providing applications and desktops to users [6]. Users connect to a remote server, sharing a single 
instance of an operating system and applications. The application access is increasingly seamless, providing 
users an illusion that they are working on the application locally even though it is executing on the 
remote server. Rather than each user getting a VM to themselves, users share connections to the server 
operating system and installed applications. Citrix Systems has coined the Dynamic Desktop Initiative 
(DDI) to contrast VMware s VDI. DDI is a Windows­based desktop that s delivered over any network and 
optimized for office tasks from simple to complex [2]. DDI is a developing initiative that builds on 
current solutions. Desktop virtualization is a term that can apply to other types of virtualization strategies. 
For example, a desktop workstation can be utilizing a desktop virtualization product to allow several 
operating systems to run simultaneously on one local desktop machine. One common example of this type 
of desktop virtualization is in the software development life cycles, where it is helpful to have a virtualized 
production environment available to the developer immediately. This is particularly useful in software 
development test-bed scenarios. Other desktop virtualization strategies focus on getting a standardized 
application or operating system image out to local workstations, streaming applications or operating 
systems out to office computers or unsecured terminals. In these scenarios, the local workstation hardware 
runs the operating system and/or software that are being provided from a remote source. Note that this 
does not match our scenario. In both notebook computer desktop virtualization and high end graphic workstation 
consolidation, the applications and operating system will be running on the remote servers. VDI and DDI 
approaches each have their strengths and weaknesses. For instance, due to lower overhead, Citrix Presentation 
Server can support more users per server. However, the applications run in the server operating system 
environment, rather than the Windows XP professional as they could in a VDI solution. This poses some 
challenges for us because the applications our users employ are created for use in desktop level operating 
systems such as Windows XP. They are often not well tested and qualified in the Windows Server environment. 
How would the developing VDI (VMware) and DDI (Citrix) solutions meet the desktop virtualization challenges 
presented by Ringling College? Only hands on testing would tell.  4. IMPLEMENTATION 4.1 Overview Ringling 
College student workflows differ from those studied in current VDI and DDI case studies. Rather than 
traditional office tasks and applications, tools appropriate for artists and designers are our primary 
focus. Generally, these applications are more graphics, compute, and memory intensive. Furthermore, they 
routinely generate and access files that are hundreds of megabytes in size. Therefore, there wasn t a 
direct match where we could identify the best solution without specific testing. VMware s free GSX and 
their enterprise class server product, ESX, servers were tested with Windows XP virtual machines. Citrix 
Systems Metaframe Presentation Server was also tested. A variety of applications we are currently running 
in academic computer laboratories were also tested in each environment. Student workflows are traditionally 
very graphics intensive. In remote access scenarios, additional graphic requirements often translate 
into additional network bandwidth requirements. However, our focus on consolidating high end graphics 
workstations is aimed at providing access from on campus locations. Specifically, our primary goal was 
to identify an acceptable and efficient framework for providing high end graphics workstation processing 
power in a computer lab environment. Although wireless network access (802.11g) would also be a factor 
when determining the best options for supporting campus notebook computer access, scenarios with very 
low bandwidth connections were not the primary determining factor. Therefore, our initial testing was 
performed with gigabit Ethernet network connections for both the server and client stations. Later testing 
could focus on performance differences that might be impacted by network bandwidth. First it was important 
to find out the best performance in the best case scenario. Testing of VDI solutions requires choosing 
a remote access method and associated client. Popular options include Remote Desktop Protocol (RDP), 
Virtual Network Computing (VNC), Citrix Independent Computing Architecture (ICA) or Remote Graphics Server 
(RGS). Remote Desktop Protocol (RDP) is a multi-channel protocol that is used for communication between 
Microsoft Windows Terminal Server and the Terminal Server Client [13]. Virtual Network Computing (VNC) 
is a platform independent graphical desktop sharing system that allows remote access from virtually any 
desktop to any other [10]. Citrix ICA is the thin protocol that allows ICA clients to connect with products 
that conform to this standard such as Citrix Presentation Server [3]. Hewlett Packard s Remote Graphics 
Software (RGS) is a remote desktop akin to RDP that offers innovative compression technology to improve 
performance and image quality while minimizing network bandwidth utilization [16]. To support the widest 
array of solutions for desktop clients and existing notebook computers, access were needed from Linux, 
Windows, and Mac OS X hosts to provide the greatest flexibility for our solution. As of this writing, 
testing has primarily focused on using RDP and RGS. Hardware platforms used for testing included several 
server platforms and a variety of client configurations. The clients in this case are remote display 
devices with keyboard/mouse. The monitor size (15 inch to 30 inch flat panel displays) and network connection 
speed were important factors in our test-bed with a variety of client configurations. Our server hardware 
included several configurations. The first was a Sun 4100 server (8GB memory, 2 Dual Core AMD Opteron 
Processor 280, 2.4GHz processors, internal SAS hard drives) running with several different operating 
systems during various stages of testing (Red Hat Linux ES 4.1 and VMware ESX 3). We also employed Hewlett 
Packard xw9300 workstation (4GB memory, 2 2.4GHz AMD Opteron 250 processors, internal SCSI 320 hard drives) 
with several different graphics cards (NVidia Quatro FX3400 and NVidia Quatro FX 5500) running several 
different operating systems during various stages of testing (Red Hat Linux ES 4.1 and Windows Server 
2003). In order to balance the I/O load, we used separate spindles for VM images and the host operating 
systems. 4.2 Testing and Results Our initial testing focused on recreating the most demanding aspects 
of our current Windows XP Pro environment in a virtual machine running on the free VMware GSX server 
product, a VDI solution. Remote access was possible using either RDP or RGS protocols. Responsiveness 
of these initial test cases indicated that this was worth pursuing. VMware provides a software interface 
for the VM to communicate with the underlying hardware. VDI is therefore hardware agnostic by its very 
nature, allowing VM s to avoid dependencies on the hardware configuration of the host server. For example, 
a virtualized generic graphics card is supplied by ESX or GSX server to the operating system running 
in the virtual machine. However, some of the applications which run on our high end graphics workstations 
depend on OpenGL acceleration provided by high end graphics card to achieve desired performance for the 
user. Indeed, a good portion of the investment in a high end graphics workstation is for the graphics 
cards. Therefore, applications such as Autodesk Maya, Architectural Desktop and Viz, which facilitate 
various kinds of 3D modeling and animation settings, were not immediately suitable for a VDI environment. 
We identified and tested an alternative approach for providing OpenGL acceleration in a remote desktop 
scenario. ThinAnywhere [19] provides OpenGL acceleration for RDP connections and Citrix ICA clients. 
Both options require the user application to run in Windows 2003 Server. Maya, Architectural Desktop 
and Viz are not qualified by their manufacturer, Autodesk to run in a Windows 2003 server. However, this 
testing did provide some interesting results. Maya would launch in both Windows 2003 server (via RDP 
connection) and Citrix Presentation Server environments demonstrating some hardware acceleration. Viz 
would not launch properly under multiple versions of Citrix Presentation server during our testing, even 
without the ThinAnywhere plug-in. This initially appears to be one of those cases where an application 
simply will not run in the Presentation Server environment. However, Viz supplies the user with options 
for software, Direct3D or OpenGL hardware acceleration. Perhaps that application could run with the software 
acceleration in a Windows XP virtual machine if absolutely needed. While searching for high end graphics 
desktop virtualization solutions, a number of projects from Citrix, Inc. started to peak our interests. 
We learned about a highly successful initiative between Citrix and Boeing to support remote, responsive 
OpenGL, high end graphics access to CATIA (Computer Aided Three Dimensional interactive Application by 
Dassault Systems) [1], a powerful, widely used computer aided design (CAD) software used in this specific 
project for major aircraft design [14]. Their pilot project has been very successful, leading to ongoing 
Citrix initiatives including a project previously code­named Trinity that ties in VDI support, or more 
specifically, brokering connections directly to remote workstations into the Citrix family [8, 9]. Offered 
by mid 2007, the first phase of Trinity is coming to market as Citrix Desktop Server, providing a combination 
of ICA and RDP connections where the connection broker stays in the connection path once a connection 
has been formed. This opens up new possibilities for supported connections that Presentation Server can 
offer, including various remote workstation connections powered by virtual machines or blade servers. 
The more exciting second phase of this project conceivably will allow the connection broker to get out 
of the way once a user gets connected. It is also projected to offer an efficient ICA connection to the 
remote host vs. current RDP and other offerings [8]. Starting by testing our most demanding, high end 
3D applications was a reasonable starting place for a number of reasons. While exposing some of the limitations 
of current solutions, it also reminded us that there are operating system and hardware dependencies among 
the applications supported on our high end graphics workstations. We need to maintain this sensitivity 
to software requirements as we seek to provide a stable, usable desktop virtualization solution. It also 
brought Citrix Presentation Server more squarely into our sights as we searched for the most efficient 
solution. Therefore, the next phases of testing involve both Citrix Presentation Server and VMware virtual 
machines running graphics intensive applications from Adobe Inc and Corel Corporation. We have successfully 
run basic tests with a variety of Adobe CS2 applications including Photoshop, In Design and Illustrator. 
Extensive testing is continuing using both VMware ESX server and Citrix Presentation Server test-bed 
environments as we continue to evaluate which solution may best suit our needs. Numerous tools are now 
available in the market for the physical to virtual migration of existing, production servers, including 
both operating system and applications. While these tools can be invaluable in a server environment, 
they are not as vital for our initial tests. However, the ability to quickly and easily back up a copy 
of the running virtual machine before making changes is extremely valuable. By copying a few files, we 
can archive the VM in execution and roll back to the original settings if we find any issues with our 
new configurations or refinements. This matches traditional workstation creation workflows we have practiced, 
but with the added benefit that the process is quicker and easier with a VM. There are several factors 
that often limit the appropriateness of VDI solutions that won t influence our decision making process 
dramatically. For example, our users do not require administrative rights to customize their environments. 
They do not need to re­connect to the same VM each time they log in. While we do want to reconnect sessions 
that are accidentally disconnected, the crash of a server providing remote access should not be a show 
stopper, as users can be re-directed to other servers. In our paradigm, this won t require the functionality 
to move a running virtual machine. With each of the remote desktop clients available for VDI solutions, 
there is a learning curve associated with using them. There is a clear connection to a remote environment. 
This will have to be considered as we move forward, requiring as seamless a solution as possible for 
our users. HP s description of just like local is a catchy idea that summarizes the best case scenario 
[16]. Decisions remain about how our clients will connect to these services functionality left to a 
connection broker of some type. Citrix offers a built in solution, but VMware offers a variety of partners 
that have products that may suit our needs. This is a new and developing area over the last year as desktop 
virtualization has started to mature. The choice of connection broker will affect the interface our users 
interact with when initially connecting to these remote sessions. Another new trend is providing virtual 
appliances, pre-built and pre-configured, ready-to-run enterprise software applications packaged along 
with an operating system within virtual machines [7]. Virtual appliances are easy to deploy and run on 
any hardware [22] and may offer an easy to install, maintain and deploy connection broker. In the very 
least, they offer some quick testing options while minimizing complexity.  5. LESSON LEARNED Gartner 
reports that desktop virtualization is several years behind the current server virtualization wave but 
will be larger [7]. In this maturing field, there are still performance issues to overcome and the tools 
and frameworks for providing high end graphics performance through a virtual desktop are just starting 
to mature. As we have evaluated relevant issues and continue extensive testing, it appears that a combination 
of VDI and DDI technologies may be the best return on investment [6]. While this sounds contradictory 
in an environment that is attempting to streamline and minimize complexity, the tradeoffs between these 
two major approaches seem to keep both of them in the running as a plausible solution. Future developments 
and the myriad of variations created by partners and competitors in this virtual desktop marketplace 
will ultimately propagate the traditional IT cycle of evaluate, test and adopt. We will simply have a 
few new options as we continue to do more with less and meet the growing expectations for technology 
performance and support. The offering of free products in the market such as VMware GSX and free connection 
clients such as RDP make a virtually free solution sound very feasible. However, feedback is indicating 
that management tools are as important in realizing potential overall savings from a virtualized environment 
as the other technologies involved. For example, the ease of deploying new virtual machines, load balancing 
existing connections and just detecting which VM s are in use necessitate a rich of central management 
suite of tools. The power to identify key performance concerns and issues is also important in keeping 
our customers working efficiently and avoiding headaches in this new workflow. Another factor to consider 
is that software version compatibility may change over time. For example, a current software revision 
that is running fine on Windows Server 2003, may not be supported when the next version of the software 
is released. As we have noted, application hardware support requirements and qualifications are also 
important factors. We can t ignore the environments where our user applications are currently best performing 
at this time. We also need to stay familiar with various options for desktop virtualization, as we may 
find that for a specific problem, only one will be feasible or perhaps a different one than the solution 
we have currently in production. As with many IT solutions, one size and one solution doesn t necessarily 
fit all. Recognizing the current hardware dependencies on the highest end 3D modeling and animation tools 
in our environment is another key consideration. While it is not currently practical or affordable to 
equip our back-end, virtualized servers with high end graphics cards that can be shared among remote 
users, perhaps the next generation of hardware and software will offer different possibilities. Licensing 
impact of the VDI and DDI approaches differ and may also impact our decision making process long term. 
For example, in a VDI solution, each virtual machine that is running Windows XP in our environment must 
be licensed. Additional licensing costs are incurred for some added functionality like the HP RGS client. 
In a DDI configuration like Presentation server, an investment in terminal services is needed to allow 
users to connect to the server environment. As with traditional desktops on our campus, neither a VDI 
nor DDI solution would require extensive checking of end user licenses. Deploying and maintaining desktop 
computer level virtualization poses many challenges, but there are opportunities for improvements at 
the application and server layers to achieve the high-level of computing performance and scalability 
required by highly intensive graphics, animation, and gaming applications. Desktop computer level virtualization 
leverages the positional and operational characteristics of high performance graphics workstations while 
embedding the processing tasks into the servers. Of course, there are limitations. All functions cannot 
be and should not be migrated to the virtual servers. In that sense, there is a delicate balance between 
the various mechanisms at the application and virtual server levels. 6. CONCLUSION Today, the top virtualization 
deployments are testing and development, server consolidation, and disaster recovery [18]. Desktop virtualization 
is about 2 years behind [15]. The last year has demonstrated tremendous growth in the VDI realm. Rapid 
development of connection brokers and management tools over the last year is helping to mature the young 
desktop virtualization field and maximize the return on investment in desktop virtualization solutions. 
Hybrid approaches now utilize a combination of techniques, providing more effective methods to supply 
users with the necessary software applications and performance. Small issues like available USB ports, 
CD/DVD burning and reading access, and other locally accessible devices also play a role in our decision 
making process. For example, our students often use Intuos Wacom tablets to compose their projects. Users 
often connect digital cameras of various types to retrieve photos and video. Our ongoing testing will 
need to carefully evaluate the support and the impact of any shortcomings and new learning curves involved 
in using such technologies. These small items are important parts of the user experience. Traditional 
sizing and scaling will require some ongoing work for us, as typical or heavy workloads that have been 
published don t align with our user applications or workloads [20]. The number of desktops that can be 
consolidated onto a single server relates directly to the end user work load. Some longer term study 
and testing will be needed to determine the number of virtual machines that can coexist on a single server. 
This also feeds into the overall investment in a desktop solution and potential for cost savings. As 
an art and design college, we have majors and a large student user community that is currently actively 
using Apple Macintosh hardware and the Mac OS X operating system. Unfortunately, no suitable desktop 
virtualization exists due to end user licensing limitations from Apple Inc [17]. On Macintosh hardware, 
products like Parallels Desktop, VMware Fusion and Code Weavers Crossover allow Windows applications 
to run on Macintosh hardware. However, our goal of providing remote OS X desktop environments running 
on server hardware is not currently feasible. The currently available alternative is working with our 
user community to see if workflows can be moved to often nearly identical products in the Windows environment. 
This is certainly not a small issue to address. Ultimately, providing IT services is about the end user 
experience. We can save money, provide a more secure environment, make IT administration more efficient, 
and even create a more earth­friendly IT infrastructure, but not have a successful project. If a remote, 
virtual desktop solution is cumbersome to use or doesn t match the traditional local, thick-pc experience 
that our users expect, acceptance will be difficult. In today s emerging VDI marketplace, we must tread 
carefully and choose wisely as we continue to provide the technology support that helps enable the people 
in our organization to do their jobs. While server consolidation through virtualization is not new, workstation 
desktop level virtualization is a natural and innovative extension of current server virtualization techniques. 
On our campus, desktop computer level virtualization is increasingly useful in simplifying the use and 
deployment of many graphics intensive applications. In addition, the advantages in management of applications, 
including control over their resource usage and relative isolation, will make virtualization at the desktop 
computer level more common for use in instructional computing laboratories and at the notebook computer 
level and in learning spaces across higher education institutions. Indeed, the general trend is towards 
applying virtualization techniques to almost all Information Technology infrastructure components, and 
we should expect to see more virtualization, virtually everywhere in higher education institutions. 
7. ACKNOWLEDGMENTS We wish to express our thanks to Kris Pegah for her assistance in configuring several 
of our test-bed environments. 8. REFERENCES [1] Childress, K. What is CATIA? http://www.practicalcatia.com/about_catia.htm. 
[2] Citrix, Dynamic Desktops. http://www.citrix.com/dynamicdesktops, (2006). [3] Citrix, Understanding 
Citrix ICA. http://www.citrix.com/English/ps2/products/qa.asp?contentID =186&#38;faqID=5638&#38;title=Understanding+Citrix+ICACity, 
(2007). [4] Camp, J S., DeBlois, P. B. and the EDUCAUSE Current Issues Committee. Current Issues Survey 
Report, 2007. EDUCAUSE Quarterly (http://www.educause.edu/ir/library/pdf/eqm0723.pdf), 30, 2 (2007). 
[5] Lai, E. Virtual Desktop Vendors Headed Toward Mainstream. Computer World (http://www.computerworld.com/action/article.do?command 
=viewArticleBasic&#38;articleId=290104&#38;pageNumber=1) (April 23, 2007). [6] Madden, B. SBC + VDI + 
Streaming = A Full Application Delivery Solution. http://www.brianmadden.com/content/article/SBC--VDI-­ 
Streaming--A-full-application-delivery-solution, (March 26, 2007). [7] Marshall, D. Gartner Says Virtualization 
will Top IT Agenda Until 2010. InfoWorld (http://www.brianmadden.com/content/article/SBC--VDI-­Streaming--A-full-application-delivery-solution), 
(May 9, 2007). [8] Martinm. Introducing Trinity. http://citrixcommunity.com/blogs/architecture/archive/2006/1 
2/05/Introducing-_2620_-Trinity.aspx, (Dec 5, 2006). [9] Martinm What Does Virtualization Mean for Trinity? 
http://citrixcommunity.com/blogs/architecture/archive/2006/1 2/20/What-does-_1C20_Virtualization_1D20_-mean-for­Trinity_3F00_.aspx, 
(Dec 20, 2006). [10] Mascio, J. R. S. What is VNC? Linux Magazine (http://www.linux-mag.com/id/1315/?r=s), 
(Mar 15, 2003). [11] Meredith, L. Gartner: Virtualization a Megatrend. http://searchcio.techtarget.com/originalContent/0,289142,sid 
19_gci1090548,00.html, (2005). [12] Microsoft, Application Virtualization. http://www.softricity.com/products/virtualization.aspCity, 
(2007). [13] Microsoft, Understanding the Remote Desktop Protocol (RDP). http://support.microsoft.com/kb/186607, 
(2007). [14] Muir, J. Project Pictor. http://citrite.org/blogs/jeffreymuir/2006/10/26/project-pictor, 
(2006). [15 ] Mullins, R. Desktop Virtualization Gains Traction. http://www.networkworld.com/news/2007/041007-trends­show-desktop-virtualization-is.html?page=1, 
(April 10, 2006). [16] Hewlett Packard, HP Remote Graphics Software. http://h20331.www2.hp.com/Hpsub/downloads/HP_remote_g 
raphics_datasheet.pdf, (2006). [17] Rudolph, B. Parallels' users can ask Ben anything. http://vmblog.com/archive/2006/10/22/2182.aspx, 
(October 13, 2006). [18] SWsoft. Top Ten Considerations for Choosing a Server Virtualization Technology. 
http://www.swsoft.com/en/products/virtuozzo/lib/wp/, (2006). [19] ThinAnywhere, ThinAnywhere Core Product. 
http://www.thinanywhere.com/products.php4, (2007). [20] VMware, VMware Infrastructure 3 VDI Server Sizing 
and Scaling. http://www.vmware.com/pdf/vdi_sizing_vi3.pdf, (2006). [21] VMware, Virtual Desktop Infrastructure 
Partners. http://www.vmware.com/partners/alliances/solutions/, (2007). [22] VMware, Virtual Appliances. 
http://www.vmware.com/appliances/, (2007)  
			