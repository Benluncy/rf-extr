
 FUNDAMENTAL LAWS OF COMPUTER SYSTEM PERFOP~IANCE J.P.Buzen Center for Research in Computing Technology 
Harvard University Cambridge, Mass., 02138 and BGS Systems, Inc. Box 128 Lincoln, Mass., 01773 ABSTRACT 
 A number of laws are derived which establish relationships between throughput, response time, device 
utilization, space-time products and var- ious other factors related to computer system performance. 
These laws are obtained by using the operational method of computer system analy- sis. The operational 
method, which differs sig- nificantly from the conventional stochastic modeling approach, is based on 
a set of concepts that correspond naturally and directly to obser- ved properties of real computer systems. 
Except for measurement errors, the operational laws pre- sented in this paper apply with complete preci- 
sion to all collections of observational data, and they are similar to fundamental laws found in other 
areas of engineering and applied science. Key Words: Computer performance evaluation~ throughput, response 
time, queueing systems, operational method. i. INTRODUCTION Most analyses of computer system performance 
rely on either benchmarks or probabilistic models. Benchmarks, which may consist of real programs, synthetic 
programs or trace driven simulations, are most useful when it is neces- sary to determine system behavior 
under a pre- cisely specified workload. However, benchmark results can be surprisingly sensitive to the 
nature of the workload that the system is assumed to be processing, and slight changes in the work- load 
definition may sometimes produce significant- ly different conclusions. Table i illustrates the crux 
of the problem with a highly simplified example. Suppose that an ana- lyst is comparing "round robin" 
(RR) and "first come first served"(FCFS) scheduling algorithms for a central processor. Assume that the 
workload consists of three jobs: Job A, with a duration of 7 seconds; Job B, with a duration of i second; 
and Job C, with a duration of 3 seconds. The first line of Table i gives the average response time for 
the three jobs in the case where the order of arri- val is "ABC" with all jobs arriving at approximate- 
ly the same time. Note that the average response for FCFS is 18% higher than the average response time 
for RR with a quantum of two seconds (see Appendix A for details). Thus the benchmark re- suits in line 
one indicate a definite preference for RR. WORKLOAD AVERAGE RESPONSE TIME FIRST SECOND THIRD FCFS RR(Q=2) 
 A B C 8 2/3 7 1/3 C B A 6 6 2/3 B A C 6 2/3 6 2/3 Table i In the second line of Table i, everything 
is the same except that the order of arrival is reversed. In this case, average response time for RR 
is 11% higher than average response time for FCFS. The second set of benchmark results thus indicate 
a strong preference for FCFS, even though this bench- mark contains the same set of jobs as the first. 
As a point of interest, the third line of Table presents yet another arrival sequence in which the two 
scheduling algorithms produce exactly the same The potential discrepancies between predicted average 
response time Although the example in Table 1 is highly sim- plified, the dangers which it illustrates 
are very real. In particular, benchmark evaluations require specification of the system workload in complete 
detail: as a result, the analyst is often compel- led to make subtle but critical decisions in areas 
where his knowledge is usually imprecise. This in turn leads to confusing situations where seeming- ly 
equivalent benchmark studies produce different final conclusions. 2. PROBABILISTIC MODELS Probabilistic 
models enable the analyst to deal directly with situations where only partial know- ledge of the workload 
exists. Suppose, in the case of Table l, that the workload is known to con- sist of Jobs A, B, and C, 
but the order in which the jobs will arrive is uncertain. If the uncer- tainty concerning the order of 
arrival can be represented with a probabilistic model, the ana- lyst may be able to formulate a meaningful 
solu- tion interms of random variables. For example, suppose that it is reasonable to assume that the 
sequence "ABC" will occur 60% of the time, the sequence "CBA" will occur 10% of the time, and the sequence 
"BAC" will occur 30% of the time. In this case, the arrival sequence can be regarded as a random variable, 
and the expected response times can be computed as follows: Expected FCFS response time 2 .60 x 8~- 
+ .I0 x 6 + .30 x 6~ = 7.80 Expected RR response time i 2 2 = .60 x 7~ + .i0 x 6~ + .30 x 6~ = 7.07 
 Thus, the analyst can compute that --"on the average" --FCFS response time will be 10% higher that RR 
response time. The analyst is not troubl- ed by the fact that individual benchmark tests fail to confirm 
his prediction; indeed, he fully expects to find RR response higher than FCFS response time for 10% of 
the arrival sequences. and observed average response times discussed in the preceding paragraph were 
magnified by the im- plicit assumption that the benchmark consisted of only a single three-job arrival 
sequence. In prac- tice one would normally expect to include many three job sequences in a single benchmark. 
In such cases, results from probability theory (e.g., the Law of Large Numbers, the Ergodic Theorem~and 
the theory of confidence intervals) imply that pre- dicted and observed average values will be reason- 
ably close in almost all cases. This is the major reason for constructing simulation programs that run 
for long periods of simulated time and con- structing benchmarks that run for long periods of real time. 
 3. OPERATIONAL OBJECTIVES  The assertion that a particular theoretical re- sult can he validated in 
~raetiee at some desired confidence level--if the experiment is run "long enough"--may be satisfactory 
for resolving cer- tain performance evaluation issues, but such assertions are clearly insufficient to 
meet all the needs of empirically oriented computer per- formance analysts. Such individuals usually 
deal with sets of data that have been collected by di- rect measurement of actual systems during finite 
intervals of time. These analysts are basically interested in: A. Precise mathematical expressions which 
re- late existing measurement data to other quantities that were not measured but which could, in principleabe 
empirically determined. B. Relationships that can be used to verify the internal consistency of existing 
sets of measurement data. C. Formulas that predict the effect that certain modifications to the system 
or the workload would have on measured quantities such as throughput and response time.  Note that empirically 
oriented computer perfor- mance analysts are not primarily interested in re- lationships between random 
variables or expected values of random variabies; rathe~ they are in- terested in relationships between 
measured quan- 201  tities and quantities which can~in principle, be measured. The remainder of this 
paper will deve- lop a theory of such relationships.  This theory is based on the concept of opera- 
tional variables. Operational variables are for- mal objects defined so that they correspond natur- ally 
and directly to observed properties of real systems. Some of the results that will be derived using operational 
variables have direct counter- parts which can be expressed in terms of random variables and probabilistic 
models. However, it is important to notice that operational results are fundamentally different from 
probabilistic results: that is, operational results apply with complete precision to all collections 
of obser- vational data, whereas probabilistic results only apply precisely (with probability one) in 
the limiting case where the length of the observation interval approaches infinity. Another important 
difference is that operation- al results can be derived without making any of the seemingly artificial 
mathematical assumptions (e.g., independent and identically distributed service and inter-arrival times, 
statistical equilibrium, specific distributional forms, etc.) that are commonly required in the case 
of pro- babilistic results. Because they apply without restriction to broad classes of systems, the operational 
results that will be derived in this paper can be regarded as universal and funda- mental laws of computer 
system performance. They are similar in certain respects to the funda- mental laws found in such fields 
as basic mechanics, thermodynamics, and electrical engineering. Some of these similarities will be noted 
in the course of the presentation. 4. TWO BASIC PROBLEMS  Before proceeding wSth the main analysis, 
it is useful to consider two specific questions which are typical of a large class of problems that arise 
in the study of computer system behavior. The two questions, which will be referred to as the throughput 
problem and the response time problem, are defined as follows: Throughput Problem: Consider a batch 
processing system with a paged virtual memory. Suppose that the utilization of the backing store (i.e., 
the paging device) is .85, the average amount of back- ing store service time required to process a page 
fault is 10 milliseconds, and the average number of page transfers (i.e.~ reads and writes) per pro- 
gram is equal to 6000. What is the throughput of the system? Reponse Time Problem: Consider a time sharing 
sys- tem which contains 25 active terminals. Suppose that the average think time is 15 seconds, the average 
number of accesses to the system disk per interaction is 7, the utilization of the system disk is .35, 
and the average service time for the system disk is 40 milliseconds. What is the ave- rage response time 
of the system? Considering the complexity of most modern day com- puter systems, it might appear that 
the information provided in the problem statements is insufficient to answer the specific questions posed 
in each case. For example, no mention is made in the problem statements of CPU utilization or the utilization 
of any other I/O devices in the system. In addi- tion, there is no discussion of memory size, level of 
multiprogramming, operating system overhead, or a number of other factors which would appear to be relevant 
to the basic problems under considera- tion. Nevertheless, it is entirely possible to provide a precise 
answer to each question. Fur- thermore, the answers which can be obtained are applicable to all systems 
which conform to the specifications in the problem statements, regard- less of any other particular 
characteristics these systems may have. For future reference, note that the solution to the throughput 
problem is 51 jobs per hour and the solution to the response time problem is 5 seconds. 5. THE OPERATIONAL 
METHOD The solutions presented in Section 4 were ob- tained by using the operational method of computer 
system analysis. This method is based on a set of definitions and working assumptions that are in- tended 
to reflect the viewpoint of individuals en- gaged in empirical studies of computer system performance. 
As stated in Section 3, such  individuals usually deal with collections of measurement data that are 
obtained by monitoring system behavior during specific intervals of time. In operational terms, an interval 
of time during which such measurement data is collected is call- ed an observation interval, and the 
quantities that are measured or computed during an obser- vation interval are referred to as operational 
variables. Analyses which utilize the opera- tional method generally involve the following three steps: 
 A. Define a set of operational variables that correspond in a direct and natural manner to the intuitive 
concepts of interest (e.g., throughput, device uti- lization, etc.). B. Derive mathematical relationships 
among operational variables which characterize system behavior during a single observation interval. 
 C. Apply these mathematical relationships to problems such as those described in sub-headings A, B and 
C of Section 3. The next section of this paper defines a set of operational variables that can be used 
to formulate a number of performance evaluation problems. 6. OPERATIONAL VARIABLES The following set 
of symbols and definitions will be used throughout the remainder of this discussion. All definitions 
should be under- stood in the context of the operational method described above. T = Length of the observation 
interval (i.e., the time interval during which the system was observed and measure- ments were taken). 
It is assumed that the time units in which T is expressed are also used to express all other time dependent 
quantities. J = Number of jobs completed during the ob- servation interval. A job is a basic unit of 
work and may refer to a program, a job step, a job, or an interaction, depending on the system being 
studied. X = Throughput (i.e.~number of job completions per unit time). The operational variable X is 
expressed as follows: X = J/T (i)  B(i) ~ Amount of time that device-or-processor is busy ( actually 
providing service) dur- ing the observation interval. It is assum- ed that the processors and devices 
in the system are numbered in some fashion so that the term "processor-or-device i" refers to a unique 
entity. U(i) = Utilization of processor-or-device i. U(i) is expressed as follows: U(i) = B(i)/T (2) 
 C(i) = Total number of service requests completed by processor-or-device i during the obser- vation 
interval. S(i) = Average service time for processor-or-de- vice i. S(i) is expressed as follows: S(i) 
= B(i)/C(i) (3)  D(i) = Average number of requests for processor- or-device i per job. D(i) is expressed 
as follows: D(i) = C(i)/J (4) 7. THE THROUGHPUT LAW  Given the above definitions, it is possible to 
derive the following basic result. Throughput Law: Throughput is equal to device util- ization divided 
by the product of average device service time and the average number of requests per job for that device. 
Symbolically, U(i) for any i. (5)  X S(i), D(i) The proof of the Throughput Law is immediate from equatio~ 
(i) through (4) since U(i) B(i) C(i) J S(i)'D(i) T B(i) C(i) = J/T = X  Despite the trivial nature 
of the proof, the Throughput Law represents a useful and powerful result. Note that it can be used to 
directly ob- tain the answer to the throughput problem present- ed earlier in this discussion. As specified 
in the problem statement, u(i) = .85 S(i) = i0 milliseconds  D(i) = 6000 Thus, X = .85/(6000 X i0) 
jobs per millisecond = 3600000 X .85/(6000 X i0) jobs per hour = 51 jobs per hour An important aspect 
of the Throughput Law is that it is independent of a large number of fac- tors which must normally be 
specified in other ana- lyses. These factors include: the degree of multi- programming; the service time 
distribution for each device and processor in the system; the fact that the system is or is not in statistical 
equilibrium; the fact that overlap of CPU and I/0 processing within a single program is or is not permitted. 
In other words, the Throughput Law is valid re- gardless of the status of these other factors. For this 
reason, the Throughput Law can be regard- ed as a universal law of computer system perfor- mance. A probabilistic 
version of the Through- put Law, which is valid in the context of the central server model, was derived 
earlier by Buzen [2]. The Throughput Law bears certain similarities to elementary laws of motion. For 
example, if a body starts at rest and accelerates at a constant acceleration (a) for an interval of time 
(t), the distance it travels (d) is given by: 1 2 d =~.a t  One point of similarity between this result 
and ip . the Throughput Law is that dlstance~ acceleration and time are most natually regarded as operational 
 variables in the above relationship. Note that it is not natural to consider them as expected values 
 of random variables since no underlying probabi- listic model is involved. It is, of course, true 
that the mathematical argument required to derive the relationship bet- ween distance, acceleration, 
and time is signi- ficantly more complex than the argument required to derive the Throughput Law. However, 
the next few sections of this paper will demonstrate that operational laws of greater mathematical interest 
also exist. 8. THE UTILIZATION EQUALITY Note that the Throughput Law can be'applied to any device or 
processor in a system. If, for example, the law were applied to device j with j # i, one would obtain 
 X = U(j) (6) S(j) 'D(j) Since throughput as defined in equation (i) has a unique value regardless of 
the device used in equa- tion (5), it follows from equations (5) and (6) that U(i) U(j) (7) S(i)-D(i) 
= S(j),D(j) Equation (7) will be referred to in this discus- sion as the Utilization Equality. This 
equation can be used to verify the internal consistency of a set of empirical data collected during some 
observation interval. As in the case of the Throughput Law, the Utilization Equality is applicable to 
all sys- tems and is auniversal law of computer performance. Probabilistie versions of the Utilization 
Equality have been derived previously by Buzen [2] and, in a very general contex~ by Chang and Lavenburg 
[4]. 9 RESPONSE TIME LAWS In order to apply operational techniques to the analysis of interactive systems, 
it is first neces- sary to provide a basic model for describing the manner in which such systems operate. 
The model and terminology that will be employed in this discussion are based on the work of Scherr [i0], 
Kleinrock [7], Moore [8], and Muntz [9]. The essence of this model is illustrated in Figure 1. There 
are a fixed num- ber of interactive terminals, and each terminal has one interactive process associated 
with it. The in- teractive process is either in think state (i.e., blocked) or system state (i.e., active). 
Response time is the elapsed time between the instant that an interactive process enters system state 
and the instant that it next leaves system state. Each time that an interactive process leaves system 
state (i.e., completes a proeessing request), an interaction is said to occur.  Think State Interactive 
Terminals System State System N J Response Time  Fig. i. Basic Interactive Model Given this general 
context, it is possible to define an additional group of operational vari- ables. N = Number of interactive 
terminals. It is assumed that N is constant through- out the observation interval. J = Number of interactions 
during the observation interval. This definition is simply a specific instance of the definition of J 
given previous- ly. r(k) = Total time that the k-th interactive process spends in system state. R = 
Average response time (i.e., average amount of time in system state per interaction). Since R is the 
average amount of system state time necessary to generate one interaction, R can be computed by first 
obtaining the total time spent in system state (by all processes) and then dividing this quantity by 
the total number of inter- actions completed during the observa- tion interval. Thus, R is given by 
N i R = ~ Z r(k) (8) k=l  z(k) = Total time that the k-th interactive process spends in think state. 
 jr = Total number of times that interactive jobs leave think state and enter system state during the 
observation interval. Z = .Average think time (i.e., average amount of think time per transition from 
think state to system state). Ap- plying the same reasoning used to define  R, N 1 Z z(k) (9) Z = 
J" k=l  By combining these definitions with the set pre- sented previously, several results concerning 
res- ponse time in interactive systems can be derived. General Response Time Law: The average response 
time of an interactive system is expressed as follows: S(i).D(i) ji R = N U(i) j Z (i0)  Proof: The 
derivation of equation (i0) utilizes the fact that the total time that the k-th inter- active process 
(the process associated with the k-th terminal) spends in think state, plus uhe total time that the k-th 
interactive process spends in system state, must be equal to the length of the observation interval. 
That is z(k) + r(k) = T for all k (ii)  Thus, N N Z z(k) + E r(k) = N-T (12) k=l k=l  Dividing both 
sides by J and using equations (8) and (9) to simplify the left hand side, JIz +R= N T  J J (13) 
 By equation (i) and the Throughput Law, J U(i) (14)  T S(i),D(i) Combining equations (13) and (14), 
 ~ZZ + R = N S(i)'D(i) (15) J u(i)  jf The proof is completed by subtracting 7 z from both sides. 
 A useful simplication of the General Response Time Law arises if it is assumed that J is very large 
with respect to N. This will occur if the observation interval is substantially longer than the average 
response time of the system. In such cases, JI/J~l since ~JI-J I ~ N. It is then approximately true 
that  N S(i)'D(i) Z (16) R = U(i)  Equation (16) will be referred to as the Asympto- t_ic Response 
Time Law, or simply, the Response Time Law. If it is assumed that J is large with respect to N, the 
Asymptotic Response Time Law can be used to solve the response time problem stated earlier in this paper. 
Recall that N = 25 terminals, Z = 15 seconds, D(i) = 7 requests, U(i) = .35, and S(i) = .040 seconds. 
Thus, R = 25 x .040 x 7/.25 -15 = 5 seconds  Specific probabilistic versions of the Asympto- tic Response 
Time Law have been derived by several investigators for particular models of interactive systems [7,8,10]. 
Derivations of the Asymptotic Response Time Law for more general interactive models are presented by 
Boyse and Warn [i] and by Muntz and Wong [9]. In all these cases, the pri- mary objects of analysis were 
random variables and stochastic processes, and results were ex- pressed in terms of expected values of 
random variables. i0. SPACE-TIME PRODUCT LAWS  Space-time products are often used to evaluate program 
performance andassign accounting charges to programs in virtual memory systems. Essential- ly, a program's 
space-time product is equal to its execution time multiplied by the average amount of memory allocated 
to it during its exe- cution. Since space-time products, response time, and throughput are all used as 
indicators of system performance, it is interesting to exa- mine the manner in which these quantities 
are related. Begin by considering an arbitrary system which may be operating in either an interactive 
or a batch processing mode. Let the operational variable A be defined as the number of jobs which arrive 
at the systemlduring the observation in- terval. Assume that A includes those jobs present at the start 
of the interval (i.e., jobs that arrived at time zero). For each job, define the following function: 
 f(k,t) = Amount of memory allocated to the k-th job at time t. Let y(k) = Space-time product for the 
k-th job. The operational variable y(k) is defined as follows: T y(k) --f f(k,t)dt (17) 0 Y = Average 
space-time product (i.e.~ space- time product per completed job), Y is defined as follows: A i Z Y = 
~ k= I y(k) (18) m(t) = Amount of memory in use (i.e., allo- cated to some job ) at time t. The operational 
variable m(t) is defined as follows: A re(t) = Z f (k, t) (19) k=l M = Average amount of memory in 
use during the observation interval. M is defined as follows: T i M = ~ ~ m(t) at (20) 0 By equations 
(19) and (20), T A M=~ i : Z f (k,t) dt (21) O k=l Reversing the order of integration and summation, 
and applying equations (17) and (18), M = Y.J/T (22) Applying equation (i) X = M/Y (23) Equation 
(23)~ which will be referred to as the Space-Time Product Throughput Law, states that the throughput 
is equal to average amount of memory in use divided by average space-time product.  206 A similar relationship 
between average space-average response time (R) times one unit of space. time product and average response 
time in the Define the operational variable L as followsf asymptotic case can be obtained by combining 
equa-L = Average number of jobs present in tions (23), (16), and (5). This yields the system during the 
observation interval. R = N'Y/M -Z (24) From the previous paragraph, Equation (24) will be referred 
to as the S_pace- Time Product Response Time Law. Table 2 illustrates the basic structure of the operational 
variables defined in this paper. Note that some operational variables correspond to event counts, some 
correspond to time durations, and some correspond tospace-time integrals. Within each class~ certain 
quantities are expressed for the entire observation interval, certain quantities are expressed on a 
"per unit time" basis, certain quantities are expressed on a "per job" basis, and certain quantities 
are expressed on a "per service completion" basis. EVENT ' TIi.iE SPACE-TIME COUNTS ~ DURATIONS INTEGRALS 
 J T T  ENTIRE A B(i)  INTER-y(k)= ~f (k, t) dt J' ~ r(k)  VAL C(i) i z (k)  PER I T UNIT JX=~i 
!U(i)=B$i) M = l~m ( t ) dt TIME O i N A PER JOB D(i)=Cj(-i) i X R=7~ r(k) Y = 7 y(k) k=l k=l PER N SERVICE 
COMPLE-TION i k=l _B(i)s(1)-c(i) Table 2 Operational Variables ii. LITTLE'S FOrmULA  If it is assumed 
that each job has unit size (i.e., occupies one unit of memory space), M will be equal to the average 
number of occupied memory units or, equi- valently, the average number of jobs present in the system. 
It also follows in this case that y(k) is equal to the time-in-system (response time) for the k-th job 
times one unit of space. Thus Y is equal to M = L x one unit of space  Y = R x one unit of space. Substituting 
into equation (23), cancelling the space units, and simplifying, L = X.R (25)  Equation (25) is the 
operational counterpart of the well known result from queueing theory that is usually referred to as 
Little's formula. Note, of course, that equation (25) is expressed in terms of operational variables 
rather than expected va- lues of random variables. Note also that equation (25) involves throughput 
(i.e., departure rate) rather than arrival rate (i.e.~ % ). If it is assumed that the system being studied 
is in equi- librium in the sense that the same number of pro- grams are present at the beginning and 
the end of the observation interval, the departure rate will be equal to the arrival rate and a direct 
counter- part to Little's formula can be deduced as a special case. It should be pointed out that a 
number of deri- vations of Little's formula have included analysis steps that are very similar to operational 
argu- ments[5],[6]. However, in all cases the ultimate objective of the analysis was to derive results 
in terms of random variables, and consequently all previous analyses required additional assumptions 
and included additional arguments. 12. RELATIONSHIP TO PROBABILISTIC RESULTS Since most operational 
results presented in this paper have counterparts which can be expressed in terms of probabilistic models 
and random variables, it is useful to consider the relationship between probabilistic and operational 
analyses Essential- ly, operational analyses are concerned with the properties of specific behavior sequences 
which systems follow during well defined intervals of time. Most results in this paper involve opera- 
 tional variables that represent averages computed over such time intervals, and as a consequence these 
results apply to all possible behavior se- quences which produce a given set of average values (lhis 
is the principal difference between opera- tional analyses and conventional deterministic analyses). 
 Probabilistic results also apply to an ensemble (i.e., a set) of possible behavior sequences. If a 
probabilistic result is based on the assumption of statistical equilibrium, then the Ergodic Theo- rem 
and the Law of Large Numbers imply that, for almost all behavior sequences, the operational averages 
defined for each of the individual se- quences will be identical and will correspond to the expected 
values of the associated random va- riables (i.e., the ensemble averages). Thus, pro- babilistic laws 
which are based on equilibrium assumptions and which involve only constants and expected values will 
correspond to operational laws that apply to almost all members of the associated ensemble of infinite-time 
behavior sequences. From the operational standpoint, only two properties of these infinite-time behavior 
se- quences are significant: A. The number of arrivals at each proces- sing element is unbounded. Thus 
the num- ber of requests pending for each proces- sing element at the start of the interval is insignificant 
and can be assumed to be zero. B. No unbounded queues develop during the observation interval. Thus, 
for each processing element, the departure and arrival rates must be equal; equivalently, the number 
of departures and arrivals at each processing element can be assumed to be equal. In general, it will 
be true that operational results which are based on assumptions that do not contradict properties A and 
B above, and which involve only constants and average values, will correspond to probabilistic results 
which in- volve constants and expected values of random variables. In many cases, additional assumptions 
must be made in the case of the corresponding probabilistic results (e.g., care must be taken to avoid 
strictly periodic behavior that is incompatible with statis- tical equilibrium). Thus, even when direct 
counter- parts exist, operational laws benefit from greater generality and simpler interpretation and 
applica- tion. 13. PRACTICAL CONSIDERATIONS One question which arises when applying opera- tional laws 
in practice concerns the problem of end effects (i.e., the state of the system at the ini- tial and terminal 
points of the observation inter- val). Actuall~ end effects do not in any way im- pair the validity of 
operational laws themselves since these laws are internally consistent and valid for all possible initial 
and terminal states. However, the implications of certain operational definitions should be carefully 
understood to avoid possible misinterpretation of operational variables. For example, equation (3) states 
that average device service time is equal to total device busy time divided by the number of requests 
completed during the observation interval. If a service re- quest is partially complete at the start 
of the ob- servation interval, the value of S(i) will, in a sense, be artificially reduced. Likewise, 
a ser- vice request which is only partially complete at the end of the observation interval will contribute 
to B(i) but not to C(i). This will artificially raise the value of S(i). Fortuantely, if the ob- servation 
interval is at least moderately long, these effects will be negligible and can be safely disregarded. 
 The same considerations apply to all variables defined on a "per job" basis (e.g., X,Y, and R). In effect, 
the operational definitions presented in this paper are based on the assumption that measurements are 
collected during the observation interval and that "per job" and "per service com- pletion" averages 
are computed at the end of the interval by simple division. This assumption appears to conform well to 
existing practice in the computer performance measurement and evaluation field. Note that the above 
comments actually pertain to the problem of estimating intrinsic system para- meters on the basis of 
observations taken during  finite intervals of time. This problem arises in both operational and probabilistic 
analyses, and it is independent of the analysis method that is actually employed. A somewhat different 
problem arises in the case of disk and drum subsystems which untilize rota- tional position sensing and 
block multiplexing[3]. The application of equation (3) to such devices yields average service times which 
are approximate- ly equal to average data transfer times. Thus, the additional delay due to seek and 
rotational latency will not appear in S(i). Once again, this phenomenon does not affect the validity 
of the operational laws derived in this paper, but it does illustrate the need to fully understand the 
implications of all operational definitions. 14. APPLICATIONS  Since the laws derived in this paper 
are direct- ly applicable to all systems, they can be used to verify the internal consistency of: performance 
measurements collected by empirical methods; numerical values generated by simulation programs; algebraic 
equations derived through the explicit solution of probabilistic models of systems in equilibrium. The 
laws can also be used to express an unknown variable (e.g., device service time) in terms of other variables 
which are easier to measure. In a somewhat different context, the Utiliza- tion Equality can be helpful 
in locating bottle- necks since, by equation (7), the device or pro- cessor with the largest value of 
S(i).R(i) must necessarily have the largest value of U(i). The fact that no value of U(i) can exceed 
i.0, when combined with the Utilization Equality, also makes it possible to calculate the maximum utilization 
for each device and processor in the system. These maximum utilization values can then be substitu- ted 
into other laws to obtain upper bounds on throughput and lower bounds on response time. The laws derived 
in this paper can also be used to estimate the effect that certain modifications to a system will have 
on performance indicators such as throughput and response time. To make these estimates, it is necessary 
to understand which variables will change and which will remain constant after the modifications are 
carried out. For example, suppose that program restructuring techniques make it possible to reduce the 
working set size of all programs at a particular installa- tion by 20%. If it is reasonable to assume 
that this modification will also reduce the average space-time product (i.e., Y) by 20%, and if there 
is a sufficient load on the system to keep the amount of memory in use (i.e., M) approximately con- stant, 
then the Space-Time Product Throughput Law implies that throughput will increase by 25%. Like- wise, 
the Space-Time Product Response Time Law im- plies that average response time will decrease by an amount 
equal to 20% of the original value of N'Y/Z. The Response Time Laws can also be used to esti- mate the 
extent to which response time will increase when additional interactive terminals are added to a time-sharing 
system. Once such systems reach cer- tain levels of saturation, increases in the number of interactive 
terminals (N) leave all other depen- dent variables in the Response Time Laws unchanged. For examples 
of this approach to estimating res- ponse time, see Scherr [i0], Kleinrock[7], Moore[8] and Muntz and 
Wong [9]. 15. ACKNOWLEDGEMENTS  Many of theconcepts presented in this paper were refined and sharpened 
during conversations between the author and D. B. Rubin, P. J. Denning, and E. Gelenbe. The author was 
also influenced by the work of R. R. Muntz and L. Kleinrock. 16. REFERENCES  i. Boyse, J. W., and Warn, 
D.R. A straight- forward model for computer performance predic- tion~ Comp. Surveys 7,2 (June 1975), 
pp.73-93. 2. Buzen, J. P. Analysis of system bottlenecks using a queueing network model= Proc. ACM SIGOPS 
Workshop on Sys. Perf. Eval. (April 1971) ACM, New York, pp. 82-103.  3. Buzen, J.P. I/O subsystem architecture~ 
Proc. of the IEEE 63,6 (June 1975), pp.871-879.  4. Chang, A., and Lavenburg, S.S. Work rates in closed 
queueing networks with general indepen- dent servers. Oper. Res. 22 (1974), pp.838-847.  5. Jewell, 
W.S. A simple proof of: L=%W~ Oper. Res. APPENDIX B GLOSSARY 15 (1967), pp.l109-1116. 6. Maxwell, W.L. 
On the generality of the equation Operational Variables A = Number of arrivals at system.  L=%W. Oper. 
Res. 18 (1970), pp.172-174. B(i) = Amount of time device i is busy. 7. Kleinrock, L. Certain analytic 
results for time Number of service requests completed by shared processors~ Proc, IFIP Congress 1968, 
C(i) = device i. pp. 838-845. D(i) = Average number of requests per job for 8. Moore, C. Network models 
for large scale time device i. sharing systems. TR-71-1, Dept. Industrial Eng., f(k,t) = Amount of memory 
allocated to the k-th job Univ. of Michigan, Ann Arbor (April 1971). at time t. 9. Muntz, R.R., and 
Wong, J. Asymptotic properties J = Number of jobs (or interactions) completed of closed queueing network 
models, Proc. Eighth during the observation interval. Annual Princeton Conference on Information j'= 
 Number of transitions from think state to  Sciences and Systems (March 1974), pp.348-3521 system state. 
 I0. Scherr, A. An Analysis of Time Shared Computer L = Average number of jobs in system during the 
Systems. M.I.T. Press, (1967). observation interval. M = Average amount of memory in use during the 
 APPENDIX A BENCHMARK ANALYSIS observation interval.  Tables A-l, A-2, and A-3 present the completion 
m(t) = Amount of memory in use at time t. times of individual jobs and the average response N = Number 
of interactive terminals. time (completion time) of the entire benchmark for Average response time. 
each of the three workloads presented in Table i. r(k) = Total time in system state for k-th inter- It 
is assumed that the quantum size in the round active process (k-th terminal). robin scheduling algorithm 
is 2 seconds. S(i) = Average service time for device i. T = Length of observation interval. FCFS RR U(i) 
= Utilization of device i. A 7 ii X = Throughput. Table A-I  B 8 3 y = Average space-time product 
per job. C ii 8 Workload = ABC y(k) = Space-time product for k-th job.  AVERAGE 8 2/3 7 1/3 Z = Average 
think time. z(k) = Total time in think state for k-th interactive process (k-th terminal). FCFS RR 
 Principal Operational Laws C 3 6 Table A-2  B 4 3 Asymptotic Response Time Law -Eq. (16) A Ii ii Workload 
= CBA General Response Time Law -Eq. (I0) AVERAGE 6 6 2/3 Response Time Law -Eq. (16) Space-Time Product 
Response Time Law -Eq. (24) Space~Time Product Throughput Law -Eq. (23) Throughput Law -Eq. (5) FCFS 
RR  Utilization Equality -Eq. (7) B 1 i" Table A-3 A 8 ii C ii 8 Workload = BAC  AVERAGE 6 2/3 6 
2/3 210   
			