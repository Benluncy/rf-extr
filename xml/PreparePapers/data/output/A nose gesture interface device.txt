
 A Nose Gesture Interface Device: Extending Virtual Realities * Tyson R. Department Henry Scott Il. Hudson 
of Computer Science and University of Arizona, Tucson Andrey Biomedical AZ 85721 K. Yeatts Interfaces 
 Brad A. Myers School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213 Abstract This 
paper reportsl on the development of a nose-machine interface de­vice that provides real-time gesture, 
position, smell and facial expression information. The DATA NOSETM2 Data AtomaTa CORNUCOPIA pNeumatic 
Olfactory I/O-deviSE Tactile Manipulation[Olsen86, Myers91] allows novice users without any formal nose 
training to perform complex interactive tasks. Hardware Design There are many different types of plastic 
noses com­monly sold in novelty stores [Spencer Gifts]. Several dif­ferent formats were tried: pig nose, 
elephant nose, rab­bit nose, cow nose, mouse nose, duck nose, witch nose and cat nose. (Figure 1 shows 
six commonly available alternative nose formats. ) Each proved to have serious disadvantages. For example, 
the pig nose was uncom­fortable after several hours of use and the whiskers on the mouse 3 and rabbit 
noses tended to get caught in printers. Because of its simplicity, sturdy attachment mecha­nism, and 
availability, the Groucho Marx nose was cho­ *This work was not sponsored at alf by the Kimberly-Clarke 
Corporation, but we are sure they would approve of it. 1This document was formatted by TfjX. 2DATANOSE 
is not a registered trademark, the M is just part of its name. 3 Problems with the whiskers on the mouse 
nose directly con­tradicts previous mouse results which showed that a mouse woufd be best for all tasks 
[Card78]. Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permieaion. 
@ 1991 ACM 0-89791-451 -1/91/ 0010/ (3065... $1 .50 Steven Feiner Department of Computer Science Columbia 
University New York, Figure 1: Alternative Noses: Bunny, Mouse, Duck, Dog sen as our hardware platform. 
(Note that not all Grou­cho noses are the same. Subtle physical variations can cause subst ant ial differences 
in usability [Buxton86] ). The initial DATANOSETM prototype mounted the nose to a motorcycle helmet [NASA], 
see Figure 2. Af­ter problems with nosebleeds, hay fever and unexplained nausea, we dispensed with the 
helmet platform and de­cided to use the traditional sturdy black rimmed glasses that come with the nose. 
 2 Rhino-Virtual Realities Early rhino-virtual realities relied on rapid hor­izontal motion twitching 
as the only interaction method [Bewitched]. The addition of modern hardware and software techniques to 
nose-based virtual realities M to use multiple inf,craction allows the DATAN OSE methods. A Polbemus-comfortably 
situated inside the November 11-13, 1991 UIST 91 Figure 2: Motorcycle Helmet Platform4 nose allows for 
nose movement in all 3 dimensions to be measured. Touch sensitive plates embedded in the tip allow for 
nose-to-screen and nose-to-keyboard inter­ actions. Pneumatic input and output sensors allow for air 
pressure inside the DATANOSETM to be used as an­ other interaction mode. Combinations of these interac­ 
tion methods can be particularly powerful. The section 3 presents an example of how multiple interaction 
modes can be used to perform one complicated action. Assigning unique smells to objects provides users 
with a valuable method for distinguishing amoung interac­ tion objects. Novice users find it particularly 
helpful when learning how to use a new interface. While they may not remember what action a particular 
interactor performs simply by looking at it, once they smell it, they often remember its function. Our 
prototype aromatic interface went one step further by assigning unpleasant odors to actions that an expert 
system calculated to be nonoptimal. The addition of multiple degrees of interaction to rhino-virtual 
realities allows non-expert users to per­ form tasks that previously could only be accomplished by experts 
and therefore takes us one step closer to re­ alizing virtual wrestling.  3 Picking and Rotating 3-D 
Ob­jects The DATAN OSETM has sufficient versatility y to re­place many different interaction devices. 
For exam­ple, the dragging and selection operations commonly 3Actually the model shown is mounted on 
a bicycle helmet, since we could not find a motorcycle helmet that fit. The wires sticking into the nose 
are surprisingly comfortable and do not interfere with sneezing.  66 UIST 91 Figure 3: Rotating 3-D 
Objects done by mice can be more easily accomplished with the DATANOSETM . Users can select object simply 
by press­ing the nose against the screen and can move objects simply by dragging the nose across the 
screen5. In addition to simple 2-D selection tasks, the DATANOSETM is an excellent 3-D selection device. 
Users can easily select and rotate 3-D objects. Objects are selected by pressing the nose against the 
screen and hoovering6 over the object to be rotated. The user can then rotate the object by rotating 
their head. Figure 3 shows how easy it is to rotate an object about the z-axis. Rotation about other 
axes is equally effortless as shown in the following complexity result: N = 0(S ). Note that the DATANOSE 
M offers true user-centered rota­tion in the user s own nasal coordinate system, rather than conventional 
object-centered rotation. Therefore the DATANOSETM empowers the user instead of the object[ACM SigCH190]. 
 4 Human Factors Experiments We were planning to test our new interface device with the canonical 16 
test users, but our funding was limited. In lieu of these extensive tests, we asked one user with no 
previous nose-computer experience (an undergrad, only cost us $2.50). He/she liked it. 5 User Interface 
As shown by previous research and surveys, the user interface takes up between 2 XO and 98 ?10 of the 
code 5Due to the plastic construction, the DATAN OSE~M does not smear the screen nearly as much as a 
human nose. 6Hoovering, v t1 : the act of producing a vacuum 2 : to use a vacuum device (as a cleaner) 
upon 3 : (s[ang,J the act of interacting with a computer using a nose interaction device. Hilton Head, 
South Carolina AP#k&#38;n Dialogue 0-0 4-S Control Model u Figure 4: Seeheim User Interface Model [Sutton7t3]. 
In order to avoid the high cost of creating a user interface for the DATANOSETM the SYSTEM (System that 
reallY doeS creaTE user interfaces that have nice featuMs) User Interface System has been de­ veloped 
over the course of six years by a team of thirty­ two undergraduates. SYSTEM is based on ideas from previous 
User Interface Management Systems, such as Guide [Kilgour85], Guide [Granor86], Guide [Sun91], Guide 
[OW191], Guide [Oren91], Guide [Trident91], and Guide [Kantorowitz89]. SYSTEM allows the user interface 
designer to create a tremendous variety of wonderful, user-friendly, stu­pendous, fascinating direct 
manipulation user interfaces with a minimum of specification. SYSTEM is one of the few systems that, 
in addition to managing the user s windows, will also actually wash them. The SYSTEM system is broken 
down into three sub­systems using a systematic decomposition strategy re­sulting in a systemic user interface 
which is useful and useable by the user. This is based on the Seiheim model [Green83] shown in Figure 
4. In order to specify the Presentation component, the designer writes a BNF description of the graphical 
ele­ments in the user interface. The next step is to define the dialogue using a direct manipulation, 
graphical ed­itor. Here, the designer creates nodes that represent the actions that the user might take, 
and links them together into a meaningful network, to show what com­mand can follow which other command. 
As an example of a SYSTEM transition network, Figure 5 shows the network for an emacs like editor. Next, 
as with most other systems conforming to the Seeheim model, the designer specifies essentially the en­tire 
user interface, by writing code for the little, un­labeled box at the bottom of Figure 4. This code will 
cause the display objects to appear at the correct places, and implement the commands described in the 
dialogue section. Finally, the designer can write the application in whatever language is desired. The 
AI component automatically determines whether any of the specified interactions will cause the user s 
nose to get out of joint. It uses a conventional rule- Figure 5: Example Transition Network based back-propagation 
hidden-Markov model Boltz­ mann neural network perception with a gradient­ descent sigmoid non-linear 
error function based on a frame-based semantic network knowledge representa­ tion system performing massively-parallel 
simulation of thought processes.  6 Future Work Initial research has shown several other body parts 
and articles of clothing to be prime candidates for 1/0 devices: DataArm~ , Data Foot~M, Data tieadTM, 
Data SocksTM, Data MouthTM, Data EyeballsTM, Data Ears M Data Underwear &#38;I, DataShoe~Jf (not to be 
confused with the ShoePhone[Smart# 86]). In addi­tion to exploring new types of clothing, combinations 
of Data*T~ 1/0 devices can provide never before thought of possibilities. For example, the combination 
of the DataGlove~M 7 and the DATA NOSETM allows for a greater range of picking tasks than a simple mouses. 
As another example, the combination of the Data SuitT* 6 and Data Underwear M allows the user to simultaneously 
interact on multiple levels. In addition to developing new Data+ fi~ 1/0 devices and experimenting with 
combinations, more economical versions such as the Power Nose M are being developed. (The PowerNoseTM 
will be compatible with most home video games and will prove indispensable to researchers with a $5.00/day 
budget [Pausch91]). 7Data GloveTM, aNd DataSuitTM, are Registered TradeMarks OF VPL ReSearCh InC. 8WARNING: 
Preliminary research has shown certain combi­nations to be dangerous: for example, the Data Mouth TM 
should not be used with the Data FootTM. Researchers pursuing colnbi­nations of input devises should 
proceed with great caution.  November 11-13, 1991 UIST 91 References [Green83] Green, M. Report on 
Dialogue Specification Tools, in Gunther E. Pfaff (Ed.), User Interface Management Systems, N. Y., N.Y. 
Springer-Verlag, pp. 1109-1234. [Sutton78] Sutton, J. A., Sprague, R. H. Jr., A Study of Display Generation 
and Management in Interac­tive Business Applications. IBM Research Re­port RJ2392(31804), Yorktown Heights, 
N.Y. (1978). [Pausch91] Pausch, R. Virtual Reality on Five Dol­lars a Day, Proceedings of the ACM conference 
on Human Factors in Computing Systems, (1991) pp. 265-270. [Smart#86] Smart, Maxwell, Get Smart, still 
on late night cable TV, drama/adventure TV series, episode 86, (1968). [ACM SigCH190] Chew, J. C., Whiteside, 
J. (Eds.) Em­pozoertng People, ACM press, (1990). [Bewitched] Stevens, Samantha, Bewitched, weekday afternoons 
on local TV, situation comedy TV se­ries, (late 1960 s, early 1970 s). [NASA] Fisher, S., McGreevy, M. 
Humphries, J., and Robinett, W., How to Mount 1/0 Devices to Mo­torcycle Helmets, NASA Tech. Rept. NASA-87­1776, 
(sometime in 1987). [Buxton86] Buxton, W. There s More to Interaction than Meets the Eye: Some Issues 
in Manual In­put. In Norman, D.A. and Draper, S.W. (Eds.), User Centered System Design: New Perspectives 
on Human Computer Interaction, Hillsdale, N. J.: Lawrence Erlbaum Associates, pp. 319-337. [Card78] Card, 
D. K., English, W. K., and Burr, B. J., Evaluation of mouse, rate controlled isometric joy­stick, step 
keys, and text keys for text selection on a CRT, Ergonomics, 21, (1978) pp. 601-613. [Spencer Gifts] 
Gifts, Spencer, Gifi and Novelty Store, Store #234 The Tucson Mall (next to Sears), Tuc­son Arizona, 
85711. [Myers91] Myers, Brad A., AcRONYIvfS: ~cronym Greating Rules Qn ~aming your Machines and &#38;stems 
 Tech. Rept. CMU-CS-91-6969, Carnegie Mellon University, College of Computer Science, Dec., 1991. [Olsen86] 
Olsen, Dan R. Jr., miKe: The Menu Interaction Kontrol Environment , ACM Transactions on Grafix 5, 4, 
(Oct. 1986). [Kilgour85] Gray, P.D, and Kilgour, A.C. GUIDE: A Unix-Based DiaIogue Design System. University 
of Glasgow (UK) Department of Computing Science Research Report #CSC/85/R8. 1985.13 pages. [Granor86] 
Granor, T.E. A User Interface Management System Generator: GUIDE. PhD Thesis. Dept. of Computer and Information 
Science, Moore School, University of Pennsylvania. May, 1986. [Sun91] Sun Microsystems. DevGUIDE: Open 
Windows Developer s Gutde. 2550 Garcia Ave. Mtn. View, CA 94043 [OW191] Owl International. Guide 2.2800 
156th Ave. SE. Bellevue, WA, 98007. [Oren91] Oren, T., Don, A., and Laurel, B. Guides 3.0 , SIGCHI 91 
Conference Video Review. SIG-GRAPH Video Review, Volume 63. [Trident91] Trident Systems Incorporated. 
XGuzde -The Graphic User Interface Development Environ­ment. 10201 Lee Highway Suite 300, Fairfax, VA 
22030. [Kantorowitz89] Kantorowitz, E. and Sudarsky, O. The Adaptable User Interfacej Comm. ACM, 32(11), 
Nov, 1989. pp. 1352-1358. UIST 91 Hilton Head, South Carolina 
			