
 Proceedings of the 1990 Winter Simulation Conference Osman Balci, Randall P. Sadowski, Richard E. Nance 
(eds.) SIMULATION FOR DESIGN, TEST AND EVALUATION, AND TRAINING: RECONCILING THE DIFFERENCES Ronald 
G. Hughes Combat Simulation and Systems Integration McDonnell Douglas Helicopter Company 5000 East McDowell 
Road, Bldg. 531/C240 Mesa, Arizona 85205 ABSTRACT A concept is presented which describes the role of 
simulation (more properly, real-time man-in-the-loop simulation) across the entire life cycle of a weapon 
system. Novel aspects of the concept include the potential for the selective use of the developer's "engineering" 
simulator during operational test and evaluation (OT&#38;E) as well as the merits of a tightly coupled 
approach to the design of the engineering simulator and that of related training devices/simulators. 
Lest the role of the engineering simulator be overstated with respect to its role in systems integration, 
a clear distinction is made between the role of the engineering simulator and that of a "systems integration 
facility" (SIF). Parallels between the prime's use of such a concept and the use of such a concept to 
achieve integration among different Government laboratories is discussed. Lastly, the issue of "fidelity" 
is discussed with respect to current simulation technology limitations and their known effects upon performance 
outcomes. 1. INTRODUCTION Simulation, both real-time man-in-the-loop and non-real-time computer (analytic) 
simulation, represents an important tool in the development and test of advanced weapon system concepts. 
Manned simulation, in addition to becoming an increasingly important design tool for the developer, has, 
in the past ten years, taken on a level of importance for training far beyond that associated with early 
procedural trainers and "simulators." Advances in a number of different simulation technology areas promise 
to revolutionize the manner in which manned simulation is used for both engineering design and test as 
well as training; in particular, advances in low-cost computer image generation systems, distributed 
microprocessor architectures, higher-order programming languages, modular system design, and the ability 
through local and long-haul networking to allow large numbers of heterogeneous systems to operate in 
a real-time '*common operating environment." Rapid advances in computer system hardware are creating 
opportunities which are increasingly making the distinction between "real-time" and "non-real-time" less 
meaningful. We are, in fact, seeing many organizations either physically merging their manned simulation 
and operations research functions or, at a minimum, imposing more deliberate management oversight over 
the long-range research and development activities of each. We are also seeing "simulation" being given 
the status of a "strategic" corporate technology in such large aerospace corporations as McDonnell Douglas. 
In the present paper, I want to deal with three separate but related issues that are important to this 
expanding view of simulation. First, I want to address engineering simulation and its potential application 
across the life cycle of a weapon system. ! want to discuss, in particular, the model which is emerging 
at the helicopter component of McDonnell Douglas and its relationship to some advanced thinking on the 
part of the Army in terms of a preliminary (Army) "master plan" for simulation. As a part of that discussion, 
1 want to draw some parallels between the approach as implemented by the "prime" and the approach as 
it might be implemented between different Government laboratories (a la the draft Army Simulation Master 
Plan). Secondly, I want to focus on a particular aspect of this application, namely the simulation of 
the operational mission environment and where that responsibility might best lie. Lastly I want to address 
certain concerns that all these applications have in common regardless of whether for design support, 
for test and evaluation, or for training -those being the effects of fidelity constraints and limitations 
on engagement/mission outcomes and the problem of "correlation" between outcomes generated under analytic, 
manned simulation, and/or actual range conditions. 2. ENGINEERING SIMULATION: A LIFE CYCLE APPROACH internally 
at the McDonnell Douglas Helicopter Company (MDHC), we are continuing to give a great deal of thought 
to the application of manned simulation across the entire life cycle of a weapon system. This approach 
is being developed and modified in the dynamic context of ongoing work on the Army LH and Apache Longbow 
programs. 2.1 Continuous Emphasis on Mission Effectiveness A key aspect of this overall process for the 
use of manned simulation is being able to design, develop, test, and train, under conditions representing 
the actual mission environment. In the context of "concurrent engineering," it represents an attempt 
to pull the operational mission environment as far "'to the left" in the engineering design process as 
possible. The role of manned simulation in this process is both very mission-oriented and man-centered 
while at the same time being very engineering-oriented in terms of the actual weapon system design itself, 
it is an approach which gives high priority to the human component of system design and to the contribution 
of the human component to overall system effectiveness. 2.2 Modular Development The concept shown in 
Figure 1 depicts that of a highly modular system with the engineering simulator at the core. The simulator 
is represented in the figure by the icon of a dome. Superimposed on the dome is the notion that the engineering 
"'simulator" apart from its cockpit, visual system, etc., is, in its earliest stage, a functional representation 
of the aircraft bus architecture and basic ""rood u les." In order to present the concept in its simplest 
form, the figure shows the "simulator" as Ueing a higher-order module in a system containing three other 
modules: a module for simulator control and performance 231 R.G. Hughes ConceptDevalopment/FSED Operational 
Production Test and Evaluation Key Modules f f T Simulation Gradual Maximum Soltware Introduction Commonality 
Commercially Avnllable ot Operational HW/SW Between Engnr. Sire and Hot Bench I DevQ.Iopment of Hot 
Bench 8810801-6A Incorporation Into Prototype Flight Tea! Vehicle Figure !. Representative Approach 
to a Concept for Life Cycle Manned Simulator Utilization measurement; a module for visual and sensor 
simulation; and a module referred to as the "combat mission environment." These three higher-order modules 
provide the invariant elements of the context in which the engineering simulator matures from pure "simulation" 
(shown in Figure 1 as open boxes with an "S") to a configuration resembling, in part, the hardware/software 
type environment of the systems integration facility (filled boxes indicate use of actual flight hardware 
and software). 2.3 Role in Systems Integration It is important to note that the engi.neering simulator 
is no__._!, intended to be a "systems integration facility" in the sense that all hardware/software integration 
would occur in the engineering simulator, per se. Aircraft hardware and operational flight software are 
integrated in environments that we refer to as the Software Integration Laboratory (SIL) and the Systems 
Integration Facility (SIF). While the engineering simulator does no_._d represent a critical path for 
all hardware/software integration prior to going to the aircraft, the engineering simulator is critical 
in those integration areas (e.g., controls and displays, etc.) where the pilot-vehicle interface is a 
key element of the system design. Thus while the actual aircraft display processor, multi-function displays, 
flight controls, helmet display, etc., would, for example, be expected to be an inherent part of the 
engineering simulator hardware environment, other hardware/software aspects of the actual aircraft (e.g., 
the full mission equipment package, or MEP) might not. When a pilot-in-the-loop requirement is critical 
to the hardware/software integration process, it is possible to physically interface the engineering 
simulator to the actual flight controls or avionics hot bench environments (e.g., the "SIF") in order 
to establish a fullv integrated systems capability. Because the engineering simulator does not represent 
the ideal environment for many aspects of hardware and software integration, many hardware and software 
functions may be simulated or emulated so that the engineering simulator can be used independently of 
its physical interface to the hot bench environment/s (e.g., .for crew station, human factors, aircrew 
training, mission effectiveness studies, etc.). 2.4 Role in Test and Evaluation Under the MDHC concept 
for manned simulation, test and evaluation are continuous functions through the life cycle and not restricted 
to formal customer-imposed requirements. The figure also suggests that the engineering simulator may 
have a critical role to play in the more formal aspects of test and evaluation. In a program such as 
LH, the effectiveness of the proposed FSD design must first be demonstrated (at the end of the demonstration/validation 
phase) in the engineering simulator under representati~ve "mission" conditions. The use of the engineering 
simulator for this function has been referred to by some as a "sim-off" (as opposed to a fly-off of actual 
flight vehicle prototypes.). Later (during FSD), when an actual prototype vehicle exists, the engineering 
simulator will be used to train the aircrews who will participate in the formal developmental and operational 
tests (DTs and OTs). These evaluations, conducted under simulated mission conditions, are important in 
obtaining estimates of mission effectiveness. A "correct" simulation of the mission environment is therefore 
of utmost importance, especially if outcomes are to be used as a basis for a "downselect" between competing 
development teams. Establishment of a "valid" mission environment (to include the activity of an opposing 
force) is critical regardless of whether that environment represents only a "slice" of the battle or 
a full- 232 Simulation for Design, Test and Evaluation, and Training: Reconciling the Differences scale 
representation of the force-on-force conflict. The ability to link one's engineering simulator via a 
long-haul land line or satellite connection to a simulated, force-on-force environment represents one 
possibility for exercising alternative designs in a highly measurable and controlled environment without 
the expense of building actual prototype flight vehicles. In the test and evaluation section of the concept, 
the suggestion is made of a Government owned and operated or leased "facility" (perhaps SIMNET). Such 
a capability would allow the Government or ultimate customer to reach into the actual system design early 
in the process. Such a capability gives the eventual user more of a concurrent role in the actual design 
of the system. That same ability on the part of the user to probe the developer's design in terms of 
its effectiveness also can work in the other direction to allow the developer to place his design in 
the ultimate OT&#38;E environment early in the program. To the extent that real-time, manned simulation 
may represent a means for increasing the concurrent nature of design and evaluation functions, the developer 
is naturally concerned that the outcomes of such evaluations are not affected by artifacts of the simulation 
itself (such as might be the case in terms of performance effects due to simulator fidelity constraints). 
This concern will be addressed in a later section of the paper. 2.5 Coupled Design Approach to Training 
Devices Under the MDHC approach to manned simulation, the engineering simulator is designed in such a 
way that its basic architecture and major modules can be transitioned directly to the aircrew training 
devices. Again. with respect to the notion of concurrent engineering, this represents an attempt to move 
key trainer design and production decisions as far to the left as is feasible, This coupling of engineering 
simulator and training device design does not permit a total "flowdown" of flight hardware and software 
from the engineering simulator to the training devices. Remember that the engineering simulator is not 
a critical path for all aircraft hardware and software. The engineering simulator will not be a perfect 
replica of the actual aircraft hardware and operational flight software. This coupled approach does, 
however, have the advantage.in a concurrent engineering sense of moving major trainer engineering issues 
(selection of image generator, display system, system architecture force cuing hardware and algorithms) 
significantly "to the left," increasing the likelihood of concurrent aircraft and training system availability. 
It also creates an effective instructional environment in which to insure that the human components of 
the system design are fully prepared (trained) prior to any full system evaluation. 2.6 Simulation During 
Production Phase in the production phase shown in the right portion of the figure, the operational aircrew 
training devices are shown as a direct extension of the basic architecture of the engineering simulator. 
The systems integration facility (SIF) is shown in conjunction with its engineering simulator interface 
as being the basis for both the air vehicle and trainer post-development support facility. Engineering 
Change Proposals (ECPs) can be evaluated within both the actual air vehicle and within trainer system 
contexts before approval. There is an additional application for simulation during the production phase. 
To the extent that simulation permits us to provide an effective operational environment around the design 
for both engineering design support and test/evaluation, that same capability can also provide an effective 
environment around the production air vehicle itself for production testing. In some instances, it should 
be possible to "fly" the equivalent of a combat mission before coming off the production line, significantly 
increasing the customer's confidence in the delivered product. 3. AN INTEGRATED APPROACH TO ENGINEERING 
SIMULATION: PARALLELS IN INDUSTRY AND GOVERNMENT APPLICATIONS Manned simulation at MDHC, in conjunction 
with analytic simulation, plays a key role in concept formulation and system design. At MDHC, manned 
and analytic (mission effectiveness) organizations have been physically integrated in order to provide 
a "common environment" for evaluating alternative concepts and system designs (refer to Figure 2). The 
key aspect of this commonality between analytic and manned simulation lies in the definition of the mission 
environment and one's ability to interact with that environment without regard to the real-time or non-real-time 
nature of that interaction. In addition to providing a common (mission) environment for evaluation purposes, 
manned simulation is important in providing a common (software) operating environment for use by developers 
in different areas (e.g., avionics, crew station, flight controls, etc.). On programs such as LH, Longbow 
Apache, and the like, developers represent either different functional organizations within the prime 
or different subcontractors and teammates. As we said earlier, although the engineering simulator (as 
well as the "correlated" use of non-real-time analytic simulation methods) is not the primary systems 
integration function, it does serve as the common ground for the early development and integration of 
capabilities from different sources. The Government is like the prime in that different laboratories, 
usually at different locations, are responsible for different "pieces" of a program (AMES for flight 
controls and crew station, AVRADA for avionics, Rucker for operations/training, OTEA for test and evaluation, 
etc.). In order for manned simulation to provide the common operating environment for cooperative laboratory 
efforts, there must be agreement as to who shall have primary responsibility for establishing the simulator 
architecture and facility and what the rules shall be for different usersilaboratories to interface with 
that facility. The use of engineering simulation as a common operating environment for the different 
systems engineering interests of different laboratory users was a chief systems engineering theme of 
the draft Army Master Simulation Plan [Hailer 1989]. Implied in the draft Master Plan was also the notion 
 that through the proffer establishment of such a common environment, Industry as well as Government 
laboratories could participate. A review of the draft plan by the American Defense Preparedness Association 
(ADPA) pointed out that such an arrangement would take deliberate effort on the part of both the Government 
and Industry in that the promises of being able to network totally heterogeneous hardware/software systems 
as well as being able to do so via yet unproven long-haul technology was currently extremely optimistic. 
Nevertheless, to do so (at some time in the future) represents a direct extension of the approach being 
employed internally by MDHC and others, The concepts explored in the Army's Master Simulation Plan (and 
supported by Darpa's SIMNET initiative) suggest. that we could be on the verge of "networking" independent 
Government laboratories and industry locations together in the same manner that we have come to find 
networking within the business office environment increasingly commonplace. We must be cautious, however. 
Whereas our use of a common alphabet and number system permits us to function in a common operating 
environment for most alphanumeric and mathematical operations in the office place, the factors governing 
the creation of a simulated. common "~mission" environment for tactical svslcms are more complicated. 
233 R.G. Hughes FORCE ON FORCE MISSION ENGAGEMENT SYSTEM SUBSYSTEM 89123663-2 NON-REALTIME REAL-TIME 
Figure 2. The Simulation Continuum 4. TACTICAL "OUTCOMES" AND THE EFFECTS OF SIMULATOR FIDELITY Simulation 
is not just a "tool" but also a technology or set of technologies. In some instances -for example, in 
the area of visual simulation for man-in-the-loop operations -limitations and constraints of current 
technology can have a significant impact upon the effectiveness of simulation as a tool. If one is not 
aware of these limitations, the outcomes of manned simulation studies can differ significantly from outcomes 
generated analytically or derived from actual field conditions. In light of the current enthusiasm for 
low-cost, networked simulators for training and the possible extension of this use for test and evaluation, 
it is important to be aware of some of these limitations and their effects. 4.1 Practice In Simulators 
Influences Operational Outcomes Until recently, real-time man-in-the-loop simulation was capable of supporting 
only "single ship" performances under limited engagement conditions [Hughes et al. 19821. These early 
studies were, however, effective in showing that pilot training, even under such limited single-ship 
conditions, could significantly affect collective performances in operational environments such as RED 
FLAG. These studies were important, too, in showing that meaningful "correlations" could be established 
between the performance of pilots in simulators and the performances of these same pilots under operational 
conditions. 4.2 Effects of Constraints and Artificialities These studies were instructive, too, in 
revealing the impacts of range "artificialities" on mission outcomes. Hughes found attrition data from 
the RED FLAG environment to differ markedly from that obtained in the simulator under similar, but not 
identical, conditions. Attrition data from the simulator were, in fact, found to agree better with computer 
simulation predictions than with actual operational range data. The area of most significant artificiality 
was associated with simulation of the surface-to-air threat [see Killion 1986]. Just as Killion was able 
to demonstrate the effects of EW threat simulation fidelity on weapon system performance, other studies 
[Kerchner et al. 1983; Hughes and Brown 1985] were showing that simulator fidelity constraints (especially 
in the visual area) could result in significant alteration of mission outcomes. Kerchner's data, which 
dealt with variables affecting simulator air combat outcomes, showed that such constraints could, in 
fact, change the entire nature of the engagement itself, not simply the quantitative level of the outcome. 
4.3 Do Operational Tests Sometimes Underestimate Effectiveness? The Hughes data are also instructive 
from a different perspective. Although Hughes used "mission-ready'" subjects in conjunction with a scheduled, 
unit RED FLAG training exercise, performances in the simulator were continuing to improve even when subi~cts 
returned to the simulator for additional practice following the two-week RED FLAG exercise. Even though 
the minimum simulator training prior to RED FLAG was able to improve RED 234 Simulation for Design, Test 
and Evaluation, and Training: Reconciling the Differences FLAG outcomes by 15-20 percent in terms of 
sorties survived, the fact that asymptotic performance was never achieved in the simulator suggests that 
most OT&#38;E activities never observe system performance under conditions where the aircrew component 
is fully trained. The sensitivity of outcomes to such "fidelity effects" is a problem for both analytic 
and real-time simulation. For traditional computer simulation approaches, fidelity effects are most often 
the result of lack of understanding of how to model essential variables; for real-time simulation, such 
effects are most often associated with technology constraints.., particularly in the area of visual simulation 
for the human operator [Hughes 1989, 19901 . 4.4 Simulators, SIMNET, and OT&#38;E Support There is a 
serious and growing interest in using manned simulation to augment conventional operational test and 
evaluation (OT&#38;E) resources [Shipley et al. 1988; Hughes t9881. Shipley et al. investigated the technical 
feasibility of such an approach in the context of the Army Scout-Attack mission. In particular, Shipley 
focused on how one might effectively augment use of the developer's high-fidelity engineering simulator 
with, other low-cost "local" simulations/simulators in order to provide an effective battlefield context 
[see also Blizek 19881. Shipley also addressed the option of providing a long-haul interface to ,SIMNET 
[see Thorpe 1988]. Such an approach would, in theory, permit the networking of either the developer's 
high-fidelity engineering simulator or the simulation of multiple platforms of lesser, but acceptable, 
fidelity into the SIMNET battlefield consisting of both manned adversaries and some degree of simulated 
opposing force (SIMOPFOR). The approach is attractive for systems where simulator technology constraints 
(especially visual) would not play a major role. However, the use of SIMNET for aviation elements with 
significant out-the-window visual requirements appears inconsistent with what we know about the effects 
of fidelity limitations (especially visual) on engagement outcomes [Hughes 1989, 19901 . The use of SIMNET 
for augmenting operational test and evaluation has several problems. These are more pragmatic than technical. 
First, a SIMNET exercise is difficult to manage logistically and is labor-intensive. Part of the inherent 
advantage of simulation is that it is readily "available" and, other than the O&#38;M costs of the simulation 
facility, does not involve a significant requirement for operational equipment and/or personnel. A second 
issue concerns the "free play'" nature of the SIMNET operation. The apparent fidelity of the large-scale 
force-on-force aspects of the engagement leads some to infer confidence in outcomes derived from a "sample 
of one." There can be a dangerous tendency to "'come off freeze" and see what happens.., rather than 
to utilize the simulation to increase the number of observations possible under a controlled set of conditions 
carefully derived from the requirements of specific test events or issues. What would be helpful would 
be for the developer to remotely (by long haul) link into an approved SIMNET scenario utilizing the SIMOPFOR, 
where the performance (or general rules governing performance) of the SIMOPFOR was selectable depending 
upon the needs of the developer. Use of the SIMOPFOR would make possible a common operating (mission) 
environment for all developers on the program and would do so without the dependency associated with 
a real-time SIMNET exercise. Such an approach would do three things: first, it would serve to standardize 
the target and threat laydowns used by individual contractors; second, it would provide the Government 
with a degree of control over test and evaluation aspects of development: and third, it would free the 
contractor/developer of the cost of developing and maintaining his own "mission" environment. 5. SUMMARY 
OF KEY POINTS a. Simulation, both manned and analytic, represents significant tools in the development 
and evaluation of advanced weapon system concepts and their associated mission effectiveness. b. Advances 
in technology are making traditional distinctions between manned and analytic approaches in terms of 
"real time" less meaningful. c. An effective "simulation" approach is one that fully integrates manned 
and analytic methods. d. Engineering (manned) simulation can provide an effective "common operating 
environment" (COE) for the development, integration, and test of capabilities developed as individual 
stand-alone "modules." e. A common operating environment, deliberately conceived and implemented, represents 
the central core of the Army's draft Master Simulation Plan. f. A central apsect of the common operating 
environment is the simulation of the "mission" environment (target and threat laydowns, threat behavior, 
etc.). Responsibility for standardizing mission environment definition for different users is extremely 
important. g. A force-on-force simulation environment, such as that being developed for SIMNET, represents 
a key requirement in the use of simulation to augment conventional operational test and evaluation (OT&#38;E) 
resources. h. The results of numerous visual simulation studies indicate that engagement outcomes can 
be significantly affected by image generation and display system constraints. i. Low-cost simulation 
is generally associated with visual system constraints and limitations and should be considered suspect 
with respect to engagement fidelity.  6. CONCLUSION Simulation, broadly defi, ned, without respect to 
the traditional boundaries of real-time or non-real-time, provides us with the exciting potential of 
being able to clearly "see the future" to the extent that we are able to understand and correctly represent 
the physical relationships between natural events. Our simulations in the past have lacked the ability 
to model the most difficult of natural events, those involving the behavior of the human element in our 
systems. Our understanding of human performance, especially under complex conditions such as combat, 
increases slowly. However, manned simulation and especially recent advances in our ability to expand 
the manned simulation "battlefield" are now providing us an important ability to observe human behavior 
under conditions approaching those of actual combat. Through networking, not only can we permit independently 
developed "modules" to communicate in a "common environment" but perhaps in the near future we shall 
also be able to permit Government and Industry to participate within common environments for design, 
test, and evaluation. The technology still has limitations. Simulation is still not "the real thing.~ 
As we move into situations where simulation represents the only means to explore the relationships between 
system performance (especially the human element of that performance) and key variables of interest, 
we cannot loose sight of the criterion problem. How much fidelity is enough?.., enough for training, 
enough for engineering design, enough for test and evalualion? The same lechnolog? that perrnil~ us to 
235 R.G, Hughes advance to new levels continues to constrain us as well. We have mentioned one such technology 
here, that of visual simulation and its limitations in terms of its effects upon human operator perfor- 
mance. Simulation is a tool, a valuable tool indeed, but like any tool, it is valuable only when used 
with a full understanding of its limitations. REFERENCES Blizek, Rd. (1988), "Operational Test and Evaluation 
Through Combined Arms Team Combat Simulation," In Proceedings of the 1988 American Institutes of Aeronautics 
and Astronautics Flight Simulation Technologies Conference, AIAA, Dayton, OH. Haller, D. (1989), "Army 
Simulation Master Plan (Draft)," Head- quarters, U.S, Army, Army Material Command, Washington, DC. Hughes, 
R., D. Graham, R. Brooks, R. Sheen, and T. Dickens (1982), "Tactical Ground Attack: On the Transfer of 
Training from Flight Simulator to Operational Red Flag Exercise," In Proceedings of the 26th Annual Human 
Factors Society Meet- ing, Human Factors Society, Seattle, WA. Hughes, R. and L. Brown (1985), "Flight 
Simulator: Effects of Vis- ual Display Field of View on A-10 Close Air Support Perfor- mance," AFHRL-TR-84-58, 
Operations Training Division, Air Force Human Resources Laboratory, Williams Air Force Base, AZ. Hughes, 
R.G. (1988), "The Application of Manned Simulation to Operational Test and Evaluation: A Logical Extension 
of the Trend Toward the Modular Development and Integration of Training and Engineering Simulation During 
Weapon System Design," In Proceedings of the 1988 Interservice/Industry Training Systems Conference, 
ADPA/NSIF, Orlando, FL. Hughes, R.G. (1989), "Visual Simulation: Capabilities and Con- strains with Respect 
to Operational Test and Evaluation," In Proceedings of the 1989 National Aerospace and Electronics Conference, 
AIAA, Dayton, OH. Hughes, R.G. (1990), "Current Simulator Visual System Limita- tions and Their Measured 
Effects Upon Engagement Out-comes," In Proceedings of the 1990 Close Combat (Light) Sim- ulation Technology 
Conference, ADPA, Albuquerque, NM. Kerchner, R., A. Lee, and R. Hughes (1983), "Combat Simulation Visual 
Display Requirements: An Application of Engagement Simulation Modeling," AFHRL-TR-82-39, Operations Train- 
ing Division, Air Force Human Resources Laboratory, Wil-liams Air Force Base, AZ. Killion, T. (1986), 
"Electronic Combat Range Training Effective- ness," AFHRL-TR-86-9, Operations Training Division, Air 
Force Human Resources Laboratory, Williams Air Force Base, AZ. Shipley, B., R. Blizek, J. Hansen, R. 
Hughes, R. King, and G. Rob- ertson (1988), "Scout/Attack Team Test Study: Technical Re- port," Submitted 
to the Directorate of Combat Developments and TRADOC Systems Manager for Scout Helicopters, U.S. Army 
Aviation Center, Fort Rucker, AL. Thorpe, J.A. (1988), "Netted Engagement Simulation," Presented at American 
Institutes of Aeronautics and Astronautics Flight Simulation Technology Conference, Atlanta, GA. 236 
  
			