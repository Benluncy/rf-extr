
 Downgrading Policies and Relaxed Noninterference Peng Li Steve Zdancewic University of Pennsylvania 
University of Pennsylvania lipeng@cis.upenn.edu stevez@cis.upenn.edu ABSTRACT In traditional information-.ow 
type systems, the security policy is often formalized as noninterference properties. How­ever, noninterference 
alone is too strong to express security properties useful in practice. If we allow downgrading in such 
systems, it is challenging to formalize the security pol­icy as an extensional property of the system. 
This paper presents a generalized framework of downgrad­ing policies. Such policies can be speci.ed in 
a simple and tractable language and can be statically enforced by mecha­nisms such as type systems. The 
security guarantee is then formalized as a concise extensional property using program equivalences. This 
relaxed noninterference generalizes tradi­tional pure noninterference and precisely characterizes the 
information released due to downgrading.  Categories and Subject Descriptors D.3.3 [Programming Languages]: 
Language Constructs and Features Constraints, Data types and structures, Frame­works; F.3.1 [Logics and 
Meanings of Programs]: Spec­ifying and Verifying and Reasoning about Programs Speci­.cation Techniques, 
Invariants, Mechanical veri.cation; K.6.5 [Management of Computing and Information Sys­tems]: Security 
and Protection. General Terms Languages, Design, Security, Theory.  Keywords Downgrading policies, 
information .ow, language-based se­curity, relaxed noninterference, program equivalence. 1. INTRODUCTION 
The Challenge of Downgrading In this paper we focus on a speci.c area of computer secu­rity research, 
namely, language-based information-.ow secu­rity [17], where the target systems are computer programs. 
Permission to make digital or hard copies of all or part of this work for personal or classroom use is 
granted without fee provided that copies are not made or distributed for pro.t or commercial advantage 
and that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, 
to post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 
05, January 12 14, 2005, Long Beach, California, USA. Copyright 2005 ACM 1-58113-830-X/05/0001 ...$5.00. 
The security properties we care about are con.dentiality and integrity, speci.ed by information-.ow policies, 
which are usually formalized as noninterference [4] [8], a global extensional property of the program 
that requires that con­.dential data not a.ect the publicly visible behavior. Such information .ow policies 
can be enforced by mechanisms like type systems and static program analysis [19] [13] [14] [1]. In information-.ow 
control, each piece of data is anno­tated by a label that describes the security level of the data. Such 
labels usually form a partially ordered set. Pure non­interference policies only allow data .ow from 
low security places to high security places. As a program runs, the la­bel of data can only become higher. 
This restriction is not practical in most applications. Take the example of a login process, the password 
is a secret and it has a higher secu­rity level than the user-level data. By comparing the user input 
with the password and sending the result back to the user, data .ows from high to low, thus the noninterference 
property is violated. We use the word downgrading to specify information .ow from a high security level 
to low security level. It is also called declassi.cation for con.dentiality and endorsement for integrity. 
As we allow downgrading in the system, pure noninterference no longer holds and the security policy of 
the whole system becomes much more complex. Instead of using an elegant extensional property such as 
noninterfer­ence, most downgrading policies are intensional, specifying exactly what circumstances information 
can .ow in which order. To formally specify such policies, we may require an accurate description of 
these intensional properties in a complex piece of software, which can be very complicated. Such security 
policies can be hard to specify, understand and enforce. It is also di.cult to prove the soundness of 
the corresponding enforcement mechanism. Our Contribution We approach the downgrading problem by allowing 
the user to specify downgrading policies. Weuse a typesystemto enforce such policies, and formalize the 
security goal as an extensional property called relaxed noninterference,which generalizes pure noninterference 
and accurately describes the e.ects due to downgrading. Our research is based on the observation that 
a noninterfering program f(h, l)can usually be factored to a high security part fH(h, l)and a low security 
part fL(l) that does not use any of the high­level inputs h. As a result, noninterference can be proved 
by transforming the program into a special form that does not depend on the high-level input. Relaxed 
noninterference can then be formalized by factoring the program into the composition of such a special 
form and some functions that depend on the high-level inputs, which we treat as down­grading policies. 
 2. BACKGROUND AND RELATED WORK Before presenting our results in detail, it is useful to de­scribe some 
prior approaches to the problem of downgrading. DLM and Robust Declassi.cation The decentralized label 
model (DLM) invented by Myers and Liskov [10] puts access control information in the security labels 
to specify the downgrading policy for the annotated data. Di.erent mutually-distrusting principals can 
specify their own access control rules in the same label. Such labels are well-structured and can be 
used to express both con­.dentiality and integrity. Downgrading is controlled based on the code authority 
and the access control information in the label of data to be downgraded: each principle can only weaken 
its own access control rules. Practical languages such Jif [9] have been built based on the DLM. The 
downgrading policy speci.ed by the DLM is highly intensional and it is di.cult to formalize as an extensional 
property of the program. Once downgrading happens in the program, the noninterference property is broken 
and the user cannot reason about the e.ects of downgrading. Trusted code can downgrade its data in arbitrary 
ways, whereas untrusted code cannot downgrade any data that does not belong to it. Robust declassi.cation 
[20] improves the DLM by impos­ing a stronger policy on downgrading that requires the de­cision to perform 
downgrading operations only depend on trustworthy (high-integrity, untainted) data. Such a policy can 
be formalized and the security guarantee can be ex­pressed as an extensional property of the system [11]. 
Nev­ertheless, it only addresses one particular useful policy for downgrading. It cannot provide detailed 
guarantees on how the data is downgraded, and downgrading is still forbidden for untrusted code. Our 
work borrows some philosophy from robust declassi.­cation. Although we are concerned with con.dentiality 
and the process of declassi.cation, the policies for downgrad­ing can be thought of as integrity properties 
of the system: they require the downgrading operation to be trustworthy and correct with respect to some 
speci.cation. Complexity Analysis and Relative Secrecy To look for a system-wide extensional guarantee 
with the existence of downgrading, Volpano and Smith proposed the relative secrecy [18] approach as a 
remedy for noninterfer­ence. They designed a type system that contains a match primitive, where the secret 
can only be leaked by comparing it to untrusted data via this primitive. The security goal is then formalized 
as a computational complexity bound of the attack. However, this approach lacks some .exibility in practical 
applications. It assumes that there is a single secret in the system and the attack model for the system 
is .xed, thus it only enforces one particular useful downgrading policy using a particular mechanism. 
To express and enforce other downgrading policies like the parity of the secret integer n can be leaked 
, we need completely di.erent frameworks and mechanisms. Abstract Noninterference Giacobazzi and Mastroeni 
used abstract interpretations to generalize the notion of noninterference by making it para­metric to 
what the attacker can analyze about the informa­tion .ow [3]. Many downgrading scenarios can be formally 
characterized in this framework, and the security guarantee is formalized in a weakened form of noninterference. 
How­ever, this framework is mainly theoretical. To practically apply this theory in building program 
analysis tools, we need to design ways to express the security policies and mecha­nisms to enforce such 
policies. Intransitive Noninterference Our work has a close relationship to intransitive noninter­ference 
[15] [7], where special downgrading paths exist in the security lattice. During downgrading, data can 
.ow in­directly through these paths, although there is no direct lattice ordering between the source 
and the destination. We improve this idea of intransitive noninterference by param­eterizing the downgrading 
paths with actions, and globally reasoning about the e.ects due to downgrading. Quantifying Information 
Flow Some interesting work has been done using quantitative ap­proaches [5] [6] [12] to precisely estimate 
the amount of in­formation leakage when downgrading is available. Drawing on this research, we order 
the security levels by comparing their abilities to leak information. Programs leaking more information 
are considered less secure. However, comparing the quantity of information leakage does not have directly 
sensible meanings in many situations. Instead of using real numbers as metrics for information leakage, 
we use program fragments; the information order is de.ned among these pro­grams. Delimited Information 
Release Sabelfeld and Myers [16] proposed an end-to-end security guarantee called delimited release that 
generalizes nonin­terference by explicitly characterizing the computation re­quired for information release. 
Our work generalizes delim­ited release in two ways. First, we treat the computation re­quired for declassi.cation 
as security policies and use these policies to represent security levels for each piece of data in the 
system. Second, downgrading can be .ne-grained and implicit in our framework. We formalize the security 
guar­antee by transforming a safe program to the form of delim­ited release, where all the downgrading 
expressions explicitly match the downgrading policies. 3. A FRAMEWORK OF DOWNGRADING POLICIES 3.1 The 
Motivation The focus of our research is studying downgrading policies. Instead of studying who can downgrade 
the data as the decentralized label model did, we take an orthogonal direc­tion and study how the data 
can be downgraded .Instead of having various mechanisms that provides vastly di.erent kinds of security 
guarantees, we would like to have a more general framework where the user can specify downgrading policies 
that accurately describes their security requirement, and have the enforcement mechanism carry out such 
poli­cies. We have the following goals for downgrading policies: Expressiveness: The programmers should 
be able to spec­ify a rich set of downgrading policies depending on their highly-customized security 
requirement. Such policies are .ne-grained and describes security requirements for each piece of data 
in the system. For example: some data is a top secret and we do not allow any information to leak from 
it; some secrets can be downgraded by encrypting them; for some secret data we can safely reveal the 
lowest several bits; root passwords can only be leaked by comparing them to public data; etc. Representability: 
The downgrading policies should be for­mally speci.ed in representable forms. It should be easy for the 
programmer to write down their policies and such policies are meant to be understood by both human and 
machines. In this paper, we use a simple programming lan­guage to express downgrading policies and treat 
these poli­cies as security levels so that the programmer can use them as type annotations. Tractability: 
Such policies must be enforceable by some mechanisms such as type systems or model checking. Since we 
are extending the traditional language-based information­.ow security, it is desirable to use similar 
static approaches, where the policies are enforced at compilation time rather than at run time. Extensional 
Guarantee: This is the main challenge we face: if the policies are enforced by some mechanism, what are 
the security guarantees they bring to the user? The policies are .ne-grained and the enforcement mechanisms 
are usually intensional, yet we would like to have a formal, system-wide, extensional security guarantee 
that looks sim­ple, elegant, understandable and trustworthy. We also want to formally prove the soundness 
of the enforcement mecha­nism with respect to this security guarantee. In this paper, we express such 
guarantees in a form of relaxed noninter­ference, where the e.ects of downgrading policies can be accurately 
characterized by program equivalences. 3.2 Downgrading Policies as Security Levels The main idea of 
our framework is to treat downgrading policies as security levels in traditional information .ow sys­tems. 
Instead of having only H and L in the security lattice, we have a much richer lattice of security levels 
where each point in the lattice corresponds to some downgrading pol­icy, describing how the data can 
be downgraded from this level. For example, the policy corresponding to H is that the information cannot 
be leaked to public places by any means, whereas the policy implied by L is that the data can be freely 
leaked to the public places. In our policy language, we express H using constant functions and express 
L using identity functions. The security levels in the middle of the lattice are more interesting. We 
take the following program as an example, where the security policy for secret is that the secret can 
only be leaked by comparing the lowest 64 bits of its hashed value to some public data , and input,output 
have security level L. Example 3.2.1 (Downgrading). 01 x := hash(secret); 02 y:= x%2^64; 03 if (y=input) 
then output:=1 else output:=0; 04 z:=x %3; Downgrading happens when the secrets are involved in some 
computation. In the .rst statement, we computed the hash of the secret, so the downgrading policy for 
x should be that x can only be leaked by comparing its lowest 64 bits to some public data . After the 
second statement, the policy for y should be that y can only be leaked by comparing it to some public 
data . In the branching statement, the policy for the conditional (y=input) should be L because y is 
compared to input. Therefore, the information leak from secret to output is safe with respect to the 
downgrading policy of secret. However, in the last statement, we cannot .nd a way to downgrade z while 
satisfying the policy for x and secret. To be safe, the security level for z can only be H: it cannot 
be downgraded by any means. With the existence of downgrading, the ordering among these security levels 
is more complicated than in the tradi­tional security lattice. Brie.y speaking, there are two kinds of 
ordering here. Subtyping order. We can extend the traditional L . H lattice with something in the middle: 
L . ls . H where ls denotes the security level of secret.We can see that it is always safe for information 
to .ow from lower levels to higher levels, because it is equivalent to making the downgrading policy 
more restrictive. How­ever, the security level lx for x has no such ordering with ls because it does 
not make sense to give x the same downgrading policy as secret doing so will violate the downgrading 
policy for secret.  Downgrading order. Although we do not have lx . ls, it is true that ls can be downgraded 
to lx via certain computation, which we call an action. Weuse theno­  a tation ls . lx to specify the 
downgrading relation via action a. This is similar to the approach of intran­sitive noninterference, 
but the key di.erence is that, the downgrading relation is determined by the seman­tics of the security 
levels and the action a performed, and this information is crucial for reasoning about the global e.ects 
of downgrading. 3.3 The Road Map Our framework consists of three parts: policy speci.cation, enforcement 
mechanism and the security guarantee.The basis of our theory is a well-studied, security-typed language 
.sec as shown in Figures 3, 4 and 6, where security levels from the simplest security lattice LLH = {L, 
H} are used as type annotations. A noninterference theorem can be proved for languages like .sec. The 
rest of this paper is organized in a step-by-step fash­ion. We .rst set out to de.ne a lattice of local 
downgrading policies called Llocal in Section 4, where each policy describes how the secret can be downgraded 
by interacting with con­stants and low-level public information. Correspondingly, we extend the language 
.sec to .. in Section 5 with typing local rules for downgrading. We formalize the security guarantee 
as a relaxed form of noninterference using program equiv­alences and prove the soundness of our type 
system. In Section 6 and 7, we extend Llocal to Lglobal with global down­grading policies that describes 
how secrets can be leaked by composing multiple secrets together, and patch the type sys­tem to .. with 
a similar relaxed noninterference theorem. global We discusses the application of this framework in Section 
8 and conclude in Section 9.  4. LOCAL DOWNGRADING POLICIES 4.1 Label De.nition De.nition 4.1.1 (The 
policy language). In Figure 1. Types t ::= int | t . t Constants c ::= ci Operators . ::= +,-,=,... Terms 
m::= .x:t. m | mm | x | c | m. m Policies n ::= .x:int.m Labels l ::= {n1,...,nk} (k = 1) Figure 1: Llocal 
Label Syntax The core of the policy language is a variant of the simply­typed .-calculus with a base 
type, binary operators and con­stants. A downgrading policy is a .-term that speci.es how an integer 
can be downgraded: when this .-term is ap­plied to the annotated integer, the result becomes public. 
A label is a non-empty set of downgrading policies, specifying all possible ways to downgrade the data. 
A label can be an in.nite set. Each label represents a security level and can be used as type annotations. 
For example, if we have x : int{m1} where m1 is de.ned as .y : int.y%4, then the result of the application 
(m1 x) = x%4 is considered a pub­lic value. Take the password checking example, we can let p: int{m2} 
where m2 is .x: int..y: int.x = y, so that the application (m2 p) = .y: int.p = y is considered as a 
pub­lic closure, assuring that the only way to leak information about p is to use this closure and perform 
the comparison with p. De.nition 4.1.2 (Label well-formedness). 1. A policy language term m is well-typed, 
i. f m: t in the simply-typed .-calculus. 2. A label l is well-formed, i. .n . l, n is well-typed. 
3. Let Llocal be the set of all well-formed labels (both .nite and in.nite).  Note. In the rest of the 
paper, we implicitly assume that all the labels are well-formed in our discussion. De.nition 4.1.3 (Term 
equivalence). We use conven­tional ß- . equivalences for .-calculus, as de.ned in Figure 2. We write 
m1 = m2 as an abbreviation for f m1 = m2 : t. We write G f m1 = m2 as an abbreviation for G f m1 = m2 
: t. The rules in Figure 2 are call-by-name equivalences, which may not preserve the termination behavior 
in a call-by-value semantics. It is important that our policy language has no .xpoints and programs never 
diverge. De.nition 4.1.4 (Term composition). If f m1 : t1 . t3, f m2 : t2 . t1, then the composition 
of m1 and m2 is de.ned as: m1 . m2 = .x:t2.m1 (m2 x). 4.2 Label Interpretation Each label is syntactically 
represented as a set of down­grading policies, but the semantics of the label includes more than the 
speci.ed policies. Generally speaking, if n . l and n' = m.n,then n' is also a valid downgrading policy 
implied G f m:t Q-Refl G f m= m: t G f m1 = m2 : t Q-Symm G f m2 = m1 : t G f m1 = m2 : t G f m2 = m3 
: t Q-Trans G f m1 = m3 : t G,x:t1 f m1 = m2 : t2 Q-Abs G f .x:t1.m1 = .x:t1.m2 : t1 . t2 G f m1 = m2 
: t1 . t2 G f m3 = m4 : t1 Q-App G f m1 m3 = m2 m4 : t2 G f m1 = m2 : int G f m3 = m4 : int Q-BinOp 
G f m1 . m3 = m2 . m4 : int G,x:t1 f m1 :t2 G f m2 :t1 Q-Beta G f (.x:t1.m1) m2 = m1{m2/x} : t2 ¬free(x,m)G 
f m:t1 . t2 Q-Eta G f m= .x:t1.mx : t1 . t2 Figure 2: Term Equivalences G f m1 = m2 : t ' by l, because 
each time we apply nto the data x annotated by l, it is equivalent to .rst applying n to x to get a public 
result (nx), then applying m to the public result, so that m (nx) = n' x can also be considered as public. 
There­fore, a .nite label implies in.nite number of downgrading policies and we need to de.ne the interpretation 
of a label l to represent all downgrading policies such that, when the policy term is applied to the 
data annotated by l,the result is considered public. De.nition 4.2.1 (Label interpretation). Let S(l) 
denote the semantic interpretation of the label l: S(l)= {n' | n' = m. n, n . l} This label semantics 
enjoys the following properties: Lemma 4.2.1 (Properties of S(l)). 1. l . S(l)= S(S(l)). 2. n . S(l) 
i. .n' . l,.m, n= m. n'. 3. l1 . S(l2) i. .n1 . l1, .n2 . l2,.m, n1 = m. n2. 4. l1 . S(l2) i. S(l1) 
. S(l2).  We can now reason about the equivalence of labels with respect to the label semantics. Two 
labels are considered as structurally equivalent if they denote the same set of down­grading policies: 
De.nition 4.2.2 (Structural equivalence of labels). We de.ne the structural equivalence =l on Llocal: 
l1 =l l2 i. S(l1)= S(l2) Corollary 4.2.1 (Properties of =l). 1. l =l S(l) 2. l1 =l l2 i. l1 .S(l2) and 
l2 .S(l1)  4.3 Label Ordering To organize Llocal as a lattice, we need to introduce partial ordering 
among the labels and to de.ne joins and meets. De.nition 4.3.1 (Label ordering). Let .be a binary relation 
on Llocal such that l1 .l2 i. S(l2) .S(l1) This de.nition relies on the set inclusion relation of label 
interpretations. If l2 has fewer downgrading policies than l1 has, then l2 denotes a higher security 
level. We can al­low information to .ow from l1 to l2 without changing its content. If we use labels 
as type annotations, the ordering of labels determines the subtyping relation: if l1 .l2,then intl1 =intl2 
. Corollary 4.3.1. .is a partial order on Llocal. Corollary 4.3.2. l1 .l2 i. l2 .S(l1). De.nition 4.3.2 
(Joins and meets). The upper bound for a set of labels X is a label l such that x .X implies x .l.The 
join or the least upper bound for X is an upper bound l such that for any other upper bound z of X, it 
is the case that l .z.  The lower bound for a set of labels X is a label l such that x .X implies l 
.x.The meet or the greatest lower bound for X is a lower bound l such that for any other lower bound 
z of X, it is the case that z .l.  The notation UX and nX denote the join and the meet of X. The notation 
l1 Ul2 and l1 nl2 denote the join and the meet of {l1,l2}. Because we de.ned the partial ordering using 
subset rela­tion, the joins and meets of labels share the same structure as sets: Corollary 4.3.3 (Interpreting 
joins and meets). 1. .X,.l1,.l2 such that l1 =l UX and l2 =l nX 2. S(UX)= n(S(X)), S(l1 Ul2)= S(l1) 
nS(l2) 3. S(nX)= .(S(X)), S(l1 nl2)= S(l1) .S(l2)  It is inconvenient to use in.nite interpretations 
to rep­resent the result of join and meets. The following lemma shows how to compute joins and meets 
directly. Lemma 4.3.1 (Computing joins and meets). 1. l1 nl2 =l l1 .l2. 2. l1 Ul2 =l {n |.m1,.m2,.n1 
.l1,.n2 .l2, n =m1 .n1 =m2 .n2}.  De.nition 4.3.3 (Highest and lowest labels). H = ULlocal, L = nLlocal 
The following lemma shows the beauty of this lattice. H corresponds to the most restrictive downgrading 
policy, where the secret cannot be leaked by any means. To ex­press such a policy in our policy language, 
we can use a constant function .x: int.c as the only policy in the label. The intuition is that this 
function is completely noninterfer­ing, i.e. we can learn nothing about its input x by studying its output 
c. On the other hand, L corresponds to the least restrictive policy, where the data itself is already 
considered as public. The simplest way to express this fact is to use the identity function .x: int.x 
as the policy, meaning that we can leak all information about this piece of data. Lemma 4.3.2. H =l {.x:int.c}, 
L =l {.x:int.x} Proof: For any well-formed label l, we can prove that (.x: int.c) . S(l): .n . l, suppose 
f n : int . t,we construct the term .x: t. c so that (.x: t. c) .n =l .x:int.c, which implies (.x:int.c) 
.S(l). Therefore, (.x : int.c) . S(H), {.x : int.c}. S(H) and H .{.x: int.c}. By de.nition of H we also 
have {.x:int.c}.H,so that H =l {.x:int.c}. .n .L, n =n.(.x: int.x), so L .S({.x: int.x}) and {.x: int.x}.L. 
By de.nition of L,wealso have L .{.x:int.x}, therefore L =l {.x:int.x} . We can further show that all 
the noninterfering functions are in the interpretation of H. In this particular scenario, con­stant functions 
and noninterfering functions have the same meaning. We can also show that all the policy functions, both 
interfering and noninterfering, are in the interpreta­tion of L. For a label l between H and L, the policy 
terms precisely de.ne a set of permitted interfering functions. Theorem 4.3.1 (Lattice completeness). 
The pair (Llocal,.)is a complete lattice.  4.4 Label Downgrading Downgrading happens when data is involved 
in some com­putation. The security level of data changes depending on the computation performed. We describe 
such computation as an action and formalize downgrading as a ternary rela­ a tion: l1 . l2. De.nition 
4.4.1 (Multi-composition). Suppose fm1 :int .t, fm2 :t1 .t2 .....tk .int, the multi-composition of m1 
and m2 is de.ned as: m1 8m2 = .y1 :t1. ....yk :tk.m1(m2 y1 ...yk) De.nition 4.4.2 (Actions). We use the 
metavariable a to range over actions. An action is a .-term that has the same syntax as a downgrading 
policy function. That is, the metavariable a and n range over the same set of terms. De.nition 4.4.3 
(Downgrading relation). We use the a notation l1 . l2 to denote that l1 can be downgraded to l2 a via 
the action a. Given a well-typed action a, . is a binary relation on Llocal: a l1 . l2 i. .n2 .S(l2),n2 
8a.S(l1) Example 4.4.1 (Downgrading). Suppose we have an integer u at security level l1,where l1 is de.ned 
as: l1 = {n1},n1 = .x :int..y :int..z :int. (x%y)= z Suppose we have another integer v at security level 
L. What is the security level for (u%v)? We can de.ne an action that describes this computation step: 
a = .x :int..y :int.x%y The result has a security level l2: l2 = {n2},n2 = .x :int..z :int.x = z a Labeled 
s ::= tl types t ::= int | (s . s) Programs e ::= (.x :s. e)l | ee | x | c | s | . | e . e | if e then 
e else e | .xl r(x)= e | r Secret inputs s ::= si Public inputs . ::= .i Figure 3: .sec, .. Syntax local 
De.nition 5.1.1 (Local Downgrading Policies). Let S(si) denote the security label for si. It is easy 
to verify that l1 . l2, because n2 8 a = n1. In this system, we aim for an end-to-end style security 
guarantee. For each secret input si of the program, the Lemma 4.4.1. user speci.es a label S(si) as its 
downgrading policy. For example, the policy for the password may be: a a 1. If l1 . l2 and l2 l3 then 
l1 . l3. S(spwd)= {(.x :int..y :int.x = y} a a 2. If l1 . l2 and l3 l1 then l3 . l2. which only allows 
downgrading by comparing the password The above lemma shows very useful properties of down-to a value 
at security level L. The policy for the variable aa grading. It implies that if l1 . l2,then l1 . H, 
but it is not secret in Example 3.2.1 can be written as: very useful to use H as the result because it 
simply forbids any further downgrading. We can see that downgrading is not deterministic: given l1 and 
a, there are many targets l1 that can be downgraded to via a. The questions are: which label is the most 
useful result, and how to .nd it? De.nition 4.4.4 (Lowest downgrading). Let . (l, a) be the greatest 
lower bound of all possible labels that l can be downgraded to via a: ' a ' S(ssecret)= {(.x :int..y 
:int. (hash(x)%264)= y} where the hash function is a function provided by the ex­ternal library and it 
can be modeled as an operator in our system.  5.2 The Type System De.nition 5.2.1 (Type stamping). tl1 
U l2 = t(l1l2). Most common typing rules are in Figure 4 and we call . (l, a)= n{l | l l } them .sec 
rules, because they are standard typing rules in traditional security-typed languages. The downgrading 
rule . Lemma 4.4.2. is in Figure 5. We only listed the DLocal-Left rule, and a . (l, a) . omitted it 
symmetrical case, the DLocal-Right rule. The 1. l subtyping rules are listed in Figure 6. a l ' then 
. (l, a) l ' For simplicity, we require that all the .xpoint functions 2. If l . have type (intl . intl)l. 
As a design choice, we do not Theabovelemma shows that . (l, a) is the most accurate allow loop variables 
have security levels other than L and (lowest) label that l can be downgraded to via a.In fact, H. The 
reason is that a loop variable changes its own values a given l and a,all the labels l ' l ' that satisfy 
l . form a sub-during recursive calls. In our security lattice, the security lattice of Llocal, where 
the bottom of the lattice is . (l, a) and the top is H. Lemma 4.4.3 (Computing downgrading results). 
. (l, a) =l {n |.n1 . l, .m, n 8 a = m . n1} This lemma shows exactly what is inside . (l, a).  5. 
A TYPE SYSTEM FOR LOCAL DOWNGRADING 5.1 The Language In this section we present a security-typed programming 
language .. that supports downgrading. The language local syntax is presented in Figure 3. Compared to 
the policy language we presented in the last section, we introduce con­ditionals and .xpoints. Security 
labels are used as type annotations. Furthermore, the inputs to the program are explicitly written as 
variables: s denotes a secret input and . denotes a public input. level of data downgrades during computation 
unless it is L or H. Since all the policy terms are terminating programs, the security level of data 
always becomes L or H after .nite steps of nontrivial computation. 5.3 The Security Goal If we erase 
the type annotations, the unlabeled programs in Figure 7 is a superset of our policy language in Figure 
1, so that we can use terms in our policy language to represent fragments of unlabeled programs. De.nition 
5.3.1 (Label erasure). E(e) erases all the la­bel annotations in e andreturns asimply-typed .-term, as 
de.ned in Figure 7. De.nition 5.3.2 (Term sanity). The predicate clean(f) holds if and only if f syntactically 
contains no secret variable s. De.nition 5.3.3 (Program equivalences). All the rules in Figure 2 are 
also used for program equivalences by sub­stituting all metavariables m with f. Furthermore, we have 
some new rules de.ned in Figure 8. G fci : intL G f.i : intL G fsi : intS(si) G(x)= s G fx: s G(r)= s 
G fr : s G,x : s1 fe: s2 x/.dom(G) G f(.x:s1.e)l :(s1 .s2)l G fe1 :(s1 .s3)l G fe2 : s2 s2 =s1 s3 Ul 
=s G fe1 e2 : s l .{L,H} s=intl G,r :(intl .intl)l,x : intl fe: s G f.xl r(x)= e:(intl .intl)l G fe: 
intl G fe1 : s1 G fe2 : s2 s1 =ss2 =s G fif e then e1 else e2 : sUH G fe: intL G fe1 : s1 G fe2 : s2 
s1 =ss2 =s G fif e then e1 else e2 : s G fe1 : intl1 G fe2 : intl2 G fe1 .e2 : intH G fe1 : intL G fe2 
: intL G fe1 .e2 : intL Figure 4: .sec Typing Rules: TConst TPublic TSecret TVar TRecVar TFun TApp 
TFix TCond-H TCond-L TOp-H TOp-L G fe: s G fe1 : intl1 G fe2 : intL a a= .x:int..y:int.x.yl1 . l3 DLocal-L(R) 
G fe1 .e2 : intl3 Figure 5: .. Typing Rules: local G fe: s l1 l2 SLab ftl1 =tl2 ft =t SRefl ft1 =t2 ft1 
ft2 ==t3 t3 STrans fs1 =s2 fs3 = s4 SFun fs2 .s3 =s1 .s4 Figure 6: .sec, .. Subtyping Rules: local fs=s 
ft=t Unlabeled Programs f ::= .x:t. f |ff |x |c |. |s |f .f |if f then f else f |.x r(x)= f |r E: e.f 
E(tl)= E(t) E(int)= int E(s.s)= E(s) .E(s) E(G)(x)= E(G(x)) E((.x:s. e)l)= .x:E(s). E(e) E(e1 e2)= E(e1) 
E(e2) E(x |c |s |. |r)= x |c |s |. |r E(e1 .e2)= E(e1) .E(e2) E(if e1 then e2 else e3)= if E(e1) then 
E(e2) else E(e3) E(.xl r(x)= e)= .x r(x)= E(e) Figure 7: Label Erasure We formalize the security guarantee 
of our type system using program equivalences. The following is the main the­orem of this paper. Theorem 
5.3.1 (Relaxed noninterference). If fe: intL,then E(e) =f (n1si1 ) ...(nksik ) where clean(f) and .j.nj 
.S(sij ). The proof of this theorem is in Subsection 5.5. This the­orem shows that a type-safe program 
can only leak secret information in controlled ways, i.e. only through the spec­i.ed downgrading functions. 
Take the password example again, if we know that E(e) =f ((.x:int..y:int.x = y) spwd) and clean(f), then 
the only way through which f can leak information about spwd is to use its argument, the closure (.y: 
int.spwd = y), which intuitively enforces the security policy speci.ed by the user in an end-to-end fashion. 
Note that this policy still allows the full password be leaked by the following program: f = .g: int 
.int. (.x r(x)= if g(x) then x else r(x+1)) 0 Nevertheless, such an attack takes exponentially long time 
to .nish. We will discuss such programs more in Section 8. We call this security guarantee relaxed noninterference, 
because it generalizes traditional noninterference as shown in the following corollary. All the G fm1 
=m2 : t rules become G ff1 =f2 : t,plus the following rules: G ff1 =f2 : int G ff3 =f4 : t G ff5 =f6 
: t Q-If G fif f1 then f3 else f5 =if f2 then f4 else f6 : t G,x :int,r :int .int ff1 =f2 : int Q-Fix 
G f.x r(x)= f1 =.x r(x)= f2 : int G fif f1 then f2 else f3 :t1 .t2 G ff4 :t1 Q-EtaIf-App G f(if f1 then 
f2 else f3) f4 =if f1 then f2 f4 else f3 f4 : t2 G fif f1 then f2 else f3 :int G ff4 :int Q-EtaIf-Op-L(R) 
G f(if f1 then f2 else f3) .f4 =if f1 then f2 .f4 else f3 .f4 : int Figure 8: Program Equivalences: 
G ff1 =f2 : t Corollary 5.3.1 (Pure noninterference). If f e : intL and .j.S(sj )= H,then E(e) = f where 
clean(f). Obviously, when no downgrading policy is available, a type-safe program is noninterfering because 
it is equivalent to another program that contains no secret variable at all, which implies that the program 
does not leak any informa­tion about the secret variables. It is important to understand the meaning 
of the equiva­lence rules. We treat these rules as the static semantics of the program. Rather than evaluating 
the program in a call­by-value semantics, we transform the program statically in a call-by-name fashion 
and formalize our security goal. In a call-by-value setting, the Q-Beta and Q-Eta rules a.ect the termination 
behavior of the program. The Q-EtaIf rules al­low us to statically reason about di.erent execution paths 
without changing the termination behavior of the program. If f1 =f2 and both programs terminate in a 
call-by-value semantics, they must evaluate to the same value. With such equivalence rules, our relaxed 
noninterference theorem gives us a notion of weak noninterference,where secrets can be leaked by observing 
the termination behavior of program. 5.4 Making Typechecking Practical During typechecking, we need 
tractable ways to work with the security labels. The major label operations in the typ­ing rules are: 
order testing, computing joins and computing downgrading results. There are two challenges here. First, 
some label operations involve higher-order uni.cation prob­lems that require searching and such problems 
are undecid­able. Second, labels with in.nite size are hard to deal with. Although higher-order uni.cation 
is generally undecid­able, most such problems in typechecking are either trivial or easily solvable. 
Take the label ordering as an example, we can use the following corollary to test whether l1 l2: Corollary 
5.4.1 (Label order testing). 1. If l1 .l2 then l2 l1. 2. l2 l1 i. .n1 .l1, .n2 .l2, .m, n1 =m .n2 In 
typechecking, it is often the case that one of l1 and l2 are either H or L,or l1 .l2. It is rarely the 
case that we need to search for the uni.er m, and if we need to do so, the size of m is usually no larger 
than n1,because the computation of n1 is being decomposed into two steps, and each piece is likely to 
have fewer computation than n1 does. If no uni.er is found within the length of n1,the typechecker could 
conservatively report that the label ordering cannot be established, as doing so does not break type 
soundness. We solve the .nite representation problem by approximat­ing intractable labels. Suppose we 
do not know how to rep­resent l .nitely and for some policies we cannot even decide whether they are 
in S(l). But, if we can compute a .nite label l ' such that we know l ' .S(l), then we have ll ' and 
l ' canbe usedas anapproximationfor l.To make such approximations useful, l ' should be as close to l 
as possible. The following shows how to approximate joins and down­grading results for .nite labels. 
Lemma 5.4.1 (Approximating joins). l1 Ul2 l where l = {.x : int.c}.{n |n .l1 and n . S(l2)}.{n |n .l2 
and n .S(l1)} In most cases, we have either l1 l2 or l2 l1 and the computation of joins can be short-circuited. 
In some rare cases, the join of l1 and l2 can be approximated by using the above lemma: for each policy 
n .l1, test whether it is implied by l2 and vice versa. The member test n .S(l2) uses Lemma 4.2.1 and 
uni.cation can be handled as we just did for label ordering. The TApp and the TCond rules do not require 
the exact join to be computed, so this approximation can always be used. Lemma 5.4.2 (Approximating downgrading 
results). .(l, a) .{n |.n1 .l, n 8a =n1} This lemma can be used to optimize the searching in Lemma 4.4.3. 
The intuition is that, a is usually a minimal step of computation in our type system and n1 is usually 
a long sequence of computation that can be decomposed into smaller steps. Therefore, we have a practical 
procedure for .nding the approximation of .(l, a): for each n1 .l,we search for n such that n 8a =n1.Since 
g is usually a policy shorter than n1, most sensible answers can be found by searching for terms no larger 
than n1. By Lemma 4.4.1, the approximated result can be safely used in typechecking.  5.5 Proof of Theorem 
5.3.1 This proof involves two stages. First, we transform the program into a normal form de.ned in De.nition 
5.5.1. The transformation takes .nite steps and preserves program equiv­alences. Then, we use induction 
to prove the theorem for normalized programs. De.nition 5.5.1 (Normal forms). In Figure 9. v ::= x |c 
|s |. |v.v |if v then v else v |(.xl r(x)= v) v |rv Figure 9: Normal forms The key idea about normal 
forms is that the metavari­able v always ranges over terms of the int type. To trans­form a program into 
a normal form, we would like to use ß-reductions to get rid of all the .-abstractions. The excep­tion 
is that the left side of an application node may not be a .-abstraction: it can be a .xpoint, a variable 
or a branch. In De.nition 5.5.2, we also de.ned .if -reduction. Lemma 5.5.2, Lemma 5.5.3 and Lemma 5.5.4 
tell us that these two reduction rules are su.cient to normalize a well-typed pro­gram. De.nition 5.5.2 
(ß,.if reductions). In Figure 10. Lemma 5.5.1 (Equivalence preservation). * ' ' If e. e ,then E(e) =E(e). 
Lemma 5.5.2 (Progress under ß,.if reductions). If fe: intl, e is stuck under ß,.if reduction, then e= 
v as in the normal form de.ned in Figure 9. Lemma 5.5.3 (Preservation under ß,.if reductions). ' ''' 
If fe: s, e.e ,then fe : s where s =s. Lemma 5.5.4 (Normalization under ß,.if reductions). If fe: intl,then 
.v such that e. * v. E ::= [] |E e |v E |E .e |v.E |if E then e else e |if v then E else e |if v then 
v else E |.xl r(x)= E .ß,.if : e.e E[(.x:s. e1) e2] .ß E[e1{e2/x}] E[(if e1 then e2 else e3) e4] .E[if 
e1 then e2 e4 else e3 e4] .if Figure 10: ß and .if reduction rules branch(FC,F) ::= (fi .F, fcj .FC) 
fi |if fthen branch(FC,F) else branch(FC,F) cj Figure 11: Short hand notion for nested branches De.nition 
5.5.3 (Branches). In Figure 11. De.nition 5.5.3 a short hand notion for representing nested branching 
statements. It is easy to show that G fbranch(FC,F) .f =branch(FC,F .f) and vice versa. The proof of 
our main lemma proceeds with induction on the typing derivation of a normalized program. Lemma 5.5.5 
(Main lemma). Suppose G only contains variables introduced by the TFix rule. That is, G f r : (intl .intl), 
G fx: intl, l .{L,H}for all r and x in G. 1. If G fv : intL, then E(G) fE(v) =f (n1si1 ) ...(nksik ) 
where clean(f) and .j.nj .S(sij ). 2. If G fv : intl, l .. = H, l = L,then (a) E(G) fE(v) =branch(FC,F) 
where FC = {E(v01),...,E(v0k)}, F = {(a1 sa1 ) E(v11) ...E(v1k1 ), ......... (aj s) E(vj1) ...E(vjkj 
)} aj (b) G fvij : intL, and the typing derivation is smaller than G fv : intl ai (c) S(sai ) . l for 
all i. Proof: By induction on G fv : intl. Case TConst, TPublic : The type must be intL.Sim­ply let 
f be v.  Case TSecret : Choose the secret variable itself si, let a1 = .x:int.x.  Case TFun,TRecVar 
: Cannot happen.  Case TVar : By our assumption on G, x must have type intL.Same as the TConst case. 
 Case TApp : v is either (.xl r(x)= v1) v2 or rv2. For the .x subcase, we must have l = L,otherwise 
v will have type intH.For the r subcase, we know from our assumption about G that r have type intL .intL. 
By inversion we know that the type of v2 must be a subtype of intL, which implies that v2 must have type 
intL in the premises of TApp. So we can use IH(1) on v2 and get E(G) fE(v2) =f2.... For the .x subcase, 
we can extend G with r and x and use our IH(1) to go into v1 and get E(G,r,x) fE(v1) = f1....Use the 
QFix Rule, we have E(G) fE(.xl r(x)= v1) =.x r(x)= f1... Then we can compose f1 and f2 to prove (1). 
The other subcase rv2 is similar.  Case TFix, TOp-H, TCond-H : Cannot happen.  Case TOp-L : Use IH(1) 
and equivalence rules.  Case TCond-L : First we can use IH(1) on e.Then we assert that both branches 
have int type.  If s= intL, then we know that both s1 and s2 are intL, so that we can use IH(1) and 
simple equivalence rules to prove this case. If s. = intL,then we use IH(2) on e1 and e2 respectively, 
then compose the result. The downgrading condition in (2)(c) is preserved by some property of the down­grading 
relation. Case DLocal-Left :If l1 is H then we can show that it is impossible. If l1 = L and l3 = L then 
we can use IH(1) to prove (1). If l1 = L and l3 .= L then we can create a vacuous secret and put a constant 
function to prove (2). Consider the subcase when l1 .L and l1 = H.Use IH(2) to prove (2a),(2b),(2c) ... 
and do a case analysis on the resulting label l3.If l3 . = L then we proved (2), otherwise use IH again 
to prove (1). Case DLocal-Right : Similar. . Finally, we can easily compose Lemma 5.5.4, Lemma 5.5.1 
and Lemma 5.5.5 to prove Theorem 5.3.1.  6. GLOBAL DOWNGRADING POLICIES 6.1 Motivation In the last 
two sections we presented a system with local downgrading, where each secret is assigned a security label 
and secrets can be downgraded by interacting with public inputs and constants. In practice, this framework 
is ca­pable of expressing many useful downgrading policies, but there are some important policies it 
cannot express. For example, we may want to specify the policy data must be encrypted before sending 
it to the network . Naively we can use the policy .x : int. encrypt(x)and treat encrypt as an operator 
in our framework. However, an encryption algorithm usually requires a key as its input, so we may try 
the policy .x : int..y : int. encrypt(x, y) for the data and .x : int..y : int. encrypt(y, x) for the 
key. Unfortunately, this does not work because the downgrading rule requires the secrets interact with 
an intL type. Furthermore, these policies allow the attacker to use its own key to downgrade the secret: 
encrypt(x, fakekey). Another interesting example is: we have two secrets s1 and s2 and we want to specify 
the policy both s1 and s2 are secrets, but their sum is considered as public . Such policies not only 
describe the computation required for downgrading, but also speci.es how multiple secrets should be composed 
in order to downgrade. We solve this problem by introducing the idea of global downgrading policies. 
We identify all the secret inputs of the system, and refer to these secrets in our policy language. In 
this section we present Lglobal , a lattice of global downgrading policies, and in the next section we 
correspondingly extend the type system to support global downgrading. 6.2 Label De.nition The only thing 
we need to change in the policy language is to allow secret variables to appear in the policy language, 
as shown in Figure 12. For example, s1 may have a down­grading policy {.x : int.x + s2}, and when we 
apply this policy term to s1, the resulting term s1 + s2 is considered public. Similarly, s2 can have 
the policy {.x : int.s1 + x}. We use Lglobal to denote the set of all well-formed labels. Policy Terms 
m ::= ... | s Figure 12: Lglobal Label Syntax 6.3 Label Interpretation The label interpretation is slightly 
di.erent from Llocal. The general idea remains the same. If n . l,then m . n is implied by n. However, 
we must assure that m does not con­tain other secrets, otherwise by applying m . n to the data, we may 
leak arbitrary secrets by deliberately choosing some m. Therefore, we need to make a patch to our de.nition. 
De.nition 6.3.1 (Label Interpretation). Let S(l) denote the semantic interpretation of the label l: S(l)= 
{n ' | n ' = m . n, n . l, clean(m)} Lemma 4.2.1 requires a similar patch. Others parts re­quire no change 
in Subsection 4.2. 6.4 Label Ordering The de.nition of label ordering in Subsection 4.3 requires no 
change. Lemma 4.3.1 requires a similar patch as above. The interesting thing is that Lemma 4.3.2, which 
asserts that the identity function is the bottom of the lattice, be­comes broken. For backward compatibility, 
we change our de.nition for the rest of the paper: De.nition 6.4.1. H = {.x :int.c}, L = {.x :int.x} 
It is easy to verify that H =l ULglobal still holds, but nLglobal is no longer structurally equivalent 
to L.The in­tuition is that a constant function is still the most restric­tive policy because it leaks 
no information. The identity function is no longer the least restrictive policy: it can only leak information 
about the data it annotates. But there are plenty of policies that allow leakage of information besides 
the annotated data itself. Take this policy as an example: .x : int..y : int.x * (y =0)+ s1 * (y = 1), 
it is capable of leaking the annotated data as well as another secret s1. Intuitively, we can try to 
quantify the information leakage of policies: constant functions leak 0 unit of information, iden­tity 
functions leak 1 unit, all policies in Llocal leak between 0 and 1, and some policies in Lglobal leak 
much more than 1. It turns out that if we add tuples and projections in our policy language and enrich 
the equivalence rules, we can easily give a simple .nite representation of nLglobal ,which we call Bottom. 
Assuming the secret variables in the system are s1, ..., sk,then Bottom = nLglobal =l {.x :int. (x, s1, 
..., sk)} Such a function is capable of leaking all possible secrets be­sides the annotated data itself. 
Although adding Bottom helps us understand the struc­ture of Lglobal , we do not need it in practice. 
The security level L still has important practical meaning: if x is anno­tated with a label l and we 
have l L,then x can still be considered as public. It is only di.erent when x has the ability to interact 
with other secrets and downgrade them. 6.5 Downgrading All the de.nitions in Subsection 4.4 require 
no modi.­cation, except that we need the uni.ers m to be clean in Lemma 4.4.3. The actions now can contain 
secret variables. For example, we have a {.x :int. (x + s2)%4} . {.x :int.x%4} where a = .y : int.y + 
s2. In fact, the secret variables are handled just like constants.  7. A TYPE SYSTEM FOR GLOBAL DOWNGRADING 
7.1 Integrity Labels In this section, we extend the Llocal language in order to support global downgrading 
policies. As we add the secret variables in the downgrading policy, there are some new is­sues to solve. 
Consider the simplest case where we are going to typecheck a term a + b. Suppose we already know that 
a has a security level {.x : int.x + s2}. We de.ne an action .y :int.y + b and attempt to downgrade a 
via this action so that the result can have security level L. In order to do that, it is necessary to 
establish that the term b must be equal to s2. More generally speaking, we need some integrity reason­ing 
about the data, and it is the dual of the con.dentiality analysis we have done. The downgrading policies 
mainly express con.dentiality requirements: where the data can go to and what kind of computation we 
must do before releas­ing it to the public. To enforce such policies, we also need integrity analysis 
of data: where the data comes from and what computation has been done with them. Since integrity and 
con.dentiality are duals, it is natu­ral to use a dual mechanism to reason about integrity. We introduce 
an optional type annotation, called an integrity label in our language. Such labels can be attached to 
the base type in the form of int(m) as in Figure 13, where m tracks the interesting computations that 
happened to this term. For example, a term of type int(s1)l must be equiva­lent to s1 itself and this 
is just a singleton type; a term of type int(.x:int.x *s2)l must be equivalent to y *s2 where y is another 
term of type intL. The integrity labels are essen­tially the dual of our con.dentiality labels. The di.erence 
is that the integrity label is optional and it has exactly one policy term in it. Labeled Types s ::= 
tl t ::= int |int(m)|(s .s) Global Policies S ::= {mi}.{H} Figure 13: .. Syntax global 7.2 Policy Splitting 
If we directly specify the downgrading policy for each se­cret input just as we did for .. we are likely 
to have local, some inconsistencies among these policies. Take the exam­ple of s1 + s2 again. If the 
downgrading policy for s1 is {.x : int.x + s2} and the policy for s2 is just H,can we downgrade s1 + 
s2 to L? The policy of s1 says yes and the policy of s2 says no. To be safe, we have to compute With 
these global policies, we can automatically generate the security policy for each individual secret in 
the following way: De.nition 7.2.1 (Label generation). S(si)= {.x:int.mj[x/si] | mj .S} Take the example 
above, we have S(s1)= {.x:int.x%2,.x :int. (x + s2)%8} S(s2)= {.y :int..x :int.y = x, .x:int. (s1 + x)%8}Thus 
when we typecheck s1 + s2, we can downgrade from either s1 or s2, and the results are consistent: .x:int.x%8. 
This policy speci.cation method not only simpli.es the user s program annotation work but also make the 
formalization of our security guarantee more concise.  7.3 The Type System The type system is shown 
in Figure 14. Compared to .. ,the DLocal-L(R) rule remains unchanged. Global local downgrading is supported 
by the DGlob-L(R) rule, which exactly shows how the labels are computed for global down­grading using 
information from the integrity label. All other downgrading rules are used to keep track of the integrity 
la­bels. The DTLocal and DTGlob rules are essentially the same as DLocal and DGlob, except that we compute 
the integrity label for the result. Integrity labels are introduced bythe TSecret rule. The SIntLabel 
rule patches the subtyping relation. Since our typing rules are mostly algorithmic and we do not have 
subsumption rules, we can make the language more con­venient by changing the TCond and TOp rules to ignore 
integrity labels in their premises. We omitted them in this paper because they do not a.ect the expressiveness 
of the language. . fint(m)=int SIntLabel G fsi : int(si)S(si) TSecret G fe1 : intl1 G fe2 : intL l1 l3 
a the downgrading result from both sides, and take the up­ per bound of them. Doing so will produce a 
result of H, which is absolutely safe but inconvenient. If the user actu­ally wants such downgrading 
to be successful, he or she has a = .x:int..y :int.x .y G fe1 .e2 : intl3 DLocal-L(R) G fe1 : int(m1)G 
fe2 : intL l1 .l2 a = .x:int..y :int.x .yl1 l3 error-prone when the policies become complicated. G fe1 
.e2 : int(a 8m1) l3 To guarantee the consistency of such policies, we change the method of policy speci.cation. 
Instead of writing poli-G fe1 : intl1 G fe2 : int(m2)cies for individual secrets, the user simply writes 
a set S of a = .x:int.((.y :int.x .y) 8m2) policy terms as shown in Figure 13. Each of these terms a 
a to write a symmetric policy for s2. Such work is tedious and DTLocal-L(R) in S denotes a way of downgrading 
secrets to public. For l1 . l3 example, we can have S = {m1,m2,m3, H}where G fe1 .e2 : intl3 m1 =(s1%2), 
meaning that s1 can be downgraded to G fe1 :int(m1)l1 G fe2 :int(m2)l2 public by exposing its parity; 
a = .x:int. ((.y :int.x .y) 8m2) a DGlob-L(R) l1 . m2 =(.x : int.s2 = x), meaning that s2 can only be 
G fe1 .e2 : int(a 8m1) l3 downgraded by comparing it to some data at security level L. l3 DTGlob-L(R) 
Figure 14: .. Typing Rules global m3 =((s1 + s2)%8), meaning that we can downgrade the last three bits 
of the sum of s1 and s2.  7.4 The Security Goal The security guarantee of .. is similar to .. .The global 
local major di.erence is that we changed our way of policy spec­i.cation. In .. , the policies are globally 
speci.ed by the global user: S is just a set of policy terms. During typechecking, S is split into local 
policies for each secret variable. Therefore, we would like to express our security goal in terms of 
the global policy S. Theorem 7.4.1 (Relaxed Noninterference). If f e: intL,then E(e) = fm1 ...mk where 
clean(f) and .j.mj . S. Corollary 7.4.1 (Pure Noninterference). If f e: intL and S= {H} then E(e) = f 
where clean(f). These security guarantees are similar to the ones in .. local. They look even more intuitive: 
a safe program can only leak secrets in permitted ways, and these permissions are directly characterized 
by the global downgrading policy. The proof of Theorem 7.4.1 is similar to the proof of The­orem 5.3.1. 
The only major di.erence is the reasoning about integrity labels. Lemma 7.4.1 shows the exact meaning 
of these integrity labels. With the help this lemma, we can go through the cases for additional downgrading 
rules. Lemma 7.4.1 (Integrity guarantee). If G f v : int(m)l,then E(G) fE(v) = branch(FC ,F) where FC 
= {E(v01),...,E(v0i)}, F = {m E(v11) ...E(v1k), ......... m E(vj1) ...E(vjk)}and for each vxy, G f vxy 
: intL for a smaller derivation. Typechecking for .. is not fundamentally harder. Han­ global dling integrity 
labels is algorithmic and requires no search­ing. The only subtle point is that the label ordering is 
changed in Lglobal, so we must be careful that L is not used as the lowest label in comparing labels 
and computing joins.  8. EVALUATION AND FUTURE WORK Strengths and Limitations We have presented an end-to-end 
style framework for down­grading policies. On one end, it provides a policy speci.ca­tion language expressive 
enough to represent a wide variety of downgrading policies useful in practice. On the other end, it formally 
describes a global security goal determined by the user s downgrading policy. To guarantee that a program 
sat­is.es the security goal, i.e. the program is safe with respect to the downgrading policies, we only 
need a proof showing that the program is equivalent to a speci.c form, by using program equivalence rules. 
We also presented type systems as enforcement mecha­nisms. The soundness theorem of the type system ensures 
that, if a program is well-typed, then there exists a proof of the security goal for the program. Thus, 
we reduced the problem of proof searching to the problem of typechecking, which is a syntax-directed 
process. The programmer can explicitly write down the types as security proofs, or we can use type inference 
to search for proofs automatically. It is necessary to point out that a type system is not the only possible 
enforcement mechanism for our framework. Type systems typically have limitations that prevent them from 
enforcing some kinds of downgrading policies. For ex­ample, consider the policy .x: int..p : int. (x+ 
p) * p:it cannot be enforced by our type system because typecheck­ing is not syntax-directed. At each 
step, all the information is locally synthesized from adjacent nodes. For the program (x+ y) * y where 
x has the policy above, we cannot down­grade the syntax node (x+ y), therefore (x+ y) cannot have a downgradable 
type annotation. To reason about such poli­cies, we need more powerful mechanisms that involve more global 
data-.ow analysis. Nevertheless, many useful policies are not in these forms and are easily enforceable 
by our type system. Understanding the Policies The security guarantee in our framework only assures that 
the program respects the user s security policies, but it does not verify anything about the policies 
themselves. It is im­portant to study how to evaluate the e.ects of these down­grading policies, especially 
when the program is not trusted. Both informal and formal reasoning can be used. For exam­ple, given 
the policy {s1%2}, it is apparently true that only the parity of s1 can be leaked to public. Given the 
policy for the password: {.y: int.spwd = y},wecan usethe same reasoning technique in relative secrecy 
[18] and assure that any program satisfying this policy must take exponentially long expected time to 
crack the password. Our framework has the ability to minimize the scope of security analysis: in­stead 
of analyzing the whole program, we need to examine only the security policies for these programs, and 
such poli­cies are usually several orders of magnitudes smaller than the program. Understanding the Equivalence 
Relation The equivalence rules are crucial in the de.nition of relaxed noninterference. Extending these 
rules can make the frame­work more expressive. For example, if we have a policy stating that x%4 is safe 
and the equivalence relation can es­tablish that x%2 = (x%4)%2, then x%2 is also safe with respect to 
our policy. However, the equivalence relation must provide a useful notion of security guarantee. Take 
the password example again: if we use the usual de.nition of observational equivalence to de.ne relaxed 
noninterfer­ence, it would make the following two terms equivalent: spwd = (.x r(x)= if (spwd=x) then 
x else r(x+1)) 0 The consequence would be that any single occurence of the variable spwd can be considered 
as a public value of type intL because it satis.es the de.nition of relaxed noninter­ference. This is 
apparently not a good security guarantee. Therefore, it is interesting to explore what equivalance rela­tions 
are good for our purposes and how to formalize such criteria. Practical Application Our framework can 
be practically adapted into existing security-typed languages such as Jif. In our policy language, some 
run-time library calls and API interfaces can be mod­eled as operators and constants, such as encryption, 
pri­mality testing and hash functions. The program annotation work mainly involves marking secret and 
public variables; the downgrading policies can be globally speci.ed outside the program. In ideal cases, 
most type annotations can be automatically inferred during typechecking and the pro­grammers do not need 
to write the downgrading policies for each piece of data in the program. To achieve this goal, more work 
needs to be done on type inference algorithms in our framework. Integrating with DLM The decentralized 
label model (DLM) expresses policies like who can downgrade the data and it is orthogonal to our work. 
Since our security policies are also formalized as a lat­tice of security levels, it is tempting to integrate 
our frame­work with the decentralized label model so that we can ex­press policies like who can downgrade 
the data in which ways and achieve a better integration of access control and information .ow. There 
has been work on combining secu­rity policies with owner information [2] in the style of DLM. This is 
a promising research direction we are planning to pursue in the future. Proof Carrying Code and Information 
Flow Our framework also facilitates the use of proof-carrying code for information-.ow security. The 
downgrading policies can be speci.ed as interfaces for untrusted software modules. The untrusted code 
must come with a proof showing that it respects our interfaces in our framework, such a proof even needs 
not to be a typing derivation; it is su.cient to give a proof using program equivalence rules because 
our security goal is expressed in this way. The trusted comput­ing base is very small: we need not trust 
the soundness of any type system; the correctness of our equivalence rules is almost indubitable; the 
proof checker is easy to implement correctly. Even without downgrading, our framework can still be very 
valuable in this aspect. Since we are not re­stricted to the use of type systems, the programmer could 
use more expensive proof searching techniques so that more expressive downgrading policies can be enforced. 
 9. CONCLUSION In this paper, we studied the challenges of downgrading in language-based information-.ow 
security and presented a generalized framework of downgrading policies. Such poli­cies are treated as 
security levels for information .ow con­trol, speci.ed in a simple, expressive, tractable and exten­sible 
policy language, and enforced by a type system. The security guarantee is then formalized as a concise 
and exten­sional property called relaxed noninterference using program equivalences, which generalizes 
traditional noninterference properties and accurately describes the e.ects of downgrad­ing. Alternative 
enforcement mechanisms can also be used. Our framework now enables untrusted code to safely declas­sify 
secrets and we can guarantee that information is only leaked in permitted ways.  Acknowledgements We 
would like to thank Stephen Chong, Stephen Tse, Ge­o.rey Washburn and the POPL reviewers for their valuable 
feedbacks and extensive proofreading of the original draft. References [1] Anindya Banerjee and David 
A. Naumann. Secure information .ow and pointer con.nement in a java-like language. In Proc. of the 15th 
IEEE Computer Security Foundations Workshop, 2002. [2] Hubie Chen and Stephen Chong. Owned policies 
for information security. In Proc. of the IEEE Computer Security Foundations Workshop, 2004. [3] R. 
Giacobazzi and I. Mastroeni. Abstract non-interference: Parameterizingnon-interference by abstract interpretation. 
In Proc. 31st ACM Symp. on Principles of Programming Languages (POPL), pages 186 197, January 2004. [4] 
J. A. Goguen and J. Meseguer. Security policies and security models. In Proc. IEEE Symposium on Security 
and Privacy, pages 11 20. IEEE Computer Society Press, April 1982. [5] James W. Gray, III. Towards a 
mathematical foundation for information .ow security. In Proc. IEEE Symposium on Security and Privacy, 
pages 21 34. IEEE Computer Society Press, 1991. [6] Gavin Lowe. Quantifyinginformation .ow. In Proc.ofthe 
IEEE Computer Security Foundations Workshop,pages 18 31. IEEE Computer Society Press, 2002. [7] Heiko 
Mantel and David Sands. Controlled declassi.cation based on intransitive noninterference. In Proceedings 
of The Second Asian Symposium on Programming Languages and Systems, volume 3302 of LNCS. Springer, 2004. 
[8] John McLean. Security models and information .ow. In Proc. IEEE Symposium on Security and Privacy,pages 
180 187. IEEE Computer Society Press, 1990. [9] Andrew C. Myers. JFlow: Practical mostly-static information 
.ow control. In Proc. 26th ACM Symp. on Principles of Programming Languages (POPL),pages 228 241, San 
Antonio, TX, January 1999. [10] Andrew C. Myers and Barbara Liskov. Protectingprivacy usingthe decentralized 
label model. ACM Transactions on Software Engineering and Methodology, 9(4):410 442, 2000. [11] Andrew 
C Myers, Andrei Sabelfeld, and Steve Zdancewic. Enforcingrobust declassi.cation. In Proc. of the 17th 
IEEE Computer Security Foundations Workshop, pages 172 186. IEEE Computer Society Press, June 2004. [12] 
Alessandra Di Pierro, Chris Hankin, and Herbert Wiklicky. Approximate non-interference. In Proc. of the 
IEEE Computer Security Foundations Workshop, pages 1 17. IEEE Computer Society Press, 2002. [13] Fran¸cois 
Pottier and Sylvain Conchon. Information .ow inference for free. In Proc. 5th ACM SIGPLAN International 
Conference on Functional Programming (ICFP), pages 46 57, September 2000. [14] Fran¸cois Pottier and 
Vincent Simonet. Information .ow inference for ML. In Proc. 29th ACM Symp. on Principles of Programming 
Languages (POPL), Portland, Oregon, January 2002. [15] A. W. Roscoe and M. H. Goldsmith. What is intransitive 
noninterference? In Proc. of the 12th IEEE Computer Security Foundations Workshop, 1999. [16] Andrei 
Sabelfeld and Andrew Myers. A model for delimited information release. In Proceedings of the International 
Symposium on Software Security (ISSS 03), 2004. [17] Andrei Sabelfeld and Andrew C. Myers. Language-based 
information-.ow security. IEEE Journal on Selected Areas in Communications, 21(1):5 19, January 2003. 
[18] Dennis Volpano and Geo.rey Smith. Verifyingsecrets and relative secrecy. In Proc. 27th ACM Symp. 
on Principles of Programming Languages (POPL), pages 268 276. ACM Press, January 2000. [19] Dennis Volpano, 
Geo.rey Smith, and Cynthia Irvine. A sound type system for secure .ow analysis. Journal of Computer Security, 
4(3):167 187, 1996. [20] Steve Zdancewic and Andrew C. Myers. Robust declassi.cation. In Proc. of 14th 
IEEE Computer Security Foundations Workshop, Cape Breton, Canada, June 2001. IEEE Computer Society Press. 
 
			