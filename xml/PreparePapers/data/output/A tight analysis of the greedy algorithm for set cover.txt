
 A Tight Analysis of the Greedy Algorithm for Set Cover Petr Slavl&#38; Department of Mathematics State 
University of New York at Buffalo Buffalo, NY 14214, USA E-mail: slaviktiath. buffalo. edu Abstract We 
establish significantly improved bounds on the perfor­ mance of the greedy algorithm for approximating 
set cover. In particular, we provide the first substantial improvement of the 20 year old classical harmonic 
upper bound, H(m), of Johnson, Lovssz, and ChvAt al, by showing that the per­ formance ratio of the greedy 
algorithm is, in fact, exactly in m in ht m + Q(l), where m is the size of the ground set. The difference 
between the upper and lower bounds turns out to be less than 1.1. This provides the first tight ansJysis 
of the greedy algorithm, as well as the first upper bound that lies below H(m) by a function going to 
infinity with m. We also show that the approximation guarantee for the greedy algorithm is better than 
the guarantee recently estab­ lished by Srinivasan for the randomized rounding technique, thus improving 
the bounds on the integralit~ gap. Our improvements result from a new approach which might be generally 
useful for attacking other similar prob­ lems. Keywords: Approximation Algorithms, Fractional Set Cover, 
Greedy Algorithm, Partial Set Cover, Set Cover. Introduction Set cower is one of the oldest and most 
studied NP-hard problems ([8], [4], [7], [9], [1], etc.). Given a ground set U of m elements, the goal 
is to cover U with the smallest possible number of sets. One of the best polynomial time algorithms for 
approxi­ mating set cover is the greedy algorithm: at each step choose the unused set which covers the 
largest number of remain­ ing elements. Johnson and Lovssz ([7],[9]) showed that the performance ratio 
of the greedy method is no worse than H(m), where H(m) = 1 + . ..+ l/m is the mth harmonic number, a 
value which is clearly between in m and in m + 1. Chv&#38;d in [1] extended their results to the weighted 
version of the problem. Permission to make digitzl/lrsrd copies of sII or part of thh material for personal 
or classroom use is granted without fee provided that the copies are not made or distributed for profit 
or commercial advantage, the copy­right notice, the title of the publication and ita date appear, and 
notice is given that copyright is by permission of the ACM, Inc. TO COPYorhe~iw, to republish, to post 
on servers or to redistribute to Iiatz, requuw specltic permission and/or fee. STOC 96, Philadelphia 
PA,USA @ 1996 ACM 0-89791.785-5196/05. .$3.50 Other, more complex approximation algorithms, have SJSO 
been studied. For example, Halld6rsson s local im­provements modification of the greedy algorithm ([5], 
[6]) improved the upper bound to about H(m) -0.43 and sug­gested that for large ground sets this improvement 
can be made even stronger. Srinivasan s analysis of randomized rounding ([1 2]) showed some further improvements 
on the performance ratio in special cases, making it appear at that point that the randomized roundhtg 
algorithm was better than the greedy method. The original classical analysis of the greedy algorithm 
has remained essentially unchanged for the last 20 years, despite the fact that H(m) is not known to 
be a lower bound on the performance ratio of the greedy algorithm. In fact, Johnson in his well-known 
paper [7] provides a lower bound of only about 0.48 in m. A straightforward modification of his approach 
gives a lower bound of about 0.72 In m. This atate of affaira was put more sharply into focus by recent 
hardness results (see e.g. [10] and [3]). In particu­lar, Feige proved a very strong result showing that 
for any c > 0, no polynomial time algorithm can approximate e set cover within (1 c) in m unless NP 
C TIA4E[n0t10g g )]. Hence, under a plausible structural complexity assumption, the performance ratio 
of any polynomial time algorithm can improve on the harmonic bound by at most a function ~(m) = o(ln 
m). In th~ paper, we provide the first substantial improve­ment of this kind. Using a new approach, we 
show that the performance ratio of the greedy algorithm is exactly in m -in in m + ~(l) (the lower and 
upper bounds differ by less than 1.1). This provides the first tight analysis of the greedy algorithm, 
as well as the first upper bound that lies below H(m) by a function going to infinit y with m. Clearly, 
Feige s recent hardness result adds to the relevance of our paper, since lower-order improvements in 
the bound for the greedy algorithm are now the best we can hope for; more­ over, this improved analysis 
holds out the prospect of further identifying the exact approximation threshold at which the set cover 
problem becomes intractable. The second part of our paper extends our results to frac­ tional covers. 
A fractional cover consists of fractions of cov­ ering sets with the condition that for each point the 
fractions add up to at least 1. This enables us to compare our results with Srinivasan s bounds, and 
show that our bound on the integrality gap for the greedy algorithm is significantly bet­ ter than that 
for randomized rounding. 2 Overview Let U be a finite set, IUI = m, and let S = {Sl,..., S~} be acoverof 
U,thatia USi=U. Let S*={ Sil, . . ..si~}be a subcover of S (that is S* C S and S* itself is a cover of 
U). Denote by cmin the number of sets in a minimum subcover. The greedy algorithm for approximating a 
minimum sub­cover, at each step, simply chooses the covering set with the maximum number of elements 
left, deletes these elements from the remaining covering sets, and repeats this process until the ground 
set U is covered. We can assume that in case of a tie, the set with smaller subscript is chosen. We de­note 
by cgr=d,ju the size of the subcover output by the greedy algorithm. Previous approximation guarantees 
were generally based on assuming some knowledge of m and cmin, and then us­ing various techniques to 
obt sin bounds on cgveed~. Our ap­proach is different. We start with numbers Cmin ad Cgre.sdy$ and obtain 
bounds on m. The key to our approach iz the int reduction of greedy numbers N(k, 1), which turn out to 
satisfy a simple recursion relation and which we prove have the following property: N(k, 1) is the size 
of the smallest set U for which it is possible to have a cover of U with Cmin = 1 md Cgreedg = k. This 
allows us to abstract from the set cover problem to an analysis of the function N(k, 1) leading to the 
establishment of both upper and lower bounds on the performance ratio. In fact we show that for any set 
U with IUI = m z 2and for any cover Sof U -<lnm-lnlnm+O.78, (1) and that for all m z 2 there is a cover 
S of some set U with IUI = m such that ->lnm lnlnm-O.31. (2) Notice that our approach leads to lower 
bounds in a stronger form than is customary. Namely, (2) holds for all values of m. Generalization of 
our analysis to fractional covers is al­most straightforward. The arguments are little more subtle, but 
lead, essentially, to the same upper and lower bounds. On our way to proving these bounds, we show that 
m -in C~in) + C%in (3)  Cgreedv< (c+) (ln which significantly improves on Srinivasan s bound for the 
randomized rounding aIgorithm -see [12] and Section 4. Here c~im is the cost of the minimum fractional 
cover. 3 Performance Bounds 1-1 Let us first define the greedy numbers N(k, J). For given 1 ~ 2, set 
al=l and ai = r al+. ..+ai-i 1 (4) fori =2,3,.... We then define the (k, 1) greedy number N(k, 1) as 
k N(k,l) = ~ai for k=l,2,. . . . (5) i= 1 Obviously, for any 2<1 ~ k, N(l, 1) = 1 and N(k, 1)N(k+l,l)= 
(6) N(k, 0 + [=1 = &#38;N(k, 01. Hence we can recursively generate N(k, 1) for any k ~ 1 z 2. Consider 
now the set cover problem. The case cmin = 1, that is the case where U can be covered by one set, is 
not interesting, since the greedy algorithm will also output a single set, hence Cgreedg = Cmin. Therefore 
in what follows, we will consider only covers for which cmi. z 2. Set m = IUI. At each step, i, of the 
greedy algorithm, we delete gi elements. We have k = c~~e~d~ steps, hence 91+92 + . +9k=m. (7) We know 
that U can be covered by 1 = cmin sets. By the pigeon hole principle, at least one of the sets in the 
minimum cover cent sins at least [ ~1 elements. Hence similarly, -91 922 r>l and, in general, (fll+ 
+qi-1)1gi2 (m (8) 1 fori =2,..., k. Using (7), we can rewrite (8) in the form gi + .-+qk Qiz( 1 1. (9) 
Solving for qi gives qi~[ qi+l+- -+!lk l l ] fori=l,..., k. (lo) Clearly, al ~ qk, az ~ qk-1, . . .. 
ak ~ gl, hence kk N(k,l)=~ai~~gi=m=lU1. (11) i=l i=l Therefore, if m < N(k, 1) and cmin = 1, it must 
be that Cgreedy < k. The following example shows that the opposite is also true, namely, for any k ~ 
1 ~ 2 and any m ~ N(k, 1) one can easily construct a cover S of some set U such that IUI = m, Cmin = 
1, ~d cg,eed~ = k. Example 1 Let k ~ 1 ~. 2, and m ~ N(k, 1) be given. De­fine U={l,2,,.., m}. Since 
m ~ N(k, 1) thereare positive integers ql ~ qz ~ . . . ~ gk satisfying (10) and (7). Define a cover S 
of U in the following way. (i) Fori=l,..., kset Si={gl+ . ..+ql+l .l, gl+, O+gi.l+gi-l +qi}, Thus each 
S; contains exactly qi elements, the sets are dis­joint, and U;=l Si = U. (ii) Set d = [m/n. Then one 
can write m = 11d+12(d-1) for some /1, 12 such that 11 +12 =1. Define sk+i={~,~+~,...,i+~(l)})} fori=l,...,l~ 
 s S2 s S5 Figure 1: Example of a cover for which Cgreed9 = k = 11, Cmin = 1= 6,andm=N(k, 1)=18. sk+i={~j~+~)... 
,i+J(d 2)} fori=ll+l, . . ..l. Then, clearly, the first 11 sets contain d elements each, the next 12 
sets cent ain d-1 elements each, the sets are disjoint, and U:=l Sk+i = U. Thus Grtin =1. Figure 1 shows 
this construction for m = 18, d = 3, i=6, k= 11. We claim that the greedy algorithm outputs a cover 
S* = {s,,..., sk}. Indeed, ql > d, hence in the fi~st iteration S1 is chosen. Assume that after the 
i-th step, the sets S1, . . . . Si have been chosen, leaving gi+l + . ..+ gk elements to cover. Set r 
= max{lS$~Jl : j = 1,.. ., 1}, where S\i) denotes the set Sj after the i-th iteration of the greedy algorithm, 
that is after deleting the elements belonging to already chosen sets. Because of the construction of 
the sets in the cover, wehaver 1 ~ lS$~Jl ~ rfor Wj = 1,...,1. Hence gi+l+ooo + qk = ~j lS$/Jl > (r -1)1 
and thus gi+l ~ r by inequality (9). As a result, the greedy algorithm will choose the set Si+l in its 
(i+ 1)-st step. Thus cgre~d~ = k. D It is now clear that, for fixed cmin = 1, m < N(k, 1) implies Cgreedy 
< k. On the other hand, if m ~ IV(k, l), there are covers for which cmi. = 1 and Cg..edv = k. This proves 
the following Lemma: Lemma 1 For any set U with IUI z 2 and for any cover S of u, (12) Moreover, there 
are covers for which the equality is attained. Lemma 1 establishes a tight bound on the quotient cweedu/c~i_. 
Unfortunately, by itself, it is of little prac­tical use since we know almost nothing about the numbers 
N(k, 1). Using (6), one can evaluate the bound for the quo­tient Cgreed~/Cmin for small m, but it does 
not say much about asymptotic behavior. Let us now establish some lower and upper bounds on N(k, 1). 
This will enable us to find up per and lower bounds on CgT..dv/&#38;~in. Using (6), one can easily show 
that k-1 k-1 () k-1 N(k,9 > N(l,l) = &#38; 1 ~ e~l (13) ~ () which gives ~ < /(In N(~, /) -In 1 + 1), 
hence, by Lemma 1, Cgreedy g %in(hl m h Gnin + 1). (14) But we can actually obtain a much better bound. 
The proof is in the Appendix. Lemma 2 For any set U with m = IUI z 2 and any cover s of u, Cgreedy s 
(Cmin -l/2)(ln m -in Cmim) + Crni.. (15) The fact that we can multiply by cmin -1/2 instead of by c~in 
makes our analysis of the greedy algorithm stronger than previous results. This improvement together 
with Lem­ma 1 is crucial for establishing the following upper bound on cg~.edy /cmin proved in the Appendix. 
Theorem 1 For any set U with IUI = m z 2 and for any cover S of U, the greedy algorithm outputs a cover 
of size cg~eed~ satisfying -~ lnm -lnlnm+3+ lnln32-ln32 (16) < lnm lnlnrn+O.78. (17) The following lower 
bound on the performance of the greedy algorithm nicely complements the above result. Theorem 2 For 
every m z 2, there exist a set U with IUI = m and a cover S ojUj such that the greedy algorithm outputs 
a cover S* with cost cgr..d~ satisf~:ng cgreed~ > lnm-lnlnm-l+ln2 (18) Cmln > lnm-lnlnm-O.31. (19) This 
Theorem shows that the upper bound (16) is tight (up to a constant). That essentially completes the 
analysis of the performance of the greedy algorithm for approximat­ ing the set cover. Note: For any 
real number u z 2 set M(u) = max{k/1 I N(k, 1) < u}, that is for u = m, M(u) = the worst case for Cg.e.dV/c~i. 
. Figure 2 shows the graphs of M(u) (in the middle), and the functions in u In in u -1 + in 2 (lower 
bound) and ln in u + 3 + lnln 32 -in 32 (upper bound), for small and large values of u. This shows that 
some improvements of the constants in (16) and particularly in (18) may still be possible. 4 Fractional 
Covers Srinivasan in [12] showed that the approximation guarantee for the randomized rounding algorithm 
is Crra < C~i~ ln( ;;) + O(lnln(-&#38;)) + 0(1) , (20) mtn mtn ) ( making it appear at that point that, 
at least in some cases, the performance ratio for the randomized rounding tech­nique waa better than 
the performance ratio for the greedy algorithm. (Here c~in _< cmin is the optimum value of the LP relaxation 
of the set couer problem.) Our bounds in the previous section are incomparable with those of [12]. In 
this section we further improve our -----...-- . -. 4 3 1 Figure 2: Graphs of M(u) and estimates and 
show that the performance guarantee of the greedy algorithm is better than that of the randomized ~ounding 
~echnique. Following [9], we define a fractional cover T of U to be a system of weights T = {tl, ..., 
t~ } such that for all points zc U wehave {j I Esj} Denote by c*(T) the cost of the fractional cover 
T, i.e. n C*(T) =~ tj >=1 and let c~i. = m? c*(T). This formulation is equivalent to the LP relaxation 
of the set cover problem considered by Srinivs,san in [12]. Obviously, c*~ln < C*i~. Let us follow the 
steps in Section 3. Set 1 = c~in. A simple argument shows that c~in = 1 implies Cmim = 1, hence by considering 
only those covers for which c~in = 1 ~ 2, we actually consider covers for which cfiin = 1 >1. We define 
generalized greedy numbers as follows. Set a; = 1 and Define k N*(k,/*) = ~ a; for k=l,2, . . . . (21) 
a=l We have again that N (k+ 1,1*) = fJ-,* _ #*(kJ )l, (22) and, with a small adjustment, N*([l*], l 
) = [/ ] for any 1* >1. 1 20000 60000 100 000 the lower and upper bounds Now, j=l j=l j=l =ESj hence 
ql z (S1. Similarly, gi ~ [ -(9 +11 +9 - )1 and thus, as before, ~~=1 a; < ~~=1 gi. From the discussion 
above, it isclear that m < N * (k, c~in) imphes Cgreedy < k hence the following counterpart of Lemma 
1 holds. Lemma 3For any set U with IUI = m z 2and for any cover S of U, Careful analysis shows that () 
k-Ll*J 1 N*([l*j,l*) ~ (~,~ ) 2 ~ for k z lb, hence In N*(k, l ) ~ k/1* +lnl; -1. (24) Thus Lemma 3 
gives the following. Proposition 1 For an~ set U with IUI = m ~ 1 and for any cover S of U, the cover 
output by the greedy algorithm satisfies Proposition 1 already improves on %inivasan s bound (20). Proceeding 
-in Section 3, we can further improve (25) and obtain the following analogy of Lemma 2. The proof is 
in the Appendix. Theorem 3 For any set U with lUl = rn ~ 1 and for any cover S of U, the cover output 
b~ the greed~ algorithm sat­ isfies Theorem 3 shows that the performance guarantee for Acknowledgements 
the greedy algorithm is substantially better than the per- I would like to thank Eugene Kleinberg, my 
advisor, for formance guarantee (20) for the randomized rounding sJgo­ many useful discussions. I am 
also very grateful to Jon rithm. This immediately gives an improved bound on the Kleinberg for his comments, 
references, and suggestions. In integrality gap particular, he pointed me towards establishing the result 
in Theorem 1 and helped me with the Introduction. (lnu -In C~i~) + 1. ( -&#38;) References Moreover, 
inequality (26) is of the same form as the bound in Lemma 2, only cmin is replaced by c~in. Thus a simple 
repetition of the steps in the proof of Theorem 1 proves that -~lnrn-lnlnrn+ln2+e mln for all m large 
enough. It is obvious that for any cover, c < crnin, hence for msn ­every m ~ 2, there are covers for 
which ->lnrn-lnlnm+ln2 -l. min 5 Minimum Partial Cover Let us now briefly mention an extension of our 
results to the partial cover problem which further generalizes set cover. The goal here is to find a 
minimum subcollection of sets covering at least a p-fraction, O < p ~ 1, of the ground set. Greedy algorithm 
works exactly as in the complete cover case, hence only a slight modification of the approach of Section 
2 would prove the following: Theorem 4 Let U be a finite set of size IUI = m and S acover ofU, and letO< 
p~1besuch that [pml =u~2. Denote by c~in the size of a minimum p-partial cover of U. The greedy algorithm 
outputs a p-partial cover of size c~,..d~ satisfying Cgreedu <hiu lnlnu+O.78. (27) cm~n Moreover, for 
any u z 2 there is a cover S of U, such that the greedy algorithm outputs a p-partial cover S* with cost 
cgr~.d~ satisfying cgreed~ >lnu-lnlnu-O.31. (28) cmsn One can similarly generalize the results of Section 
4. The only difference would be the definition of p-partial fractional cover, where we want the condition 
~{ j I =~ ~j } tj > 1 to hold for at least u = [pml points. For a more detailed treatment of partiaJ 
covers see [11]. 6 Conclusion Simple modification of our analysis to Ha,lld6rsson s local improvements 
algorithm shows that the performance ra­tio of this slgorithm is also exactly in m -in in m + ~(l), wit 
h slightly better constants than in (16) and (18). Since Halld6rsson s algorithm has the best performance 
guaran­tee among the known polynomial time approximation algo­rithms, our analysis suggests a direction 
for possible further improvements of Feige s hardness result. [1] V. Chv&#38;tal. A Greedy Heuristic 
for the Set-covering Problem. Mathematics of Operations Research 4(1979), pp. 233-235. [2] P. Crescenzi 
and V. Kann. A Compendium of NP Op­timization Problems. Technical Report SI/RR-95/02, Department of Computer 
Science, University of Rome La Sapienza , 1995. [3] U. Feige. A Threshold of inn for Approximating Set 
Cover. In Proc. ACM Symposium on Theory of Corn. puting (1996). [4] M.R. Garey and D.S. Johnson. Computers 
and Intractability: A Guide to the Theory of NP-Completeness W.H. Freeman, New York, NY (1979). [5] M.M. 
Halld6rsson. Approximating Discrete Collections via Local Improvements. Proc. 6th Annual A CM-SIA M Symposium 
on Discrete Algorithms (1995). [6] M.M. Halld6rsson. Approximating Set Cover via Lo­ cal Improvements. 
JAIST Technical Report IS-RR-95­0002F, 1995. [7] D.S. Johnson. Approximation Algorithms for Combina­torial 
Problems. .lournaJ of Computer and Sgstem Sci­ences 9(1974), pp. 256-278. [8] R.M. Karp. Reducibility 
among Combinatorial Prob­ lems. In R.E. Miller and J.W. Thatcher, editors Com­plexity of Computer Computations, 
85-103, #lenum Press, New York, NY (1972). [9] L. Lovasz. On the Ratio of Optimal Integral and Frac­tional 
Covers. Discrete Mathematics 13(1975), pp. 383­ 390. [10] C. Lund and M. Yannakakis. On the Hardness 
of Ap­proximating Minimization Problems. Journai o} the ACM 41(1994), pp. 960-982. [11] P. Slavik Improved 
Performance of the Greedy Algo­rithm for Minimum Set Cover and Minimum Partial Cover. Technical Re ort 
95-45, De artment of Com­puter Science, SUN # at Buffalo, 19 1 5. [12] A. Srinivssan. Improved Approximation 
of Packing and Covering Problems. In Proc. ACM Symposium on The­ory of Computing (1995), pp. 268-276. 
Appendix Therefore for any u large enough, and for any k and 1 such ProoflLemma 2]: Since the function 
y = l/z is convex (=concave up), we have b 2b ln(a+b) lna> a+: 2a+b for any a, b >0. Hence, by the first 
part of inequality (13), lnN(k, i) ~ Inl+ (k l)(ln 1-ln(l -1)) > lnl+(k-1)~. (29) Rearranging (29) immediately 
gives kg(l-1/2) (lrt N(k, i)-lnl)+l (30) for any k z 1 ~ 2. The discussion preceding Lemma 1 easily concludes 
the proof. 0 ProoflTheorem 1]: We can rewrite (3o) in the form ;< (l-+)(ln N(k,l) -in 1) + 1, hence for 
any real w ~ IV(k, 1) (31) To simplify the reasoning, allow 1 ~ 2 to be a real number. Define lnu-lnl 
g(l, u) = ~ +lnl-1 and f(~) = pl g(l, u). .- One can easily show, that for fixed 1 ~ u ~ 2e3, g(l, u) 
is an increasing function of 1, and for fixed u > 2e3, g(l, u) is a unimodal ~unction -with both relative 
-and absolute mini­mum at 1 = 1, where 1 satisfies in u = h(l) with lnu=h(~)=lni +21-1. (32) Therefore 
31n2 f(u) = g(2, u) = y+~-1 forl~u~2e3 and for u > 2e3. Here h-l is the inverse of h. Since h is increasing, 
so is h-l. Let us establish a lower bound on ~(u) for large u. Clearly, for any small w > 0, in u = 2~+ln 
~-1 ~ (2+w)~, for ~ big enough. Hence / ~ ~, and lnl~lnlnu -ln(2 + w) ~ lnlnu -ln2 -w/2. Also, l/(2f) 
can be made arbitrarily small, hence for any c > 0 there exists U. such that ~(u) ~ inin u-In2-cfor all 
uz u.. that N(k, 1) ~ u, the inequality (31) implies lnu-~ ~g(l, u)~~(u) ~lnlnti-ln2 -c. (33) Hence, 
by Lemma 1, -~ ln7n-lnlnm+ln2+c < lnm-lnlnrn+O.69+c for m large enough. By actually checking small values 
of m and j (~s 17, m ~ 4. 101s), one can show that -< lnm-lnln m+3+lnln32-ln32 Cmi~ < lnrn-lnlnm+O.78 
for2dlm~2. D ProoflTheorem 2]: In order to prove the Theorem, we will need the following Lemma. 1-2 1-1 
- lnIV(k,l) -lni)+~+~ (~) .  +(1-+)( Proofi Obviously, N(i+l,l) ~ N(i, /)&#38;+~ 1 = f f(i,~) 1 + ~ 
+ (~ -\~N2(i,l) () Using the fact that ln(l + a) < :(1+ ~), for any a >0, and inequality (13), we have 
(- 1 2 lnN(i+l,l) -ln N(i,l)~ln l+++ (1 -l)N(i, /) ) 11 ( 1 2 1 1-2 ~ l l+(l-l)N(i,l) 1+ ~ ) 11 5 l-1+ 
(1-l) iv(l,l) )( ~ +(~  ( -2 )(1+*) ~_I i-l <21-1 1 1-2 . 21 /-1+/(1-1) ()] 1 [ Adding the above inequalities 
for i = 1,..., k -1, and using (13) again, we get lnN(k,l) -lnl <21-1 k-1 21 1 1-2 . # 1 ;(y) -  21 
1-1+ 21 /(/-1) -+ s-[(k-2)+(i-2) (1-(+) k-[)]. Multiplying the whole inequality by 2(/ -1)/(21 -1) and 
rearranging the terms completes the proof, 0 Proo~Theorem 2-continue]: Let m be arbitrary. Taking advantage 
of the condition (32) define 1 to be the largest integer such that 21-1 + in 1< in m and let u satisfy 
in u = 21-1 + in 1. Thus we have lnu=21-l+lnl<lnm <21+l+ln(l+l), (34) therefore . lnm lnu <2+ln(l+l)-hk~ 
<2+ ~ . (35) and, for 1 ~ 3 (that is for m ~ 446), lnm~21+ l+ln(l+l) <2(21-1). (36) Using (34) we have 
lnu-lnl+l <lnu lnm lnm-lnu 1=  2 -2 -2 2 Since ln(b -a) ~ in b-a/b for any O< a < b, we obtain in m 
lnm-lnu lnl~ln ~ () lnm which by (36) can be reduced to lnm-lnu lnl<lnlnm-ln2 (37) 2(2/-1) Let k be 
such that N(k, 1) ~ m < iV(k + 1, l). Using the inequality from Lemma 4 we have k+l < ~nl+lu N(k+l,l)-lnl 
lnN(k+l, ~)-~ _ 21 1 2 2-2 l-l +1-1 .- . 111 () Now we can rearrange the terms and use the above inequal­ities 
to obtain lnu lni lnm lnu lniV(k+ l,l)-~S~+lnl+ 2/-1 + 21-1 +ln N(k+l,l) lnm 2 1-2 1-1 +1-[ 21 1 i 
1 ()-i­ lnm lnu+21-l+~m-~~ < lnlnm ln2­2(2/ -1) 21-1 21-1. +ln N(k+ 1,1) -lnlV(k, ~) _ ~ 1-2 _1-1 +1- 
21-1 1 ()1 lnm-lnu < lnlnm ln2+l+ 2(21 -1) 2++ J-+ fi( ; )k- + -2, < lnlnm-*n 2+1+ 2(21-1) 1 1-2 1 
1 +1- . 111 () 2++ = lnlnm-ln2+l+ 2(21 -1) + 2/(21-1) ­+1 [ Thus for each m ~ 446 there are 1 and 
k, such that N(k, ~) < m and k ~ > lnN(k+l,l) -1nlnm+ln2-1 > lnm-lnlnm+ln 2-1. (38) Checking small values 
of m, one can show that (38) is true forallm~2. Q ProoflTheorem 3]: In order to simplify the notation, 
let us omit the * when referring to N* and 1 . Hence 1> is now a real number. Repeating the proof of 
Lemma 2, we get 2(k -Llj)lnN(k,l) Zlnllj + 21_1 , hence where Seta=l-[l], thatia O~a<l. Then w = fi+ln(l-a)-lni 
2cr a rr(l 2cr) 2 - G= (2 I -1)(2 -a) Thus for O<rr~l/2andanyk~ 1>1, wehavew~O, hence 2(k 1)lnN(k, 
i) ~ in 1+ ~. (39) Ifs= 1-[/j ~ 1/2, then 1 ~ 3/2, hence N([il, 1) = [1] +2. Therefore 2(k -ii] -1) 
in N(k, 1) ~ ln(ll] +2)+ 21-1 = lnl+-+c, where 2( I -1~1-1, +ln([lj +2) lnL c= 21-1  Similarly as 
above, ~,2a-2 2-a 21+-3 a-4 21-l+m= (2r -1)(1+1) 20 hence (39) is valid for 1/2 < a < 1 as well. Rearranging 
(39) completes the proof. D +[2/:;:,2 - ]  (Wk+ -%(%k+ <lnlnm ln2+l.  
			