
 Copyright and Reprint Permission: Abstracting is permitted with credit to the source. Libraries are 
permitted to photocopy beyond the limit of U.S. copyright law for private use of patrons those articles 
in this volume that carry a code at the bottom of the first page, provided the per-copy fee indicated 
in the code is paid through Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923. For other 
copying, reprint or republication permission, write to IEEE Copyrights Manager, IEEE Service Center, 
445 Hoes Lane, P.O. Box 1331, Piscataway, NJ 08855-1331. All rights reserved. Copyright 2001 by the Institute 
of Electrical and Electronics Engineers, Inc. All rights reserved.Copyright 2001 IEEE. Personal use of 
this material is permitted. However, permission to reprint/republish this material for advertising or 
promotional purposes or for creating new collective works for resale or redistribution to servers or 
lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. 
Pen-and-Ink Rendering in Volume Visualisation S. M. F. Treavett M. Chen Department of Computer Science, 
University of Wales Swansea, United Kingdom Abstract This paper is concerned with the development of 
non­photorealistic rendering techniques for volume visualisa­tion. In particular, we present two pen-and-ink 
rendering methods, a 3D method based on non-photorealistic solid m textures, and a 2 D method that involves 
two rendering phases in the object space and image space respectively. As both techniques utilize volume-and 
image-based data representations, they can be built upon a traditional vol­ume rendering pipeline, and 
be integrated with photoreal­istic methods available in such a pipeline. We demonstrate that such an 
integration facilitates an effective mechanism for enhancing visualisation and its interpretation. Keywords: 
Volume rendering, non-photorealistic render­ing, pen-and-ink rendering, 3D texture mapping 1 Introduction 
The past decade has witnessed the rapid development of volume visualisation techniques, driven mainly 
by applica­tions such as medical imaging and scienti.c computation. The work in this .eld has produced 
a collection of visual­isation methods, including surface extraction [1], volume ray casting [2] and 
splatting [3], together with numerous acceleration techniques. The majority of work in the .eld of volume 
rendering has been focused on the synthesis of photorealistic (PR) im­ages to assist in the visualisation 
of iso-surfaces and amor­phous phenomena contained in volume datasets. By simu­lating the way objects 
are viewed by human eyes, these PR techniques generally give good visual cues to the viewer and enable 
them to interrogate data intelligently. Figure 1 shows some typical visualisations of datasets obtained 
from a magnetic resonance imaging (MRI) and a computed to­mography (CT) scanner respectively. (a) (b) 
Figure 1: (a) An image generated as a visualisation of a MRI dataset, (b) a visualisation of a CT dataset 
showing the skin transparently to convey its relationship with the skull. Recently there has been a surge 
of effort in surface graph­ics for developing non-photorealistic (NPR) modeling and rendering methods. 
Such development has established a no­ticeable role in the .eld of graphical illustration and the en­tertainment 
industry. In the 1998 IEEE Visualisation Con­ference, a call was made for the extension of these tech­niques 
to the .eld of visualisation [4]. Meanwhile, the ad­vances in volume visualisation, coupled with the 
rapid in­crease in computer power, also suggest that volume visu­alisation may be developed into volume 
graphics [5, 6] as a general purpose graphics technology. It is these develop­ments that motivated our 
efforts in the application of NPR techniques to volume rendering particularly as effects sim­ilar to 
pen-and-ink had already been used to try and help visualise transparent surfaces [7]. Pen-and-ink based 
line drawing has been used as an effec­tive form of abstraction for hundreds of years [8]. The artist 
leaves out a large amount of detail, such as texture and colour, and instead concentrates on outlines 
and lim­ited mood shading. These types of images have often been used in preference to more accurate 
images in spe­ci.c circumstances. For instance a group of psycholo­gists reported in 1996 [9] that, when 
asked to compare a computer-produced sketch against a photorealistically rendered CAD image, architects 
showed a great preference for the sketch for certain purposes. In this paper, we focus on the development 
of pen-and-ink techniques in a volume rendering pipeline. We will de­scribe two different methods for 
rendering volume datasets with line drawing effects. We will apply these techniques to datasets with 
complex geometry such as medical volume datasets, while using mathematically de.ned scalar .elds to illustrate 
various attributes of the techniques. We will demonstrate that not only can the techniques be used as 
a cost-effective tool for graphical illustrations involving vol­ume datasets, they can also be employed 
to enhance the process of extracting meaningful information from volume datasets. In particular, we will 
show that integrated NPR and PR rendering can offer different levels of abstraction to assist in the 
interpretation of synthesised images for visual­isation. 2 Background of Nonphotorealism An ever increasing 
amount of work has been carried out in the .eld of non-photorealistic (NPR) rendering since its emergence 
around 1990 [10]. In 1995 an extensive review of the state of the art was published by Landsdown and 
Scho.eld [11]. Although not trying to exactly imitate the work of human artists, most researchers in 
the .eld of non­photorealism have modeled their expressive effects on a well known image style, including 
line drawings using pen­cil and pen [12, 13] oil painting [10] and water colour [14]. Imitation of paintings 
started with Strassman s detailed simulation of a brushstroke [15] and progressed into more re.ned and 
simplistic brush stroke models such as Pham s [16] and Hertzmann s [17] approaches using B­splines [18, 
19]. Hertzmann s technique incorporates these strokes into complete painting-style images in the fashion 
pioneered by Haeberli s oil painting model [10] and contin­ued by Curtis et al. s complex model of water 
colour paint­ing [14]. In Strassman s Piranesi [15] system the 2D tech­niques used by the others are 
extended by passing some spa­tial information from the rendering engine into image space as a z-buffer 
[20]. Due to the inherent simplicity of line drawings many au­thors have focused their efforts on production 
of this kind of effect. The papers by Wikenbach and Salesin [21] and Sal­isbury et al. [12] in SIGGRAPH 
94 paved the way for this work. Wikenbach and Salesin later extended their pen-and­ink styles to the 
rendering of parametric surfaces [22] and Elber made further extension for freeform surfaces [23]. Buchanan 
and Veryovka treated pen-and-ink drawing as a special case of halftoning [24, 25]. Further work by Sal­isbury, 
with his colleagues, provided methods of orient­ing [26] and scaling [27] pen-and-ink textures. Moving 
away from pen-and-ink, Sousa and Buchanan have researched into the simulation of graphite pencil draw­ings 
[13, 28]. Hamel and Strothtte [29] developed a system which allows users to capture and reproduce particular 
NPR styles generated with the system. Among the existing NPR techniques, many have been purely 2D techniques 
working in image space. Those tech­niques that have made use of 3D information from graphics models are 
almost all built upon surface-based representa­tions [13]. Despite the 1998 call [4] for research into 
NPR techniques in the context of visualisation, adequate effort is yet to be made to develop such techniques 
for visualisation purposes, and to investigate into their effective deployment in visualisation applications. 
 3 Pen-and-Ink Rendering Pen-and-ink techniques can be classi.ed into three main categories according 
to the speci.cation of pen-and-ink strokes and the use of information associated with the orig­inal 3D 
objects. These categories are: 3D drawing, where 3D strokes are generated in the object space and are 
projected onto an image plane by a rendering algorithm. A common approach is to generate pen-and-ink 
strokes as textures and to render the textures with a purposely built renderer [23, 22]. m 2 D drawing, 
where 2D strokes are generated based on 3D or partial 3D information associated with orig­inal 3D objects. 
Such a technique often involves a pre-rendering stage which generates necessary 3D at­tributes for each 
pixel in the image space; and an NPR rendering stage which synthesises a pen-and-ink image based on the 
information which has been for­warded to image space. A typical example is the use of G-buffers employed 
by a number of pen-and-ink algorithms [25, 30]. 2D drawing, where 2D strokes are generated based solely 
on the 2D information available in image space. Techniques in this category are fundamentally akin to 
many traditional halftone techniques [27]. The 2D pen-and-ink techniques have limited control over 3D 
effects that may be represented by strokes. Without the intervention of a user, it is unlikely such techniques 
can be used effectively for the purpose of visualisation. Our work has therefore focused on the other 
two categories. 3.1 3D Pen-and-Ink Rendering A scalar .eld is the underlying mathematical de.nition of 
a volume dataset coupled with an interpolation function. This concept forms the basis of a variety of 
volume visualisa­tion techniques, including isosurfacing, volume sampling and attribute mapping. It also 
provides a means for specify­ing NPR textures in volume rendering. In general, an NPR texture is essentially 
de.ned as a .lter: DD mD whereis a point in the spatial domain of a texture, is a set of object attributes 
associated with(e.g. the cor­responding value in the original volume dataset, the RGB m values for a 
mapped colour, etc.), andis a set of tex­ture attributes (e.g. density, line width and length, noise 
level, etc.). (a) (b) (c) (d) (e) (f)   Figure 2: pen-and-ink techniques of increasing complexity: 
(a) straight pen lines , (b) varying thicknesses, (c) noise added to lines, (d) introducing lighting 
effects, (e) a second set of lines, (f) advanced techniques. All our 3D NPR textures are de.ned in a 
normalized do- D eNPD e main of[0D eNP[0[0. In our rendering pipeline [31] which was designed for multi-volume 
rendering, there is no extra cost for mapping an arbitrary sampling point to a point in the normalized 
domain. Consider a simple texture, as shown in Figure 2(a), that consists of horizontal rings de.ned 
in cylindrical manner. The geometry of the texture is controlled by its density e D e D e [0and ring 
thickness[0. We thus have a scalar .eld:  e 0 (0 n yDe D 0 lPPy -2N(d K ))-P1y I2  2 (d K )- e lP 
2N(d K )- P1y I: 2(d K )- ewhere (yd 2 denotes a round operation, andde.nes ny the maximum number of 
rings as 2 ( K -. Scalar .eld preserves the consistency and coherence of the texture in e terms of varyingand 
. For instance, given a point and a .xed , nyDe Dee Dny DDe implies V d 2d; and n yDe D e Dn yDD 0implies 
V d :d0. This feature is essential in maintaining coherence in ani­mation even for such a simple texture. 
In particular, in the following discussions, we will .nd that many visualisation e effects are controlled 
byand . n y The binary output of easily leads to aliasing, which can be overcome by introducing a simple 
grey scale function to reduce the ring intensity gradually along their edges. How­ever, a more dense 
texture could easily cause unnatural arti­facts as shown in Figure 2(b). We thus add a noise function 
into the texture through the use of a set of pre-computed noise lattices [32, 33]. The use of such lattices, 
instead of a run-time random number generator, is not only for the consideration of computational speed 
but also for maintain­ing coherence in animation. As shown in Figure 2(c), the noise function removes 
the undesirable artifacts shown in Figure 2(b), as well as the degree of arti.cial perfection which is 
rare in real life hand drawings. ny Together with the anti-aliasing and noise functions, can be implemented 
as the following procedural texture float f1(p, td, tt, tn) Point3 p; float td, tt, tn; /* density, thickness, 
noise */ { int k, r; float y1, y2, dy, fr; if ((k = round(td*K)) == 0) return(0.0); y1 = p.y + noise_field(p)*tn; 
 r = (01)<<(k-1); /* r = 2 (k-1) */ y2 = round(y1*r)/r; /* needs float division */ dy = abs(y1 -y2); 
 if (dy >= tt) return(0.0); else if ((fr = dy/tt) <= 0.5) return(1.0); else return(2.0-2.0*fr); } During 
rendering, it is quite possible to treat an NPR tex­ture in the same way as a PR texture, that is by 
feeding the obtained texture colour as the object colour into an illumi­nation model. However, in this 
case, the visual cues are in fact provided mainly by the traditional shading, and it somehow defeats 
the objective of NPR rendering. We adopt an approach that applies shading prior to the ap­plication of 
a pen-and-ink texture. Given a point detected to be on a speci.ed iso-surface, the rendering process 
.rst determines the light intensity at using a traditional illu­mination model. It then modi.es the texture 
attributes such e as and according . The resultant texture value is then used to synthesis the pixel 
colour. The example shown in Figure 2(d) is rendered by the following sequence of oper­ations: Colour 
F(p, oatt, tatt) Point3 p; Oatt oatt; Tatt tatt { float l, td, tt, tv; Colour c; l = illumination(p, 
oatt); switch (tatt.type) { ... case CYLINDRICAL_RINGS: td = tatt.td * (1.0 -l); tt = tatt.tt * (1.0 
-l); tv = f1(p, td, tt, tatt.tn); break; case ...: ... } c.r = (1-tv)(oatt.r*tv + BG.r); c.g = (1-tv)(oatt.g*tv 
+ BG.g); c.b = (1-tv)(oatt.b*tv + BG.b); } The last three statements in the above procedure determine 
b a colour at according to the obtained texture value, which also acts as an opacity value when applying 
an over operation to the colour and a background colour. Later, we b will also discuss the use ofas an 
opacity value in the combination of PR and NPR rendering. (a) (b) Figure 3: Pen-and-ink style rendering 
of a CT dataset. A variety of textures can be de.ned in a way similar to nyDe DD , and they can easily 
be combined together to give more visual cues (Figures 2(e) and 2(f)). Figure 3 shows the application 
of two pen-and-ink textures to a CT dataset. Both volumes were lit by a point light source in the front. 
m 3.2 2D Pen-and-Ink Rendering While a 3D pen-and-ink rendering method may bene.t from the availability 
of a variety of 3D information associ­ated with graphics objects, it faces a degree of dif.culties in 
appreciating the information in the context of the .nal im­age. For instance, during the rendering of 
a volume dataset, it is trivial for a renderer to locate information near a sam­pling point or a voxel. 
However it is not that straightforward for the renderer to know if such information would ever be used 
to determine the colour of any pixel in the image plane. This leads to the desire to a two-phase approach, 
with which the .rst phase rendering in the object space identi.es all necessary 3D information relevant 
to what is to be synthe­sised in the image plane, and the second phase rendering in the image space applies 
NPR effects, often to more than one pixel, with a global view of all relevant information. m We refer 
such techniques as 2 D NPR techniques, as the NPR renderer has access to a restricted collection of spatial 
information. Different information from the object space can be used to in.uence the pen-and-ink drawing 
in different ways. An outline of an object, such as the one shown in Figure 4(a) may be determined by 
the variation of the distance of neigh­bouring pixels in the image plane to the visible surface or, alternatively, 
by the angle between the surface normals and the view plane normals. The length, thickness and density 
of strokes may be determined by normals in relation to a light source, as shown in Figure 4(b) where 
all strokes fol­low the same direction. Direction of strokes can be con­trolled by the curvature of the 
surface (Figure 4(c)). The .­nal image shown in 4(d) is generated by an amalgamation of the interior 
shading (Figure 4(c)) and outline (Figure 4(a)) images. (a) (b) (c) (d)  Figure 4: The sphere rendered 
in pen-and-ink as: (a) out­line only, (b) interior shading with lines in oue direction only, (c) interior 
shading with control of line direction (d) (a) and (c) together. m In 2 D pen-and-ink rendering, the 
.rst phase forwards more than just colour information into the image space. This information can be passed 
on as a set of gimage n ByD n BDcn n n D n Bg buffers. The choice of information to 2 pass on very much 
depends on the NPR effects one wishes to achieve, but obviously the more information, the more .exibility 
and control can be exercised in image space. In m our 2 D rendering system we forward the following set 
of image buffers into image space: n Byt eN: : A greyscale image synthesized using a PR shading method 
as shown in Figure 5(b), where any light source or sources can be introduced as required. n BgeNt : A 
buffer containing the distances from the image plane, following the individual projection lines, to the 
visible part of a speci.c iso-surface in the n B dataset. Figure 5(a) shows a visualisation of this where 
the distances are mapped to a grey-scale range of 0215 5and the background designated as not hit­ting 
the surface in the dataset is coloured red for clar­ity. n B w : A buffer that forwards, for each pixel, 
a vector represents the normal estimated for the cor­responding point on the visible surface. In Fig­ 
n B ure 5(c),is visualized as the angles between the surface normal and the view plane normal. An angle 
D cP D [02maps onto an intensity [02 515, and red once again represents the background.n Bgtwb: n B : 
Actually split into two s, namely n B twb:n BybNtwb: (Figure 5(e)) and (Figure 5(d)), which contain 
the curvature of the surface in the hor­izontal and vertical directions respectively. In this case, curvature 
is taken as the rate of change of nor­mals across the surface. (a) (b) (c) (d) (e)   Figure 5: Control 
image buffers containing (a) distance, (b) shade, (c) normals, (d) vertical curvature and (e) horizontal 
curvature. n B Having a set of s containing the necessary spatial infor­mation, the second phase renderer 
can apply different pen­and-ink .lters to synthesise an NPR image. For example, an outline .lter n t 
:n BgeNt nI y nI y determines the pixel values in according to the val­ n BgeNt ues in. If a pixel neighbours 
others of signi.cantly different distance values, it is interpreted as being on the outline, and a short, 
oriented pen stroke is added in the di­rection of this section of the outline. Figure 6(a) shows an outline 
image generated based on the information contained in Figure 5(a). A more complicated .lter nte :n BteN:D 
n BetD n BywD n Btwb:nI2 is used to generate sketch drawings inside the boundary, as shown in Figure 
6(b), taking into a variety of information nt eN: forwarded by the .rst phase rendering. acts by the 
drawing of short lines emanating from randomly sampled n Bn BteN: points in the set. enables us to make 
the deci­sion of whether a line is needed at each pixel in the image n BgeNt plane, is used to ensure 
lines do not traverse more n Bgtwb: than one surface, allows us to decide which direc­ n B w tion a stroke 
should be drawn in and constrains the length of strokes. A simple .lter is then invoked, which combines 
two images, nIynI and , into a .nal image as shown in Figure 6(c). 2 (a) (b) (c) m Figure 6: The application 
of 2 D pen-and-ink rendering to a CT dataset: (a) the outline, (b) the interior shading and (c) the .nal 
image.  4 Integration with Photorealistic Rendering Both pen-and-ink rendering techniques discussed 
above were implemented in a volume-based pipeline using ray casting, with a focus on the evaluation of 
single or multiple Figure 7: Using pen-and-ink rendering to display the skin around the skull gives good 
visual cues to its thickness. iso-surfaces. As the pipeline also incorporates traditional PR rendering 
techniques, it intrinsically facilitates the inte­gration between PR and NPR effects. One of our approaches 
is to apply PR and NPR rendering to different iso-surfaces as shown in Figure 7, where the bone surface 
is rendered using traditional PR effects while the skin surface is rendered in the same way as in Figure 
3(a). However, the main algorithmic difference between the two .gures is that the skin surface in Figure 
7 does not have a uniform opacity, its opacity in fact varying according to the pen-and-ink texture. 
In this particular example, we have NNbn yDe DD , which transforms the surface to a net full of holes. 
In tra­ditional volume visualisation, we often visualise multiple isosurfaces by making the outer surface 
transparent as in Figure 1(b). Our integrated method provides an alterna­tive mechanism for such needs. 
Comparing Figure 7 with Figure 1(b), the former shows more visual cues to the rela­tionship between the 
skin and bone, giving a greater insight into the variations of skin depth around the head, where the 
latter effectively allows the translucent outer surface to ob­scure the real colour of the skull. We 
can also introduce some minimal opacity to a surface rendered with a pen-and-ink texture. As shown in 
Fig­ure 8(a), the pen-and-ink effects on the outer surface pro­vide necessary 3D visual cues to an otherwise 
constant sphere in terms of both colour and opacity. On the other hand, many of us would experience a 
degree of uncertainty about the actual geometry when given a visualisation sim­ilar to the one shown 
in Figure 8(b). The merits of com­bined PR and NPR effects are clearly demonstrated in Fig­ures 8(c) 
and 8(d) where more than two nested surfaces are considered. We can also assign different surface attributes 
to different volume objects as seen in Figure 9. One application of pen-and-ink visualisation is to convey 
to the viewer a less .nished, or less real, appearance for the object in ques­tion. Figure 9(a) shows 
a visualisation of an actual head with the introduction of a new object, possibly a schematic for intended 
surgery or such like. Varying rendering styles through a visualisation can also be used to direct attention 
as seen in Figure 9(b) where the attention is immediately drawn to the rod rather than the head, as it 
is in Figure 9(a). In the case of Figure 9(c) emphasis is very clearly given to the photorealistic brain. 
The pen-and-ink rendering is used  (a) (b) (c) (d) Figure 8: NPR gives better visual cues for concentric 
spheres. to aid visualisation of the brain by showing the relative ge­ometry of the face. This brings 
the brain in context without distracting the viewer too much from the intended focus of the visualisation. 
 5 Other Results and Discussion One of the great strengths of pen-and-ink visualisation is that it can 
be used to leave out details that may be consid­ered a little too much or even gloss over missing details 
in an initial presentation. Our techniques can be applied to any volume dataset and we have produced 
extremly powerful images from a number of sources. One major source of vol­ume data is medical machinery 
output very often showing body parts such as skulls, brains, or other internal organs. Although a photorealistic 
visualisation may be of great ben­e.t to a surgeon in diagnosing what problems exist and de­ciding what 
course of action to take it may sometimes be desirable to present this data to a patient or their relatives 
by means of explanation. In this case a photorealistic visualisa­tion may be too vivid and shocking whereas 
a pen-and-ink rendering could be used to as a less gory visual aid. Fig­ure 10 shows two examples of 
non-photorealistic medical data visualisation: Figure 10(a) being a monkey s skull and Figure 10(b) being 
the skull from the CT data set shown in previous images in this paper (e.g. Figures 5 and 6). As mentioned 
above another use for pen-and-ink visualisa­tions could be as an initial presentation of a preliminary 
design to a client. In the real world it is often the case that expensive CAD tools may be laid aside 
in favour of an artist s hand at the initial stages of the design process. Figure 11 shows a sketch of 
a plane, in this case gener­ated from a volume dataset, although presentable to a client as a designer 
s .rst ideas. The visualisation can be further enhanced with animations, for which the 3D pen-and-ink 
techniques ensure the coher­ (a) (b) (c) Figure 9: Non-photorealism can be integrated with pho­torealism 
to provcide certain emphasis and/or direct the viewer s attention. ence between consecutive frames. Figure 
12 shows two se­quences of frames extracted from an animation with varying lighting and camera positions 
respectively. 6 Conclusions There is no doubt that NPR techniques in general, and pen­and-ink effects 
in particular, are effective tools for graph­ical illustrations. In this paper, we have shown that pen­and-ink 
rendering techniques can also be implemented in a volume-based graphics pipeline, which facilitates a 
consis­tent representation of NPR textures as scalar .elds, an in­trinsic integration with traditional 
PR techniques, and a rich collection of information for image space pen-and-ink ren­ m dering. The 2 
D method discussed in this paper provides pen-and-ink drawings close to human hand painting in both style 
and quality with very little user interaction-the same parameter set was used for all the images shown 
in this pa­per. For visualisation, the 3D method, in conjunction with PR rendering, can also be used 
to enhance 3D visual cues for translucent surfaces, and to highlight or de-emphasise objects. In many 
scenarios, such combined techniques can be more effective than the use of PR techniques on their own. 
To follow this work, we intend to conduct a human-factor study into the effectiveness of pen-and-ink 
rendering tech­niques in volume visualisation.  References [1] W. Lorensen and H. Cline, Marching cubes: 
a high resolution 3d surface construction algorithm, Proc. SIGGRAPH 87, vol. 21, no. 4, pp. 163 169, 
July 1987. [2] M. Levoy, Display of surfaces from volume data, IEEE Computer Graphics and Applications, 
vol. 8, no. 3, pp. 29 37, May 1988. [3] L. Westover, Footprint evaluation for volume ren­dering, Proc. 
SIGGRAPH 90, vol. 24, no. 4, pp. 367 376, Aug. 1990. [4] D. Laidlaw (Organiser), Art and visulaization: 
Oil and water?, in IEEE Visualisation, 1998, pp. 507 509, Panel Session. [5] A. Kaufman, D. Cohen, and 
R. Yagel, Volume graph­ics, IEEE Computer, vol. 26, no. 7, pp. 51 64, 1993. [6] M. Chen, A. Kaufman, 
and R. Yagel, Eds., Volume Graphics, Springer, London, 2000. [7] V. Interrante, H. Fuchs, and S. Pizer, 
 Illustrating transparent surfaces with curvature-directed strokes, Visulaisation 96, pp. 211 218, 1996. 
[8] W. Luzadder and J. Duff, Fundamentals of Engineer­ing Drawing, Prentice-Hall International Editions, 
1989. [9] J. Schumann, T. Strothotte, A. Raab, and S. Laser, Assessing the effect of non-photorealistic 
rendered images in cad, CHI 96, pp. 35 41, Apr. 1996. [10] P. Haeberli, Paint by numbers: Abstract image 
rep­resentation, Proc. SIGGRAPH 90, vol. 24, no. 4, pp. 207 214, 1990. [11] J. Lansdown and S. Scho.eld, 
Expressive ren­dering: A review of nonphotorealistic techniques, IEEE Computer Graphics and Applications, 
pp. 29 37, May 1995. [12] M. Salisbury, S. Anderson, R. Barzel, and D. Salesin, Interactive pen-and-ink 
illustration, Proc. SIG-GRAPH 94, vol. 28, no. 2, pp. 101 108, 1994. [13] M. Sousa and J. Buchanan, 
Computer-generated graphite pencil rendering of polygonal models, Pro­ceedings of Eurographics, vol. 
19, no. 3, 1999. [14] C. Curtis, S. Anderson, J. Seims, K. Fleischer, and D. Salesin, Computer-generated 
watercolour, Proc. SIGGRAPH 97, 1997. [15] S. Strassman, Hairy brushes, Proc. SIGGRAPH 86, pp. 225 232, 
1986. [16] B. Pham, Expressive brush strokes, Computer Vi­sion, Graphics, and Image Processing, vol. 
53, no. 1, pp. 1 6, 1991. [17] A. Hertzmann, Painterly rendering with curved brush strokes of multiple 
sizes, Proc. of SIGGRAPH 98, pp. 453 460, July 1998. [18] R. Bartels, J. Beaty, and B. Barsky, An Introduction 
to Splines for Use in Computer Graphics and Geometric Modelling, Morgan-Kaufmann, 1987. [19] C. De Boor, 
On calculating with b-splines, Journal of Approx Theory, vol. 6, pp. 50 62, 1972. [20] E. Catmull, A 
hidden surface algorithm with anti­aliasing, Proc. SIGGRAPH 78, pp. 6 11, 1978. [21] G. Winkenbach and 
D. Salesin, Computer-generated pen-and-ink illustration, Proc. SIGGRAPH 94, vol. 28, no. 2, pp. 91 100, 
1994. [22] G. Wikenbach and D. Salesin, Rendering parametric surfaces in pen and ink, Proc. SIGGRAPH 
96, pp. 469 476, 1996. [23] G. Elber, Interactive line art rendering of freeform surfaces, Proceedings 
of Eurographics, vol. 18, no. 3, 1999. [24] J. Buchanan, Special effects with half-toning, Com­puter 
Graphics Forum, vol. 15, no. 3, pp. 97 108, 1996. [25] O. Veryovka and J. Buchanan, Comprehensive halftoning 
of 3d scenes, Proceedings of Eurograph­ics, vol. 18, no. 3, 1999. [26] M. Salisbury, M. Wong, J. Huges, 
and D. Salesin, Orientable textures for image-based pen-and-ink il­lustration, Proc. SIGGRAPH 97, 1997. 
[27] M. Salisbury, C. Anderson, D. Lischinski, and D. Salesin, Scal-dependent reproduction of pen-and­ink 
illustrations, Proc. SIGGRAPH 96, pp. 461 468, 1996. [28] M. Sousa and J. Buchanan, Observational model 
of blenders and erasers in computer-generated pencil rendering, Proceedings of Graphics Interfaces 99E, 
1999. [29] J. Hamel and T. Strothotte, Capturing and re­using rendition styles for non-photorealistic 
render­ing, Proceedings of Eurographics, vol. 18, no. 3, 1999. [30] T. Saito and T. Takahashi, Comprehensible 
rendering of 3d shapes, Proc. SIGGRAPH 90, vol. 24, no. 4, pp. 197 206, 1990. [31] M. Chen, J. Tucker, 
and A. Leu, CROVE -a render­ing system for constructive representations of volume environments, in International 
Workshop on Volume Graphics, Mar. 1999, pp. 275 294. [32] D. Peachy, Solid texturing of complex surfaces, 
Proc. SIGGRAPH 85, vol. 19, no. 3, pp. 279 286, July 1985. [33] K. Perlin, An image synthesiser, Proc. 
SIGGRAPH 85, vol. 19, no. 3, pp. 287 296, July 1985. [34] M. .amek and A. Kaufman, Object voxelization 
by Sr´.ltering, in IEEE Symposium on Volume Visualiza­tion, 1998, pp. 111 118. [35] M. Sr´.amek and A. 
Kaufman, vxt: a c++ class li­brary for object voxelization, in International Work­shop on Volume Graphics, 
1999, pp. 295 306.  (a) (b) Figure 10: The technique can be used to visualise different volumes in the 
same style. Figure 12: Exerts from two animation sequences: (left) lightsource animation, (right) viewpoint 
animation.  Plate 1: A PR rendered MRI head (above), and the same with an NPR textured face (right). 
 Plate 2: A PR rendering showing skin translucently (above), and one with NPR lines (left).  Plate 
4: From left to right: two concentric spheres, PR and then NPR, three concentric spheres, PR and then 
NPR. Plate 5: A pen-and-ink sketch of the CThead along with the .ve image buffers used to generate it. 
The image buffers contain (top right to bottom left) distance, shade, normals, vertical curvature and 
horizontal curvature information. 
			