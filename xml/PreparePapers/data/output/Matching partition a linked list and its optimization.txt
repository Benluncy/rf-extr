
 Matching Partition a Linked List and Its Optimization Yijie Hart Department of Computer Science University 
of Kentucky Lexington, KY 40506 ABSTRACT We show the curve O( nl°gi + log~0n + log/) for the time P 
complexity of computing a maximal matching for a linked list, where n is the size of the input list, 
p is the number of processors used in the algorithm and i is an adjustable parameter. For all constructible 
i the time complexity represented by the curve can be realized. Our algorithm is n optimal using up to 
O(lo~0n ) processors with an arbitrarily large constant i. This algorithm can be used to compute a maximal 
independent set or a 3 coloring for a linked list.  1. Introduction A matching set of a graph is a set 
of edges such that no two edges in the matching set are incident on the same vertex. The matching set 
is maximal if adding one more edge to the matching set makes it a nonmatching set. In a sense, to find 
a maximal matching set for a linked list in parallel is to break the parallel symmetrical situation of 
the linked list. The parallel computation model used in this paper is the well known Parallel Random 
Access Machine[2] (PRAM). We say that a parallel algorithm is optimal if p.Tp =O(T1), where p is the 
number of processors used in the parallel algorithm, T e is the time complexity of the parallel algorithm 
and T 1 is the time complexity of the best known sequential algorithm. In this paper we shall use n to 
denote the size of the input, i.e., the number of Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. nodes in the linked list, and p to denote the number of processors 
used in an algorithm. Although many previous linked list prefix algorithms [9,11,13,16] can be used to 
compute a maximal matching set for a linked list, they are either randomized algorithms or algorithms 
with time complexity not less than O(logn). A previous algorithm discovered independently by Han[6] and 
Cole and Vishkin[3] for computing a maximal matching set uses p=n processors and achieves time complexity 
O(G(n)), where G(n)=min{kllogCk)n < 1}, log(k)n is defined as: log0)n=logn, log(k)n=log(log(k-On), and 
as usual, the base of a logarithm is 2 if not specified. This algorithm is not optimal. An EREW[14] PRAM 
algorithm with time complexity 0(~ + logn) was also independently discovered by Han[6] and Cole and Vishkin[3]. 
This algorithm is optimal using up to 0(lo~) processors. The main obstacle prohibiting this optimal algorithm 
using more than O(lo~n) processors is a global sorting step which sorts integers of small magnitude. 
By using Reifs sublogarithmic partial sum algorithm[12], Han[6] showed that on the CRCW(concurrent read 
concurrent write)[14] PRAM the sorting can be done in O(~ + 7~P~TZ)logC3)n steps, thus obtaining a CRCW 
maximal matching algorithm with time complexity O(~ + lo~ log(3)n 9 which is optimal using up to . processors. 
Cole and Vishkin showed[4] that nlo~, O( logn : the partial sum can be computed in time O(~ + --~P-~-q--:log(Z)n~, 
&#38;#169; 1989 ACM 0-89791-323-X/89/0006/0246 $1.50 thus yielding a CRCW maximal matching algorithm 
with time complexity O(~+ 7~7) which is optimal using up log(2)n nlog(2)n  to O ~ iogn -=) processors. 
Recently Han[7] and Beame observed a faster algorhhm for computing a maximal matching. Beame's observation 
was stated in the journal paper of Goldberg et al.[5]. This algorithm uses a table lookup technique and 
has time complexity 0(~+ logG(n)). Han's P version[7] gives a fast scheme for constructing the lookup 
table. Note that this algorithm is not optimal. In this paper we present a new algorithm for computing 
a maximal matching set for a lir~ked list. This algorithm is designed by applying an optimal processor 
scheduling technique to compute a maximal matching set from the matching partition obtained by the known 
0 1 2 X x 0 x 2 x 4 NEXT 3 5 4  Fig. 1. A 2. Matching Partition a Linked List Let us assume that a 
linked fist of n elements (nodes) is stored in an array X[0..n-1] and NEXT[O..n-!] is the array of pointers 
with NEXT[i] pointing to the next element to X[i], as shown in Fig~ 1. For a node v in the linked list, 
we also denote the node following v in the list by suc(v) and the node preceding v by pre(v). We use 
<a, b> to denote a pointer valued b in location NEXT[a]. b is the head of the pointer and a is the tail. 
A pointer <a, b> is a forward pointer if b > a, otherwise the pointer is a backward pointer. By drawing 
a line c bisecting the array containing the linked list as shown in Fig. 2, we observe that forward pointers 
crossing line c have disjoint heads and tails. This is because no two pointers can have the same head 
or the same tail and the head of one pointer can not be the tail of the other pointer because both pointers 
are forward pointers crossing line c. We associate with bisecting line c two matching sets of pointers, 
one consisting of forward pointers crossing c, the other of matching partition algorithms. Combined with 
previous results we demonslrate the curve O( nl~ + log(0n + log/) P for the time complexity of computing 
a maximal matching for a linked list, where n is the size of the input list, p is the number of processors 
used in the algorithm and i is an adjustable parameter. We say that i=i(n, p) is constructible if the 
time complexity of computing function i(n, p) does not dominate the time complexity of the whole algorithm. 
Here, i(n, p) is constructible if it can be computed in O( nl°~ + log(°n + log/) time. For all P constructible 
i the time complexity represented by the curve can be realized. In particular, when i is a constant an 
algorithm with time complexity O(~ + log(0n) can be 1 n obtained which is optimal using up to O(lo~0n) 
processors. 3 4 5 6 x 1 x 5 x 3 x6  1 6 2 nil linked list. backward pointers crossing c. The linked 
list array is divided into two sub-arrays by line c. We can draw bisecting lines cl, c2 for the two sub-arrays. 
Forward pointers crossing either cl or c2 but not c have disjoint heads and tails. Continuing in this 
fashion it is not difficult to see that the pointers of the linked list can first be partitioned into 
two sets, a set of forward pointers and a set of backward pointers, and then each set can further be 
partitioned into [-logn] matching sets, with pointers in one set having disjoint heads and tails. A close 
examination of the pointers crossing bisecting lines reveals that the function g(<a, b>)=max{i I the 
i-th bit of aXORb is 1}, where XOR is the bit-wise exclusive-or operation and bits are counted from the 
least significant bit starting with 0, characterizes the set of pointers crossing bisecting lines (both 
forward and backward pointers). Function g can be modified to distinguish between forward and backward 
pointers. We define function f(<a, b>)=2k+ak, where k=max{i I the i-th bit of aXORb is 1} and ak is the 
k-th bit of a. Note that ak denoms whether <a, b> is a forward pointer or a backward pointer. C cl | 
c2 Fig. 2. The intuitive Lemma 116]: Function f partitions the n pointers of a linked list into 2Ulogn] 
matching sets. [] We say that function re(a, b) is a matching partition function if re(a, b)#m(b, c) 
whenever ac-b or b:~c. Function f defined above is a matching partition function which partitions the 
n pointers of a linked list into 2[logn] matching sets [6]. In [6,15] we also used the least significant 
bit 1 instead of the most significant bit for defining functionf. In doing so, we gain the advantage 
for computing function f at the expense of losing intuition. Function f can be computed using a table 
lookup technique[6,15]. We shall deal with the details of the parallel computation of the matching partition 
functions in the appendix of this paper. Henceforth we shall assume thatf(a, b) can be computed in O(1) 
time by a single processor. 1 Lemmas 1 to 4 are from [6]. The scheme of using the least significant 1-bit 
to obtaining a matching partition function and the results in Lemmas 2 to 4 were independently discovered 
in [3]. The intuitive observation presented here was observed exclusively by the author[6]. observation 
of bisecting. Because on a linked fist b=suc(a), we also writef(<a, b>) asf(a, suc(a)). If a is the last 
element in the list, we can definef(a, suc(a))=f(a, b), where b is (the address of) the first element 
of the linked list. After we assign the value off(a, suc(a)) to node a and view it as the "new address" 
of the node, functionfcan be re-applied to obtain a coarser partition[@ Defmej42)(ab a2)=f(ab a2),fi~)(ab 
a2, .... at`)=f(l~k-1)(al, a2 ..... at`_l), fCk-1)(a/, a3 ..... ak)). Function fit') represents repeated 
applications of function f to the linked list. Lemma 2[6]: Function ilk) partitions the pointers of a 
finked fist into 21og(k-1)n(l+o(1)) matching sets. [] We shall extend the definition of matching partition 
functions. We say that function m(k) is a matching partition function ff m(k)(ab a2 ..... ak)C-m(k)(a2, 
a3 ..... ak÷l) whenever there exist i and j such that ai#aj. Function j~k) is a matching partition function 
which partitions the n pointers of a linked fist into 21og(~l)n(l+o(1)) matching sets[61. Remark: Recent 
studies[8] show that there exists a matching partition function m(k)(al, a2 ..... ak) which partitions 
the n pointers of a linked list into log(k-1)n(l+o(1)) matching sets. Such a function may be more difficult 
to compute than the matching partition S:=O; functions provided in Lemmas I and 2. However, it can be 
for all nodes i do in parallel: shown that no matching partition function m(~}(al, a2 ..... DONE[ tq:=false; 
 ak) can partition the pointers into less than 1og(k-~ln matching sets[8,10]. When k reaches G(n), 210g(k-lIn(l+o(1)) 
becomes a constant. Consequently, we obtained a maximal matching. The algorithm[6] for achieving this 
is shown below. Algorithm Matchl: Step 1. For node v, l_<~_n, do label[v]:= address of v. Step 2. for 
i:-- 1 to G(n) do for node v, l_<v~n, do in parallel /*ComputefCi*l). */ label[v]:=f(<label[v], label[suc(v)]>); 
 Step 3. If label[pre(v)] > label[v] and label[v] < label[suc(v)] then delete pointer <v, suc(v)>. Comment: 
After step 3 the linked list is cut into many sublist each of them has constant number of nodes. Step 
4. Walk down each sublist to add every other pointer of the sublist to the matching set. The matching 
set found by Algorithm Match1 is maximal because at least one of any three consecutive pointers of the 
linked list is in the matching. The time complexity of Algorithm Matchl is O(riG(n) + G(n)). P Lemma 
3[6]: The n pointers of a linked list can be partitioned into O(log(0n) matching sets in 0(~ time, where 
i is a constructible parameter. A maximal matching can be computed in o(nG~+ G(n)) time. []P To obtain 
an optimal algorithm for computing a maximal matching set, we designed the following algorithm[6]. Algorithm 
Match2: Step 1. Partition n pointers into at most log(2)n matching sets. Step 2. Sort pointers by their 
set numbers so that pointers in one set are sequentially located. Note that sorting is performed on integers 
in the range {0, 1 ..... log(2)n-1 }. Step 3. begin for k:=0 to log(2}n-1 do for all pointers <a, b> 
in matching set k do in parallel begin if DONE[a]=false AND DONE[b ]=false then begin DONE[a]:=Irue; 
DONE[b]:=true; S:=S u { <a, b> }; end end Lemma 4[6]: A maximal matching for a linked list can be computed 
in 0(~ + logn) time. [] The time complexity of Step 2 in Match2 dominates the whole algorithm. As shown 
in [6], by adapting Reitfs CRCW partial sum algorithm to sort integers in the range {0, 1 ..... log(2)n-1 
}, the time complexity of the sorting step can be improved to 0(~,~ + log(3)n 9. Cole and Vishkin[4] 
showed that partial sum can be done in time O~° + thus yielding a better algorithm for   logC2 ,? 
computing maximal matching. The idea in Match2 is to obtain a matching partition, then combine partitioned 
sets into a maximal matching. The sorting step is used to schedule processors to process partitioned 
sets one by one. In the next section we show that this global sorting scheme is inefficient. We note 
that the inefficiency due to the global sorting and packing steps for computing linked list prefix on 
the EREW model was exposed[3,6]. Anderson and Miller[l] presented an elegant load balancing scheme to 
circumvent the repetitive global sorting and packing operations in the linked list prefix algorithm. 
The inefficiency due to the sorting step in Match2 seems to be more subtle. The fact that known algorithms 
for computing maximal matching are good enough for the design of a linked list prefix algorithm with 
timing O(~ + logn) on the CRCW model[6] may IF have left the impression that the global sorting step 
in Match2 is efficient. Recently Han[7] and Beame observed a faster algorithm for computing a maximal 
matching set. This algorithm has time complexity O(nl°gG(n) + logG(n)) and P is shown below. Algorithm 
Match3 Step 1. For node v, l_<vgn, do label[v]:= address of v. Step 2. for i:=1 to k do for node v, l_<v'2:n, 
do in parallel label[v]:=f( <label[v], label[suc(v) ]> ); Comment: k is an adjustable parameter. What 
step 2 accompfishes is number crunching. After step 2 label[v] can be represented using no more than 
log(~)n bits. Step 3. for i:=I to logG(n) do for node v, l_<v<_n, do in parallel begin label[v] :=label[v] 
label[NEXT[vii; NEXT[v]:=NEXT[NEXT[v] ]; end Comment: label[v]label[NEXT[v]] is the concatenation of 
the bits of label[v] and the bits of label[NEXT[v]]. After step 3 label[v] has G(n)logtk)n bits. Step 
4. For node v, l_<v<_n, do label[v]:=T[label[v]]. Comment: Step 4 does table lookup. After step 4 each 
label[v] is a constant not related to n. Besides, label[ v ]c-label[ suc(v) ]. Step 5. Step 3 of Matchl. 
Step 6. Step 4 of Matehl. A copy of the lookup table T is of size 2 G(n)l°g(k)n. The largest k we can 
use for this algorithm is O(logG(n)). As shown in [7], a copy of table T can be constructed in constant 
time using n processors on the CRCW model when k is greater than 4. Note that table T contains the function 
values of a matching partition function. We shall deal with the details of the parallel computation of 
the matching partition functions in the appendix of this paper. Lemma 5: The n pointers of a linked list 
can be partitioned into O(log(On) matching sets in O( nl°gi + log/)P time, where i is a constructible 
parameter. A maximal matching can be computed in O(nlogG(n) + logG(n)) P time. [] Note that in order 
to prove the first statement in Lemma 5 we execute O0og/) iterations of the loop in step 3 of Match3 
and initialize the contents of the lookup table with the function values of an appropriate matching partition 
function. 3. Optimization in Computing a Maximal Matching In order to study the processor scheduling 
on the linked list, we view the finked fist of n nodes being stored in a two dimensional array of x rows 
and y columns, y processors are used, each one works on one column. A pointer <a, b> is called an intra-row 
pointer if both a and b are on the same row, otherwise the pointer is called an inter-row pointer. Note 
that by rearranging the pointers in this array we may convert certain inter-row pointers to intra-row 
pointers and certain intra-row pointers to inter- row pointers. We have the following lemma. Lemma 6(Algorithm 
WalkDownl): If all the pointers of a linked list are inter-row pointers, then a maximal matching can 
be computed in O(x) steps with y processors. Proof: We let y processors walk down the columns of the 
array, starting at row 0 and proceeding to row x-1. In a step, let <a, b> be the pointer to be processed 
by processor p. Processor p checks to see whether and what numbers pointers <pre(a), a> and <b, suc(b)> 
are labeled, and label pointer <a, b> with a number in {0, 1, 2} such that the label is different from 
the labels assigned to pointers <pre(a), a> and <b, suc(b)>. Because all pointers are inter-row pointers, 
when processor p is working on pointer <a, b>, no processor is working on either of the pointers <pre(a), 
a>, <b, suc(b)>. Thus the labelling of pointer <a, b> by processor p can be done in constant time. After 
the labelling, we have obtained a partition of 3 matching sets. Executing steps 3 and 4 of Matchl yields 
a maximal matching set. [] For any input linked list, we can always use Lemma 6 to partition the inter-row 
pointers into 3 matching sets. If we have a scheme to partition the intra-row pointers into 3 matching 
sets, we would have a scheme of partitioning the pointers of the whole list into 3 matching sets. Note 
that minor adjustment is needed in combining the partitions for the inter-row and intra-row pointers. 
We now outline a processor scheduling scheme. Suppose that each element of a two dimensional array of 
x rows and y columns is labeled with an integer from {0, 1, .... x-1 }. Let each column of the array 
be sorted in the ascending order by these labels. Allocate one processor to each column and each processor 
walks down the column in the following manner: Algorithm WalkDown2: Let processor p walk down the array 
A [0..x-1 ] containing the sorted labels. count:=O; index:=O; /*Initialize count and index which are 
local variables of processor p. */ for i:=0 to 2x-2 /*Step i*l if index<_x-1 then begin if A[index]=count 
then begin A[ index] :=MARKED; ~ /*Mark the array element*/ index:=index+l; /*Walk to next row*/ end 
else /*Idling in the same row but increment the count*/ count:=count+ 1; end We say that a processor 
is in row r at step k if A/r] is marked at the k-th iteration (starting with 0-th iteration) of the loop 
indexed by i. Lemma 7: In an execution of WalkDown2, processor p is in row r at step k iffA[r]=k-r before 
it is marked. Proof: Each iteration of the loop indexed by i increments either variable count or variable 
index when index is not greater than x-1. It takes k-r iterations to raise the value of count to k-r 
and another r iterations to raise the value of index to r. Therefore A/r] is marked at step k. [] Corollary 
1: After the execution of WalkDown2, every element of A is marked. Proof: Since A[x-1]~_X-1, processor 
p is in row x-1 at step _<2x-2. [] When WalkDown2 is executed in parallel, processors need to be synchronized 
at the beginning of each step. We assume that this is implied by the algorithm. Corollary 2: At step 
k, 0.~_k_<2x-2, all processors in the same row have the same A/index] value before A/index] is marked. 
 Proof: Allprocessors in row r have A[index]=k-r at step t. [] Our main algorithm follows. Algorithm 
Match4: Step 1. Compute a partition of log(0n matching sets for the input linked list, where i is an 
adjustable parameter. log(0n-1}). The sorting can be done by using a sequential integer sorting scheme. 
Step 3. Call WalkDownl to partition the inter-row pointers into 3 matching sets. Step 4. Use WalkDown2 
to partition the intra-row pointers into 3 matching sets. Step 5. Execute steps 3 and 4 of Match1 to 
obtain a maximal matching. Step 4, the key step of the algorithm, may need further explanation. Note 
that in step 4 only intra-row pointers are treated. Corollary 2 says that all processor in the same row 
at a step have the same A/index] value. This implies that pointers in the same row which are processed 
in a step by processors in that row at that step are in the same matching set, therefore no pair of these 
pointers is incident on the same node. This ensures that processors process these pointers can independently 
choose matching set numbers from {0, 1, 2} to label these pointers. When WalkDown2 is used to partition 
the intra-row pointers, we need only replace the statement A[index]:=MARKED with the statement "process 
the pointer at that memory cell". Here "process the pointer" indicates the same operation performed on 
a pointer in WalkDownl, i.e., label it with a number in { 0, 1, 2} such that the labeling differs from 
the labeling of the predecessor pointer and the successor pointer. A trace of step 4 would show that 
intra-row pointers are processed in a pipelined fashion. Note that step 1 of Match4 takes O( nl°gi + 
log/)P steps and the sequential sorting step can be done in time O(x), where x is the number of rows. 
Thus we obtain: Theorem 1: A maximal matching set for a linked list n can be computed in optimal time 
using up to O(loTn) processors, where i is an arbitrarily large constant. [] Combined with previous lemmas, 
we have:  Theorem 2: A maximal matching set for a linked list can be computed in time O( nl°gi + logC0n 
+ log/) for any P constructible i. D 4. Conclusions Step 2. View the array containing the input linked 
list as n a two dimensional array with x=log(0n rows and y=~- columns. Allocate one processor to :each 
column. Each processor then sorts pointers in its column by the pointers' matching set numbers (numbers 
in {0, 1 ..... The processor scheduling technique presented in this paper is powerful enough to yield 
an optimal algorithm with timing O(t) for computing a maximal matching set for a linked list provided 
that the pointers of the list has already been partitioned into O(t) matching sets. Since the best known 
algorithm with timing O( nl°l~i + log/) can P 251 partition a list into at least log(On matching sets, 
the application of our scheduling technique stops here for obtaining optimal algorithms. It is not known 
whether a faster optimal algorithm exists for partitioning the pointers of a linked list. In particular, 
we do not know whether it is possible to partition pointers into G(n) n matching sets in O(G(n)) time 
using G~processors.  References [1]. R.J. Anderson, G. L. Miller. Deterministic parallel list ranking, 
Lecture Notes in Computer Science 319, VLSI Algorithms and Architectures(John Reif ed.), 3rd Aegean Workshop 
on Computing, 81-90(June-July, 1988). [2]~ R. A. Borodin and J. E. Hopcroft. Routing, merging and sorting 
on parallel models of computation, Proc. 14th ACM Symposium on Theory of Computing, San Fransisco, 338-344(April, 
1982). [12]. J. H. Reif. An optimal p~u'allel algorithm for integer sorting, 26th Symp. on Foundations 
of Compt~ter Sci., IEEE, 291-298(1985). [13]. J. H. Reif. Probabilistic parallel prefix computa- tion, 
Proc. of 1984 International Conf. on Parallel Processing, 493-443(Aug., 1984). [14]. M. Snir. On parallel 
searching, SIAM J. Comput., Vol. 14, No. 3,688-708(Aug., 1985). [15]. R.A. Wagner and Y. Han. Parallel 
algorithms for bucket sorting and the data dependent prefix problem, Proceedings 1986 International Conf. 
on Parallel Processing, 924-930. [16]. J. C. Wyllie. The complexity of parallel computation, TR 79-387, 
Department of Computer Science, Cornell University, Ithaca, NY, 1979. [3]. R. Cole and U. Vishkin. Deterministic 
coin tossing and accelerating cascades: micro and macro techniques for designing parallel algorithms, 
Proc. 18th ACM Symp. on Theory of Computing, 206-219(1986). [4]. R. Cole and U. Vishkin. Approximate 
and exact parallel schedufing with applications to list, tree and graph problems, 27th Symp. on Foundations 
of Comput. Sci., IEEE, 478-491 (1986). [5]. A.V. Goldberg, S. A. Plotkin, G. E. Shannon. Parallel symmetry-breaking 
in sparse graphs, SIAM J. on Discrete Math., Vol 1, No. 4, 447-471(Nov., 1988). [6]. Y. Han. Designing 
fast and efficient parallel algorithms. Ph.D. dissertation. Dept. Computer Sci., Duke Univ., 1987. [7] 
Y. Han. An optimal linked list prefix algorithm on a local memory computer. Proc. of the Computer Science 
Conf. (CSC'89), 278-286(Feb., 1989). [8]. Y. Han. On the chromatic number of shuffle graphs, Technical 
report, TR 140-89, Dept. of Computer Sci., University of Kentucky, 1989. [9]. C.P. Kruskal, L. Rudolph, 
M. Snir. The power of parallel prefix, IEEE Trans. Comput., Vol. C-34, No. 10, 965-968(Oct., 1985). [10]. 
N, Linial. Distributive graph algorithms global solutions from local data, Proc. 1987 IEEE Annual Symposium 
on Foundations of Computer Science, 331- 336(1987). [11]. G. L. Miller, J. H. Reif. Parallel tree contraction 
and its application, 26th Syrup. on Foundations of Computer Sci., IEEE 478-489(1985). Appendix We discuss 
the details of the parallel evaluation of certain functions in this appendix. Note that these function 
values can be computed in the preprocessing stage and their time complexity can be excluded from the 
time complexity of our algorithms shown in the paper. However, there is always the desire that the computation 
of these functions be included in the algorithm and their time complexity be counted in the time complexity 
of the whole algorithm. We show how to evaluate these functions on the EREW model. In some cases we need 
the concurrent read feature to fan out the function values to all processors. Two schemes have been proposed 
for computing the 2) matching partition funcaonj~l (a, b)=2k+ak, k=min {i I the i-th bit of aXORb is 
1 }. The key step for evaluating/Y ) is the operation of converting a unary number to a binary number. 
One may suggest building such an instruction into the computer[5]. This scheme leaves the question of 
whether each processor in a parallel computer should have the power of performing a number conversion 
in one step. An alternative is to use a lookup table to convert unary numbers to binary numbers[6,15]. 
This scheme is illustrated below: c:=aXORb; c:=cXOR(c-1); /*Converting the unary number in c to a binary 
number yields k.*/ c:=(c+ 1)/2; k:=T[c]; It is straightforward to compute]~ 2) once the value of k is 
obtained. Note that the table T has only [-logn] entries which are useful. To run our algorithms on the 
EREW model we need p copies of the table, one for each processor. It is impossible to create that many 
copies of T in O(G(n)) time. Therefore, to run Matchl, Match3 and Match4 on the EREW model without building 
the number conversion instructions into the processors we need p copies of T to be set up in the preprocessing 
stage. Because p copies of table T can be created using O(plogn) space and o(on-+ logn) time on the EREW 
model[6,15], Match2 can be executed on the EREW model without any precomputation. To compute.fi2) we 
can use a bit reversal permutation table to reverse the bits of a number so that the most significant 
bit becomes the least significant bit. With the assumption that the conversion from unary to binary can 
be done in O(1) step (either by assuming that such an instruction is built into each processor or by 
applying a table lookup technique), functions log~0n, G(n) and logG(n) can be evaluated. Here, the evaluation 
of function H should be interpreted as finding a number m=O(H). Functions log(0n and G(n) are used in 
Matchl, Match3 and Match4. They can be evaluated as follows: To evaluate logn, let the binary representation 
of n be ak...a2a~, compute n'=ala2...ak, which is the bit reversal permutation of n by using a table 
lookup technique. The following instructions evaluate logn. n':=n'XOR(n'-l); n':=convert(n');/*Converting 
the unary number in n' to a binary number.*/ logn:=k-n'; To evaluate log(0n, we execute this procedure 
i times. Note that this is a sequential procedure. To evaluate G(n) using one processor, we iterate the 
above procedure until the input n being log-ed into a constant, and then count how many iterations has 
been executed. This sequential procedure takes O(G(n) ) time. Function logG(n) is used in Match3. To 
evaluate logG(n) in O(logG(n)) time we use a parallel procedure. We use array N[1..n] and n processors. 
Processor i checks to see whether i is a power of 2. If i is a power of 2, processor i set N[i]:=logi, 
otherwise processor i set N[i]:=nil. Processor 1 sets N[1]:=I. This creates many linked lists in array 
N. We call the one containing NIl] the main list. We can evaluate G(n) by computing the length of the 
main list. This can be done in O(logG(n)) time by using the pointer jumping operation N[O :=N[N[O]. The 
number of executions of the statement N[i]:=N[N[i]] needed to transform the last pointer in the main 
list to point to 1 is an evaluation of logG(n). Therefore both G(n) and logG(n) can be evaluated on the 
EREW model in O(logG(n)) time using n processors. We turn to the computation of fi0(al, a2 ..... al). 
It is now obvious that it can be done in O(/) steps. To satisfy Lemma 5 and Theorem 2 we require that 
it be computed in O(log/) steps if this time complexity is not to be excluded from the time complexity 
of the whole algorithm. A scheme is given in [7] for constructing a table for a matching partition function 
with i arguments. Construct a graph G as in [10] with each vertex of the graph denoted by an i-tuple 
(al, a2 ..... ai), a F {0, 1 ..... n-l}, l_<j_<i. Vertices (al, a2 ..... a/) and (bl, b2 ..... bi) are 
connected by an undirected edge iff a/=b/+l, l<j<i. A valid vertex coloring of G using 21og(i-1)n(l+o(1)) 
colors gives a table for a matching partition function. Such a valid coloring can be found in 0(1) time 
on a CRCW model using exponential number of processors[7]. Because of step 2 of Match3, we can reduce 
the size of the table and the number of processors used for constructing the table. As shown in [7], 
the adjustable parameter k can be adjusted so that the number of processors needed for constructing the 
table is less than n. We now give a scheme to construct the table on the EREW model. To compute ~O(al, 
a2 ..... ai), we use a table containing ~ cells. These cells are labeled with apap+l...ap+q, l_<p_<i, 
~_q_<i-p. Cell ap contains ap. Cell at, ae+l...ap+ q is supposed to containj~l)(ap, at,+l ..... de+q). 
Now we guess these values and place them into cells and then verify them. A processor verifies the value 
of cell a~,at,+l...ap+ ¢ by computing function value.fi2) using the values in cells aeat,+l...ae+q_ 1 
and a~lat,+2...a~q. If the value in cell apap+l...ap+q is equal to the function value the processor writes 
"Yes" into the cell, otherwise it writes "No". The function value we guessed for.fi0(a 1, a2 ..... ai) 
is correct if all the cells contain "Yes". This can be checked in O(log/) time using a binary tree to 
fan in all the cell values. In order not to miss the correct value for fCl)(al, a2 ..... ai), we shall 
enumerate all possible situations. To set up the table we compute the rio value for all possible arguments 
in parallel. This would require exponential number of processors if a/e {0, 1 ..... n}. Again step 2 
of Match3 can be used to reduce the size of the table r Consequently the number of processors needed 
can be reduced to less than n. Note that because there is only one correct guess for riO(a1, a2 ..... 
ai) no concurrent read or write is needed in setting up a copy of the table.  
			