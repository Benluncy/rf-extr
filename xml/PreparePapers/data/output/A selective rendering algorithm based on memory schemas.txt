
 A Selective Rendering Algorithm based on Memory Schemas  Alexandros Zotos Technical University of Crete, 
Greece azotos@ced.tuc.gr Katerina Mania Technical University of Crete, Greece k.mania@ced.tuc.gr Nick 
Mourkoussis University of Sussex, UK n.mourkoussis@sussex.ac.uk  Abstract In order to economize on 
rendering computation, selective rendering guides high level of detail to specific regions of a synthetic 
scene and lower quality to the remaining scene, without compromising the level of information transmitted. 
Scene regions that have been rendered in low and high quality can be combined to form one complete scene. 
We propose a novel selective rendering approach which is task and gaze-independent, simulating cognitive 
creation of spatial hypotheses. Scene objects are rendered in varying quality (polygon count) according 
to how they are associated with the context (schema) of the scene. Methodology Previous selective graphics 
research rendered in high quality the fovea regions based on either eye-gaze or on task focus or utilized 
saliency models. Gaze-dependent rendering encounters problems with updating the multi-resolution display 
after an eye movement without disturbing visual processing. Task focus rendering cannot be used when 
there is no overt task to be conducted and even when there is, we cannot predict exactly where each task-relevant 
saccade will land. Finally, selective rendering based on saliency models has revealed that correlation 
between actual human and artificially presented scan paths was much lower than predicted when carrying 
out real-world tasks. The proposed approach is based on classic findings from memory research (Brewer 
et al. 1981). The basic premise is that an individual s prior experience will influence how one perceives, 
comprehends and remembers new information in a scene. Schemas are knowledge structures or cognitive frameworks 
based on past experience. Schema consistent scene elements are those which are expected to be found in 
a given context, as with books in an academic s office. Experimental studies in synthetic scenes have 
revealed that consistent objects which are expected to be found in a scene can be rendered in lower quality 
without affecting information uptake taking advantage of such expectations, whereas inconsistent items 
which are salient would require a high level of rendering detail in order for them to be perceptually 
acknowledged (Mania et al. 2005). Therefore, by exploiting schema theory, it is possible to reduce computational 
complexity, producing scenes from a cognitive point of view without affecting information uptake and 
resulting in an entirely novel and interdisciplinary approach which is gaze, task and saliency-model 
independent. This poster will discuss the implementation of such a selective rendering system. A demo 
synthetic scene was built which included a kitchen, lounge and office area and comprised of consistent 
and inconsistent objects relevant to each context. The office area included two sub-regions, the desk 
area and the bookcase area. Similarly, the lounge area included a sofa area. The input to the system 
is an X3D document that describes the geometry of the scene. Varying versions of polygon detail were 
produced for all objects in the scene. The system (Figure 1, bottom right) comprises of two main components. 
The initially-activated Selective Renderer Pre-process component is responsible for the modification 
of the X3D input document in order to be enriched with metadata which describe the scene objects in relation 
to the level of their consistency with each scene region (kitchen, lounge-sofa, office-desk-bookcase). 
Metadata information were also defined for each area (Proximity Nodes) representing the scene s regions 
or knowledge schemata. The metadata enrichment process of the X3D document can also be achieved with 
the support of a simple GUI. Varied polygon count versions of the objects of the scene are available 
during the real-time selective renderer process. The second main component of the Selective Renderer 
Module is the Selective Renderer Real Time Process Component. This is responsible for dynamically loading 
a low or high quality version of a scene s object. A high quality version of an object is loaded for 
a specific area s inconsistent objects, whereas, low quality version of consistent objects are displayed 
in that region. For example, when the user approaches a scene s region, the content of that specific 
region will be activated this could be the desk s area (schema) in the office, rather than the office 
s schema. In this way, as above, polygon detail displayed is dependent on each object s association with 
the region in focus. Real-time user interaction triggers changes of each object s metadata information 
based on user focus and object type. Such modification of the metadata field of any X3D descriptions 
provokes changes on the corresponding Switch Node of the object. Switch Nodes contain varied quality 
versions of the object but only one version is rendered at one time since the references of the Switch 
Nodes are able to change. It has to be noted that the Selective Rendering Module accommodates any context 
of a scene, as long as relevant object metadata are described. The system s architecture and validation 
results are going to be discussed during the Poster session. C:\Documents and Settings\alejandro\Desktop\topview.JPG 
 Figure 1: Experimental scene and system architecture BREWER, W.F. and TREYENS, J.C. (1981). Role of 
Schemata in Memory for Places, Cognitive Psychology 13, 207-2. MANIA, K. &#38; ROBINSON, A., BRANDT, 
K. (2005). The Effect of Memory Schemas on Object Recognition in Virtual Environments. Presence Teleoperators 
&#38; Virtual Environments, 14(5), 606-615, MIT. 
			