
 The Complexity of Optimization Problems Mark W. Krentel* Computer Science Cornell University Ithacal 
New York 14853 Abstract We consider optimization problems such as CLIQUE and TRAVELLING SALESPERSON 
and show that their true optimization versions yield a natural class of functions, Which we call OptP, 
with natural complete problems. The motivation for considering problems in this manner is that it gives 
rise to a hierarchy of problems and thus allows us to make finer distinc- tions on their complexity. 
For example, in our frame- work, TRAVELLING SALESPERSON is strictly harder than CLIQUE, and CLIQUE is 
strictly harder than BIN PACKING. We also relate OptP to the class of func- tions computable in polynomial 
time with an oracle for NP by showing that every pSAT function decom- poses into an OptP problem followed 
by a polynomial- time computation  1 Introduction Many important problems in computer science, such 
as CLIQUE, COLORING, and TRAVELLING SALESPER- SON, arise naturally as optimization problems. In- stead 
of considering these problems as decision pro- cedures, we study the complexity of the optimization problem 
itself, and we show that this idea yields a natural class of problems that we call OptP. An OptP function 
is computed by an NP machine that writes a *This work was partially funded by NSF grant BCR 85-03611 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 
1986 ACM 0-89791-193-8/86/0500/0069 $00.75 binary number on each branch and then (magically) outputs 
the maximum (or minimum) of these num- bers. Problems such as computing the size of the maximum clique 
in a graph fit naturally into this scheme: an NP machine can try all possible cliques in a graph and 
print the size of each one. Valiant [Va] used an analogous approach in defining the class #P by considering 
the plus function instead of the max function. In section 2 we show that natural problems such as TRAVELLING 
SALESPERSON, 0-I INTEGER LIN-EAR PROGRAMMING, and MAXIMUM SATISFYING ASSIGNMENT are complete for OptP, 
thus giving a precise characterization of their complexity. We also define subclasses of OptP by putting 
a bound on the number of bits used to express the value of a func- tion. Then we show that MAXIMUM CNF 
SATISFIA- BILITY, CLIQUE, and COLORING are complete for the class of OptP functions whose values can 
be expressed with O(logn) bits. Although the OptP completeness proofs for many of these problems are 
straightforward extensions of their NP completeness proofs, the con- struction for COLORING requires 
stronger techniques and shows that the chromatic number of a graph ac- tually contains more information 
than was previously known. The motivation for considering the optimization version of problems is that 
it allows us to make finer distinctions on their complexity than is possible by considering them only 
as decision procedures. In sec- tion 4, we show that TRAVELLING SALESPERSON is strictly harder than CLIQUE 
in the sense that TSP is complete for OptP and CLIQUE cannot be complete for OptP unless P = NP. A similar 
result in this same framework is that CLIQUE is harder than BIN PACKING. It is not known how to bring 
out these distinctions for languages because the corresponding questions can be relativized. A further 
result, discussed in section 3, is that any 69 function computable in polynomial time with an ora- cle 
for NP can be decomposed into an OptP function followed by a polynomial-time computation. The sig- nificance 
of this result is that the essential difficulty of a pSAT computation lies in evaluating a related OptP 
function; and thus the number of bits needed to express the answer of an OptP function corresponds to 
the number of NP questions needed to determine its value. Furthermore, every OptP complete func- tion 
gives rise to a A~ complete language. An appli- cation of this result is that the inherent complexity 
of UNIQUELY OPTIMAL TRAVELLING SALESPERSON, as considered by Papadimitriou [Pa], really comes from computing 
the length of the shortest tour. The uniqueness serves only to transform the problem to a decision procedure. 
Another and more natural way to make the TRAVELLING SALESPERSON problem com- plete for ~ is to ask the 
question, "Is the length of the optimal tour equivalent to 0 mod k?" It appears that our measure of the 
relative com- plexities of NP-complete problems, namely the num- ber of NP queries needed to determine 
the optimal value, doesn't correlate with other methods. For example, KNAPSACK is complete for n Â°(1) 
queries but is solvable in pseudo polynomial time and hence is not strongly NP-complete [GJb]. On the 
other hand, BIN PACKING is strongly NP-complete but only needs O(loglogn) queries. Our classification 
also doesn't seem to correspond to approximation algorithms and worst-case performance ratios. For example, 
although TRAVELLING SALESPERSON and KNAPSACK are both OptP complete, TSP (without the triangle inequality) 
cannot be approximated to within any constant factor, while KNAPSACK has a fully polynomial-time approximation 
scheme.  Optimization Problems In this section, we give the definitions of optimization problems and 
their corresponding reductions, and we show that several natural problems are complete for certain classes 
of optimization problems. Definition An NP metric Turing Machine, N, is a non-deterministic polynomiaily 
time-bounded Turing machine such that every branch writes a binary num- ber and accepts; and for z E 
E* we write optN(z) for the largest value (for a maximization problem) on any branch of N on input z. 
Definition A function f: E* ~ N is in OptP (op- timization polynomial time) if there is an NP metric 
Turing machine N such that f(z) = opt N(z) for all z E E*. We say that f is in OptP[z(n)] if f E OptP 
and the length of f(z) in binary is bounded by z(Iz]) for all z E E*. OptP is defined analogously to 
Valiant's [Va] class #P (sharp P). The value of a ~P function is defined to be the number of accepting 
paths of an NP ma- chine, or equivalently, the sum of the values over all of the branches. Thus, it is 
natural to consider other associative operators, such as the max function. Al- though OptP is defined 
in terms of the max function, we could equally have used the rain function, and we will consider both 
maximization and minimization problems. Many optimization problems fit naturally into this scheme. For 
example, problems such as finding the size of the maximum clique or the length of the short- est travelling 
salesperson tour in a graph can be com- puted by taking the maximum (or minimum) value over a set of 
feasible solutions that are definable by the branches of an NP machine. The natural notion of reducibility 
between OptP problems is the metric reduction, which is essentially is a many-one reduction from one 
OptP function to another. Note that we need a many-one reduction in order to bring out distinctions such 
as saying that computing the size of the largest clique in a graph is harder than its decision procedure. 
If, for exam- ple, we considered Turing reducibility, then these two problems would be equivalent. And 
lastly, we note that metric reductions are closed under composition. Definition Let f , g: E* --~ N. 
A metric reduction from f to g is a pair of polynomial-time computable functions (Ti,T2) where TI:E* 
~ E* and Tz:E* x N -* N such that for all z E E* we have f(z) = T2(z,g(T~(z))). We are now ready to show, 
for "sufficiently nice" bounds z(n), that OptP[z(n)] has complete functions; in particular, OptP and 
OptP[O(log n)] have natural complete problems. For many problems, we can ob- tain a proof of their OptP 
completeness by a straight- forward extension of their NP completeness construc- tion. This is not true, 
however, for COLORING. Karp's [Ka] reduction for k-COLORING constructs a graph which is k-colorable if 
some boolean formula is satisfiable and (k + 1)-colorable if not. And similarly for the reduction to 
3-COLORING: the graph that is obtained has chromatic number 3 or 4 [GJS,AHU]. Our construction shows 
that the chromatic number of a graph contains much more information than just the answer to a single 
yes/no NP question. We first show that the universal function, UNIV.(.), is complete for OptP[z(n)] by 
a generic reduction. We say that a function z: N ~ N is smooth if z is non- decreasing and if the function 
1" ~ I z(") is com-putable in polynomial time. Lemrna Let z be smooth. Then, any f E OptP[z(n)] is metrically 
reducible to UNIVz. UNIVz(,) instance: N#z#0 k where N is an NP metric Turing machine. output: UNIVz(,) 
simulates N(z) for k moves and outputs the same value; branches that do not halt within k steps have 
value 0. Proof: Let f E OptPlz(n)], let N be an NP metric TM that computes f, and let N run in time p(n) 
for some polynomial p. Then, for z E E*, where Iz[ = n, reduce z to Tl(z) = N#z#(F("). By the definition 
of UNIVz, we have opt N (z) = opt UNIV, (Tx (z)), which gives us a metric reduction from N to UNIVz. 
[] Theorem I The following functions are complete for OptP under metric reductions. WEIGHTED SATISFIABILITY 
instance:CNF boolean formula ~ with (binary) weights on the clauses. output: The maximum weight of any 
assignment, where the weight of an assignment is the sum of the weights on the true clauses.  TRAVELLING 
SALESPERSON instance:Weighted graph G. outpat: The length of the shortest travelling salesperson tour 
in G.  MAXIMUM SATISFYING ASSIGNMENT instance: Boolean formula ~(zi .... , z,). oetpet: The lexicographically 
maximum zs...z, E {0, 1}" that satisfies ~. 0-I INTEGER LINEAR PROGRAMMING instance: Integer matrix A 
and vectors B and U. outpet: The maximum value of CX over all 0-1 vectors X subject tq AX _< B. KNAPSACK 
instance: Integers zt, ..., zn, N. outpat: The largest value, less than N, of ~Es z~ taken over all S 
_C {1 ..... n}. Proof: WEIGHTED SATISFIABILITY. We reduce UNIV,, to WEIGHTED SAT. Forz E E*, let n = 
[z I and define the boolean formula ~z(zt,..., zm, Yl, ..., Y,) to mean "zl .... , zm encode a legal 
computation of some branch of UNIV,(z); and Yi'"Y,~ is the binary representation of the output on this 
branch." Clearly, Pz can be verified in polynomial time; therefore, by Cook's theorem [Co], we can encode 
P= as a CNF formula where m is polynomial in n, the length of z. We now reduce the string z to the cnf 
formula 22n 2n-1 2n-2 Cz = (~z) (Y,) (Y2) ... (y.)'. Clearly, ~z is satisfiable, since any branch of 
UNIVn will give a valid computation; therefore, the optimal assignment to @x must satisfy ~x. This means 
that the maxi- mum number of simultaneously satisfiable clauses in @z must be equal to the optimal value 
of UNIVn on z plus 2 2" times the number of clauses in ~=. That is, opt w" SAT(Or) ---- optUNIV"(z) + 
constx. This gives a metric reduction from UNIVa to WEIGHTED SATISFIABILITY, and hence WEIGHTED SAT 
is complete for OptP. [] Proof:TRAVELLING SALESPERSON. The construc- tion given in [Pal can be modified 
to give a straight- forward reduction from WEIGHTED SAT to TRAVEL- LING SALESPERSON. [] Proof: MAXIMUM 
SATISFYING ASSIGNMENT. The reduction for WEIGHTED SAT also works here. Re-duce z to p~ and order the 
variables Yi, ..., Y,, zl, .., zm. Then, opt UNIV- (z} can be found from the high-order bits of opt MAX 
SAT ASSGN(~z)" 1"3 Proof: 0-1 INTEGER LINEAR PROGRAMMING. We reduce WEIGHTED SAT to 01ILP. Let p be a 
weighted CNF formula with variables zt,..., z,, clauses Ut,..., Urn and weights wt,..., win. Reduce to 
to an instance I of 01ILP with variables zl,..., z,, 1,...,~,, and el,...,cm. For each variable zi, include 
the constraint zi + 5i = 1, and for each clause Cj = (Yl + Y2 -t-Ys), include the constraint Yl -t- Y2 
+ Ys -cy _> 0. Then, a 0-1 solution to this problem represents a legal truth assignment to the variables 
in to, and ej can be set to 1 only if at least one of the literals in clause Cy is set to true. Thus, 
by using clwl +'." +emWm as the objective function, we see that opt w. SAT(9~) = opt 0 IILP (I). Thus, 
0-1 INTEGER LINEAR PROGRAMMING is OptP complete. [] Theorem 2 The following functions are complete for 
OptP[O(log n)] under metric reductions.  MAXIMUM SATISFIABILITY instance: CNF formula io. output: The 
maximum number of simultaneously satisfiable clauses.  CLIQUE instance: Graph G. output: The size of 
the largest clique in G.  COLORING instance: Graph G. output: The chromatic number of G.  LONGEST 
CYCLE instance: Graph G. output: The length of the longest cycle in G.  Proof: MAXIMUM SATISFIABILITY. 
The proof for WEIGHTED SAT can be modified to give a reduction from UN!Vlogn to MAX SAT. We can remove 
the weights by repeating clauses, since the weights for UNIVlogn only need to be polynomially large. 
[] Proof: MAXIMUM CLIQUE. The reduction from SAT to CLIQUE given ill [Ka] or in [AHU] has the property 
that the size of the maximum clique is equal to the maximum number of simultaneously satisfiable clauses. 
[] Proof: COLORING. First we show how to reduce a boolean formula F to a graph Gn such that x(G) = n 
if to E SAT and X(G) = 2n -4 if Â¢~ ~ SAT, and then we use this result to show that MAX SAT is metrically 
reducible to COLORING. In order to make the graph Gn, we need the idea of a multicoloring. A (k,m)-multieoloring 
of a graph G = (V, E) is a function f that assigns to each v e V a set f(v) _C {1,...,m} such that If(v)l 
= k and such that f(u) and f(v) are disjoint whenever (u, v) E E. We write Xk(G), the k.chromatic number 
of G, for the smallest integer m such that G has a (k, m)-multicoloring. Let W be a boolean formula, 
and pick an integer n. By the "True-False-Red" reduction of SAT to 3-COLORING in [GJS] and in [AHU], 
we can make a graph G such that x(G) = 3 if to E SAT and x(G) = 4 if to Â¢~ SAT. Now, define the graph 
Ha = (Vn,En) where Vn = {{i,j,k} l l _< i < i < k _< n} En = {(u,v)]u^v=Â¢}. The key property of these 
graphs, as proved in [GJa] is that xs(Hn) = . and x4(H~) = 2.-4. It is straightforward to verify that 
if x(G) = k and if Xk(H) = m then x(H[GI) = m. So, let Gn --Hn[G] and thus, n if to is satisfiable x(Gn) 
= 2n -4 if to is not satisfiable. Now let ~ be a CNF formula with n clauses. From Cook's theorem, we 
can construct boolean formulas pl, .... ~,,+1 such that Â¢~i is satisfiable if and only if has an assignment 
of its variables that satisfies at least i clauses. By the previous paragraph, we can construct graphs 
Gl,..., Gn+l such that 2n -i if ~/ is satisfiable x(G~) = 4n -2i -4 if Â¢~i is not satisfiable. Define 
G* = Gi +-..+ G~,+i, so that x(G*) = maxi x(Gi), and let k --optSAT(Â¢). Then, ~l,..., ~k are satisfiable 
but Â¢~k+1, ., ~a+l are not, so x(G*) = X(Gk+I) = 4n -2k -0 and hence opt COLORING (G*) = 4n -6 - 2opt 
MAX SAT (~). Thus, COLORING is OptP[O(logn)] complete. [] Proof: LONGEST CYCLE. The reduction from WEIGHTED 
SAT to TRAVELLING SALESPERSON can be modified to give a reduction from MAX SAT to TSP such that the weights 
on the edges are only polyno- mially large. Then, we can remove the weights by repeating edges. [] 3 
Applications to pSAT Compu- tations In this section, we consider functions and languages computable in 
polynomial time with an oracle for SATISFIABILITY, and we show that they are closely related to OptP 
functions. Definition A function f: E* -~ N is in FP SAT if f is computable in polynomial time with an 
oracle for NP. We say that f is in FpSAT[z(n)] if f E FP SAT and f is computable using at most z(n) queries 
on inputs of length n. Definition A language L C_ E* is in pSAT if L is decideable in polynomial time 
with an oracle for NP. We say that L is in pSAT[z(n)] if L E pSAT and L is computable using at most z(n) 
queries on inputs of length n. First weshow that every function in FP SAT decom- poses into-an OptP 
problem followed by a polynomial- time computation, thus: isolating the essential diffi- culty of pSAT 
computations. Since OptP functions are defined by NP machines, the difficulty in the proof is in showing 
that an NP machine with the max func- tion is as powerful as a pSAT machine. An NP ma- chine could guess 
the pSAT computation and could even verify the 'yes' answers, but it has no way of ver- ifying the 'no' 
answers. We get around this difficulty by trying all possible sequences of oracle answers and taking 
the maximum sequence for which all of the 'yes' answers are correct. In this way, the output of the OptP 
function represents the true oracle answers in the pSAT computation. Theorem $ Let z be smooth. Then, 
any f E FpSAT[z(n)] can be written as l(z) = h(z,g(z)) where g E OptP[z(n}] and h:E* x N --~ N is com-putable 
in polynomial time. Proof: Let f e FpSAT[z(n)], and let M com-pute f, where A/r is a pSAT machine making 
z(n) queries on inputs of length n. Except for the an- swers to its queries to SAT, ~If's computation 
is in polynomial time; so, on input Izl = n, and given bl,... ,bz(,) E {0,1}, we can simulate M's computa- 
tion in polynomial time, substituting bt ""bz(n) for the answers to Air's queries. We construct N, an 
NP metric Turing machine as follows. On input I=1 = -, N first computes z(n) and then branches for each 
string in {0,1} z("). On branch bt .-.b=(,), N simulates M and constructs M's queries on this branch, 
say, tol .... , tOz(r,). Then N tries to guess satisfying assignments for each ~o~ such that b~ = I and 
ignores the toi's such that b~ = 0. If N successfully finds a satisfying assignment for each toi where 
b~ -- 1, then N outputs the value bl ... bz(,) as a binary integer on this branch; otherwise N out-puts 
0. Now, we claim that optN(z) represents the true oracle answers for M(z). Write optN(z) as bl...bz(,O 
E {0,1} z('O. First, we show that bt is correct. Let tol be M's first query. If tol E SAT, then N(z) 
on branch 10... 0 will find a satisfying assign- ment; so, optN(z) > 10..-0 and thus bl = 1. On the other 
hand, if tol ~ SAT,then no branch of the form ld2""dz(,O for any d~ E {0, 1} will find a satisfying assignment 
to ~1; therefore, optN(z) _< 01...I and hence bi = 0. In either case, the value of bl is correct. By 
the same argument, we see that b2 is cor-rect, given that bl is correct; and hence, by induc- tion, all 
of the bi's are the correct oracle answers in M's computation on z. And since we can run M(z) in polynomial 
time given opt N (z), we can write f(z) = h(z, opt N (z)) where h is computable in poly- nomial time. 
[] The converse of'theorem 3 is immediate; therefore, we can completely characterize pSAT computations, 
for both functions and languages, in terms of OptP. Theorem 4, Let z be smooth. f E FpSAT[z(n)] if and 
only if/ can be written as f(z) = h(z,g(z)) where g E OptP[z(n)] and h is p-computable. * ,f E FpSAT[z(n 
Â°(') )] if and only if f is metrically reducible to some g E OptP[z(n)]. L E pSAT[z(n)] if and only ill 
can be written as L = {= I P(=, g(=))} where g ~ OptP[z(n)] and P is a p-computable predicate. We can 
apply theorem 3 to relate OptP to other complexity classes. For example, every OptP com-plete function 
gives rise to a A2 p complete language, and every OptP function that is hard for OptP[2] gives rise to 
a D r complete language. Theorem 5 Let f be in OptP. If f is complete for OptP, tben tbere is a p-computable 
predicate P sucb tbat {z ] P(z,/(z))} is complete for A~. If f is bard for OptP[2 l, tben {z#k [ f(z) 
= k} is complete for D p. If f is hard for OptP[1], then {z#k I f(x) > k} is complete for NP. Proof." 
If f is complete for OptP, then P can simu- late a A2 p machine by using the output of f to com- pute 
the machine's oracle answers. [] We conclude this section by giving natural com- plete languages for 
pSATand pSAT[O(logn)]. Pre-viously, the only known example of a complete lan- guage for pSAT was UNIQUELY 
OPTIMAL TRAVEL-LING SALESPERSON [Pal. We suggest that ODD MAXIMUM SATISFYING ASSIGNMENT be considered 
the canonical 2t~ complete language. Theorem 6 The following languages are complete teor pSAT. {p(z, 
..... z.)l z. = I in ~'s max sat assgn} {~#k [ max weight of p is equiv to 0 mod k}  {G#k ] length 
of rain TSP tour in G is equiv to 0 mod k }  Proof: Let L be a pSAT complete language, and let M be 
a pSAT machine accepting L. First, define f(z) = the oracle answers for M(z); then define re(z) = 2f(z) 
+ 1 if M(z) accepts and 2f(z) if M(z) rejects. By computing f as the maximum over all sequences of M's 
oracle answers, we see, by an argument similar to theorem 3, that f is in OptP. Thus, L can be written 
as {z I f(z) is odd}. The other results follow by the reductions given in section 2. I~ Theorem T The 
following languages are complete for pSAT[O(Iog n)].  {~@k [ max number of simul sat clauses in t~ is 
equiv to 0 mod k }  {G#k I size of max clique in G is equiv to 0 mod k }   Separation Results In 
this section, we consider the question of which classes of OptP functions are provably distinct un-der 
the assumption that P ~ NP. Clearly, if P = NP then all OptP functions are computable in polynomial time. 
We would like to say, for example, that since TRAVELLING SALESPERSON is complete for FpSAT[n O(1)] and 
since CLIQUE is in FpSAT[O(logn)l, that TSP is strictly harder than GLIQUE. Unfortunately, there are 
oracles where these problems, considered as decision procedures, are equivalent. In fact, there is an 
oracle for which pSAT collapses to just pSAT[I]. Lemma There is an oracle A such that pA ~ NpA and pSAT,A[i] 
= pSAT,A. Proof: Pick an oracle A such that pA ~ NpA = coNP A [BGS]. Then, NP A = coNP A implies that 
NpA = pSAT,A and hence pSAT'A[J] = pSAT,A. [] Thus, it is unlikely that current techniques are strong 
enough to answer this question for languages. On the other hand, the corresponding question for the optimization 
versions of the same problems can be resolved. We can show directly that P ~ NP im- plies that n queries 
are strictly more powerful than O(logn) queries. This result shows that there can be no metric reduction 
from TSP to CLIQUE, and hence TSP is strictly harder than CLIQUE. Theorem S FpSAT[O(Iogn)] = FpSAT[n 
Â°(1)] =~. P=NP. Proof: Assume FpSAT[O(Iogn)] = FpSAT[nÂ°(')]. Then we show that P = NP by showing how 
to recog- nize SATISFIABILITY in polynomial time. Define the function f as: for a boolean formula ~(zl 
.... , z,), let f(~) = the lexicographically maximum string in {0, 1}" that satisfies ~, if p E SAT; 
otherwise 0, if ~ SAT. Then, f E OptP; so, by assumption, there is a pSAT machine, .M, that computes 
f and makes at most O(log n) queries. Then, to determine if p E SAT, simulate M(p) for all possible oracle 
an- swers. This gives a polynomial number of possible assignments, at least one of which must be a satisfy- 
ing assignment if p E SAT. El We can also prove a more general separation result: FpSAT[f(n)] is properly 
contained in FpSAT[g(n)] whenever f(n) < g(n) and f(n) < ~logn. We can use this result to show that CLIQUE 
is harder than BIN PACKING. Karmarkar and Karp [KK] showed that BIN PACKING can be approximated in polynomial 
time within an additive constant of O(log 2 n). The exact optimal number of bins can then be found with 
only O(loglogn) queries to SAT, and so BIN PACK- ING+is in FpSAT[O(loglogn)]. CLIQUE, on the other hand, 
is complete for FpSAT[O(Iogn)]. Theorem 9 Let f and g be smooth where f(n) < g(n) and f(n) _< ~logn. 
Then, FpSAT[f(n)] = FpSATIg(n)] =, P = NP. Pro ol: Assume f and g are as above and that FpSAT[f(n)] = 
FpSAT[g(n)]. We show how to rec-ognize SATISFIABILITY in polynomial time. Define the OptP[g(n)] function 
h(~(zl, .... z,)) = the lex. max zi ... zg(,~) that can be extended to a satisfying assignment. By hypothesis, 
h E FpSAT[f(n)], so let M be a pSAT machine that computes h with only f(n) oracle queries. To test for 
satisfiability, let ~(zt,...,zn) be a boolean formula of length n. Simulate M(~) for all possible oracle 
answers; we can do this because f(n) < logn. Then, we can write zl,...,za(n) as a function of Yx,..., 
Y f(,), the oracle answers for M(~). Express this relation, T(zl,..., za(n ), Yl, .. . , YI(,) ), as 
a truth table of size < g(n) . 2 f(") logn _< n. Rewrite ~ as 7~~ = ~ ^ T with the variables in the 
order Yi,.  ,Yf(,), zg(,~)+l,..., zn, zl,..., za(,~ ), and say that Yl,..., Yy(n) are independent and 
that zl,..., za(,, ) are dependent. Then, ~ is satisfiable if and only if ~' is satisfiable. And since 
f(n) < g(n), we have eliminated at least one independent variable in ~ by increasing the length of ~ 
by an additive amount of at most n. We can repeat this process with input ~' to make a formula ~" of 
length 3n, and so on. Since we always eliminate at least one independent variable, we never need more 
than n iterations to remove all but f(n) of the independent variables. Then, we can try all possible 
values for the remaining f(n) independent variables. Since the formula never grows beyond size n 2, we 
can solve SAT in polynomial time. []  Discussion In this paper, we considered the optimization version 
of problems, and we showed that this idea forms a natural class of functions with complete problems. 
We then showed that OptP functions captured the essential difficulty of pSAT computations, and lastly, 
we considered the question of which classes of OptP functions were provably harder than other classes. 
This work gives rise to several new open problems. First, are there other associative operators besides 
the max and plus functions that define interesting classes of problems when applied to the branchs of 
an NP machine? Considering the exclusive or oper- ator, for example, PARITY SAT, the set of boolean formulas 
with an even number of satisfying assign- ments, is the canonical complete problem. Valiant and Vazirani 
[VV] show that PARITY SAT is hard for both NP and coNP under randomized reductions, and they ask where 
in the polynomial-time hierarchy it lies. Also, we could define a hierarchy of functions based on alternating 
max and min functions (or other functions), for which OptP is the base case. Are there natural problems 
complete in such a hierarchy? Another problem is improving the separation re-suits in section 4. Theorem 
9 breaks down for/(n) > log n due to reasons of Kolmogorov complexity. Is it true that P # NP implies 
that FpSATIf(n)] is prop- erly contained in FpSAT[g(n)] whenever ,f(n) < g(n), or are there oracles for 
which FpSAT[O(Iog s n)] = FpSAT[n], for example? One more direction to pursue is determining the precise 
complexity of BIN PACKING. We know that BIN PACKING is in FpSAT[O(Iog log n)] and is hard for FpSAT[I]. 
The precise complexity of BIN PACKING, however, is not known. And finally, we would like to see other 
functions z(n) besides n and log n for which FpSAT[z(n)] has complete problems: BIN PACKING is a possibility. 
 Acknowledgements We would like to thank Neil Immerman for his sugges- tions for further work, David 
Shmoys for many help- ful discussions, and especially Vijay Vazirani for his continued support and encouragement. 
This paper was typeset using the IbTEX document preparation system.  References [AHU]Aho, A., J. Hopcroft, 
and J. Ullman, The Design and Analysis of Computer Al-gorithms, Addison-Wesley, Reading, Mas-sachusetts, 
1974. [BGSI Baker, T., J. Gill, and R. Solovay, "Relativiza- tions of the P =? NP Question," SIAM J. 
Comput. 4, pp. 431-442, 1975. [Col Cook, S., "The Complexity of Theorem-Proving Procedures," Proc. Srd 
Ann. ACM Syrup. on Theory of Computing, pp. 151-158, 1971. [GJal Garey, M., and D. Johnson, "The Complexity 
of Near-Optimal Graph Coloring," JA CM 23, pp. 43-49, 1976. [GJb] Garey, M., and D. Johnson, Computers 
and Intractability: A Guide to the Theory o/ NP- Completeness, W. H. Freeman and Company, San Francisco, 
1979. [GJSl Garey, M., D. Johnson, and L. Stockmeyer, "Some Simplified NP Complete Graph Prob- lems," 
Theoretical Computer Science 8, pp. 237-267, 1976. [Jol Johnson, D., "The NP-completeness Column: An 
Ongoing Guide," J. of Algorithms, June 1985. [Ka] Karp, R., "Reducibility Among Combinato- rial Problems," 
in Complezity of Computer Computations, R. Miller and J. Thatcher, eds., Plenum Press, New York, pp. 
85-103, 1972. [KKI Karmarkar, N., and R. Karp, "An Effi-cient Approximation Scheme for the One-Dimensional 
Bin-Packing Problem," Proc. ~Srd Ann. IEEE Syrup. on Foundations of Computer Science, pp. 312-320, 1982. 
Papadimitriou, C. "On the Complexity of Unique Solutions," Proe. ~3rd Ann. IEEE Syrup. on Foundations 
of Computer Science, pp. 14-20, 1982. [Va] Valiant, L., "The Complexity of Computing the Permanent," 
Theoretical Computer Sci- ence 8, pp. 189-201, 1979. lvv] Valiant, L., and V. V. Vazirani, "NP is as 
Easy as Detecting Unique Solutions," Proc. 17th Ann. ACM Symp. of Theory of Compet- ing, 1985.  
			