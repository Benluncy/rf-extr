
 Retrieval of Complex Objects Using a Four-Valued Logic Thomas Rolleke, Norbert Fuhr [roelleke,fuhr] 
@ls6.informatik. uni-dortmund.de University of Dortmund, Germany Abstract The aggregated structure of 
documents plays a key role in full-text, multimedia, and network Information Retrieval (IR). Considering 
aggregation provides new querying fa­cilities and improves retrieval effectiveness. We present a knowledge 
representation for IR purposes which pays spe­cial attention to this aggregated structure of objects. 
In ad­dition, further features of objects can be described. Thus, the structure of full-text documents, 
the heterogeneity and the spatial and temporal relationships of objects typical for multimedia IR, and 
meta information for network IR are representable within one integrated framework. The model we propose 
allows for querying on the con­tent of documents (objects) as well as on other features. The query result 
may contain objects having different types. Instead of retrieving only whole documents, the retrieval 
process determines the least aggregated entities that imply the query. 1 Motivation and Background New 
IR applications like full-text, multimedia, and net­work IR require a more sophisticated knowledge repres­entation 
than the pure set of terms used in classical IR. What should the properties of a more sophisticated data 
model be? We need an integrated framework which allows a uni­fied view of text documents, multimedia 
documents, and databases by considering all of them as retrievable ob­jects which have some aggregated 
structure and some local knowledge about other objects. Classical IR only considers documents as atomic 
units, i. e. some kind of a black box. This black box thinking is very useful regarding the representation 
of the content, because this content representation should be abstract, i. e. Permission to make digital/hard 
copy of all part of this work for per­sonal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage, the copy­right notice, the title of the 
publication aad its date appear, and notice is given that copying is by permission of ACM, Inc. To copy 
otherwi­se, to republish, to post on servers or to redistribute to lists, requires prior specific permission 
and/or fee. SIGIR96, Zurich, Switzerland@ 1996 ACM 0-89791-792­8/96/08.$3.50 independent of the actual 
media. The model we present provides a unified content view plus the possibility to express other (factual) 
knowledge, i. e. features of objects. In addition, we also represent and exploit the aggregated structure 
of the documents. Thus, we get new query facilities: Querying for documents and facts can be combined. 
And, instead of retrieving only a reference to the whole document, the least aggregated entity that implies 
the query is identified. Due to the finer granularity of the retrieval result connected with the power­ 
ful querying language, we reduce the costs of obtaining the requested information and information retrieval 
becomes more effective. Modelling the structure: In our approach each object can have an aggregated 
structure. Full-text docu­ments may be structured in chapters, sections, and paragraphs. Multimedia documents 
comprise differ­ent objects with varying media types. In network IR several databases form a knowledge 
base and each database knows the local documents and possib!y again other knowlege bases. [Brown 89] 
pointed out that maintaining the under­lying logical structure of a document can have many advantages 
for document processing , since the ideas of the author are reflected by the structure and the system 
can provide intelligent help for navigating. Standards like ODA and SGML are widely used and so IR can 
take advantage of the structured inform­ation available. [Fuhr 95a] motivates the differenti­ation between 
the content structure and the logical structure for making IR more effective. [Macleod 90], [Colby et 
al. 94], and [Christophides et al. 94] propose retrieval models which take into account the structure 
of documents. The latter presents the inter­esting new facility of querying for paths leading to the 
relevant part of a document. Modelling features: Besides modelling the structure, we need a means for 
representing knowledge about ob­jects. Since we want to deal with objects of differ­ent types (e. g. 
documents, databases), we have to model propositions about classification for grouping the objects. In 
addition, we need a means to model relationships between objects (e. g. authorship of doc­uments). [Pfeifer 
et al. 95] demonstrates how classical content retrieval can be combined with searching for docu­ment 
features. [Fuhr &#38; Rolleke 96] and [Fuhr 95b] present approaches to integrate such factual know­ledge 
into a data model appropriate for indexing a collection. [Meghini 95] underlines the need of mod­elling 
relationships between objects for multimedia IR by distinguishing between the syntactical and the semantical 
level. (For example, the representation of a picture showing Giulia playing with Francesco re­quires 
modelling the semantical relationship between persons.) Classification and generalization are intro­duced 
as appropriate methods for modelling the se­mantical relations of objects. [Fuhr 96] also stresses the 
usage of object-oriented concepts for improving IR systems. From generalization (inheritance, re­ spectively), 
we gain a unified view onto retrievable objects which is especially important in network IR. Concluding, 
a sophisticated knowledge representation should incorporate the principles of object-oriented design, 
namely aggregation, classification, and generalization. Following [Rijsbergen 86], we want the retrieval 
process to be expressed as proving the inference d + q between a document d and a query g. Therefore, 
we combine logical means and object-oriented modelling in our data model similar to [Kifer et al. 95]. 
In the following, we first introduce the concepts (sec­tions 2, 3, 4) and the semantics (section 5) of 
the data model. For defining the semantics, we use Kripke struc­tures as described in [Halpern &#38; 
Moses 92] and we add a four-valued truth assignment. Section 6 presents the consideration of the intrinsic 
uncertainty of knowledge for achieving a ranking of the retrieved objects. Section 7 sketches the application 
of the model for multimedia and network retrieval.  2 Basic Components of the Data ModeI Classical IR 
systems use a set of terms for representing the knowledge necessary for retrieving the documents which 
imply a query. This pure set of terms is a one-dimensional knowledge representation: it only aims at 
modelling the knowledge about the content of the documents. The ad­vantages of the model are its simplicity, 
the possibility to add term weighting for getting a relevance measure, and its efficient processing when 
retrieving documents. The model we propose aims at having the same advant­ages. In addition it allows 
for modelling knowledge more complex in structure. As argued in section 1, we have to represent the aggregated 
structure and features of objects. Figure 1 depicts the basic components of the data model. Aggregation: 
The first clause expresses the aggregation relation. The document dl consists of two words (hel 10, world) 
and it has two subsections (s11, Figure 1: Basic components of the data model. % Aggregation dl [hello, 
world, s11 [sailing] , s12 [boats] ] % Classification book ( dl ) % Attribute value dl . author (peter) 
% Generalization document (X) :­ book (X) X. Cousin(Y) :- X.parent(PX) , Y. parent ( PY) , PX. sibling 
(pY) s 12) which also consist of words. This aggregation expression reflects the logical structure of 
objects. In the case of full-text documents, the aggregation clause corresponds to a nested set of terms. 
Classification: Classification provides the necessary pos­sibility for representing the features of objects. 
Ob­jects are grouped into a classification structure and they have relationships with other objects. 
The second clause states that document (object) dl is an instance of the class book. The third clause 
indicates a relation between object dl and object peter. This attribute value assign­ment can be interpreted 
as a classification, i. e. pet er is a member of class dl. author. Generalization: Rules enable to formulate 
generaliza­tions of classes. Reading the first rule: If X is known to be a book, then it is a document. 
By rules, we add the expressive power of predicate logic for maintain­ing the knowledge. A set of aggregation, 
classification, and generalization clauses is called a program. The most important aspect of our model 
is the possibil­ity to arrange programs local to a certain context. These contexts correspond to the 
aggregation structure of the ob­jects. Similar to [Rijsbergen 89], where each document represents a possible 
world, in our approach each context assigns truth values to propositions, independent of the truth value 
assignments of other contexts. Figure 2 shows a program local to document (context) dl. The proposi­tions 
hello, writer (peter ) , etc. hold within context dl. In IR, we search for documents (contexts) where 
a dl [ % Program within context dl hello, world, writer (peter) , peter. friend (paul) , peter. fri-end(mary) 
1 Figure 2: A program local to a context, query formula is true. Usually, this query formula only contains 
simple predicates of arity zero, e. g. he 110. In our approach, we can also refer to the features of 
objects which are known within the context and thus we can pose semantically richer queries. The locality 
provides the basis for regarding documents (contexts, respectively) as consistent sets of propositions. 
Section 3 shows how the knowledge of documents can be retrieved within the global context (i. e. on the 
level of the database), since the global context learns the knowledge of its components. At the end of 
this section, we want to point out the semantical difference between content knowledge like dl [writer 
( pet er ) ] and factual knowledge like dl . author ( pet er ) : The first clause represents that document 
dl has the knowledge that peter is a writ er. This knowledge is local to context dl. Syntactically, this 
locality is indicated by brackets. The second proposition holds in the global context (also referred 
to as this­context) and shows the authorship relation between dl and pet er which is independent of the 
knowledge of dl. We use the common notation of object-oriented lan­guages separating object identifier 
(all) and attribute name (author) by a dot. In the notation of predicate logic, these attributes could 
be considered as binary predicates, e. g. author (dl, peter) . 3 Querying Facilities Retrieving Aggregated 
Entities What do we gain from the introduced data model regarding IR purposes? In this section, we concentrate 
on exploiting the aggregation structure for making IR more effective and we present the integrated querying 
for documents and facts. In section 7, we demonstrate the application of the model for full-text, multimedia, 
and network IR. In section 2, we have shown how to express the indexing knowledge. Having the knowledge, 
what can we query for and what should the result look like? A query can refer to the aggregated structure 
to draw conclusions about the semantical content of objects. This type of queries corresponds to the 
aboutness queries in IR. In addition, a query can refer to the features of objects, e. g. asking for 
all authors of a document. The set of retrieved objects can be restricted by classification. Further, 
we want to allow logical conjunction and disjunction for combining various subqueries. The query result 
should make the underlying aggreg­ated structure transparent in order to provide intelligent help while 
browsing. And, by taking into account the ag­ gregated structure, the query process also can determine 
the least aggregated entity that implies the query. These aggregated entities are constmcted by combining 
entities (contexts), as demonstrated in Figure 3. A query is in­dicated by ?-followed by a formula possibly 
containing variables which differ syntactically from constants in that dl . author (peter) dl [sailing, 
boats, sailor (peter) ] d2 [s21 [sailing] , s22 [boats] , s23 [sea] ] d3 [s31 [peter, paul, mary] ] 
? X [ sailing] % Content query dl d2 nS21 ?-X [sailing, boats] % Combination of % ~Onte~~ dl d2 n (s21 
u S22) ? X [sailing, mary] dl U (d3 ns31) (d2 fl s21) u (d3 rl s31) % Document and fact retrieval ? 
X [sailing] , X. author (peter) dl ? sailln< % Augmentation T % TRUE ? sailor x) peter Figure 3: Query 
facilities: they are capitalized. The query result yields the variab!c instantiations which make the 
formula true. We use the %-ch~acter for indicating a comment. Within our model, we have the following 
query facilit­ies: Content query: The first query asks for all objects where the proposition sai 1 ing 
is true. This type of aboutness query is identical to querying for all ob­jects which contain an entity 
sai 1 ing. The query result is a set of paths leading to the least entities that fulfill the query. These 
paths reduce the costs for obtaining the requested information, since the result list has a finer granularity 
than just a set of document references. Combination of contexts: In IR, often a single document on its 
own may not fulfill the query. Considering the aggregated structure of objects, single components will 
hardly ever satisfy the query completely. For this reason, we introduce the possibility of combining 
contexts in order to form an object that implies the whole query. The results of the second and third 
query demonstrate this concept. dl is an answer to the first query. In d2 the union s21 U s22 of sections 
fulfills the query. There is no entity that fulfills the query for [ sai 1 ing, mary] , but the union 
of several en­tities make the query formula true. These combined contexts of the answer set form an aggregated 
entity which can be represented as a directed graph. The whole answer can be delivered as a hierarchical 
hy­pertext object and eases the handling for the user. Combining document and fact retrieval: In document 
retrieval, one searches for contexts which make the query true, These contexts may contradict each other. 
On the other hand, fact retrieval in databases refers to the (consistent) knowledge of only one context, 
i, e. the global context. In the fourth query, we combine a document query with a factual query. The 
document query (X [ sai 1 ing ] ) refers to the local knowledge of a context and the factual query (X. 
author (peter ) ) addresses the knowledge of the global context. The query result contains the instantiations 
of the variable X, i.e. the objects (contexts) which make the whole query formula true. Augmentation: 
So far, all knowledge is local to a certain context. However, in some applications, we also want to be 
able to pose queries referring to the local knowledge of the subcontexts directly, For example, in network 
IR, we would like to know the topics covered by a database, i. e. the topics occuring in the documents 
of the database. For this purpose, we introduce augmentation. This concept exports the knowledge of subcomponents 
into the enclosing context. Thus, the enclosing context learns the knowledge of its subcontexts and we 
can pose queries on this knowledge. The last two queries show the possibility of querying the knowledge 
augmented from the documents. The predicate sai 1 ing is true in the global context, since the subcontext 
dl knows it to be true. By means of the classification predicates, we also can query on more complex 
knowledge. Since the this-context knows document dl which knows that peter is a s ai 1 or, this knowledge 
is available and retrievable in the enclosing context. Summing up, from taking into account the aggregation 
structure as demonstrated and providing a classification means, we gain: 1. Retrieval on documents of 
different types is feasible, e. g. a collection of articles and a collection of books can be handled 
within the same framework. (For example, let dl be an article, and let d2 be a col­lection of articles 
s21, s22, etc. The query process would find d2 as well as s 2 1.) This already in­dicates the multimedia 
and networking facilities of the model, since multimedia objects typically differ in their aggregation 
structure and for network IR a database could be considered as an object containing other objects, and 
so on (see section 7). 2. The retrieval result contains the least aggregated en­tities which imply the 
query. It could be presented as a hypertext object and thus ease browsing. IR becomes more effective. 
Since the retrieval process combines entities (con­texts), the finer granularity does not lead to empty 
query results in the case of conjunctive subqueries. The result can only be empty if none of the predicates 
are satisfiable for any entity. 3. Querying for documents and facts can be combined. 4. Classification 
and generalization (rules) are powerful concepts for describing content and querying in a more sophisticated 
way. 5. Querying the knowledge of sets of documents be­comes possible by augmenting the knowledge. This 
concept provides the nice possibility of using the knowledge of the documents itself instead of only 
indexing the knowledge about documents. The en­closing object (the database) learns from its com­ponents 
(the documents).  4 Negation In this section, we outline the handling of negation within our model, 
Most classical IR models use a a closed-world assumption (CWA) for the indexing terms, i. e. if a term 
is not assigned, then the document is assumed to be not about the corresponding subject. We are convinced 
that the use­fulness of negation in IR is strongly connected with making different assumptions for different 
predicates. Modelling an authorship relation, we would assume that we know all authors of a paper and 
thus a CWA for this class (predicate) is reasonable. On the other hand, we would not want to assume that 
we know all friends of a person and thus we want to make an open-world assumption (OWA) for this relationship 
between objects. Reconsider the example from above and a query for documents which are not about sai 
1 ing: ? X[7sailing] d2 nS22 d2 ns23 d3ns31%=d3 Like in Boolean retrieval, we use a CWA for the predic­ate 
sai 1 ing. This leads to the depicted result. d3 on its own is not an element of the answer set, since 
there is the smaller entity d3 n s31 that fulfills the query. The same holds for d2, but in addition 
d2 [ sai 1 ing ] is true, because of the knowledge augmentation, i. e. there exists an entity where sai 
1 ing is true. Making an OWA, we would have no evidence whether 7s a i 1 ing is true in any context (entity). 
Note that in this case only those entities would be in the answer set where 1s ai 1 ing is explicitly 
mentioned. In the following, we use an OWA for peter. friend and a CWA for dl. author. Making an OWA 
requires a third truth value: unknown (U). In contrast to a CWA, where the truth value of a formula is 
taken to be false, if it is not explicitly defined to be true in a given program, an OWA uses the truth 
value unknown for a formula when no explicit truth value assignment is given. Consider the following 
example: peter. friend (paul) dl . author (peter) ? peter. fri. end(paul) T % TRUE ? ~peter. friend 
(paul) F % FALSE ? peter. friend (mary) U % UNKNO~ ? ~peter. friend (mary) u ? dl. author (mary) F 
 The first query yields true, since the proposition is in the database. Thus, the negation is known to 
be false. But the queries involving mary yield unknown, since noth­ing about this proposition is to be 
found in the database. Using a CWA, from the database we would have drawn the conclusion that dl . author 
(mary) is false and thus ~dl . author (mary) is true. Knowledge augmentation and combining contexts may 
lead to inconsistencies. A proposition may be known to be true in one context whereas the other context 
knows the same proposition to be false. For coping with this situ­ation, we introduce the fourth truth 
value inconsistent (I), reflecting that we have evidence for both true and false. In the following example, 
we have two contexts dl and d2 and each context is consistent on its own. dl [Tpeter . friencl(mary) 
] d2 [peter. friend (mary) ] ? peter. friend (marY) I % INCONSISTENT In the global context, we have evidence 
that peter . friend (mary ) is both true and false. In this case, the retrieval process yields inconsistent 
as truth value. In case of a CWA for a predicate all facts are taken to be false that are not mentioned 
explicitly to be true. Thus a fact of this predicate can only be true (false) in a union of contexts 
with a CWA if it is known to be true (false) in all elements of the union. Concerning augmentation, a 
fact in the enclosing context is true (false) if it is true (false) in all subcontexts having a CWA. 
This way, we can direct augmentation and context com­bination. For example, we could use a CWA on the 
doc­ument level and an OWA on the section level. A union of sections would make a formula true if it 
is true in one section. A union of documents would make a formula true only if it is true in all documents. 
 5 Semantics For defining the semantics of the described knowledge representation, we use Kripke structures 
as introduced in [Halpern &#38; Moses 92], but choose a three-valued truth assignment. Let O be a set 
containing propositions like sailing, sailor (peter) , dl. author (peter) . A Kripke structure is a tuple 
ill = (S, n, KI, .... Km), where S is a set of possible worlds (states), T is a family of truth value 
assignments on the propositions p G O for each worlds E S (n(s) : 0 + {T, F, U}), and each K, is a binary 
relation over the worlds for an agent K,. These relations are called accessibility relations. The function 
K,(s) := K,,, := {tl(s, t) c K,} assigns the set of worlds which agent K, can reach from the world s. 
Beside being a standard for describing the meaning of a logical program, this model-oriented approach 
has the following advantages: The accessibility relations connec­ted with the world-dependent truth assignments 
consider the context-dependency of knowledge. By defining ax­ioms on the Kripke structure, specific properties 
of the knowledge can be defined. Extending the Kripke struc­ture with a probability assignment provides 
the means for coping with uncertain knowledge as described in [Fagin &#38; Halpern 94]. In our model 
the objects (documents) correspond to the agents. Depending on the current world an object knows a set 
of worlds. Consider the following example: dl [sailing, sailor (peter) ] d2 [s21 [boats] ] dl . author 
(paul ) Figure 4 depicts the structure of the knowledge rep­resented by the given progam with the correspond­ing 
world dependent truth assignment. We have four worlds {sO, SI, SZ, S3 } and three agents dl, d2, and 
s 21 with the corresponding accessibility relations {(so, sl)}, {(sO, s2)}, {(s2, s3)}. Since in this 
sample case each agent knows exactly one truth value for a pro­position, the sets K,,. of accessible 
worlds contain ex­actly one world and we may also use an agent s name for referring to a world. The so-called 
this-agent corres­ponds to world so. The set + of propositions is given by {all, d2, sailing, sailor 
(peter), s21, boats, dl I sailing, sailor(peter) I I 1 dl .author(paul) m(s) (p) s (K, ) so (this) S1 
(all) S2 (d2) S3 (s21) P dl T u u u d2 T u u u sailing u T u u sailor(peter) u T u u 521 u u T u boats 
u u u T dl.author(paul) T u u u Figure 4: Worlds, accessibility, and truth values. dl.author(paul )}. 
 For a Kripke structure A4 and a world s, an interpret­ations afunction.f(~,s) : L* + {T, F, U, I} which 
as­signs a truth value to every closed formula of the language L. (L* denotes the set of closed formulas 
of L.) Fig­ure 5 outlines the grammar of the language. A program program ::= {proposition I rule}* proposition 
::= entity I classification .._ entity ..-obj-id I obj-id [ proposition ] classification ::= glob-class 
I attr-val glob-class ::= pred-name ( obj-id ) attr-val ::= obj-id.pred-name ( obj-id ) ..­ rule ..-rule-head 
:- rule-body rule-head ::= classification. rule-body ::= subgoal-conjunction subgoal ::= proposition,, 
Figure 5: Outline of the grammar of the language. is a set of propositions and rules. A proposition 
is an entity or classification for describing the aggregation and knowledge of the current object. An 
entity itself again may have an aggregated structure and classification know­ledge. A classification 
could be a global classification (e. g. sailor (peter)) or an attribute value assignment (e. g. dl . 
author (paul ) ). Within rules variable names may be used in place of object identifiers (indicated by 
the subscript v). We restrict the formal definition of the se­mantics to the truth values of closed formulas, 
assuming a variable valuation for instantiating the rules.  For defining the interpretation function, 
we consider the truth values {U, T, F, I} to be the powersets of {true, false}, thus obtaining {{}, {true}, 
{false}, {true, false}} accordingly. Figure 6 shows some of the constraints for defining the interpretation 
function. Let p be a basic entity (without further structuring, e.g. sai 1 ing) or a classific­ation. 
The truth value of the interpretation contains true true ~ l(M,,) (p) -+== true E 7r(s)(p) false E ~(hf,.) 
(P) +== false E 7r(s)(p) Figure 6: Constraints for the interpretation function, (false), if the initial 
truth assignment of the Ktipke struc­ture contains true (false). Remember that the interpreta­tion may 
yield inconsistent for an atomic proposition ac­cording to context combining and augmentation. The third 
and fourth constraint define the truth value of a formula like dl [ sailor (peter) 1. It contains true 
(false), if for all worlds t which agent K, (all) can reach from the current world s the interpretation 
of p (sailor (peter) ) con­tains true (false). The interpretation of a negated formula contains true 
(false), if the truth value of the non-negated formula contains false (true). Figure 7 depicts the truth 
values for conjunctions, rules, and negation. In [Rolleke &#38; Fuhr 96], we give the com- Conjunction 
I(M,.)(+) TIUIF II ~( vr,s)(%?J) m Rule ~(M,s)(P :-P) ~(A4,s)(P) TIUIFII m Negation Figure 7: Truth 
values. plete set of constraints according to this truth value assign­ ment and we show that this definition 
of truth values has some desirable properties of two-valued logic. Now we add the constraints for the 
augmentation 211 concept. Let K be the set union over all accessibility relations and let v be a closed 
formula. true E 10W,.I (v) e 3t((s, t) c KA true ~ ~(M,tJ(9)) false G l(M,,) (P) -+== 3~((s, ~) E ~A 
false c ~(A4,tJ (w)) If there is one world twhere the interpretation of a for­mula P contains true (false), 
then the interpretation of this formula in the current world s contains true (false). The truth value 
of a predicate depends on its truth value in the entities that form the current object. According to 
this augmentation rule, the formula dl [ sai 1 ing 1 is true, if sai 1 ing is true in some section of 
dl. According to the given definition for an interpretation, we get the following truth values for the 
formulas of the example: I(M,s) (P) D dl T u u u d2 T u u u sailing T T u u sailor(peter) T T u u S21 
T u T u boats T u T T dl .author(paul) T u u u  The proposition sai 1 ing is true in the thi s-context, 
since it is true in dl. And so forth. For demonstrating the use of the truth value incon­sistent, imagine 
we would have further evidence for d2 [ ~sai 1 ing ] . In this case we would have the fol­ lowing truth 
value assignment in the Kripke structure with the corresponding interpretation function: s n(s) (--mailing) 
I(M,~) (msailing) this I U II ~ The initial truth assignment in the this-world is un­known, and the 
interpretation yields inconsistent according to augmenting inconsistent knowledge from dl and d2. In 
the following, we investigate the combination of the knowledge of objects. We allow an agent to be constructed 
out of other agents according to the following rules: The interpretation of a formula within the union 
of two contexts contains true (false), if one of its contexts con­tains true (false). The intersection 
of contexts represents a path to a context where the formula is true. The union of contexts is commutative, 
whereas intersection of contexts is not commutative. The retrieval process yields for a closed formula 
the truth value and it determines for an open formula all closed formulas with the truth value T. It 
determines the set of (combined) contexts where the query condition holds. Only the least contexts are 
included in the result set, since they imply the enclosing context which is indicated by the path to 
follow. In case a context on its own does not fulfill a query, a union with another context might fulfill 
the query (see example in figure 3). The next table depicts the truth values of some formulas in combined 
contexts Ki: ~(M>s)(Kzbl) this m The propositions sai 1 i.ng, boats are true in the com­bined context 
{dl U d2}, since sai 1 ing is true in context dl and boats is true in context d2. In the intersection 
{d2 n s21 } the formulas have the truth values of context S21. Given this formalization of the semantics, 
we are able to add a world and proposition dependent CWA. ~(~,s) (v) = U * ~(iw,s) (1P) = T We can use 
this rule for closing on a cer­tain predicate (class) in a certain context, e. g. this [ CWA ( document 
) ] expresses that the CWA is assumed for the predicate (class) document within the this-context. 6 
Adding Uncertainty Of course, a state-of-the-art IR system should provide a ranking of the retrieved 
objects to increase retrieval effect­iveness. One reason for the success of the set of terms approach 
is certainly to be found in its straight forward extension with term weights which leads to a ranking 
func­tion. Assuming a probabilistic interpretation of the rank­ing function, the retrieval process tries 
to determine the probability of relevance given a query and a document (P(R[q, d)). This probability 
is supposed to be a func­tion of the probability that the implication d + q holds (P(ll[q, d) N f(p(d 
+ q))). We have based the semantics of our data model on a four­valued interpretation. Keeping in mind 
the underlying OWA, we could assign probabilities for the truth values true or false which do not necessarily 
sum up to one. The overlap of the probabilities reflects the inconsistency, the gap between them mirrors 
the degree of unknown. The aim of future work will be to investigate the application of probability theory 
and Dempster-Shafer theory for coping with these uncertainty values. As an example, here we demonstrate 
the modelling of the probabilistic interpretation of the vector space model, where P(d + q) = ~t(P(tld) 
.P(qlt)) holds (see [Wong &#38; Yao 95]). We consider two (disjoint) documents dl and d2 and process 
some queries: 0.5 dl[O.9 sailing, 0.1 peter, 0.8 sailor (peter) ] 0.5 d2 [0.5 sailing, 0.5 boats] ? X 
[sailing]  0.9 dl 0.5 d2 1.0 r(X) :-X[sailing]  0.6 r(X) :-X[boats] ?-r(x) 0.9 dl 0.8 d2 ? sailor 
(peter) 0.4 T The factor 0.5 in front of the document context reflects the portion of the current context 
that a document covers, i. e. in this case every document has the same import­ance for the collection. 
Analogously, the weights in front of the terms indicate the portions of the documents. We interpret these 
weights as conditional probabilities. For example, the weight 0.9 could be interpreted as the probab­ility 
P(tld) = P(sailingldl) = P(dl [sailing]). In the first and second query, we compute the result­ing weights 
according to the vector space model. The ranking of the result of the first query is determined by the 
conditional probability P(t Id). Here, P(qlt) = 1 is assumed, i. e. the retrieval function does not use 
query term weighting, In the second query, we use weighted rules (predicate r) for representing query 
term weighting. Document d2 fulfills both rules. We get P(r ( d2 ) ) = P(r(d2)ld2 [sailing]) . P(d2 [sailing]) 
+ P(r(d2)\d2 [boats ]). P(d2 [boats]) = 1. O. O.5+ 0.6. 0.5 = 0.8 as resulting retrieval weight. The 
third query demonstrates the knowledge augment­ation. Since in document dl we know that peter is a sailor, 
we can query on this knowledge in the global context. Considering the disjointness assumption for con­texts, 
knowledge augmentation defines the term space of the whole document collection. For the example above, 
the term space is defined by {0.7 sai 1 ing, 0.05 peter, 0.25 boats}, The extended Kripke structure M 
= (s,7r,Kl, ...,Kn,P) defined in [Fagin &#38; Halpern 94] provides a sound framework for integrating 
uncertainty into the semantics of our data model. The function P(z, s) assigns a probability space (S,,., 
v,,.) to each agent and world, where S,,. is a subset of the worlds Kz, ~ and p,,. is a probability distribution 
over the a-algebra of S,,.. Given this structure, the interpretation of a weight is defined by the sum 
of the probabilities of the worlds, where the proposition is true. For example: 0.9 = ({slr(s)(sailing) 
= true}). The ~se,sd,,.o ~dl,o agent corresponds to the enclosing context (all) and the all-context 
considers those worlds which it can reach from the this-world so. 7 Application Domains The examples 
presented so far already indicate the use of the model for full-text document retrieval, The different 
parts of a document can be considered appropriately. Even documents which differ in their aggregation 
structure can be handled within one knowledge representation, since the result of a query is a set of 
paths which may differ in their depth. Multimedia IR requires handling different types of ob­jects within 
one knowledge representation. Consider two databases: one document database and one picture data­base: 
document-db[dl [ . . . ] ] picture-db[pl [ . . . ] ] {document-db} [ ?­ . ..1 {document-db U picture-db} 
[?­ . ..] The above example shows the structure of an integ­rated knowledge representation for multimedia 
IR pur­poses. Queries can be posed context-dependent. The first query considers only the document database. 
By means of context combination, various contexts for querying can be chosen. For answering the second 
query the knowledge of both databases (contexts) is united. Context-dependent querying provides intuitive 
possib­ilities for considering context-dependent knowledge (for example user preferences) and for combining 
several con­texts to a new database for querying. This combination of contexts also supports network 
IR. Since the knowledge representation is object-oriented, media-independent and powerful enough to describe 
the relationships between semantical objects, the model is especially suitable for processing content 
retrieval on a distributed multimedia database. 8 Conclusion and Outlook We have presented a data model 
built on the object-oriented principles aggregation, classification, and generalization for IR purposes. 
It provides an integrated knowledge representation for full-text, multimedia, and network IR. Structurally 
complex knowledge can be represented. By considering the aggregated structure of objects, their classification 
and relationships, we gain new query facil­ities. Querying for documents and facts can be combined and 
instead of retrieving only whole documents, the least aggregated entity that implies the query is determined. 
The query result can be delivered as a hypertext docu­ment. This feature offers the possibility of improving 
the effectiveness of IR. The major concerns of this paper are the knowledge rep­resentation and new querying 
facilities. We indicated how to take into account the intrinsic uncertainty of knowledge and vagueness 
of queries in order to achieve a ranking of the retrieved objects. The semantics we use offers a well­defined 
possibility to add different flows of probabilities for obtaining the desired ranking with a sound meaning. 
Further work will be done in investigating the suitab­ility of probability theory versus Dempster-Shafer 
theory. Concerning aggregation we want to exploit more know­ledge about the given ordering. A database 
is just a set of documents, whereas the sections of a document have a specific order and should be considered 
as a list. This ordering could be useful for interpreting the knowledge of a document and for browsing 
the retrieval result. References Brown, H. (1989). Standards for Structured Documents. The Computer Journal 
32(6), pages 505 514. Christophides, V.; Abiteboul, S.; Cluet, S. (1994). From Structured Documents to 
Novel Query Facilit­ies. In: Snodgrass, R. T.; M., W. (eds.): Proceedings of the 1994 ACA4-SIGMOD. International 
Conference on Management of Data., pages 3 13 324. ACM, New York. Colby, L. S.; Saxton, L. V.; van Gucht, 
D. (1994). Concepts for Modeling and Querying List-Structured Data. Information Processing &#38; Management 
30(5), pages 687-709. Fagin, R.; Halpern, J. (1994). Reasoning About Know­ledge and Probability. Journal 
of the ACM 41(2), pages 340 367. Fuhr, N.; Rolleke, T. (1996). A Probabilistic Relational Algebra for 
the Integration of Information Retrieval and Database Systems. (To appear in: ACM Transactions on Information 
Systems). Fuhr, N. (1995a). Logical and Conceptual Models for the Integration of Information Retrieval 
and Database Sys­ tems. In: East/West Database Workshop, Klagen@t 1994, pages 206 21 8. Springer, Berlin 
et al. Fuhr, N. (1995 b). Probabilistic Datalog -a Logic for Powerful Retrieval Method. In: Fox, E.; 
Ingwersen, P.; Fidel, R. (eds.): Proceedings of the 18th Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval, pages 282 290. ACM, New York. Fuhr, N. (1996). Object-Oriented 
and Data­base Concepts for the Design of Networked In­ formation Retrieval Systems. (submitted for publication). 
URL: http://ls6-www. informatik.uni­ dortmund.de/reports/96 fFuhr-96 .html. Halpern, J.; Moses, Y. (1992). 
A Guide to Completeness and Complexity for Modal Logics of Knowledge and Belief. Art@cial Intelligence 
54, pages 3 19 379. Kifer, M.; Lausen, G.; Wu, J. (1995). Logical Founda­tions of Object-Oriented and 
Frame-Based Languages. Journal of the Association for Computing Machinery 42(4), pages 741 843. Macleod, 
I. (1990). Storage and Retrieval of Structured Documents. Information Processing and Management 26(2), 
pages 197-208. Meghini, C. (1995). An Image Retrieval Model Based on Classical Logic. In: Fox, E.; Ingwersen, 
P.; Fidel, R. (eds.): Proceedings of the 18th Annual International ACM SIGIR Conference on Research and 
Development in Information Retrieval, pages 300 309. ACM, New York. Pfeifer, U.; Fuhr, N.; Huynh, T. 
(1995). Searching Struc­tured Documents with the Enhanced Retrieval Func­tionality of freeWAIS-sf and 
SFgate. In: D. Kroemker (cd.): Computer Networks and ISDN Systems; Pro­ceedings of the third International 
World-Wide Web Conference, pages 1027 1036. Elsevier, Amsterdam -Lausanne -New York -Oxford -Shannon 
-Tokyo. van Rijsbergen, C. J. (1986). A Non-Classical Logic for Information Retrieval. The Computer Journal 
29(6), pages 481-485. van Rijsbergen, C. J. (1989). Towards an Information Logic. In: Belkin, N.; van 
Rijsbergen, C. J. (eds.): Proceedings of the Twel@h Annual International ACM-SIGIR Conference on Research 
and Development in Information Retrieval, pages 77 86. ACM, New York. Rolleke, T.; Fuhr, N. (1996). Retrieval 
of Complex Objects Using a Four-Valued Logic. Technical report, University of Dortmund. Wong, S.; Yao, 
Y. (1995). On Modeling Information Re­trieval with Probabilistic Inference. ACM Transactions on Information 
Systems 13(1), pages 38 68.  
			