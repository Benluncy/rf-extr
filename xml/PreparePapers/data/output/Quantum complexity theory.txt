
 Quantum Complexity Theory (Preliminar~ .4bstract ) . Ethan Bernstein* Umesh Vaziranit Computer Science 
Division University of California, Berkeley Berkeley. CA 94720 :1 Introduction Just as the theory of 
computability had its foundations in the Church-Turing thesis, computational complex­ity theory rests 
upon a modern strengthening of this thesis, which asserts that, an-y reasonable model of computation 
can be eficierztly simulated on a. proba­bilistic Turing Machine (an efficient, simulation is one whose 
running time is bounded by some polynomial in the running time of the simulated machine). For ex­ample, 
computers that can operate on arbitrary length words in unit, time, or that can exactly compute with 
infinite precision real numbers are unreasonable nlod­els -since it seems clear that they cannot be physically 
implemented. It had been argued that the Turing Ma­chine model (or the polynomial time equivalent cellular 
ZLUtOlllatOll model ) is the inevitable choice once we as­sume that we can implement only finite precision 
conl­puts.tiona] primitives. Given the widespread belief that J\r P # BPP, this would seem to put a wide 
range of important, computational problems (the ArP-hard prob­lems) well beyond the capability of computers. 
However, the Turing Machine is an inadequate model for all physically realizable computing devices for 
a. fun­damental reason: the Turing Machine is based on a classical physics model of the Universe. whereas 
cur­rent physical theory asserts that, the Universe is quan­tum physical. Can we get inherently new kinds 
of ( dis­crete) computing devices based on quantum physics? The first indication that such a. device 
might potentially be more powerful than a probabilistic Turing Machine *Supported by an NSF Graduate 
Fellowship. Supported bv grants NSF CCR-88%M2 and NSF IRI­!}320074. lPermission to copy without fee all 
or part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notico and the title of the publication and its date appear, and notice 
is given :hat copying is by permission of the Association for Computing Ihlachinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. 25th ACM STOC 93-51931CA, USA @ 1993 ACM 
0-8979 J-591 -7/9310005/00~ 1...$1.50 appeared in a paper by Feymnan [Fe82] about a. decade ago. In that 
paper, Feynman pointed out a very curi­ous problem: it, appears to be impossible to simulate a. general 
quantum physical system on a probabilistic TM without an exponential slowdown. The difficulty with t,he 
simulation has nothing to do with the prob­lem of simulating a continuous system with a. discrete one 
-we may assume that, the quantum physical system to be simulated is discrete, some kind of a quantum 
cellular automaton. In view of Feynman s observation, we must re-exa.mine the foundations of computational 
complexity theory, and the complexity-theoretic form of the Church-Turing thesis, and study the computa­tional 
power of computing devices based on quantum physics. A precise model of a quantum physical computer -here­after 
referred to as the quantum Turing Machine -was formulated by Deutsch [De85]. This model may be thought 
of as a quantum physical analogue of a. prob­abilistic TM -it has an infinite tape and a finite state 
control, and the actions of the machine are local and completely specified by this finite state control. 
In full generality, on any given input, a quantum TM produces a random sample from a probability distribution. 
Are general quantum Turing Machines physically real­izable? (See [De89] for a dicussion of this issue. 
) We must not have to devise a new physical implementation for each specification of a finite state control. 
Therefore, the first step toward resolving this question involves an­swering whether there is a universal 
quantum Turing Machine. Deutsch [De85] describes a universal sinmla­tor for quantum Turing Machines; 
this simulator is not, satisfactory from a. complexity theoretic point of view because the simulation 
overhead is exponential in the rlmning time of the simulated Turing Machine in the worst case. In this 
paper, we prove the existence of a universal qua.t~­tum Turing Machine whose simulation overhead is poly­nomially 
bounded. In full generality, on any given in­put a. quantum TM produces a random sample from a 11 probability 
distribution. We say that quantum TM T simulates T with accuracy c, if on every input z, T out­puts a 
sample from a distribution which is within total variation distance c of the corresponding distribution 
for T. VVe prove that there is a universal quantum TM, which takes as input the description of a quantum 
TM T. time t, and input, z, and simulates T(x) for time t with accuracy c. The slowdown is polynomial 
in t and 1/6. How powerful are polynomial time quantum TMs? The dynamics of a quantum TM are time reversible, 
and therefore it is necessary to appeal to results of Bennett [Be73] to show that polynomial time quantum 
TMs can simulate polynomial time deterministic TMs, and more generally, polynomial time probabilistic 
TMs. A se­quence of papers [DeS5,DJ91,Jo91, BB92a,BB92b] study the power of quantum TMs that, output 
the correct an­swer with certainty (probability 1): Deutsch and Jozsa [DJ91] showed the existence of 
a promise problem that can be solved exponentially faster on a quantum TM than on any classical deterministic 
TM. Berthiaume and Brassard [B B92a] [B B92b] formulated this result in terms of oracle quantum TMs. 
They showed that there is an oracle relative to which there is a problem that can be solved in polynomial 
time on a quantum TM, whereas any classical probabilistic TM. which is re­stricted to always give the 
correct, answer, requires ex­ponential time. However, the cruciaI assumption in aII the above results 
is that the classical TM is required to be error-free. For all the above problems, quantum TMs exhibit, 
no advantage in running time over classical probabilistic TMs that are allowed a small probability of 
outputting the wrong answer on any input. It is well known that the error probability of such a probabilistic 
TM can be reduced to a negligible value (for example, much smaller than the chance of hardware failure) 
at a very modest, increase in running time. For this reason the class BPP, of computational problems 
for which there exist bounded-error probabilistic polynomial time TMs, is regarded as the complexity 
class of efficiently solvable problems. In this paper, we present, the first evidence that, quan­tum 
TMs might, be more powerful than classical proba­bilistic TMs. We prove that there is an oracle relative 
to which there is a language that can be accept,ed in poly­nomial time by a quantum TM but cannot be 
accepted in n 0(log ~~ time by a bounded-error classical probabilis­tic TM. A more careful construction 
exhibits an oracle relative to which quantum polynomial time is not even contained in the class Arthur-Merlin 
where the verifier has no( ~ n ) time (see [BMW] for a definition of this class). Let BQP ( bounded-error 
quantum polynomial tzm.e) be the class of languages that are accepted by a polynomial time quantum TM 
with error probability at most 1/3. It is not hard to show that, BQP ~ PSPAC E. There­fore, we cannot, 
hope to prove that BPP C BQP with­out resolving the longstanding open question BPP # ?PSPACE. In fact, 
Valiant [Va92] recently pointed out to us that, the above result can be strengthened to say that BQP 
~ #P. bye feel that issues of quantum computation are relevant to physics as well as computer science. 
The study of the computational power of quantum TMs gives a method of demonstrating, in a quantifiable 
way, the inherent difference between the model proposed by quantum physics and any classical model. This 
may be viewed in the spirit of the famous Einst,ein-Podolsliy-Rosen para­dox and Bell s inequalities 
(discussed in [Fe82] ) which demonstrate a difference in the statistical properties of the quantum model 
and any local hidden variable model. Also, showing that BQP is equivalent to BPP (or even just that, 
BQP is contained in sub-exponential time as a preliminary step), would mean that the com­puter simulation 
of quantum physical systems could be efficiently carried out. To introduce the model of a quantum TM, 
we need some new terminology. This is introduced in Section 2 in the context of classical probabilistic 
TMs. Then in Sect, ion 3, we formulate quantum TMs as a natural extension of this model. In Section 4, 
we give two useful alternative characterizations of a well-formed quantum TM. These are used in Section 
5 in a series of constructions culmi­nating in a universal quantum TM. Finally, in Section 6 we present 
our evidence that, quantum TMs may be more powerful than classical probabilistic TMs. Please note that 
this is only a preliminary abstract; the final version of this paper will contain a number of issues 
that have been suppressed for this preliminary version. 2 A physics-like view of randomized computation. 
Before we can formally define a QTM, we must introd­uce some new terminology. We will use the example 
of a classical probabilistic TM to introduce this termi­nology in a familiar setting. As a bonus, we 
will be able to precisely pin-point, the point, of departure in the definition of a QTM, The new terminology 
is necessary because quantum me­chanical systems cannot be observed without being al­tered. Let us consider 
how we can describe the compu­tation of a PTM if we are not allowed to observe it while it is working. 
Therefore, we imagine that the PTM, T, is placed in a black box. The rules of the game are that, we know 
the finite state control of T, as well as its initial configuration, and the interval of time between 
successive steps. What we must not observe are the outcomes of any coin-flips that T makes. If we mentally 
keep track of T s configuration. then we would know when it, flipped its first coin, but we would not 
know which of the two possible successive configurations it entered. Instead. we will say that, the machine 
is in a linear superposition of the two configurations, and as­suming that the coin was fair, the coefficient 
for each configuration is 1/2. We shall refer to the coefficient of a configuration as its ampl~tude. 
As the machine con­tinues to compute and flip coins, it will, in general, be in some linear superposition 
of configurations, Given the linear superposition at one time step, how do we compute the amplitude of 
a configuration in the su­perposition at the next, time step? First we apply the finite state control 
s rules separately to each configu­ration in the superposition, and then we take a sum of these contributions 
weighted according to the superposi­tions amplitudes. Notice that. this means the rna.chine s finite 
state control is really specifying a linear mapping in the space of superpositions of configurations. 
This will remain true even if we give up the assumption that, the machine must toss a fair two-sided 
coin, and in­stead allow the machine several arbitrary many-sided coins. Suppose we think of the transition 
function 6 of a randomized TM on state set Q and alphabet X as 6: QxSXSXQX{L, R} [0,1] where 6(1). a. 
~, q, d) gives the probability that, if the ma­ chine is in state p reading a c it will write a r, enter 
:state q, and move in direction d. Then the machine s transition function is a linear map, given by the 
nla­trix where the entry corresponding to the configuration (cl row and configuration C2 column is &#38; 
evaluated at 1:.he tuple which transforms C2 into c1 in a single st$ep, or (I if no such tup]e exists. 
Since the number of possi­ble configurations is unbounded, this matrix has infinite dimension. Nevertheless, 
it s finitely specified and sat­isfies a locality constraint. We shall refer to this matrix iis the t?me 
evoktion operator of the PTM. Depending on tlhe particular machme, as the machme runs, ltls su­perposition 
may easily include an exponential number of distinct configurations. But, regardless of the nla­chine, 
the linear superposition will always contain only non-negative amplitudes and the amplitudes will always 
fiunl t,o one. Now, let s think about what happens when we open the box and observe the machine. LVe 
will find the machine in a specific configuration -not a linear superposition. The act of opening the 
box and observing the machine, forces it to choose a configuration out of the linear su­ perposition 
-the rule is that, each configuration is cho­S:ell t,o be t,he observed one with probability equal to 
its amplitude in the linear superposition. Next, > consider the case where we are only interested in 
one particular bit of the configuration, ancl we take a quick peek in­side the box to examine just that, 
bit. Then we will see a one with probability equal to the sum of the anlpli­tudes of configurations with 
a one in that, position, and a zero with probability equal to the sum for configura­tions with a zero. 
JVe will then think of the machine as being in a linear superposition corresponding to the distribution 
of configurations conditioned according to the actual bit, value we saw. This superposition could be 
computed by first, erasing the amplitudes of all config­urations inconsistent, with the observed ~alue, 
and then scaling Up t,he remaining amplitudes t,o maintain unit sum. Therefore, we think of the act of 
observing a bit as operating on the machine to effect this restriction and renormalization. Finally, 
note that, although the superposition ( distribu­tion) of the machine after t steps may take exponential 
space to write down, we can sample from it online in the obvious way. Each time our simulation s configu­ration 
splits, we can choose a single next configuration randomly according to the split s weights. This on-line 
sinlulation may alternatively be achieved by observing the PTM after each step. It is easy to see that, 
these multiple observations leave the final output, distribution undisturbed. 3 Quantum computation 
Our model of randomized computation is now surpris­ingly close to Deut,sch s model of a quantum Turing 
Machines. The major change that, is required is that in quantum physics, the amplitudes in a system s 
linear superposition and the entries in a system s time evolu­tion matrix are allowed to be complex numbers 
rather than just positive reals. J$rhen an observation is made, the probal)ilit,y associated with each 
configuration is not the configuration s amplitude in the superposition, but rather t,he squared magnitude 
of its amplitude. Making these changes to our moclel, we arrive at the following definitions (which are 
otherwise analogous to our model of PTMs). Definition: A quuni~(m Turing Mach zne ( QTIv1 ) con­sists 
of a finit,e state set Q, a finite alphabet Y, and a qaantum $ntte stui~ control 6 : QxZXYXQX{L, R} C 
where 6(p. 0. ~, q, d) gives the amplitude with which the machine in state p reading a a will write a 
~, enter state q. and move in direction d. As noted above, this trans­ition functiou specifies a liucww 
mappiug MA (the time evolution operator ) in the infinite dimensional space of superpositions of configurations. 
We will say that the machine s transition function is wc n-formed if the time evolution operator always 
preserves L2 length. Well­formedness is an essential condition because we wish to associate squared magnitude 
of a configuration with its probability in a measurement. Recall that, a matrix Al is called unitary 
if Ali ,If = Jf.lft = 1 where Alt is the transpose conjugate of M. It s not, hard to see that, AI preserves 
L2 lengt,h if and only if Aft M = 1. aud that, if Al is fillite-dil~lellsiollal this is in turn equivalent, 
to Al being unitary. How­ever. for infinite dimensional matrices Alt Al = 1 is not, equivalent to i\IAIt 
= 1. N-evertheless. the time evolu­tion operators of quantum TMs have special structure. and in fact 
these two conditions are equivalent for Alfi. Tkorem 1: A QTM is well-formed iff its tinwevo­ lution 
operator is unitary. Proof: Sketch. JJtAf = 1 and k] subjective together areellougll tol>rovetllat Af 
is unitary. So, suppose t,hat the time evolution operator of a QTM is notsurjective. Then, clearly there 
must be someparticular configura­ tion c which is not in the range of the operator. More­ over, any configuration 
which looks locally like c must also not be in the range. Now, .n cellsselect contiguous of tape. and 
consider the the set S,, of configurations which have t,heir tape head iuside the n cells and whose tapes 
are blank outside the n cells. The corresponding columns of 111 ~can only have non-zero entries in the 
cor­responding rows and in the 2 IQ I Is In rows corresponding to configurations where the tape head 
has moved out of the n cells. However. at least (n - 2)lEln-3 of the con­figurations in Sn look locally 
lilie c, and therefore also cannot, be hit. Hence, for n > 21QI IY13 + 2, not all of the columns of S 
n can he mutually orthogonal. giving a contradiction. 0 Definition: An OI)SCrvutwn of some bit of the 
super­position of a QTM returns a zero (one) with proba­bility according to the sum of squared magnitudes 
of configurations in the superposition with a zero (one). Moreover, the superposition is immediately 
restricted to those configurations consistent with the observed value and renormalized to have unit L2 
length. Quantum physics allows more general observations than we have included in our QTM. However, the 
effects of these nlore general olmervations can he efficiently sinl­ulated by the machines defined above. 
We do not have space to include a full discussion here. lye will briefly note thal, with our current 
model of observations. we need only consider QTNIs that are observed at, only one time step. l%is is 
because when a bit would first be ob­served. we could copy the bit into a special area of the tape where 
it will never again he touched. The space of linear superpositions of configurations can then be thought 
of as being split into the subspace of configu­rations with a O and the suhspace where configurations 
have a 1. Clearly, the portions of the linear superposi­tion in these two subspaces will develop indepenclently, 
since thel-can never interfere. But this means that if we later observe the saved bit, the linear superposition 
will illllllediately _take on the superposition it wouId have developed had we seeu the same value on 
an early ob­servation of the bit. So, replacing each observation with a copy to this safe storage, we 
can aIlow the observer to sample from the same series of distributions just hy obser~ing a series of 
hits at a single time step. In the following definition we will additionally assume a passive observer 
who merely reads a fixed bit at a fixed time. Again. although we will not give a discussion here, the 
power of a more general observer can be moved into the QTM being observed. Definition: A language L is 
in the class EQP ( era ct or error-free y7~a7/tunl polyno7nza/ t7rnc) if there exists a QTM with a distinguished 
acceptance tape cell, and a polynomial p. such that given any string z as input. observing the acceptance 
cell at, time p(r) correctly clas­sifies z with respect to L. More generally. a language is in the class 
BQP if this classification can be acconl­ plished with probability at least 2/3. A QTM certainly cannot, 
compute any non-recursive function. In fact. it s easy to see that, by computing a QTMs linear superposition 
at each step, a PTM can simulate the QTM using exponential space and an ex­ponential slowdown. By using 
depth first search, the straightforward simulation can be run using only poly­nomial space. so BQP ~ 
PS P.4CE. As Valiant [VaW] recently pointed out, this result can be strengthimed to say tlla,t, BQP ~ 
#P. However. this quantum model does lead to very curious effects. For example, suppose in our machine 
config­urations c1 and C2 each lead to configuration c with amplitude @. Then if we start the machine 
ill either configuration and observe one step later, we ll see c with probability p. However. if we start 
the machine in some superposition of just c1 and C2 we won t necessarily see c with probability p. To 
see this. suppose our nla­chine is started in the superposition {o1c1 + 0ZC2. If we observe the machine 
at time O, we ll see c1 with prob­ability] I(Y1 l? and C2 with probability la ~\2, and then in either 
case at time 1, we ll see c with conditional prol>a­bility p. But, if instead, we only observe at time 
1. we ll see c with probability [(@al) + (fiog)lz = p[al+uzlz rat,ller than ~j( 10* I! + Iozlz ). This 
means the simultane­ous computations from c1 and from C2 interfere with each other. In fact. if a 1 = 
oz, then the contribut­ions cancel out, and there s no chance we ll see c at all. Therefore, in this 
model observing the machine re­ally can alter the machine s computat~on. For this rea­son, the straight,forward 
simulation discussed above for PTMs will no longer work. If we simulate a repeatedly observed machine 
we nla~ obtain a distribution very far from that of the corresponding unobserved machiue. The above argument 
was certainl~ not rigorous. since we haven t argued that, tlms hypotbetlcal transition func­tion can 
reall~ occur in a well-formed quantum machine. llakiug such an argument requires checking that, an in­finite 
dimensional matrix is unitary. \flat we really need is some local charactemzatlon of the quantum fi­uite 
state controls satisfying this requirement, 4 Alternative views of the well-formedness constraint [n 
tlhls section. we will describe two additional charac­ ~erizatious of the well-f ormedness constraint, 
on quan­I:,llln finlt,e st,at,e controls, First. we will show that the constraint is equl~:alent to requiring 
that the finite state control be reversible. Then. we will give a set of locall~. checkable constraints 
equivalent to the global one. i\ e will find it useful to briefi}-review the notion of a classical reversible 
TM. first examined as part of an effort to determine whether computation inherentl~-dis­ si~ates energ~. 
]Definition: A TM T is revcrs?ble if rm:ersing its ar­ro~~ s gives a (deterministic) mapping of configurations 
T that undoes the computation of T: For any pair of configurations cl, C2 c1 Fz-C2 iff c2 F~{ cl. liote 
that the arrow reversal of a reversible TM T is not, necessarily a TM, since the reverse of a transition 
that both writes and moves must write in a non-local cell. Also. suppose we have a TM T which computes 
a function ~, i.e. it outputs ,f(~ ) on input, r. Then if j is not injective there can clearly be no 
reversible m~ that computes ~ (i.e. has j (r) on its output tape ancl all other work tapes erased). However. 
Bennett [Bei 3] showed that, for any TM T computmg a function .ic. there is a reversible TM T such that 
T computes r f(r) on input, r: the running time of T is within a constant factor of the running time 
of T. l~~e can consider analogously the reversibility of QTMs: we want an arrow reversal of a QTNI to 
reverse the lnachine s computation. However, we must decide what, should happen to the arrows amplitudes 
as we reverse their directions. ~f~e know that a quantum finite state control 6 is well-formed iff Jl,s 
flf~ is the identity matrix. Therefore M: reverses 6. Now, lool{ing at Af/ we see that, 6 is well-formed 
iff it is reversible in the following wav: The configuration map $ . specified by reversing the arrows 
and conjugating the amplitudes of 6, undoes the computation of d: For any superpositions, VI F~ [p iff 
v? h~, 71. It s eas) to see that this is a generahzat,ioll of classical reversibility. and thus, as Deutsch 
[Deii5] pointed out. the classlcal reversible TMs are a subclass of QThfs, So. using Bennett s result, 
an~ efliclent classical conJ­put,ations can also he carried out efficiently on a QThI. In particular. 
P is contained in EQP and BPP is cou­ tained in BQP. h-ext. we give a local characterization of t,he 
~ell­forrnedness constraint, directl) in terms of the finite state control of the QTIvl. Theorem 2: A 
quantum finite state control 6 is well­formed if it satisfies the following The anlplitucles leaving 
any state-symbol pair have unit, total squared magnitude: YI). CT EQXE ~ 16(P+u, T,q. d)l = 1 r q,d 
 The superpositions of writte}l character, new state, and direction leaving au! two different state-symbol 
pairs are orthogonal:  V(P1.ml)+(P~.a2) E QxY ~ 6(,,al,T.qd)6*(p,.m,, T.*,d) = T,q ,i If we fix all 
of 6 s parameter except the new state, then 6 specifies a linear superposition of new states consistent, 
wit h this fixed data. The space of lin­ear superpositions of states consists of two nlutju­ally orthogonal 
subspaces. one for each direction of mo~:ement, such that any superposition obtained in this way lies 
in the appropriate subspace, 3 QL ~QR C c Q mlltualh Orthwal SUCh that Vp, o,~, cl 6 QxSXSX{L, R} ~ b(Pc>Tq.d) 
q E Q, qeQ Proof: Sketch. Me know &#38; is well-defined iff ,lf~ltl~ gives the identity matrix. or equivalently 
iff the columns of Jfi have unit, leugth and are mutually ort hogoual. Clearly, the first condition specifies 
exactly that each column has unit, length. In general. configurations whose tapes differ in a cell not, 
under either of their beads. or whose tape beads are not, either in the same cell or exactly two cells 
apart, cannot, yield the same configuration in a single step. Therefore such pairs of columns guaranteed 
to be orthogonal. and we need onl~ consider pairs of configurations for which this is not, the case. 
The second condition is necessary aud suficieut for orthogouality of columns with the same head posi­tion, 
and the third for orthogonality of columns with tape head offset by exactly two cells. 0 We can now argue 
that the interference which we de­scribed in the previous section can happen in a legally defined QTM. 
For example, consider the simple machine with Q = {q}.~ = {0, 1}, and 6(q. hl, b2, q,R) = -$ if b1=b2= 
1, * otherwise, and d = O everywhere e~se. It can be easily verified that this 6 satisfies the local 
constraints and therefore is well-formed. Also if config­ urations c1 and C2 differ only in the bit under 
the tape head, then they each lead to the corresponding O con­ figuration with amplitude -$. Therefore. 
this machine - will exhibit the interference pat,t,ern discussed above.  5 The universal QTM In this 
section, we exhibit, a series of reductions cuhni­nating in a universal QTM. In the previous sections, 
we have highlighted two unique characteristics of QTMs: QTMs are always reversible, and they exhibit 
interfer­ence patterns. We must therefore simulate a QTM re­versibly, and in such a way that tke particular 
interfere­nce patterns of the machine are preserved. The sinml­taneous satisfaction of these two requirements 
makes building a universal machine for QTMs much more dif­ficult than the straightforward constructions 
seen for many other classes of TMs. Our solution will consist of two stages. First, we will simplify 
the set of QTMs we must simulate by showing that the distribution com­puted by any QTM is also computed 
by some QTM from a simple sulocla,ss. Then, we will discuss reversible simulation and show how a single 
QTM can simulate any machine from this subclass. First, we must say what it means for one QTM to sin~­ula.te 
another. Definition: In full generality, on any input z. a QTM T produces a sample from a probability 
distribution on configurations. We will say that machine T! wnulates T if on input, T it allows an observer 
to sample this distribution. Alternatively, we will say that T simulates T with accuracy c if it allows 
an observer to sample a distribution which is within ~ total variation distance of this distribution. 
Our first simplification will be to observe that, we need work only wit h QTMs with real-valued transitions. 
The trick relies critically on the fact that, we are working with TMs, and hence our configurations have 
a single state. In particular, we do not know if a similar result will hold for a parallel model of quantum 
computation like a quantum cellular automaton. Lemma 3: Any QTM T k simulated, with constant, slowdown, 
by some QTM T satisfying PI T S finite state control uses only real an~pli­tudes. Proofi Sliet,ch. For 
each state q from T, give T two states qr and q$. We ll rely on the natural correspon­dence between complex 
superpositions of configurations of T and real superpositions of configurations of T (a+b~)q aqr+bqi 
We let &#38; be the finite state control compatible with under this correspondence: d (pr, a,r, qr, d) 
= Re(15(p, cT,T, fJ+d)) Cv(pr. a,r,q,, d) = I???(($(p,a, T,q, (i)) A (pi,a,r,qr,d) = I?72((i(p, (7, T,y, 
d)) ($ (});, u, T, q~, d) = Re(ti(p, a, 7, y, d)) It can be easily verified that T is a. well-formed 
QTM simulating T. n Next, we restrict the complexity of the quantum finite state control by requiring 
that it, enter any particular state from only one direction. Lemma 4: Any QTM T k simulated, with constant 
slowdown, by some QTM T satisfying PI and P2 T only enters any particular state while nlov­ing in one 
direction: If c$ (pl. al, ~1, q,dl) and 15 (pz, OJ, rz. q, d? ) are both non-zero. then cll = d2. Proofi 
Sketch. Given T with finite state control A, then. in the language of our local reversibility con­straints, 
we choose orthonormal bases {tl~,1, . . . . UL,m} and {!~R,l, . . ., VR,, } for QL and QR. Then, we augment 
Q with a state for each vd,~. Now, if T s finite state COn­trol is translated so that it maps from Q 
to the ~d,i, then it will obey P2. So T can implement this map, and then using two more time steps and 
another set of auxiliary states, change basis back from the t!d,, to Q. This achieves the required simulation 
with a slowdown by afactor of 3. n The class of machines satisfying P2 are much easier to analyze than 
general QTMs. The time evolution nla­trix of a general QTM is unitary, but this matrix is in­finite dimensional, 
prohibiting the use of this unitarity except, in a. global argument. However, the finite state control 
of one of our simpler machines also specifies a finite dimensional unitary matrix. Indeed, we can write 
the entries of a 6 satisfying P2 in a matrix, which we will call LA, indexing the columns by the current 
state and symbol and the rows by the new state and sym­bol (the direction in which the machine moves 
is inl­plied by the new state). Then the first and second local well-formedness constraints guarantee 
that L6 must be unitary. This local unitary characterization will allow us to con­ sider only machines 
whose configurations have indegree and outdegree at, most, z. Definition: lt e will say that a square 
matrix Jll df ­composes into square matrices .V1, . . . . Ill,, if flf con­sists of independent copies 
of the M; s. We will call Jtf l-decomposable where k is the maximum dimension of any of these matrices, 
Lemma 5: Any QTM T is simulated. with constant slowdown, by some QTM T satisfying P 1-P2 and P3 Affi, 
is 2-decomposa,ble. Proof: Sketch. First, an easy argument by induction can be used to show that any 
d-dimensional real unitary matrix can be written as a product, of k = poly( d) 2­clecomposable d-dimensional 
real unitary matrices. IVe apply this construction to LA. W-e augment T s state set, and alphabet to 
include k + 1 copies of the old versions. Then, we let the ith matrix from the product determine the 
transitions from the ith copy to the i + 1st copy. as the machine steps back and forth. Finally, the 
k + 1st copy map deterministically back to the first, copy, while the tape head moves in the proper direction 
according to the state. The new machine will simulate the old machine with slowdown by a constant, factor, 
n For our universal machine to simulate a QTM T we cer­tainly must provide an encoding of T as input, 
However, the set of possible input, strings is countable whereas T s amplitudes can be chosen arbitrarily 
from the uncount­able setofreals. Therefore, wecanuot hope for a single universal machine to exactly 
simulate all QTMs. So, our final simplification will be to restrict to accountable set, of QTMs which 
approximate the whole set. lemma 6: There exists a 2 x 2 nmtrixl? such that, any QTM T is simulated up 
to time t, with accuracy ~ zLndslo~~ dom 711 polyllollliaiinf and l/c, by son~eQTM r , satmfyina w P1.P3 
and P4 AfJ/ can be decomposed into the set {[-l], [l], R} Proof: Sketch. Consider amachineT satisfying 
Pl-P3. We can simulate Tif we can simulateeach of the unitary 2 x 2 matrices of lffi in such a way that, 
the op­eration on anyvect,or is within O(t/c). This will be pos­sible if we let R be a rotation in the 
plane such that for any other rotation R , there exists a k < O(poly(t/c)) such that Rk is within O(c/t) 
of R . Now, rotation by the angle ~T~2_2 2=1 gives one such R. 0 Now, we will show that t,he countable 
subclass of llla­chines satisfying P1-P4 contains a universal machine, First. we must discuss the reversible 
simulation of This. In fact, the construction of a classical reversible TM that call silllulatea llotllercl 
assicalrev ersil~leTLi provided as input, is not, immediate. Consider the straightforward simulation 
method for TMs: lVe insist that the target machine s finite state control be provided in table form as 
input. JYe then use chunks of cells, or supercells . of our tape to simulate cells of the target machine. 
Each supercell llolds t,he corresponding symbol from the target machine s tape. and the supercell under 
the simulated tape head also contains the target machine s state. Simulating a sin­gle timestep of the 
target machinerequires a ta­ just ble lookup and a bit of copying. Unfortunatelyj copy­ing is an irreversible 
process. However, copying can be achieved reversibly in the case that the destination is known to beempty,f 
orexample by adding the desired entry bitwise mod 2 to the current contents of the des­tination, Similarly 
supercell can be erased by bitwise addition using a copy of its contents. This suggests the following 
method. First we insert aflagintothet,able at the p,u entry while erasing p. a from the tape. Then we 
copy the new information from the table into the now empty locations. Finally, we use a reverse table 
to allow us to use the new information written on the tape to erase theflagfromthe table. Building a 
universal QTM introduces a new difficulty. Clearly, we ll again need to use manl-steps of our nla­chine 
to simulate one atomic step of the desired nla­chine. Now, however, the step we ll need to simulate will 
not be a deterministic mapping, but, instead will involve quantum interference. The problem is that if 
we spread the interference over several steps of our sinl­ulation, the intermediate interference patterns 
may not be reversible. Forexample,c onsidert hestraightforward extension of the above simulation to QTMs. 
Since we need to consider only time evolution matrices which can be decomposed into {[1], [ I], R}, we 
can encode each fi­nite state control into a table as before. But now when we look up a state-symbol 
pair in the simulated nla­chine s tables we may find not, one set of instructions for updating the tape, 
but a listing of two possible up­dates. We can have our machine split appropriately into two paths of 
computation and then try to follow the two sets of instructions in superposition. However, reversibly 
erasing the old state and symbol (or the flag in the table) is now problematic because the new tape contents 
are not, sufficient to recover the old infornla­tion. Our solution will be to simulate the interference 
atonl­ically. In other words, all but one of the steps in our simulation will be reversible deterministic 
steps. In the one special step, we will simulate all of the splitting and interference of the desired 
machine s step. To do this we will need to somehow bring the information which determines the desired 
splitting (which in general will be spread across the bits of the arbitrarily large super­cell ) into 
one state and symbol of our universal machine. The following is a brief sketch of how this can be acconl­plished. 
Since LK is 2-decomposable, we can group the entries of the first table into pairs where both list the 
same two instructions. The two entries, instead of list­ing these instructions, will each contain a pointer 
to a single entry of a second table which contains a single copy of the two instructions. As before, 
we first insert, a flag at the p, m entry of the first table while erasing p, a from the tape. Next, 
we insert, a flag at the ap­propriate entry in the second table, while erasing the first. flag and adding 
a single bit to our machine s state according to which of the two possible first table en­tries we came 
from. This bit. can then be transformed according to the special transformation R, and the two possible 
updates can be followed in superposition. But now, the new tape contents are sufficient to determin­istically 
determine which entry of the second table was used, and hence to era,,e the flag. This technique allows 
us to prove the following lemma. Lemma 7: There exists an encoding of the machines satisfying P1-P4 and 
a QTM [? such that, given as input, the encoding of some machine T. [~ simulates T with constant slowdown. 
Lemmas 6 and 7 together imply our theorem. Theorem 8: There exists a. universal QTM L which when input, 
a description of any QTM T, and any t > 0, simulates T for t steps with accuracy c, and with slowdown 
polynomial in tand 1/6. 6 Computing with a QTM Can a QTM compute faster than a classical TM? In this 
section we will give some evidence suggesting a positive answer. First let us introduce the Fourier power 
spectrum of a function mapping n-bit strings to real values. The usual way of thinking about such a function 
is by listing its 2 values. Each point of the vector space IRn is thereby associated with a function 
on n-bit strings, and we ex­press our function in terms of the orthonorrnal basis b.,....b2m-1, where 
hi(z) = 1if x = i and Ootherwise. However, another useful basis for this space can be con­structed using 
parity functions. For each subset, of [1. n], identified by an n-bit, integer i, we define the normalized 
parity function par, by pari(x ) = 1 if an even number of the bits oft in the positions selected by i 
are 1. and 1 otherwise ( we ll denote this parity of z with respect to i by z &#38; i). Clearly. the 
2n parity functions also form an orthonormal basis of Et z. So, we could also describe a function .f 
by listing its unique representation as a linear combination of the parity bases ~ = ~i }ipuri. Since 
representing j by { &#38; } corresponds to doing discrete spectral analysis on the tl-hypercube. we call 
{At} the Fourier power spectrum of the function ~. Clearly, we have ~, ~~ = ST .f ( x )2, and if we restrict 
our attention to boolean functions with range {-1, 1}, then we have ~, A? = 2 . So. we define the Fourter 
sanlpltng problen~ by providing as input, a classical program to compute .f, and requiring as output 
each i with probability ~ A;. We will show that, a QTM described by Deutsch and Jozsa [DJ91] exactly 
solves the Fourier sampling prob­lem in polynomial time. This result does not, prove that QTMs are more 
powerful than PTMs since a PTM can approximate the same distribution in polynomial time. Specifically, 
we can show that a PTIvI can, with high probability-. sample from a distribution within ~ total variation 
distance of the desired Fourier distribution. However, we will show that the QTM solution can be extended 
to solve a difficult problem. First, we must describe Deutscb and Jozsa s QTM. In general, a QTM effects 
a unitary transformation. The particular one we will find useful is the Fourier trans­formation. Suppose 
we associate each standard basis function 15i with having i written on the QThI s tape, and that instead 
of using the standard representation of our function ~ = ~i ~( i)bt, we represent ~ with a superposition 
of these tapes, ~ = xi ,f( i) i. Then the Fourier transformation given by the matrix F, where F, ,3 = 
~ i &#38; j. converts this representation to the par­ity basis. To see this, note that applying F gives 
This is exactly what we want, since observing this su­perposition will give i with probability ~ A:. 
The transformation F also allows the QTM to construct, the original superposition representing ~, ~i 
~( i ) i. If we start with the tape O and apply F, the result is the superposition where all n-hit tapes 
have equal mag­ .. nltude and ldentlcal phase: &#38; ~1 i. Then, the QTM can (again appealing to Bennett 
s result) follow the pro­gram for ~, computing each j(i) in the piece of the su­perposition with i on 
the tape. Next, the machine can apply a phase shift of 1 or 1 to each piece according to the value ~(i). 
We have not yet achieved the desired superposition because the pieces of the superposition differ not, 
only in the string i, but also in the value ,f( i) and in various information left over from running 
the program for ~. However, these other differences can be removed h: reversing the computation of ~, 
giving us the desired superposition. Finally, we describe how the QTLf can effect the trans­ formation 
F. It is easy to see that the QTM can ac­ complish this by applying the unitary transformation :<0each 
of the n bits one at a time. [n summary, the QTM solves the sampling problem in O(n) time. First, it 
applies F to a piece of n tape cells i nit,ially all blank. Next, it computes ~(i) in parallel for all 
i in superposition. Then, it applies phase shift, f(i), reverses the computation of ~( z ), and once 
again applies .F. ~Remarkably. this algorithm only requires calling the al­gorithm for j twice. We can 
see the power of this abil­i t,y more clearly by turning this sampling problem into ii deterministic 
problem. Promising that, the function ,f is one of the parity functions. we define the following special 
case of the sampling problem IDefinition: PARITY PROMISE: 3 n-bit k such that V n-bit i, ~(i) = i &#38; 
k. ANSWER: k The QTM we have already described amazingly solves for the n-bits of information to answer 
P.ARITY using only two computations of ~. Solving P.ARITY in the straigllt,forward manner on a classical 
TM requires conl­puting n values of ~. This suggests that a recursive construction will separate the 
two classes of machines. To ready this problem for recursion, we first need to turn PARITY into a problem 
with range { 1, 1}. This is easily done by adding a second function g, and requiring the answer g(k) 
rather than k itself. Now, we ll make the problem recursive. For each prob­lem instance of size n., we 
ll replace the 2 values of ~ with 2n independent recursive subproblems of siz~ n/2, and so on, stopping 
the recursion with function calls at the bottom. The QTM will be able to solve an instance c)f size n 
recursively in time T(n) where T(n) < O(n) +2 T(n/2) ~ T (n) < O(nlogn) However, the straightforward 
recursive solution on a PTM will require time T(n) where T(n) ~ fl(n)T(n/2) q T(n) ~ nQ(lOgfi) which 
specify its location in the recursive tree. Once again we have two functions .~ and g. Function .f will 
be used to bottom out the recursion, and therefore when provided with a series of strings of length n, 
n/2. . . . . 1. it gives the answer to the identified problem at depth lo,gn + 1. Function y takes input 
strings of length 7L. ?1/2, . , ., 2i0~ - +1 bits specifviug a problem at lel:el d < log n in the tree, 
plus a str;ng of length 210~n +1 specifying one of the parity patterns of length 210~ - +1. .-log ~~-~+l_l>it, 
a,nswer bacli Its answer map the problem s .2 to a single bit. Formally we define a problem at depth 
d, identified by the strings il, . . ., id, by Definition: REc (d. il. . . . . id) PROMISE: If d < log 
n, then 3 2]0~n-dtl-bit, k such that V 2i0~ -d+bitrtr i~+l, REC(d+l, iI . . . ..i~+l)=i~+l &#38;L. ANSW 
ER: If d< logn, g(il, . ..id. k), otherwise ~(il, . . . . id). Finally to prevent, the PTM from clirectly 
analyzing the programs for .f and g to determine the answer, we instead present, the machine with au 
oracle which can be queried for values of j and g. It is straightforward to alter the above QTM, using 
recursion and replacing function evaluation with oracle lookup, to construct a QTM to solve REc in time 
polynomial in n. However, When t,he oracle is chosen randomly, then, even in the best case, nn(log n 
) questions must be asked to determine the answer to REc with bounded probability of error. kVe omit 
the following lemma s proof due to the space constraints of this abstract. Lemma 9: There exists a c 
> 0 such that, for suf­ficiently large n the following is true: Fix arbitrarily the answers to any n 
log queries that can be asked of the oracle, and then choose an oracle uniformly at ran­dom among all 
those which satisfy the promises and also agree With t,lle fixed answers. Then answer to R,LC ~ill be 
1 with probahilit~-no further than 1/6 away from 1/2. This lemma S11OWS that a PTM (or even an Art,llur-O(lOg?I) 
Callllot solve REC Merlin verifier) with time n for a randomly chosen oracle with bounded error prob­ability. 
So. if we choose a different random oracle independently for each 71, and consider the language L = {1 
: REC = 1}, then any particular PTM (AM verifier ) will fail to accept L with probability 1. Since, PTMs 
(AM verifiers) are countable we will cause all machines to fail with probability 1. Theorem 10: There 
exists an oracle relative to which the class EQP is not contained in two-sided error II 0( g n ) time. 
A problem at depth d 6 [0, log n + I] is described by Theorem 11: There exists an oracle relative to 
which the strings il, iz, . . . . id of length n, n/2, . .,2 Ogn-d+l the class EQP is not contained in 
the class Arthur­ N erliu with verifier time 770( og n ). [BeT3] 7 Discussion [BB92a] The main open issue 
that, remains is characterizing the exact power of BQP. In particular. we would like to know whet,her 
BQP #?BPP. AS we have pointed out earlier, proving BQP # BPP would also resolve a long­standing open 
question in complexit~ theory. However, it may be possible to obtain such a result under some standard 
complexity assumptions such as P # lVP or the existence of one-way functions. In general a re­sult showing 
the increased power of quantum compu­tation might provide another method of den]onstrat­ing the inherent 
difference between quantum physics and any classical model. On the other hand, show­ing BQP = BPP would 
S11OW that, quantum physical systems can be efficiently simulated on a classical com­puter. [BB92b] [DeS5] 
[De89] [D.J91] In the quantum Turing Machines we have far, the transitions must, always move the ther 
left or right. For classical machines, use such a machine to simulate a machine considered so tape head, 
ei­it is trivial to which is also [Fe82] allowed to leave its tape head unmoved. However, in QTMs, allowing 
stationary head transitions introduces more complex interference patterns. In particular. the third of 
our local well-formedness c.oustraints does not generalize to three subspaces QL, QR, Q_. The prob­lem 
is that, two configurations with tape heads one cell apart, can interfere with the head in either of 
the two cells. The more complex local reversibility constraints for such machines will not allow a change 
of basis into states which specify the direction of previous movement, as in Lemma 4. Therefore our universality 
construction would not apply to machines in this more general for­mulation. JVe are currently searching 
for another sinlu­lation method that will allow us to decompose the time evolution matrices of these 
machines. and therefore ex­tend out universal QTM construction. [J091] [Va92] Acknowledgements We wish 
to thank Noam Nissan, Leonard Schulman, Richarcl Jozsa, ~.ille. Brassarcl, and Charles Bennett for helpful 
discussions, and to thank Richard Jozsa for noticing an error in an earlier version of this paper. References 
[BMW] L. Babai and S. Moran. Merlin games: a randomized and a hierarchy of complexity nal of Compuier 
and System :36, 1988, pp. 254-276. LArthur­proof system, classes . Jour-Sciences, Vol. 20 C. Bennett. 
Logical reversibility of compu­tation. IBM J. Res. Develop., vol. 17.1973, pp. 525-532. A. Berthiaunle 
and G .Brassard. The quan­tum challenge to structural complexity tJle­ory. - Procecd?ngs of ?ih IEEE 
Confe ren cc on ,Structure ~n (.lomplezzty Theory, 1992, A. Berthiaume and G. Brassard. Oracle quantum 
computing. l-%ocee~~?tgs 0} thePl~yszcs of G omputaiton, Dallas, 1992. D .Deutsch. Qua ntunl theory. 
the Church-Turing principle and the universal quantum computer. Proc. R. Sot. Lend., l~ol. A4W, 1985, 
pp. 97-117. D. Deutsch. 5Quantum computational net­works. Proc. R. Sot. Lend., Vol. A425. 1989, pp. 73-90. 
D .Deutsch and R.Jozsa. Rapid solution of problems by quantum computation. Proc. R. $OC, Lend.. Vol. 
A439. 1992, pp. 553-.558. R. Feynman. %imulating physics with conl­puters. International Journal of Tl)eorettcal 
Physics, Vol. 21, nos. 6/?, 1982, pp. 46:-488. R. Jozsa. Characterizing classes of functions computable 
by quantum parallelism. Proc. R. Sot. Lend.. Vol. A435, 1991, pp. 563-574. L. Yaliant. Personal communication, 
19X2.  
			