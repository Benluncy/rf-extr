
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; 
1981 ACM 0-89791-029-X $5.00 way as their low-level, equivalents. The only necessary change is the addition 
of the machinery required to enforce the constraints on the con­structs use. By employing this strategy, 
we have developed a computationally efficient abstract alternative to the most common disciplined use 
of impure operations in LISP: selectively updating (destruc­tively modifying) unshared data objects. 
Although we will discuss the new construct in the limited context of manipulating LISP S-expressions, 
our ideas easily generalize to arbitrary recursive data structures as defined by Hoare [5] and McCarthy 
[6]. 2. The Critical Role of Impure Operations in LISP It is noteworthy that all practical dialects 
of LISP (such as LISP 1.6 and MACLISP) include a multitude of impure operations (e.g. rplaca, rplacd) 
which directly modify the pointer and record structures representing S-expressions. The semantics of 
these operations cannot be described at the abstract level of S-expressions; they have meaning only at 
the level of the underlying imple­mentation. Despite the logical complexity of impure operations, they 
are indispensable in many practi­cal applications because they enable the program­mer to write much more 
efficient programa. As an illustration, consider the problem of maintaining a queue in Pure LISP. The 
standard solution is to store the queue aa a linear list, inserting new elements at the end and removing 
elements from the front. The operations of inspecting and removing the first element require only constant 
time. Inserting an element at the end of the list, how­ ever, requires time proportional to the length 
of the list. By ueing more sophisticated data structures and algorithms, it ia possible to reduce the 
asymptotic time bound, but the result­ ing programs are much more complicated.l k If we split the queue 
into two separate lists so that both the head and the tail are accessible In constant time, we can reduce 
the cost of n queue operations from 0(n2) to O(n). A single operation, however, can still require O(n) 
steps. In particular, removing an element from the queue when the head list is empty involvea replacing 
the On the other hand, if we allow impure (des­tructive) operations, we can improve the efficien­cy of 
the simple linear list solution so that all operations take only constant time. The modifica­tion is 
obvious: maintain a pointer to the last record of the list representation and use the pointer to destructively 
update the list (using rplacd) when inserting a new element. It is not only more efficient than the Pure 
LISP solutions, but it seems logically simpler as well. Neverthe­less, it is difficult to prove that 
the impure solution actually implements a queue. The Pure LISP solutione have simpler proofs because 
they are expressed at a much higher level of abstrac­ tion. In comparison to proofs involving abstract 
data objects, pointer-and-record proofs are long and complex because a pointer variable can refer­ence 
any record in the associated record class. Hence, changing the contents of some field of a record potentially 
modifies the dereferenced value of every pointer associated with the record class. In other words, a 
dereferenced pointer is a possi­ble alias for any other dereferenced pointer be­ longing to the same 
clasa. In spite of their pathological semantics, im­pure operations are commonly used in LISP to per­form 
the simple operation of updating variables with unshared values i.e. values represented by pointer-and-record 
structures that are not part of the repreaentations of any other values. In this situation, a pointer 
serves as an abstract index, analogoua to an array index, identifying a partic­ ular location within 
the variable-s value. By US­ ing impure operations, the LISP programmer can efficiently replace the structure 
at the specified location by a new structure, thereby modifying the value of the variable. In this limited 
context, low-level destructive operations have a simple abstract interpretation: they update a value 
at an head list by the reverse of the tail list a linear time operation. At the cost of adding several 
more lists to the representation and further complicating the definition of the queue operations, we 
can reduce the cost of every opera­tion to constant time (producing a real time- im plementation[7 ]). 
The trick is to distribute the work done in reversing the tail list over a number of operationa. abstract 
location within the value. In the The two functions are defined as follows: remainder of the paper, we 
will develop an { return the value in at v } abatract, yet efficient alternative to using { the end 
of path <sl, . . ..sn> } generalized As the first pointers as indices. extract ( v : S-expr, <sl, . . 
. , Sn> : path ) step in this process, we must precisely define if n=O abstract locations and create 
operations for v, extract(car(v), <s , . . . , s >), if S1=CAR 2n manipulating them.  [(-tr-t(cdr(v),<s2, 
.. ..sn>). if S1=CDR 3. Paths as Abstract Locationa { A natural description for a location within a 
 return the value of v with the value at the recursive data structure is a sequence of selector end of 
<s . . . ,Sn> replaced by new_part 1 names specifying the path from the root to the lo­ } cation. We 
call such a sequence a path. In ac­ update ( v : S-expr, <sl, . . . , Sn> : path, cordance with typical 
notation for sequences, we new part : S-expr )  denote the path consisting of the sequence of new part, 
if n=O selector names 1 s2  sn by sl 2 cona(update(car(v) , . . . ,Sn>. The empty path is denoted 
by <>. In the <s2, . ..$sn > , new part), special case of LISP S-expressions, the elements cdr(v)), 
If S1=CAR of the path are taken from the two element set 1   {CAR, CDR}.2 For example, in the list 
(A B C) the cons(car(v), path <CDR, CAR> refers to the second element B, update(cdr(v), while the path 
<CDR> refers to the tail (B C). <s2 , .. ..sn >, Like array indices, paths can be used either new_part)), 
if S1=CDR \ to extract values from composite values or to up- Note that update is a function; it does 
not modify date them. The function the value v as a side effect. extract : S-expr X path ~ S-expr We 
now define three functions for manipulat­ing paths: extend, last, and retract. They extracts values 
from within S-expressions and the correspond to the standard cons, car, and cdr function operations on 
lists except that they operate on update: S-exprx path XS-expr ~ S-expr the tail of a sequence rather 
than the head. extend(<sl, . . . , Sn> : path, f : field-sel) replaces values within S-expressions. 
For exam­= <sl, . . ..sn.f> ple, extract((A B C), <CDR, CAR>)=B last(+l, . . . ,Sn> : path) extract((A 
B C), <CDR>)=(B C) extract((A B C), <CDR, CDR>) =(C) =S n update((A B C), <CDR, CAR>, D)=(A D C) retract(<sl, 
. . . ,Sn> : path) update((A B C), <CDR>, (A))=(A A) update((A B C), <CDR, CDR, CDR>, (D))=(A B C D) 
(abbreviated t<sl, . . ..sn>) ~ sl  sn-l> For the sake of convenience, we also define a con­catenation 
operator * , which behaves much like the append function in LISP: The selector names CAR and CDR are 
capitalized . . ..sn>*(tl. . . ..tm> <sl , to distinguish them from the selector functions car and cdr. 
In other words, capitalization = sl  sn tl  tin> serves aa our quoting convention. The concatenation 
operator is recursively defin­able in terms of extend, last, retract, and equal­ ity; the definition 
is essentially identical to the usual recursive definition of LISP append. To support imperative programming 
where vari­ ables and assignment are present, we introduce a path selection mechanism analogous to array 
selec­ tion. Modeling our notation after array selection in ALGOL, we let VIPI specify the global location 
(within the entire program state) at the end of path p in variable v. Adopt ing the terminology of Kernighan 
and Ritchie [8], we will call global locatione 1­ values. We also adopt the usual convention that l-values 
are implicitly dereferenced (coerced) in right-hand contexts (e.g. within an expression). As a result, 
path selections may freely appear in both left and right-hand contexts just like array selections. In 
other words, a path selection v[p] can be used within an expression to extract the value at location 
p within v, or it can be used as the target (left-hand-side) of an assignment statement to update v at 
location p. For example, is equivalent to the simple assignment vl:=update(vl, pl, extract(v2, P2)). 
 4. Restrictions to Facilitate Efficient Xmplemen­tatioll To implement paths efficiently, we must im 
pose some restrictions on their use. In this sec­tion, we describe the necessary restrictions and present 
a table (Figure 1) summarizing the new no­tation that we introduce. 4.1. Built-in Patha With any variable 
of type S-expression the programmer can associate a built-in path. All variables of type struct consist 
of a pair con­taining a value part and a path part. Specifical­ly, if v is a struct variable, then v.value 
 is the S-expression associated with v, and v.path ia its path. By using the built-in path v.path, the 
programmer can efficiently access and update the corresponding S-expression variable v.value. To avoid 
cumbersome notation for l-values involv­ing built-in paths, we use the abbreviation vi in place of 
v.value[v.path] to denote the 1­value at the end of v.path within v.value, and vL*P in place of v.value[v.path* 
p] to denote the l-value at the end of v.path*p within v.value. To accommodate fast accessing and updating 
of S-expreesions through built-in paths, we force every struct v to obey the following invariant: the 
built-in path v.path must specify a valid lo­ cation within v.value. We enforce the invariant by imposing 
the following restrictions on updating atruct v. A speared node in v is any node ex cept the last one 
 on the path described by 3 v.path within v.value. If v.path is empty, for example, then no node in v.value 
is speared. To preserve the invariant, we prohibit assignments to v.value that replace speared nodes. 
Similarly, we __ prohibit assignments either to v.path or to the entire structure that would falsify 
the invariant. Both restrictions are designed specifically to maintain the invariant. Assignments to 
v.value that replace speared nodes can falsify the invari­ant because they modify structure traversed 
by v.path. For example, if v.value=(A B C) and v.Path=CCDR, CDR, CDR>, (i.e. V1=NIL) then the assignment 
v.value[<CDR>] :=(A) would yield v.value=(A A), but v.path would be invalid because cdr(cdr(cdr(A A))) 
does not exist. The most straightforward solution to this problem is to ban the potentially offending 
assignments. We will discuss possible liberalizations of this policy in g6.2. With the addition of built-in 
paths, our im­plementation includes three basic kinds of paths: (1) path constants sequences of selectors 
using the angle-bracket notation as in <sl , . . ..sn >. Path constants can be given namea by declaring 
them with a const attribute. 3 They are called speared because the path im­pales them. The path goes 
to but not through the last one; hence it ia not sp~red. (2) built-in paths the path part (s. path) 
of a struct variable s. (3) general path variables variables whose t.path -­ the built-in path of struct 
t values are sequences of selectors. t.value -­ the value part of struct t In general, operations involving 
built in VIPI -­ the location in v at the end of paths can be performed much more efficiently than path 
expression p the corresponding general path operations. For tl -­ t.value[t.path], the location tunately, 
built-in variables seem to suffice for in t at the end of its path most situations that arise in practice. 
Moreover, PI*P2 -- PI extended by p2 in many cases (such as the queue example) the path tl*p -­ t.value[t.path* 
p], the location is intuitively an integral part of the data struc­ in t at the end of t.path*p ture, 
making the use of built-in paths particular­ tP -­ retract(p) ly appropriate. We believe that paths independent 
of particular S-expression variables should be Figure 1: Summary of Path Notation available in the programming 
language, but the programmer must be warned that their implementa­ tion is costly in comparison to built-in 
paths. 4.4. Two Examples In the next two sub-sections, we describe two important operations involving 
built-in paths that To illustrate the use of built-in paths, in that have efficient implementations. 
Figure 2 we present a solution to the queue prob­ lem discussed earlier. A queue q is a struct 4.2. Shrinking 
S-expression =,here q.value is a list of the queue Shrinking is an operation that replaces a elements, 
head first. A path to the NIL value at struct variable by a substructure of itself. In the tail of q.value 
is kept in q.path. this operation, the path associated with the structure is truncated at the front so 
that it {return the first element of q} refers to the same value within the structure function Qfront(q 
: strnct) after the operation as before. Operation shrink return car(q.value) is defined aa follows: 
end Qfront shrink(s : struct) = {delete the first element of q} s value := s.value[<sl>]; procedure Qdelete(var 
q : strnct) s.path := <s2, . . ..s> n shrink(q) end Qdelete where s.path has old value sl ....sn >. 
{addv to the tail of q} 4.3. Growing procedure Qinsert(var q : struct, v : S-expr) Growing is an operation 
that replaces a ql:=cons(v, NIL); struct variable by a superstructure of itself. As q.path:=q.path *<CDR> 
with shrink, the built-in path is modified so that end Qinsert it refers to the same value after the 
growing operation as before. Grow is defined as follows: Figure 2: A Solution to the Queue Problem grow(s 
: struct, f : field-sel, newval : S-expr) = s value := update(newval, <f>, s.value); s. path := <f>*s.path 
In Figure 3 we implement three operations on a binary search tree: Search, Insert, and Delete. Note that 
the value newval[<f>] has no effect on A binary tree node is a list the outcome of the operation; it 
is simply a (keyValue lefttree righttree), where any keyvalue placeholder that is filled by the old s.value. 
in lefttree is less than keyvalue, which in turn is less than any keyvalue in righttree. Assume 18 key, 
leftson, and rightson are path constants de­clared as follows: const key = <CAR> const leftson = (CDR, 
CAR) const rightson = <CDR, CDR, CAR> A binary search tree T will be a stmct S-expression. If T.path 
is a path to some tree node, then T1 is a tree and Tl*key is the key­value of its root. Similarly, Tl*leftson 
and Tl*rightson are T1-s (possibly empty) subtrees. 5. Implementation We represent recursive data structures 
by standard pointer-and-,record list structures in­cluding reference count fields for storage manage­ment. 
With the exception of a single Boolean flag (the speared flag described below), no additional fields 
are required to support the implementation of paths. Since flag bits are usually available in the low 
order bits of record pointers, there is no space penalty beyond the space required for reference counts 
 involved in supporting paths. In discussing the implementation of paths we will restrict our attention 
to the special case of built-in paths.4 An efficient implementation of paths must perform primitive path 
operations (with the exception of a few pathological cases) in time independent of path length. Otherwise, 
algorithms expressed in terms of path operations will be asymptotically less efficient than the correspond­ing 
algorithms employing impure pointer Opera­tions. For example, if adding an element v to the end of a 
queue q, q.!. :=cons(v, NIL), takes time proportional to the length of the built-in path, q.path, then 
the queue implementa­ tion presented in Figure 2 is no faster (asymptot­ ically) than the most straightforward 
Pure LISP implementation. On the other hand, if the assign­ ment is performed in constant time, then 
the path solution matches the asymptotic efficiency of the pointer solution. We assume that general 
paths are implemented in an obvious brute-force fashion so that as­signments and value extractions using 
general paths require time proportional to the length of the path. { extend T.path down to the tree with 
keyvalue v, if v is in T; otherwise extend it to the empty tree where v should be J procedure Search 
(var T: struct, v : S-expr) T.path:=<>; do .null(Tl) A v<(Tl*key) ~ T.path:=T.path * leftson o=null(Tl) 
A v>(Tl*key) ~ T.path:=T.path *rightson od {null(T~) V v=(T~*key)} end Search { add value v to tree T 
(if it is not already there) } procedure Insert (var T : struct, v : S-expr) Search(T, v); if null(Tl) 
~ Tl:=list(v,.NIL, NIL) Dotherwfse ~ skip {v is already inT} fi end Insert { remove v from T if v is 
in T otherwise error } procedure Delete (var T: struct, v : S-expr) local rtree : S-expr; Search(T, v); 
if null(T~) ~ error Dotherwise ~ {v is keyvalue of Tl} {save T1-s right subtree} rtree:=Tl*rightson; 
{replace T1 by its left subtree} Tl:=Tl*leftson; {add saved tree as the rightmost subtree of Tl} do =null(T~) 
~ T.path:=T.path *rightson od ; T~:=rtree fi end Delete Figure 3: Binary Search Tree Operations To perform 
path operations in constant time, we need a representation of paths that allows us to extract and update 
list structures without traversing them. An obvious way to approach this problem is to represent a built-in 
path v.path as a pointer to v~. More precisely, since an update must change a field in the father of 
vL, a built­in path representation must contain the pair [pointer to the father, field selecting the 
aon]. For example, suppose v.value=(A (B C)) and v.path=<CDR, CAR, CDR> as illustrated in Figure 4. V.path 
is represented by the pair [pointer to node 3, CDR]. After the statement v1:=(D E), the CDR field of 
node 3 is changed to point to (D E) (i.e. node 5). V.path remains unchanged. We call the last node speared 
by a built-in v the \ 1 built-in m ~~ path v.path c NfL (a) before V1 := (DE) v 5 \ 1 A2 3 NIL m B m 
* E NIL (b) after V1 := (D E) Figure 4: Implementation of v1:=(D E) path (node 3 in the example in Figure 
4), the tar­ get node of the path. Since the address of the target node is stored in the path representation, 
we say that a built-in path points to its target node. TO implement assignment efficiently and to 
utilize space effectively, it is imperative that the implementation avoid recopying list structure whenever 
possible. However, we must ensure that updating a variable sharing list structure with other variables 
does not modify the other variables. In order to avoid the side effects when updating at the end of a 
built-in path, we must check that the speared nodes are not shared. Since we cannot explicitly check 
the appropriate reference counts in constant time, we simply prohibit the sharing of speared nodes. All 
path operations must maintain this invariant. In par­ ticular, extend must recopy the new target node 
if it is shared. As a result, we can safely imple­ment path updates by destructively modifying the target 
node. Using this approach, an update operation usually takes only constant time. In the unlikely event 
that the new components root is a speared node, the update operation must recopy all of the speared nodes 
of the new com­ponent. Each node has an . is speared bit so that it is manifest whether or not a node 
is speared. To implement the cons operation efficiently, we employ a reference counting scheme for storage 
management instead of garbage collection. Although real-time garbage collection is feasi ble [9], reference 
counting is a simpler, more elegant solution in the case of path operations. Since all destructive operations 
on variables in­volving paths have semantic definitions in terme of non-destructive operations (pure 
functions and simple assignment), it is impossible to form cir­ cular list structures. Consequently, 
a pure reference counting scheme can effectively manage storage without recourse to garbage collection. 
In fact, reference counting seems ideal for this particular situation because some form of refer­ence 
count information is necessary to implement paths efficiently. Without reference counts, we cannot tell 
whether or not a particular piece of list structure is shared, precluding the implemen­tation of update 
by destructively modifying the target node. In a conventional reference counting storage management 
system, freeing a node can force the reclamation of an unbounded number of nodes (all descendants of 
the freed node that become inacces­ sible after the node is freed). Hence, any opera­ tion that frees 
a node has unbounded running time. Fortunately, there is a simple modification to conventional reference 
counting (suggested by Bak­ er [9]) that evenly distributes the cost of storage reclamation over subsequent 
node alloca­ tions. The modified scheme, called lazy free-list . management, does not propagate the 
decrementing of reference counts generated by freeing a node until the node is reallocated. Since the 
reference count of a speared node is 1, we can use the reference count field of speared nodes as a back 
pointer. The back pointer supports the efficient implementation of the re­traction operation. 6. Removing 
Restrictions In g4 we placed three restrictions on the use of paths to facilitate efficient implementation: 
(1) Only one path can be associated with a struct variable. (2) Update operations cannot replace speared 
nodes. (3) To admit efficient implementation, path variables must be associated with a par­ticular struct 
variable.  We now sketch how these restrictions can be re­ laxed or eliminated by making minor changes 
to the implementation presented in Fj5. 6.1. Multiple Paths In some cases, it is advantageous to associ­ate 
more than one path with a structure. A good example is the problem of swapping two disjoint substructures 
within a variable. The natural, ef ficient way to perform this task is to embed two built-in paths within 
the variable. Fortunately, we can accommodate multiple built-in paths in­cluding block-structured allocation 
and dealloca­ tion by making only minor modifications to the Implementation. In order to maintain an 
accurate record of the speared status of nodes, we must keep a target count for each node, recording 
the number of built-in paths pointing to that node. Without target count information, the retract function 
cannot determine whether the unspeared target node is still speared by other built-in paths. (The target 
node remains speared if any of its children are speared or if any other built-in paths point to it.) 
Since target counts greater than 2 are un­ likely to arise much in practice, a space­ efficient implementation 
could use 2 bits to record the count and handle overflows either by storing the information in a hash 
table or by creating a dummy father node (accessible via the back pointer stored in the reference count 
field) to hold the oversize count and a back-pointer to the real father node. The efficient implementation 
of the shrink and grow operations requires the use of phantom nodes in the event that the replaced node 
is a also a target node. The replaced target node be­comes a phantom node containing a pointer to the 
correct path-ending node. The first time a path pointing to a phantom is referenced, it is fixed up to 
point to the proper target node. Phantom nodes eliminate the need to search all paths asso­ciated with 
a structure to find the ones that need fixing up after a shrink or grow operation. 6.2. Updates at Speared 
Nodes In g4, we outlawed updates that replace speared nodes because they could make a structure inconsistent 
with the path (or paths if multiple built-in paths are allowed) embedded within it. If we want to remove 
this restriction, we must formulate a policy on how to handle paths embedded within replaced structure. 
There are three basic choices: (1) All such paths become undefined (in­valid. ) (2) Each such path is 
embedded in the new structure, if possible. Otherwise it be­comes undefined. (3) Each such path is 
embedded in the result­ing structure on demand. Any attempt to dereference the path embeds it in the 
structure. In the meantime, extensions and retractions are permitted.  We will show how to implement 
the first alterna­t ive. The other choices require more complicated (but not more enlightening) implementations. 
 When an update operation attempts to replace a apeared node, all paths pointing to nodes in the replaced 
list structure must be invalidated. Since the target nodes corresponding to invalid paths are much easier 
to find than the path variablea themselves, we indirectly invalidate the appropri­ate path variables 
by searching the replaced structure and marking all the target nodes as in­valid . In the process, we 
free all speared nodes that are not target nodes and lazily reclaim the unspeared nodes. In addition, 
if the location of the update is not the target of some built-in path, then the update must unspear any 
speared nodes that are no longer on a valid path. Whenev­er a path variable pointing at an invalid node 
is either deallocated or assigned a valid value, we decrement the node s target count. When an in­valid 
node-s target count reaches zero, the node is returned to the free-list. Updates at speared nodes are 
clearly less efficient than updates at unspeared nodes; instead of constant time, they take time proportional 
to the number of speared nodes that are either unspeared or freed by the update. 6.3. Unbound Paths In 
the context of compiling programs with paths, we suspect that it is often possible to np­timize the implementation 
of a general path vari­able by embedding its representation in one or more value variables (just like 
a built-in path). Moreover, a compiler should be able to optimize the implementation of built-in paths 
in contexts where some operationa (such as retract) are not needed. Global optimization of path programa 
is one of our chief research interests. 7. Reasoning About Path Operations Since patha are ordinary sequences 
and path operations (other than assignment) are pure func­tions without side effects, it is straightforward 
to develop a simple first-order axiomatization including a structural induction schema for a data domain 
consisting of paths and recursive data structures. A previous paper [10] describes how to generate such 
an axiomatization. Within this for­mal system, we can treat recursive function defin­itions (as in Pure 
LISP) over the data domain as logical definitions extending the system [11]. Using this approach, we 
can prove theorems about paths and recursive data structures by using natural structural induction arguments 
like those in the Boyer-Moore LISP theorem prover [12], and the Stanford Typed Lisp verifier [13] [14]. 
In Appendix I we illustrate the approach by proving three sample theorems. 8. Reasoning About Procedural 
Programs Involving Paths To reaaon about imperative programs (programa involving assignment) using patha, 
it is suffi­ cient to apply Hoare style proof rules [15] or Dijkstra s predicate transformers [16] to 
reduce the correctness of an asserted program to the truth of a collection of sentences in the first 
order system described in the previous section. The only extension required ia the development of proof 
rules or predicate transformers to handle explicit and implicit (e.g. shrink) path-indexed assignment 
statements. To solve the problem, we simply treat path-indexed assignments like indexed assignments to 
ordinary arrays [17] [18]. The predicate transformer substitutes an entire updat­ ed value for the aggregate 
variable on the left hand side. Of course, the exact form of the predicate transformer for path-indexed 
assignments depends on the particular restrictions placed on paths by the language implementation. We 
will restrict our attention to general and built-in paths in the context of S-expressions where each 
struct variable is limited to a single built-in path. Let valid: patha X S-expreasiona ~ Boolean be a 
recursively defined function where valid(p, v) is true if and only if p is a valid path in v. Then, explicit 
path assignments to ordinary vari­ ables obey the predicate transformer: WP( V[P] :=E , R(V)) =valid(p, 
v) A R(update(v, p,E)) . Path-indexed assignment to struct variables are slightly more complicated because 
they must maintain an invariant. In this case the predicate transformer must include an additional precondi­ 
 9. ConcluaiOntion that asserts that the invariant holds: Paths are abstract data objects that wp( v.value[p] 
:=E , R(v)) correspond to the disciplined use of pointers in = valid(p, v) A updating recursive data 
structures, just as while reinitial segment(p, v.path) A R(struct~update(v.value, p, E), v.path)).  
loops correspond to the disciplined use of go to-s in performing indefinite iteration. Although mostInitial 
segment : path X path ~ Boolean is a paths are implemented with pointers, their seman­ recursively defined 
Boolean function that is true tics are defined in terms of simple abstractif and only the first path 
is a proper initial operations on recursive data structure. We be segment of the second one. Hence, initial 
segment lieve they constitute a positive step toward the(p, v.eath) iS t~e if and only if the root node 
of development of efficient very-high-level program­v.value[p] is speared. ming languages. Implicit path-indexed 
assignments performed by the shrink and grow procedures are treated in References the same way as their 
ekplicit counterparts. Each [1] Naur, P., Ed. Revised Report on the Algo­ procedure is equivalent to 
a simple assignment rithmic Language ALGOL 60. Comm. ACM 6, 1  statement. The call (Jan. 1963), 1-17. 
[2] Jensen, K. and Wirth, X. PASCAL: User Manual shrink(s) and Report. Springer Verl-w =, 1974.  where 
s is a strwct variable is semantically [3] McCarthy, J., et al. LISP 1.5 Programmer-a . Manual. MIT P~s~ 
Cambridge, Mass., 19657identical to the assignment: [4] Kennedy, K. and Schwartz, J. An Introduction 
s:= struct(s.value[head(e.path) ], tail(s.path)) to the Set Theoretical Language SETL. Comp. and Maths. 
with Appls. 1, 1, 97-119. where head and tail are car and cdr operations for [5] Hoare, C.A.R. Recursive 
Data Structures. CS paths, and struct is a constructor that forms a Report Stan-CS-73-400, Stanford U., 
1973. structure object from a path and a value. Simi­[6] McCarthy, J. A Baeis for a Mathematical larly, 
Theory of Computation, in Computer Program­ming and Formal Systems, P. Brafford and D. . Hirschberg Eds. 
North-Holland, Amsterdam,  grow(s, f, t) 1963, pp. 33-70. where e is a struct, t is an S-expression, 
and f [7] Hood, R. and Melville, R. Real Time Queue Operations in PURE LISP. CS Report TR80-433, is 
a field-selector, is equivalent to: Cornell U., 1980. s:= struct(update(t, f, s.value), <f>*e.path) . 
[8] Kernighan, B. and Ritchie, D. The C Program­ ming Language. Prentice-Hall, ~l~wood cliffs, 1978. 
Hence the predicate transformers for shrink and 9] Baker, H. List Processing in Real Time on a grow 
are: Serial Computer. Comm. ACM 21, 4 (April 1978), 280-~ wp(shrink(s), R(s))= 10] Cartwright, R. A 
Constructive Alternative to s.path#<> A Axiomatic Data Type Definitions. LISP R(struct(s.value[head(s.path) 
], Conference Proceedings, August 1980. tail(s.path))) 1111. . Cartwrixht R. and McCarthv. ., J. First 
Orderwp(grow(s, f,t), R(s))= Program~ing Logic. POPL Conference Proceed­ matom(t) A ings, January 1979. 
 R(struct(update(t, f, s.value),<f>*s.path) ) [12] Boyer, R. and Moore, J. Proving Theorems To demonstrate 
how easy it is to reason about about LISP Functions. J. ACM 22, 1, 122-144.  paths, we prove in Appendix 
II that the path solu­ [13] Cartwright, R. User-Defined Data Types as tion to the queue problem is equivalent 
to the Aid to Verifying LISP Programs, in Automata, Languages, and Programming, S. Michelson andinefficient 
Pure LISP solution. R. Milner, ~. Edinburgh Press, Edinburgh. 23 [14] Cartwright, R. A Practical Formal 
Semantic Definition and V~rification System for Typed LISP. AI M= 77-296, Stanford U., 1976. [15] Hoare, 
C.A.R. An Axiomatic Approach to Com­puter Programming. Comm. ACM 12, 10 (Oct. 1969), 332-329. [16] Dijkstra, 
E. A Discipline of Programming. Prentice-Hall, New York, 19%. [17] Cartwright, R. and Oppen, D. Unrestricted 
Procedure Calls in Hoare s Logic. POPL Conference Proceedings, Jan. 1978. [18] Gries, D. and Levin, G. 
Assignment and Pro­cedure Call Proof Rules. To appear in Trans. on Prog. Lang. and Sys. Appendix I Proof 
of Sample Theorems about Paths Let front, is queue, delete, and insert be speci fied by the following 
logical definitions: (a) front(z:list) ~ car(z) (b) is_queue(q:struct) = q.value:list points to end(q.value, 
q.path) . (c) points_to_end(z:list, p:psth) = if null(z) then p=<> else (p+<>) /l first(p) =CDR A 
points_to_end(cdr(z) ,rest(p)) (d) delete(z:list) ~ cdr(z) (e) insert(z:list, v:S-expr) ~ if null(z) 
then cons(v, NIL) else cons(car(z),inaert(cdr(z) ,v))  where first and rest are the usual sequence opera­ 
tions defined by: first(<sl, . . . ,sn>) = S1 rest(<sl, . . ..sn>) = (s2, . ..sn> We will prove: (1) 
Vz:list, p:path z+() A is_queue(struct(z, p)) ~ is queue(struct(z[first(p)], rest(p))) ~z[first(p)] 
=delete(z) (2) Vz:list, p:path,v:S-expr is queue(struct(z, p)) * ~s_queue(struct(update(z, p, cons(v, 
NIL)), P*<CDR> ) ) (3) vz:list, p:path, v:S-expr is_queue(struct(z, p)) ~  update(z, p, cons(v, NIL)) 
=insert(z, v) Proof of (l). The proof is a simple symbolic evaluation argument. Let z:list, p:path. Applying 
symbolic evaluation to tbe hypothesis yields: z+() A is_queue(struct(z, p)) ~z+() A z:list A points_to_end(z, 
p) ~z#() ~ p#<> A first(p) =CDR A points_to_end(cdr(z), rest(p)) . In this context, applying symbolic 
evaluation to the conclusion produces: is_queue(struct(z[<first(p)>] , rest(p))) A z[<first(p)>] =delete(z) 
e is_queue(struct(cdr(z), rest(p) )) A cdr(z)=cdr(z) * cdr(z):list A pointa_to_end(cdr(z) ,rest(p)) 
 * true Q.E.D. Proof of (2). The proof proceeds by induction on z. Base case: z = (). Let p:path, v:S-expr. 
Applying symbolic evaluation to the hypothesis yields: is_queue(struct(z,p)) ~ ():list A points_to_end(z, 
p) 63 p=<> Hence, applying symbolic evaluation to the conclusion produces: is_queue(struct(update(z, 
p, cons(v, NIL)), p*<cDR>)) ~ is_queue(struct(cona(v, NIL) ,<CDR>)) * cons(v, NIL):list A points_to_end(cons 
(V, NIL),<CDR>) H true ~ <CDR>+<> A first(<CDR>)=CDR A points_to_end ((),<>) ~ true  24 Induction step: 
Instantiating the induction hypothesis with Let z:list. P =rest(p), V =v yields: Given the induction 
hypothesis: is_queue(struct(z, rest(p)))+ Vp :peth, v-:S-expr is_queue(struct(update(z, rest(p), is_queue(struct(z, 
p-)) ~ cons(v, NIL)), is_queue(struct(update(z, p-, rest(p) *<CDR>)) cons(v-, NIL)), which (by symbolic 
evaluation) reduces to: P *<CDR>)), is_queue(struct(update(z, rest(p), we must show: (ii) cons(v, NIL) 
), Vu:S-expr, p:psth, v:S-expr { rest(p)*<CDR>) ) is queue(struct(cons(u, z),p)) + is_queue(struct(update(cons(u, 
z),p, Lemma: Vpl, p2:path cons(v, NIL)) , p1+<>+rest(p1*p2) =rest(p1)*p2 p*<CDR>)) . Let u:S-expr, p:path, 
v:S-expr. Proof of Lemma: The proof is a very easy induc- Applying symbolic evaluation to the tion on 
the structure of PI. The details hypothesis gives: sre left to the reader. Q.E.D. cons(u, z):list /l 
points to end(cons(u, z),p) By the lemma, the induction hypothesis (ii) e reduces to: is_queue(struct(cons(u, 
z),p)) update(z, rest(p), cons(v, NIL)):list A e points_to_end(update(z ,rest(p), p#<> A first(p) =CDR 
A cons(v, NIL)), points_to_end(z, rest(p)) . reat(p)*<CDR>) Similarly, applying symbolic evaluation to 
proving the conclusion (i). the conclusion yields: Q.E.D. update(cons(u, z), p,cons(v, NIL)):list A points_to_end(update(cons(u, 
z),p, Proof of (3). cons(v, NIL)), The proof proceeds by induction on the p*<cDR>) structure of the list 
z. Base case: z = (). cons(u, update(z, rest(p), Let p:path, v:S-expr. cons(v, NIL))):list A As in the 
preceding proof, symbolically p*<CDR>#<> A first(p) =CDR A evaluating the hypothesis yields: points_to_end(update( 
z, rest(p), is_queue(struct(l, p)) cons(v, NIL)), * rest(p*<CDR>)) p=<> e As a result, symbolically evaluating 
the update(z, rest(p), cons(v, NTL)):list A conclusion gives: (i) points_to_end(update(z ,rest(p), update(z, 
p,cons(v, NIL)) cons(v, NIL)), =insert(z, v) { rest(p) *<CDR>) . * cons(v, NIL) =insert(NIL, v) * true 
 Induction step: Let z:list. Given: Vp-:path, v :S-expr is_queue(struct(z ,p-)) ~ update(z, p , cons(v, 
NIL) =insert(z, v ), we must show: Vu:S-expr, p:path ,v:S-expr is_queue(struct(cons(u, z),p)) + update(cons(u, 
z), p, cons(v, NIL)) =insert(cons(u, z),v) . Let u:.s-expr, p:path, v:S-expr . As in the preceding proof, 
the hypothesis reduces to p#<> A first(p) =CDR A points to end(z, rest(p)) . . Applying symbolic evaluation 
to the conclusion produces: cons(u,update(z, rest(p), cons(v, NIL))) =cons(u,insert(z, v)) * update(z, 
p, cons(v, NIL)) =insert(z, v) Instantiating the induction hypothesis with p-=rest(p) and V =V yields 
(after symbolic evaluation) update(z, rest(p), cons(v, NIL)) =fnsert(z, v) proving the theorem. Q.E.D. 
Appendix 11 Proof of Correctness of Queue Implementation The queue implementation annotated with formal 
specifications appears below: function Qfront(q : struct) pre: true post: result = front(q.value) return 
car(q.value) eud Qfront procedure Qdelete(var q : struct) logical z:list, p:path pre: is_queue(q) A 
 q.value+() A q=struct(z, p) post: is_queue(q) A q= struct(delete(z) ,rest(p)) shrink(q) end Qdelete 
procedure Qinsert(var q : struct, v : S-expr) logical z:list, p:path pre: is_queue(q) A q=struct(z,p) 
post: is_queue(q) A q=struct(insert(z ,v), P*<CDR>) ql:=cons(v, NIL); q.path:=q.path *<CDR> end Qinaert 
 The specification primitives front, is queue, and insert, and delete are defined in Appendix I. To prove 
the correctness of the implementa­ tion we must prove the verification condition pre+wp(body,post) for 
Qfront, Qdelete, and Qinsert operation. Hence we must prove: (1) vq:stnlct true =+  wp( return car(q.value) 
, result = front(q.value)) . (2) kfq:struct, z:llst, p:path q.value+() A is_queue(q) A q=struct(z, p) 
~ wp( shrink(q) ,  is_queue(q) A q= struct(delete(z), rest(p))) .  (3) Vq:struct, v:S-expr, z:liat, 
p:path is_queue(q) A q=struct(z,p)~ wp( ql:=cons(v, NIL);  q.path:=q.path* <CDR> , is queue(q) A q= 
struct(inaert(z, v), p*<CDR>) ) . Proof of verification condition (l). Since we( return car(q.value) 
, result = front(q.value)) + car(q.value) = front(q.value), formula (1) reduces to: Tjq:struct car(q.value) 
=front(q.value) which is a trivial consequence of definition (a) of Appendix 1. Q.E.D. Proof of verification 
condition (2). Proof of verification condition (3). Since wp( shrink(q) , is_queue(q) A Since wp( q~:=cons(v, 
NIL); q=struct(delete(z), rest(p)) q.path:=q.path *<CDR> , e is_queue(q) A q= struct(insert(z, v), is_queue(struct(q.value[first(q.path) 
], p*<CDR>) ) rest(q.path))) A e struct(q.value[first(q.path) ], is_queue(struct(update(q.valua,q.path, 
rest(q. path)) cons(v,NIL)), = struct(delete(z), rest(p)) (ii) q.path*<CDR>)) A e struct(update(q.value,q.path,cons(v,NIL)), 
is_queue(struct(q.value[first(q.path) ], q.path*<CDR>) rest(q.path))) A { = struct(insert(z, v), P*<CDR>), 
(i) q.value[first(q.path)] = delete(z) A formula (3) reduces to: { rest(q.path) = rest(p), Vq:struct, 
v:S-expr, z:list, p:peth formula (2) raduces to: is_queue(q) A q=struct(z,p)+ (ii). ffq:struct, z:list, 
p:path Applying the second hypothesis yields: q.value+() A is_queue(q) A Vv:STr, z:liat, p:peth q=struct(z, 
p) + (i) . is_queue(struct(z,p)) =+ Applying the third hypothesis yields: ie_queue(atruct(update(z,,p,cons(v,NIL)), 
Yz:list, p:path p*<CDR>)) A is_queue(struct( z,p)) A z+()+ update(z,p,cons(v,NIL)) = insert(z,v) is_queue(atruct(z[first(p) 
], which ie the conjunction of theorems (2) and (3) rest(p))) A of Appendix I. z[firet(p)] = delete(z) 
A Q.E.D. rest(p) = rest(p) e $fz:list, p:path is_qaeue(atruct(z,p)) A z+()+ ls_queue(struct<z[firat(p) 
], rest(p))) A zlfirst(p)] = delete(z) which is theorem 1 of Appendix I. Q.E.D.   
			