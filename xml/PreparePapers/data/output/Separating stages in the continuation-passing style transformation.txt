
 Separating Stages in the Continuation-Passing Style Transformation Julia L. Lawall Olivier Danvy Department 
of Computer Indiana University jll@cs.indiana.edu Science * Department of Computing and Information Kansas 
State University t danvy@cis.ksu,edu Sciences Abstract The continuation-passing style (CPS) transformation 
is powerful but complex. Our thesis is that this transforma­tion is in fact compound, and we set out 
to stage it. We factor the CPS transformation into several steps, separating aspects in each step: 1. 
Intermediate values are named. 2. Continuations are introduced. 3. Sequencing order is decided and 
administra­tive reductions are performed.  Step 1 determines the evaluation order (e.g., call-by-name 
or call-by-value). Step 2 isolates the introduction of con­tinuations and is expressed with local, structure-preserving 
rewrite rules a novel aspect standing in sharp contrast with the usual CPS transformations. Step 3 determines 
the ordering of continuations (e.g., left-to-right or right-to-left evaluation) and leads to the familiar-looking 
continuation­passing terms. Step 2 is completely reversible and Steps 1 and 3 form Galois connections. 
Together they leading to the direct style (DS) transformation of our earlier work (including first-class 
continuations): 1. Intermediate continuations are named and sequencing order is abstracted. 2. Second-class 
continuations are eliminated. 3. Administrative reductions are performed.  A subset of these transformations 
can leverage program manipulation systems: CPS-based compilers can modify se­quencing to improve e.g., 
register allocation; static program analyzers can yield more precise results; and overspecified CPS programs 
can be rescheduled. Separating aspects of the CPS transformation also enablek a new programming style, 
wit h applications to non deterministic programming. As a byproduct, our work also suggests a new continuation 
semantics for unspecified sequencing orders in programming languages (e.g., Scheme). *Bloomington, Indiana 
47405, USA. Part of this work was sup­ported by NSF under grant CCR-9000597. tManhattan, Kansas 66506, 
USA. Part of this work was supported by NSF under grant CCR-9102625. Permission to copy without fee all 
or ,part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appbar, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. ACM-20th PoPL-1/93-S.C., USA G 
1993 ACM 0-89791 -561 -5/93 /0001 /0124 . ..$1 .50 1 introduction Continuation-passing style (CPS) terms 
enjoy a number of useful properties: They offer a good format for compil­ing and optimization [1, pages 
4 6] and the y enable non­trivial improvements for semantics-based program manipu­lation [6, 28]. CPS 
terms are independent of their evaluation order [29, 30] and CPS is at the basis of several mathemat­ical 
semantics of programming languages [12, 36]. On top of that, the CPS transformation occurs in several 
areas of theoretical Computer Science, including Category Theory [13, 26, 3 7] and Logic [17, 27]. In 
short, there is something truly fundamental in the CPS transformation, even though it can be expressed 
in only three lines for the pure J-calculus [29]: [Z]K = ttz [Ax. e]K = K(A2. Ak. [e]k) [eo el] K = [co] 
(Avo . [elJJ(Azrl . w VI K)) Figure 1: Plot kin s call-by-value, left-to-right CPS transfor­ mation The 
simplicity of this transformation is, however, de­ceiving. At least-three things happen in the CPS transfor­mation: 
Intermediate values are named, continuations are introduced forcing terms into tail-recursive form, and 
terms are sequenced [1, 9, 14, 16, 29, 33]. Our thesis is that the CPS transformation is in fact a compound 
transformation. We propose to stage the mapping between the DS world and the CPS world. We stage the 
mapping between DS and CPS terms as follows. First we restrict the DS and CPS languages so that continuations 
can be introduced and eliminated with­out dkturbing the structure of the source term. The re­stricted 
languages are called CoreDS and CoreCPS, respec­tively. Then we define a transformation between ordinary 
DS and CoreDS, and another transformation between ordi­nary CPS and CoreCPS. Thus the CPS and DS transforma­tions 
are staged as follows: DS ~ CoreDS ~ CoreCPS ~ CPS Our staged transformation shows a number of useful 
properties: t-i-+$ kl-.i+k kt-i-ki k~i-i l-x-+x kl­ k-k FAx.4+Ax. Ak. t I-io+;o I-t l+i] kEt o L=)-iJik 
 Figure 2: Restricted CPS transformation it does not require any administrative reductions. So it is 
both simpler to use and simpler to understand. For example, our earlier example f(Ax. x) directly yields 
the CPS term Ak. f(Az. Ak. kz)k without any administrative reductions. Here is the BNF of the restricted 
CPS terms A k. e pro­duced by this transformation: e ::= kt Is t ::= z IAz. Ak. e s ::= totl k where 
k is a meta-variable representing the set of all con­tinuation identifiers.3 We call this language the 
CoreCPS language for the A-calculus. The transformation can be rewritten more expressively in a natural 
semantics-style, as displayed in Figure 2. We use Stoy s diacritical convention [35] of overlining DS 
terms with an acute accent and CPS terms with a grave accent . Given a continuation k, a CoreDS term 
i is translated into a CoreCPS term, $ whenever k k 4-2. Correspondingly, a trivial DS term t 1s translated 
into a CPS term t whenever 1-t + ~, and, given a continuation k, a serious DS term 4 is translated into 
a CPS term ? whenever k 1-4 + ~. The resulting transformation is not only expressed with local and structure-preserving 
rewrite rules it is also re­versible, as shown by Figure 3. Given a cent inuation k, a CoreCPS term 
&#38; is translated into a CoreDS term d when­ever k R d .-?. Correspondingly, a trivial CoreCPS term 
; is translated into a CoreDS term ~ whenever + t + ? and, given a continuation k, a CoreCPS term ; is 
translated into a serious CoreDS term i whenever k F 4 @ 3. We capture this symmetry by merging the contents 
of Figures 2 and 3 in Figure 4. 2.2 Restoring expressiveness The CoreDS and CoreCPS languages do allow 
inverse CPS­and DS-transformations with local and structure-preserving rewrite rules, but these languages 
cannot directly express 3In the absence of control operators such as call/cc, one variable k is enough 
[8, 11, 31]. I Fi.mre 4: Restricted DS and CPS inter-transformations intermediate results, such as nested 
function calls. Let us now restore the expressiveness of the J-calculus. Essentially, the CPS-transformation 
names intermediate results [1, Sec­tion 1.1]. Observing that a name (i. e., a variable) is a trivial 
term, we only need a special form for naming intermediate results, with the constraint that it can be 
transformed into CPS with a local and structure-preserving rewrite rule. We choose to extend the BNF 
of serious CoreDS terms wit h a bind-expression: .. s .. ... I bind (xl, .... z~) = (s,, .... s~)in e 
A bind-expression provides a name x, for the result of evaluating a non-trivial term s: that may occur 
as an im­mediate sub-t erm in e. For example, a DS term such as (f X)(9x) yields the term bind (v, w) 
= (f c, gx)invw Symmetrically, unfolding all the bind-expressions yields a DS term. NB: In the rest of 
the paper, we use bind-expressions interchangeably with their higher-order abstract-syntax counterpart, 
combke (A(zl, .... xn) . e) (s1, .... sn) Correspondingly, we extend the BNF of serious CoreCPS terms 
wit h a schedule-expression: .. s .. ... I schedule (Ak. sl, .... ~k.s~) (J(zI, .... zn). e) A schedule-expression 
provides a name x, for the result of performing a computation .-l k. sl. For example, a term such as 
bind (w, w) = (fz, gz)in v w yields the term Jk. schedule (Ak. fzk, Ak. grk) (A(v, w). vwk) Choosirm, 
e,g., left-to-right sequencing-order t hen yields the CPS term Ak. fz(Av. g%(Aw. vwk)) Accordingly, we 
extend the inter-transformations of Fig­ure 4 with the rule displayed in Figure 5. This rewrite rule 
is local and structure-preserving. 3 A Scheme-like language We now generalize the above transformations 
to a more re­alistic DS language, by adding Scheme s constants, primi­tive operations, conditional expressions, 
and let-and letrec­expressions [4]. We also consider n-ary functions. e ::=cli\i I eo (cl, .... en) I 
op(el, .... em) I cond(el, e~, e~) I let (ii, .... in),= (cl, .... en)in e I letrec (il, .... Zn) = (1,, 
.... L)ine i ::= J(il, .... ire). e Constants are trivial. For simplicity we classify all the other new 
synt act ic constructs as serious. We use continuation­psssing primitive operators in the CPS world. 
The CPS transformation is displayed in Figure 6. Here is the BNF of the CPS terms A k. e this transformation 
pro­duces: e ::=kt I s t::= clili s .. . to (h, . . . . tn, Av. e) I op(tI, . . ..i~. Av. e) I cond(tl, 
e,, es) I letk=~v. eins I let (ii, .... in) = (tl, .... tn)in e I letrec (ii, .... in)= (11, .... L)ine 
1 ::= A(z1, .... in, k). e where v occurs once in J v. e. N13: Originally, we derived the BNF of CPS 
terms by in­duction over DS terms and over the possible values of K, in Figure 6. Since then, we have 
verified it using Malmkjax s analysis that takes a two-level J-term and produces the BNF of its result, 
based on abstract interpretation [22, 23]. Applying this analysis to the CPS transformer of Figure 6 
yields the same BNF as the one derived by hand. We use Malmkjax s analysis again in the following section. 
3.1 CoreDS and CoreCPS Along the lines of Section 2.2, we now define CoreDS for the Scheme-like language. 
In CoreDS again, all sub-terms but the actual parameters of bind-expressions are trivial. A CoreDS term 
e is defined by the following BNF: .. e .. tls ..   t .. Cizli to(tl,.. .%)I Op (h, .... k) cond(tl, 
ez, es) s : let (i,, :.., in) = (tl,... tn)in e letrec(il, .... in) = (11, .... L)ine I combine (A(zl, 
.... z~). e) (s1, .... s~) i ::= A(il, .... t~ ) .e Symmetrically, a CoreCPS term for the Scheme-like 
lan­guage has the form ~ k. e and is defined by the following BNii .. e .. ktls t ::= Clill to (tl, 
.... tn, k) I Op(tl, .... tm,k) cond(tl, ez, es) let (aI, .... in) = (tl,....tn)in e letrec(il, .... 
in) = (11, .... L)ine s :1 I schedule (~k. sl, .... ~k.s~) (A(zl, .... z~) .e) 1 ::= J(il, .... in, 
k). e As in Section 2.2, we can transform CoreDS terms into CoreCPS terms, using local and structure-preserving 
rewrite rules. These two transformations are exact inverses. They generalize Figure 5 and are presented 
in Figure 7. NB: These two transformations (minus the rule for combine-and schedule-expressions) can 
be derived using Consel s partial evaluator [5]. Specializing the CPS t ransfor­mation with respect to 
CoreDS yields one half of the trans­formation of Figure 7. Dually, specializing the DS transfor­mation 
with respect to CoreDS yields the other half of the transformation of Figure 7. 3.2 Conclusion To summarize, 
we have defined a CoreDS language as ex­pressive as the ordinary DS language, for both the A-calculus 
and the Scheme-like language. In CoreDS, the result of all serious subcomput ations are named. Similarly, 
CoreCPS is as expressive as CPS. In CoreCPS, all intermediate e continu­ations are named (by the parameters 
of expressions in the tu­ple argument to schedule). We have derived local, structure­preserving, and 
reversible transformations between the two languages. Let us now turn to the transformations between 
DS and CoreDS, and between CPS and CoreCPS. These transforma­tions are applicable to both the A-calculus 
and the Scheme­like language. They are described in the next two sections. 4 DS and CoreDS In CoreDS, 
serious subterms must be named, whereas in DS they may occur anywhere. Thus the transformations be­tween 
these two languages simply amount to introducing or eliminating names for serious expressions. Both transfor­mations 
preserve the implicit sequencing order of DS. This section is written in the spirit of the programming 
language Scheme, where sequencing order is unspecified [4]. Further refinements may be possible in a 
language that specifies a sequencing order, as, e.g., in Standard ML [25]. Nd DS ~ CoreDS u~ kl-k=i 
kkil~il ... kl-in+;n k 1-combine (A(rq, .. .. v~). d) (ii, .... .i~) + schedule (Ak. il, .... Ak.i~) 
(A(vI, . . . . vn). ?) Figure 5: Extended DS and CPS inter-transformations [c]X = Kc [2]K = Ki [/l(iI, 
.... in). e]tc = K(A (L, .... i~, k). [e]k) [eo (e], .... %)]K = [co] (AVO .[e~] (A VI . ...[en] (/lvn 
.vo (vi, .... vn, K)))) [ok(el, . . . . em)]6 = [cl] (AVI . ...[em] (Avm. (Jp (VI, .... v~, K)))) [cond(eo, 
el, ez)] 6 = [co] (A vo . let k = K in cond(vo, [cl] k, [e,] k) ~et (ii, .... in)= (cl, .... en)ine]~ 
= [cl] (~ q . ...[en] (A Vn let (21, .... in) = (VI, .... Vn) in [e]~)) IPetrec(fl, ...)= (-l(il, .... 
i~).e~, ...)ine]~ = letrec (~1, ...) = (A(il, .... am, k) .[e~jk, ...)in [e]~ where k is a fresh variable. 
A DS term e is transformed into CPS as A k . [e] k. Figure 6: The call-by-value CPS transformation kl-i~? 
1-A(il, . . . . in). 6++ A(il, ....in. k).&#38; E t o-io ... t-in-in t-io+ icl ... I-im++ im k+ t o(~1, 
....t n) U ~0(i, .... k k) k1-oj(~l, .... t ~) ~ o p(?I, ....?~,k) t-io ++ i) ... I-i .-in kki~i k h 
let (i], ,.., in) = (~1, .... ~n) in.+ * let (21, .... in) = (;1, .... in) in? t iO ++ i) ... kin.-jn 
kt-t+eb k t-letrec (ii, .... in) = ([1, .... in)in L * letrec (ii, .... in) = (jl, .... in)in~ Fieure 
7: Inter-translation between CoreDS and CoreCPS 4.1 Naming DS terms 4.3 A Galois connection The transformation 
from DS to CoreDS, J%(d,maps a com­pound term in which some immediate subterms are serious into a bind-expression 
naming all these serious subterms. Replacing the serious terms by their names yields the body of the 
bind-expression. For example, ~d((~ z) (g x)) = bind (v, w)= (&#38;(j z), Md(9 z)) invw s combine (A 
(v, w) . w w) (~d(.f *), ~d(g $)) Naming all the serious subterms in a single bind-expression preserves 
the sequencing order of the original term. The formals of the bind-expressions introduced by tid are 
fresh names, which makes it difficult to compare CoreDS terms. For simplicity we define equality on CoreDS 
terms to be equality up to a-equivalence of the formal parameters of bind-expressions. This definition 
of equality of CoreDS terms makes ~d into a function. In practice, CoreDS terms can be compared by simultaneously 
substituting fresh vari­ables for all the formal parameters of bind-expressions [34]. 4.2 Unnaming CoreDS 
terms Unnaming a CoreDS term with ~d corresponds to perform­ing the administrative reductions of the 
DS transformation. For each bind-expression, we either unfold all the bindings, substituting each named 
term for its name, or we residualize the entire bind-expression as a let-expression. Our strategy is 
similar to that used in partial evaluation [3]. We first consider the image of ~d. Because there are 
no bind-expressions in DS, ~d never produces a bind-expression where the body is another bind-expression. 
Additionally, each name bound by a bind-expression occurs exactly once, specifically as one of the t 
s in the BNF production of the body. If an expression denotes a CoreDS term in the image of tid, mapping 
it back to DS amounts to unfolding every bind-expression. On such terms, naming and unnaming are inverses. 
In addition to the terms in the image of J%(d,~d must ac­commodate terms that result from transforming 
CPS terms into CoreDS. Thus we extend it to the full BNF of CoreDS terms. To maintain the sequencing 
order, we simply resid­ualize as a let-expression any bind-expression that is not in the image of the 
transformation from DS to CoreDS. For example, bindv=fzingz is transformed into the DS term letv=jzingx 
More precisely, ~d unfolds a bind-expression whenever 1. The body is an application, a primitive operation, 
a conditional expression, a let-expression, or, degener­ately, an identifier and, 2. Each of the names 
bound by the bind-expression oc­curs exactly once and as one of the trivial subterms of the body.  
Otherwise the bind-expression is residualized into a let­expression. We now examine the relationship 
between ~d and Ud. While the transformations are not inverses on all terms, there are some terms, called 
normalized terms on which they are in­verses. For each language we give a semantics-preserving mapping 
from terms to normalized terms. Then, we show that the partial orderings generated by these functions 
are related as a Galois connection. Naming and then unnaming a DS term produces the orig­inal DS term, 
but the converse is not true. As described in the previous section, a bind-expression in the CoreDS term 
may be residualized into a let-expression in the DS term. These let-expressions remain let-expressions 
when translat­ing back to CoreDS. These problematic CoreDS terms are not in the image of ~d. Nd DS cc 
reDs u~ More formdy, ~d and .?/,j are related as fo~ows: L?/do Nd = IdentityD~ UdONdOUd = l?/d { We 
can trivially define a mapping SDS from DS terms to normalized DS terms, because the transformations 
are inverses on all DS terms. Hence we define Although /.&#38; and ~d are not inverses on all CoreDS 
terms, the following equation NdOud O&#38; Oud=Nd O&#38; which can be easily verified using the above 
equations, shows that they are inverses on terms that have been unnamed and then named again. Thus we 
can define a mapping SCO,CDS from all CoreDS terms into the set of normalized CoreDS terms, as follows 
b,.~s[e] = Nd(ud(e)) This mapping can be described inductively over CoreDS terms. We first give the 
rules for a bind-expression: 1. Whenever ud residualizes bind (ZI, . ..) = (sI, . ..) in e as a let-expression, 
Sc~,@s[bind (XI, ...)= (sl, ...) in e] = fijt$l;,...) = (SCO,,DSISI], . ..) . ..) = (w, . ..) in SCoreDS[e] 
~c~,.ms~bind (zl, ...) = (s1, ...)in e] = bind (ZI, ...)= (Sco,,~s[sI~, ...)in &#38;oreDS[e] 3. Finally, 
Sco,eDs[bind z = .sin z] = 5CoreDS[s] The rules for other terms are defined by straightforward in­duction 
over the structure of the term, as in the second case above. Using the mappings SDS andSco,eDs wemay 
define the partial orders~Ds and ~c,,,Ds on DSand CoreDStermsre­spectively. These partial orders relate 
terms tosemanticWy ­equivalent normalized terms, and are defined as follows. Again we use Stoy s diacritical 
convention of overlining DS terms with an acute accent and CoreDS terms with a grave accent . e;~Ds 
e; * e 2= e> { Together these two equations imply a Galois connection [24]: 4.4 Conclusion CoreDS was 
introduced as an intermediate language where the result of every serious expression is explicitly named, 
on the motivation that, given a CoreDS term, continuations can be introduced with local and structure-preserving 
rewrite rules. In this section, we have described the mappings J$(d and ud between plain DS terms and 
CoreDS terms, Sev­eral CoreDS terms may encode a single DS term. We have characterized this flexibility 
with a Galois connection, and have specified the corresponding partial orders on DS and on CoreDS terms. 
5 CoreCPS and CPS In CoreC!PS, intermediate continuations must be named, whereas in CPS they may occur 
anonymously. Thus the transformations between these two languages simply amount to introducing or reducing 
redexes that name continuations. Because the sequencing order of CPS is explicit, while that of CoreCPS 
is implicit in the definition of schedule, some care must be taken in the transformation from CPS to 
CoreCPS to preserve the intent of the CPS term. u= CoreCPS ~ CPS N. 5.1 Unnaming Core CPS terms The 
transformation U= unnames CoreCPS terms by (1) choosing a sequencing order and simplifying the schedule­expressions, 
and (2) by performing administrative reduc­tions over the resulting CPS term [29]. Choosing a sequencing 
order amounts to selecting a def­inition of schedule. The following function schedulez se­quences two 
computations from left to right: schedule2 = A (cl, C2) . AK . c1 (Aol . oz (Aw . K (q, 02))) Simplifying 
a schedule-expression amounts to moving its se­mantics into the syntax of the CPS term. 5.2 Naming CPS 
terms The primary task of the DS transformation is to encode a flat, tail-recursive term into a tree-like 
(in general non-tail recursive) term. This mapping from a flat, string-like term into a tree is reminiscent 
of parsing a concrete-syntax string into an abstract-syntax tree. Indeed, the analogy holds for CPS terms 
that encode the sequencing order of the DS lan­guage, e.g., left-to-right as in SML. For example, the 
CPS term Ak. f(z, Ave. g(z, Av,. wo(vl, Av2.h(z, Av3. v2(v3, k:))))) straightforwardly yields Terms that 
do not encode the sequencing order or that may contain side-effects or control-effects require a more 
de­tailed analysis, particularly if the DS language is Scheme, where the sequencing order of subexpressions 
is unspecified. For example, the term Ak. f(z, Awe. h(x, Av3. g(z, Avl. vo(ol, Av2. v2(v3, k))))) should 
yield Az.letvo =jzinlet v,=hzin(oo(g z)) v, We conjecture, however, that the sequencing order of most 
CPS terms is overspecified, and thus for most terms the straightforward tree-building algorithm applies. 
In any case, an effect analysis would come in handy here. 5.2.1 Canonically-sequentiafized CPS terms 
The task in naming a CPS term is to reconstruct the tree structure of the original DS term, hiding the 
sequencing cnr­der in the definition of the schedule operator. A CPS term essentially encodes a postfix 
traversal of this tree [7]. Each expression is evaluated tail-recursively and yields a value that is 
denoted by the actual parameter of the continuation. Once a parameter is used in a term to yield a new 
value, it is never used again. Thus the problem of const rutting a tree from a CPS expression is analogous 
to the problem of pars­ing a program written in a postfix language. In particular, independent subexpressions 
in a CPS term can be naturally detected using a stack. The transformation A(C traverses the continuation, 
push­ing the temporaries (i. e., the continuation parameters) on a stack. At consumption points (i. e., 
where the continu­ation parameters occur), we pop the stack and match the temporaries according to the 
sequencing order of the target DS language. For example, if the target language is SML where the sequencing 
order is left-to-right, then a prefix of the stack must equal the sequence of the temporaries of the 
expression. On the other hand, if the target language is Scheme where the sequencing order is unspecified, 
then we only require that the temporaries in the expression be equal to the set of temporaries on top 
of the stack. In a CPS term that encodes the sequencing order of the DS language canonically, the temporaries 
on the top of the stack are always the ones required. The evaluation of the corresponding expressions 
does not need to be explicitly se­ quenced. 5.2.2 Other CPS terms A CPS term is not, however, constrained 
to reflect precisely a postfix traversal of some tree. Temporaries need not be declared in a last-in, 
first-out fashion. If a subexpression is evaluated early, then the CPS term reflects a sequencing constraint 
that should be preserved in the CoreCPS term. In this case the temporaries at the top of the stack are 
not the temporaries required for the current expression, since one denotes the subexpression evaluated 
early. In that situation the expressions denoted by all the variables lower on the stack must be explicitly 
sequenced in the CoreCPS result. 5.2.3 Computational effects Side effects and control effects do not 
raise particular prob­lems in a language where sequencing order is fixed. In a language such as Scheme, 
however, some kind of effect anal­ysis is needed to avoid assuming that every expression has a computational 
effect otherwise we would have to trans­late a term such as A(z, k). j(z, Ave. g(z, Avl. vo(v,, k))) 
 iut o ~z.letffo=~zinvo(gz) instead of Am. jz(gz) Given safe effect information, a CPS term can be staged 
using the above algorithm, modified to sequentialize sub­terms that may contsin effects.  5.3 A Galois 
connection We now examine to what extent tic and Uc are inverses. For each language we give a semantics-preserving 
mapping from terms to normalized terms. Then, we show that the partial orderings generated by these functions 
are related as a Galois connection. As in the case of the naming and unnaming of DS terms (ct. Section 
4.3), the naming and unnaming of CPS terms are not inverse transformations. In fact the transformations 
are not inverses on either CoreCPS or CPS terms. u= CoreCPS ~ * CPS N. Naming and unnaming are not inverse 
transforma­tions on CPS terms because let-expressions may name continuations that are used only once. 
N. trans­forms all continuation-naming let-expressions into schedule­expressions. When the term is transformed 
back into CoreCPS a continuation-naming let-expression is introduced only if the continuation identifier 
occurs more than once. Thus the transformations are not inverses on CPS terms containing useless let-expressions. 
Because U. does not pro­duce these useless let-expressions, the transformations are inverses on the result 
of unnaming CoreCPS terms. The transformations are not inverses orI CoreCPS terms because Z4c moves nested 
let-and letrec-expressions out­ward. Because AfC does not create nested let-and letrec­expressions, the 
transformations are inverses on the result of naming CPS terms. More formally, NC and Z.4care related 
m follows: Ncouco Nc = N. U.ON. OU. = U. { These equations imply the following: u.o Ncou. oNc = t/coNC 
Ncouco N.ou. = Ncoi% { which say that the transformations are inverses on terms that have been named 
and unnamed once. We can thus define the functions SCPS and Sco,ecP5, which normalize CPS and CoreCPS 
terms respectively. Scps[e] = U.(N.(e)) { Sc.,.cps[e] = N.(~.(e)) SCPS and SCo,eCpS can be defined inductively 
over source terms using the observations outlined above. ScOrecP5 must be defined relative to a fixed 
sequencing order. Using the mappings SCPS and SCO,,CPS we may define the partial orders gCpS and ~c.,ecps 
on CPS and CoreCPS terms respectively. These partial orders relate terms to semantically-equivalent normalized 
terms, and are defined as follows. Again we use Stoy s diacritical convention of overlining CPS terms 
with an acute accent and CoreCPS terms with a grave accent . et ~cps e> ~ e; = UC(iVC(e\)) { e 1 gcorecps 
.5 * J2 = Nc(u.(e 1)) Together these two equations imply a Galois connection: ei ~CPS @(e 2) U &#38;(el) 
Zcorecps s 2  5.4 Conclusion The administrative reductions of the full CPS transforma­tion make it difficult 
to predict the shape of the result of transforming a DS expression. We have isolated these ad­ministrative 
reductions in the transformation from CoreCPS to CPS. The definition of the partial order on CoreCPS 
terms shows how the administrative reductions affect the shape of a term. The partial order on CPS terms 
reflects a mismatch be­tween how contexts may be specified in CPS and how they are specified in DS. Thus 
there is some flexibility in the relationship between CoreCPS and CPS terms. We have characterized this 
flexibility as a Galois connection. 5.5 Caveat This particular partial order may not be the most appropri­ate 
one, though, because the introduction and elimination of continuations is not order-preserving. For example, 
bindv=fz ~cO.eDs bind v = f z in bind w=gx in let w= v invw in bindw=gx invw  but introducing continuations 
in these two terms as specified by Figure 7 does not yield two terms that are related by the partial 
order LCO,,CPS. We are currently looking for partial orders that would be preserved by the introduction 
and elimination of continuations. 6 First-Class Continuations (outline) In an earlier work [11], we describe 
how to handle first­claas continuations in the DS transformation. The technique scales up to the staged 
transformation. Briefly stated, we instrument the BNF of CPS terms with the set of all the continuation 
identifiers that are lexically visible, and we re­lax the constraint that only the current continuation 
beap­plied. Instead we let any continuation identifier be applied. Then we analyze CPS terms to determine 
whether a contin­uation k is used exceptionally in a term e. We then need to distinguish terms where 
continuations are declared. Any declaration of a continuation that is used exceptionally is translated 
into a call/cc. Conversely, any application of a continuation that is not the current one is translated 
into a throw. Correspondingly, we instrument the BNF of DS terms with the set of all first-class continuation 
identifiers that arelexically visible, and we enforce that only acontin­uation identifier can be thrown 
values. 7 A complete example We consider the binary tree specified by the data type in Figure 8. This 
declaration and the corresponding control structure caseType are inspired by SML and usedin Consel s 
partial evaluator Schism [5]. We are using them for read­ability. Also for readability, we have maintained 
direct-style primitive operators in Figures 11 and 12. Let us determine whether a given tree of positive 
num­bers weighs more than a given number. Rather than first computing the weight of the tree and then 
comparing this weight with the number, we combine the comparison with computation of the weight, using 
call/cc to abort the com­putation as soon as the weight exceeds the number. This leads to more comparisons 
on average but to a potentially shorter tree traversal. The corresponding direct-style pro­gram is given 
in Figure 9. Let us transform this program into CoreDS by naming all intermediate (i. e., temporary) 
values. The result is given in Figure 10. We now turn this program into CoreCPS. Thanks to bind, the 
evaluation steps are explicit and we can express them as continuation abstractions, using a schedule 
expres­sion to sequentialize these abstractions. The resulting pro­gram is given in Figure 11. Finally, 
we can choose e.g., left-to-right sequencing order to transform the CoreCPS program into CPS. The resulting 
CPS program is given in Figure 12. Each step is reversible. First, continuations are named and continuation 
extensions (and thus sequencing order) are abstracted, thereby going from the CPS program of Figure 12 
to the CoreCPS program of Figure 11. Second, continua­tion abstractions are turned into evaluations of 
expressions, thus going from the CoreCPS program of Figure 11 to the CoreDS program of Figure 10. Third, 
expressions are in­lined (provided the order of their evaluation does not con­flict), leading from the 
CoreDS program of Figure 10 to the DS program of Figure 9. 8 Conclusion CPS is generally agreed to be 
useful but it overcommits a program to a particular sequentialization. We have factored out this commitment 
by separating stages in the CPS trans­formation: Proposition 1 (CPS transformation) Naming serious subterms 
in a DS term, introducing continuations in the res­ ulting CoreDS term, choosing a sequencing order, 
and un­ narning the resulting Core CPS term amount to transforming the DS term into 6 PS with respect 
to the same sequencing order. Proofi By composition. Unnaming the CoreCPS term amounts to performing 
the administrative reductions of the CPS transformation. Proposition 2 (DS transformation) Naming contiraua­ 
tions in a CPS term, eliminating continuations in the re­sulting Core CPS term, and unnaming the resulting 
CoreLM term amount to transforming the CPS term into DS, re­specting the sequencing order. Proof: By 
composition. Unnaming the CoreDS term amounts to performing the administrative reductions of the DS transformation. 
c1 Fundamentally, we have isolated the heart of the CPS and of the DS transformations i.e., the int 
reduction and elimination of continuations with local, structure­preserving, and reversible rewrite 
rules. The CPS and the DS transformations looked complicated because of red tape the administrative 
reductions [29]. We have isolated th~ red tape and characterized it with two Galois connections: naming 
and unnaming of DS and CPS terms. naming introduction of naming ~ values Core -L Core .- CPS DS ~ DS 
- Cps ~ continuations Galois Galois connection btjection connection This staging scales up to the call-by-name 
CPS transfor­mation [29] because this transformation can be staged into (1) thunk introduction and (2) 
call-by-value CPS transfor­mation [10]. Thus the call-by-value CPS transformation is a more basic CPS 
transformation, in some sense. 9 Issues and Future Work The CPS transformation must offer useful properties 
be­cause it is used in many places: for flow analysis [32], for parallelization [19], for compiling [1, 
33], and for partial eval­uation [2, 6], to name a few. Yet it is not easy to pinpoint which properties 
CPS offers that are not already therein DS, besides the obvious: CPS terms area subset of DS terms and 
thus they can be modeled and processed in a simpler way. A staged CPS-transformation such as the one 
presented here enables one to examine each stage to determine which one triggers which property. To this 
end, we need to refine the partial order over CoreDS and CoreCPS terms because the introduction and elimination 
of continuations is not order-preserving, cur­rently (ct. Section 5.5). Better partial-orders would make 
it possible to consider the transformation over a least term. (defineType Tree (Leaf value) (node left 
right) ) Fiszure 8: Binarv tree datatvDe declaration (define overweight? (lambda (x t) (call/cc (lambda 
(c) (letrec ([traverse (lambda (t) (let ([v (caseTv~e t [(Le~2 value) value] [(mode left right) (+ (traverse 
left) (traverse right) )1 )] ) (if (> w x) (throw c *t) 8)))1) (let (L (traverse t)]) *f)))))) Figure 
9: DS program ( define overweight? (lambda (x t) (call/cc (lambda (c) (letrec ( [traverse (lambda (t) 
(let ([w (casaType t [(I,eaf value) value] [(mlode left right) (bind ([1 (tr~verse left)] [r (traverse 
right )1 ) (+ 1 r))])]) (if O w x) (throw c *t) u)))]) (bind ([v (traverse t)] ) (let ([­ vI) #f))))))) 
Figure 10: Staged DS program (all intermediate values are named) (define overweight? (lambda (X t C) 
(letrec ( [traverse (lambda (t k) (let ([k (lambda (v) (let ([u vI) (if (> =x) (c #t) (k w))))]) (caseType 
t [(Leaf value) (k value)] [(node left right) (schedule (list (lambda (k) (traverse left k)) (lambda 
(k) (traverse right k)) ) (lambda (1 r) (k (+ 1 r))))])))]) (schedule (list (lambda (k) (traverse t k))) 
(lambda (v) (let ([-v]) (c *f)))))) Figure 11: Staged CPS program (all intermediate continuations are 
abstracted) (define overweight? (lambda (x t c) (letrec ( [traverse (lambda (t k) (let ([k (lambda (v) 
(let ([w v]) (if (> u x) (c #t) (k u))))]) (caseTypa t [(1.eaf value) (k value)] [( Iiocle left right) 
(traverse left (lambda (1) (traverse right (lambda (r) (k (+ 1 r))) ))1)))1) (traverse t (lambda (v) 
(let ([­ vI) (c *f))))))) Figure 12: CPS program with left-to-right sequencing order &#38; [(EII El 
. . . En)] p K = ap~is (permute (~ [Eo] p, .... &#38; [En] p)) (( A(to, .5,, .... en). fapplicate co 
(151,.... cn) 6) o rmperrnute) where K = E*+C permute : (K+ c)* + (K+ c)* unpermute : E* + E applicate 
: E+.E*+K+G single : (E+C)+K apli8 : (K + C)* +K-FC aplis = A(fo, .... fn). A K. fo (single(A 60 . ...fn 
(sing/e(A6n .K (60, .... En)))...)) and apks is the only new auxiliary function in the formal semantics 
of Scheme. Figure 13: Denotational semantics of applications, in Scheme (fragment) 133 &#38; [(Eo El 
. . . En)] p K = schedde (t [Eo] p, .... t [En] p) (A (60, 61, .... Cn) . applicateco (cI, .... fn) 6) 
 where ~ schedule appkate = : : ll +c (K -C)* + E+E*4K-+C K+C and schedule is the only new auxiliary 
function in the formal semantics of Scheme. Figure 14: Denotational semantics of applications, in Scheme 
(revised fragment) Then we could determine to which extent it would be suf­ ficient to simplify a term 
within the same style (i.e., DS, CoreDS, CoreCPS, or CPS) rather than transforming it into another style. 
 10 Applications 10.1 The Scheme programming language A few years ago [20], Jones and Muchnick proposed 
a pro­ gramming language design based on binding times in­cluding lexica,l-andysis time, syntax-analysis 
time, macro­expansion time, semantics-analysis time, code-generation time, link-time, and run-time. They 
also proposed that the compiler for such an ideal programming language should be structured in phases 
corresponding to each of the bindhg times, and that no reference should be made to an earlier binding 
time. Our staged CPS-and DS-transformations fol­low this spirit by separating evaluation order from sequenc­ing 
order. They can also be applied to the Scheme program­ming language as follows. According to the semantics 
of Scheme [4], sub-expr­essions in an application are evaluated in an unspecified order (a controversial 
issue among Scheme programmers). Our C H transformation remains uncommitted with respect to the sequencing 
order and thus it suggests we rephrase a part of the Scheme semantics as follows. The formal semantics 
of Scheme [4, Sections 7.2.3 &#38; 7.2.4] uses two inverse functions permute and unper­rnute to ensure 
the sequencing-order independence of sub­expressions in an application. These functions map a piece of 
abstract syntax into a new piece of abstract syntax, hiding the fact that this semantics is actually 
compositional [35]. From the point of view of binding-times, this specification freezes the sequencing 
order at syntax-analysis time. Our uncommitted CPS transformation enables one to delay this permutation 
until a later binding-time, by permuting the cornput at ions of these sub-expressions. Figure 13 presents 
the new fragment specifying the semantics of applications, and Figure 14 re-expresses it in terms of 
:schedule. In addition, unscheduled CPS introduces a new style of CPS programming, without oversequentialization, 
e.g., to simulate nondeterminism. 10.2 Compile-time analyses Let us now assess the new possibilities 
offered by this staged transformation, and whether we can isolate the use­fulness of the CPS transformation 
into one of the stages. CoreCPS seems quite promising as an intermediate language for compile-time analyses. 
It enjoys many of the useful prop­erties of both DS and CPS. Instantiating a CoreCPS term with any scheduling 
strat­egy yields a CPS term. Therefore, CoreCPS enjoys the same traditional advantages as CPS and leads 
to naturally for­ward program analyses4 [6] and simpler program analyzers [32]. Accordingly, compile-time 
analyses still yield more pre­cise results, both intra-procedurally and inter-procedurally [2, 6], given 
CoreCPS-transformed terms [28]. Compile-time analyses benefit from CPS to differing de­grees. Binding-time 
analysis produces better information on CPS terms because information moves across the boundaries of 
conditionals and procedure calls. Here sequencing order is irrelevant, so ordinary CPS is adequate. On 
the other hand, while the fact that sequencing order is explicit in CPS terms improves single-threading 
detection, Fradet observes that whether a variable is classified to be single-threaded may depend on 
the choice of the sequencing order [15]. By main­taining the boundaries between independent subexpressions, 
CoreCPS allows the single-threading analysis to determine the best sequencing order for each expression 
locally, when it makes a difference. Finally, some analyses do not benefit from CPS transforming the 
source program. For example, analyses for register allocation require reordering indepen­dent subexpressions 
to produce useful results. This reorder­ing is notoriously complex on CPS terms, but in CoreCPS the independent 
subexpressions are easily accessible. The analysis can proceed almost unchanged, taking advantage of 
the bijection between CoreCPS and CoreDS terms. Acknowledgments We are grateful to Dan Friedman for his 
support and to the other members of the programming language groups of In­diana University and Kansas 
State University for their feed­back. Special thanks to Andrzej Filinski, Jiirgen Koslowski, Karoline 
Malmkj=r, and David Schmidt for commenting an earlier draft, and to the referees for their guidance. 
4Since CPS terms are tail-recursive, there is nothing to propagate backwards but the final result. The 
diagrams illustrating the separation of stages were [15] drawn with Kristoffer Rose s ~-pic package. 
[16]References [1] Andrew W. Appel. Compiling with Continuations. Cambridge University Press, 1992. [17] 
[2] Anders Bondorf. Improving binding times without ex­ plicit CPS-conversion. In LFP 92 [21], pages 
1 10. [3] Anders Bondorf and Olivier Danvy. Automatic auto­ projection of recursive equations with global 
variables and abstract data types. Science of Computer Program­ [18] ming, 16:151 195, 1991. [4] William 
Clinger and Jonathan Rees (editors). Revised4 report on the algorithmic language Scheme. LISP Pointers, 
1V(3):1-55, July-September 1991. [19] [5] Charles Consel. Report on Schism 92. Oregon Graduate Institute, 
Beaverton, Oregon, October 1992. Research Report. [20] [6] Charles Consel and Olivier Danvy. For a better 
support of static data flow. In Hughes [18], pages 496-519. [7] Olivier Danvy. Three steps for the CPS 
transforma­ tion. Technical Report CIS-92-2, Kansas State Univer­ [21] sity, Manhattan, Kansas, December 
1991. [8] Olivier Danvy. Back to direct style. In Bernd Krieg- Briickner, editor, Proceedings of the 
Fourth European [22] Symposium on Programming, number 582 in Lecture Notes in Computer Science, pages 
130-150, Rennes, France, February 1992. [9] Olivier Danvy and Andrzej Filinski. Representing con­ trol, 
a study of the CPS transformation. Mathematical Structures in Computer Science, 2(4), 1992. To appear. 
[23] [10] Olivier Danvy and John Hatcliff. Thunks (contin­ ued). In Proceedings o~ the Workshop on Static 
Anal­ ysis WSA 92, volume 81-82 of Bigre Journal, pages 3 11, Bordeaux, France, September 1992. IRISA, 
Rennes, France. [24] [11] Olivier Danvy and Julia L. Lawall. Back to direct style II: First-class continuations. 
In LFP 92 [21], pages 299­ 310. [12] Matthias Felleisen and Robert Hieb. The revised report on the syntactic 
theories of sequential control and state. Theoretical Computer Science, 103(2):235-271, 1992. [25] [13] 
Andrzej Filinski. Declarative continuations: An inves­ tigation of duality in programming language seman­ 
[26] tics. In David H. Pitt et al, editors, Categorg Theory and Computer Science, number 389 in Lecture 
Notes in Computer Science, pages 224-249, Manchester, UK, September 1989. [27] [14] Michael J. Fischer. 
Lambda calculus schemata. In Proceedings of the ACM Conference on Proving Asser­ tions about Programs, 
pages 104-109. SIGPLAN No­ tices, Vol. 7, No 1 and SIGACT News, No 14, January 1972. [28] PSSCSJ Fradet. 
Syntactic detection of single-threading using continuations. In Hughes [18], pages 241-258. Daniel P. 
Friedman, Mitchell Wand, and Christopher T. Haynes. Essentials of Programming Languages. MIT Press and 
McGraw-Hill, 1991. Timothy G. Griffin. A formulae-as-types notion of cou­trol. In Proceedings of the 
Seventeenth Annual ACM Symposium on Principles oj Programming Languages, pages 47-58, San Francisco, 
California, January 1990. ACM Press. John Hughes, editor. Proceedings of the Fifth ACM Conference on 
Functional Programming and Computer Architecture, number 523 in Lecture Notes in Computer Science, Cambridge, 
Massachusetts, August 1991. William L. Harrison III. The interprocedural analy­sis and automatic parallelization 
of Scheme programs. LISP and Symbolic Computationj 2(3/4):179-396, Oc­tober 1989. Neil D. Jones and Steven 
S. Muchnick. Some thoughts towards the design of an ideal language. In ACM Con­ference on Principles 
of Programming Languages, pages 77-94, 1976. Proceedings of the 1992 ACM Conference on Lisp and Functional 
Programming, San Francisco, California, June 1992. Karoline Malmkjzer. On static properties of specialized 
programs. In Michel Billaud et al., editor, Analg9e Sta­tigue en Programmation Equationnelle, Fonctionnelie 
et Logique, volume 74 of Bigre Journal, pages 234 241, Bordeaux, France, October 1991. IRISA, Rennes, 
France. Karoline Malmkjzer. Predicting properties of residual programs. In Charles Consel, editor, ACM 
SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, Research Report 909, 
Depart­ment of Computer Science, Yale University, pages 8 13, San Francisco, California, June 1992. Austin 
Melton, David A. Schmidt, and George Strecker. Galois connections and computer science applications. 
In David H. Pitt et al., editors, Category Theory and Computer Programming, number 240 in Lecture Notes 
in Computer Science, pages 299 312, Guildford, UK, September 1986. Robin Milner, Mads Tofte, and Robert 
Harper. The Definition of Standard ML. The MIT Press, 1990. Eugenio Moggi. Computational lambda-calculus 
and monads. In Proceedings of the Fourth Annual Sgmpfi sium on Logic in Computer Science, pages 14 23, 
Pa­cific Grove, California, June 1989. IEEE. Chetan R. Murthy. An evaluation semantics for classi­cal 
proofs. In Proceedings of the Sixth Symposium on Logic in Computer Science, pages 96 107, Amsterdam, 
The Netherlands, July 1991. IEEE. Flemming Nielson. A denotational framework for data flow analysis. 
Acts Injormatica, 18:265-287, 1982. [29] Gordon D. Plotkin. Call-by-name, call-by-value and the J-calculus. 
Theoretical Computer Science, 1:125-159, 1975. [30] John C. Reynolds. Definitional interpreters for higher­order 
programming languages. In Proceedings of 25th ACM National Conference, pages 717-740, Boston, 1972. [31] 
Am, Sabry and Matthias Felleisen.. Reasoning about programs in continuation-passing style. In LFP 92 
[21], pages 288-298. [32] Olin Shivers. Control-Flow Analysis of Higher-Order Languages or Taming Lambda. 
PhD thesis, CMU, Pittsburgh, Pennsylvania, May 1991. Technical Report CMU-CS-91-145. [33] Guy L. Steele 
Jr. Rabbit: A compiler for Scheme. Tech­nical Report AI-TR-474, Artificial Intelligence L abo­ratory, 
Massachusetts Institute of Technology, Cam­bridge, Massachusetts, May 1978. [34] Allen Stoughton. Substitution 
revisited. Theoretical Computer Science, 59:317-325, 1988. [35] Joseph E. Stoy. Denotational Semantics: 
The Scott-Stracheg Approach to Progravnming Language Theory. MIT Press, 1977. [36] Christopher Strachey 
and Christopher P. Wadsworth. Continuations: A mathematical semantics for handling full jumps. Technical 
Monograph PRG-11, Oxford Uni­versit y Computing Laboratory, Programming Research Group, Oxford, England, 
1974. [37] Philip Wadler. The essence of functional programming (tutorial). In Proceedings of the Nineteenth 
Annual ACM Symposium on Princtpies of Programming Lan­guages, pages 1 14, Albuquerque, New Mexico, January 
1992. ACM Press. [38] Mitchell Wand. Correctness of procedure represen­ tations in higher-order assembly 
language. In Steve Brookes, Michael Main, Austin Melton, Michael Mis-Ilove, and David Schmidt, editors, 
Mathematical Foun­dations of Programming Semantics, volume 598 of Lec­ture Notes in Computer Science, 
pages 294 311, Pitts­burgh, Pennsylvania, March 1991. 7th International (Conference.   
			