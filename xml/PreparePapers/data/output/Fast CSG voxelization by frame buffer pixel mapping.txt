
 Fast CSG Voxelization by Frame Buffer Pixel Mapping Shiaofen Fang1 Duoduo Liao Department of Computer 
and Information Science Indiana University Purdue University Indianapolis ABSTRACT This paper describes 
a fast algorithm for the volume conversion and rendering of CSG models constructed from both geometric 
and volumetric primitives. Using 3D texture mapping and frame buffer pixel operations, the algorithm 
can interactively generate a binary volume of the CSG model. The result can be used for volume ren­dering 
and other applications. Boolean operations are implicitly computed by a Point-Classi.cation Map, and 
implemented by a hardware assisted frame buffer pixel map. The algorithm can be applied to any regions 
of interest of the model, thus provides a multi-resolution rendering solution through dynamic voxelization 
of the viewing regions. Since no pre-processing is required for any change of the CSG tree, it can be 
used as an effective rendering tool in a volumetric CSG modeling environment. Keywords voxelization, 
CSG modeling, volume rendering, 3D texture mapping.  1 INTRODUCTION The Constructive Solid Geometry 
(CSG) representation allows users to de.ne complex 3D solid objects by hierarchically combining simple 
geometric primitives using Boolean operations and af.ne transformations [14, 9]. It is a very popular 
and powerful solid modeling scheme, and is particularly suitable for interactive ob­ject manipulations 
and design. Traditionally, CSG primitives are de.ned by simple analytic objects, such as cubes, cylinders 
and spheres. Some recent CSG algorithms can also support primitives that are general solid models de.ned 
by their boundary surfaces. Using voxel-based volume representations, a further extension can include 
objects extracted from volume data sets using intensity thresh­olding. These volume data sets may come 
from various types scan­ning of real objects, such as CT, MRI, and microscopy images, or from the sampling 
of implicit or procedural functions. Such ex­tended CSG models are sometimes called Volumetric CSG models 
[7, 6], and are very useful in applications such as medical imaging, 1723 W. Michigan St., SL 280, Indianapolis, 
IN 46202. e-mail: sfang@cs.iupui.edu Permission to make digital or hard copies of all or part of this 
work for personal or classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation on the first 
page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior 
specific permission and/or a fee. Volume Visualization 2000 Salt Lake City, Utah USA Copyright ACM 2000 
1-58113-308-1/00/10 ... $5.00 surgical simulation, and amorphous phenomenon modeling. For the simplicity 
of presentation, in this paper, we will still refer to this extended model as CSG model. Due to the lack 
of explicit representation of surface boundaries, CSG display is not directly supported by standard graphics 
sys­tems. Although several interactive CSG rendering algorithms have previously been developed [8, 13, 
17, 20], they cannot be directly applied when volume data sets are involved. In principle, there are 
two potential solutions for the rendering of volumetric CSG mod­els. The .rst is to explicitly extract 
an iso-surface from the vol­ume data set, and convert the model into a regular geometric CSG model, which 
can then be displayed by an existing CSG rendering algorithm. This method is, however, very slow and 
dif.cult for two reasons: (a) the iso-surface extraction process is time-consuming, and (b) the extracted 
iso-surface normally contains an extremely large number of tiny polygons, which are dif.cult and expensive 
to display and operate. The second solution is to .rst convert the CSG model into a voxel-based volume 
representation, and then dis­play the resulting volume using a standard volume rendering algo­rithm. 
This solution, however, requires a fast volume conversion (voxelization) process for volumetric CSG models. 
The voxelization problem for general curve and surface objects have been extensively studied [5, 4, 10, 
11, 16]. Voxelization algo­rithms for more complex models have also received more research attention 
recently. Conceptually, CSG voxelization is a set mem­bership classi.cation problem with respect to the 
CSG object for all sampling points in a volume space. Early CSG voxelization meth­ods can date back to 
the spatial enumeration representation by point classi.cation [12]. More recent work includes the Beam 
Oriented method [15], the volume sampling method [18], the point sampling algorithm [1], the octree-based 
algorithm [7], and the distance vol­ume algorithm [2]. A common problem of these algorithms is that the 
voxelization is slow and does not support interactive modeling applications. In [6], we described a hardware 
accelerated CSG voxelization algorithm that uses combinations of frame buffer blending func­tions to 
carry out the CSG Boolean operations. Although that al­gorithm is reasonably fast for small scale interactive 
applications, its performance have been limited by the need of generating an in­termediate texture object 
for each Boolean operation node, and by the hardware restrictions in blending function combinations. 
In this paper, we present a new CSG voxelization and rendering algorithm that employs a Point-Classi.cation 
Map (PCM) for Boolean oper­ations based on a frame buffer color encoding scheme. The result is a binary 
voxelization of the CSG model, which can be used for volume rendering and other applications. The algorithm 
is clearly faster than the one given in [6]. To overcome the volume resolu­tion limitations, this algorithm 
can also be applied to any regions of interest of the model. This provides a natural multi-resolution 
rendering solution for the rendering of different scales of the CSG scene. Since the dynamic changes 
of the CSG tree do not require any pre-processing time in this algorithm, it is particularly suitable 
for the interactive volumetric CSG modeling applications. In the following, we will .rst discuss, in 
Section 2, some ba­sic concepts and de.nitions regarding CSG modeling using vol­ume data sets. The Point-Classi.cation 
Map (PCM) method will be described in Section 3. Section 4 presents the binary CSG vox­elization algorithm. 
The CSG volume rendering process using the voxelization result is described in Section 5. Section 6 discussed 
some implementation issues and results. We conclude the paper in Section 7 with some further remarks 
and future work.  2 THE CSG MODEL Let a scalar volume Vbe represented by an intensity function I(P), 
where Pis sampled over a 3D regular grid in a volume space. A solid object can be extracted from a volume 
by thresholding with an intensity interval [s;tn(s>t). More speci.cally, a point P belongs to the object 
if and only if I(P)2[s;tn. This process may also be de.ned as a thresholding operation Fs;t:V!R3,i.e. 
F)fP2R3 :I(P)2g Fs;t](V[s;tn Multiple intensity intervals may also be used in the thresholding operation. 
The result is the union of the objects de.ned by the individual intensity intervals: . 3 FS(V)fP2R:I(P)2[si;ting 
Fsi;ti] In general, a CSG model can be constructed by the following two types of primitives: 1. A general 
solid model de.ned by its boundary surfaces. 2. A solid object de.ned by a thresholding operation from 
a volume data set.  The thresholding operation provides additional .exibilities through the changes 
of the thresholding intervals to generate objects from different layers of the volume. This can be considered 
part of the CSG editing process, and is an essential feature for the designing of volume based objects. 
It should be mentioned that although vol­ume data sets are used, the Boolean operations are only carried 
out with the (binary) solid objects extracted from the volume data. An example of such CSG models is 
given in Figure 1. The binary voxelization of a CSG model is the process of gen­erating a binary volume 
of the CSG model within a given volume domain (region of interest). Only 0and 1intensity values are gen­erated 
in binary voxelization, with 1representing an inside point and 0outside point. The result from the binary 
voxelization can be directly rendered, as a solid object, by 3D texture mapping. It can also serve as 
a volume space mask for the volume rendering of the CSG model using the original data sets. If the binary 
volume is considered as a spatial enumeration representation of the CSG ob­ject, it can also be used 
in many other solid modeling applications such as integral property computation, .nite element analysis 
and layered manufacturing. Figure 1: A CSG model using a CT data set. T: af.ne transforma­tion; F: thresholding 
operation n=p+q bits 0 . . . qi*2 +j 2n-1 p bits q bits 0 . . . i . . . 2p -1 Figure 2: Combining 
two PCMs  3 POINT-CLASSIFICATION MAP An essential component of a CSG voxelization process is the mem­bership 
classi.cation of points in a volume space with respect to the 3D object represented by the CSG model. 
For a given CSG tree, The .nal CSG classi.cation of a point is uniquely determined by its classi.cations 
with respect to all the CSG primitives. This relationship is de.ned by a Point-Classi.cation Map (PCM) 
that maps a complete primitive classi.cation result to an in/out CSG classi.cation. If the CSG tree has 
nleaf nodes (primitives), numbered from 0 to n,1,an n-bit binary number can be used to encode the classi­.cation 
results of a point with respect to all nprimitives. We call this binary number the classi.cation index.A 
1at the jth bit of the index indicates that the point is inside the jth primitive, and a 0indicates outside. 
Thus, for a given CSG tree, the classi.cation index uniquely determines the .nal CSG classi.cation. Since 
there are only 2ndifferent possible classi.cation indices, a look-up table of 2nentries (i.e. the Point-Classi.cation 
Map) will be suf.cient to describe all possible point classi.cation cases. The PCM of a CSG tree can 
be easily constructed by the following recursive procedure. PCM PROCEDURE CSG_PCM (CSG_NODE N) BEGIN 
 IF (N is a leaf node) RETURN the PCM of the primitive; ELSE PCM_left = CSG_PCM (N.left); PCM_right 
= CSG_PCM (N.right); PCM_combined = combine (PCM_left, PCM_right, N.op); RETURN PCM_combined; ENDIF 
 END This procedure recursively computes a PCM table for a bi­nary node by combining the PCM tables 
of its two child nodes, as shown in Figure 2. The index domain of the combined PCM is the Cartesian product 
of the index domains of the two sub-PCMs. The combined classi.cation result is simply a binary Boolean 
op­eration (given by the CSG node) of the classi.cations in the two sub-PCMs, i.e. cc1op>c2. In practical 
implementation, a common PCM memory space can be shared by all levels of recur­sive calls to avoid unnecessary 
memory resource consumption.  4 CSG VOXELIZATION In this section, we present a hardware accelerated 
CSG voxelization algorithm using certain hardware features in 3D graphics systems. The required graphics 
system features include the polygon based graphics engine, frame buffer pixel map and logical operations, 
and 3D texture mapping. In the following, we will .rst describe a basic algorithm that does not consider 
the frame buffer depth lim­itation. In fact, it assumes that each pixel of the frame buffer has as many 
bits as the number of primitives in the CSG tree. This basic algorithm will then be modi.ed to accommodate 
the frame buffer limitation. 4.1 A Basic Algorithm A cubic volume space is .rst de.ned over the CSG model. 
The algorithm proceeds slice-by-slice in a front-to-back order by mov­ing the Z-plane, a plane parallel 
to the projection plane, along the viewing direction to generate slices for all primitives (as shown 
in Figure 3). For each slice, the algorithm de.nes the viewing volume of the system as the thin space 
between two adjacent Z-planes in­side the volume boundary, and then renders each primitive within this 
viewing volume. When the algorithm moves from Z-plane to Z-plane, slices of the primitives are displayed 
and composited onto the frame buffer in a front-to-back order. Using proper color cod­ing of the the 
primitives, the algorithm can directly generate slices of the point classi.cation indices in the frame 
buffer. These classi­.cation indices can then be mapped, by the PCM, to form a binary volume of the CSG 
model. The PCM can be implemented by the frame buffer pixel map de.ned in OpenGL, which is basically 
a color look-up table for frame buffer pixels. The distance between adjacent Z-planes determines the 
resolution of the volume in the Z direction. The resolutions in the X and Y directions are determined 
by the size of the display window. If the CSG tree has nprimitives, ndistinct colors are assigned to 
different primitives so that the color code of the jth primitive is a binary number, with the jth bit 
set to 1and all other bits set to 0. For a spatial point P,the color of Pwith respect to the jth primitive, 
Cj(P), is de.ned as the color of the jth primitive if Pis inside the primitive, and 0otherwise. Now, 
if we com­bine C1(P);C2(P);;Cn(P)using a logical operation OR or XOR, the result, C(P), is exactly the 
classi.cation index of point P. Thus, for each Z-plane, the algorithm generates a slice for each primitive, 
and then composites the slices from the primitives into one single slice of classi.cation indices in 
the frame buffer using appropriate frame buffer pixel functions. This composition process is carried 
out differently for the two different types of primitives: For a primitive de.ned by its surface boundaries, 
since only the boundary surfaces are drawn, we need to have a way to determine the interior points. The 
idea is similar to the solid voxelization algorithm described in [4, 6], and is based on the principle 
that when a ray is shot from a pixel towards the jth primitive in the viewing direction, it has to enter 
the primitive object .rst (jth color bit becoming 1) and stay there (keep­ing the jth bit 1) until it 
exits the object (changing the jth bit to 0). This can be done by drawing the boundary surfaces of each 
primitive with a logical XOR operation. The clip­ping hardware of the graphics engine will ensure that 
only the parts of the surfaces within the thin viewing volume are displayed. When a slice is complete, 
the frame buffer will not be cleared, i.e. the frame buffer content of the slice will be used for blending 
operations with the subsequent slices. This way, the XOR operation will automatically set the jth color 
bit to 1for all interior points, and 0for all outside points. Since the pixel colors on the slice generated 
by the jth primitive has 0 s at all bit positions except the jth, the XOR operation for the jth primitive 
will have no effect to the classi.cations of other primitives.  If a primitive, say the ith primitive, 
is de.ned by a volume data set, its Z-plane can be rendered by 3D texture mapping using the texture object 
de.ned by the volume data set. A color look-up table may be used to de.ne a transfer function that maps 
the intensity values within the threshold interval of the ith primitive to the primitive s color and 
other intensity values to 0. Apparently, multi-interval thresholding opera­tions may also be similarly 
de.ned.  Before drawing the Z-plane, however, the ith bit needs to be cleared for all pixels on the 
frame buffer. This cannot be done by simply clearing the entire frame buffer since the bits for all geometric 
primitives need to be retained for the XOR operation. We can, however, draw the Z-plane, as a solid color 
polygon using a color that is the binary complement of the ith primitive s color with a logical AND frame 
buffer operation. This basically set the ith bit to 0for all pixels in the frame buffer while keeping 
all other bits unchanged. Once the classi.cation indices are generated in the frame buffer for each slice, 
the Point-Classi.cation Map can be applied to the frame buffer image to generate the .nal CSG classi.cations. 
The result (for each slice) will then be copied to the texture memory as one slice of the .nal volume. 
Using the frame buffer pixel map, the above two steps can be combined into one. The pixel map is a hardware 
implemented look-up table that maps the color of each pixel in current frame buffer to a new color. Once 
de.ned, pixel map can be invoked by any frame buffer image operations, includ­ing the copy operation 
from frame buffer to texture memory. In other words, the PCM is automatically applied during the process 
of copying the frame buffer image to the texture memory. This process will be repeated for each Z-plane, 
leading to a complete bi­nary volume representation in the texture memory. The following procedure summarizes 
this algorithm: PROCEDURE CSG_Voxelization (CSG_NODE root) BEGIN Generate a cumulative transformation 
matrix for each primitive; Define texture objects for all volume primitives; Assign color codes to 
all primitives; pcm = CSG_PCM(root); Clear frame buffer; FOR (each Z_plane) BEGIN Define the thin 
viewing volume; FOR (each primitive) BEGIN Define system transformation matrix; IF (geometric primitive) 
 Set the XOR logical operation; Set the primitive s color; Render the primitive; ELSE Clear the frame 
buffer s color bit for this primitive; Bind 3D texture; Set color look-up table; Set OR logical operation; 
 Draw Z-plane by 3D texture mapping; ENDIF END Define frame buffer pixel map using pcm; Copy frame 
buffer to texture memory; END END  4.2 Region-Based Voxelization In order for this algorithm to work 
correctly, the slicing process has to start from the outside of the object. In other words, the object 
needs to be completely contained by the volume space. Conse­quently, the volume space may need to be 
made very large. Since the size (resolution) of the volume is limited by the system memory and the texture 
memory, large spatial region can lead to low reso­lution voxel representations of the object details. 
But in order for this algorithm to work correctly, the slicing process has to start To overcome this 
problem, the voxelization process should be applied on-the-.y to only a region of interest (e.g. the 
viewing region) of the scene. With a .xed sized volume representation, region-based dy­namic voxelization 
leads to a natural multi-resolution volume ren­dering approach with desired level of details for different 
viewing regions. This region-based voxelization process, however, requires a small modi.cation of the 
basic voxelization algorithm. The basic algo­rithm assumes that the slicing process starts from the outside 
of all primitives. But when the Z-plane starts from the front face of a subregion of the spatial domain, 
the XOR operation may not work correctly for all pixels since the parity is no longer guaranteed for 
every pixel. If we de.ne the 0th slice as the space between the .rst Z-plane of the region and the z,1plane, 
as shown in Figure 3, this 0th slice can be used to represent and store information about the starting 
status of each pixel. To generate the content of the 0th slice, we can draw all the geometric primitives 
once using the 0th slice as the viewing volume, with the XOR logical operation set for the frame buffer. 
The resulting frame buffer image will then be car­ried over to the voxelization process to ensure proper 
parities for all the pixels. X  4.3 A Multi-Pass Approach There are two frame buffer limitations that 
restrict the implementa­tion of this algorithm: 1. The bit depth of the frame buffer is normally limited 
to 8to 32bits. The common RGBA frame buffer has 8bits for each component of the RGB color, and another 
8bits for the alpha channel. 2. The frame buffer pixel map used to implement the PCM can only have separate 
look-up tables for individual RGBA com­ponents. Therefore, we can have four look-up tables of 256 (8bits) 
entries, but not any cross combinations.  Thus, in general, the basic voxelization algorithm can only 
han­dle a CSG tree with eight primitives, i.e. using only one color com­ponent of the frame buffer bits 
and the corresponding pixel map. To overcome this limitation, a multi-pass approach can be employed for 
large CSG trees. The idea is to repeatedly apply the basic vol­ume conversion algorithm to subtrees of 
the CSG tree. At each step, a subtree with at most 8primitives is chosen and voxelized into a texture 
object in the 3D texture memory. This texture object is then used to replace the entire subtree as a 
new volume primi­tive. Repeating this process will lead to an iterative trimming of the CSG tree, which 
eventually will be small enough to be directly voxelized. This multi-pass algorithm will have some speed 
penalty from the extra traf.c between the frame buffer and the texture mem­ory. But from our experience, 
the overhead is fairly small. This is mainly because that reading from frame buffer to texture mem­ory 
is a very fast and direct cache operation that does not take up main memory cycles. Another drawback 
is that it puts more pressure on the texture memory requirement, since several intermediate volumes may 
need to be stored in the texture memory simultaneously, potentially caus­ing more frequent texture memory 
swapping, and consequently a performance penalty. One way to reduce the number of intermedi­ate volumes 
is to always choose the subtree with the most number of volume primitives, so that the old volumes can 
be replaced by the newly generated volume. Nevertheless, for large CSG trees, the texture memory swapping 
between the multiple passes is in­evitable. But as long as the texture memory can hold all the texture 
objects simultaneously for each pass (at most eight texture objects), texture memory swapping is not 
a serious problem since it only oc­curs once for each pass.  5 CSG VOLUME RENDERING The result from 
the above voxelization process is a binary volume stored in the system s texture memory. It can be directly 
rendered by 3D texture mapping [3, 19], or written to the main memory for other applications. A common 
problem in the direct rendering of binary volumes is that it often suffers severe aliasing problem due 
to the lack of gray level intensity data for smooth surface boundaries. The problem can, however, be 
alleviated by a multi-pass 3D texture mapping approach. Since 3D texture mapping uses trilinear interpolations 
for sample points around the surface boundaries of the object, the interpolated results will have intensity 
values between the 0 and 1 binary values. This essentially generates some gray level intensity data around 
the surfaces, and has a similar effect as an anti-aliasing process in surface rendering. For smoother 
results, this process can be iteratively repeated by writing each texture mapped slice (without blending) 
from frame buffer back to the texture memory as a slice of a re.ned volume. In general, more iterations 
generate smoother surfaces, with higher rendering cost. But our experiments show that two or three iterations 
are normally suf.cient for reason­ably smooth surfaces. For CSG models involving volume data sets, it 
is also possible to generate blended images using the intensity values in the original data sets. This 
is done by using the binary voxelization result as a 3D mask that extracts, slice-by-slice, the volumetric 
portion of the model from a union of the rendering results of the volumetric prim­itives. For each slice, 
all the volumetric primitives are .rst individ­ually rendered and combined in the frame buffer using 
a logical OR operation (or any other desired blending function). The part of this slice that is within 
the spatial region of the CSG model is then extracted by drawing the same slice from the mask (by 3D 
texture mapping) using a logical AND frame buffer operation. To avoid part of the binary volume being 
removed by the AND operation, a white background needs to be used in drawing the slices for the volumetric 
primitives. Since the primitives can be rendered using their original volume data, better blending results 
can be achieved. 6 IMPLEMENTATION The volume conversion and rendering algorithm described in this paper 
has been implemented on an SGI Onyx-2 workstation us­ing a single processor Reality Engine and 64MB texture 
memory. For large CSG trees, the multi-pass volume conversion algorithm is used with 8primitives processed 
in each pass. The program is written in C and OpenGL 1.1. In the examples shown in Figure 4, each model 
is converted into a 1283binary volume. Among the primitives used, a CT head and a knot object are volume 
data sets. The rest are all synthetic geometric primitives. A zoom-in result of (f) is given in (i). 
All the images except (d)(e)(h) are generated directly from the binary voxelization results using a two-pass 
texture mapping approach as described in Section 5. Images in (d)(e)(h) are generated using the 3D mask 
approach. Timing data for these examples are shown in the following ta­ble. The timings are affected 
mainly by three factors: (a) the com­plexity of the scene, (b) the size of the frame buffer window, and 
(c) the number of slices. The scene complexity determines how fast the graphics system can render the 
scene during the slicing process. The window size determines the size of the slices in the resulting 
volume, which (along with the number of slices) in turn affects the voxelization speed due to the large 
number of image movements between the frame buffer and the texture memory. sample image a b c d e voxelization 
time (sec) 0.61 0.96 0.6 0.32 1.4 number of primitives 13 5 14 4 4 sample image f g h i voxelization 
time (sec) 0.84 0.22 0.22 0.73 number of primitives 12 3 3 12  7 CONCLUSIONS A fast CSG voxelization 
and rendering algorithm is described in this paper. Since volume techniques are used, volume data sets 
can be naturally included in the CSG construction process. Such CSG models allow solid modeling and CAD/CAM 
applications to input objects from sampled or scanned data sets in the design and manufacturing processes, 
and are also potentially useful for other applications involving both geometric objects and volume data 
sets, such as surgical simulation and biomedical data exploration. Our algorithm makes use of commonly 
available graphics hardware fea­tures, and is able to provide interactive feedbacks for the modi.ca­tion 
and manipulation of general CSG models. Thus, it can be an effective tool in interactive CSG modeling 
and volume graphics en­vironments. Several future works are being planned. The current algorithm is only 
able to use one color channel of the frame buffer memory. We would like to investigate an approach that 
can make full use of all 32frame buffer bits in the point classi.cation process for better performance 
with large CSG trees. The algorithm has so far only been tested on relatively small CSG trees. The applicability 
and performance of this algorithm on very large scale CSG problems (e.g. thousands of primitives) still 
need to be tested and analyzed.  REFERENCES [1] D. E. Breen. Constructive cubes: CSG evaluation for 
display using discrete 3D scalar data sets. In Eurographics 91, pages 127 142, 1991. [2] David E. Breen, 
Sean Mauch, and Ross T. Whitaker. 3d scan conversion of CSG models into distance volumes. In Proc. IEEE/ACM 
symposium on Volume Visualization, pages 7 14, 1998. [3] Brian Cabral, Nancy Cam, and Jim Foran. Accelerated 
vol­ume rendering and tomographic reconstruction using texture mapping hardware. In Proc. 1994 Symposium 
on Volume Vi­sualization, pages 91 98, October 1994. [4] Hongsheng Chen and Shiaofen Fang. Fast voxelization 
of 3D synthetic objects. ACM Journal of Graphics Tools, 3(4):33 45, 1999. [5] D. Cohen and A. Kaufman. 
Scan-conversion algorithms for linear and quadratic objects. In A. Kaufman, editor, Volume Visualization, 
pages 280 301, 1991. [6] Shiaofen Fang and Hongsheng Chen. Hardware accelerated voxelization. In Volume 
Graphics, Chapter 20, pages 301 315. Springer-Verlag, March 2000. [7] Shiaofen Fang and R. Srinivasan. 
Volumetric CSG a model­based volume visualization approach. In Proc. 6th Interna­tional Conference in 
Central Europe on Computer Graphics and Visualization, pages 88 95, 1998. [8] J. Goldfeather, J. Molnar, 
S. Turk, and H. Fuchs. Near real­time CSG rendering using tree normalization and geometric pruning. IEEE 
Computer Graphics and Application, 9:20 28, 1989. [9] Christoph M. Hoffmann. Geometric and Solid Modeling: 
An Introduction. Morgan Kaufmann Publishers, 1989. [10] Arie Kaufman. Ef.cient algorithms for 3D scan-conversion 
of parametric curves, surfaces, and volumes. In SIGGRAPH 87, volume 21, pages 171 179, July 1987. [11] 
Arie Kaufman and Eyal Shimony. 3D scan-conversion al­gorithms for voxel-based graphics. In Proceedings 
of 1986 Workshop on Interactive 3D Graphics, pages 45 75, October 1986. [12] Y.T. Lee and A. A. G. Requicha. 
Algorithms for computing the volume and other integral properties of solids. Communi­cations of the ACM, 
25(9):635 650, 1982. [13] Ari Rappoport and S. Spitz. Interactive Boolean operations for conceptual design 
of 3D solids. Computer Graphics, SIG-GRAPH 97, pages 269 278, August 1997. [14] A. A. G. Requicha. Representation 
for rigid solids: Theory, methods and systems. Computing Surveys, 12(4):437 464, December 1980. [15] 
Naeem Shareef and Roni Yagel. Rapid previewing via volume-based solid modeling. In Solid Modeling 95, 
pages 281 292, May 1995. [16] Milos Sramek and Arie Kaufman. Object voxelization by .l­tering. In Proc. 
IEEE/ACM symposium on Volume Visualiza­tion, pages 111 118, 1998. [17] W. C. Thibault and B. F. Naylor. 
Set operations on polyhedra using binary space partitioning trees. SIGGRAPH 87, pages 153 162, 1987. 
[18] Sidney Wang and Arie. Kaufman. Volume-sampled 3D mod­eling. IEEE Computer Graphics and Application, 
14:26 32, September 1994. [19] R. Westermann and E. Thomas. Ef.ciently using graphics hardware in volume 
rendering applications. In SIGGRAPH 98, pages 169 177, 1998. [20] T. F. Wiegand. Interactive rendering 
of CSG models. Com­puter Graphics Forum, 15(4):249 261, 1996.  (a) (b) (c) (d) (e) (f) (g) (h) (i) 
  Figure 4: Some rendering examples 
			