
 A PSYCHOMETRIC THE JOB Department ABSTRACT Job Diagnostic Survey (JDS) is instrument in research focusing 
and motivation. Based Oldham s Job Characteristics generally used to examine spond to job design. It 
used in the MIS literature characteristics of system on STUDY OF THE JOB CHARACTERISTICS SCALE OF DIAGNOSTIC 
SURVEY IN AN MIS SETTING Maung K. Sein of Decision Sciences and Information College of Business Administration 
Florida International University University Park, Miami, FL 33199 Robert P. Bostrom Department of Management 
College of Business Administration Systems University Athens, a widely used on job design Hackman and 
Theory, it is how workers re­has been especially to measure the job professionals and their motivation 
and satisfaction level with their jobs, and their role perceptions. Yet JDS has been widely criticized 
for its suspect factor structure. Several psychometric studies JJilv G UGCIJ GUILUUGICU, VGIY to replicate 
the factors Hackman-Oldham model. searchers have found that ture varied depending on other job related 
factors. incs the dimension ality of JGW llLIVG UCCIJ iJUJC postulated by the Consistently, re­the proposed 
struc­the profession and This paper exam­the job characteris­ tics scale of JDS in a sample consisting 
of analysts and programmers. The factor struc­ ture that emerges suggests that factors may relate to 
analysts and mers. It is recommended that JDS with caution especially in a non-ho sample. ACM CPR 91 
different program­be used mogenous Permission to copy without fee alt or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy other­ wise, or to republish, requires a fee and/or 
specific permission. @ 1991 ACM 089791-389-2/91/0003/0096 $1.50 of Georgia GA 30602 INTRODUCTION The 
manner in which design of their jobs examined research decades or so both in 1967; Goldstein, 1989; workers 
respond to the has remained a much issue over the past 3 MIS (Blood and Hulin, Goldstein and Rockart, 
1984) and in organizational behavior (Davis and Taylor, 1972; Rizzo, House, and Lirtzman, 1970). Job 
design alters or reformats certain aspects or characteristics of a job thus chang­ing the task requirements 
of the worker or the worker role. This change in the task design in turn leads to a change in the work­ers 
perception about their jobs. The exist­ence of a relationship between job character­istics and worker 
outcomes has been docu­mented by numerous researchers in MIS and organizational behavior (Baroudi, 1985; 
Blood and Hulin, 1967; Bostrom, 1978; Hackman and Lawler, 1971; Mumford, 1972; Rizzo, House, and Lirtzman, 
1970; Rush, 1971; Shepard, 1970). MIS researchers have used Job Diagnostic Survey to measure job characteristics 
varia­ bles (Bostrom, 1978; Zviran, 1989; Couger, man, 1979; Goldstein, Rockart, 1984). The the job characteristics 
remained a debatable have examined its and concluded that structure is seldom Couger, Borovits, and 
Zawacki, and Opper­ 1989; Goldstein and true dirnensionality of scale of JDS has issue. Several studies 
psychometric properties the postulated factor replicated across all populations and occupations (Dunham, 
1976; Dunham, Aldag, and Brief, 1977; Fried and Ferris, 1986; Harvey, Billings, and Nilan, 1985; Idaszak, 
Bottom, and Drasgow, 1988; Idaszak and Drasgow, 1987; Katz, 1978; Kulik, Langner, and Oldham, 1988; 
Lee and Klein, 1982). The recommendation from this stream of literature has been that researchers should 
examine the factor structure of JDS before using it. [For brevity s sake we will refer to the job characteristics 
scale of JDS simply as JDS from here onwards. In other words, we will review the literature on psy­chometric 
studies of the job characteristics scale and not the entire JDS.] Unfortunately, MIS researchers have 
not heeded this advice. This is especially crucial because frequently JDS is administered to generic 
IS professionals without differenti­ating analysts and programmers. That differ­ences exist between these 
groups is well documented in MIS literature (Goldstein, 1989). The question is then whether it is appropriate 
to assume a uniform JDS factor structure for all classes of MIS professionals. In this study, wc examined 
the factor struc­ture of the job characteristics scale of the JDS for a population of MIS professionals 
consisting of programmers and analysts. We found that the factor structure proposed by JDS was not replicated 
for our sample. The structure that emerged suggested that differ­ent dimensions may relate to analysts 
and programmers. The rest of the paper proceeds as follows. The second section describes JDS in detail, 
reviews its use in MIS research and summa­ rizes the previous research on its dimensional­ ity. The third 
section describes this study and the data analysis. The fourth section discusses the findings and offers 
interpreta­ tions. The paper concludes with implications and directions for future research. DESCRIPTION 
OF JDS Overview The theoretical basis of JDS is Hackman and Oldham s Job Characteristic Theory (JCT) 
(Hackman and Oldham, 1980; Hackman and Oldham, 1975). In its basic form, JCT pro­poses that desired or 
affective worker out­comes (motivation, satisfaction etc. ) arc enhanced when three psychological states 
(experienced meaningfulness of work etc.) are present. The theory identifies measurable job characteristics 
or core iob dimensions that create the three psychological states. The model argues that these core job 
dimensions result from a particular organizational design decision e.g. the assignment of tasks to an 
individual. Thus, job design affects worker outcomes. This effect is moderated by indi­vidual difference 
variables labeled as modera­tors. The model is shown in Figure 1. In its entirety, JDS is an inventory 
of 103 items that forms 6 scales -job characteristics, experienced psychological states, reactions to 
work, individual growth need strength, indi­vidual social need, and job effectiveness performance. In 
the job characteristics scale, Hackman and Oldham (1975) had five core dimensions, namely, skill varietv, 
task identi­&#38;, task significance, autonomy and feedback from the iob. They also included two sup­plemental 
dimensions feedback from agents, and dealin ~ with others. In the considerable body of literature that 
examined the dimen­sionality of JDS, some researchers analyzed the first five factors (E. g., see Dunham, 
Aldag, and Brief, 1977.) while others includ­ed all seven dimensions. (E.g., see Harvey, Billings, and 
Nilan, 1985. ) In the current study, we considered the 7 factor model plus an eighth factor, learnin~ 
otI t20rtunitv. The last factor was introduced by Bostrom (1978) as it constitutes a key job dimension 
for MIS professionals. Thus, the instrument examined in this study had 8 a priori factors. It is shown 
in the Appendix. Use of JDS in MIS Research Researchers in MIS have used JDS to examine the influence 
of job related factors on such affective outcomes as job satisfaction (Bos­trom, 1978; Goldstein and 
Rockart, 1984) and motivation (Couger, Borovits, and Zviran, 1989; Couger and Zawacki, 1981; Couger, 
Zawacki, and Opperman, 1979). Other re­searchers have examined the conflict-handling issues in the job 
redesign process (Bostrom. 1978) and the perception of task differences between programmers and analysts 
based on their job characteristics (Goldstein, 1989). Each of these studies drew important conclu­sions. 
Couger concluded from his series of o $4 u w c1 ~ z 0 H v) 04 w > al z +-l  v 1 O.co UC5 Qt)E Lo.r-(o 
 studies (Cougcr, Borovits, and Zviran, 1989; Couger and Zawacki, 1981; Couger, Zawacki, and Opperman, 
1979) that specific aspects of an MIS professional s job had varied motivat­ing potential, For example, 
he found that feedback from supervisors is an area that needs improvement for MIS professionals. He also 
found that MIS managers differed from their employees in motivational levels as indicated by JDS. Couger 
et al. (1979) also found differences between MIS and non-MIS professionals based on their JDS scores. 
In a similar vein, Goldstein and Rockart (1984) and Bostrom (1978) found that job character­istics are 
highly correlated to job satisfaction. Goldstein (1989) found that different catego­ries of programmers 
and analysts viewed their tasks to be different and perceived different job characteristic to be more 
related to job satisfaction. Specifically, he found that those who are engaged in user support worked 
more autonomously compared to traditional pro­grammer/analyst. He also found differences among the subgroups 
on specific job charac­teristics. The confidence we can place on these find­ings is contingent upon the 
premise that the job characteristics measured through JDS is stable. In other words, all respondents 
are presumed to view the inherent dimensions in the same manner as postulated in the instru­ment. Should 
that not be the case, we have to question the conclusions of these studies, For instance, if the dimensions 
are not viewed in the same way by programmers and analysts, the differences in their observed perceptions 
may be attributable to the instrument rather than the existence of an actual difference. It is, therefore, 
important to examine the true dimensionality of the job characteristics scale of JDS. Prior mvchomctric 
studies of JDS Hackman and Oldham (1980) administered the JDS to 658 workers from 7 organizations and 
found high internal consistency (high within­scale correlations ranging from 0.56 to 0.88). The inter-scale 
correlations were low (0.12 to 0.28). They accepted this as evidence of multi -dime nsionality and did 
not feel the need to do a factor analytic study. Since then, several studies have been conduct­ed to 
examine the psychometric properties of JDS. The objective of each study was to determine if the factor 
structure proposed in Hackman and Oldham s original model was stable across different populations. Table 
summarizes these studies. The review of the literature provided here reveals that even after revisions, 
the true dimensionality of JDS remains a debatable issue. It needs to be examined especially when it 
is administered to a non-homogenous population consisting of employees of varying job, age and position 
level. Unfortunately, this fits precisely the description of MIS employees studied by researchers in 
the field (Bostrom 1978; Couger, Zawacki, and Opper­man, 1979; Goldstein, 1989; Goldstein and Rockart, 
1984), However, MIS researchers have accepted the dimensionality of JDS at face value and have not felt 
the need to determine its true factor structure. This study was conducted with the specific objec­ tives 
of determining the dimensionalitv of the job characteristics scale of JDS and identifv­in~ which combinations 
of items measured common dimensions. DESCRIPTION OF THE STUDY Sam~le JDS was administered to approximately 
250 personnel from 8 different organizations located in the midwest. Eighty of the re­spondents held 
clerical and other non-MIS jobs and were dropped from the study reduc­ing the sample size to 170. The 
organizations comprised of 4 manufacturing and 4 non­manufacturing concerns. The subjects were MIS personnel 
consisting of programmers, programmers/analysts and systems analysts. Table 2a summarizes the characteristics 
of the organizations and Table 2b shows the descrip­tive statistics of the sample. Data analvsis The 
SPSS package (Nie, Hull, Jenkins, Stein­brcnner, and Bent, 1975) was used to analyze the data. As the 
purpose of the study was to examine whether the factor structure pro­posed by the JDS was indeed valid 
for an MIS setting, Principal Components Factoring was considered most appropriate. This method TABIZ 
1 -Key psychometric studies of JDS Study Dunham, Aldag &#38; Brief (1977) Examined 5 factor structure 
on 20 samples of workers Harvey, Billings&#38;Nilan(1985) Examined 7 factor structure on 2028 National 
Guardsperson Fried &#38; Ferris (1986) Examined 5 factor structure on 6930 workers in 876 jobs in 56 
organizations Idaszak &#38; Drasgow (1987) Examined 5 factors structure with revised scale on 134 printing 
workers Idaszak Bottom &#38; Drasgow (1988) Examined 5 factors structure with revised scale on 5 worker 
populations. Revised the instrument to include twice the number of items per scale and ran simulations 
on 3 samples of of 75, 150 and 900 Kulik, Langner &#38; Oldham (1988) Compared revised and original instruments 
on 224 dairy workers Major Findinqs &#38; SucTcTestions *The 5 factors replicated 39 of the time *Suggested 
dimensionality be examined for every sample *The 7 factors not replicated *Negative items formed method 
factors *Suggested rewriting of items *The 5 factors replicated for younger, more educated and managerial 
workers *For the rest, a 3 factor structure emerged *Suggested JDS unstable across contexts (position), 
not jobs *The 5 factors replicated. *Suggested use of revised scale (no negative items) *obtained 3, 
4 and 5 factors for different samples *Suggested that statistical artifacts (small sample, few items 
per scale, range restriction) explain findings *Suggested sampling of workers from multiple job classes 
*The revised scale exhibited closer fidelity to JCT but prediction of job outcomes no better than original 
scale *Suggested recommended use of revised revised scale premature TABLE 2A -Organizational Characteristics 
Industrv Grou~in~s: Manufacturin~ Industries Number Chemical/allied products 1 Printing/publishing 1 
Food 2 Total 4 Non-manufacturing Industries Number Banking 1 Government 1 Public utility 1 Commodity 
merchandising 1 Total 4 TABLE 2B -Descriptive Statistics 1. Job Title FreQucncv Analyst 43 Programmer/a 
nal}vt 30 Programmer 97 Freauencv Male 129 Female 41 3. Educational background Frcauencv College degree 
120 (MIS/Conlputcr Sc major 35) No college degree 50 4. MIS Experience (in months) Total 72.5 2-246 
-Current Job 34.0 1 -169 transforms a given set of variables (items) into a new set of composite variables 
or principal components that are orthogonal (Kim and Mueller, 1978). The new set or factor structure 
represents a combination that account for more of variance in the data than any other set. It was therefore 
the most appropriate technique to achieve the objec­tives of the study. This technique has been used 
by several studies that examined the dimensionality of JDS. (E.g., see Dunham, 1976.) Preliminary to 
the actual analysis, the distri­bution of the variables was examined. The results did not show a serious 
violation of the normalcy assumption. The correlation matrix revealed only a low degree of association 
between some inter-scale items. RESULTS Findings We set the following criteria in seeking the most meaningful 
factor structure solution: 1. All the items must load to factors 2. There should be no multiple loading 
3. The solution should be interpretable. These criteria were considered vital in the study because the 
express purpose was valida­tion of an instrument which precluded item dropping, and examination of dimensionality 
which made multiple loading undesirable. The cutoff level for loading was set at 0.40 with factors retaining 
items with the highest loading. In order to determine whether the expected 8 factor structure emerged 
from the data, the initial analysis using varimax rotation speci­fied the number of factors to be extracted 
as 8. The results of the orthogonal rotation showed that the a priori factor structure was not replicated. 
The conclusion was based on the following observations: 1. One of the factors had a single item loading 
 2. One item did not load on any  factor and thus suggested that it be dropped. 3. Three items loaded 
on more than one factor. 4. Only two a priori factors -Feedback from Job and Task Significance -were 
partially replicated (2 items loaded along with a stray item).  As the next step, an 8 factor oblique 
rotation solution was tried. The results were, if any­thing, even less interpretable. Several items loaded 
on multiple factors, while 3 items did not load on any. The resultant factors were almost impossible 
to interpret meaningfully. The oblique solution was therefore discarded. It was obvious that an orthogonal 
factor structure existed and that the number of factors that would provide the m ost meaningf­ul and 
interpretable solution was not 8. Three separate solutions were then tried by specifying the number of 
factors to be ex­tracted as 5, 6 and 7. The 6 and 5 factor solutions were almost identical, with 2 factors 
from the 6 factor solution collapsing to form a single factor in the 5 factor solution. Both solutions 
had the shortcomings of item dropping, multipl e loadings and uninterpretability. Both SOIU­tions were 
therefore discarded in favor of the 7 factor structure which, for this sample, represented the most meaningful 
solution. Eigenvalues for the 7 factors were 7.76, 2.34, 1.72, 1.57, 1.40, 1.10 and 0.92. The last factor 
had an eigenvalue of less than 1. But it was retained because, as will be seen later, it has both practical 
and psychological significance. These criteria are considered to be primary bases for retaining a factor 
by Weiss (197 1), who further contends that under-factoring is a more serious error than over-factoring. 
Extracting too few factors leads to nlis-iden­tification of the true factor structure. As the purpose 
of this study was to identify precise­ly what the true structure was, it was decided to retain all 7 
factors. Moreover, all the items were retained only in this solution. Total variance accounted for was 
70 percent. One a priori factor -task significance -was partial­ly replicated (two a priori items loaded 
on this factor). The factor structure that emerged is shown in Table 3. TABLE 3-Extracted Factors Factor 
1 2 3 4 5 6 7 Items Section Section Section Section Section Section Section Section Section Section Section 
Section Section Section Section Section Section Section Section Section Section Section !%ction Section 
1 #4 1 #5 1 #8 2 #6 2 #7 2 #10 2#l 1 2 #12 2 *13 2 *15 1 #3 1 #6 2 *5 1 #2 2 #l 2 *3 1 #l 1 #7 2 #2 2 
#4 2 #8 2 #14 2 #9 2 #16 Loadings 0.52 0.62 0.86 0.81 0.52 0.85 0.51 0.52 0.62 0.41 0.78 0.61 0.71 0,83 
0.75 0.43 0.54 0.46 0.49 0.67 0.67 0.58 0.40 0.74 TABLE 4 -Factor Classes Analvsts Programmers General 
FACTOR 1 FACTOR 4 FACTOR 2 Learning Potential Job Identity Feedback FACTOR 5 FACTOR 7 FACTOR 3 Interaction 
Opportunity Learning Potential Job Variety FACTOR 6 Task Significance The criteria of associating items 
that loaded highest on a factor and also setting a mini­mum cut-off (0,40) presented some problems. For 
some factors, items with a 0.40 loading or greater were discarded because that item loaded higher on 
some other factor. At the same time an item with a lower loading was retained for this factor (factor 
3) simply because that item loaded highest on that factor. For instance Factor 3, item 208 (Section 2 
#8) loaded at 0.43 but was not retained as it loaded at 0.67 on Factor 6. However item 215 (section 2 
#15) with a loading of 0.41 was associated with this factor as this was the highest loading for that 
item. However, there were only 3 such cases. Inter~retation of the factor solution As noted, some a priori 
factors were partially replicated i.e. expected items loaded in a few cases on the expected factors. 
But there were a greater number of factors that had items from different a priori factor loading on them. 
A good example is Factor 4. Three items loaded on it, one each from the a priori Autonomy, Task Identity 
and Skill Variety factors. On first glance, this appears to be a stray factor. Closer examination of 
the items reveal a different picture. The questions related to an aspect of a job that requires high 
and complex skills, where the worker has a great degree of freedom but the job itself is a small part 
of the whole scheme. We can clearly recognize the job description of a programmer here. It also suggests 
a skilled technician or craftsman. This factor appears to be related to a programmer s Job Identitv. 
Another interesting factor is Factor 5. It is made up of 4 items -two each from the a priori feedback 
from the iob and dealing with other factors. A closer examination of this combination factor suggests 
that it is related to opportunity to interact with others. This appear to be related to an analyst s 
job. The factor structure that emerged appears to be reflective of the sample composition. Data were 
gathered from systems analysts, pro­grammer/analysts and programmers. These roles are vastly different 
in terms of interac­tion both with their own fellow professionals and users of MIS (Goldstein, 1989). 
A pro­grammer s job calls for highly skilled person­nel, is repetitive and is performed in relative isolation. 
A systems analyst, on the other hand, has to deal with a wide variety of users and other clients. A programmer 
s job can be viewed as operating in a relatively narrow domain, while a systems analyst, mainly due to 
a far greater degree of interaction with others, has more job variety. Programmer/analyst is a combination. 
Given this understanding of the sample, the factor structure that surfaced appear to be meaning­ful. 
Clearly some factors are programmer­related while others are systems analyst-relat­ed. Based on a close 
examination of the items that loaded on the factors that surfaced, the factors are classified into three 
categories: pro~rammer-related, analyst-related and _ (Table 4). This classification is, at best, tentative. 
It is based on a rather subjective interpretation of the solution. Moreover, the methodology followed 
in this study, and its limitations, does not allow us to draw a clear conclusion in this regard. Hence, 
we offer this solution only as a beginning point for further evalua­tion. A specifically designed study 
separating the samples into groups of analysts and programmers is needed to validate this classi­fication. 
DISCUSSION OF FINDINGS Discussion The primary finding of the study is that the 7 factor structure proposed 
by Hackman and Oldham (1980, 1975) and the added factor ­learning opportunity -did not exist for this 
sample of MIS professionals. This confirms the finding of several previous researchers (E.g., see Fried 
and Ferris, 1986, and Harvey, Billings, and Nilan, 1985.) that separate factor structures prevailed for 
different samples. Their recommendation that users of JDS examine its dimensionality before using it 
is appropriate and is reinforced by this study. We cannot pass any judgment on the Job Characteristics 
Theory (Figure 1) based on this stiudy. Clearly a relationship exists between job characteristics and 
worker outcomes. At least in its broad outlines, the theory is an appropriate framework to stud> the 
effects of job design. Jvhat is not con­firmed, however, is the dimension ality of characteristics as 
postulated by Hackman and Oldham (1980, 1975). Some other combination of dimensions were perceived by 
the MIS professionals in the sample of this study. It is imperative to identify these dimensions, if 
the theory were to serve as a guideline for job redesign. A more accurate identification of the core 
job characteristics will enable MIS managers to manipulate specific aspects of an MIS profes­sional s 
job that have an actual influence on affective outcomes. However, it is possible that, instead of specific 
dimensions, the core dimensions taken as a whole is of interest (e.g., in calculating the Motivating 
Potential Score), then JDS in its present form may serve the purpose (this is a testable hypothesis). 
In that case, we do lose the precision of the instrument. It is in this light -naming of the dimensions 
-that the 7 factor structure that surfaced was examined in the previous sec­ tion. MIS researchers have 
called for the extension of JCT to gain a better insight to the work related determinants of job satisfaction 
(Goldstein and Rockart, 1984). Bostrom (1978) added role conflict and role ambiguity to the model and 
found both to have signifi­cant negative correlation with job satisfac­tion. This finding was also observed 
by Baroudi (1985) and Goldstein and Rockart (1984). In this study, we included another of Bostrom s factors, 
learning opportunity. A test of JCT using a revised JDS needs to be conducted before we can make firm 
conclu­ sions about JCT. Recommendations and future research directions This study adds weight to the 
findings re­garding the instability of the JDS across samples. That a factor structure different from 
that postulated by JCT emerged is not surprising. What is illuminating is that the solution is interpretable 
once the organiza­tional contextual factors (position, job types) were considered. This is in line with 
Fried and Ferris (1986) findings. Hence we recommend that confirmatory factor analysis be run on JDS 
prior to using it to predict job outcomes (satisfaction, motivation level etc.) The true dimensionality 
of JDS needs to be established. The nature of the instability also needs to be determined, Researchers 
question whether it is unstable across job samples (Harvey, Billings, and Nilan, 1985) or samples that 
differ on account of personal and con­textual factors (Fried and Ferris, 1986). This is especially crucial 
for MIS research as the JDS is used widely to examine job design issues of programmers and analysts -two 
quite different samples. Substitutes to JDS are available to MIS researchers. Franz, Robey and Koeblitz 
(1986) used the Job Characteristics Inventory (JCI) in a study of users of an online information system 
in a health care environment. Developed by Sims, Szilagy and Keller (1976), JCI is conceptually similar 
to JDS. Franz et al. state that JCI has demonstrated better reliability than JDS. For situations where 
a more general perception of the job is of interest, researchers may use Smith et al. s (1987) Job Descriptive 
Index (JDI) or Ironson et al. s (1989) Job in General (JIG) scale. However, neither of the latter two 
are multidimensional and are not concep­tually equivalent to JDS or JCI. There are other implications 
for MIS re­searchers. In most studies, programmers and analysts arc differentiated on the basis of their 
job titles. This study is no exception. But its findings suggest that perhaps a better way of distinguishing 
them would be job descriptions or, better still, examination of their actual roles. Instruments such 
as JDS have an inherent assumption that respondents perceive job dimensions in a homogeneous manner which 
implies that they perform very similar activities. In the case of MIS profes­sionals, this assumption 
may not be valid. Conclusions A key observation about factor analysis or for that matter any multivariate 
technique must be made here. These techniques postulate that we view the same phenomenon from different 
dimensions. Questionnaires and inventories are developed with a particular combination of these dimensions 
as constructs. The under­ lying assumption is that those who answer these questions will sort the phenomenon 
under study in the same manner or in the same dimensions as the questionnaire implies. How often is this 
true? Intuition would suggest: not many times. The failure of factor structures to surface in the same 
way for different samples bear further testimony to this. It is therefore absolutely necessarv that no 
a priori dimensionality be accepted without validating it first. Instrument validation has remained a 
major concern in MIS research. Straub (1989) and Zmud and Boynton (1989) have documented the fact that 
instruments in the MIS literature are, at present, insufficiently validated. They recommend using well-developed 
validated instruments that fit the level of analyses and detail required by a particular research model. 
By using JDS, MIS researchers seem to have followed this suggestion. What we have demonstrated in this 
paper is that researchers need to go beyond this recommendation to use validated instruments. A detailed 
evaluation of the instrument s background and applica­ bility and the need for revalidation for the current 
research context is warranted. REFERENCES Aldag, R.J. and Brief, A. P., Impact of Indi­vidual Differences 
on Employee Affective Responses to Task Characteristics, Journal of Business Research, October 1975, 
pp. 311-322. Baroudi, J.J., The Impact of Role Variables on Information Systems Personnel Work Atti­ 
tudes and Intentions, MIS Ouarterlv, Decem­ber 1985, pp. 341-356. Blood, M.R. and Hulin, C. L., Alienation, 
Environmental Characteristics and Worker Responses, Journal of A~~ lied PsvcholoRv, 1967, pp. 284-290. 
Bostrom, R.P. Conflict-Handling and Power in the Redesi~n Process: A Field studv Investim ­tion of the 
Relationshi~ between MIS Users and Svstem Maintenance Personnel, I-Jnpub-Iished Doctoral Dissertation, 
University of Minnesota. 1978, Couger, J. D,, Borovits, 1., and Zviran, M., Comparison of Motivating 
Environments for Programmer/Analysts and Programmers in the U. S., Israel, and Singapore, Proceedings 
of the Twentv-Second Hawaii International Conference on Svstem Sciences -vol 4, 1989, 316-323. Couger, 
J. D. and Zawacki, R. A., Motivating and Mana~in~ Com~uter Personnel , New York:John Wiley and Sons, 
1981. Couger, J. D., Zawacki, R. A., and Opperman, E. B., Motivation Levels of MIS Managers Versus Those 
of Their Employ ees, ~ Ouarterlv, September 1979, pp. 47-56. Davis, L.E. and Taylor, J. C., Design of 
Jobs, Middlesex, England: Penguin 1972. Dunham, R. B., The Measurement and Dimen­ sionality of Job Characteristics, 
Journal of A~~lied Psychology, June 1976, pp. 404-409. Dunham, R. B., Aldag, R. J., and Brief, A. P., 
Dimensionality of Task Design as Measured by the Job Diagnostic Survey, Academv of Management Journal, 
February 1977, pp. 209­ 223. Franz, C. R., Robey, D., and Koeblitz, R. R., User Response to an Online 
Information System: A Field Experiment, MIS Ouarterlv, March 1986, pp. 29-42. Fried, Y. and Ferris, G. 
R., The Dimensionali­ty of Job Characteristics: Some Neglected Issues, Journal of APtI lied Psvchologv, 
August 1986, pp. 419-426. Goldstein, D. K., Effects of Task Differences on Job Characteristics of Programmer/Ana­lysts, 
Journal of MIS, Summer 1989, pp. 41­ 58. Goldstein, D.K. and Rockart, J. F., An Exami­nation of Work-Related 
Correlates of Job Satisfaction in Programmer/Analy sts, ~ Ouarterlv, June 1984, pp. 103-115. Hackman, 
J. R. and Lawler, E. E., III, Enlployee Reactions to Job Characteristics, Journal of Applied Psvchologv 
Monogra~h, June 1971, pp. 259-286. Hackman, J. R. and Oldham, G. R., \! ork Redesign, Reading, MA: Addison 
Wesley, 1980. Hackman, J. R. and Oldham, G. R,, Develop­ment of the Job Diagnostic Survey, Journal of 
APV lied Psv cholo~v, April 1975, pp. 159­ 170. 1985, pp. 461-468. Idaszak, J. R., Bottom, W.P., and 
Drasgow, F., A Test of the Measurement Equivalence of the Revised Job Diagnostic Survey: Past Problems 
and Current Solutions, Journal of Atmlied Psvchologv, August 1988, pp. 647-656. Idaszak, J.R. and Drasgow, 
F., A Revision of the Job Diagnostic Survey: Elimination of a Measurement Artifact, Journal of A~~licd 
Psvcholo~v, February 1987, pp. 69-74. Ironson, G. H., Smith, P. C., Brannick, M. T., Gibson, W.M., and 
Paul, K. B., Construction of a Job in General Scale: A Comparison of Global, Composite, and Specific 
Measures, Journal of At)vlied Psychology, May 1989, pp. 193-200. Katz, R., Job Longevity as a Situational 
Factor in Job Satisfaction, Administrative Science C)uarterlv, June 1978, pp. 204-223. Kim, J. and Mueller, 
C. W., Introduction to Factor Analvsis: What it is and How to do it, Beverly Hills: Sage Publications, 
1978. Kulik, C.T., Langner, P.H., and Oldham, G.R., Measurement of Job Characteristics: Com­parison of 
the Original and the Revised Job Diagnostic Survey, Journal of A~tI lied Psvchologv, August 1988, pp. 
462-466. Lee, R. and Klein, A. R., Structure of the Job Diagnostic Survey for Public Health Occupa­tions, 
Journal of AR~lied Psvchologv, August 1982, pp. 515-519. Mumford, E., Job Satisfaction: A Studv of Com~uter 
S~ecialistst London: Longmans, 1972. Nie, N. H., Hull, C. H., Jenkins, J. G., Stcin­brenner, K. and 
Bent, D. H., Statistical Pack­age for the Social Sciences, Second Edition, McGraw Hill Book Co., 1975. 
Rizzo, J.R., House, R.J. and Lirtzman, S.1., Role Conflict and Ambiguity in Complex Organizations, Administrative 
Scicncc Qu3r ­terlv, June 1970, pp. 150-163. Rush, H.M,F., J ob Design for Motivation, New Harvey, R. 
J., Billings, R. S., and Nilan, K. J., Confirmatory Factor Analysis of the Job Diagnostic Survey: Good 
News and Bad News, Journal of A~~lied Psvcholo~y, August York: The Conference Board Inc., 1971. Shepard, 
J.M. Functional Specialization, Alienation and Job Satisfaction, Industrial and Labor Relations Review, 
1970, pp. 207­ 219. Sims, H.P. Jr., Szilagy, A. D., and Keller, R. T., The Measurement of Job Characteristics. 
AcademV of Management Journal, June 1976, pp. 195-212. Smith, P.C., Balzar, W., Brannick, M., Eggles­ton, 
S., Gibson, W., Ironson, G., Josephson, H., Paul, K., Reilly, C., and Whalen, M., Manual for the Revised 
JDI and Job in General scales. Bowling Green, Ohio: Department of Psychol­ogy, Bowling Green State University, 
1987. Straub, D. W., Validating Instruments in MIS Research, MIS Ouarterlv, June 1989, pp. 147­ 169. 
Weiss, D. J., Further Consideration in Applica­ tion of Factor Analysis, Journal of Counsel­ in~ Psvchologv, 
January 1971, pp. 85-92. Zmud, R.W. and Boynton, A. C., Survey Measures and Instruments in MIS: Inventory 
and Appraisal, Working paper, School of Business Administration, Florida State Uni­versity, May 1989. 
APPENDIX -Job Characteristics Scale Job Characteristics Scale comprises section 1 (7 items) and section 
2 (14 items) of the full inventory. An 8th dimension, Learning 0~ ~ortunities was added by adding 1 item 
to section 1 and 2 to section 2. Section 1 items require responses on a 7-point Likert scale. Section 
2 items require a numeric response ranging from 1 to 7. The definitions of the dimensions and the associated 
items are given below. A. Skill Variety: The degree to which a job requires a variety of different activities 
in carrying out the work, involving the use of a number of different skills and talents of the employee. 
Section 1 #4 How much varietv is there in your job? That is, to what extent does the job require you 
to do many different things at work, using a variety of your skills and talents? Section 2 #l The job 
requires me to use a number of complex or high-level skills. Section 2 #5 (reversed scoring) The job 
is quite simple and repetitive, B. Task Identitv: The degree to which the job requires the completion 
of a whole and identifiable piece of work --i.e. doing a job from beginning to end with a visible outcome. 
Section 1 #3 To what extent does your job involve doing a whole and identifiable uiece of work? That 
is, is the job a complete piece of work that has an obvious beginning and end? Or is it only a small 
~ of the overall piece of work, which is finished by other people or by automatic machines? Section 2 
#l 1 The job provides me the chance to completely finish the pieces of work I begin. Section 2 #3 (reversed 
scoring) The job is arranged so that I do ~ have the chance to do an entire piece of work from beginning 
to end. C. Task Significance: The degree to which the job has a substantial impact on the lives of work 
of other people --whether in the immediate organization or in the external environment. Section 1 #5 
In general, how significant or im~ortant is your job? That is, are the results of your work likely to 
significantly affect the lives or well-being of other people? Section 2 *8 This job is one where a lot 
of other people can be affected by how well the work gets done. Section 2 #14 (reversed scoring) The 
job itself is ~ very significant or important in the broader scheme of things. D. Autonomv: The degree 
to which the job provides substantial freedom, independ­ence and discretion to the employee in scheduling 
his/her work and in determining the procedures to be used in carrying it out. Section I #2 How much autonomy 
is there in your job? That is, to what extent does your job permit you to decide on vour own how to go 
about doing the work? Section 2 #13 The job gives me considerable opportunity for independence and freedom 
in how do the work. Section 2 #9 (reversed scoring) The job denies me any chance to use my personal initiative 
or judgment in carry­ing out the work. E. Feedback from the Job Itself: The degree to which carrying 
out the work activities required by the job results in the employee obtaining information about the effective­ness 
of hi or her performance. Section 1 #7 To what extent does doino the iob itself provide you with information 
about your work performance? That is, does the actual work itself provide clues about how well you are 
doing -­ aside from the feedback co-workers or supervisors may provide? Section 2 #4 Just doing the 
work required by the job provides many chances for me to figure out how well I am doing. Section 2 #12 
(reversed scoring) The job provides very few clues about whether or not I am performing well. F. Feedback 
from Agents: The degree to which the employee receives information about his/her performance effectiveness 
from supervisors or from co-workers. Section 1 #6 To what extent do managers or co-workers let you know 
how well you are doing on your job? Section 2 #10 Supervisors often let me know how well they think I 
am performing the job Section 2 #7 (reversed scoring) The supervisors and co-workers on this job almost 
never give me any feedback about how well I am doing in my work. G. Dealing with others: The degree to 
which the job requires the employee to work closely with other people (whether other organization members 
or organizational clients . Section I #1 To what extent does your job require you to work closelv with 
other oeo~le (either clients, or people in related jobs in your own organization)? Section 2 #2 The job 
requires a lot of cooperative work with other people. Section 2 #l 5 (reversed scoring) The job can be 
done adequately by a person working alone --without talking or checking with other people. H. O~~ortunities 
for on-the-iob Learning: The degree to which the job provides employees with opportunities to learn new 
skills and increase job-related knowledge. Section 1 #8 To what extent does your job allow you to learn 
new skills and information relat­ ed to the job? Section 2 #6 The job allows many opportunities for 
me to increase my skills and job-related knowledge. Section 2 #16 (reversed scoring) There is little 
chance to learn any additional skills and information about the job while I am working. 
			