
 . -  - .  + - . .. . . . Probabilistic Segmentation of Volume Data for Visualization Using SOM-PNN 
Classifier ,. Feng Ma , Wenping Wang2, Wai Wan Tsang2, Zesheng Tang , Shaowei Xa , Xn Tong Tsinghua 
Univemi~, P. R. China 2The Unive~i~ of HongKong, HongKong Abstiact W e present a new probtilfisdc cl=-fier, 
ded SOM-PNN class-tier, for volume data class-fi~on md ~om The new classifier produces probabilistic 
cl=-fication with Bayesian cofidenu measure which is hi@y desirable in volume rendering Based on the 
SOM map traind with a large training data set our SOM-P~ classifier performs the probabiic classification 
using the PNN rdgoriti This combmed use of SOhf and PNN overcomes the shortcomings of the parametric 
methob the non­p~etric methoa and the SOhI method The proposed SOM-P~ classifier has been used to segment 
the CT sloth data and the 20 human h~ brain volumes retiting in much more informative 3D rendering with 
more deti and less *ts than other methods. Nurnerid comparisons demonstrate that the SOM-PNN classifier 
is a ~ accurate and probtil~c cl-er for volume rendering. CR Categories and Subject Dwcriptors: L4.6 
me Processing md Computer Viion]: Segmention -Piiel Classticatioq L5.I Pattern Ra@tion]: Modek -Neurrd 
NeK. Additional Keywords medicrd image seqentatiom multisde, wavelet transfom SOhL pm, sohf-p~ cl=s-fier, 
3D vol~e rendering 1 INTRODUCTION SegmentadoL or Class-ficatiou is defid as dividing a data set into 
components with distincti}re characteristics. hfany methods have bwn developed for CT or h~ images segrnentatiom 
including tisticd segmentation [15], model-based methods [n, snake methods [S] and the neti network approaches 
[6,13]. Feng htq Shaowei XI&#38; Department of Autornatio~ Tsinghua University, Befiins 100084, p. ~ 
-E~~ stia@tsinghmeducn. R enping W ang, Wai lVm Tsan~ Dep*ent of Computer Scien% The University of Hon&#38;ong 
Po~arn Rod Hon&#38;ong. ErnaiI: wenping@cs.hk~W hheng Tan% ~ Tong Department of Computer Science, Tsinghua 
University, Beijing, 100084, P. R China EmW. ag@-mghmedwa 0-81 S691S0-S/9S/$10.00 Copfight 199S EEE However, 
few of these classtiers produce probabilistic classtication, which is highly desirable in volume rendering 
[4]. Tradhiondly, mixture models are often used for data segmentation in volume rendering [2,4]. h these 
models, voxels are modeled as compositions of one or more materials. Different materird attributes, such 
as the light intensity and transparency, are determined by the percentages of constituent materials. 
Thus in this setting probtillistic classifiers are more desirable than rdl­or-none methods in reducing 
artifacts in rendering. Classification is given in terms of the percentage of each material from the 
original dak For each voxel in the volume data reprwented by a d dimension f-e vector x = Rd, the percentage 
of materird i in this voxel is determined by the posterior probability p(xli) p(ilx) = ~ (1)  ~p(xlk) 
k=]  where p(x] k) is the class condition probabili&#38; density of materhd k of the voxel x and K is 
the toti number of classes [4]. b practice, there are many ways to estimate the probability density fictions, 
such as parametric methods, non-parmnetric methods and semi-parametric methods [1]. The parametric approach 
assumes a spectic form of the density fiction, usually the norrnrd ditibutioq with a number of parametem 
to be op=d by fitting the model to the data seL Maximum Weriood ~) method is usually used to fid the 
optimal vducs of the parameters. For an image pixel represented by d dimension feature vector x = Rd, 
the normrdly distributed densi~ fiction is -;(X-P)TZ- (X-P) {} (x) = (2z)~:214~2 e ,, with parameters 
{p, X} , where P is the d dimension mean vector and x is the dxd covariance mati The parameters are estimated 
as ;=+$x. (3) n N (4) z= +Z(xn ;)(X. -j)T , n=l given adataset X= x1,~2, ..,xN . {} ~ough W method 
is straightforward and easy to implemen~ tie particulm form of the density functions chosen might be 
incapable of providing a precise representation of the true density. k con-non-pmetric estimation does 
not assume a particulm fictional foq but rdlows the density function to be . .  .->~.<.. . -.. - 
-  -- ______ ,.. .. -. -- -z -., ._. . . .+:,-_:.---,___ : determined entirely by the data [14]. Such 
methods typidly tier horn the drawbacks of r-g dl the data points to be stored and the slow spd of evrduating 
a new data point k tie semi-pammetic metho&#38; a me distribution is used to estimate the densi~ function. 
h the W-e distriiutio~ the density tiction is @ formal born a ~m= combination of basis tictios whereas 
the number of basis functions is a parameter of tie model itse~ and can be varied independently from 
the size of the data set A gened class of tictiond forms is *O dewed as in the non-parametric metho~ 
The E~ectation-h~on @h~ method is an e=ple of the semi-pammetric method [1]. However, for -h class, in 
addition to esdmatm ga setof parameters iteratively, the number of the basis tictions has to be determined 
in advance. This raises another problem which has to be solved exTetienM1y. h this paper, we propose 
a hybrid classfier, the SOM-P~ classfier in which the densi~ function is ~ simply by the com~mation of 
the se~-oreg map (SOW [9] and the probtil~ic ned network ~~ [11,12]. The SOM map is trained with a tminiig 
set W The Pm algorithm is then tied out based on the SOM map traind k addition to the gened form of density 
fictions achieve~ the number of the kernel tictions used in Pm is independent of the training set and 
much fewer than tie number of data poin~ This makes the estimadon of the probtilfig density fictions 
much easier and fnster. Feature \7ectora play an important role in statistid pattern ragnitiom According 
to the sale-space theory [~, Gaussian and dl its ptid derivatives form a complete operator My of an irnoge. 
W eadopt this idea and form our f-e vmtor in the proposed SOM-P~ classtier using the mtitistie technique 
based onthewavelet tiorm [3], as descri%d byhfdlat [10]. ~~e apply our method to sloth CT data and h~ 
human brain volume data classification The probabiidy classified volumes are rendered with the direct 
volume rendering technique [lq. h botb w+ higher qtilty rendered images and better numencrd re~ts have 
been achieved with the SOM-P~ classtier than with other methods. The remainder of ti paper is organized 
as fo~ows. Swtion 2 gives the backgound of mtitisde image structure and wavelet tiorrn. Section 3 presents 
the Pm, SOhI rdgorhhms and our new SOM-P~ classfier. fiTerimentation redts and conclusions are given 
in Sections 4 and 5 respecti~rely. 2 MULTISCALE IMAGE FEATURE VECTOR ~RACTION USING WAVELET TWNSFORM 
 It hos been shown that the ody operator fkrnily s-g the nti front-end *ion constraints of ~meari~, s~ 
varianw, rotation vtianc% and sde invariance is the bsian and W its pardd derivatives [~. This operator 
Wy provides a complete representation of image structure. For tw-ensiond hnage% the five irreducible 
invariant of up to second order derivatives can be represented using tensor notations {L, L,L,, L , L,LOLJ,L,LJJ 
(5) where L is the image intensity, L&#38;j the squared norm of the gradieng and L,, the Laplacian of 
the image. It has been shown that the segmentation of intensiv images can be done using ody the zero 
and fist derivatives of tie Gaussi~ wtie the second order derivatives are useti when d~g with te= images 
[q. 72 The nmnerid dculation of these elements can be performed with the type of wavelet transform described 
by Mdlat [10] when the Gaussian is used as the smoothiig function in the wavelet transfom For each pkel 
in the irn@e, our feature vector is then formed by 9 components: the original intensity value, the smoothed 
intensiv value and the gradient magnitude of the smoothed images from scale 1 to scale 4 by following 
Wls idea Let be the ddation of tbe smoothiig function O(x,y) at sdes. The two wavelet fictions are de(x,y) 
 y (x,y) = ~ m(x,y) y (x,y) = (? @ The dilations of tie wavelet functions at sties are (8) The wavelet 
transform of the image, ~(x,y), at scales has two components w,lf(x,y) = f * y: (X,y) W= f(X,y) = f * 
y:(x,y) (9) Sinw = SVU* ~.)(x,Y) > (lo) tie image @lent magnitude at sdes is [~ f (X,y)lz +Iyzf (X,y)tz 
(11) Hence, for each pkel in the image, its smoothed intensity value and the gradient magnitude of the 
image smoothed at each scrde are obtained dwecfly from the discrete wavelet transform. 3 PNN, SOM ALGORITHMS 
AND THE NEW SOM-PNN CLASSIFIER 3.1 The PNN Algorithm The probtilfistic neti networh or Pm, is originated 
from P-n s probtilli~ density estimator [11,12]. For a given data set X+{xl,~,...,xN}, theParzendensity 
functionestimatoris (12) where Xn = Rd, G is the kernel function and c tie scale factor. The kernel 
fiction often takes the tiussian type .. --- .. - ­ - ----?.-, -­ . __ .. . - -.-__. .. . _ ..-..- 
X2 1 2 -B~~ on tie condition pmb~fi~ G(x) = e (27) dJ2 density function estimated us mg(12), a ~ven 
sample x win be classified as class i if P(X] i) > p(xlj) ford classes j #j. Dfierent values of sde titer 
o lead to @erent classification petiorman= We fo~ow the id= in [11,12] to find the optimal 0. F@ tie 
performance score of the Pm classfier with a given G is determined by the cross-vflldation method h the 
process of cross-vrdidatio% each -g smple is tempotiy removed from tie training set and used as the test 
sample. The remaining training data is then used in the Pm classfier to clnssify tis test sample. H the 
sample is corrdy class-tied the performance score is increased by 1. Repeat this procedure ford tie -g 
-Ies go give the find score. FinMy, a one dimension heuristi~y search is petiormed to fid the optimal 
c with the lnrgest performance score.  3.2 The SOM Algoritim me ~dard Kohonen map [9] is a useti tool 
for clustering topologicrdly or-g and subspace mapping h most cases, the topology of the SOhfisa two 
dirnensiomd lattice of neurons, =h of which is associated with a reference vector connected to m input 
ht x = Ra be the input data vector and m*c Rd be the reference vector of map node ~ The input data vector 
is compared with dl the m, in a metri~ such as the EucHd-distanw. The node with its reference vector 
yielding the minimum distance to x is selected as the winner nod~ si~ed by subscript c, i.e., (13) l~-m=ll=+{ll~-m,ll}, 
i=lz,---,u where Jlis the toti number ofnodes. During the learning process, the referenm vector associated 
with each node is updated whh the same input x(t) in the following way m,(t + I) = m,(~)1 (14) m,(t) 
+ h. (t)[x(~) ~vhere t is the discrete-time coordinate and hd (t) is the neighborhood kernel. The neighborhood 
kernel here adopts the Oaussian type I]rc-Zlr h.(t) = a(t). eq -(15) 202 (t) [1 where the width of the 
kernel a(t) and the lag* ~(t) me monotonicrdly decrming tictions of time, and q is the two dirnensionrd 
coordinates ofnode i in the lattice.  3.3 The Hybrid SOM-PNN Classifier me tradition Pm rdgorhhrn descriied 
above uses dl the samples in the timg set to ehate the probability density fictions and perform classification 
k image segmentatio~ a -g set often comprises a large number of samples and the evaluation of a new sample 
is very slow for such a large training set On the other han~ data in the training set is not noise free 
and if the tradition~ Pm dgorhhrn is used don% the classtication may be *-wted by the noise. We propose 
a SOM-PN classfier to overcome the ~cdties of the tradition Pm dgonti b the SOh4-P~ classifier, reference 
vectors from each class of the trained SOM map, instead of the originrd training samples of a large she, 
are used to estimate the probtillig density function. Suppose that the tied SOM map has Nk nodes for 
materhd with label k and the ,, b corresponding reference vectors are m}, i=1,2, .... N1, the probtilfity 
density fiction ofmaterid k is then estimated by (16) Having obtained the estimated probability density 
of each material, the probabilistic classification are obtained using formula (l). Our hybrid approach 
as described in tils section has the following advantages. F-through the use of SOM, the Pm algorithm 
is relaed of the burden of having to proms a large S* training se~ Secon&#38; since the trained SOM map 
serves as a good representative of the training samples, its use makes the Pm classfier more robust M 
the presence of noise data in the original trainiig set Ftiemore, the probabilistic classification, which 
is highly d~irable for visudimtion but cannot be obtained with SOM rdone, is achieved naturally in Pm. 
Finrdly, the wmbination of SOM and Pm determines the number of basis functions in the model automatically 
and simplifies the process of probability density estimation as compared with the EM method [1]. The 
procedures of our rdgorithm me shown in Fig. 1. Step 1: SOM trainiig trainiig set SOM map Step 2 Pm 
classtication SOM map obtained in step 1 I fig. 1. Dagram of SOM-PNN classifier. 4 =PERIMENT RESULTS 
The proposed SOM-P~ classfier has been built for classing both CT sloth volume data and W human brain 
volume dak For dtierent kinds of volume daw we apply different strategies in choosing the f=ture vectors 
to achieve the best segmentations. Compared to the brain volumes, the ~ sloth data is less complicated 
anatomicrdly. The intensity contrast of image pkels in ~ sloth data is dso higher than that in MR brain 
volumes. Moreover, the phenomena of intensiv inhomogeneities in ~ data are much less apparent than in 
MR dam To achieve fast ad accurate segmentations, for each pkel, we use only the originrd intensity value 
and its gradient magnitude at scale 1 to form the !­ f-e vector. Adding more components into the ftiture 
vector in this case would not improve the performacc of the classifier, and 4 t would m&#38;e the algorithm 
less efficient However, for the I segmentation of more complicated MR brain data to be addressed , -. 
 in the second subsection, we will have to use the complete 9 components f~ture vector for each pkel 
as described in Section 2 to get better results. I  _____ . .._  _. -. ~.,, ,- ..,,. 4.1 Sloti CT 
Volume Classification The dimensions of the ~ sloth data are 128x128x128 with each (18) voxel haling 
256 gray Ievek. The task is to segment each voxel in /1 n=l j=l tie &#38; set as a composition of four 
class= air, m soft tissue, where K is the number of materkds to be classified and N the andbone. number 
of voxels in the test set Table 1 lists the results. Fti. 23643 phek of ~erent classes were hand-picked 
from 24 evdy spaced sficcs in the volume &#38; According to their Table 1 Correct rate of the data sets 
with intensity levels these pixels were labeIed mandy. N these different classifiers 23643 feature vectors 
together with their labek form the training seL me SOhl with dimensions of 7x11 is set up and trained 
as destibed in Section 3.2. By the cross-vfildation method (see SOM-PNN m Pm SOM Section 3.1). the optimal 
sde tier o is determined to be 0.45. training set 97.97 97.89 97.85 98.52 fien tie SOM-PNN classifier 
is appfied to ah sfice of the ~ test set 1 83.99 66.44 78.56 83.65 I olume. test set 2 74.17 74.81 73.36 
55.17 For compariso% the h~ classfier and the Pm rdgorithm were implemented with the same training set 
The SOM map obtained Comparing Fig. 2 (c) with Fig. 2 (a), we might conclude that above was dso used 
to classfi tie ~ volume as a separate the ~ method over-segmented the bone pixels in the image. This 
classtier. Fig. 2 (a) is one Originrdstice image. Its classifications agre~ with the low correct rate 
of test set 1 and high mrrect rate with these four classifiers are shown as Fig. 2 @) to Fig. 2 (e). 
b of test set 2 with the ~ method in Table 1. It can dso been seen tiese image 4 increasing gray levels 
are assigned to air, @ sofi horn Fig. 2 (e) that bone pixels with low intensity level are not tisme, 
and bone pixels. For the probtilfistic classifie~ the gray correctiy classfied with the SOM classifier 
which accords with level of a p~~el in tie classfied images is the avemgd vrdue of the very low correct 
rate of test set 2 with the SOM classifier. For * four matends with classified probabilities.the three 
data sets, the SOM-P~ classifier outperforms the PNN classfier due to the clustering abifity of SOM. 
Ml the 128 slice images are classified by the above classifiers. The classified images are stacked together 
to yield a 3D probtilhstic classification. On an SGI hdigo2 Maximum ~A~ wor~tion with 195W RIOOOOCPU 
and 192Mb memory, the time used to perform the classification of the whole 3D ~ sloth data using the 
SOM-PNN, ~, PNN and SOM clmstiers are 241s, 178s, 48524s and 159s, respectively. The um SOM-PNN classifier 
is about 200 times faster than the PNN (a) (c)  classtier. The signticant improvement in efficiency 
makes the proposed SOM-PNN classifier a favorable choice in time-critid applications, where non-parametric 
methods would be too slow to be used. Moreover, the time that Pm classifier takes varies with ~erent 
trainiig sets, while the time used by the SOM-PNN classfier is ahnost the same. The training time of 
the SOM used in the SOM-PNN classifier is 734s while that of the PNN with the full training set is more 
than 20 hours on the same machme. R A direct volume rendering method based on 3D texture(d) (e) mapping 
[16] is used to render tie classfied daa The rendered images of the volumes classified with the SOM-P~, 
~, PNN fig. 2.The original slice image (a) and the and SOM classifiers ae shown in Fig. 3, 4, 5 rmd 
6, respectively. classifications wifi the SOM-PNN (b), ML (c), k Fig. 4, the front cartilage of the 
sloth chest is clear and the back PNN {d) and SOM (e) classifier respectively. ribs are shown to be 
connected to the spine. But the qurdity of the image is severely tiectcd by the bone noise. h con-the 
To test tie perfomanm of diffment classifiers, two test sets are SOM-PNN classifier achieves stillar 
classification of the bone selatei Test set 1 consists of 930 sofi tissue pixek which are with much less 
noise as shown in Fig. 3. h Fig. 5, where Pm located near to tie bone in Fig. 2 (a). Test set 2 consists 
of 696 rdone is us~ the image quality is dso badly affected by the noise bone pisels in the ssme image 
without special consideration The due to the noise sample in the trainiig set Finally, in Fig. 6, the 
two sets ~vereused to t-tie classifiers abiity to distinguish the front tilage disappears entirely and 
the back ribs are shown to surrounding =eas of the bone and the bone itseK For pixel A let be disconnected 
to the spine with the SOM classifier. tie clasfied probtilfities be Pa = {~,, ~,,---, Rx} and the me 
above results show that the proposed SOM-P~ classifier  works very well in the ~ sloth data classification. 
Nurnericrdly it manually lAeIcd Frobtilfities be ~ = {Pn,, P.,,---,~}, the produces nearly the highest 
ovedl correct rate for different test correct classtication rate of the test set is defid as sets. The 
efficiency improvement is rdso siguifican~ From visurd inspections, the SOM-P~ clmsfier segments the 
volume data P-:a =l-;, (13 with least noise. Compared to the SOM cIasstier used in the literature, the 
segmentation produced using the SOM-PNN classifier revds anatomidly more meaningful structures. 74 4.2 
Human Brain Classification ~ ~&#38;SOapp~ed the SOhI-P~ classfier to human brain data se-mention. The 
bra volumes are the 20 nod brain volume data sets provided by the titemet Brain Segmentation Reposito~ 
(BSR)l [In. The dimensions of these coronal three~ensionrd T1-~vei-@ted spoiIed pent echo h~ data range 
from 2j6x2j6x51 to 2j6Q56x61. Al the volumes have been positiondly norm~ed by imposing a adard tbree~ension~ 
br~ coordinate ~~en hianti segmentation is rdso avtiahle from tie same source [In, w hich is obtained 
\viti semi­autommed segmention algorithms. These brain ~ oImnes ore to be segmented into three classe~ 
Cerebra Spired Fluid (CSF), gray matter (Gh~ and \vtite matter ml~. For cnse 112_2, to apply our metho~ 
16763 brain pixels oftiese tie? clnsses from sfice 35 and stice 36 of the volume are seIected as the 
training seL To precisely segment the complicated bra .-ctures in the lo~v intensity contrast imagey 
multisde feature vectors tvhh the complete 9 components described in Section 2 are exti3cti using the 
lvnvelet tiorm The SOM mzp ~~ithdimensions of 13x 11 is then established and trained as described in 
Section 4.1. The correct rate of the training set is 90.S7?6. The optimal sde fictor 5 found using the 
cross­~Jltion method is 0.13. Then the SOhf-P~ classtier is appfied tO e~h scan of the ~vhole data set 
to field a 3D se-mention. A threshold \7~ue of 20 is set to separate air pixels horn kraa pixels. E3ch 
pixel lvith the intensity value greater than 20 is clmfied into the probtil~ic composition of CSF, gray 
m=r and v;hite mntter ~vith the SOhI-P~ classifier. As in Section 4.1, the hfi. Pm nnd SOhI classifiers 
\vere implemented ~~ith the selected training set and used to se~ent tie same voluma h -h se.gmentatiom 
no post-processing is performd Fig. 7 (a) is an onginrd brain scnn (sfice 21), Fig. 7 @) is the manual 
segmentation. The segmentations using the SOM-P~, h~, PNW and SOhl classifiers of the same brain sw are 
presen~d os Fig. 7 (c)to Fig. 7 (~. The gray Ievek of air, CSF, .gmymatter and \vhite matter are assigned 
in an increasing order. As hefor% the coIor of each fid p~xel is the average of tie 3 closses colors 
\vei@ted ~viththe class-tied percentages. From Fig. 7, it cnn be seen thti the SOhI-P~ classfier achreves 
better segmentation compared to the marmd se.gmention. As shoi~min Fig. 7 (e), the Pm algorithm using 
the oti.gind training set retits a segmentation stim to tie one obtained Tvith the SOhI-P~ classifier. 
h Fig. 7 (d), the h~ clustier produces good segmentation in the upper part of the brain but CSF ficts 
nre produced in the bottom boundary of tie train. hforeover, due to the e%ence of intra-sm inhomogeneities 
of tie brain p~~el intensity, the ~vhite matter in tie lo~verpti of tie bmin is under-segmented compared 
~viththe SOhl-P~ class~ed segmentation &#38; seen in Fig 7 (~, the ~vhitematter in the lo~verpti of the 
brain is largely lost due to non-prob~i~ic ch=cteristic of tie SOhI classtier. Atiough tie problems ~~iti 
inter-and intra-scan inhomogeneities are not dedt tvith in tils pzper, the proposed SOhl-P~ classifieryields 
r-or~le se-mention despite these artifacts. Cl=ified stices are stacked together to yield a 3D ] The 
20 normal h~ brain &#38;to sets and tieir manurd se~entations tvere provided by the Center for hforphometric 
Adysis at Mussachuseti Geneti Hospitsd and ze av~able at httpY/neuro­ i\~\n\7.m@.hm7tidedticmtilbm. segmentation. 
The time used to segment this volume \vith the SOhf-P~, SO~ ~ and Pm classtier is 158s, 134s, 63s and 
14470s respectively. Again significant improvement of efficiency is achieved Ivith the SOM-P~ classifier 
compared tith the original Pm algorithm. The classified volumes are rendered ~vith textie mapping hard~vare. 
h Fig. 8, the five rendered volumes are cfipped corondly \viti the same vie~vpointmd clipping depth. 
k these images, the colors assigned to gray matter, \vhite matter and CSF are r~ ~vhite and ~een respectively. 
From visual inspection the SOM-P~ classifier, the Pm classifier and the h~ classtier yield similar segmentations 
of gray matter and \vhite matter in the upper pti of the brain. The ~ clmsifier over­segments the CSF 
\vhich leads to the noise in the boundary area of the brain. k the Io\ver part of the brain, due to the 
etistence of intensity inhomogeneities, most of the \vhite matter is lost in the SOM segmentation. For 
the other 3 methods, i.e., the ~, Pm, and SOM-P~, the segmentations obtained \vith the SOM-P~ classifier 
are closest to the manual segmentation. (a) (b) (c) (d) (e)  fig. 7. The original bwin scan (a), its 
manual segmentation (b), the segmentations with the SOM-PNN(c), ML(d), PNN(e) and SOM (9 classifier respectively. 
For dflerent segmentations, in addition to the visual inspection, nmnerid metrics are needed to compare 
them quantitatively. b tie literature, there are bvo metics often used to compare the similarity behveen 
segmentations. One is tie overlap metric [ln and the other is the percentage of dtierence [15]. For a 
given 75 . . --­ +:.:. . . ____ .-.-__.. -,.,<,.. ____ voxel class assignrnen~ the overlap metric between 
two se~entations is defied as the number of voxek that have this cl= assignment in boti segmentations 
divided by the number of voxels where either of the two segmentations has this class assignment [In. 
~ metric approaches 1.0 for retits that are very stiar and is near 0.0 when they share no stiarly classfied 
voxek. The percentage of ~erence between two segmentations is defined as tie ratio between the number 
of ~erenfly labeled pixeh Mithin the region of interest @O~ and the toti number of pixels ivithin the 
ROI [lq. The percentage of ~erence measures tie sirnilarig between two segmentations in the ROI #obdy 
w~e the Overlap m-es each classes separately. Nthough these two metrics yield a reasonable comparison 
between two se~entatiow they are not appropriate for comparing probabiic segmentations because pixel 
aunting does not accommodate prob&#38;iEties associti with probabiidy classtied voxek However, since 
in the Eterature, many segrnentadons are ody compared with manti segmentatio~ in pardctiar the orerlap 
metric in the ae of the 20 h~ brain volumes we will dso use this metric to compare our results. To evaluate 
a probabi~c segmentation with the overlap metic, the prob~l~ic re~ts must ~ be mnverted into non­prob~l~ic 
ones. To this en~ probabiistidly classified voxek are labeled as the class with the largest probability. 
As with the case 112_2, the other 19 h~ brain volumes are classfied and tested in the same way. The over~ap 
values of CSF, gray matter and white matter are averaged over these 20 normal wes. Table 2 is there-tits 
and the comparison witi other methods reported in ~SR ~lm. The gray matter overlap metric of ~erent methods 
for tie 20 h~ brain volumes is shown in Fig. 9. k Fig. 9, the sequence of the 20 brain volumes is rou@y 
arranged by their Mcdty to be segmenti Some volumes that were acquired recentiy with more sophisti-h~ 
machines have better data qtixties and are Med at tie end of the sequence. Table 2 Averaged ovedap of 
20 normal brain volum~ be~ean automatic segmentations and tie manual segmentation methods CSF Ghi Mf 
ad~tive hN­ 0.069 0.564 0.567 biased hN­ 0.071 0.558 0-562 m c-m-s 0.04s 0.473 0.567 h~. 0.071 0.550 
0.554 m*urn­ 0.062 0.535 0.551 l~elihood tree-structure I 0.049 0.477 0.571 **4 b&#38; aveqd over 2 
exTerts From Table 2 and Fig 9, it can be seen that the SOhI and SOhI-P~ classfiem actieve hi@er overlap 
with the manti se~entadon than tie other seven methods. For gray matter, the SOM and SOhf-P~ classfier 
are at 1-13% higher than other methods. The most si@mt improvement is the CSF segmentation. The CSF overlap 
of dl methods in ES~ with rqect to the manual segmentatio~ is below 0.1. The CSF overlap of our implementation 
of ~ is only 0.13. However, the CSF overlap of the SOM-P~ classfier with manual se~entation and that 
of the SOM classifiers have achieved 0.3S9 and 0.419 respectively. Besides, as seen in Fig. 9, the performance 
of tie SOM and SOM-P~ classfier varim much less si@candy than other methods, thus consistent classification 
has been achieved for these 20 nonnd MR brain volumes. It is not smprising that the SOM classifier yields 
better numerid resdts than the SOM-P~ classifier with the overlap metric because truncation on the probabilistic 
classification ofiets the accuracy of the SOM-P~ classtier. Since there is a considerable loss of classified 
information when mnverting probabilistic segmentation into a non­probabilistic segmentatio~ to get a 
more reasonable comparison between the SOM-P~ classifier md the SOM classfier, we now propose a generrdked 
difference ratio metric. For pixel n, let the probabilities of segmentation A be PnA= {Pn~,Pn~,..-, P;} 
and that of segmentation B be ~ ={~~, Pn~,..., P~} , the genedied dtierence ratio between A and B is 
defined as (19) where N is the totrd number of voxels in the ROI and K is the number of materials to 
be segmented. Here the ROI is the brain volume without air and K= 3. h the non-probabilistic we, the 
genedtid dtierence ratio is reduced to the percentage of dfierence be~een *O se~entation used in [15]. 
The dfierence ratios of automatic segmentations and the manual segmentation for the 20 norrnrd brain 
volumes are listed in Table 3. Three automatic segmentations, SOM-P~, SO~ and ~, are compared altogether. 
Table 3 Difference ratio of tie 20 normal brain volumes betieen automatic segmentation and manual segmen~tion 
VA) .­,2 t . ..=­12 01 1 7s 1103 I 13.82I 10.59 I 14.52I 12.77 I 22.23 15.s3 11 3 .2. d 123 133 124 2053 
aveme I I 10.02 I 7.UL S.sl 9.0s 10.41 9.63 13.03I 11.J4 I 11.04 12.27 9.74 10.97 13.15 10.00 10.s2 14.7n 
10.OGI 11.79 15.74 14.07 14.1s 17.5s 13.s9 15.03 lRR? 76 . . . . r---- - - . .. . From Table 3, it 
a be seen that the avcragd difference ratio of tie SOM-PNN clmsfier is 1.6~% lower than that of the SOM 
cl=~er. Compared with ML metho~ the SOM-PNN classifier has a 5.S96 lower difference ratio. hforeover, 
this refit is quite promising because in [15], the avemgd ~erenm ratio is about 20Yq though ditTerentdata 
sets are usd The experiment rd= in this subsection revd tie superiority of the SOM-PNW classifier to 
other automatic classifiers mentioned above. From 2D and 3D inspection it produ= the closest images to 
the manti segmentation. Numeridy, the SOhI-P~ classifier produws much better re~ts thm the tradhion~ 
statistid classtiers with the o~rerlapmetric. According to tie genedid ~erence ratio metic, it is *O 
better than the SOM classfier. Compard with the tradition PNN dgoriti the SOM-PNN classifier achieves 
si@cant improvement in eticiency and the classification accuracy is dso irnprovd 5 CONCLUS1ONS N e have 
proposed a new probabiiic classfier, the SOhf-PNN class-tier. for medicrd data classification and volume 
rendering. The new classfier is a serni-pmetric density esdmator and produces probtil~istic classification 
with the Bayesim cofidence masure. The volumes segmented using the SOM-PNN classfier reverd anatomidly 
more meaningful structures than non­probtilfisdc segrnentatiom Nnrneridly, the SOhl-PNN classtier is 
more accurate than other automatic se~entation methods in both the sloth and the brain ens= me SOhI-PNN 
clwfier is dso a M classfier. Based on the noise-free representative reference vectors providti by SOhL 
tie SOhI-PNN classfier segmens the sloti CT data 200 ties -r than the originrd PNN algorithm. Essentially, 
tie SOhI-PNN classfier is an intensity based cl-er and wi~ lose its power when the inter-and intra-scan 
intenshy inhomogeneities present severe problems. However, with the modem h~ sue~ this problem has been 
- d as inditied by tie low ~erence ratios for the last seved cases in tie 20 normrd brain data sets. 
h another aspecc the SOh~-P~ clmsifier needs the semi-automatic segmentation of seved brain scans -ad 
the pre-training of the SOhi map as prepro=s-mg steps. By our exTefien&#38;, segmentation of 2 or 3 scans 
does not present as a big bnrdq and tie pre-tig of the SOhI in the SOhI-P~ classtier can be done in a 
matter of minutes. The problem of quantitatively evdnating probabiiidy segmentation is raisd in this 
paper. The metrics cmrentiy used in fite-e are suitable for non-probtil~ic segmentation and are not appropriate 
for evrduatiag the qufllty of segmentation for volume rendering. For e=ple, although the SOM classifier 
Ao produ= high overlaps with mand segrnentatiow tie volumes se~ented with tie SOhI classifier lose more 
detaik than probtiiicrdly segmented volumes. h this paper, a gene~ed ditimence mtio is proposed in order 
to conduct reasonable comparison among probtilfistic classtien without sacrificing the probtil~ic propm. 
Acknowledgment Thisres=ch has been supported by National N-Science Foundation of China ~o. 69775001). 
. .- - -. . . - . . ..-. . .- ---.. ...... -... References [1]Christopher M. Bishop, Neurrd Networks 
for Pattern Recognition, 1995, Clarendon Press, Mort ISBN O-19­853849-9. [2] Werdi Cai, et d., Rendetig 
of Surface and Volume Details in , Volume D-E~OGWHICS 95, vol. 14, No. 3, 1995,pp. 421430. [3] hgrid 
Daubechies, Ten Lectures on Wavelets, Philadelphia : Pa: Society for hdustrird and Applied Mathematics, 
1992. [4] Robert A Drebti Loren Carpenter, Pat Hanrahan, Volume ~ Rendering, Computer Graphics, vol. 
22, no. 4,august 198S, pp. 65-74. [~ L. M. J. Florack B. M. ter Hoar Romeny, J. J: Koendeti ~ md M. A 
Vlergever, Scrde and the Differentkd Structure of hages, Image and Vfiion Computing, 10(~, July/Aug., 
1992, pp. 376388. [q S. Haring M. L Viergever, J. N. Ko~ A Multistie Approach ,. to hage Segmentation 
Using Kohonen Networks, h A Grnitro and H. H. Barre% editors, PM, Proc. of the 13fi conference, Springer-Verl~ 
Berlim 1993, pp. 212-224. [n M Kamber, D. L. Collins, G. S. Francis, A C. Evans, Model- Based 3-D Segmentation 
of Multiple Sclerosis Lesions in Magnetic Resonance Brain hages, IEEE Trans. on Medical Imaging, vol. 
14, no. 3, SepL 1995, pp. 442453. [8] M. Kass, A Witi D. Temopoulos, Snak= Active Contour Models, Int. 
J Comput. Vfiion., vol. 1,19S7, pp. 321-331. [9] T. Kohone% Tbe Self-Organting Map, Proceedings of the 
~E, vol. 78, no. 9,1990, pp. 14W1480. [10] S. G. Mdl~ and S. fiong, Charactetition of Si@rds from Mdti-scrde 
Edges, IEEE Trans. Pattern Ana~sis and machine IntelZ.,vol. 14,1992, pp. 710-723. [11] Timothy Masters, 
Practid NeM Network Recipfi in C+, Academic Press, San Diego, 1993. ISBN 0-12479040-2. [12] Tmothy Masters, 
Advanced Mgorithrns for Ned Network A C+ sourceboo~ John Wiley &#38; Sons kc., New ,. York 1995. ISBN 
0471-10588-0. [13] M. Oh, B. M. Dawan$ and R J. Maciunas, Neti­Network-Based Segmentation of Multi-Modrd 
Medicd kages: A comparative and Prospdve Study, I~E Trans. on Medical Ima@ ng,vol. 12, no. 3,SepL 1993, 
pp. 534-544. [14] Ronrdd H. Randles, Dou~as A WoKe, ktroduction to the Theory of Nonpammetric Statistics, 
New York Wiley, c1979. ISBN 0471-04245-5. [15] W. M. Wells, W. E. L. Grirnson, ~ Kikinis, and F. A Joles3 
Adaptive Segmentation of ~ Da@ Z= Trans. on Medical Imaging, vol. 15, no. 4, Aug. 1996, pp. 42942. [lq 
Orion Wilsou Nlen Van Gelder, Jane WMehns, Direct Volume Rendering via 3D Temes, University of CrdKomia 
Technid Repo~ UCSC_CRL_94_19, 1994. [la h~J/neuro-~.mgh.harvard.edticmtiibsr.htm. 77 = - ,7,.,.+--. 
 - _ ___ __ _ ,.,. -- . .  . .. . . . ___ ,. Fig. 3. Rendered images of tie sloti CT volume Fig. 4. 
Rendered images of tie sloti CT volume wifi SOM-PNN segmentation. witi MLsegmentation. Fig. 5. Rendered 
images of tie sloti CT volume Fig. 6. Rendered images of tie sloti CT volume witi PNN segmentation. witi 
SOM segmentation. Fig. 8. CoronaIIy clipped views of tie MR1 brain case 112_2 witi manual segmentation, 
SOM:PNN, ML, PNN and SOM segmentitio;s respectively. ­ + amap 0.9 + bmap 0.8 =2-tiq 0.7 *map 0.6 + 
mlc 0.5 +tskmeans 0.4 +som 0.3 + som-pnn 0.2 ml 0.1  Fig. 9 Gray matier ovetiap between automatic 
metiods witi manual segmentation for tie 20 normal MR brain volumes 7s . .  -. ,. .=:- .. -..  
			