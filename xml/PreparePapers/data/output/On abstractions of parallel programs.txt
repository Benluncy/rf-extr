
 t On Abstractions of Parallel Programs Thomas W. Doeppner, Jr. Department of Electrical Engineering 
&#38; Computer Science PRINCETON UNIVERSITY Princeton, NJ 08540 Abstract: We discuss a parallel program 
model that allows a very general synchron- ization mechanism with a scheduler to control the progress 
of processes "undergoing synchronization." We how to "abstract" the program, i.e. remove the scheduler, 
resulting in a simpler program. We then show that, for a large class of schedulers, a process can become 
dead- locked in the original program iff it can become deadlocked in the abstracted pro- gram. Motivation: 
A problem of current interest in the theory Of asynchronous computation is that of proving correct- 
ness of systems of parallel processes. In order to simplify such proofs, it is useful to abstract from 
the program only those details relevant to the particular property which one wishes to ascribe to the 
program. In this paper, the particular property in mind is that of deadlock-freeness. In [i] we discuss 
systems where process communication and synchron- ization was performed by means of semaphores. In this 
paper we general- ize the concept of a semaphore by allowing a process to wait for an arbitrary predicate 
on the (entire) program state to become true. (In [i] we allowed what we called "internal balkingP This 
is allowed only in a restricted sense in this paper). We then address the question of whether we can 
ignore the effects of scheduling in certain correctness proofs of such parallel programs. The answer 
is not obvious, because the introduction of a scheduler restricts the "degrees of freedom" of a parallel 
program, and could act to either cause a deadlock to occur or prevent one from occurring. In [3], Lipton 
gives a set of constraints under which a sequence of transitions can be replaced by a single transition, 
while preserving halting or non-halting. However, these constraints are fairly stringent and, it can 
be seen, are much more restrictive than our constraints. To add perspective, the examples discussed in 
[3] begin the reduction at the level of abstraction at which we stop. The Formalism: A system of parallel 
processes will be viewed as a binary relation --> on set Q of states. If q and q' are states, t an instruction, 
 and ~ a process, then t(~) q > q' means that there is an indivisible pro u gression by process ~ 
from state q to state q', named t(~). We extend --> to its reflexive, transitive closure in the usual 
way. We call t(~) a transition and let Z denote the set of all transition names. The set Q may be 
infinite. It will be thought of as being a set of arbitrarily-long sequences of elements, which are called 
state vectors. We split the state into two parts, the program state and the scheduler state, the components 
of which are called program variables and scheduler variables, respectively. If q is a state, ~ a process 
and ~ an expression (e.g. a variable), we let q.~(~) denote the value of ~ for process ~ in state q. 
When includes local variables, the values of those variables are those particular to ~. In particular, 
we consider the instr- uction pointer of ~ to be a local variable, taking on values called places. A 
transition is thought of as having 65 two parts -an enablinq predicate and an action function. We say 
that transition t(~) is enabled if process ~'s instruct- ion pointer references an input place to t(~) 
and t(u) 's enabling predicate is true. A transition can be executed only when it is enabled~ and the 
effect of the execution is to cause the state to be changed as specified by the action function~ and 
for ~7's instruction pointer to reference the output place of t(n). We model process creation by a transition 
with no input place and process destruction by a transition with no output place, following [1,2]. It 
is important in this paper that the program state be "isolated" from the scheduler state. Hence we require 
that for any transition which changes the value of a program variables that the new value of the program 
variable be a function only of other program variables. The use of the scheduler state is described in 
the following paragraphs. In general a place will be input to several transitions. If the disjunction 
of the enabling predicates of these transitions is identically true, then the place is called a non-synchronizing 
place. Otherwise the place is called a synchronizing ~lace. An output transi- tion of a synchronizing 
place is called a synchronizing transition. See figures I and 2. when R d_o_ S 1 when ~R d_o_ S 2 Figure 
1 p is a non-synchronizing place. i t: when k > 0 do S Figure 2 p is a synchronizing place, t is 
a synchronizing transition In this paper~ we restrict syn- chronizing transitions to appear only as 
parts of synchronizers, defined below. A synchronizer y is a pair of transitions along with their input 
and output places. The first transition of a synchronizer is called a type e (for enter) transition~ 
and it is denoted tY(~). Its input place is referred to e pY and its output place is p~. Y is e Pw 
also the input place to the second trans- ition of the synchronizer~ called a type s (for schedule) transition, 
denoted v ¥ ts(~ ) . Its output place is denoted Ps" A type e transition has an identically true enabling 
predicate and its action function modifies only scheduler variables. A type s transition is a synchronizing 
transition with an arbitr- ary enabling predicate, called a syn- chronization predicate and denoted P 
and an arbitrary action function. Y Both type e and type s transitions can only appear as part of synchronizers, 
and scheduler variables can only be referenc- ed or modified by type e and s transit- ions. Intuitively 
s a type e transition represents the act of entering a queue of processes, implemented by scheduler variables, 
awaiting some synchronization condition to become true. These waiting processes are each at p~ for 
some y. When both the condition is true and the process has been "chosen" by the scheduler to proceed, 
then it is enabled for the type s transition. The execution of the type s transition modifies the state 
of the scheduler and hence modifies the queue of waiting processes. For example see figure 3. We will 
be more specific about the scheduler in the next section. local hum V initially demand = 0 )Pe supply 
= 1 t Y | | do (num, demand) <---- e (demand +17 demand +i) / y when (k > 0 A m < 1 S A num< supply) 
 do (k, m, supply) <--- (k-2~ m*3, supply +i) Figure 3 An example of a synchronizer. Here we have scheduler 
variables num, demand, and supply, with num also a local variable (i.e.~ each process has its own copy 
of num). Processes are scheduled in FIFO order for the condition k > 0 A m < i. The Scheduler: Intuitively, 
we think of a scheduler as something which uses information from the history of uhe program states 
of a system's execution to determine which of a set of processes whose synchronization condition is 
true should be allowed to proceed. We subsequently present a large class of schedulers for which the 
action of the scheduler is irrelevant as far as deadlock is concerned. We begin by presenting some 
definit- ions. Definition: Two states ql and q2 are similar, written ql~q2 , if the values of their 
program variables are identical. Clearly, state similarity is an equival- ence relation. Next we define 
what might loosely be called an "enabled" set. Definition: q.E = {processes ~ I (~q')q ~ q' A q.i(n) 
= Y A q'.Py(~)] Pw (recall that P is the enabling predicate Y of the type s transition of syn- chronizer 
y). The idea here is that if process 6 E~ then as far as the program state is concerned~ it is alright 
for ~ to proceed. If ~ is not enabled for tT(u), it is because the scheduler has S disabled it. We 
now present our class of schedulers. Definition: A system has an enabled-only scheduler (cos) iff it 
is the case that (assuming initial state q0) : eos (i) If in states ql and q2 such * X that q0 > ql' 
ql > q2' where x 6 Z* is such that x does not contain any transitions for processes in ql.E, and ql.E 
= q2.E, then for each process 6 ql.E, ql. Py(~) iff q2.Py(~). e cos (2) If q.E ~ ~ and q0 > q' then 
 there exists some process ~ 6 q.E such that P (~) is true. Y Intuitively, condition (i) says that in 
deciding which processes to schedule, a scheduler should only use information pertaining to processes 
in the "enabled set" E. This seems to be a reasonable restriction. It is certainly met in FIFO schedulers, 
for example, Condition (2) says that if there is a non-empty set of "schedulable" processes, then the 
scheduler should schedule at least one of them. This also seems reasonable. Suppose the condition is 
not met. Then, in order that the waiting processes not be blocked indefinitely, the scheduler would have 
to either await the arrival of some new process, or wait for some change elsewhere in the parallel program. 
The latter event can best be modelled in the program state, not the scheduler state. The former events 
if such a thing is desired, could also be handled in the program state° Abstraction: Our next goal is 
to "abstract" the program state from the specification of a parallel program, eliminating considerations 
of the scheduler state. We will do this by merging together the two transitions of each synchronizer, 
thereby eliminating all p 's and t 's, and by using our notion ,W. of slmllar states to remove the 
scheduler state. Related to the enabled set E we de- fine what we call tlhe p roqram-abstract of a synchronization 
predicate P . The idea Y is that a process is in E iff the program- abstract of its synchronization 
predicate is true. Given P ~ the program-abstract of Pv' PA(Py), isY(~C)Py, where c is the vector of 
all scheduler variables. PA(P ) is true in state q iff there is a Y way to change the scheduler state 
of q so that P is true. Y Let [q] denote the ~ equivalence class of which q is a member. We define 
8, mapping states into equivalence classes of states, as follows. B (q) = [q], where q is such that 
 i) for all scheduler variables and non- instruction pointer program variables ^ v, q.v(~) = q.v(n), 
and 2) if q.i(~) = p~, then q.i(n) = p~ otherwise q.i(~) = q.i(n) Intuitively, we would like q to 
resemble the state one gets by "backing up" all processes that are at p~ ~o p~, for each Y. That is, 
we want a state for which no process has committed itself in a queue. Because of uncertain- ties about 
the scheduler state, we look at all possible scheduler states, hence the ~ equivalence classes. If 
a state q is such that q E 8(q)~ we call q a backup state. We now define the state set of our abstracted 
parallel program. Given a state set Q_. (for implementation), each 1 state compose~ of a program state 
and a scheduler state, we define QABS' the state set of the abstracted parallel program. Roughly, QABS 
is the image of QIMP under 8, which effectively "collapses" each synchronizer into a single trans- ition 
and eliminates the scheduler state. To be more precise~ we need to retain the concept of program variable 
in the states of QABS" We therefore define the isomorphism ~ mapping equivalence classes of states in 
QIMP to program states~ where ~([q]) is the program state common to all states in [q]. Hence QABS = 
[~(8(q)) I q 6 QiMP}. For convenience, we denote the composit- ion of ~ and 8 as ~. Hence the effect 
of on state q is to "back up" all processes v that are at Pw' and then yield just the -i program state 
of q. We also define ~ , the inverse of ~, mapping QABS into the equivalence classes of states in QIMP" 
 If Z denotes the set of trans- IMP ition names in our parallel program IMP, then we define ~ABS~ the 
set of trans- ition names for the abstractions intui- tively as follows. We let ZAB S be all but the 
type e transitions in ZiM P. The effect of the type s transitions is changed so that the enabling predicate 
becomes the program-abstract of the original enabling predicate~ and the action function is that of the 
original, restricted to the program state. We change the name of the type s transition tY(~)s to t~(~) 
~ and call its input place p~(~). For examples see figure 4. t v ~ when (k > 0 A m < i) do (k,m) <--(k-2, 
m*3) Figure 4 The abstraction of the synchronizer of Figure 3. More formally, we define ~ABS to be 
 the image of ~IMP under the mapping ~, as as follows = u(t~(~)) = A, the empty sequence ~(t~(~)) 
= t~(~) u(t(v)) = t(~), for all other transitions t(~). We extend ~ to a homomorphism in the usual 
way. It will be shown in Lemma 3 that if x q, q -~> , then ~(q) ~(x) > ~(q ) We ABS -i also define 
U , the inverse of ~, mapping into ~ : ABS IMP -l(t~(~)) = tV(~)t~(~) e -I U (t(~)) = t(~), for all 
other transitions t(~). -i is also extended to a homomorphism. Results: Before we give our results, 
we need to define two more terms. We have been using the term "deadlock" with its intuitive meaning, 
we now try to capture its meaning more precisely in the predicate "dead." Definition: (following [i]) 
We say that a process ~ is dead in state q if ~ has not executed an exit transition and there , exists 
no q' such that q > q' and ~ is enabled in q' We write this condition as dead (q). Definition: (Following 
[2]) We say that a predicate is q-reachable if there is a state reachable from q such that the predicate 
is true in that state. We now state our main result. Theorem If q0' the start state, is such that 
the instruction pointers of no processes reference a Pw (i.e., q 6 8(q0 )) , then (I) dead is q0-reachable 
in IMP iff (II) dead is q0-reachable in ABS, the abstraction of IMP. The theorem states that abstraction 
preserves deadlock properties. It should be noted that this theorem applies to a fairly large class of 
schedulers. It is certainly not intuitive that all of the schedulers in this class should have this 
property. An important idea used in handling the scheduler is that of a frozen syn- chronizer. We define 
a synchronizer to be frozen if, solely because of the program states any process that enters it will 
become dead. More formally: Definition: A synchronizer V is said to be frozen in state q if ~PA(Py) 
is q-invariant. We will show that if a state is reachable in ABS, then a corresponding state is reachable 
in IMP. Corresponding to a process being dead in ABS is that process having entered a frozen synchroni- 
zer in IMP. From this it will follow that if a process can become dead in ABS, then that process can 
become dead in IMP, there- by proving one direction of the theorem. The other direction is more difficult, 
 as a process being dead in IMP does not necessarily imply that the synchronizer is frozen. Consider 
the example of figure 5. ~'--~2 % tY J d_o_ enter queue e  ~'--~3' ~4 --7 when S > 0 S A at 
top of queue do S <-- S -i Figure 5 An example in which ~4 is dead, but ¥ is not frozen. Assume that 
S = 1 and that instruction pointers are designated by arrows.  69 Assuming a scheduler that gives process 
~. priority over process ~i+l' n4 is dead, 1 but v is not frozen since S > 0. However, y will become 
frozen as soon as ~2 or n4 perform t . s  It does not suffice to show that if a process can become 
dead in IMP, then the synchronizer can become frozen. It also must be shown that the synchronizer can 
become frozen in a backup state. This will then correspond directly to a process being dead in ABS. 
We first proceed to prove that II ~-I. we first determine where a process can become dead. Lemma i: 
Dead (q) in ABS implies that ? ~'s instruction pointer references Pa' for some v. The next lemma states 
that, given our conditions on the start state, q0' if a state is reachable in ABS, then a corresponding 
state is reachable in IMP. X  Lemma 2: If ~(q0 ) ABS > q, then -i (~q' 6-l(q)) q0 ~ (x) > q,. IMP 
 Proof: (by induction on the length of x). From the definitions we have that if 6 8(q0) , then q0 6 
~-l(~(q0) ). Hence q0 for x = A, we are done. Now suppose t(~) that ~ (q0) Y > qi > with ABS ABS qi+l 
' £  y 6 ~ABS" For the induction hypothesis, -.i (y) we have that q0 > q~' and IMP i  , -i E c~ 
(qi). We wish to show  qi i -I (t i,)) i > qi+l' with qi IMP -1 q~+l 6 ~ (qi+l).  For t(~) # t~(n), 
the result is trivial, so suppose that t(~') = t~(~). Now, -l(t~(~)) = t v(~)t~(~). Clearly u e tY(~) 
 , e ^ qi IMP > ~ for some q~ since tv(~)e has a trivial enabling predicate. Since -i q£ 6 ~ (qi) , 
q~.E = ~. Hence q.E = [~], and by cos (2), there is a state q" such   tv(~) that q ^ S > q". Clearly, 
IMP -i ) q,,  q" 6 ~ (qi+l ~ hence is our desired !  state qi+l" The following is a generalized 
converse of Lemma 2. Lemma 3: If ql "-'~---> q2 then IMP ~(ql ) U(x)> ABS ~(q2 )"  Proof: This is 
a simple induction on the length of x. The next lemma gives, for one direction, our desired connection 
between a process being dead in ABS and that process awaiting a frozen synchronizer in IMP. Lemma 4: 
If, for some ~, dead (q) in ABS, then (Vq' E -l(q)) y is frozen in q', where v is the synchronizer for 
which is waiting in ABS. Proof: That ~ is waiting on a synchroni- zer v in ABS follows from lemma i. 
The lemma then follows from the contra- positive of lemma 3. Proof that (II) ~ (I): Suppose q is a reachable 
state in ABS such that dead (q). By lemma 2 we know that (~q' E -l(q)) such that q' is reachable in 
IMP. By lemma 4, V is frozen in q', where y is the synchronizer being entered by ~. ~ is not dead in 
q', but after performing transition tv(~) it clearly will be. e  We now concentrate on the proof of 
(I) ~ (II). similar to lemma 1 we have: Lemma 5: Dead (q) in IMP implies that v  ~'s instruction pointer 
references Pw' for some v. If a process is dead in IMP, it is dead because of the values of the scheduler 
variables, the program variables, or both. The nextlemma states that if a process is dead in IMP, there 
is a reachable state such that it is dead solely because of the values of the program variables, i.e., 
the process is not stopped due to the action of the scheduler. We first give the following definition. 
 7O Definition: A synchronizer y is said to be active in state q if there exists a process such that 
q.i(~) = p~. Lemma 6: If q0 IMP > q and dead (q)~ then there exists a w state q' such that q IMP-q' 
and all active synchronizers are frozen. V Proof: That q.i(n) = Pw for some v follows from lemma 
5. Suppose that dead,(q) but v is not frozen~ i.e.~ there exists a state reachable from q such that P 
(~) is Y true but t ¥ is not enabled. We will show s that there is state reachable from q satisfying 
the lemma~ by first showing how to reach a state in which all processes Y for any v are dead. We will 
then at Pw show that all such synchronizers are frozen. We assume w.l.o.g, that q.E = (if not~ such 
a state is clearly reachable). Let q.R = {nli(~) = Pw A ~dead (q)]. We wish to show that W ora process 
~ to be in R there must be a state reachable from q such that ~ is enabled for the type s transition. 
Let x be the shortest possible transition sequence such that q ~ q' and some E q.R is enabled'in q'. 
By definition a type e transition only causes a trivial change to the program state (by trivial we mean 
it only affects the instruction pointers (in the program state)). Hence, by minimality of x~ any type 
e transition in x is followed (not necessarily immediately) by a corresponding type s transition. Hence 
there are no new pro- cesses at any pw ~ and we can conclude that q'.R = q.R. We also have that tV(~) 
x s q .~ q' > q" for some q"~ and IMP IMP therefore q".R c q.R. By repeatedly applying this procedures 
we will arrive in a state q such that q.R = @. consider the processes at Pw in state q. For an Z of 
them to join E requires a nontrivial change to the program state. consider a transition sequence y such 
that Y > ~, and a process ~ such that IMP dead (q). We claim that if ~ E ~.E, then cannot be dead. 
 Suppose that y contains some type s tz~nsitions. For each t v there must have S been a t Y. Let us 
then modify y by moving e each type e transition to the right so that each transition t v is immediately 
 S preceeded by a t v. For examples e tlt~ (nl) t2t~ (~2) t3t: (~i) t4t: (~2) becomes tlt2t3t ~(~l)t~(~l)t4t~(~2)t~(~2 
). The question is~ is this a valid transition sequence? The modification could only possibly affect 
the enablement of the type s transitions. But by eos(2)~ they are still enabled~ since E in each case 
is a singleton set. Let z represent the possibly modified version of y. We have that q z ~. ~, for some 
state q, where IMP E q.E. But we also have that q.E = [~] and hence ~ is enabled by cos(2), contradicting 
our assumption that n was dead. Having shown that if a process can become dead in IMP, it can be awaiting 
a frozen synchronizers we now need to show that it can be awaiting a frozen syn- chronizer in a backup 
state. Unfortunate- ly~ we cannot shows due to obvious reasons~ that from a "frozen state" we can reach 
a backup state. What we will do is show that if a system can reach a state in which a process is awaiting 
a frozen syn- chronizer~ then it is also possible that the system can reach a backup state in which that 
process is awaiting a frozen synchronizer. Lemma 7: If q0 -------> q such that all IMP active synchronizers 
are frozen in q~ then there exists a state q' such that , > q' ~ all active synchronizers are" q0 
IMP frozen in q' and q' 6 B(q') proof: The proof is based on the follow U ing observation. If in state 
q'~ i(,) = p~ tY(-) x I x2" e and q' ~MP '-~ ql > q2 > "'"  Xn_ 1 > qn' with x i 6 ~IMP' such that 
XlX2...x n (Vi) ~ ~ qi.E, then (Z~q' > q, IMP  i.e., ~ can be "backed up" without affecting the transition 
sequence XlX2...x n. This follows from eos(1). Let V denote t[he set of processes whose instruction 
pointers reference Pw for some synchronizer. If V = @, we are done, since q 6 8(q). Otherwise, let ~i 
 denote the last process to enter V. By our assumption, it is awaiting a frozen synchronizer. By t[he 
above observation, we can "back up" ~i to Pe and still have a reachable state. Since the type e transition 
has no nontrivial affect on the program state, all the synchronizers are still frozen. By repeating this 
procedure until V = @, we achieve a reachable backup state, in which the appropriate synchronizers are 
still frozen. Proof: that (I) ~ (II) We are now in a position in which we can apply the contrapositive 
lemma 2. This states that if IMP can reach a backup state from which no transition sequence containing 
t~(~) is possible, then a state is reachable in ABS such that no sequence containing tv(~) is possible. 
 a  By lemmas 5,6, and 7 we have that dead being reachable in IMP implies the premise of this statement, 
and the conclusion certainly implies that dead is reachable in ABS. ~ Conclusions: We have shown that 
for a large class of schedulers, the schedul- ing policy is irrevelant as far as deadlock is concerned. 
Hence one can prove properties of the program state independent of what the scheduler is doing, avoiding 
complicated interact- ions, and thereby simplifying correct- ness proofs. We have therefore seen that, 
in a sense, scheduling only affects the "local" behavior of a system. References: [1] Doeppner, T. 
W. Jr., and Keller, R.Mo, On the Relevance of Abstract Models in Modeling Semaphore Imple- mentations, 
TR 193, Computer Sciences Laboratory, Department of  Electrical Engineering~ Princeton University (October, 
1975).  [2] Keller, R.M. On Formal Verification of Parallel Programs, To appear in CACM. [3] Lipton, 
R.J., Reduction: A Method of Proving Properties of Systems of Processes, CACM (December, 1975). Acknowledgement: 
' I owe a sincere debt of gratitude to Professor Robert Keller. He co-authored a previous paper with 
me~ made numerous corrections to this one, and has helped me immensely through many valuable dis- cussions. 
I am also grateful to Mrs. Gerree Pecht for typing the several versions of this manuscript for me. This 
work was supported by the National Science Foundation through grant GJ-42627   
			