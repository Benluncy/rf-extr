
 Shallow Multiplication Circuits Michael S. Paterson Dept. of Computer Science University of Warwick 
Coventry CV4 7AL, England Abstract Paterson, Pippenger and Zwick have recently ob­tained a general theory 
that describes the opti­mal way in which given carry-save adders can be combined into carry-save networks. 
Their work produces, in particular, multiplication circuits of depth 3.71 logz n (these circuits put 
out two num­bers whose sum is the result of the multiplication). In this work an extension of the above 
general the­ory is obt ainecl. We now consider carry-save adders that may receive inputs and produce 
outputs us­ing several different represent ation methods. We describe the optimal way of utilising any 
such col­lection of carry-save adders. The optimality proof uses the min-max theorem of game theory. 
By using several different representation standards, the depth of multiplication circuits can be surpris­ingly 
reduced to 3.48 log2 n (again two output num­bers are produced). We introduce bit level redun­dancy by 
using a novel coding scheme in which each bit is distributed over four wires, Interestingly, the information 
on these four wires is usually not trans­mit ted simultaneously. Finally, an analogy is made between 
the optimisa­tion problem faced by the circuit designer and the optimisation problem faced by an investor, 
offered *This work was partially supported by the ESPRIT II BRA Programme of the EC under contract # 
3075 (AL-COM). Authors e-mail addresses: nw.p@dcs.warwick. ac.uk and zwick@math. tau. ac.iJ Permission 
to copy without fee all or part of this matariel is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fea and/or specific permission. 24th ANNUAL 
ACM STOC -5/92/VICTORIA, B. C., CANADA e 1992 ACM 0.89791.51 2.7/92/0004 \0429...$j .50  and Wise Financial 
Investments * Uri Zwick Dept. of Computer Science Tel Aviv University Tel Aviv 69978, Israel  a collection 
of financial investment plans, each in­ volving perhaps several different currencies. This analogy is 
used to obtain intuitive explanations of the results obtained. 1. Introduction A carry-save adder (or 
CSA for short) is a unit with k input numbers and 1 output numbers (t < k), with the property that the 
sum of the outputs is always equal to the sum of the inputs. It has long been known (see [2] ,[4] ,[9]) 
that constant depth carry-save adders can be built and that they can be used to obtain logarithmic depth 
circuits for multiple addition, multiplication and related problems. Since the multiplication of two 
n-bit integers is such a basic task it is interesting to investigate the exact depth it requires. In 
particular we would be int crested in knowing the minimal constant d for which there exist multiplication 
circuits of depth (c$+ O(l))logz n. An attempt to tackle this problem was made in [6],[7]. While that 
work did not identify this minimal 6, a task which is probably still far beyond our reach, it did supply 
a good upper bound (6 < 3.71) and presented a general theory that described the optimal way in which 
given carry-save adders could be used to construct carry-save networks that reduce the sum of 7t numbers 
to the sum of only a fixed number of numbers. In particular, it was shown that the 3.71 logz 7~ depth 
construction was optimal within its class, i.e., within the class of networks built from CSA Sj.z s (3 
+ 2 carry-save adders) made up of arrays of standard FA3 s (3-bit full-adders). 0 11 2 3 t d (a) (b) 
Figure 1.1. A 3-bit full-adder and the resulting 3 ~ 2 carry-save adder  In this work a generalisation 
of the theory devel­oped in [6], [7] is presented. We begin the descrip­tion of this generalised theory 
with two concrete examples. Fig. 1. l(a) shows the standard implementation of an FA3. This implementation, 
as all other implementations considered in this paper, uses only dyadic (2-input) gates. Using this implementation, 
CSA SA2 units with the time characteristics shown in Fig. l.l(b) can be constructed. The CSA3A2 unit 
of Fig. 1. l(b) is said to have the characteristic polynomial 2 + x x2 x 3. Each input contributes 
a positive term and each output a negative term to this polynomial. The terms are all powers of x, where 
the exponent depends on the time at which this input or output is supplied or produced. It is an immediate 
consequence of the theory of [6],[7], that the optimal networks for the carry-save addition of n numbers 
that could be constructed using this CSA 3+2 as a basic building block have depth about log~ n where 
A &#38; 1.20557 is the principal root, i.e., the largest real root greater than 1 of the characteristic 
polynomial of the unit. Since logx n z 3.71 logz n, this yields the upper bound referred to earlier. 
Assume that we have at our disposal the collection of CSA3+2 S given in Fig. 1.2. The terms so, S1 and 
52 labeling the inputs and outputs of these units, describe the standard in which each input is required 
and in which each output is produced. We do not specify for the time being, what these different standards 
are. We are not allowed to connect, say, an s2-output directly into an so-input (this may cause a short 
circuit). We have however the means of translating between the different standards, if we so wish. In 
this case we assume that we can use the conversion units shown in Fig. 1.3. Some of these translations 
are done instant aneously (such as translating an so to an S1 or 52) but others take time. We are now 
given n input numbers, in the so standard, and we want to build a network that will return two numbers, 
again in the so standard whose sum is equal to the sum of the n original numbers. What is the minimal 
depth that such a network would require? The theory we develop here gives a general answer to questions 
of this type, Given any collection of units with possibly many different input and output standards, 
we describe the way in which they could be combined optimally to reduce the sum of n inputs to the sum 
of only a fixed number of out puts. We will assume that conversion between any two standards is possible, 
although such a conversion may sometimes incur a large delay. Nonetheless, the possibility of such conversions 
shows that the standard in which the initial inputs and final outputs are required is of little importance, 
as the initial and final conversions will only add a fixed delay to the networks. The fixed number of 
numbers obtained as the output oft hese networks may be taken to be the minimal number of outputs among 
the CSA units available. An application of this general theory to the specific question posed earlier 
concerning the collections given in Fig. 1.2 and Fig. 1.3 will give an answer of about 3.48 log2 n. 
so soso so so b S1 so B so S1 soS1 soS2 S1 S1 S1 S2 S2 . 0 S1 S1 DEF bbb so S1 soS2 soS2 Figure 1.2. 
A collection of CSA units that use three different standards &#38;,; J ,; + S1 S2 .91 so Figure 1.3. 
Conversion units between the three different standards As the reader may have suspected, the collections 
To get optimal constructions that match the lower of Fig. 1.2 and Fig. 1.3 were not chosen arbitrarily. 
bounds of Section 4, we have to introduce a We have found three transmission standards so, S1 reasonable 
causality assumption that states that and S2 for which each of the units shown there an output of a unit 
can only depend on inputs to is realizable using 2-input binary gates. Thus the that unit supplied at 
earlier times. The causality depth 3.48 log2 n obtained does correspond to a reaJ assumption and its 
consequences are considered in construction. more detail in Section 5. In the next section we describe 
the three transmis- Using the causality assumption, we present in sion standards so, S1 and S2 and describe 
the con-Section 6 constructions that match the lower struction of the units shown in Fig. 1.2 and Fig. 
1.3. bounds of Section 4. The proof that the lower and In Section 3 we present the analogy between upper 
bounds of Sections 4 and 6 do in fact match the network construction problem and a financial uses the 
min-max theorem of game theory and it is invest ment problem. This analogy intuitively given in Section 
7. suggests the idea of introducing the exchange rates that support the proof of the lower bound in We 
end the extended abstract by some concluding Section 4 and that of introducing the portfolios in remarks, 
open problems and suggestions for future Section 6. work. ab d;d: e Figure 2.1. An implementation of 
unit A 2. Split-input full adders Consider the standard implementation of an FA3 given in Fig. l.l(a). 
Note that a delay is introduced on the left input wire to the OR gate computing the carry output d. This 
seems to suggest that the design could be improved, but how? The answer is simple. We do not have to 
insist on producing the output d as a single entity. We can simply remove the bottom OR gate and get 
two output bits d~, d; such that d = d) V d: = d[ @ d; (note that d; = aAb and d:= (a@b)Ac are never 
1 sinmlt aneously). If we are then required to OR (or XOR) d with another bit f supplied at the time 
d: is produced, we can reassociate (d; V d;) V f as (d~v f )Vd;, thereby gaining one time unit. It is 
the accumulation of these time units that will enable us to lower the delay of the carry-save addition 
and multiplication circuits, But what will we do when required to AND d with another bit 4? It seems 
that we would then have to OR the two fractions d;, d;, losing the time unit we tried to gain. To overcome 
this problem we not e that we can easily get, within the same time limits used to obtain the pair d~, 
d[, another pair d;, d$ such that d = d; A d;. To get this pair we simply use the following alternative 
majority formula d = (a V b) A ((a A b) V c). We may therefore taked~= aVbanddQ=(a Ab)Vc. A description 
of the unit we get, which we call unit A is given in Fig. 2.1. Note that the output bit d is coded over 
four wires (d:, d$, d;, d;) and that the information on the wires d;, d; flows one unit of Table 1. Generic 
forms of formulae used to compute the outputs d;, d;, e. A: (aob)oc B: (((aob1)ob2)oc c: (((a ob)oc1)oc2 
D: ((((uI o h) o az) o b~) o c E: ((((a obl)obz)ocl)ocz F: (((((uI o h) o az) o h) o cl) o C2 time after 
the information on the wires d) , d?. We consider normal input and output bits to conform to standard 
so, and split bits, like d of the previous paragraphs, to conform to standard S1. We consider a split 
bit (d~, d;, dy, d;) to be produced (or supplied) at time t if d~, d} are produced (or supplied) at time 
t 1 and d;, d; are produced (or supplied) at time t. We will also encounter split bits of standard S2 
in which the time difference between the availability y of the two pairs d:, d; and d;, d; is two time 
units. With these conventions we see that the time characteristics of unit A of Fig. 2.1 do correspond 
to those of unit A of Fig. 1.2. The output bits d; = (a@ b)Ac, d; = (aAb)Vc and e = (a@ b) @ c were all 
obtained using formulae with the generic form (a o b) o c. Other generic forms that may be used to design 
split-bit FA3 units wit h no int ernal delay are given in Table 1. To get concrete formulae for d;, dj 
and e from these generic forms, the generic connective o should be replaced by an appropriate sequence 
of V, A and @ connective. To get the concrete formulae for e for example, all the connective should be 
taken to be @ (and al, a2, bl, b2, cl, C2 should be taken to v v v v ). The generic expressions be aY,a2,bl,bz,cl,cz 
for the fractions d~, d; are obtained from those of Table 1 by removing the last level (or two levels) 
of nesting involving c (or c1 and C2). A detailed construction of units C and D is given in Figs. 2.2 
and 2.3. The construction of units B, E and F goes along the same lines and requires no new ideas. The 
conversion units U, V, X, Y are also easily implemented. Note that we may convert an so-bit a ab d: 
ed; Figure 2.2. An implementation of unit C into a split bit b = (b~,b~,b~,bj) in standard S1 or SZ instantaneously 
by taking b; = bj = a and by letting b) = O and b: = 1. This takes care of units V and X. Units U and 
Y are simple to design. The question now is whether all this extra effort was worthwhile. Can we use 
the collection of Fig. 1.2 to improve the result obtained using the gadget of Fig. 1.1? As indicated, 
the answer is yes. Using the new collection we can design circuits with depth 3.48 logz n. This will 
follow from the general construction of Section 6. The results of Section 4 will show that this is indeed 
the best that we can squeeze from this collection.  3. Financial Plans Before proceeding with the lower 
and upper bounds of Sections 4 and 5 we introduce a new interpret a­tion to the problem with which we 
are faced. Consider again the gadget of Fig. I. I(b), thk time upside-down with inputs and outputs interchanged. 
It now corresponds to a financial plan of the following kind: invest $1 now, $1 in a month s time and 
get in return $1 in two months time and $2 in three months time. How much money could a shrewd investor 
with initial capital of $2 accumulate after n months? t d; Figure 2.3. An implementation of unit D The 
theory obtained in [6] ,[7] supplies an answer to this question. The investor can get about c . An dollars 
after n months, where c is some fixed constant and A is the principal root of the characteristic polynomial 
of the gadget/plan. Note that this principal root simply corresponds to the effective interest rate of 
the plan. In this work we are faced with a more complicated situation. We are given a collection of financial 
plans that may involve several different currencies. Gadget C of Fig. 1.2, for example, corresponds to 
a plan that calls for the investment of $1 and NIS 1 (new Israeli Shekel) at time O, and promises in 
return .41 in a month s time and $2 in three months time.  4. Lower bounds We first extend the definition 
of characteristic polynomials to the case in which more than one standard is present. An input (output) 
of standard Sj required (produced) at time i contributes the term +Sj Zz ( sjza) to such a characteristic 
polynomial. The symbols Sj are regarded as indet erminat es. The characteristic polynomials of the units 
shown in Figs. 1.2 and 1.3 are therefore : A = (2+ Z Z2)OS0 Z20S1 B = (1+$2 Z3).SO+(Z Z3).$1 c = (2 
z3) so +# sl-z3 s2 D = (Z2 Z3).S O+(l Z3).S1+X.S2 E = (l Z4). SO+(Z+Z3). SI Z4. S2 F= X*. SO+ (1+23).s]+(z 
Z4).S2 and u = X sl)+sl v = So sl x = sf)-s2. Y = S2 S1 When connecting several gadgets to form a net­work, 
delays may be introduced, i.e., some outputs may be ready afew time units before they are ac­tually needed. 
We may transform a network with internal delays into one without such delays by in­troduc.ing explicit 
delay units. For simplicity we will assume that units capable of delaying an input of any given standard 
by one time unit are always available. Note that in the concrete example of Figs. 1.2 and 1.3, delay 
units for every standard are easily obtained by combining two or more con­verters. The essential parameters 
of a network (i.e., the number of inputs and outputs it has at each time unit ) are fully described by 
specifying the number of units of each type initiated at each time unit. Thus the characteristic polynomial 
of any network constructed from units G1, . . . . G,n with characteristic polynomials gl (z; s),..., 
g,n(z; s) (where s denotes the vector of standards) could be written in the form .fl (~)gl(z; s) + f2(~)92(~; 
s)+ . . .+.ftn(z)g~(z; s) where each ~i(x) is a univariate polynornkd in z with non-negative integer 
coefficients that specifies how many copies of unit Gi should be placed at each time unit. The characteristic 
polynomial of a network Iv((c; s) = &#38;)gi(z; s) i=l specifies how many inputs or outputs of each 
standard the network has at each time unit. We are interested in networks that take at least n inputs 
at time O and return at most some fixed number 1 of outputs. In this section we derive a lower bound 
on the total delay of such networks. The characteristic matrix M of a collection G1,. . . . Gm of gadgets 
that use standards so,..., s&#38;~ is an m x k matrix in which the entry m;,j is the coefficient of the 
indeterminate Sj in gi(x; s). The characteristic matrix of the collection of gadgets of Fig. 1.2 and 
Fig. 1.3, for example, is so .qS2 A 2+X X2 X2 o B 1+ Z2 Z3 X X3 0 c 2 X3 X2 X3 D X2 X3 1 X3 x 1 X4 X+X3 
X4 X4 1+X3 X X4 u x 1o v 1 10 x 1 o 1 Y 0 1 1 We are now ready to state the lower bound. Theorem 1 If 
A> 1,v E(R+)k, v # O(i.e., v is a non-zero k-dimensional vector of non-negative real numbers), and M(A). 
v ~ O then any network composed of the units G1, . . . . G~ that takes at least n so-inputs and produces 
at most/. so-outputs (and no outputs of any other standard) has delay at least logJ(n/l). Proof : The 
condition M(A) -v <0 implies that g:(~; V) s Ofor 1< i < m. Let N be anetwork with characteristic polynomial 
N(x; s) = ~fi(x)gi(x; s) i=l where each ji(x) has non-negative (integral) coef­ficients. Since gi(~; 
v) <0 for 1< i < m, we have N(A;V) <0. By introducing delays if necessary, we may assume that all the 
inputs to the network IV are required at time O. If N has n! > n so-inputs at time O and only 4 < ./ 
so-outputs at times dl < . ..< dl, (and no other outputs), then P N(x; s) = (n ~# )-So , i=l Since 
N(A; v) <0 we get that (n ~~=1 ~d~).vo < 0. The existence of converters between any two different standards 
implies that vj > 0 for every O<j<k l, since ifvi>O but vj<O then the condition M(A). v < 0 would be 
violated in a row corresponding to a converter from s~ to sj. In particular V. >0 and therefore n ~~=1 
Ad; <0, which implies that d ~ log~(n/1), where d = dl~ is the delay of the network. o When M is the 
characteristic matrix for Figs. 1.2 and 1.3, the minimal ), for which there exists a non-zero vector 
v E (13+)3 that satisfies M(A).v < 0, turns out to be the principal root of the equation 3A3 + 2A2 2A 
 6 = O. A corresponding vector is v = (1,vl, v2) where VI = 1 + A l + 2A 2 and V2= 1 A-l +A-2 +4A-3. 
Thus AR 1.22096, v] H 1.16064, V2 E 1.04941 and log~ n &#38; 3.47201 log2 n. These values are obtained 
by solving the three simultaneous equations A(A; v) = C(A; V)=D(A; V)=o. Note that assigning the numerical 
values V., . . . . v~_l to the indeterminates so, . . . . Sk l corresponds to setting a fixed exchange 
rate between the different currencies . 5. Causality To get constructions that match the lower bounds 
of the previous section, we need to assume that the gadgets with which we are dealing are causal. Definition 
A unit G is said to be causal if an output produced at time t depends only on inputs supplied at times 
strictly less than -t. As a consequence we get that a causal carry-save adder can produce a useful, non-constant, 
output only after receiving at least one input and that it cannot receive any input after all the outputs 
have been produced. A further consequence of causality that will be used in the next section is the following 
property: if all the inputs supplied to a causal unit before time t are zero, then all the outputs at 
or before time t are constants. Note that any gadget implemented using Boolean gates or any other conceivable 
technology will certainly be causal, since it cannot predict its future inputs. The conversion units 
V, X and Y are not strictly causal as they produce their outputs instanta­neously. Any combination of 
these units with other strictly causal units will yield a strictly causal con­st ruct however, so no 
problems arise in the con­structions and proofs. We note that at the imple­ment ation level these units 
seem to violate causal­ity in a stronger sense. Unit V for example puts out a part of the S1-output before 
it gets its so-input. However this part is identically constant. If G is a gadget, we denote by G[tl 
the gadget obtained by removing from G all the inputs before time tand all the outputs at or before time 
-t. Note that if G is causal, then Gltl could be emulated by feeding zeros to all the inputs required 
before time t and ignoring all the outputs that are produced at or before time t (as they are all constant 
anyway). Causality has an interesting interpretation from the reversed point of view relating to financial 
plans. It corresponds to allowing the investor to stop all further payments to a financial plan at the 
cost of receiving no further returns in the future, but without any other penalty. 6. Construct ions 
We can now present our constructions. Theorem 2 If ~ >1 and u ~ (R+)~, u # Oand uTJk?( ~) ~ O, then there 
exist networks with at least Q(n) inputs at time O and at most O(1) outputs, all produced before time 
log~ n + O(1). Proof : Let us at first ignore problems of integrality and consider networks that may 
use a non-integral number of gadgets at any level. Pogx ~1 ~-~z~, and let the gad- Let Pn,~(z) = n ~f=o 
get 11 correspond to a mixed investment portfo­lio in the gadgets G1, . . . . G,n, with corresponding 
weights u], . . ., u~, so that H has the characteristic polynomial h(z; s) = ~&#38; uigi(z; s). We consider 
the network IVn with characteristic polynomial ~m(x; S) = P,,,x(z). h(x; S) built from copies of H as 
specified by the polyno­ mial Pm,~(x) (the coefficients of Pn,X(Z) prescribe how many copies of H are 
placed at each level). We can classify the inputs and outputs to the gadget H according to their standard: 
k 1 h(z; s) = ~hj(z)q . j=(l The condition UT oM(A) 2 0 is equivalent to the condition hj(~) Z O for 
O < j < k 1. We divide each hj(z) by 1 A-lz and get that where h~~Ofor O~j~k -1. Note that l ~-dxd 
P,,,A(z) = n ~_J_,z where d = (log~ nl + 1. Thus where k l k l h (z; s) = ~ h~(z)si and h (s) = ~ hfij 
. jdl jd) All the coefficients of h are non-negative and therefore correspond to inputs. As n~ d < 1 
the term nA dzdh (x; s) specifies a finite (perhaps fractional) number of inputs and outputs all within 
time d+ ah where ah is the degree of z in h (z; s). We are left with the term n ch (z; s). Each of the 
units Gl, . . . . G~ is causal, and therefore the unit B obtained from them is also causal. In particular, 
ifweletA=ah,then attime Atheunit H produces some outputs and does not take in any inputs. As a consequence, 
all the terms in h (z; s) wit h degree i?hl = A 1 in x have positive signs. Since H is causal, any network 
, such as Nm, composed from it is again causal. We now consider the network N. [A-l] obt~ned by feeding 
zeros to all the inputs required before time A 1 and ignoring all outputs at or before time A 1. This 
network has Q(n) inputs at time A 1 and perhaps some additional inputs at other times, but only O(1) 
outputs, all within time log~ n + O(l). This network satisfies all our requirements except that it usually 
involves fractional gadgets. The solution to the integrality problem is quite simple. Consider the network 
It is easy to check that the coefficients in N; differ from the corresponding coefficients in N. by at 
most an additive constant. Thus the network N; will still have Q(n) inputs at the start (time A 1) but 
may now have O(1) additional outputs at every time unit up to log~ n + O ( 1). Since these additional 
outputs trickle out very slowly (only a fixed number at each time unit), it is easy to reduce their sum 
to the sum of a fixed number of outputs at time log~ n + O(1) by adding a fixed number of carry-save 
adders at each level. This establishes the validity of the theorem. 1 Let A N 1.22096 be the principal 
root of the equation 3A3 + 2A2 2A 6 = O. It can be verified that (2 -A3).A(A; s)+ C(A; S)+ ~2.~(Z;S) 
= O where 2 A3 ? 0.17985. This corresponds to a portfolio using which networks of depth log~ n s 3.47201 
logz n could be constructed. These networks make optimal use of the gadgets shown in Figs. 1.2 and 1.3. 
Note that units l?, E, 1 are not used at all by these networks and that the converters U, V, X, Y are 
needed (if at all) primarily at the initial and final stages.  7. The min-max theorem An easy consequence 
of the von Neumann/Morgen­stern min-max theorem of game theory (see [5]) is the following: Theorem 3 
For every m x k matrix M of real numbers, there exists a vector v c (R+)k, v # O, such that ikf. v <0 
or a vector u c (R+) , u # O, such that UT. M z O. This theorem establishes the optimality of the lower 
bounds and constructions presented in Sec­tions 4 and 6. For every A > 1 we either get a lower bound 
of log~ n O(1) or an upper bound of log~ n + O(l), or both. Continuity considerations References Fischer 
M. J., Meyer A. R., Paterson M. S., Q(n log n) lower bounds on length of Boolean formulas, SL4J4 J. Comput., 
Vol. 11 (1982), pp. 416-427. Karatsuba A., Ofman Y., Multiplication of multidigit numbers on automata, 
Soviet Physics Dokl,, Vol. 7 (1963), pp. .595-596. Khrapchenko V. M., A method of deter­mining lower 
bounds for the complexity of n-schemes, Mat. Zametki, Vol. 10 (1972), pp. 83-92 (in Russian). Math. Notes 
Acad. Sci­ences USSR, Vol. 10 (1972), pp. 474-479 (En­glish translation). Khrapchenko V. M., Some bounds 
for the time of multiplication, Problemy Kibernet., Vol. 33 (1978), pp. 221-227 (in Russian). von Neumann 
J., Morgenstern O., Theory of Games and Economic Behavior, Princeton Univ. Press, 1944. Paterson M. S., 
Pippenger N. and Zwick U., Faster circuits and shorter formulae for mul­tiple addition, multiplication 
and symmetric Boolean functions, Proceedings of the 31st Ann. IEEE Symp. on Found. of C omp. Sci., St. 
Louis 1990, pp. 642-650. Paterson M. S., Pippenger N. and Zwick U., Optimal carry save networks, Boolean 
func­tion complexity: Selected papers from the LMS symposium, Durham 1990. To appear, Cam­bridge Univ. 
Press, 1992. Paterson M. S., Zwick U., Shallow multiplica­tion circuit s, Proceedings of ARITH-10, the 
10th IEEE Symposium on Computer Arith­metic, Grenoble, France, 1991, pp. 28-34. Wallace C. S., A suggestion 
for a fast multi­ plier, IEEE Trans. Electronic C omp. EC-13 (1964) pp. 14-17. use networks of carry-save 
our results are presented in circuits model, we think that here may have practical value The circuits 
described in this {v, A, @}. In [8], a construction depth about 4.95 logz n over presented. This construction 
block a unit with 11 inputs with 6 inputs and 3 outputs show that, for the maximum a log~ n + O(1) upper 
bound, sponding log~ 71 O(1) lower A for which we also get bound. we get a corre­ [1] 8. Concluding remarks 
[2] The multipliers already follow of many Wallace s present suggestion day CPU units (see [9] ) and 
[3] equal to the depth of multiple addition? there a finite collection of gadgets using optimal depth 
circuits for multiple addition obtained? How far from optimal are our circuits? best lower bound currently 
known for the of multiplication over the full binary basis logz n + fl(log log n) (see [1]). Over B2 
 {6, -}, the unate clyadic gates, bound on the depth of multiplication Khrapchenko s lower bound [3] 
for Obtaining better lower bounds for is a challenging problem. Acknowledgement The authors would like 
to thank helpful discussions on the min-max game theory. adders. Although the idealised Boolean some 
of the ideas used in the future. paper use the basis of multipliers with [4] the basis {V, uses as a 
and 4 outputs. over the basis yielding multiples with depth about 3.57 logz n, may also be found there. 
It would be interesting to [6]know whether the methods described in the present paper yield further improvements 
when applied to such larger units. From the theoretical point of view many questions remain unanswered. 
Is the depth of multiplication Is which can be [7] The depth l?2 is Uz = [8] the basis A,m} is building 
A unit [5] {A, 6)}, a 2 log2 n lower follows from [9] formula size. multiplication Noga Alon for theorem 
of  
			