
 VALIDATION OF A QUEUEING MODEL WITH CLASSES OF CUSTOMERS C. A. Rose Naval Electronics Laboratory Center 
San Diego, California 92152 Abstract -There have been many queueing models of computer systems published 
in the literature, but relatively few studies have appeared in which the models have been validated on 
actual systems. A procedure is described which permits an analyst to obtain values for the parameters 
of queueing models using measured statistics of operational computer systems. The particular model which 
was validated is the first queueing network model which will permit more than one class of customer. 
Parti- tioning a computer system environment into classes of timesharing and batch jobs appears to be 
useful, and the model was validated with these classes on an IBM 370/155-2 and an IBM 370/168. INTRODUCTION 
 There have been many queueing models of com- puter systems and subsystems published in the literature, 
but relatively few studies have appeared in which the queueing network models have been validated on 
actual systems. Recent survey papers for this area include [2] and [4]. Vali- dations which have been 
reported include [i], [7], [8] and [i0]. The queueing network models in [3], [5] and [6] are the first 
which will permit multi- ple classes of customers. Partitioning a computer system environment into classes 
of timesharing and batch jobs appears useful, and this paper will describe in detail the procedure for 
validation of a theoretical model on an IBM 370/155-2 using these classes. Results of validations on 
an IBM 370/155 and on an IBM 370/168 will also be men- tioned. The specific model which was validated 
is described in [3], with the crucial normalization constant determined as in [5]. The model is motivated 
by the concept of a computer system as a network of processors (CPU's, 2/O processors, terminals) and 
a collection of customers (jobs, tasks). Of particular interest is the ability to group the customers 
into classes. Four types of service centers are modeled. Type one service centers (FCFS scheduling) can 
represent either CPU or I/O channel operation. Type two (processor sharing [PSI) or type four (LCFS preemptive 
resume) service centers can be used to model CPU's, de- pending on whether a round robin or a preemptive 
scheduling policy is used by the operating system. Type three service centers (as many servers as customers) 
are appropriate models for terminals. For this particular application, it is assumed that a fixed number 
N of customers (programs) traverse a closed network consisting of the central processor (CPU) and the 
I/O channels. A customer alternately receives service from the CPU and one of the channels. The customers 
may be partitioned into R classes. After completing service at the CPU, a customer selects a channel 
according to a probability Pi(r) associated with that channel and which may be class dependent. The CPU 
scheduling discipline may be either FCFS or PS. If the CPU is FCFS, its mean service time (MST) is i/Uo; 
if the CPU is PS, each class of customer has an MST of i/uo(r). The MST of each channel i is i/u i. 
Figure 1 depicts the model. At this point, a discussion is in order regarding type two, or processor 
sharing, service centers. Processor sharing (round robin) may not be a good approximation for computers 
with high overhead or long quantum times. For good results, the quantum time should be approximately 
fifty times as long as the computer switching time. Also, the quantum time of service should be less 
than the mean CPU burst time, where burst time is the CPU processing time between I/O interrupts. If 
mean CPU burst time is less than the quantum time, the scheduling policy is more FCFS than PS and a type 
one service center should be used. One should carefully note that a type one server (FCFS), be it a 
CPU as discussed above or an I/O channel, is assumed to have an exponential service distribution which 
is class independent. In other words, mean service times for all classes of customers are drawn from 
the same exponential distribution. Conversely, branching probabilities are less restrictive, and may 
be class dependent for all types of servers. The required input parameters to the model are: i. Number 
of classes of customers 2. Whether the CPU scheduling discipline is FCFS or PS 3, Channel branching 
probability (Pi(r)) 4. Channel i mean service time (CH i MST)  5. CPU mean service time (CPU MST) 
 6. Degree of multiprograrmming (N)  The objective of these experiments was to study system behavior 
rather than a detailed examination of the operation of a particular sub- system. In particular, these 
experiments did not require either a separate or an embedded paging model. Hence the paging statistics 
were included as an integral part of system statistics, e.g., the number of page-in/page-outs were included 
in the computation of the branching probability for the channel with the paging pack. Of course, this 
 318 N CUSTOMERS P-~ Queue i/u I P2(r) ~ Queue . ~f~ Queue'~ 1/u 2 FCFS: 1/u Â° PS : I/uo(r)  Pm(r) 
~.f Queue '~ 1/u m FIGURE I. QUEUEING NETWORK MODEL 319 simplification may not be valid in all cases, 
but good results using this assumption were achieved for these experiments.  The first parameter (number 
of classes of customers) is specified rather than measured, according to the job environment and the 
objectives of the analysis. The scheduling discipline is also specified. It may be determined from either 
a knowledge of the workload and computer hardware characteristics; or from the validation procedure, 
i.e., try both FCFS and PS and select the one which more accurately models computer system be- havior. 
(If there is only one class of customer, the CPU scheduling disciplines of FCFS and PS will yield the 
same results.) The remaining model parameters require measurement, and the following sections will dis- 
cuss the procedures for obtaining each one. Unless the analyst has previously measured a computer similar 
to the one under investigation, this stage of the validation process will require a thorough and detailed 
study of the computer's architecture and operating system. The problem to be solved is to determine what 
measurable quantity and characteristics of the particular computer system most nearly correspond to the 
parameters in the queueing network model. Correct solution of this problem is of crucial importance in 
the valida- tion, and it may not be as easy as it might appear. CHANNEL BRANCHING PROBABILITIES  Conceptually, 
one can obtain the branching probability using the relative frequency defi- nition of probability. Recalling 
the model's assumption of alternating periods of CPU and channel processing, the branching probability 
for a channel is the number of I/O operations for that channel divided by the total number of channel 
I/0 operations. The total number of channel operations will, of course, be equal to the total number 
of CPU processing cycles. Unfortunately, the number of I/O operations per channel is not a statistic 
normally selected for hardware measurement by computer operating personnel. Although it is relatively 
easy to obtain I/O channel and control unit utilizations, hardware probe points at the channel or control 
unit which will conveniently measure the number of times that a channel or control unit was used are 
not gen- erally available for IBM computers. There are two possible solutions to the problem. One approach 
using software monitors is to count the number of times that the EXCP (EXecute Channel Program) macro 
was executed for each channel. For the earlier releases of operating systems (OS/MVT and VS2 Release 
i), it will probably be necessary ho use IBM proprietary measurement programs, since SMF will record 
only EXCP's resulting from appli- cation programs. The EXCP's resulting from operating system tasks will 
not be counted, and often consist of 40-50% of the total number. The capability of recording all EXCP's 
is included in the supplied software for VS2 Release 2.0. The second approach is to install a hardware 
monitor and count the number of times each disk pack on a channel is used. For the validation described 
in this paper, the number of I/O processing cycles was obtained from EXCP counts. As mentioned before, 
the model permits class dependent branching probabilities. Referring to  Figure i, the branching probability 
from the CPU to channel i for class r jobs is EXCP'si(r) Pi(r) = r=l ..... R (i) m E EXCP' si(r ) 
i=l If one is interested in obtaining branching probabilities for IBM computers with Time Sharing Option 
(TSO) and batch classes, it will be neces- sary to change equation (i) slightly. The IBM routines which 
measure the total number of EXCP's will tabulate the EXCP's by volume address, but will not present a 
breakdown as to whether they were issued by TSO or batch jobs. One method for approximating Pi(r) is 
to modify equation (i) to include a weighting factor wi(r) , which is the relative fraction of EXCP's 
for that channel resulting from TSO and batch applications programs. The weighting factor can be obtained 
from SMF data as described below. An application for using this approach is to determine the branching 
probability for each class on the channel with the paging pack. In this case, wi(r) will be the relative 
fractions of TSO and batch paging EXCP's obtained from SMF Type Four (batch) and Type Thirty-four (TSO) 
records. EXCP's i Pi(r) = wi(r) r=l,...,R (2) m E EXCP ' s i i=l For example, suppose that SMF recorded 
4,000 batch and 3,000 TSO EXCP's to the paging pack during concurrent operation, and suppose that the 
software monitor recorded 9,000 total EXCP's to the paging pack. Then the number of TSO EXCP's is approximately 
[3,000/(3,000 + 4,000)] 9,000. In other instances, obtaining the weighting factor in equation (2) from 
SMF data will not be possible. An alternate method is to first collect EXCP statistics when the system 
is operating exclu- sively in the batch mode. Next, EXCP statistics can be measured when the system is 
operating exclusively in the timesharing mode. The weighting factor for concurrent TSO and batch operating 
is the relative fractions derived from these two sets of data. This particular approach for obtaining 
the weighting factor is proposed for the job queue because SMF does not count any EXCP's to that data 
set. In order to establish controlled experiments and to insure repeatability of data using this second 
approach, a benchmark program was obtained from the Federal Computer Performance Evaluation and Simulation 
Center (FEDSIM). This particular benchmark is capable of exercising computers with batch, TSO and virtual 
storage capabilities. It executes sixty job steps for batch processing during a running time of approximately 
twenty minutes, and provides a mix of CPU bound, I/O bound and balanced workloads. For TSO operation, 
it executes a circular list of commands for such typical timesharing tasks as editing, allocating and 
linking. All of the experiments described in  this paper were conducted during dedicated time with no 
other users on the system. As an example of this second method, there were approximately 18,000 EXCP's 
for the job queue during the batch run and 8,000 EXCP's for the job queue during the TSO run for this 
benchmark. During concurrent operation, the number of EXCP's to the job queue was of the order of 24,000, 
which suggests that as the activity increases, certain data transfers are being combined. In this case, 
the number of job queue EXCP's for TSO (class i) is approximately [8,000/(8,000 + 18,000)] 24,000. Similarly, 
class 2 EXCP's for this data set are approximately [18,000/(8,000 + 18,000)] 24,000. This same procedure 
can be used for job and data management libraries, and the system's tem- porary data sets for application 
programs. For certain data sets there may be no ambiguity; the TSO component of the benchmark did not 
use SPOOLING and these EXCP's were assigned exclusively to the batch class. Similarly, the EXCP's to 
the time- sharing terminals were assigned exclusively to the TSO class. MEAN CHANNEL SERVICE TIMES 
 Conceptually, this parameter can be obtained by dividing the total channel service time by the number 
of channel processing periods. Since existing measurement equipment does not accumulate channel processing 
times, one possibility is to derive the total service time for a channel by measuring the channel utilization 
(UTIL i) and multiplying this figure times the test period (T). For example, if the channel utilization 
were 50% and the test period were one hour, then the total channel service time would be thirty minutes. 
Dividing total channel service time by the number of EXCP's for that channel will yield a channel mean 
service time (CH i MST). Referring to Figure 1 CH i MST = (UTIL i) (T) i=l,...,m (3) EXCP i One might 
expect, however, that the mean service time obtained in this manner would be too small. The model assumes 
that during the I/O cycle a job will be either in a queue or receiving service at a processor. The channel, 
on the other hand, may very well be idle while control units and devices on the channel are performing 
useful work in response to a task. It is, in actual practice, very difficult with current analytical 
techniques andimeasure- ment devices to accurately model and measure the I/O channel behavior of modern 
computer systems. From the analytical aspect, it is extremely difficult to model the channel operation 
when several devices are in various modes of operation, such as seek, latency, data transfer, waiting 
for a control unit and waiting for a channel, Analy- tical techniques for modeling overlap are not currently 
available, and this problem will probably require much research and effort in the future. Modern I/O 
channel architecture can also cause problems from the measurement point of view. The service time of 
a disk or drum operation is equal to the seek time (if the device is a disk) plus the time of rotational 
latency plus the time of data transfer. The channel mean service time (MST) for the model should include 
all of these compo- nents. Although the channel will always be re- quired for the transmittal of data, 
with modern computer architecture the channel may not be required for latency or seek. It would be ex- 
tremely desirable to have a measurement probe point which would indicate channel busy time when any device 
on that channel is busy. It is sug- gested that this utilization is the one which should be used in equation 
(3). Unfortunately, it appears that such a probe point has not been researched and documented for most 
computers. The mean rotational latency for disks or drums is available from manufacturer's specifications, 
and it is believed that only a small variance is associated with this quantity. The most difficult problem 
lies in the determination of mean seek time for disks. Although mean seek time is available from specifications, 
there can be a significant variance associated with it depending on the loca- tion and frequency of usage 
of the data sets. Again, the problem of overlap of several disks on a single channel increases the complexity 
of the problem. Various assumptions are made in the model in  [3] and [5] for tractability of analysis 
which do not exactly agree with actual computer system behavior. Hence, the objective of the validation 
procedure is to validate measurement techniques and approximations such that model.utilizations agree 
reasonably closely with measured values. During the validations on the IBM 370/155's and the IBM 370/168 
it was noted that in order for model and measured CPU utilizations to agree, the proper value of channel 
seek time varied from 0 ms. to i0 ms. Several experiments were conducted to study the characteristics 
of channel seek time for the model. Experiments on the IBM 370/155 with oS/MVT and 3330 disks showed 
that there was no simple direct relationship between the proper value of model channel seek time and 
measured mean values derived from disk arm measurements. Experiments on the IBM 370/168 showed that the 
proper value of model channel seek time was primarily dependent on the degree of multiprogramming and 
not on the nature of the workload. Thus the model channel seek time may be regarded as an empirical constant 
to be determined during the validation, such that model utilizations will agree reasonably closely with 
measured values. A possible solution to this problem is dis- cussed in [9], which may prove useful until 
more powerful analytical techniques and measurement tools are available. This procedure is based on a 
review of the equations of the model in [5], which shows that correct computation of CPU throughput is 
crucial, since CPU throughput is then used to determine channel throughputs. Values of server throughput 
are subsequently used to calcu- late utilizations. The approach calculates a calibration factor and then 
recomputes the server throughputs and utilizations. The value of the calibration factor is simply the 
ratio of measured CPU utilization to model CPU utilization obtained on the first pass. The results of 
the calibration method are presented later in this paper, and show that by forcing a solution for CPU 
throughput, good agreement is obtained between model and mea- sured utilizations for all servers. 321 
 A possible interpretation of the calibration procedure is that certain simplifying assumptions must 
be made for mathematical tractability in order to derive the model. Furthermore, it is not feasible with 
existing monitors to obtain measure- ments which exactly correspond to model parameters. To reduce the 
effect of these inaccuracies, it is necessary to first calibrate the model for a given baseline configuration. 
After the model has been calibrated, it is then feasible to use the model to predict performance of the 
reconfigured computer system. This approach is similar to the small- signal analysis of electronic circuits. 
For small values of input signals, the behavior of the cir- cuit is assumed to be linear in the vicinity 
of an established operating point. MEAN CPU SERVICE TIME The determination of this parameter is similar 
to that for mean channel service time. Available  measurement devices do not accumulate CPU burst times, 
so that total CPU service time is obtained  by multiplying the CPU busy utilization (UTIL). times the 
length of the test period (T). Dividing the total number of EXCP's will give the CPU mean service time 
(CPU MST). This relationship may be  expressed, with reference to Figure i, as (UTIL) (T) CPU MST = 
m (4) Z EXCP i i=l Now suppose that the analyst is using two classes of customers and wishes to model 
the CPU as a PS service center. Assume that the relative fractions for the number of customers in class 
1 and class 2 are n(1) and n(2), respectively. Then n(1) (UTIL) (T) CPU MST (i) = (5a) m Z EXCPi(1) 
 i=l n(2) (UTIL) (T) CPU MST (2) = (5b) m Z EXCPi(2 ) i=l Equation (5) assumes that the amount of 
pro- blem state and supervisor time required is directly proportional to the relative fractions of the 
number of customers in the two classes. For classes of timesharing and batch customers in IBM machines, 
one can perhaps improve upon this assump- tion by defining n(1) and n(2) to be the relative fractions 
of time that these two classes are in the CPU problem state. This data can be obtained from SMF reports, 
using Type Four records for batch jobs and Type Thirty-four for TSO jobs. Even with this information 
from S~I.F, the over- head in equation (5) is prorated in proportion to the relative fraction of time 
in the problem state. For classes of timesharing and batch jobs, it is reasonable to expect that the 
timesharing jobs would require more overhead due to the number of swapping operations required. However, 
currently available monitors are not able to measure the fraction of overhead associated with these classes, 
and the above allocation strategy was used in this validation. DEGREE OF MULTIPROGRAMMING  The number 
of customers in the queueing net- work will quite naturally relate to the number of jobs executing in 
the system. For batch operation, the operating system of IBM computers assigns an initiator to each job 
class, and jobs are serviced FCFS within a job class. The initiator is a routine which performs the following 
functions: i. A region of main storage is acquired. 2. Input data sets are located.  3. Required I/O 
devices are assigned.  4. Auxiliary storage for new data sets is reserved. 5. A task for that job 
step is attached. At the completion of item 5, the job is loaded and then executed. Statistical data 
to compute the time average of the number of batch initiators in execution can be obtained from SMF data, 
using a Type Four (Job Step Termination) record. Normally, the SMF analyzer displays the number of initiators 
which had jobs assigned. In general, this number will not be the number of tasks in execution, since 
the five functions listed above must be performed by the initiator before execution can begin. To more 
accurately reflect model behavior, it is suggested that the SMF analyzer be modified to display the number 
of initiators which were actually in execution at the time of job step termination. This modification 
can be accomplished through proper selection of the appropriate field in the record.  For IBM TSO operation, 
main memory is normally partitioned into four to six regions. There can be only one user executing in 
each region. Any additional users are assigned to queues on a secondary storage device. If there are 
more users than regions, a user will be swapped out of main memory during the think times between executions. 
Data to compute the time average of timesharing tasks in execution was estimated from the IBM measurement 
programs. EXPERIMENTS ON AN IBM 370/155-2 The first validation was made on an IBM 370 Model 155-2, 
with virtual storage operating system VS2, HASP and the Time Sharing Option (TSO). The system configuration 
consisted of one CPU, 1.5M bytes of main storage, and four channels.  Referring to the block diagram 
in Figure i, channel 1 was a byte multiplexor channel and pro- vided a data path through a control unit 
to one IBM 1403 printer and a 2504 card punch. Channel 2 was a block multiplexor channel and provided 
a path to four 3330 disks via a 3333 Disk Control Unit (DCU). The remaining two channels were selector 
 channels which connected to independent banks of 2314 disks via DCU's. There were eight 2314's connected 
to channel 3. Channel 4 had eight 2314's plus an IBM 2848 Display Control and eight 2260 timesharing 
terminals. For the first experiment the system was con- figured without the IBM 3330 disks, i.e., channel 
2 was not used. To simplify generation of the oper- ating system no timesharing terminals were used, 
and only the batch portion of the benchmark was needed. (For this workload channels 5 and 6 were not 
required.) The objective of this first experiment was to validate the model and the measurement methodology 
for a single class of customer (batch). Since the time-averaged degree of multiprogramming was mea- ured 
at 3.7, utilizations using the model in [5] were solved for N=3 and N=4 using the FORTRAN program shown 
in [9]. The results are shown in Table i. TABLE 1 Model vs. Measured Utilizations for the Case of IBM 
2314 Disks The validation procedure for the model with TSO and batch classes will now be described in 
detail. Using the allocation strategy discussed previously, EXCP's by class are shown in Appendix A. 
The branching probabilities by class are easily determined from equation (i). For example, there were 
a total of 21,389 TSO (class i) EXCP's and 72,247 batch (class 2) EXCP's. There were 11,143 TSO EXCP's 
and 22,141 batch EXCP's to channel 2. Then P2(1) = 11,143/21,389 = 0.521 and P2(2) = 22,141/72,247 = 
0.306. (Using single class statistics, P2 = 33,284/93,636 = 0.355.) Remaining branching probabilities 
are computed in a similar manner. For mathematical tractability, the model assumes that channel MST's 
are FCFS and class independent. Using hardware monitor utilizations, CH 2 MST = 366.83/33,284 = 11.02 
ms. The other CH i MST's are determined using the same procedure, with CH 1 MST using the "any device 
busy" utiliza- tion. (Adjusting for 3330 rotational latency, CH 2 MST = 11.02 + 8.35 = 19.37 ms.) The 
CPU may be modeled using either FCFS or PS scheduling. If FCFS is used, then CPU MST = 1555.14/93,636 
= 16.61 ms. If PS is used, then SMF data can be used to prorate the CPU busy utiliza- tion by class. 
Substituting in equation (5): SERVER MODEL MEASURED MODEL UTILIZATIONS UTILIZATIONS UTILIZATIONS N=3 
N=3.7 N=4 CPU 0.648 0.696 0.733 CH 1 0.544 0.576 0.615 CH 2 0.000 0.000 0.000 CH 3 0.372 0.400 0.421 
CH 4 0.394 0.422 0.445 IBM 2314 disks are used with selector channels and remain connected to the channel 
for the data transfer and the full rotational latency of the search. The channel is not connected to 
the 2314 during a seek. An interesting point of this experiment is that good results were obtained without 
including any mean channel seek time. The channel MST's were derived from equation (3) using measured 
channel busy utilizations which took into account data transfer operation and rotational delay only. 
Calibration of the model was not required. Since good results were obtained in the first experiment 
using the 2314 disks and since it was desirable to further investigate the problem of determining the 
proper mean seek time, it was decided to establish a policy for the following experiments on the 370/155-2 
to add the 3330 mean rotational delay of 8.35 ms. to the values of channel 2 MST obtained from channel 
busy times. (The channel is not connected to the 3330 during either a search or a seek.) For some experiments 
 slightly more delay would have worked better; for other experiments less delay would have improved accuracy. 
Overall, it did appear to work reason- ably well for a uniform policy. CPU MST (i) = ( 440.96 ) 1551.14 
= 34.53 ms.  440.96 + 487.60 21,389 CPU MST (2) = ( 487.60 ) 1551.14 = 11.30 ms. 440.96 + 487.60 72,247 
 SMF data indicated that the average number of batch jobs in execution was 3.8. The number of TSO users 
in execution cannot be obtained from SMF, but IBM measurement routines showed that the time- averaged 
number of TSO tasks in execution was approximately 0.8. The model requires integer values of N, so it 
was assumed that the TSO degree of multiprogramming for the model was equal to one and the batch degree 
of multiprogramming was four. Using data from Appendix A, the equations in [5] and the FORTRAN program 
in [9], model versus measured utilizations are shown in Table 2. The third column shows model utilizations 
for a CPU scheduling discipline of FCFS with an MST of 16.61 ms. Column six shows model utilizations 
assuming a PS CPU scheduling discipline with MST(1) = 34.53 ms. and MST(2) = 11.30 ms. The numbers in 
parentheses in column five were obtained on a second run of the same benchmark using identical system 
configuration and initiali- zation. Thus columns four and five indicate the degree of variation between 
runs, and show reason- able consistency from one run to the next. Column four, of course, was obtained 
from the measured data in Appendix A, and it was this run which was used to derive the parameters for 
the model. For IBM VS2, a job is permitted to have up to 500 ms. of CPU time between interrupts before 
the dispatcher assigns the CPU to another job. Since this 500 ms. quantum is very long in comparison 
to a mean CPU time between I/O interrupts of 1555.14/ 161,644 = 9.62 ms., one would hope that the model 
utilizations assuming FCFS CPU scheduling would be  323 Using Two Classes of Customers SERVER MODEL 
MODEL MEASURED MODEL MST UTILIZATIONS UTILIZATIONS UTILIZATIONS (ms) N=I/4 N=0.8/3.8 N=I/4 CPU:FCFS 
CPU:PS CPU 16.61 0.890 0.893 (0.894) 0.865 34.53 11.30  CH i 425.40 0.433 0.449 (0.442) 0.517 CH 
2 19.37 0.209 0.211 (0.217) 0.203 CH 3 18.60 0.318 0.320 (0.307) 0.355 CH 4 29.19 0.476 0.478 (0.453) 
0.518 PI(1) = 0.000 P2(1) = 0.521 P3(1) = 0.206 P4(1) = 0.273 PI(2) = 0.025 P2(2) = 0.306 P3(2) = 0.354 
P4(2) = 0.314 more accurate than for the case of PS. It is tions were forced to agree. Table 3 illustrates 
reassuring to note in Table 2 that this is, in the results of the procedure, and shows that after fact, 
the case. CPU utilizations were brought into agreement reasonable accuracy existed between model and 
measured channel utilizations. For this experiment EXPERIMENTS ON AN IBM 370/155 only channels i and 
2 were used. The IBM 370/155 with OS/MVT and HASP con-TABLE 3 sisted of one CPU, 2.0M bytes of main 
storage, one byte multiplexor channel and two selector/block Model vs. Measured Utilizations multiplexor 
channels. TSO capability was not Using Calibration Method included. Referring to the block diagram of 
Figure i, channel I was a byte multiplexor and provided a data path through a control unit to two IBM 
1403 printers and one 2504 card reader/punch. Channel 2 provided a path to five IBM 3420 Magnetic Tape 
SERVER MODEL MEASURED Units (MTU) via a 3803 Tape Control Unit (TCU), UTILIZATIONS UTILIZATIONS and to 
two IBM 3330 disks through a 3333 Disk N=4 N=3.7 Control Unit (DCU). When connected to the TCU the channel 
operated as a selector channel; when UNCALIBRATED CALIBRATED connected to the DCU it functioned as a 
block multiplexor channel. Channel 3 was connected to a second DCU with two 3330 disks, and operated 
as CPU 0.677 0.458 0.458 a block multiplexor channel. The system was con-CH i 0.770 0.520 0.522 figured 
with the multiple path switching capability CH 2 0.517 0.349 0.349 such that either channel 2 or 3 could 
utilize any CH 3 0.000 0.000 0.000 of the four disks. Previously, the paper discussed the difficulty 
in modeling and measuring I/O channel behavior. This situation is particularly true for IBM 3330 disks 
which are connected to the channel only during data transfer. A calibration procedure was proposed in 
which model and measured CPU utiliza-  ADDITIONAL EXPERIMENTS COMPCON 75. (Sep. 1975), 293-296. The 
third and final computer system which was available for validation and experimentation was an IBM 370 
model 168-1, with virtual storage operating system VS2, HASP and TSO. The system configuration consisted 
of one CPU, 4.0M bytes of main storage, and eight channels. The results of this validation are similar 
to those previously described, and in the interest of brevity will not be reproduced here. Since TSO 
was available, two classes of customers were used in the validation. The system employed 3330 disks, 
so again the calibration procedure was used. One possible use of an analytical model of a computer system 
is to predict the increase in per- formance resulting from a proposed modification of the existing system. 
With this aspect in mind, additional experiments were conducted that hypothe- sized situations in which 
a manager was consider- ing upgrading his system and was interested in estimating the performance improvements 
to weigh against the anticipated costs. The basic concept was to run a benchmark program on the baseline 
system and to validate the model parameters. After validation, the model was used to predict CPU and 
I/O channel utilizations for the upgraded or reconfigured system. Lastly, the benchmark was rerun on 
the reconfigured system and measured utilizations were compared with predicted values from the model. 
There was good agreement between predicted and measured utilizations when adding a channel to the IBM 
370/155, when reallocating files and adding two channels to the IBM 370/155-2, and when adding a channel 
to the IBM 370/168-1. Detailed results are shown in [9]. 5. 6. 7. 8. 9. i0. Chandy, K.M., Herzog, U. 
and Woo, L. Parametric analysis of queueing network models. IBM J. Res. Develop., 19, i (Jan. 1975), 
36-42. Chandy, K.M., Herzog, U. and Woo, L. Approximate analysis of general queueing networks. IBM J. 
Res. Develop., 19, 1 (Jan. 1975), 43-49. Hughes, P.H. and Moe, G. A structural approach to computer performance 
analysis. Proc. AFIPS 1973 NCC, Vol. 42, Thompson Books, Wash., D.C., 109-119. Moore, C.G. Network Models 
for Large-Scale Time-Sharing Systems. Ph.D. Thesis, Univ. of Mich., Ann Arbor, Mich., April 1971. Rose, 
C.A. Measurement and Analysis for Computer Performance Evaluation. Sc.D. Dissertation, George Washington 
Univ., Wash., D.C., July, 1975. Sekino, A. Performance Evaluation of Multi- programmed Time-Shared Computer 
Systems. Ph.D. Thesis, MIT Project MAC Report MAC-TR-103, Cambridge, Mass., Sep. 1972. ACKNOWLEDGEMENT 
I am deeply grateful to the IBM Corporation for the use of their measurement devices and for their very 
capable systems programming support. I also appreciate the helpful discussions with Prof. J. Buzen of 
Harvard University, and Professors J. C. Browne and K. M. Chandy of the University of Texas (Austin). 
REFERENCES i. Baskett, F. and Gomez, F.P. Processor sharing in a central server queueing model of multiprogramming 
with applications. Proc. of the Sixth Annual Princeton Con- ference on Information Sciences and Systems, 
Princeton Univ., (March 1972), 598-603. 2. Baskett, F. and Muntz, R.R. Networks of Queues. Proc of the 
Seventh Annual Princeton Conference on Information Sciences and Systems, Princeton Univ., (March 1973), 
1-7. 3. Baskett, F., Chandy, K.M., Muntz, R.R. and Palacios-Gomez, F. Open, closed and mixed networks 
of queues with different classes of customers. JACM, 22, 2 (Apr. 1975), 248-260. 4. Buzen, J.P. Cost 
effective analytic tools for computer performance evaluation. Proc. of 325 MEASURED DATA FOR VALIDATION 
ON IBM 370/155-2 DURING TIMESHARING AND BATCH OPERATION CONFIGURATION One byte multiplexor channel; 
one block multiplexor and two selector channels; 1.5M bytes of memory with five initiators; TSO and batch 
benchmark. DATA FROM HARDWARE MONITOR  Description Count or Time (Sec) Utilization Elapsed Time 1741,78 
CPU Prob. State 246.98 0.142 CPU Supvr. State 1308.18 0.751 Total I/O Interrupts 161,644 CH i Busy 12.98 
0.007 CH i, Any Device Busy 782.75 0.449 CH 2 Busy 366.83 0 211 CH 3 Busy 557.50 0 320 CH 4 Busy 833.33 
0 478 CH 5 Busy 0.00 0 000 CH 6 Busy 0.00 0 000 CPU Busy 1555.14 0 893 DATA FROM SOFTWARE MONITOR IBM 
Measurement Routines CPU Utilization  Problem State 0.349 Supervisor State 0.513 Total 0.862 Channel 
Utilization  CH 2 0.203 CH 3 0.364 CH 4 0.526 CH 5 0.000 CH 6 0.000 Total I/O Interrupts 155,687 EXCP's 
TSO Batch Subtotal CH i 1,840 1,840 CH 2 11,143 22,141 33,2841 CH 3 4,403 25,563 29,966 CH 4 5,843 22,703 
28,546 CH 5 0 CH 6 0 Total 21,389 72,247 93,636 llncludes 4391 TSO and 4760 Batch paging EXCP's SMF 
 Average No. of Tasks in Execution: 0.8 TSO; 3.8 Batch EXCP's From Problem Programs Time in Problem 
State (CPU-Sec) TSO Batch TSO Batch CH 2 224 20 440.96 487.60 CH 3 48 21,098 CH 4 98 20,842  
			