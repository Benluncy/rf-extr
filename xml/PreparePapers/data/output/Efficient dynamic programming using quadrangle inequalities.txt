
 Efficient Dynamic Programming Using Quadrangle Inequalities F. Frances Yao Xerox Palo Alto Research 
Center Palo Alto, California ABSTRACT. Dynamic programming is one of several widely used problem-solving 
techniques in computer science and operation research. In applying this technique, one always seeks to 
find speed-up by taking advantage of special properties of the problem at hand. However, in the current 
state of art, ad hoc approaches for speeding tip seem to be characteristic; few general criteria are 
known. In this paper we give a quadrangle inequality condition for rendering speed-up. This condition 
is easily checked, and can be applied to several apparently different problems. For example, it follows 
immediately from our general condition that the construction of optimal binary search trees may be speeded 
up from O(n ~) steps to O(n2), a result that was first obtained by Knuth using a different and rather 
complicated argument. 1. INTRODUCTION. In the application of a general technique, it is often possible 
to improve the solution by taking advantage of special properties of the problems at hand. Dynamic programming 
is one of several widely used problem-solving techniques in computer science and operation research (see, 
e.g.[2]). It finds applications in context- free language parsing [8], constructing optimal binary trees 
[7], finding shortest paths [4], and in solving various "intractible" combinatorial problems (see the 
references in [2]). In the con-struction of optimal binary search trees, for example, Knuth[5][7] showed 
that one can have an algorithm that runs in time O(n2), whereas straightforward dynamic programming would 
yield an O(n 3) algorithm. Knuth's proof is quite complicated and involves detailed properties of the 
optimal binary trees. In general, ad hoe approaches for speeding up seem to be characteristic in dynamic 
programming; few general criteria are known. In the present paper we will discuss a quadrangle inequality 
condition for the purpose of achieving speed-up in dynamic programming. This condition is easily checked 
and will be applied Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. &#38;#169; 1980 ACM 0-89791-017-6/80/0400/0429 $00.75 to several apparently different problems. 
In particular, it is used to give a simple proof of Knuth's construction of optimal trees, and applied 
to optimization problems involving Vary partitions. 2. DYNAMIC PROGRAMMING AND QUADRANGLE INEQUALITIES. 
We consider a simple dynamic programming problem for the purpose of illustration. Example 1. Let Li, 
L2,-.,Ln be n finite, nonempty sets of strings. We wish to compute their product ('concatenation) Ll. 
L2...Ln by using L. L t, the product of two sets, as the primi- tive. To simplify matters, we assume 
that the product operation is charged a cost of ILl. ILtl, and results in ILl. I L'I strings stored in 
L. L t (i.e., duplicate strings will not be detected). Let ILil -~ ni and w(i, j) ~ nini+l...nj, then 
the optimal cost c(i,j) for computing L/- Li+l . ..Lj satisfies the following recurrence relations: c(i, 
i) = 0; e(i, j) = w(i, j) + mid (c(i, k -l) + c(k, i)) for i < j. i<k~j (1) 429 We will refer to the 
function w in the above relations as the increment function for e; it determines the cost function e 
completely. To evaluate c using the obvious procedure suggested by these equations will require total 
time O(n3). However, as we will see, the increment function w in Example 1 satisfies the quadrangle inequalities 
(QI) w(i, 3') + ~(i', 3") < w(¢, j) + w(i, y) for i < i' < i _< Y. (2) This property allows the dynamic 
programming to be speeded up because of the following general theorem. Theorem 1. If w satisfiesQIand 
furthermore is monotone on the lattice of intervals (ordered by inclusion), i.e., wCi, j) _< loCi', J3 
i/ [i, j] c_ [i', jq, then the function c defined by (13 can be computed in time OCn23 . We now verify 
these conditions for the w in Example 1. The monotonicity is obvious, For the QI, let a ~ hi. "nv-b b 
= ne ..,nj, and c = nj+l ..ny, Then the QI becomes ab .-4- be ~ b + abe. This is true since o <_ b(a-- 
1#-1). Theorem 1 is proved by establishing the following two lem- mas. Lemma 2.1. If w satisfies QI and 
is monotone on the lattice of intervals, then the function c defined by (1) also satisfiesQL Proof. The 
proof is by induction on the length l -~ If--il of the "long side" of the quadrangle inequality cCi, 
j) + eCi',/3 --< cCi', J3 + cCi, 3") /or i < i' < j < j'. (3) First note that (3) is trivial when i -~- 
i' or ] = j'. Therefore (3 3 is true when l _< 1. Inductively, consider two cases: A)i < i I -~- ] < 
j', and B)i < i' < j < j'.(See Figure 1). Case A). i < i' = j < j'. In this case, (3 3 becomes the (inverse3 
triangle inequality: eCi, j) + cCj, j') < cCi, j') for i < j < j'. (4) Suppose c(i,/3 is minimized at 
k = z; that is, e(i, JO = e~(i,/) where we use ck(i, j) to denote w(i, j) -4- e(i, k-- l) + c(k, j). 
There ? Figure 1. The proof of Lemma 2.1 are two symmetric subcases. Case A1). z _< j. We have e(i,j) 
~ cz(i,j) -~-w(i,]) -4- c(i,z --13 -4-- c(z,j). Therefore, eCi, j) + c(j, j') < wCi, J3 + eCi, z -- 1) 
+ eCz, j) + eCj, J'3 < wCi, j') + eCi, z - 1) + c(z, j') = c(i, y), where we used the monotonicity of 
w, and the induction hypothesis (4 3 at z ~ j < j'. Case A2). z > ]. This is symmetric with A1), with 
all the intervals reversed. Case B). i < i' < j < j'. Assume the two terms on the right hand side of 
(3) achieve their values at k = y and k = z respectively. That is, c(i', j) = ev(i' , J3, and c(i, j') 
-~ cz(i,/3. We again look at two symmetric subeases. Case B1). z ~ y. We have e i t "I cCi', j') _< 
~( , 3 ) and eCi, j) < czCi,.i). 430 Adding them up, we obtain c(i, j) + c(i', j') < c~(i, j) + %(i', 
j') = ~(i, j) + wCi',/) + c(i, z -t) + eCz, j) + c(i', v -1) + c(v, j') (s) Applying the QI of w, and 
the induction hypothesis (3) at the points z < y < j < j', (5) becomes c(i, j) + c(i', JO _< w(i', j) 
+ w(i, j') + c(i,z --1) + c(i', y -- i) + c(y, j) + c(z, j') _< ey(i', j) + c~(i, y) = c(i', j) + e(i, 
j') Case t32). z > y. This again reduced to B1) when all intervals are reversed.ll Let us use K~(i,j) 
to denote maz{klck(i,j ) = c(i,j)}; so Kc(i, j) is the largest index k where the minimum is achieved 
in (1). (We define Re(i, i) = i.) Lemma 2.2. If the function c defined in (I) satisfies QI, then we have 
IeJi, j) A Ke(i, j + t) _< Kc(i + L J + t) for i < j. (o) Proof. It is trivially true when i = j, therefore 
assume i < j. To prove the first inequality Kc(i, j) < Kc(j, j + 1), we show that for i < k < ld < j, 
[ek,(i, j) ~ ck(i, j)] = [ca,(i, j + 1) ~ ck(i, j + 1)1. (7) Take the quadrangle inequality of c at 
k < k s < j < j n t- 1 c(k, j) + c(ks, j -+- 1) _< c(k ~, j) + c(k, j -4- 1) Adding w(i,j) + w(i,j + 
1) + e(i,k --1) -1- c(i, ks -- 1) to both sides, we get ck(i, j) + ck,(i, j + 1) < ek,(i, j) + ck(i, 
j + 1), from which (7) follows. Similarly, the second inequality Kc(i, j + 1) < Kc(i + 1, j + 1) follows 
from theQI of c at i < i -1- 1 <_ k g ks.I Lemma 2.2 says that the matrix K~(i,j) is nondecreasing along 
each row and column. As a consequence, when we com- pute c(i,j) for 6 = j --i = O, I, 2 ..... n --1, 
only Ke(i "4- 1, J +- 1)--'K~(i, j) minimization operations need to be carried out for c(i,j + 1). Hence 
for a fixed g, the total amount of work is O(n); the overall computation time is therefore reduced to 
O(n2). This proves Theorem 1.| We remark that the monotonicity assumption on w in Lemma 2.1 is necessary 
for the QIof e. For example, if we let (i, i', j, j') -= (1, 2, 2, 3), then the QI of e becomes c(1, 
2) + ~C2,3) < cO, 3), which is equivalent to w(1, 2) "4-w(2, 3) < w(1, 3) "4-minCw(1, 2), w(2, 3)), 
 or max(w(l, 2), w(2, 3)) ~ w(l, 3). 3. OPTIMAL BINARY SEARCH TREES. The construction of optimal binary 
search trees is a well known example of dynamic programming. The statement of the problem is as follows[5][7]. 
Example 2. We are given 2n -t- 1 probabilities PbP2, "",Pn and qo, ql, '", qn where Pl =probability that 
Key/is the search argument; q/=probability that the search argument lies between Keyl and Keyi-.H. We 
wish to find a binary tree which minimizes the expected number of comparisons in the search, namely pj(l 
-t- level of jth internal node in symmetric order) -[- l</<n C qk(level of the (k+l)st external node,) 
 O<k<n where the root has level zero. Let c(i,j) be the cost of an optimal subtree with weights (P/+b 
"", PJ; q/, "", qJ). Since all subtrees of an optimal tree are optimal, it follows that c(i,j) satisfies 
the same recurrences as given by Equ.(1) with w now defined by w(i, j) = p~+~ + ...+p~ + q/+ ...+~. 
(s) This increment function is monotone, and it satisfies the quad- rangle inequalities in fact as equalities. 
It therefore follows from 431 Theorem 1 that we can have an O(n 2) time construction of an optimal tree 
by dynamic programming. In [5], the monotone property (6) is derived by a more complex argument. Note 
that the question asked in Knuth [7, Section 6.2.2 ex.30] is whether the cost function e satisfies a 
special case of the quad- rangle inequalities, namely c(i, j) + c(i + 1, ] + l) < e(i + l, j) + c(i, 
j + 1), (9) "and is therefore answered in the affirmative by Lemma 2.1. In fact, (9) is equivalent to 
the general QI since (3) can be derived from (9) by induction on li'-- i I and IJ' -- Jl. 4. PATHS IN 
A CONVEX POLYGON . We look at an example where the quadrangle inequalities have a most intuitive interpretation, 
and where binary partitions generalize easily to t-ary partitions. Example 8. Suppose vtv2 ".vn is a 
convex polygon in E 2. Let d(i,j) = the Euclidean distance between vl and vj if i < ], and d(i, j) = 
0 if i > j. We notice that d satisfies the inverse quadrangle inequalities, i.e., d(i, 1)+ d(i', j') 
> d(i', j) + d(i, ]') for i < i' < ] < 1'. 0o) (Inverse QI's are what we need in considering maximization 
problems such as the present one.) We use A (~ B to denote the (max, +) -- multiplication of upper triangular 
matrices A and B. That is, if A = (a(i, j)) and B = (b(i, j)), then A ~ B == (c(i, j)) where c(i,j) ~-maxi<k<j(a(i, 
k) + b(k, ])). We define D (t) ~-D = (d(i,j)), D (*) = D (t-t) ~D, and write D (0 as (d(t)(i,])). For 
example, d(2)(i, j) is the length of the longest trajectory from vi to vj that allows one bounce off 
the wall vlvi+,...vj. We are interested in computing D (t) fast. By associativityD (t) ~-D (~)~D (8) 
for t -~-r+s. This multiplication is a special case of a relation of the following form. e(i,j)~-w(i,j)+ 
max (a(i,k)+b(k,])) for i<j. (11) It follows from Lemma $.1 below that d(~)(i,j) satisfies the in- verse 
QI for any r ~ 1 by induction on r. Lemma $.2 then tells us that the multiplication D (~) ~ DO) can be 
done in O(n 2) time for anyr~ I ands~ 1. Lemma $.1 If w, a and b all satisfy the inverse QI, then the 
function c defined by (11) also satisfies the inverse QL Proof. Similar to the proof of Lemma 2.1, except 
that we need not consider Case A) seperately from Case B). Lemma $.2. If both a and b satisfy the inverse 
QI, then for the function e defined by (11) we have KcCi, 1) ~ KcCi, j + 1) < KcCi + 1, j + 1) for i 
< 1. Proof. Similar to the proof of Lemma 2.2. Theorem 2. For any t, D (t) can be computed in time O((log 
t)n 2) Proof. Apply a standard binary algorithm for computing powers. | Example 5'is reminiscent of the 
problem studied in [3], where monotonicity properties similar to Lemma $.2are utilized to find a maximum 
triangle inscribed in a convex polygon efficiently. An interesting question is whether the present approach 
can be used to obtain a fast solution for finding maximum k-gons. 5. OgrlMhU T-AnY TRe~ . In view of 
Theorem 2, what can we say when Equ(1) is generalized to allow c(i,j) to be partitioned into up to t 
sub- problems? The recurrence becomes c(i, j) = ~(i, j) + rain (cCi, kt --1) + eCkt, k2 -- 1) +...+eCkt-t, 
])) if i<L c(i,j)=O if i>].   (12) So when i < j, the problem of computing c(i, ]) is divided into 
2 to t subproblems whose sizes are strictly smaller than that of the original problem. (We say a subproblem 
c(k,l) is empty if k > l.) This problem is similar to Example 3; it requires a little more care since 
it involves recurrences. The main result we have here is the following. We say that a function w satisfies 
the triangle inequalities (TI) if w(i, j) + w(j, j') < w(i, j') /or i < 1 < J'. Notice that w satisfies 
TI implies that w is monotone.(We assume that w(i, j) __~ 0.) 432 Theorem 3. If w satisfies Q/and T/, 
then the function c defined by (12) can be computed in time O((logt)n2). Example ~. Consider the construction 
of optimal search trees as in Example 2, but allowing each node to have degree at most t. In the special 
case that all the q's are zero, we have w(i, j) ----Pi+l ~ ""'-~Pj, which satisfies the condition of 
Theorem 3, and such optimal trees can be constructed in time O((log t)n2). Let us denote the 'rain' term 
in Equ(12) by f(t)(i,j). Thus, ~)(i, j) = min (c(i, kt --1) --{- e(k b k2 -- 1) -I.- ... +c(kt_ t, J)) 
i <kl~k2<.._<kt--t.~_j i/ i<L riO(i,j)=O if i~j. (13) Furthermore, define l(~)(i, j) = c(i, j); and 
for 2 < q < t --1, define/(q)(i, j) to be the optimal sum of ~ q subproblems. ~)Ci,./) = min (c(i, ki 
--1) --{- c(kt, k2 -- 1) +...+c(kq_t, j)) if i<j, flq)(i, j) = 0 i/ i > j. (14) Note that, in a partition 
of ](q)(i, j), only one subproblem is re- quired to be nonempty. Fact A. f(I)(i,y) > f(2)(i, j) ~ ... 
~ f(t)(i,j). Proof. All except the last inequality follows immediately from the definition of ~q). If 
f(t--U(i, j) is obtained by a decomposition into two or more subproblems, we have f(t--')(i, j) > f(t)(i, 
y) ; other- wise ](t--l)( i, j) ---- c( i, j) > f(t)(i, j) by Equ(12) since w( i, j) > O. | Fact B. f(q)(i, 
j) -~-i~./(f(r)(i, k -- 1) + f(')(k, j)) for q = r -~- s, and r~l,s>l,2~q<t--l.  (15) Proof.We will 
show that !efthand side>righthand side since the other direction is obvious. If in (14) the minimum value 
off(q)(i, i) is achieved with division points kh ...,k~, "',kq--b we choose k to be this k~ on the righthand 
side of Equ(15).| 433 Fact C. f(t)(i, j) = min (](~)C i, k -- 1) +](8)(k, j)) for t = r + s, i<k_<j 
 and r> 1, s>l. (10) Proof. Similar to the proof of Fact B. Again choose k on the righthand side to 
be the kr of the lefthand side.II Lemma 5.1. In (14), iff(~)(i,j) and f(s)(i,j) satisfy Qlfor i --j < 
~f, then f(q)(i, j) satifies QI for i --j ~ 5. proof. Similar to the proof of Lemma 2.1.1n the case correspond- 
ing to Case A1), we need the TI ~)Cz, j) + ~q)CJ, J0 _< f~)Cz, J"), which follows from the QI of ]('), 
and the fact f(q) ~ f(s). Similarly, Case A2) follows from the QI of f(r), Case B1) from the Q[ of ](s), 
and B2) from the QI of ~). (See Figure 2). |. 4 i .fc fr) ., f P Figure 2. The proof of Lemma 5.1  
Lemma 5.2. In (15), iff(r)(i,j) and ](8)(i,j) satisfy Q/for i-- j < ~i, then fit)(/, j) satifies QI for 
i --j < ~ .-f- 1. proof. Analogous to the proof of Lemma 5.1; here the problem sizes are strictly reduced 
in the inductive step. | Lemma 5.8. In (12), w satisfies Q/and T/implies that f(l)(=. c), ..., f(q),..., 
fit) all satisfy QI. proof.It follows from the preceding two Lemmas by induction on 6 = j--i and on q, 
noting that w satisfies QI, T/and f(t) satisfies QI together imply that c satisfies Q/.ll proof of Theorem 
5'.For the f's on the lefthand side of (15) and (16), we use K](i,]) as before to denote the largest 
k on the righthand side which allows the minimum value of f(i,]) to be achieved. By the same argument 
which led to Lemma 2.2 and $.2, we have Ks(i, j) <_ Ks(i, j + l) < K~(~ + 1, j + 1) /or / < y, (IT) 
 and / ~--/(q), l < q < t. Let q0, qh "', qh be an addition chain[6] for t; that is, q0 -~-1, qh --~ 
t, and for each i > 1, qi = qj--Fqkfor some ] < i, k < i. It is well known that any t has an addition 
chain of length h < 2 log t. The following procedure then employs Equ(15), (16) and (17) to compute c(i, 
]). begin for l<i<n,l<m<hdoflq~)(i,i)~-0; for6~ltondo for m4- ltohdo for j-- i -~ 6 do compute/q~)(i, 
j) end Because of Equ(17), the innermost loop takes only O(n) steps. Therefore the algorithm uses total 
time O(hn2), which is oCClogt)~). u 6. CONCLUDING REMARKS . In this paper we have considered a general 
type of conditions which ensures monotonicity of division points in certain dynamic programming processes. 
This monotonicity property makes it possible to achieve speed-up by a facor of n or more over the straightforward 
implementations. We would also like to point out some situations where the present results do not apply, 
and which deserve further study. The monotonicity property for the division points does not hold for 
the matrix multiplication chain problem[If, as shown 434 h P~ P~ r, Figure 3a. c(],3) + c(2,2) ~ c(] 
,2) + c(2,3). I  ~orse  I I ,, ,/\ . .... [% _~.: ¢(2,1) ct;3? I /~T~ x :z¥ ~:.¢ /IX  c(t,2) cc/,3) 
Figure 3b. For tne w defined by (8), Equ (16) fails.  by the following example. Consider the matrices 
Mh M2, M3, M4 with dimensions 2 × 3, 3 × 2, 2 × 10, and 10 × 1, respectively. As can be easily verified, 
the proper order to compute MLM2M~is to parenthesize it as (MjM2)M3, while the optimal computation of 
MihC2M3M4 corresponds to Mt( M2(M3M4)). Similarly, optimal t-ary search trees in general (when the q'a 
are not zero) do not satisfy the monotonicity property either.The addition of a new leftmost key may 
force the division points (at the root) to shift rightward! An example is shown in Figure 3. As the w 
defined by (8) fails to satisfy TI (for example, w(l, 2) .q- w(2, 3) > w(l, 3)), the function c defined 
by (12) does not satisfy the QI (Figure 3a). When Keyi is added, the division points change from {3, 
4} to {4, 5}.(Figure 3b). ACKNOWLEDGEMENT We recently learned that Zhu Yongjin and Wang Jianfang [9], 
in studying algorithms for constructing alphabetic trees with restricted depth, used an approach similar 
to ours. REFERENCES [1] A. Aho, J. Hopcroft and J. Ullman, The design and analysis of computer algorithms, 
Addison-Wesley, Reading Mass., 1974. [2] K. Q. Brown, Dynamic programming in computer science, Computer 
Science Department Report CMU-CS-79-106, Carnegie-Mellon University, February 1979. [3] D. P. Dobkin 
and L. Snyder, On a general method for max- imizing and minimizing among certain geometric problems, 
Froc. IEEE 20th Annual Symposium on Foundations of Computer Science, Puerto Rico, 1979, 9-17. [4] R. 
W: Floyd, Algorithm 97 : shortest path, Comm. ACM5 (1962), 345. [5] D. E. Knuth, Optimum binary search 
trees, Acta Informatiea 1 (1971), 14.-25. [6] D. E. Knuth, The Art of Computer Programming, Vol 2 :Seminumerieal 
Algorithms, Addison-Wesley, Reading Mass., 1975. [7] D. E. Knuth, The Art of Computer Programming, Vol 
8 :Searching and Sorting, Addison-Wesley, Reading Mass., 1973. [8] D. H. Younger, Recognition of context-free 
languages in time n 3, Information and Control 10 (1967), 189-208. [9] Y. Zhu and J. Wang, On alphabetic-extended 
binary trees with restricted path length, Scientia Sinica 22 (1979), 1362-1371.  
			