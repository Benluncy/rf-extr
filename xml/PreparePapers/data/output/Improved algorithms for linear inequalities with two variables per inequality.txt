
 Improved Algorithms with Two Variables Edith Cohen (Extended Abstract. We show that a system of m linear 
inequalities wit h n variables, where each inequality in­volves at most two variables, can be solved 
det erministi­cally in O(mn log m + mnz log2 n) time. A randomized O(n3 log n + mn log3 n log m + mn 
log5 n) time algorithm is given for the case where in every inequality the two nonzero coefficients have 
opposite signs (monotone sys­tems). This algorithm improves the known time bounds for the incapacitated 
generalized transshipment problem, with many sources and no sinks. We also present a new al­gorithm that 
solves the capacitated generalized flow prob­lem by iteratively solving monotone systems. Combined with 
the improved bound, it yields the fastest known algorithm for the problem which does not rely on the 
theoretically fast matrix multiplication algorithms. This approach also yields the first strongly polynomial 
time bound for approximating the maximum generalized flow within any constant factor. 1. Introduction 
In this paper we consider a system of m linear inequalities wit h n variables, where each inequality 
has at most two nonzero coefficients. We give algorithm that either find a point which satisfies all 
the inequalities, or conclude that no such point exists. In addition, the algorithms can be adapted to 
find the solution which minimizes or maximizes a specific variable. The system of inequalities is called 
monotone if in each inequality the two nonzero coefficients have opposite signs. For instance, the dual 
of *Department of Computer Science, Stanford University, Stan­ford, CA 94305, and IBM Almaden Research 
Center. Research partially supported by ONF1-NOOO14-91-C-0026 and by NSF PYI Grant CCR-8858097, matching 
funds from AT&#38;T and DEC. tIBM Almaden Research Center, San Jo~e, CA 95120.6099, and School of Mathematical 
Sciences, Tel Aviv University, Tel Aviv, Israel. Research partially supported by ONR-NOOO14-91-C-0026. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direet commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy other­wise, or to republish, requiresa feesod/orspecificpermission. @ 1991 ACM 089791-397-3/9110004/0145 
$1.50 for Linear Inequalities per Inequality Nimrod Megiddot Abstract) the incapacitated generalized 
transshipment problem is monotone [1]. Shostak [13] characterized the set of solutions of sys­tems with 
at most two variables per inequality, and gave an algorithm which was exponential in the worst case. 
Nelson [12] gave an n i] gmj algorithm. Aspvall and Shiloach [3] and Aspvall [2] proposed algorithms 
which performed 0(rnn31) and 0(mn21) arithmetic operations, respectively, where 1 is the size of the 
binary encoding of the problem. Megiddo [11] proposed the first strongly polynomial time algorithm for 
the problem, which per­formed 0(rmz3 log m) operations. The algorithms presented in this paper have improved 
time complexities. We give a deterministic algorithm which performs O(mn log m+mnz log2 n) operations, 
and an 0(n3 log n+rian log5 n+mn log mlog3 n) time random­ized algorithm for monotone systems. The effort 
involved in translating these algorithms into actual programs is about the same as in the previously 
known algorithms, and the constants in the time complexities are still rea­sonable. In a Generalized 
network fiow problem (also known as flow with gains and losses), each edge (z, j) has a positive gain 
factor aal associated with it so that if a flow Zij en­ters the edge at i then a flow of aijxa~ exits 
the edge at j. Adler and Cosares [1] reduced the incapacitated gener­alized transshipment problem, where 
only demand nodes are present, to a single solution of a monotone system. Therefore, the improved bounds 
for the latter problem result in a faster algorithm for the former. The best known time bound for the 
capacitated gen­eralized flow problem is due to Vaidya [15]. However, Vaidya s bound relies on the theoretically 
fast, but com­plicated, matrix multiplication algorithms. We present a new algorithm that solves the 
capacitated generalized flow problem by iteratively solving monotone systems. The resulting algorithm 
is comparable to Vaidya s algo­rithm, where each is faster on a different range of prob­lems. In adchtion, 
our algorithm is much simpler. Our algorithm is faster than all previous algorithms which do not rely 
on the theoretically fast matrix multiplication (see Goldberg, Plotkin, and Tardos [7], and Kapoor and 
Vaidya [8]). This approach also yields the first strongly polynomial algorithm for approximating the 
maximum generalized flow within any constant factor. Section 2 gives the preliminaries. In Section 3 
we in­troduce the basic deterministic algorithm and analyze its running time. In section 4 we give a 
randomized algo­rithm for the monotone case. In Section 5 we discuss applications to generalized network 
flows. Most proofs were omitted in this abstract. 2. Preliminaries In this section we introduce some 
terminology, notation, and discuss the special properties of systems of inequal­ities which involve at 
most two variables per inequality. We define some basic constructs and operations. We also present an 
algorithm, a variant of which was used by As­pvall and Shiloach [3], that locates a value of a variable 
with respect to the projection of the feasible region. This algorithm is used in the following sections 
as a subroutine. 2.1 The associated graph With every system of inequalities, where each inequality involves 
at most two variables, we associate a graph and a set of intervals as described in the following definition. 
We assume throughout the paper that a system is given by the associated graph and set of intervals. Definition 
2.1. Suppose we are given a system of m linear inequalities in n variables i-cl, . . . . z~ such that 
each inequality involves at most two variables. With­out loss of generality, assume that the inequalities 
with only one variable are summarized in the form of intervals Si = [a,,llZ] ( ~ < a~ ~ b~ < 02, i= 1,..., 
n), We consider a directed graph G = (V, E) as follows. For each variable xi, there are two vertices 
in G associated with z,, namely, V=~U~where~={~il i= 1,. ... n} and y={~\i= l,... ,n}. For u c V, we 
define u-l ~ V as follows. Ifu=~ic~, then u-l =Vi,andif u=tia~ ~, then u-1 = y,. The edges of G are associated 
with the inequalities that involve exact ly two variables as follows. Each such inequality is represented 
by two edges and also each edge e is labeled with a certain linear function f~. The edges corresponding 
to an inequality of the form y%5azj +o are as follows: (i) Ifa>0and ~= 1,wehave anedgee= (Dj,i7i) labeled 
f.(z) = QZ + ~ and an edge e-l = (Yi, Ij) labeled fe., (z) = AZ ~. (ii) If a <0 and y = 1, we have an 
edge e = (~,,tii) labeled f.(z) = az + @ and an edge e-l = (~,, tij) labeled ~c-, (z) = AZ ~. (iii) 
If a >0 and ~ = 1, we have an edge e = (Bj,~) labeled f.(z) = crc P and an edge e-l = (D,, yj) labeled 
fc-, (z) = $z ~. See Figure 1 for an example of such a system and the associated graph. For any one-to-one 
function f let f 1 denote the inverse function. In particular, if f(z) = az + ~ and a # O, then f-l(z) 
= ~Z ~. Note that for all e E E, f,--, = fe-l. Our algorithm maintains numerical values associated with 
the vertices of G; the value associated with Di (resp., qi ) is denoted by Zi (resp., ~i ). Intuitively, 
~a and Zi give the current upper and lower bounds, respectively, on the value of the variable x%.We introduce 
an operation which considers an edge (u, v) and updates the bound associated with v, as implied by the 
inequality associated with (u, v) and the bound associated with u. Definition 2.2. A push through an 
edge e is defined as the following operation: (i) If e = (tij, Oi), E, ~ min{E,, f.(Ej)}. (ii) If e 
= (uj, u), ~i +max{g,f~(~j)}.  (iii) If e = (mI, u), &#38; -max{%,f~(~j)}. (iv) If e = (Ki, fi.), ~i 
+-min{zt, ~e(&#38;,)}. A push is said to be essential if it actually modifies the value of ~i or Zi. 
Proposition 2.3. Suppose ~i and E% (i = 1, . . . . n) are initialized to any values and let X be the 
set of vectors Z=(zl, . . . , Xn)T which (t) satisfy all the given inequal­ities and (ii) ~ < x% < Ei 
(i = 1, ....n). Under these conditions X is in~arzant under pushes. It is easy to see that a vector z 
solves the given system if and only if (i) z, E Si (i = 1,....n) and (ii) the set of values Ei = ~i = 
~i (i = 1,....n) is invariant under pushes. The push operation (see Definition 2.2) is used as a subroutine 
in the algorithms presented here. We define a new operation which amounts to pushing through all the 
edges simultaneously. We then give some definitions applicable to repetitive executions of this new operation. 
Definition 2.4. Consider the graph G with some initial values at the vertices, q = z~, ZI = @ (i = 1,. 
... n), A x+2 (1.) (l.) y< x+2 (2.) y> z (3.) y> -z (4.) y < -Z+2 y A -1. /. ,\ * /:::, ,:: ,% / :: 
> , .. ~. /:: :,. , .< ..\ d .,., 5. ;,.., .... \ A :: ,$,...... .. >;.. >..\ #.,;: >.,..,. :: , . .Ce:: 
,, fl:,~:: :: .-.::: : :.. ,;: .: :.. x , \,..,,~... ... :.77....::,... .(..:: / \ . < :: .:,, .,.. ., 
.. ;: .,.../ \ .. ;. ,,, ., .,,.. :: :: :s::1.,;:;/ . . . $..+ \ .< .:,.. .<,.. -.. # \:: :., . .:.,:: 
Y \ ; .,<. ... ,.? ... ., . / i.-., .../ \ , / II Setof all feasiblepoints -y+2(4.) x > Figure 1: An 
example of a system of inequalities and the associated graph push phase on G is the step of pushing through 
all the edges of the graph simultaneously. Suppose we perform push phases repeatedly. Denote the respective 
values of gi and iii after the k th push phase byg: and@. Consider pairs consisting of a value and a 
vertex, (~~, ~J) and (E:, Uj ). The predecessor of a pair (f, v) is the pair (( , v ) such that e = 
(v , v) is the edge through which the essential push determined the value <, and f = ~,-1(() is the corresponding 
value at v . If the predecessor is not uniquely defined we choose arbitrarily among the quali­fied pairs. 
A pair ((, v) does not have a predecessor if and only if ~ is the initial value at v. The essential path 
associated with a pair (~, v) consists of the sequence of pairs ((1, VI), . . . . ((f, Vz) and the cor­responding 
sequence of edges el, . . . . el _ ~ such that (i) (~i, W) is the predecessor of ((,+1, vi+l) and e, 
is the edge through which the essential push occurs (i = 1,...,1? I), (ii) (~~, u4)= (~, v), and (iii) 
(t,, w,) does not have a pre­decessor. It is easy to see that the essential paths which corre­spond to 
(q:, yi) and (z:, ni) (i = 1, . . . . ~) can be found within the same time bounds of performing 1 push 
phases, simply by keeping track of all essential push operations. Definition 2.5. Given a set S of intervals, 
i.e., upper and lower bounds associated with the variables, the op­eration of shrinking S amounts to 
performing 2n push phases on G initialized with S, and updating S accord­ingly. A shrink step requires 
O(rrm) operations. It follows from Proposition 2.3 that a shrink operation does not affect the set of 
feasible points contained in the box defined by the intervals of S. Let G be as in Definition 2.1. A 
linear function asso­ciated with an edge corresponds to an inequality in the original system. We shall 
define the linear function asso­ciated with a directed path. This function corresponds to a two-variable 
inequality that involves the variables which correspond to the end points of the path. This inequal­it 
y is implied by the original system. We also extend the notion of a push through an edge to directed 
paths. Definition 2.6. Let p = (el, . . . . e~) be a (directed) path in G. (i) A push aiong p is defined 
to be the composition of k successive pushes, through the edges el, . . . . ek. (ii) We denote by p-l 
the path p = (e~l, . . .,e~l).  (iii) For any path p, we define a linear function f,, where fp=fe, o... 
ofe,. It is easy to see that if all the pushes through edges along p are essential, then the function 
fP(z) gives the result of pushing z along p. Note that if both ends of p lie either in ~ or in ~ then 
fp is increasing. Otherwise, fP is decreasing. In particular, this definition applies to cycles (closed 
paths) starting at distinguished vertices. Consider directed paths and the associated inequali­ties. 
Cycles play a special role since they give a relation 147 that involves a single variable, from which 
a a bound on this variable can be deduced. This is formalized in the following definitions. Definition 
2.7. We extend the definition of a cycle to paths starting at v and ending either at v or at v 1. (i) 
Let c be a cycle starting at one of the vertices V, and yt, and ending at a vertex TTi(resp., Xi). Let 
fC be the associated linear function. The bound on z, implied by the cycle c follows from the inequality 
z s ~C(Z) (resp., z ~ ~.(z)). Obviously, the implied inequality must hold for all feasible points. Note 
that if a cycle c starts at T, and ends at yi (resp., starts at g, and ends at Da), then fC is decreasing. 
Hence, c implies a lower bound (resp., an upper bound) on z,. (ii) We say that the cycle c contradicts 
a value &#38; of El  (resp., ~i) if the bound implied by c is of the form Zi ~ a (resp., z, ~ a) whereas 
&#38; < Q (resp,, <i > a).  2.2 Properties of the feasible region Consider the bounds on the variables 
which are implied by directed cycles. We discuss the relation of these bounds to the feasible region. 
We first give the following definitions. Definition 2.8. (i) For each variable za, let [z;, ~Y] S [ai, 
b,] be the set of values which are not contradi~~ed by any simple cycle. Note tha,t the two cycles c 
and c 1 imply the same bound. It follows that in order to find Z; (resp., ~~), it sutllces to consider 
cycles ending at tii (resp., Ii). (ii) Denote by [z~in, z~ax] ~ [z;, z;] the largest interval such that 
1) for all paths p from a vertex iij (resp., Qj ) to fii we have z;= s fP(Z~) (resp$, o; ax s fp (!72;) 
) and, 2) for all paths p from a vertex =j (resp., Yj) to Qi we have z~in ~ jp(~~) (resp., zi in 2 fp(I!;) 
). (iii) A value Z, (resp., ~i) is inconsistent with an interval [a, b] if 31< a (resp., ~ > b). We say 
that a value of Ea (resp., Zi) is inconsistent if it is inconsistent with the interval [a~in, z?=]. (iv) 
A value Ei (resp,, ivi) is consistent with an interval [a, b] if ~i > b (resp., q < a). Note that if 
a value lies inside an interval [a, b], it is neither inconsistent nor consistent with the interval. 
The following observation, due to Shostak, is crucial for the correctness of all known algorithms for 
linear systems with at most two variables per inequality: Proposition 2.9. [Shostak [13]] If the problem 
is ~easi­ble, then the interval [z~in, z~ax] is the projection of tie set Of solutions on the xi-axis. 
Proposition 2.9 is a key for an exponential time algo­rithm that essentially examines all directed cycles 
[13]. 2.3 Locating values We present two corollaries of Propositions 2.3 and 2.9. Given a feasible system, 
consider a sequence of push phases. Corollary 2.10. If the values at the vertices are initially consistent 
with the respective intervals [xyi , x?=], then they Temain consistent afteT any numbe? of push opera­tions. 
Corollary 2.11. Consider a vertex g (resp., v,) and a value [ = L&#38; (resp., [ = Z:) fo? some ~. Let 
(~~, vi) (j=l , . . . . k < !) be the pai?s comprising the es­sential path (see Definition 2.~) associated 
with (f, ~) (resp., (~, Ui)). Let zil ,..., ~i~ = Xi be the variables which co?v espond, ? espective~y, 
to VI, . . . . vk. If ( is in­consistent with [z~in, z:=], then for eveTy pai~ ((i, VJ) (j=l , . . . 
. k) which corresponds to (.$, v), &#38; is inconsis­tent with [z~in, z;=]. The following proposition 
shows that if there is a cycle which updates a value of E, (resp., Zi) for some i, then the inequality 
y < Zi (resp., y ~ Zi) holds either for all feasible values of ~i or for none of them. Moreover, this 
can be decided by considering the updating cycle. Proposition 2.I2. Let [ be a value of ?Fi (resp., ~), 
and suppose c is a cycle which staTts and ends at Ga (Tesp., ~%) is such that fc(() < ( (Tesp., f.(() 
> f) i.e., sequence of pushes along c results in an update of ?&#38;). Then eitheT (i) [ is inconsistent 
(< < x~in, OT, ? esp., ( > x~=) and the cycle c contradicts z, = &#38; OT (ii) ~ is consistent (~ > z 
:=, OT, TeSp., ( < X~in). The essence of the following proposition is proved by Aspvall and Shiloach 
[2, 3]. Proposition 2.13. Given a variable xi and a value (i, it can be decided in O(mn) operations whetheT 
(i) ~i < x~in, (ii) <Z > x~ax, or (iii) &#38; C [x~in, z~a]. Definition 2.14. (i) We refer to the decision 
made in Proposition 2.13 as deciding the value &#38;. (ii) The system of inequalities found by the algorithm 
(see below), which determines (i < z~in or (i > x~=, is the certi$cate of [i. These decisions are made 
using the following algorithm. The algorithm considers a value <i. The goal is to decide whether or not 
&#38; > Z,m=. The algorithm applies push phases iteratively. It stops when it finds a subsystem that 
implies fi > z~= (the case (, < z~in is similar). The subsystem found is minimal. If it is of size -t, 
it is found after O(l) iterations. If after 2n iterations such a subsystem is not detected, the algorithm 
determines that (~ < X?=. Algorithm 2.15. (i) Consider the graph G where the values at the vertices are 
initialized as: E3 = aj for j # i, Z3 = bl for j= l,... ,n, and ~i =[i. (ii) Repeat Steps (iii) -(vi) 
for k = 1,..., 2n. If the algo­rithm did not terminate, the system is feasible.  (iii) Perform a push 
phase. Denote the values at the vertices after the kth push phase by ~~, Z; (k = o,...,2n). Keep track 
of all essential push operations. At itera­tion k, the total size of the forest of essential pushes is 
at most 2kn. At each iteration, the forest can be updated in O(m) operations. We maintain only essential 
paths such that each vertex appears only once. The algorithm may discard some paths (see Step (vi)). 
If there are no remaining essential paths, (i ~ x?=, stop. (iv) If k # 23 for any integer j, and k # 
2n then go to Step (iii) (next iteration). Otherwise, continue as follows. If for some j we have F; > 
Z; then stop and conclude as follows. Consider the essential paths associated with these values. If for 
both paths, the initial vertex is not (yi, fi ), the system is infeasible. Otherwise, &#38; > Z$=. (v) 
For each vertex v, let pV be the essential path that corresponds to the last update of the value at v. 
 (vi) For all vertices v E V do as follows, Consider the last simple cycle c on the path p.. Denote by 
u the vertex where the cycle starts and ends. Denote by ( the value associated with u at its first occurrence 
on the cycle. Check whether the bound implied by c contradicts (. If there is no contradiction, discard 
all essential paths originating from the first pair of the cycle; continue and consider the next path. 
Other­wise, it follows that ~ is inconsistent, and so are all values along the path p. before c, Consider 
the first vertex w of pv. If w = E%,then ~~ > Xrnax. Otherwise,  z if w # g,, the system is infeasible. 
 The correctness proof is omitted. 3. The basic algorithm Recall that every directed path corresponds 
to a two vari­able inequality. Consider two inequalities which corre­spond to two paths between the same 
pair of vertices (w, Vj), where V; = {D,, g, }. These inequalities are linear, hence, there exists a 
number a such that for all Zi < a one of the inequalities implies the other, and vice versa for xi ~ 
a. If we focus only on feasible points x for which Zi ~ a (similarly z, < a), one of the inequalities 
is redundant. The algorithm described in this section eliminates paths and simultaneously restricts the 
feasible region, When comparing two paths, the decision about which one to eliminate is done as follows. 
First, the num­ber a, as above, is computed. Then, Algorithm 2.15 of the previous section is used to 
locate a with respect to feasible values of Zi. We formalize the concept of comparing paths in the following 
definition. Definition 3.1. (i) Suppose that pl and pz are two directed paths from a to b, and from b 
to c, respectively. Denote by p1p2 the path from a to c obtained by concatenating pl and pz. (ii) Suppose 
that pl and pz are two paths from a to b. Let I c R be an interval. We say that the path pl is at least 
as tight as pz relative to J (denote it by  (iii) Suppose pl, pz, . . . . p~ are paths from a to b. 
If for some i, pi + pj for all j, then we can write pi = min~l{pl, pz, . . . . p~}. Note that rein<, 
is well­ defined if I is a single point. The algorithm maintains a set of intervals S~ (i = 1 ,..., 
n), and a path pa~ from a to b for every pair of vertices (a, b). The algorithm runs in llogz nl phases. 
During each phase, the paths and the intervals are con­sidered for possible updates. Denote by S: (i 
= 1, . . . . n) and p~~ ({a, b} g V) the intervals and paths, respectively, at the beginning of the k 
th phase. The algorithm has the following properties: (i) The set of intervals Sk contains a solution, 
and (ii) the path p~b is the tightest path from a to b, of length at most 2k, relative to the interval 
S: (where a E {u,, y,}). The algorithm is based on solving instances of the fol­lowing problem: Problem 
3.2. Given are a graph G and a set of intervals 51, ..., Sn as in Definition 2.1. Denote by F G Rn the 
set of all feasible points. If we are interested in a more specific solution, denote by F the set of 
acceptable solutions. For every ordered pair of vertices we are given a collection of directed paths 
inG. Foranordered pair ofvertices(u, v), denote the collection of paths from u to v by p~v, . . . . p~W. 
Let ~~~,... , f$:t be the linear functions associated with these paths. The goals are (i) Find a set 
of n intervals 11, . . . . In, (~~nl ~,) n F # 0, and (ii) For every pair (u, v) of vertices select a 
path p~v as follows. Suppose U.E {~, iii}. The se­lected path p;v is the minimum path among p~v, . . 
. . p~ , relative to the relation <r;. We later suggest algorithms for Problem 3.2. The fol­lowing algorithm 
uses it as a subroutine. It first initializes the tightest-paths matrix by selecting the tightest edge 
out of every set of multiple edges (Step (ii)). The rest of the algorithm consists of [log nl update 
phases of the tightest-paths matrix (Step (iv)). During each phase, the algorithm considers nz sets of 
n paths (one for each pair of vertices). It then selects the tightest path in each set. Algorithm 3.3. 
[Solve systems with at most two vari­ables per inequality] (i) [Initialization] Construct S and G as 
in Defini­tion 2.1. (ii) [Initialize tightest paths matrix] For each pair of ver­tices consider the 
paths of length 1, i.e., the multiple edges. Solve Problem 3.2 relative to these paths. Let p~w be the 
tightest edge from u to v. Let S: = Ii (ill,..., n).  (iii) Fork =1, ..., Fog, nl, execute Step (iv): 
(iv) For all pairs (u, v) E V x V, consider the set of paths {P!; } U {P% P&#38;~l I(w = V \ {u, v})}. 
Solve Prob­ lem 3.2 relative to this collection of paths. Denote the resulting minimum paths by p~v ((u, 
V) ~ V x V). Replace S; by the resulting interval 1, (i = I,. . . . n,). (v) Fori= 1,. ... n, let pi 
= p~$t?l, let p: = p~~~,V1, Pwnl. si + sin{zIfP,(z) S Z}l S e let P; = P5t,wt , .si n {zlfP:(x~> z}, 
S, +--.% n {zlfP:(z)s x}. (vi) Shrink S (see Definition 2.5). The correctness proof is omitted. 3.1 
Complexity The complexity is dominated by the calls to an algorithm for Problem 3.2. We consider a solution 
for Problem 3.2 where the decisions are made in n sequential stages. At the i th stage we compute the 
interval 1, and make all decisions which regard the O(n) ordered pairs, such that the first vertex is 
in {~, Z, }. We then set Sa to Ii. The following Proposition discusses the complexity of a single stage. 
Proposition 3.4. Problem 5 ..2 can be solved so that each stage requires O(k + mn log k) operations, 
where k = Zfl(ku-l. + kuv). The full proof is omitted. The solution is based on O(log k) calls to Algorithm 
2.15. We apply the bounds given in Proposition 3.4. In Step (ii), k is the number of edges in the graph. 
Hence the number of operations is 0(mn2 log m). Step (iv), con­sists of n stages where for each one, 
k = n2. Hence, the number of operations is 0(n3 + mn2 log n). Step (iv) is performed Pog2 n.1 times. 
It follows that the total number of operations is 0(mn2 logm+n3logn+mn2log2n) . 4. The randomized algorithm 
In this section we present a faster implementation of Al­gorithm 3.3 for solving monotone systems. The 
better bounds are achieved by using a more efficient algorithm for Problem 3.2. In Subsection 4.1 we 
define mono­tone systems. In Subsection 4.2 we present an algorithm for Problem 3.2 that breaks down 
the computation into 0(log2 n+log m) comparison stages . Each stage mainly involves resolving a constant 
fraction out of O (n3 + m) independent path-comparisons. This is done by deciding a pool of O(n) values, 
all of different variables. In Sub­section 4.3 we analyze the total time complexity in terms of number 
of calls to a procedure which decides a pool of values. In Subsection 4.4 we present an algorithm for 
deciding such a pool of O(n) values. In the succeeding subsections we discuss procedures used by the 
algorithm of Subsection 4.4. 4.1 Monotone systems Consider systems of linear inequalities with at most 
two non-zero coefficients per inequality, that is, systems of the form Ace ~ b where b c Rn is a real 
vector and A c Rmx is a matrix with at most two non-zero entries per row. Consider the following two 
operations on vectors in Rn : Zvy = (max{zl! Yl},..., max{% ! !/rL})T xAy = (min{zl, Y1},..., max{zr,, 
Y71})T If in matrix A there is at most one positive (resp., neg­ative) entry per row (that is, AT is 
a pre-Leontief matrix) then the set of solutions of such a system constitutes a semilattice relative 
to the V (resp., A) operation (see Cot­tle and Veinott [5]). The associated graph of such a system (see 
Defini­tion 2.1) does not contain edges from ~ to ~ (resp., from vto ~). A system where for every inequality 
the two non-zero coefficients have opposite signs (both AT and AT are pre-Leontief ) is called monotone. 
The set of solutions of monotone systems constitutes a lattice relative to the V and A operations. It 
follows that if all the variables are bounded, then there exists a solution where all the variables are 
maximized (or minimized) simultaneously. Note that in the associated graph of a monotone system there 
are no edges passing between the two sets of vertices ~ and ~. The system underlying the dual of the 
inca­pacitated generalized transshipment problem (see Section 5) is monotone. In this section we present 
a randomized implementation of Algorit hm 3.3 for monotone systems. We show that the maximum (or, equivalently, 
the minimum) point can be found using 0(rz3 log n + mn log m log3 n + mn logs n) op­erat ions. The algorithm 
determines which variables are unbounded and supplies dependencies that allow us to compute feasible 
solutions. These time bounds also ap­ply to computing a maximum solution when the matrix AT is pre-Leontief. 
When the goal is to find the point a! =, Problem 3.2 can rely on a simpler notion of decid­ing values. 
In this section, deciding the value ( means locating it with respect to Z?= (rather than determining 
its position relative to z~in as well). Consider Algorithm 2.15 in case the underlying system of inequalities 
is monotone. Assume the algorithm locates a value ~ with respect to z~ax. The algorithm yields the same 
result when applied only to the connected compo­nent containing ~. In the initialization step it suffices 
to set gi = ~, and gl = bf (j # i). The algorithm termi­ nates after at most n iterations, or when it 
determines ~ > z~= and the certificate E is found. Note that the certificate E always consists of a path 
and a cycle, both in ~. We interchangeably refer to the set E 1 of the reversed edges (which pass between 
vertices in ~), and to the corresponding set of inequalities as the certificate. Proposition 4.1. Consider 
a mm of the algorithm for some [ > x?= when the initialization is Z% = [, but g3 = iij, where aj < h~ 
< xjrn= (j # i) . For ail choices of ~j (j # i), the algorithm terminates with the same certificate. 
Definition 4.2. Suppose {~%Ii E J} where J C {l,... , n} is a set of values for the corresponding vari­ables. 
An application of Algorithm 2.15 to this set of values is a run where the initialization step is ~ = 
(% (i EJ), and Zi = b; (i $?J). 4.2 Framework of the algorithm Consider an application of Algorithm 3.3 
to a monotone system with the objective of finding the maximum solu­tion. Recall that the algorithm maintains 
a tightest-path for each pair of vertices. The algorithm performs com­parisons between pairs of paths 
and chooses one which is at least as tight as the other member of the pair on part of the feasible region. 
Resolving a comparison amounts to deciding a value. The search is then restricted to the interval where 
this comparison holds. When the objective is to find a specific point (e.g., the maximum), all resolved 
path-comparisons need to hold at this point (i.e., select the path which is at least as tight on z =). 
It suffices to consider onlY vertices in ~ (or equivalently, ~) since the outcome of comparing pl, pz 
is identical to the outcome -1 of comparing p; 1, pz . We discuss the complexity of solving Problem 
3.2. A single value can be decided in O(mrz) steps by using Algo­rithm 2.15. We benefit, however, from 
grouping together independent query values. In the algorithm for Prob­lem 3.2 outlined in the previous 
section we infer from the answer to a query about the value of one variable only with regard to other 
values of the same variable. In the implementation used here, we use a randomized approach that does 
even better and typically infers with regard to values of other variables as well. This results in an 
al­gorithm for Problem 3.2 which is faster by a factor of n, and hence, to a faster implementation of 
Algorithm 3.3. The main difficulty solved in this section is an efficient solution for the following 
problem: Problem 4.3. [Decide a pool of values] Given are values &#38; for the corresponding variable 
z, (i= 1,..., n). Decide these values, i.e., determine if &#38; > z~= (i = 1, . . . . n). We review the 
algorithm for Problem 3.2 given in Sub­ section 3.1, and contrast it with a new approach used here. 
We give a set-up which breaks down the computa­ tion to a polylogarithmic number of stages, where each 
such stage involves solving Problem 4.4. In the solution of the previous section, the variables are considered 
in n sequential steps, where decisions regard­ing values of one variable affect later decisions regarding 
values of others. Solving all the comparisons regarding a single variable requires deciding O(log m) 
values in the initialization step, and O(log n) values in each iterative step. Since in the monotone 
case all decisions are made with regard to the feasible point Z nax, decisions regarding different variables 
are independent. We can perform the computation for all n variables concurrently . The ini­tialization 
step is divided into O(logm) stages and each phase is divided into O(logn) stages. Each such stage consists 
of deciding n values of different variables, i.e., solving Problem 4.3.  4.3 Complexity The algorithm 
consists of an initialization step of the tightest-paths matrix followed by Pog nl path-doubling phases 
which update the tightest-paths matrix. We discuss the number of steps required for the ini­tialization 
and the update phases. The initialization step involves finding a tightest path in each of nz sets with 
a total number of elements of at most m. This is done in O(log m) stages, where stage t consists of solving 
an in­stance of Problem 4.3 and 0(rn/2t ) additional time. The update operation done in each phase involves 
finding a tightest path for n2 sets of n elements each. This is done in O(log n) stages, where stage 
t consists of solving Prob­lem 4.3 and 0(n3/2t) additional time. It follows that the complexity is dominated 
by O(log m + log2 n) applications of an algorithm for Prob­lem 4.3 and O(m + n3 log n) additional time. 
The rest of this section is concerned with Problem 4.3. We prove the following: Theorem 4.4. Problem 
~. 3 can be resolved in an ex­pected number of O(mn log3 n) operations. It follows that monotone systems 
can be solved in an expected number of 0(n3 log n+ mn log5 n+ mn log mlog3 n) operations.  4.4 Deciding 
a pool of values In this Subsection we present an algorithm for Prob­ lem 4.4. For purposes of analysis, 
let us classify values of vari­ables according to the sizes of their certificate es. Definition 4.5. 
A value &#38; of a variable x, is 1-bzg if <, > x~= and the certificate is of size at most L A value 
is (11, Iz]-big if it is L2-big but not n-big. If ~, < z:= then la is small. We now explain the motivation 
for this classification. The algorithm which decides a pool of values is based on a tradeoff between 
the following two properties. These properties are stated more formally and proved later. The first one 
favors values with small certificates; for any !-big value < it takes O(m.t) operations to find the certifi­cate. 
Hence, a decision procedure which decides l-big val­ues requires only O(mY) operations. The second property 
favors values with large certificates; we give a procedure that considers a big value [ along with an 
associated cer­tificate G . This procedure can on average decide many other big values whose certificates 
intersect G . We introduce the following two procedures which are applied to a set of values: The first 
procedure reveal is applied to a set of k un­decided values; it either finds a big value which belongs 
to the set, or concludes that all these values are small. A reveal can be performed in O(mn) steps. The 
algo­rithm is omitted. The second procedure is a check of an l-big value. The certificate of an Z-big 
value can be computed in O(rnl) operations, using Algorithm 2.15. The (check procedure uses the certificate 
to compute upper bounds on feasible values of other variables. This gives rise to decisions re­garding 
other values in the pool. An O(ml) time check algorithm is given in Subsection 4.5. In Subsection 4.6 
we show that at least half of the (t?, 21]-big values in the pool have the following property. When a 
check is applied to any of them, it decides at least l/(6n) of the other (1, 2.!]-big values in the pool. 
 The following algorithm decides a pool of n values. Let r < n be the (unknown) number of big values. 
The check and reveal procedures are used as subroutines. Appropriate values for the constants Cl, Cz, 
and C are given later. Algorithm 4.6. [Decide a pool of values] (; Loop A: Steps (i)-(ix) Apply the 
(reveal procedure to the set of all values. If there are no big values, stop. Otherwise, compute an estimate 
r-of the number of big values in the pool such that 1/2 ~ r /r ~ 2 with probability ~ 1/2. This estimate 
is achieved by applications of the reveal procedure Set ti = O (a counter of the number of operations). 
(ii) Set tb = O (the number of big values discarded in the current iteration of Loop A). Loop B: Steps 
(iii)-(ix) (iii; If either (i) tb z ~ /4 (the estimate is successful), or (ii) tt> Cmnlog2 n (estimate 
failed), go to Step (i). (iv) Set b = O (number of big values discarded in the current iteration of Loop 
B). (v) Choose k = [Cl log nl random samples S1, . . . . Sk from the pool, each of size min{n/4, [n/2~-l 
}. (vi) Execute concurrently k runs of Algorithm 2.15 ap­ plied to S1, ..., Sk (See Definition 4.2) as 
follows: (vii) Initialize copy i according to the set of values Si. Set 1 = O (current phase number). 
Set K = {1, . . . . k} (set of active runs). Loop C: Steps (viii)-(ix) (viii; Apply another iteration 
(push phase) to the runs in K. Set Z &#38; 1 + 1. If certificates are found for a subset K c K of the 
runs, apply a check opera­ tion, discard the big values found, increment b and tb accordingly, and set 
K = K \ K . (ix) If either I = n or b ~ [C#/(nlog n)~ l then tt = tt + C#rnlog n, go to Step (iii) (next 
iteration of Loop B). Otherwise, go to Step (viii). In the full version we show the following. There 
ex­ist a choice of the constants C, Cl, C2 such that for all inputs, Algorithm 4.4 terminates successfully 
in an ex­pected number of O(mn log3 n) iterations. This concludes the proof of Theorem 4.4. 4.5 The 
check procedure In this subsection we give an algorithm for performing checks. The check algorithm is 
given a (2k -1, 2k]-big value along with the certificate e, and provides information from which it can 
be concluded that certain other values are also big. Proposition 4. 7. Suppose &#38; is a big value of 
xi. Con­sider a vertez Tj in the ceytijicate Gi of (i. If p is a path in Gi from iij to Vi, then the 
value (j = fP-1 ((i ) is big for Xj . The following algorithm performs a check. Given is a (2k -1, 2k]-big 
value &#38; of z. along with the certificate G,. Algorithm 4.8. [check] (i) For each variable Xf ~ G,, 
compute the big value .$j induced by <i through Gi, as described in Proposi­tion 4.7.  (ii) Initialize 
the values of El, . . . . Zn as follows. If XJ 6 G,} set ZJ = ~j. Otherwise, if ~j @ Gil set ZJ = ~. 
 (iii) Perform 2k push phases. When finite, the final values of Ej (j=l, . . ..n) are big. (iv) Make 
conclusions as follows. If for some value q we have ~ > Ej, conclude that q is a big value of Zj. Definition 
4.9. If in Step (iv) of Algorithm 4.8 we de­duce that a value ~ is big, we say that ~% 2k -decides q. 
 4.6 Properties of the check procedure This subsection establishes the following theorem: Theorem 4.10. 
Consider a collection of b (2k -1, 2k]-big values. A check applied to a Tandomly chosen big value, decides 
with probability at least ~, i_l(b2k /n) values. The following proposition analyzes the dependencies 
among values of different variables. Proposition 4.11. Let <i and [, be big values of xi and - xj, Tespectiveiy, 
and let Gi and Gj be the respective cer­tificates. The ceTtijicates are such that [G; I <1, lGj [ <1 
for some 1. Under these conditions, if the sets of va? iab~es participating in the certificates intemect, 
then at least one of the values [, and (j is -t-decided by the otheT. PToof: Suppose u e ~ is a vertex 
in the intersection of Gi and Gj. Let pi be a directed path in Gi from u to ~i and let pj be a directed 
path in Gj from u to Fj. Assume, to the contrary, that neither of&#38; and (j is decided by the other. 
It follows that Recall that all functions associated with paths (and their inverses) are nondecreasing 
linear functions. Hence, by substituting the first inequality in the second we get I Definition 4.12. 
Consider a pool of b (2k -1, 2k]-big val­ues. The influence graph oft his pool is defined as follows. 
Each big value in the pool corresponds to a vertex in the influence graph. If one value 2k-decides another, 
then there is a directed edge from the vertex of the former to the vertex of the latter. Theorem 4.10 
is an immediate corollary of the following theorem: Theorem 4.13. In the influence gTaph of a pool of 
b (2k- , 2k]-big values, at least half of the vertices have an out-degree greater than ~b2k -l/n 1. 
5. Applications 5.2 Generalized circulation Generalized network flow problems are defined on a di­graph 
G = (V, E) given together with positive flow mul­tipliers a, (e c E) associated with the edges. The mul­tipliers 
are interpreted as gain factors (when a. > 1) or loss factors (when ae < 1) of flow along the edge e. 
When Z(: units of flow enter the edge e, a~ ZC units {leave . In the notation used later in this section, 
edges are indexed by their end vertices. The algorithms, however, general­ ize to allow multiple edges. 
Therefore, for some instances ?-n = U(?Z2).  5.1 Generalized transshipment problem The generalized incapacitated 
transshipment problem is defined as follows. A generalized network G = (V, E) is given together with 
edge-costs c~j and supplies (or de­mands) bi associated with the vertices. The goal is to find a nonnegative 
fiow function x = (xzj) such that for every i,~ Xii -~ aJiz~i = bi, so as to minimize the cost ~%,1 cij 
xij. The linear programming dual of the problem is as fol­lows. Find nonnegative numbers ~1, . . . . 
~n such that for every edge e = (i, j), ~i aij~j ~ GJ , and ~~=1 ~i bi is maximized. Note that the dual 
system is monotone with at most two variables per inequality, how­ever, the problem has a general objective 
function. The algorithms of the preceding sections compute the simul­taneous maximum or minimum feasible 
point, but do not solve the problem relative to a general objective function. Adler and Cosares [1] proposed 
an algorithm for a spe­cial class of linear programs where each variable appears in at most two inequalities. 
The class they considered in­cludes the incapacitated generalized transshipment prob­lem, where there 
are either only sources (i.e., vertices with positive supply) or only sinks (vertices with negative sup­plies). 
Their algorithm is based on using Megiddo s algo­rithm [1 I] for systems with two variables per inequality 
to solve the dual problem. This also dominates the running time. Note that when b ~ O (resp., b s O) 
the maximum (resp., minimum) feasible point of the dual system, max­imizes the objective function. Our 
algorithms improve over the running time of [11], and hence the incapacitated generalized transshipment 
problem with only sources (or only sinks) can be solved in a randomized running time of 0(n3 log n + 
mnlog mlog3 n + mn log5 n), and a deter­ministic time of O(mn log m + mnz log2 n). The generalized circulation 
problem is defined for a gen­eralized network G = (V, E) with a distinguished vertex s and nonnegative 
edge-capacities C,J (possibly co). A generalized flow is a flow function a = (Z~J ) (z~j ~ O) which satisfies 
the following conservation constraint. For every i # s, X3 Xij = E2 a,lzxjz. A generalized flow is feasible 
if Zil 5 Cij for all edges. The goal is to find a feasible generalized flow a which maximizes the excess 
at s, defined by El x~j EJ aj$xjs. Generalized circulation problems can be used to model many situations 
that arise in financial analysis [6, 7, 9]. The best known time bound for the problem, due to 2 1.5 log(n7)), 
were -Y is an uPPer Vaidya [15], is O(n m bound on the numerators and denominators of the ca­pacities 
and costs. Vaidya s bound is based on a special­ization of his currently fastest known general-purpose 
lin­ear programming algorithm. His algorithm relies on the t heretically fast matrix multiplication algorithms. 
Our algorithms give better running time for some cases (e. g., when the number of bits in the binary 
encoding of the maximum excess S is small) and are simpler. The best previously known bound which does 
not rely on fast matrix multiplication is worse by a factor of &#38; and was given by Kapoor and Vaidya 
[8]. Our time bound improves over the latter, as well as over previous algo­rithms of Goldberg, Plotkin 
and Tardos [7]. The existence of a strongly polynomial time algorithm for the generalized circulation 
problem remains open. This problem is of special interest because it is one of the simplest classes of 
linear programming problems for which no strongly polynomial algorithms are known [7, 14]. Here we give 
the first strongly polynomial approzimaiion algorithm for the problem. The algorithm computes a feasible 
generalized flow whose excess approximates the maximum excess to any constant factor. The algorithm presented 
here for the generalized circu­lation problem is based on iterative calls to an algorithm for monotone 
systems with two variables per inequality. Each iteration computes a feasible generalized flow where 
the excess is at least 1/m of the maximum excess in the residual graph. Hence, a feasible generalized 
flow which approximates the maximum excess S within any constant factor, can be computed using O(m) iterations 
of our al­gorithm. An exact solution can be found after O(mlSl) iterations, where IS I is the number 
of bits in the binary encoding of S. As a consequence, we get: (i) An 0((n310g n + mnlog mlog3 n + mnlog5 
n)mlSl) randomized algorithm. (ii) An O((nm2 log m+rnz nz log2 n) IS I) deterministic al-References 
~ gorithm. (iii) An 0(mn3 log n+rnznlog mlog3 rz+m2rzlog5 n) ran-[1]L Adler and S. Cosares, Strongly 
polynomial algorithms for linear programming problems with special structure, domized approximation algorithm. 
manuscript, 1989. (iv) An 0(nm2 log m + mz nz logz n) deterministic ap­ proximation algorithm, [2] B. 
Aspvall, Eficient algoTithrns for ceTtain satisjiability and linear programming problems, Ph.D. Dissertation, 
Tech. Rep. STAN-CS-80-822, Stanford University, 1980. Note that the bounds for the approximation problem 
are [3] B. Aspvall and Y. Shiloach, A polynomial time algo­ strongly polynomial. rithm for solving systems 
of linear inequalities with two What remains is to discuss a single iteration, that is, variables per 
inequality, SIAM J. Comput. 9 ( 1980) 827­ show how by using one call to a subroutine that solves 845. 
monotone two-variables per inequality systems, we can [4] E. Cohen and N. Megiddo, Strongly polynomial 
and NC find a feasible generalized flow with excess which is at algorithms for detecting cycles in dynamic 
graphs, in: least S/m. The following algorithm computes such a flow. Proceeding of the 21st Annual A 
CM Symposium on The­ory of Computing (1989), ACM, pp. 523 534. Consider an instance of the generalized 
circulation [5] R. W. Cottle and A. F. Veinott Jr., Polyhedral sets hav­problem on a digraph G = (V, 
E) with a distinguished ing a least element, Mathematical Programming 3 (1972) vertex S, nonnegative 
edge-capacities Cil and positive flow 238-249. multipliers aij. For each edge (i, j), define the cost 
c~j [6] F. Glover, J. Hultz, D. Klingman, and J. Stunz, Gener­ as C~j = I/cij if ci,j < m, and C~j = 
O otherwise, For ev­alized networks: a fundamental computer-based planning ery flow function y ~ O, denote 
by p(y) = &#38; yij C;j the tool, Management Science 24 (12) (August 1978). cost of y relative to c 
. Note that (i) if y 1s a feasible [7] A. V. Goldberg, S. K. Plotkin and E. Tardos, Combina­ generalized 
flow, p(y) g m, and (ii) if v saturates at least torial algorithms for the generalized circulation problem, 
 one edge (i.e., yiy = c~j for some edge), p(y) ~ 1. Denote in: Proceedings of the 29th Annual IEEE Symposium 
on by S(y) = xi ~,yi, xi y,i the excess at the source. Foundations oj Computer Science (1988), IEEE, 
pp. 432­ 443. Algorithm 5.1. [Compute a feasible generalized flow y [8] S. Kapoor and P. M. Vaidya, 
Speeding up Karmarkar s such that S(y) ~ S/m] algorithm for multicommodity flows, Mathematical Pro­gramming 
, to appear. [9] E. L. Lawler, Combinato~ial optimization: networks and matToids, Holt, Reinhart, and 
Winston, New-York, NY, (i) Construct an instance of the incapacitated general­ ized transshipment problem 
on the digraph G with 1976. flow multipliers a%j and edge costs c~j (see Subsec­tion 5. 1). Define the 
demand to be 1 at the source s [10] G. S. Lueker, N. Megiddo and V. Ramachandran, Linear programming 
with two variables per inequality in poly log time, SIAM J. Comput. 19 (1990), to appear. and O at all 
the other nodes. (ii) Find a generalized flow a = (zaj ) which solves the generalized transshipment 
problem defined in the [11] N. Megiddo, Towards a genuinely polynomial algorithm for linear programming, 
SIAM J, Comput. 12 (1983) previous step. Use the Adler and Cosares s scheme 347-353. and the algorithms 
of previous sections (see Subsec­tion 5.1). Note that there is only a single demand [12] C. G. Nelson, 
An no( g ) algorithm for the two­node and no supply nodes, hence, the scheme is ap­ variable-per-constraint 
linear programming satisfiabiEty problem, Tech. Rep. AIM-319, Stanford University, plicable. If the 
problem is infeasible then stop; there 1978. is no feasible generalized flow on the capacitated net­work 
wit h positive excess at s. [13] R. Shostak, Deciding linear inequalities by computing loop residues, 
J. Assoc. Comput. Mach. 28 (1981) 769­ (iii) If p(m) = O, stop; the maximum excess of a feasible 779. 
generalized flow (on the capacitated network) is un­bounded, and the flow functions riz are feasible 
for  [14] E. Tardos, A strongly polynomial algorithm to solve combinatorial linear programs, Operations 
Research 34 all~~O. (1986), 250-256. (iv) Otherwise, compute the maximal number ~ (must be [15] P. M. 
Vaidya, Speeding-up linear programming using such that ~ < 00), such that for all edges e = (i, j) fast 
matrix multiplication, in: Proceedings of the 30th Tz,j ~ cil. Output the feasible generalized flow TZ. 
 Annual IEEE Symposium on Foundations of Computer Science (1989), IEEE, pp. 332-337. The correctness 
proof is omitted.   
			