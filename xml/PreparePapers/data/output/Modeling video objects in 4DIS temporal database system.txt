
 Modeling Video Objects in 4DIS Temporal Database System* Antonio Si Rynson W.H. Lau Qing Li Hong V. 
Leong Department of Computing The Hong Kong Polytechnic University Hung Horn, Kowloon Hong Kong {csasi, 
cswhlau, csqli, cshleong}@comp.polyu.edu.hk Keywords: Multimedia databases, data modeling, temporal 
database, object-oriented database. ABSTRACT Video objects are temporal in nature~ A video object is 
com- posed of a set of video frames which are related in a total time ordering. By imposing additional 
timing constraints among video frames, various presentation operators on video objects could be defined. 
A core set of presentation operators include Play, Pause, Resume, Fast Forward, Fast Backward, Slow Mo-tion, 
and Stop. A video database system must be able to support the temporal ordering of video frames and the 
tem- poral constraints required by any presentation operators. In this paper, we demonstrate how our 
Four Dimen- sional Information Space (4DIS) temporal database system is used to model video objects and 
the presentation opera- tors. Since rime'is defined as a first class object in 4DIS, querying operators 
and constraints for time objects are sup- ported, These temporal querying operators and constraints are 
used to describe the timing requirements of video objects and the presentation operators. This allows 
users to describe video objects and operators declaratively, without worrying about their low level representation. 
Furthermore, a user could specify arbitrary operations on video objects using the query language supported 
by 4D1S. This is in contrast with existing video database systems in which operators on video objects 
are limited and are defined in advance. 1 Introduction Recently, there is a resurgence of research in 
video data- base systems (or multimedia database systems in gen- eral) [1, 3, 5, 12, 14, 16]. A video 
database system aims at providing modeling and querying capabilities for video objects at a high level 
of abstraction in a way similar to conventional database system for literal data. This allows users to 
describe video objects and their op- erators declaratively, without worrying about their low level representation 
and implementation details. Digitized video objects are temporal in nature. A video object is composed 
of a set of video frames which "Research supported in part by the Hong Kong Polytech- nic University 
Central R,esearch Grant numbers 353/066 and 340/115. Permission to make digital/hard copy of all or part 
of this work for personal or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage, the copyright notice, the title of the publication and 
its date appear, and notice is given that copying is by permission of ACM, Inc. To copy otherwise, to 
republish, to post on servers or to redistribute to lists, requires prior specific permission and/ora 
fee. &#38;#169; 1998 ACM 0-89791-969-6/98/0002 3.50 are related by a total time ordering. By imposing 
ad- ditional timing constraints among video frames, vari-ous presentation operators on video objects 
could be defined. A core set of presentation operators include Play, Pause, Resume, Fast Forward, Fast 
Backward, Slow Motion, and Stop, These seven operators impose dif- ferent temporal constraints on the 
relationships among video frames. For instance, the Play operator might re- quire that 30 video frames 
are presented every second. A video database system must have the capability to man- age the aspects 
of time required for video objects and the temporal requirements of any presentation operator. Similar 
to conventional database system, a video data- base system contains three components: a data model to 
describe the structures and constraints of video data, a query processor for retrieving video data, and 
a storage manager for persistent management of video data. Data models developed in existing video database 
systems are usually application-oriented, tailored to a specific appli- cation domain [1, 3, 6, 16]. 
This confines operations on video objects to those of the specific application. This approach lacks flexibility 
and extensibility; it is difficult to specify operations on a video object beyond the ca- pabilities 
supported by the provided operators. In this paper, we propose to model video objects us- ing a temporal 
database system [8, 13]. Since time is defined as a first class object in a temporal database system, 
querying operators and constraints for time ob- jects are supported. The temporal constraints can be 
used to describe the timing relationships among video frames of a video object while the querying operators 
can be used to support any presentation operators, Fur-thermore, a user could specify arbitrary operations 
on video objects using the query language supported by the temporal database system. This provides extensi- 
bility. We demonstrate the idea in the context of our Four Dimensional Information Space ( 4DIS) temporal 
database system [10]. A temporal database system also provides persistence for video objects, but our 
focus in this paper will be the capability" of a temporal database system for describing video objects 
and specification of presentation operators. Employing a temporal database system to model video objects 
provides extra capabilities in addition to sup- porting presentation operators. A temporal database system 
provides persistent storage and querying capabil- ity for video objects upon which additional application 
User Layer /\\ Ap~tion Layer Iv,0eol°0ex,,,I. . . . Driver Layer LOW Level Drivers Kernel Layer Temporal 
Database Figure 1: System architecture. abstractions could be developed. This idea is depicted in Figure 
1, which shows the system architecture of our prototype. The system is composed of four layers. The kernel 
layer is made up of a temporal database, model- ing a set of video objects. The driver layer is built 
on the kernel layer. It contains a set of low level driver rou- tines for interfacing between the applications 
and the database. The application layers include different ap- plication programs developed for specific 
purposes. It is similar in spirit to the external layer or view of a database system [11]. Sample applications 
include VCR interface to provide presentation operators for video ob- jects and video indexing interface 
to allow the selection of video objects or video frames based on some user spec- ified search keys. In 
addition, a video editing interface may be implemented that allows various video frames and video clips 
to be merged together in different ways, according to temporal constraints. Furthermore, it is possible 
to model the data requirement for virtual real- ity applications like a virtual visit environment, retriev- 
ing the required video objects and presenting them to the user at the correct moment. Finally, the user 
layer represents the person who initiates the request and to whom the output is sent. We would like to 
stress that the system is not confined to supporting video objects. Additional multimedia objects such 
as audio objects or animation sequences could be supported as well. The remainder of this paper is organized 
as follows. In Section 2, we review previous work on modeling video data. In Section 3, we give a brief 
description of the 4DIS temporal database system. In Section 4, we il-lustrate how video objects and 
presentation operators could be modeled in 4DIS. In this paper, we only fo- cus on seven core presentation 
operators, namely, Play, Pause, Resume, Fast Forward, Fast Backward, Slow Mo- tion, and Stop. Finally, 
in Section 5, we present a brief concluding remark and current research directions.  Related Work There 
have been two objectives in providing a data model for video objects. First, we would like to provide 
a high level description on their content, so as to allow users to query and search for video objects 
or video frames. in a way similar to the querying of conventional data-base systems on literal data [2, 
5, 12. 14], Second, we would like to be able to specie" the temporal chaxac- teristics of video objects 
so that temporal requirements of various presentation operators could be enforced and supported [7, 9]. 
The focus of this paper is on the latter issue which has been receiving less attention. Existing work 
on video retrieval has been focused al- most entirely oil video segmentation techniques which partition 
a video object into a collection of video seg- ments, each containing a sequence of video frames. The 
idea is to allow segments of video to be indexed indepen- dently so that they can be retrieved and manipulated. 
Chua and Ruan [3] proposed a video retrieval and sequencing system, which supports the entire process 
of video information management: segmenting, index- ing, retrieving, and sequencing of video data, In 
the system, each video segment is logged using text descrip- tions, audio dialogues, and cinematic attributes. 
A two- layered, concept-based model is used as the basis for accurately retrieving relevant video shots 
based on free- text queries, issued by users. Chang et as. [1] proposed a generic video database, which 
is composed of six modules. An object annota- tion module provides users with a friendly interface to 
mark the start and the end frames of a video object and to build annotations of each video segment. A 
con- tent acquisition/retrieval module provides image/video processing routines in order to support content-based 
re- trieval. A video management module has the capability to compress video data from video sources and 
decom- press it for playing. A video indexing module provides the annotation and other information for 
good indices to speed up retrieval of the desired video objects. A query processing module provides a 
way to query video objects using a variety of query methods and interfaces. However, unlike conventional 
SQL queries [11], queries specified against a video database axe usually imprecise; a video database 
is required to evaluate properties of the data specified in a query. Finally, an interactive brows- ing 
module provides user friendly interfaces to browse the video segments. Tonomura et as. [15, 16] proposed 
a video processing method that analyzes a video object and automatically segments it into shots. Each 
shot is indexed using the extracted features, such as camera work information and representative colors. 
Lee and Kao [6] developed a mech- anism for indexing video data based on the concept of objects and object 
motion with interactive annotation. A motion representation for the track of a moving ob- ject was presented. 
The access methods of video queries were introduced and a prototype of video indexing sys- tem was implemented. 
The specification of temporal characteristics and con- straints of video objects has only begun to receive 
lim- ited attention recently. In [9], an event calculus is pro- posed to describe the relationships and 
synchronization among several multimedia objects. Similarly, in [7], seven temporal relationships among 
multiple multime- dia objects are defined: before, meets, overlaps, during, starts, finishes, and equals. 
Each relationship has a cor- responding inverse relationship. Each temporal relation- ship or its inverse 
defines constraints on the starting time. the ending time, and the duration of the multime- dia objects 
involved. Synchronization among multime- dia objects could be specified by combinations of these seven 
relationships. Algorithms utilizing the provided constraints were also presented for playing multimedia 
objects. In contrast, our work focuses on describing the timing relationships of video objects and the 
timing con- straints of presentation operators using built-in model- ing constructs of a temporal database 
system [8, 13]. One can, thus, take advantage of the querying and op- timization capabilities of the 
underlying temporal data- base system. The 4DIS Model The 4DIS model provides uniformity in modeling 
data and recta-data in an extensible framework so that they can be manipulated by a single set of basic 
operators. For our discussion here, we will focus only on its capabil- ity on modeling data. 4DIS supports 
two basic modeling constructs: objects and mappings. Every fact in the real- world corresponds to an 
object in a 4DIS database. The 4DIS model supports atomic, class, and composite ob-jects. Atomic objects 
represent the symbolic constants in a database. Class objects specify the descriptive and classification 
information. Composite objects describe entities of application environments. Mappings belong to a special 
kind of composite objects. They are mainly used for modeling relationships between two objects. A relationship 
among objects is modeled as a four- valued tuple: (domain-object (d 6 D), mapping-object (rn 6 M), range-object 
(r 6 R), chronon-object (t E T)). Each relationship, r4d,, in a 4DIS database is a member of/9 x M x 
R x T, representing a relationship, m, between objects d and r at chronon t. A chronon object could be 
defined as a specific moment [8, 13]. A 4DIS database contains a collection of inter-related objects 
at various time chronon. It is basically a set of four-valued tuples: (domain-object. mapping-object, 
range-objec'c, chronon-objec'c). There are three dif- ferent predefined abstraction primitives based 
on a set of mapping objects. The abstraction primitives include classification / instantiadon (member), 
aggregation / de- composition (member), and generalization / specializa- tion (subclass). At chronon 
t, the definition of an Employee class ob- ject might be modeled by" the following tuples: (Employee, 
member, recta-class, t) (Employee. name, String, t) (Employee, level-of-skill. Integer, t) (Employee, 
address. String, t) (Employee, work-for, Company, t) Here, meta-dass is a system predefined class object, 
con- raining all class objects. Name, level-of-skill, and address are user-defined mapping objects, relating 
the Employee class object to the predefined class objects of String, In- teger, and String respectively. 
Company is another class object defined by another similar set of tuples and is related to Employee via 
tile mapping object work-for. Similarly, the definition of an object John at chronon t might be modeled 
by a similar set of tuples: (John, member, Employee, t) (John, name. "John", t) (John, level-of-skill, 
28, t) (John. address, "'Los Angeles", t) (John, work-for, Xerox, t) A 4DIS database couht be viewc(t 
graphically as il- lustrated in Figure 2. Sime a 4D space i.~ intunively dif- ficult to present, we depict 
a 4D space by a ~equcnce of Figure 2: Temporal evolution of objects in 4DIS. 3D space snapshots along 
the temporal dimension. The mapping axis holds only mapping objects. The temporal dimension holds only 
the chronon objects. All objects other than chronons appear on both the domain and range axes. Each relationship 
is represented by a point in the 4D space. 3.1 Data Evolution in 4DIS One characteristic of the 4DIS 
system is its simplicity in modeling data evolution. The idea of data evolution is illustrated in Figure 
2, where it depicts three snapshots, modeling the evolution of the object John. In the Krst snapshot, 
John is a member of the Person class object. In the second snapshot, John becomes a member of Student 
and finally, John becomes a member of Employee. As another example, the level-of-skill of John evolves 
from 3to18to28. In Figure 2, the evolution of an object is modeled by the evolution of its relationships 
with other objects. The temporal property of a relationship is indicated by its set of snapshots aver 
the 4D space as indicated by the dashed lines (a) and (b). The evolution of an object is thus modeled 
by its relationship closure with other objects at different chronons. To illustrate, let us denote the 
three chronons of the three snapshot databases in Figure 2 as tl, t2, and ta respectively. At tl, the 
object John is characterized by the following relationship closure: (John, member, Person, tl) (John, 
name, "John", tl) (John, level-of-skill, 3, tl) At t2, since the member and level-of-skill relationships 
of John have evolved, the object John is now character-ized by: (John, member, Student, t2) (John, name, 
"John", tl) (John, level-of-skill, 18, t~) Notice that since the name relationship of John has not changed, 
it does not need to be duplicated at the snap- shot captured in chronon t2. In other words, its rela- 
tionship with the temporal dimension does not change. This is indicated by the dashed line (c) in Figure 
2. At chronon tj. John is characterized by: (John. member. Employee, ta} (John. name. "John", t]) (John: 
level-of-skill, 28, tj) The interval that a relationship is valid is defined by the duration from the 
time the relationship is defined in the 4DIS database to the time the relationship has been changed or 
removed. This is called the "until-changed" semantics [8]. We call this duration, the validity dura-tion. 
For instance, in our above examples, the relation- ship that John is a member of the Person object has 
a validity duration of t2 -tl since the relationship is de- fined at chronon tl and the relationship 
is changed at chronon t2.  3.2 Query Specification in 4DIS Query specification in 4DIS is simple. It 
is based on three geometric components: line, plane, and spacecom-ponents. Each 4DIS query is specified 
as a four-valued constraint specification: (D constraint, M constraint, R constraint, T constraint), 
indicating the constraint on each of the four different dimensions. Each constraint can be a predicate, 
or the wildcard matching pattern of "?" symbol, A line component is specified with a "?" symbol in place 
of one of the constraints. A plane component is specified with two "?" symbols in place o.f two of the 
constraints. Similarly, a space component is specified with a "?" symbol in place of three of the constraints. 
In addition, a "-" symbol in place of any constraint denotes no information on that particular di- mension. 
Therefore, (-, -, -,-) denotes no information, Finally, a "." in place of the T constraint denotes the 
most current chronon. Therefore, (-, -, -, .) denotes no information at the current chronon. Each query, 
(D constraint, M constraint, R con-straint, T constraint) returns a set of four-valued tuples which satisfy 
the constraints. To project information on a specific dimension, we use operators Pick-D ({r4a,~ }), 
Pick-M ({tad.}), Pick-R ({r4..}), and Pick-T ({r,..}). Each operator takes a set of four-valued tuples 
as argu- ment and returns the set of objects on the corresponding dimension. We illustrate query specification 
in 4DIS with a few examples. To retrieve the current level-of skill informa- tion of John, a query could 
be specified as a line compo- nent: (John, level-of-skill, ?, .). Similarly, to obtain the level-of-skill 
information of John at time t. one could specify the line component: (John, level-of-skill. ?. t). With 
the sample database used in Section 3.1. we will obtain the tuple (Jotm, 3, 28, t~5) if tt < t < t.,.. 
since the level-of-skill of John is equal to 3 between chronon tt and t2. To retrieve all information 
of John at tl, one could specify a plane component: (John, ?, ?, tt). Finally, to obtain the historical 
information of John, a space component can be used: (John, ?, ?, ?). Predicates can be included in a 
query, Predicates are well-formed formulae, with some matching variables. It is of the form: ?X [P(X)]. 
Here, X is a variable and P(X) is the condition(s) defined on X. For instance, to obtain objects living 
in Los Angeles or Long Beach at chronon tl, one could specie' a line component: (?. address, ?X [X = 
"Los Angeles" or X = "Long Beach"], tl). We define inclusive and exclusive time intervals by [+ and +} 
and [- and -} pairs. As an example, an inter- val [+ t~, tz -] represents the set of chronons from and 
including t~ up to but excluding t.,. Specifying a time interval as a time constraint will thus select 
all tuples whose chronon object is a member of the set of chronon objects defined by the time interval. 
For instance, the line component: (John, level-of-skill, ?, [+ tz, t2 +]} is equivalent to (John, level-of-skill, 
?, ?X[ V X E [+ tl, t2 +] ]) or (John, level-of-skill, ?, ?X[ X in [+ tl, t2 +l ]) in 4DIS query syntax. 
Several temporal operators can thus be defined on chronon objects: 1. FIRST({r4a, }): The FIRST operator 
takes in a set of four-valued tuples as argument and returns the oldest chronon object of the set. For 
instance, FIRST((d, m, -, ?)) returns the oldest chronon object associated with the m mapping of object 
d since the line component in (d, m, -, ?) select a set of tuples related to d via the rn mapping at 
all points in time. 2. LAST({r4al,}): The LAST operator takes in a set of four-valued tuples as argument 
and returns the last (most current) chronon object of the set. 3. PRECEDE(t): The PRECEDE operator takes 
in a chronon object as argument and returns: { t' I t' < t}, That is, it returns a set of chronon objects 
before time t. For instance, (d, m, ?, PRECEDE(t)) selects the set of tuples related to d via the m 
mapping at all points in time before t. 4. SUCCEED(t): The SUCCEED operator takes in a chronon object 
as argument and returns: { t' [ t' > t}. That is, it returns a set of chronon objects after t. 5. 8EFORE(raa,~): 
The BEFORE operator takes in a four-valued tuple as argument and returns the previous snapshot. In other 
words:  BEFORE((d, m, r, t)) = (d, m, r', t') if and only if (J < t and ~Jt" E T where t' < t" < t and 
(d.m,r',t') is in the database. 6. NEXT(r4a,): The NEXT operator takes in a four- valued tuple as argument 
and returns the next snapshot, In other words: NEXT((d, m, r, t)) = .(d, m, r', t') if and only if t' 
> t and -~t" E T where t < t" < t' and (d,m,r',t') is in the database.  4 Management of Video Objects 
with 4DIS 4.1 Video Modeling A video object has a structure that could be modeled nicely by a temporal 
model. The idea is illustrated in Figure 3. We model video and frame as two different classes of objects. 
At a particular chronon, a video ob- ject is related to a frame object presented at that mo-ment m time. 
Each such relationship between a video object and a video frame has a validity duration, indi- cating 
the duration that the video frame will be pre- sented. When a relationship becomes invalid, the video 
object will be related to another frame. The relationship closure with different frame objects along 
the temporal dimension constitutes the evolution of the video object. In 4DIS. we could model such perspective 
by a Video class: Fr~= ......... ,' , , ~ .~:!!:~i!:!:~!!i!: Figure 3: A temporal structure of a video 
object. (Video, member, meta-class, tl~ (Video, current-frame, Frame, tl)  Here, current-frame is a 
user-defined mapping object that relates a Video class object to the Frame class object. As discussed 
in [5], it is important for a video object to be a first class object in a database system, or the database 
 system will be forced to use binary large object (BLOB) or a reference to an external file storing 
the video data. Neither approach is satisfactory. 4DIS supports video data via the Frame class. Each 
object of a Frame class is one frame of a video object. The second step will be to populate all video 
frames as objects of class Frame. This is achieved by the following set of tuples: (Framel, member, 
Frame, tz) (Frame2, member, Frame, tl) (Frame3, member, Frame, tl) (Frame4, member, Frame, $1) Framel, 
Frame2, Frame3, etc. are simply the symbolic name (or old) to the various frames of a video object. Finally, 
we need to populate the history of a video ob- ject, starting with its first frame to its last frame. 
This could be specified by the following set of tuptes: (Videol, member, Video, tl) (Videol, current-franm, 
Framel, tl) (Videol, current-frame. Frame2, t~) (Videol, current-frame. Frame3, t3) Here, Videol is 
a symbolic name to a video object such as "Star War". At chronon tl, the current-frame of Videol is Framel. 
This indicates the first snapshot of Videol object. The evolution of the Videol object is specified by 
relating the current-frame of Videol to Frame2 at the next chronon t2. This indicates the second snapshot 
of Video1 object. The remaining snapshots of Videol object are specified similarly, where each chronon 
differs from the previous one by ~u second Using the meta-tuple in 4DIS [10], one may define the following 
set of meta-tuples to relate the fi'ames (start- ing from the second frame) of all videos, i.e.,everything 
that can match with the first frame Framel will have its second frame Frame2 mapped to the next chronon, 
com- puted by adding the value ~0 to the chronon of Framel. With Frame2 defined, it can generate the 
next frame Frame3 and its correct chronon. The definition is as follows: (% current-frame, Framel: Frame2, 
?T: T+~) (?, current-frame, Frame2: Frame3, ?T: T+~) (?, current-frame, Frame3: Frame4, ?T: T+~) Finally, 
the spacing between chronons may be de- fined based on a synchronization chronon object speed. By altering 
the value of the speed object, the number of frames available per second can be adjusted. For exam- ple, 
slow motion can become relatively straightforward. (?, Video, speed, ~. t,~ (?, current-frame,~I~-~amel" 
Frame2, ?T: T+Pick-R((Video, speed, ?, .)))  4.2 Presentation Operators The seven basic core presentation 
operators of a video object could be modeled easily on 4DIS as a query. The intuitive idea is to select 
the current-frame of a video object at various chronon objects which are specified by the constraints 
required by an operator.  Play The Play operator is implemented by selecting for dis- play the current-frame 
of a video object at various time starting from its first chronon to its last chronon. This is retrieved 
by the Plck-R operation for a projection on the attribute or dimension of the current-frame at a specific 
chronon. Using Videol object as an example, playing Videol could be specified by the query: Pick-R((Videol, 
current-frame, ?, [+ FIRST((Videoi, current-frame, -, ?)), LAST((Videol, current-frame,-, ?)) +])). 
 Pause To pause the presentation of a video object at a specific chronon, t, the database system should 
repeatedly select the current-frame of the video object at t indefinitely This could be achieved from 
two different perspectives: from a modeling perspective and from an implementa-tion perspective. From 
a modeling perspective, pausing the presenta- tion of a video object at chronon t could be viewed as 
associating ~ as the validity duration for current-frame at chronon t. Selecting the current-frame of 
the video ob- ject at any chronon, g > t thereafter, would then result in selecting the current-frame 
at chronon t. Defining an c¢ validity duration for current-frame at chronon t could be achieved by associating 
the oo chronon to the next snapshot of the video object. For instance, assume that (Video1, current-frame, 
Framel, t} and (Videol, current-frame, Frame2, t') axe two con- secutive snapshots of Video1. Pausing 
the presentation of Video1 at time t could be achieved by associating the oo chronon object to the next 
snapshot, i,e., (Videol, current-frame, Frame2, oo). This could be achieved by the following query in 
general: (Videol, current-frame, Pick-R(( Videol, current-frame, ?, Pick-T({NEXT((Videol, current-frame.?, 
t))}) )), oc). Pick-T ({NEXT((Videol, current-frame, ?, t))}) returns the chronon object associated 
with the next snapshot of Videol. The nested line component: Pick-R (( Video1, current-frame, ?, Pick-T 
({ NEXT((Videol, current-frame, ?, t )) }) )) retrieves the frame object associated with Videol at the 
chronon object following the chronon ob- ject t. The expression, ( Video1, current-frame, Pick-R (( Videol, 
current-frame, ?, Pick-T ({NEXT (( Video1, current-frame, ?, t ))}) )), c~ ), will associate the c¢ chronon 
object to the following frame object. Once the ~ chronon object is associated with the frame object following 
the one being presented, the va- lidity duration of the frame object at chronon t will start from chronon 
t and end at chronon c¢. Therefore, pro- jecting the frame object from chronon t to c¢ will re- sult 
in projecting the same frame indefinitely. The line component: (Video, current-frame, ?, [+ t, ~ +]) 
could achieve the pausing effect. Notice that implementing the Pause operator via the modeling perspective 
is implicitly supported by temporal constraints. In particular, the temporal database system needs to 
enforce that once a frame object is selected for presentation, it is presented for a duration defined 
by its validity duration. Alternatively, from an implementation perspective, pausing the presentation 
of a video object at chronon t could be achieved by selecting the same frame object at chronon t within 
an indefinite loop: do { (Videol, current-frame, ?, t} } while (true);  Resume The Resume operator 
is similar to the Play operator, It is implemented by projecting the current-frame at vari- ous time 
starting from a specific chronon, t, to its last chronon. The time that the Resume operator starts is 
usually the time that the video object is paused. Using Videol as an example again, the Resume operator 
could be implemented by the following query: Pick-R ((Video1, current-frame, ?, [+ t, LAST((Videot, current-frame.-, 
?)) +1)). However, if the validity duration of the frame object being presented at chronon t has been 
changed to c¢ due to the Resume operator, it must be reset to a normal playback situation. This can be 
achieved by setting the chronon of the current-frame to the current time, and the meta-tuple will do 
the rest. (Videol, current-frame, Pick-R ((Videol, current-frame, ?, Pick-T ({ NEXT((Videol., current-frame, 
?, t))}))), t+Pick-R((Video, speed, ?, .))). From a user interface point of view. Pause and Re- sume 
operators could both be activated by the same user function with a toggle state variable, have_Paused: 
if (-~ have_Paused) { Pause; have_Paused = true: } else { Resume: have_Paused = false: } Such kind of 
mapping between the user interface and the temporal database could be implemented at the driver layer 
(see Section 1). Fast Forward The Fast Forward operator is similar to the Play opera- tor except that 
k chronons are skipped for each frame selected. Using Videol as an example, it could be im- plemented 
by the following query: Pick-R((Videol, current-frame, ?, [+ t, LAST((Videol, current-frame, -, ?)) +] 
and ?X IX E Pick-T ((Videol, current-frame, ?, ?Y [YE SUCCEED(t)])) and X = t+nk, Vn > 0])). The predicate, 
X E Pick-T ((Video1, current-frame, ?, ?Y [Y E SUCCEED(t)])), ensures that the chronon objects of interest 
are those chronon objects associated with the current-frame of Videol that follow the current chronon 
object t. The predicate, X = t + nk, V n > O, further restricts the chronon objects of interest to be 
a multiple of k chronons after the current chronon t. Fast Backward The Fast Backward operator is similar 
to the Fast For- ward operator except that the playing and skipping se-quences are reversed. It could 
be implemented by the following query: Pick-R((Videol, current-frame, ?, [+ t, LAST((Videol, current-frame,-, 
?)) +] and ?X IX E Pick-T ((Videol, current-frame, ?, ?Y [Y E PRECEDE(t)])) and x =t-nk, Vn>O])). As 
with Fast Forward, the predicate, X E Pick-T ((Videol, current-frame, ?, ?Y [Y E PRECEDE(t)])), ensures 
that the selected chronons are those associated with the current-frame of Videol, preceding the current 
chronon t. The predicate, X = t-nk, V n >_ O, fur-ther restricts the selected chronons to be a multiple 
of k preceding the current chronon t. Slow Motion This operator is similar to the Play operator except 
that each frazne is selected multiple times. This could be achieved from the modeling perspective and 
from the implementation perspective. From the modeling per-spective, this can be easily achieved by re-defining 
the synchronization object speed with other values, for ex- ample, ~ for a two-time slow motion. From 
an imple- mentation perspective, we could explicitly select a frame multiple times within a loop: t ,-- 
start time; do { for (i=i: i < k. i++) (Videol, current-frame, ?, t) t *-- Pick-T (NEXT((Videol, current-frame, 
?, t))) } while (t _< LAST ((Videol, current-frame,-, ?)));  Stop The Stop operator is implemented by 
selecting no frame at the current chronon, t: (Videol, current-frame, -, t). Conclusion and Future Work 
 In this paper, we have illustrated the feasibility of man- aging video objects using a temporal database 
system. In particular, we have illustrated via the temporal data- base system that it is quite simple 
to express presenta- tion operators of video objects as a temporal query. Several issues constitute our 
current research direc- tions. First, we would like to support quality of service (QoS) for video objects 
in 4DIS. In general, QoS can be measured by two factors: the number of frames pre- sented per second 
and the degree of resolution of each frame. We have illustrated in Section 3 that the number of frames 
presented per second could be modeled by the duration between two consecutive frames within a video object. 
However, to successfully provide this service, the temporal database system should properly enforce this 
constraint during run-time. To this end, we are currently incorporating the concept of real-time trans- 
actions into 4DIS. However, the environment may not be capable to provide the required number of frames 
per second~ such as in a high traffic network. One alterna- tive is to reduce the resolution of each 
frame. This could reduce the presentation time for rendering each frame. A "video frame object must be 
properly structured to incorporate information for presentation at various lev- els of resolution. This 
is not supported in the current 4DIS implementation where each frame is modeled as an atomic object. 
Sometimes, it might be useful to derive a video ob- ject from several existing video objects. Such a 
capabil- ity would be useful for relating multiple video objects for video editing, video transition, 
and video composi- tion [4]. We believe such capabilities could be easily supported in 4DIS. For instance, 
consider the following set of 4DIS expressions: (Video1, current-frame, Pick-R((Video2, current-frame, 
?. [+ tl, t2 +])),   [+ t~, t~ +]) (Videol. current-frame, pick-R((Video3, current-frame. ?, [+ t~. 
tr +])), [+ ts, t6 +]) The query Pick-R ((Video2. current-frame. ?. [+ t~, t~ +])) selects all frame 
objects related to video object Video2 within the duration t~ to t~. These frame objects will be related 
to video object Videol within the dura- tion t3 to td. Similarly, frame objects of Video3 within the 
duration t6 to tr will be associated with Videol within the duration t~ to t~. We are currently inves- 
tigating along this direction and results will be reported in the future. Another issue that we are investigating 
is the model- ing and support of audio objects. Audio objects exhibit a large degree of resemblance with 
video objects. Both media are composed of a collection of components, re- lated in a temporal sequence. 
Presentation operators on both media require timing relationships among their components, Due to the 
striking similarities between these two media, we believe that our approach to man- age video objects 
could be fruitfully applied on audio objects as well. ~Ve are also modeling the sy,~chronization process 
be- tween video and audio objects at various levels of granu- larity. Synchronization between video and 
audio objects can be at a coarse level such as aligning the start and end of an audio annotation with 
the first and last frame of a video frame sequence, both of which last for a du- ration of several seconds. 
In contrast, synchronization could be achieved at a fine level such as alignment of a lip movement which 
usually requires synchronization be- tween video frame sequence and audio annotation every seconds [7]. 
We are currently modeling synchroniza- tion with temporal constraints. References [1] C. W. Chang, K. 
F. Lin, and S. Y. Lee. The Char- acteristics of Digital Video and Considerations of De- signing Video 
Databases. In Proceedings of ACM In- ternational Conference on Information and Knowledge Management, 
pages 370-377, 1995. [2] T. Chua, S. Lim, and H. Pung. Content-based Retrieval of Segmented Images. In 
Proceedings of A CM Interna- tional Con/erence on Multimedia, pages 211-218, 1994. [3] T. S. Chua and 
L. Q. Ruan. A Video Retrieval and Sequencing System. A CM ~nsactions on Information Systems, 13(4):373-407, 
1995. [4] S. Gibbs, C. Breiteneder, and D.Tsichritzis. Data Mod- eling of Time-Based Media. In Proceedings 
of ACM In- ternational ConIerence on Management of Data, pages 91-102, 1994. [5] R. Hjelsvoid and R. 
Midstraum. Modelling and Query- ing Video Data. In Proceedings of International Con/er- ence on Very 
Large Data Bases, pages 686-694, 1994. [6] S. Y. Lee and H. M. Kao. Video Indexing - An Ap- proach based 
on Moving Object and Track. Storage and Retrieval for Image and Video Databases, SPIE, 1908:25-36, 1993. 
 [7] T. D. C. Little and A. Ghafoor. Interval-Based Con- ceptual Models for Time-Dependent Multimedia 
Data. IEEE Transactions on Knowledge and Data Engineer- ing, 5(4):551-563, August 1993. [8] G. 0zsoyo~lu 
and K. Snodgrass. Temporal and Real- Time Databases: A Survey. IEEE Transactions on Knowledge and Data 
Engineering, 7(4):513-532. August 1995. [9} G. A. Schloss and M. J. Wynblatt. Building Tempo- ral Structures 
in a Layered Multimedia Data Model. In Proceedings of ACM International Conference on Mul- timedia, pages 
271-278, 1994. [10] A. Si, H. V. Leong, and P. Wu. 4DIS: A Temporal Framework for Unifying Meta-Data 
and Data Evolution. In Proceedings o] ACM Symposium on Applied Comput- ing, Database Technology Track, 
1998. (to appear). [11] A. Silberschatz, H. F. Korth, and S. Sudarshan. Data-base System Concepts. McGraw-Hill, 
1996. [12] S. Smoliar and H. Zhang. Content-Based Video Indexing and Retrieval. IEEE Multimedia, 1(2):62-72, 
1994. [13] K. Snodgrass and I. Ahn. Temporal Databases. IEEE Computer, 19(9):35-42, 1986. [14] Ft. Srihari. 
Automatic Indexdng and Content-Based Re- trieval of Captioned Images. IEEE Computer, 28(9):49-56, September 
1995. [15] Y. Tonomura. Video Handling Based on Structured In- formation for Hypermedia Systems. In Proceedings 
of the International Con]erence on Multimedia Informa-tion Systems, pages 333-344. 1991. [16] Y. Tonomura, 
A. Akutsu, Y. Taniguchi. and G. Suzuki Structured Video Computing. IEEE Multimedia, 1 (3):34-43, 1994. 
 
			