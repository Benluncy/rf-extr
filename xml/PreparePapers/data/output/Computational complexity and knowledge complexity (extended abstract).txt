
 Computational Complexity and Knowledge Complexity (EXTENDED ABSTRACT) Oded Goldreich Rafail Ostrovskyt 
Erez Petrank$ Abstract We study the computational complexity of languages which have interactive proofs 
of logarithmic knowledge complex­ ity. We show that all such languages can be recognized in B7VN7. Prior 
to this work, for languages with greater­ than-zero knowledge complexity (and specifically, even for 
knowledge complexity 1) only trivial computational com­ plexity bounds (i.e., only recognizability in 
PSPAC&#38; = ZP) were known. Inthe course of our proof, we relate statistical knowledge-complexity with 
perfect knowledge-complexity; specifically, we show that, for the honest verifier, these hi­ erarchies 
coincide, up to a logarithmic additive term (i.e., sKc(k(.)) g Pxc(k($)+ log(.))). Introduction The 
notion of knowledge-complexity was introduced in the seminal paper of Goldwsaser Micali and Rackoff [GMR-85, 
GMR-89]. Knowledge-complexity (KC) is intended to mea­sure the computational advantage gained by interaction. 
Sat­isfact ory formulations of knowledge-complexity, for the case that it is not zero, have recently 
appeared in [GP-91]. A nat­ural suggestion, made by Goldwasser, Micali and Rackoff, is to classify languages 
according to the knowledge-complexity of their interactive-proofs [G MR-89]. We feel that it is worth­while 
to give this suggestion a fair try. The lowest level of the knowledge-complexity hierarchy is the class 
of languages having interactive proofs of knowledge­complexity zero, better known as zero-knowledge. 
Actually, there are three hierarchies extending the three standard def­initions of zero-knowledge; namely 
perfect, statistical and computational. Let us denote the corresponding hierarchies by PKC(.), SKC(.), 
and CKC(.). Assuming the existence Department of Applied Mathematics and Computer Science, Weizmann Institute 
of Science, Rehovot, Israel. E-mail: oded@ wis­ dom.wiezmann.ac. il. Supported by grant no. 92-00226 
from the United States Israel Binational Science Foundation, Jerusalem, Israel. TComputer Science Division, 
University of California at Berkeley, and International Computer Science Institute, Berkeley, CA 94720. 
E-mail: rafailQcs.Berkeley. EDU. Supported by an NSF Postdoctoral Fellowship and ICSI. t Computer Science 
Department, Technion -Israel Institute of Technology, Haifa 32000, Israel. E-mail: erez@cs.technion. 
ac.il. Permission to cop without fee all or part of this material is granted provided ti at the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
of Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
of one-way functions, the third hierarchy collapses, namely CKC(0) = CICc(poly) = ZP [GMW-86, IY-87, 
B+ 88]. Put differently, the zero level of computational knowledge-com­plexity extends to the maximum 
possible. Anyhow, in the rest of this paper we will be only interested in the other two hierarchies. 
Previous works have provided information only concern­ing the zero level of these hierarchies. Fortnow 
has pioneered the attempts to investigate the computational complexity of (perfect/statistical) zero-knowledge 
[F-89], and was followed by Aiello and Haatad [AH-87]. Their results can be sum­marized by the following 
theorem that bounds the computa­tional complexity of languages having zero-knowledge proofs. Theorem 
[F-89, AH-87]: 5XC(0)s AM (1 CO-AJU Hence, languages having statistical zero-knowledge must lie in the 
second level of the polynomial-time hierarchy. Need­less to say that T KC(k(.)) ~ SKC(k(.)), for any 
function k and in particular for k = O. On the other hand, if we allow polynomial amount of knowl­edge 
to be revealed, then every language in Z? can be proven. Theorem [LFKN-90, Sh-90]: ~~c(poly(!)) = 1P 
= ?JSPACt As indicated in [GP-91], the first equality is a property of an adequate definition (of knowledge 
complexity) rat her than a result. In thk paper we study the class of languages that have interactive-proofs 
with logarithmic knowledge-complexity. In particular, we bound the computational complexity of lan­guages 
having interactive proofs of logarithmic knowledge complexity, showing that they can be recognized by 
proba­bilistic polynomial-time machines with access to an NP ora­cle. Main Theorem: S)cc(o(log(.))) c 
t?PPNp We recall that f?TWNP is contained in the third level of the polynomial-time hierarchy (7%). It 
is believed that P% is a proper subset of PSPACE. Thus, assuming 7V-1 c # PSPAC&#38;, our result yields 
the first proof that there ex­ist languages in FSPACE which cannot be proven by an interactive-proof 
that yields O(log n) bits of knowIedge. In STOC 94-5194 Montreal, Quebec, Canada @ 1994 ACM 0-89791 
-683-8/94/0005..$3.50 other words, there exist languages which do have interac­tive proofs but only interactive 
proofs with super-logarithmic knowledge-complexity. Prior to our work, there was no solid indication 
that would contradict the possibility that all languages in PSPAC&#38; have interactive-proofs which 
yield only one bit of knowledge. The only attempt to bound the computa­ tional complexity of languages 
having interactive proofs of low knowledge-complexity was done by Bellare and Petrank. Yet, their work 
refers only to languages having interactive proofs that axe both of few rounds and of low knowledge com­plexity 
[BP-92]. Specifically, they showed that if a language L has a r(n) -round interactive-proof of knowledge-complexity 
O(%) then the language can be recognized in BPPNP. \.., Our proof of the Main Theorem consists of two 
parts. In the first part, we show that the procedure described by Bel-Iare and Petrank [BP-92] suffices 
for recognizing languages having interactive proofs of logarithmic perfect knowledge complexity. To this 
end, we use a more careful analysis than the one used in [BP-92]. In the second part of our proof we 
transform interactive proofs of statistical knowl­edge complexity k(n) into interactive proofs of perfect 
knowl­edge complexity k(n) +Iog n. This transformation refers only to knowledge-complexity with respect 
to the honest verifier, but this suffices since the first part of our proof applies to the knowledge-complexity 
with respect to the honest verifier. Yet, the transformation is interesting for its own sake, and a few 
words are in place. The question of whether statistical zero-knowledge equals perfect zero-knowledge 
is one of the better known open prob­lems in this area. The question haa been open also for the case 
of zero-knowledge with respect to the honest ver­ifier. We show that for every poly-time computable function 
k: N +) N (and in particular for k s O) Skx(k(.)) g PKc(k(.) + log(.)) This result may be considered 
an indication that these two hierarchies may collide. Techniques Used As stated above, the first part 
of our proof consists of pre­senting a more careful analysis of an existing procedure, namely the procedure 
suggested by Bellare and Petrank in [BP-92], Their procedure, in turn, is a culmination of two sequences 
of works discussed bellow. The first sequence originates in Fortnow s definition of a simulator-based 
prover [F-89]. Fortnow [F-89], and conse­quently Aiello and Hastad [AH-87], used the simulator-based 
prover in order to infer, by way of contradiction, bounds on the sizes of specific sets. A more explicit 
usage of the simulator-based prover was introduced by Bellare, Micali and Ostrovsky [BMO-90]; specifically, 
they have suggested to use a PSPACE-implementation of the simulator-based prover, instead of using the 
original prover (of unbounded complex­ity) witnessing the existence of a zero-knowledge interactive proof 
system. (Thus, they obtained a bound on the complex­ity of provers required for zero-knowledge proof 
systems.) Ostrovsky [Ost-91] suggested to use an implementation of the interaction between the verifier 
and the simulation-based lA1a~ if one had been willing to assume that all languages in PSPACE have interactive 
proofs of logarithm$callg many rounds, an amumption that we consider unreasonable, then the result in 
[BP-92] would have yielded a proof that PSPAC&#38;_ is not contained in SKC( 1 ), provided (again) that 
P% $ PSP.AC&#38; prover as a procedure for deciding the language. Further­more, assuming that one-way 
functions dc) not exist, he used universal extrapolation procedures of [ILu-90, ILe-90] to approximate 
the behavior of the simulator-based prover. (Thus, assuming that one-way function do not exists, he presented 
an efficient procedure that decides languages in SKC (0) and inferred that one-way functions are essential 
to the non-triviality of statistical zero-knowledge). Bellare and Petrank distilled the decision procedure 
from the context of one-way functions, showing that the simulator-based prover can be implemented using 
a perfect universal extrapolator (also known as a uniform generation procedure) [BP-92]. The error in 
the implementation is directly related to the deviation of the uniform generation procedure. The second 
sequence of works deals with the two related problems of approximating the size of sets and uniformly 
generating elements in them. These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating 
the size of sets were invented by Sipser [Si-83] and Stock­meyer [St-83], and further improved in [(1S-89, 
AH-87], all using the (hashing paradigm . The same hashing technique, is the basis of the universal extrapolation 
procedures of [ILu-90, ILe-90]. However, the output of these procedures deviates from the objective (i.e., 
uniform distribution on the target set) by a non-negligible amount (i.e., l/poly(T) when running for 
time T). On the other hand, J,wrum et. al. have also pointed out that (perfect) uniform generation can 
be done by a BPPZ~ -procedure [JVV-86]. Bellare and Pe­trank combined the hashing-baaed approximation 
methods with the ideas of [JVV-86] to obtain a BPPNp-procedure for uniform generation with exponentially 
vanishing error prob­ability y [BP-92]. Actually, if the procedure is allowed to halt with no output 
with constant (or exponentially vanishing) probability, then its output distribution is exactly uniform 
on the target set. Motivation for studying KC In addition to the self-evident fundament~l appeal of knowl­edge 
complexity, we wish to point out some practical motiva­tion for considering knowledge-complexity greater 
than zero. In particular, cryptographic protocols that release a small (i.e., logarithmic) amount of 
knowledge maybe of practical value, especially if they are only applied once or if one can obtain sub-addkive 
bounds on the knowledge complexity of their repeated executions. Note that typically, a (single ap­plication 
of a) sub-protocol leaking logarithmically many bits (of knowledge) does not compromise the security 
of the en­tire protocol. The reason being that these (logarithmically many) bits can be guessed with 
non-negligible probability, which in turn means that any attack due to the leaked bit­s can be simulated 
with non-negligible probability without them. But why use low knowledge-complexity protocols when one 
can use zero-knowledge ones (see, [G MW-87])? The rea­son is that the non-zero-knowledge protocols may 
be more efficient and/or may require weaker computational assump­tions (see, for example, [OVY-91]). 
Remarks A remark concerning two definitions. Throughout the pa­per, SKC(IC()) and PKC(k(0)) denote the 
classes of knowledge­complexity with respect to the honest verijie.r. Note that the Main Theorem is only 
strengthen by this, whereas the trans­formation (mentioned above) is indeed weaker. Furthermore, by an 
interactive proof we mean one in which the error proba­bility is negligible (i.e., smaller than any polynomial 
fraction). A few words of justification appear in Section 2. A remark concerning Fortnow s paper [F-89]. 
In course of this research, we found out that the proof that SKC(0) G co-AM as it appears in [F-89] is 
not correct. In pmticular, there is a flaw in the AM-protocol presented in [F-89] for the complement 
language (see AppendIx). However, the paper of Aiello and Hastad provides all the necessary machinery 
for proving Fortnow s result as well [AH-87, H-94]. Needless to say that the basic approach presented 
by Fortnow (i.e., looking at the simulator-baaed prover ) is valid and has inspired all subsequent works 
(e.g., [AH-87, BMO-90, Ost-91, BP-92, OW-93]) as well as the current one. 2 Preliminaries Let us state 
some of the definitions and conventions we use in the paper. Throughout this paper we use n to denote 
the length of x. 2.1 Interactive proofs Let us recall the concept of interactive proofs, presented by 
[GMR-89]. For formal definitions and motivating discussions the reader is referred to [GMR-89]. A protocol 
between a (computationally unbounded) prover P and a (probabilistic polynomial-time) verifier V constitutes 
an interactive proof for a language L if there exists a negligible function ~ : N -+ [0, 1] (i.e., for 
every polynomial p and all sufficiently large n s c(n) < ~) such that 1. Completeness: If z E L then 
Pr [(P, V) (z) accepts] > 1-e(n)  2. Soundness: If x @ L then for any prover P* Pr [(P*, V)(z) accepts] 
< e(n)   Remark: Usually, the definition of interactive proofs is ro­bust to setting the error probability 
to be bounded away from ~, since the error probability can be reduced by rep­etitions. However, this 
standard procedure is not applica­ble when knowledge-complexity is measured, since (even se­quential) 
repetitions may increase the knowledge-complexity. The question is, thus, what is the right definition. 
The def­inition used above is quite standard and natural; it is cer­tainly less arbitrary then setting 
the error to be some favorite constant (e.g., ~) or function (e.g., 2- ). Yet, our tech­niques yield 
non-trivial results also in case one defines inter­active proofs with non-negligible error probability 
(e.g., con­stant error probability). Details are omitted. Also note that we have allowed two-sided error 
probability; this strength­ens our main result but weakens the statistical to perfect transformation2. 
 2.2 Knowledge Complexity Throughout the rest of the paper, we refer to knowledge­complexity with respect 
to the honest verifie~ namely, the 2suppose you had ~ transformation for the one-sided case. Then> given 
a two-sided interactive proof of some statistical knowledge com­plexity you could have transformed it 
to a one-sided error proof of the same knowledge complexity (cf., [GMS-S7] ). Applying the trans­formation 
for the one-sided case would have yielded an even better result. ability to simulate the (honest) verifier 
s view of its interac­tion with the prover. (In the stronger definition, one consid­ers the ability to 
simulate the point of view of any eficient verifier while interacting with the prover.) We let (P, V) 
(x) denote the random variable that repre­sents V s view of the interaction with P on common input x. 
The view contains the verifier s random tape aa well as the sequence of messages exchanged between the 
parties. We begin by briefly recalling the definitions of perfect and statistical zero-knowledge. A protocol 
(P, V) is perfect zero-knowledge (resp., statistical zero-knowledge) if t here is a probabilistic polynomial 
time simulator M such that the random variable M(z) is distributed identically to (P, V)(z) (resp., the 
statistical difference between M(z) and (P, V)(Z) is a negligible function in [z 1). Next, we present 
the definitions of perfect (resp., statisti­cal) knowledge-complexity which we use in the sequel. These 
definitions extend the definition of perfect (resp., statistical) zero-knowledge, in the sense that knowledge-complexity 
zero is exactly zero-knowledge. Actually, there are two alternative formulations of knowledge-complexity, 
called the oracle ver­sion and the fraction version. These formulations coincide at the zero level and 
differ by at most an additive constant otherwise [GP-91]. For further intuition and motivation see [GP-91]. 
It will be convenient to use both definitions in this paper3. By the oracle formulation, the knowledge-complexity 
of a protocol (P, V) is the number of oracle (bit) queries that are needed to simulate the protocol efficiently. 
Definition 2.1 (knowledge complexity oracle version): Let k: N ~ N. We say that an interactive proof 
(P, V) for a language L has perfect (resp., statistical) knowledge com­plexity k(n) in the oracle sense 
if there exists a probabilistic polynomial time oracle machine M and an oracle A such that: 1. on input 
x ~ L, machine M queries the oracle A for at most k(lzl) bits. 2. For each x ~ L, machine MA produces 
an output with  probability at least ~, and given that MA halts with an output, MA(z) is identically 
distributed (resp., statis­tically close) to (P, V) (z). In the fraction formulation, the simulator 
is not given any explicit help. Instead, one measures the density of the largest subspace of simulator 
s executions (i.e., coins) which is identical (resp., close) to the (P, V) distribution. Definition 2.2 
(knowledge complexity fraction version): Let p: N + R. We say that an interactive proof (P, V) for a 
language L has perfect (resp., statistical) knowledge­complexity log2(l/p(rz)) in the fraction sense 
if there ezists a probabilistic polynomial-time machine M with the following good subspace property. 
For any x E L there is a subset of M s possible mndom tapes Sz, such that: 1. The set S, contains at 
least a p(lxl) fraction of the set of all possible coin tosses of M(x). 2. Conditioned on the event 
that M(x) s coins fall in S., the random variable MA(z) is identically dk.tributed  (resp., statistically 
close) to (P, V)(z). Namely, for the perfect case this means that for every E Prob(M(z, w) =EI w c S 
z) = Prob((P, V)(z) =z) sThe analY~i~ of the [BP-92] procedure is ea6ier when using the fraction version, 
whereas the transformation from statistical to perfect is easier when using the oracle version. where 
M(z, w) denotes the output of the simulator M on input x and coin tosses sequence w. The fraction measure 
and the oracle measure are equal up to an additive constant [G P-91]. Since none of our results is sensitive 
to a difference of an additive constant in the mea­sure, we ignore this difference in the subsequent 
definition as well as in the statement of our results. Definition 2.3 (knowledge complexity classes): 
Q PKC (k(.)) = languages having interactive proofs of per­fect knowledge complexity k(.). SKX (k(.)) 
= languages having interactive proofs of sta­tistical knowledge complexity k(.).  2.3 The simulation 
based prover An important ingredient in our proof is the notion of a simu­lation based prover, introduced 
by Fortnow [F-89]. Consider a simulator M that outputs conversations of an interaction between a prover 
P and a verifier V. We define a new prover P*, called the simulation based prover, which selects its 
mes­sages according to the conditional probabilities induced by the simulation. Namely, on a partial 
history h of a conver­sation, P* outputs a message a with probability Prob(P*(h)=a) ~f Prob(Ml~l+, =hoa 
I Mlhl =h) where Mt denotes the distribution induced by J-4 on t-long prefixes of conversations. (Here, 
the length of a prefix means the number of messages in it.) 3 The Perfect Case In this section we prove 
that the Main Theorem holds for the special caae of perfect knowledge complexity. Combin­ing this result 
with the transformation (Theorem 2) of the subsequent section, we get the Main Theorem. Theorem 1 PKC(O(log 
n)) C 13PPNP Our proof follows the procedure suggested in [BP-92], which in turn follows the approach 
of [F-89, BMO-90, Ost-91] while introducing a new uniform generation procedure which builds on ideas 
of [Si-83, St-83, GS-89, JVV-86] (see intro­duction). Suppose that (P, V) is an interactive proof of 
perfect knowledge complexity k(.) for the languages L, and let M be the simulator guaranteed by the fraction 
formulation (i.e., Definition 2.2). We consider the conversations of the original verifier V with the 
simulation-baaed-prover P* (see defini­ tion in 32.3). We are going to show that the probability that 
the interaction (P , V) is accepting is negligible if z @ L and greater then a polynomial fraction if 
x ~ L. Our proof differs from [BP-92] in the analysis of the case z c L (and thus we get a stronger result 
although we use the same procedure). This separation between the cases x $Z L and x c L can be amplified 
by sequential repetitions of the protocol (P*, V). So it remains to observe that we can sample the (P*, 
V) in­ teractions in probabilistic polynomial-time having access to an NP oracle. This observation originates 
from [BP-92] and is justified as follows. Clearly, V s part of the interaction can be produced in polynomial-time. 
Also, by the uniform generation procedure of [BP-92] we can implement P* by a probabilistic polynomial 
time machine that haa access to an NP oracle. Actually, the implementation may fail with negli­ gible 
probability, but this does not matter. Thus, it remains only to prove the following lemma. Lemma 3.1 
1. If x ~ L accepting then the probability that conversation is at least ~ (P , . 2-k. V) outputs an 
2. If x $Z L accepting then the probability that conversation is negligible. (P*, V) outputs an Remark: 
In [BP-92], a weaker lemma is proven. Specifi­cally, they show that the probability that (P*, V) output 
an accepting conversation (on z 6 L) is related to 2 k t, where t is the number of rounds in the protocol,, 
Note that in our proof tcould be an arbitrary polynomial number of rounds. proofi The second part of 
the lemma follows from the sound­ness property as before. We thus concentrate on the first part. We fix 
an arbitrary z c L for the rest of the proof and allow ourselves not to mention it in the sec~uel discussion 
and notation. Let k = k( Iz[ ) and q be the number of coin tosses made by M. We denote by Q ~f {O, 1}9 
the set of all pos­ sible coin tosses, and by S the good subspace of M (i.e., S has density 2-k in Q 
and for w chosen uniformly in S the simulator outputs exactly the distribution of the interaction (P, 
v)). Consider the conversations that are output by the simu­lator on w 6 S. The probability to get such 
a conversation when the simulator is run on w uniformly [selected in !2, is at least 2-k. We claim that 
the probability to get these conver­sations in the interaction (P*, V) is also at least 2-k. This is 
not obvious, since the distribution produced by (P*, V) may not be identical to the distribution produced 
by M on a uni­formly selected w E Q. Nor is it necessarily identical to the distribution produced by 
M on a uniformly selected w c S. However, the prover s moves in (P*, V) are distributed as in the case 
that the simulator selects w uniformly in !2, whereas the verifier s moves (in (P*, V)) are distributed 
as in the case that the simulator selects w uniformly in S. Thus, it should not be too surprising that 
the above claim can be proven. However, we need more than the above claim: It is not enough that the 
(P*, V) conversations have an origin in S, they must be accepting as well. (Note that this is not ob­vious 
since M simulates an interactive proof that may have two-sided error.) Again, the density of the accepting 
conver­sations in the good subspace of A4 is high (i.e., ~ 1 e), yet we need to show that this is the 
case also for the (P*, V) interaction. Actually, we will show that the probability than an (P*, V) conversation 
is accepting and has an origin in S is at least * 2-k. Let us begin the formal argument with some notations. 
For each possible history of the interaction, h, we define sub­sets of the random tapes of the simulator 
(i.e., subsets of Q) as follows. oh is the set of w c Q which cause the simulator to output a conversation 
with prefix h. 8h is the subset of w s in ~h which are also in S. Ah is the set of w s in sh which are 
also accepting. Let C be a random variable representing the (P*, V) inter­action, and x be an indicator 
so that X(C) = 1 if the conver­sat ion ~ is accepting and x(c) = O otherwise. Our aim is to prove that 
Prob(X(C7)) > ~ . 2-k. Note that The above expression is exactly the expectation value of ~. Thus, we 
need to show that: (1)  where the expectation is over the possible conversations c as produced by the 
interaction (P*, V). Once Equation (1) is proven, we are done. To prove Equation (1) it suffices to prove 
that (2) (since ~ > G and ~ ~ 2-k). The proof is by a reverse induction. We consider two cases: 1. the 
current step is by the prover (i.e., P*); and 2. the current step is by the verifier (i.e., V).  In 
both cases we show, for any history h and any possible next message m, [Ahmnl lA~oml > kf!d . k!d (3) 
  . Exp~ lQhom] Ishoml 1%1 1%1 () where the expectation is over the possible current moves m, given 
history h, as produced by the interaction (P*, V). Technical Claim The following technical claim is used 
for deriving the inequal­ ities in both cases. The claim is that the minimum of x; E ;Z subject to the 
constraints ~i ~~ = Y and ~, z~ = X (with all xi s and w s non-negative) is obtained at ~ = ~ and is 
thus equal $. Prover Step denoted a Given history h, the prover P* sends a as its next message with 
probability W. Thus, l-ha!  = E I:hl Ishoal >lA~l l;hl . -l~hl lS~l The inequality is justified by 
using the Technical Claim and noting that ~a lAko~ I = lA~l and ~a lsho~ I = lS~ 1. Verifier Step -denoted 
,fl By the perfectness of the simulation, when restricted to the good subspace S, we know that given 
history h, the verifier V sends/3 as its next message with probability W. Thus, The inequality is justified 
by using the Technical Claim and noting that ~P lA~~~l = lAhl and ~p 1%.p I = Ifhl. Having proven Equation 
(3) for both cases, Equation (2) fol­lows and so does the lemma. 0 4 The Transformation In this section 
we show how to transform statistical knowl­edge complexity into perfect knowledge complexity, incurring 
only a logarithmic additive term. This transformation com­bined with Theorem 1 yields the Main Theorem. 
Theorem 2 For every (poly-time computable) k : N + N, SKC (k(.)) ~ PKC (k(.) + O(log(.))) We stress 
again that these knowledge complexity classes refer to the honest verifier and that we don t know whether 
such a result holds for the analogous knowledge complexity classes referring to arbitrary (poly-time) 
verifiers. proofi Here we use the oracle formulation of knowledge com­plexity (see Definition 2.1). We 
start with an overview of the proof. Suppose we are given a simulator M which produces output that is 
statistically close to the real prover-verifier interaction. We change both the interactive proof and 
its simulation so that they produce exactly the same distribu­tion space. We will take advantage of the 
fact that the prover in the interactive proof and the oracle that assists the sim­ulator are both infinitely 
powerful. Thus, the modification to the prover s program and the augmentation to the ora­cle need not 
be efficiently computable. We stress that the modhication to the simulator itself will be efficiently 
com­putable. Also, we maintain the original verifier (of the in­teractive proof ), and thus the resulting 
interactive proof is still sound. Furthermore, the resulting interaction will be statistically close 
to the original one (on any z G L) and therefore the completeness property of the original interac­tive 
proof is maintained (although the error probability here may increase by a negligible amount). Preliminaries 
Let L c SKC(k(.)), and (P, V) be the guaranteed interactive proof. Without loss of generality, we may 
assume that all messages are of length 1. The message-length convention is merely a matter of encoding. 
Recall that Definition 2.1 only guarantees that the simu­lator produces output with probability > ~. 
Yet, employing Proposition 3.8 in [GP-91], we get that there exists an ora­cle machine M, that after 
asking k(n) + 2 log log n queries, alwags produces an output so that the out~ut is statisti­cally-cl~se 
to the intera~tion of (P, V). Le~ A denote the associated oracle, and let i vf ~f MA and P and V be 
the . 538 simulation-baaed prover and verifier4 induced by M (i.e., (P , v ) = M ). notations: Let [A, 
B]i be a random variable representing the i-message (i-bit) long prefix of the interaction between A 
and B (the common input is implicit in the notation). We denote by A(h) the random variable representing 
the message sent by A after interaction-history h. Thus, if the ith message is sent by A, we can write 
A([A, B]t..-l) = [A, B];. By X ~ Y we denote the fact that the random variables X and Y are statistically 
close. Claim 4.1 The distribution induced by (P , V) is statisti­ cally close to the distributions induced 
by both M = (P , V ) and (P, V). proof By definition, the distributions produced by M = (P , V ) and 
(P, V) are statistically close. Thus, we have [P, V], ~ [P , V ]j, for every i (4) We prove that [P 
, V] is statistically close to [P , V ] by in­ duction on the length of the interaction. Assuming that 
[P , V]i A [P , V ]~, we wish to prove it for i +1. We distin­guish two cases. In case the i + I t move 
is by the prover, we get [P , V]i+l = [P , v], o P ([P , v]i) A [P , v ], o P ([P , v ],) = [P , v ],+, 
 (use the induction hypothesis for ~). In case the i+ 1 move is by the verifier, we get [P , v],+, = 
[P , v], o V([P , V]i) s = [P , v ], o V([P , v ],) s [P, v], o V([P, V]i) . [P, v],+, s = [P , v ]i+l 
 where the first A is justified by the induction hypothesis and the two others by Eq. (4). We stress 
that since the induction hypothesis is used only once in the induction step, the statistical distance 
is linear in the number of induction steps (rather than exponential). 0 Motivating discussion: Note that 
the statistical difference between the interaction (P , V) and the simulation AI = (P , V ) is due solely 
to the difference between the proper verifier (i.e., V) and the verifier induced by the simulator (i.e., 
V ). This difference may be due to V putting too much probability weight on certain moves or putting 
too lit­tle weight. The first caae is relatively easy to deal with since one can always decrease the 
probability that the simulator outputs certain conversations (by properly augmenting the oracle). The 
second case is more problematic and it is re­quired to modify the prover P so that it gives up its attempt 
to convince the verifier in these cases (the simulator will be modified as well). Details follow. Technical 
remark: The oracle can be used to allow the simu­ lator to toss bias coins when the simulator does not 
know 4A ~imulator.ba~ed verifier is defined analOgOudY tO the simulatOr­based prover. It is a fictitious 
entity which does not necessarily coin­cide with V. the bias. Suppose that the simulator needs tc~ toss 
a coin so that it comes-up head with probability ~, where N < 2m and both N and m are integers, The simulator 
supplies the oracle with a uniformly chosen r c {O, 1}m imd the oracle answers head if r is among the 
first IV strings in {O, 1}~ and tail otherwise. A similar procedure is applicable for implementing a 
lottery with more than two a-priori known values. Using this procedure, we can get extremely good ap­proximations 
of probability spaces at a cost related to the a-priori known size of the support (i.e., the oracle answer 
is logarithmic in the size of the support). Definition: Let c ~f ~ where tis the number of rounds in 
the interaction (P, V). Let h be a partial history of the interaction and /3 be a possible next move 
by the verifier. We say that /3 is weak with respect to h if Prob(V (h) =/3) < (1 c) ! Prob(V(h) =~) 
  A conversation z = (cl, .... c~) is i-weak if ci is weak with respect to (cl, .... c~.-l ), otherwise 
it is i-good. (Note that a conversation can be i-weak only if the ith move is a verifier move.)  A 
conversation c = (cl, .... et) is i-cratical if it is i­weak but j-good for every j < i. A conversation 
~ = (cl, .... c,) is i-co-critical if the conversation obtained from Z, by complementing (only) the 
ith bit, is i-critical. (Note that a conversation can be i-critical only for a sin­gle i, yet it may 
be i-co-critical for many i s.)  A conversation is weak if it it i-weak for some i, other­wise it is 
good.  Claim 4.2 (P , V) outputs weak conversations with negligi­ ble probability. proof Recall that 
[P , V] ~ [P , V ] and that the same holds also for prefixes of the conversations. Namehy, for any 1 
s is t,[P , V], ~ [P , V ],. Let us define a prefix h c {O, l}i of a conversation to be bad if either 
Prob([P , V ]i=h) < (1 ~) . Prob([P , V]~=h) or Prob([P , V ]4=h) > (1+ ~) . Prob([P , V]~=h) The 
claim follows by combining two facts. The first fact is that the probability that (P , V) outputs a conversation 
with a bad prefix is negligible, and the second fact is that weak conversations contain a bad prefix. 
0 Claim 4.3 Suppose that E = (cl, .... et) is a good conver­sation. Then, the probability that z is output 
by M is at least (1 c)rt/21V] =E). Furthermore, for 1< k, .Prob([P , ijfi = (cl, ..., et) is i-good for 
every i E {1 + 1, .... k}, then Prob ([M ]k = ~ I [M ]J = h) is bounded below by (1 -c)[~l .Prob ([P 
, V]~=~[[P , V]l=h) where ~d~f (cl, .... c~) and hd~f(cl, ....ct) proof To see that this is the case, 
we write the probabilities step by step conditioned on the history so far. We note that the prover s 
steps happen with equal probabilities in both sides of the inequality, and therefore can be reduced. 
Since the relevant verifier s steps are not weabk, we get the mentioned inequality. 0 Dealing with weak 
conversations We stzrt by modifying the prover P , resulting in a modified prover, denoted P , that stops 
once it gets a verifier message which is weak with respect to the current history; otherwise, P behaves 
as P . Next, we modify the simulator so that it outputs either good conversations or truncated conversa­ 
tions which are originally &#38;critical. The modified simulator, denoted M , proceeds as follows5. First, 
it invokes M and obtains a conversation c = (cl, ..., et). Next, it queries the augmented oracle on Z. 
The oracle answers probabilistically and its answers are of the form (i, a), where i G {1, .... t} and 
a c {O, 1}. The probability distribution will be specified below, at this point we only wish to remark 
that the oracle only returns pairs (i, a) for which one of the following three three conditions holds 
1. Eis good, i = tand u = O (if the conversation generated by M is good and furthermore is not i-co-critical 
for any i s then the oracle always answers this way); 2. Z is i-critical and a = I); 3. E is i-co-critical 
and a = 1.  Finally, the simulator halts outputting (cl, .... ci-1, C; @ a). Note that i maybe smaller 
than t, in which case M outputs a truncated (i-critical) conversation; otherwise, Al outputs a non-truncated 
conversation. It remains to specify the ora­cle s answer dktribution. Let us start by considering two 
special cases. In the first case, the conversation generated by M is i-critical, for some i, but is not 
~-co-critical for any j < i. In this case the oracle always answers (i, O) and consequently the sim­ulator 
always outputs the i-bit long prefix. However, this prefix is still being output with too low probability. 
This will be corrected by the second case hereby described. In this ( second ) case, the conversation 
z generated by M is good and i-co-critical for a single i. This means that the i-bit long prefix is given 
too much probability weight whereas the prefix obtained by complimenting the ith bit gets too little 
weight. To correct this, the oracle outputs (i, 1) with probability q and (t, O) otherwise, where q will 
be specified. What happens is that the M will output the i-complimented prefix with higher probability 
than with which it haa appeared in M . The value of q is determined as follows. Denote p Af Prob(V(cl, 
.... c;-1) = c; @ 1) and p ~f Prob(V (cl , ....c~-1) =c~ @ 1). Then, setting q so that p = p + (1 -p 
) . q (i.e., q = ~) allows the simulator to output the prefix (cl, .... ci -1, ci @1) with the right 
probabil­ityy. In the general case, the conversation generated by M may be i-co-critical for many i s 
as well as j-critical for some (single) j. In case it is j-critical, it can be i-co-critical only for 
i < j. Let us consider the sequence of indices, (il, .... il ), for which the generated conversation 
is critical or co-critical (i.e., the conversation is ik-co-critical for all k < 1 and is either $1-critical 
or i~-co-critical). We consider two cases. In both cases the @ s are defined as in the above example; 
namely, Qk = ++, where Pk ~f Prob(V(cl, .... ci~-l) =c~b EB1) and pi Af Prob(V (cl ,...,Cil)=C~~~~ @ 
1). 1. The generated conversation, 3 = (cl, .... ct ), is ik-co­critical for every k < t and is it-critical. 
In this case, the dktribution of the oracle answers is as follows. For 5we stre~~ that PII is not necessarily 
the simulator-based PrOver Of ~tl . every k <1, the pair (ik, 1) is returned with probability (~j<k (1 
 %)) %; where= the pair (it, 0) appe~s with probability ~j<l (1 qj ). We stress that no other pair appeaxs 
in this distribution. 2. The generated conversation, ~ = (CI, ..., c~), is ik-co­critical for every 
k ~ 1. In this case, the dktribut ion of the oracle answers is as follows. For every k s 1, the pair 
(ik, 1) is returned with probability (~j<~ (1 qj )) . qk; whereas the pair (t, O) appears with probabil­ity 
~J <1 (1 q~). Again, no other pair appears in this distrib~tion. Claim 4.4 1. [P , v] A [P , v]; 2. 
Each conversation of (P , V), be it a complete (P , V)­corwersation or a truncated (i. e., critical) 
one, is output by M with probability that is at least a (1 c)* > ~  fraction of the probability that 
it appears in [P , V]. proof The weak conversations are negligible in the output distribution of (P , 
V) (see Claim 4.2). The only difference between [P , V] and [P , V] originates from a different be­havior 
of P on weak conversations, specifically P truncates them while PI does not. Yet, the distribution on 
the good conversations remains unchanged. Therefore the distribution of [P , V] is statistically close 
to the distribution of [P , V], and we are done with part (1). For part (2) we write again the probability 
that (P , V) out­puts c as the product of the conditional probabilities of the tsteps. Namely, fiProb 
([p ) t ]i+~=hi oci+~ I [P , V]t=ht) isl where hi ~f (cl, .... ci). We do the same for the probability 
that M outputs a conversation E. We will show by induction that each step of any conversation is produced 
by M with at least (1 e) the probability of the same step in the (P , V)­interaction. Once we have shown 
this, we are done. Clearly this claim holds for the null prefix. To prove the induction step, we consider 
the two possibilities for the party making the i + Ist step. i+ let step is by the prover: Consider the 
conditional behavior of M given the history so far. We show that this behavior is identical to the behavior 
of P on the same partial history. A delicate point to note here is that we may talk about the behavior 
of M on a prefix hi only if this prefix appears with positive probability in the output distribution 
[M ];. However, by the induction hypothesis any prefix that is out­put by [P , V], appears with positive 
probability in [M ]i. The simulator M is defined by two modifications of M . The first modification truncates 
i-th critical conversations after the Lth step, and the second modification compensates for the low weight 
given by the simulator to weak steps of the verifier. We note that the second modification concerns only 
the conditional behavior of the simulator on verifier steps and is thus irrelevant to the current case, 
On the other hand, the first modification exactly matches the modification applied on P to get P . Specifically, 
P is identical to P (which is the M -based prover) except that it terminates immedi­ately upon receiving 
a weak message of V with respect to the his~ory so far. - To summarize, the conditional behavior of IM 
in the prover steps and the conditional behavior of P are both based on the M -baaed prover P , and are 
both modified in exactly the same manner. Thus, their conditional behavior is exactly the same for any 
possible history. i + Ist step is by the verifier: Again, we consider the condi­tional behavior of M 
given the history so far. Let us recall the second modification applied on M to derive M , This modification 
changes the conditional probability of the veri­fier steps in the distribution of M in order to add weight 
to steps having low probability in the simulation. We note that this modification is made only in critical 
or co-critical steps of the verifier. Consider a history hi which might appear in the interaction (P 
, V) and a possible response ~ of V to hi. Again, by the induction hypothesis, hi has a positive prob­ability 
to be output by the simulation M and therefore we may consider the behavior of M on this history hi. 
There are three cases to be considered, corresponding to whether either @ or /3 01 or none is weak with 
respect to hi. We start with the simplest case in which neither @ nor @ @ 1 is weak (w.r.t. h,). This 
case is dealt with exactly as the case that the i + l t step is by the prover. Specifically, none of 
the modifications applied to M is relevant here and the claim follows by the hypothesis that neither 
@ nor ~ @ 1 is weak. We now turn to the case in which @ is weak (w.r.t. hi). A weak message appears in 
the output of (P , V) only if it is critical. Recall that given that M has produced the prefix hi, it 
produces hi o~ whenever M produces the prefix h, o~, and furthermore, with conditional probability qi+l 
(as defined above), M produces the prefix hi o ~ also in case M produces the prefix hi o (~ @ 1). The 
validity of the claim for this case follows from calculations. We omit them in this version. Finally, 
we turn to the case in which @@ 1 is weak (w,r.t, hi). Again, this means that ,6 is co-critical in E. 
Given that M has produced the prefix hi, it produces h, o ~ only when M produces the prefix hi o /3, 
and furthermore, M does so only with probability 1 qi+l. Again, the claim follows from calculations 
which we omit here. This completes the proof of Claim 4.4. 0 Lowering the probability of some simulator 
outputs The purpose of the last modification is to lower the proba­bility that the simulator outputs 
a conversation, in case it outputs this conversation more frequently than it appears in (P , V). The 
modified simulator, denoted M , runs M to obtain a conversation C. (Note that M always produces output.) 
Using the further-augmented oracle, M outputs 2 with probability def 3. Prob([P , V]=E) < ~ c = ~ Prob([M 
] =5) where the inequality holds due to part 2 of Claim 4,4. Claim 4.5 1. M produces output with probability 
~; 2. The output distribution of M (i. e., in case it has out­put) is identical to the distribution 
[P , V].  proof The probability that M produces an output is ex­actlv: As for part (2), we note that 
the probability y that a conver­sation .5 is output by M is exactly ~ . Prob ([P , V] = 2), Since the 
simulator halts with an output with probability exactly ~, we get that given that M halts with an output, 
it outputs z with probability exactly Prob ([P , V]= z)) and we are done. 0 An important point not explicitly 
addresseal so far is whether all the modifications applied to the simulator preserve its ability to be 
implemented by a probabilistic polynomial-time with bounded access to an oracle. Clearly, this is the 
case with respect to M (at the expense of additional 1 + logz t= O(log n) oracle queries). Yet, regarding 
the last modifica­tion there is a subtle points which needs to be addressed. Specifically, we need to 
verify that the definition of M is implementable; namely, that M can (witlh help of an aug­mented oracle) 
sieve conversations with ezactiy the desired probability. Note that the method presented above (in the 
technical remark ) may yield exponentially small deviation from the desired probability. This will get 
very close to a perfect simulation, but yet it will not achieve it. To this end, we modify the sieving 
process suggested in the technical remark to deal with the specific case we have here. But first we modify 
P so that it makes its random choices (in case it has any) by flipping a polynomial number of unbiased 
coins. This rounding does change a bit the be­havior of P , but the deviation can be made so small that 
the above assertions (specifically Claim 4.4) still hold. Consider the specific sieving probability we 
need here. Namely: pa = ~ . ~, where ~ = Prob([P , V] = Z) and ~ = Prob([M ] = Z). A key observation 
is that c is the number of coin tosses which lead M to output i: (i.e., using the notation of the previous 
section, c = [Qc 1). Observing that b is the size of probability space for [P , V] and using the above 
modification to P , we rewrite PZ as ~ ,~_, &#38;, where e and j = poly(n) are some non-negative integers. 
We now note, that the oracle can allc}w the simulator to sieve conversations with probability ~ I(f = 
O), for any O s e S c in the following way. M sends to the oracle the random tape o that it has tossed 
for M , and the oracle sieves only e out of the possible c random tapes which lead M to output E. The 
general case of pe := -&#38; is deal by writing p~ = ~ + ~, where q = le/2~J and r = e q2f < 2f, To implement 
this sieve, M supplies the oracle with a uniformly chosen f-bit long string (in addition to w). The 
oracle sieves out q random-tapes (of M ) as before, and uses the extra bits in order to decide on the 
sieve in case u equals a specific (different) random-tape. Combining Claims 4.1, 4.4 (part 1), and 4.5, 
we conclude that (P , V) is an interactive proof system of perfect knowl­edge complexity k(n) + O(log 
n) for L. This completes the proof of Theorem 2. 5 Concluding Remarks We consider our main result as 
a very first step towards a classification of languages according to the knowledge com­plexity of their 
interactive proof systems. Indeed there is much to be known. Below we first mention two questions which 
do not seem too ambitious. The first is to try to pro­vide evidence that NP-complete languages cannot 
be proven within low (say logarithmic or even constant) knowledge complexity. A possible avenue for proving 
this conjecture is to show that languages having logarithmic knowledge com­plexity are in CO-AM, rather 
than in BPPN P (see [BHZ-87]). The second suggestion is to try to provide indications that there are 
languages in PSPACE which do not have inter­active proofs of linear (rather than logarithmic) knowledge 
complexity. The reader can easily envision more moderate and more ambitious challenges in this direction. 
Another interesting question is whether all levels greater then zero of the knowledge-complexity hierarchy 
contain lan­guages that previous levels do not contain, or if some collapse occurs. For example, it is 
open whether constant or even log­arithmic knowledge complexity classes do not collapse to the zero level. 
Regarding our transformation of statistical knowledge com­plexity into perfect knowledge complexity (i.e., 
Theorem 2), a few interesting questions arise. Firstly, can the cost of the transformation be reduced 
to bellow O(log n) bits of knowledge? A result for the special case of statistical zero­knowledge will 
be almost as interesting. Secondly, can one present an analogous transformation that preserves one-sided 
err-or probability of the interactive proof? (Note that our transformation introduces a negligible error 
probability into the completeness condition.) Finally, can one present an analogous transformation that 
applies to knowledge com­plexity with respect to arbitrary verijiers? (Our transforma­tion applies only 
to knowledge complexity with respect to the honest verifier.) References [AH-87] W. Aiello and J. H&#38;stad. 
Perfect Zero-Knowledge can be Recognized in Two Rounds. Proceedings of the ,% 8th An­nual IEEE Symposium 
on the Foundations of ComputeT Science, IEEE (1987). [BMO-90] M. Bellare, S. Micali and R. Ostrovsky. 
The (True) Com­plexity of Statistical Zero-Knowledge. Proceedings of the 22nd Annual ACM SWZposiwn on 
the Theo~ of Com­puting, ACM (1990). [BP-92] M. Bellare and E. Petrank. Making Zero-Knowledge Provers 
Efficient. Proceedings of the 2Jrd Annual ACM Sgmposium on the Theo?_y of Computing, ACM (1992) [B+ 8S] 
M. Ben-Or, S. Goldwasser, O. Goldreich, J. Hi%tad, J. Kilian, S. Micali and P. Rogaway. Everything Provable 
is Provable in Zero-Knowledge. Advances in C~ptologg Proceedings of CRYPTO 88, Lecture Notes in Computer 
Science 403, Springer-Verlag (1989). S. Goldwasser, ed. [BHZ-87] R. Boppana, J. Hfwtad and S. Zachos. 
Does CO-NP Have Short Interactive Proofs . Information Processing Let­ters, Vol 25 (1987), No. 2, pp 
127-132. [F-89] L. Fortnow. The Complexity of Perfect Zero-Knowledge. Advances m Computing Research (cd. 
S. Micali) Vol. 18 (1989). [GMS-87] O. Goldreich, Y. Mapsour and M. Sipser. Interactive Proof Systems: 
P rovefs that never Fail and Random Se­lection. Proceedings of the 28th Annual IEEE Sgmpo­sium on the 
Foundations of Computer Science, IEEE (1987). [GMW-86] 0. Goldreich, S. MicaIi, and A. Wigderson, Proofs 
that Yield Nothing But their Validity and a Methodology of Cryptographic Protocol Design , Proc. 27th 
FOGS 86, See also Jour. of ACM. Vol 38, No 1, July 1991, pp. 691­ 729. [GMW-87] 0. Goldreich, S. MicaIi, 
and A. Wlgderson, How to Play any Mental Game or a Completeness Theorems for Pro­tocols of Honest Majority 
, STOCS7. [GP-91] O. Goldreich and E. Petrank. Quantifying Knowledge Complexity. Proceedings of the 32nd 
Annual IEEE S~m­posium on the Foundations of Computer Science, IEEE (1991). [GMR-S5] S. Goldwasser, S. 
MicaIi, and C. Rackoff. The Knowledge Complexity of Interactive Proofs. Proceedings of the 17th Annual 
ACM Sgmposium on the Theor~ of Computing, ACM (1985). [GMR-89] S. Goldwasser, S. Micali, and C. Rackoff. 
The Knowledge Complexity of Interactive Proofs. SIAM J. Comput. 18 (l), 1S6-20S (February 19S9). [GS-89] 
S. Goldwasser, and M. Sipser, Private Coins vs. Public Coins in Interactive Proof Systems, Advances in 
Com­putmg ReseaTch (cd. S. Micali), 1989, Vol. 5, pp. 73-90. [H-94] J. Htistad. Perfect Zero-Knowledge 
in AM n co-AM. Un­published 2-page manuscript explaining the underlying ideas behind [AH-87]. 1994. [ILU-90] 
R. Impagliazzo and M. Luby, One-Way Functions are Es­sential for Complexity Based Cryptography, 30th 
FOCS, pp. 230 235, 1990. [ILe-90] R. Impagliazzo and L.A. Levin, No Better Ways to Gen­erate Hard NP 
Instances than Picking Uniformly at Ran­dom, $lst FOCS, pp. 812-S21, 1990. [IY-S7] R. Impagliazzo and 
M. Yung. Direct Minimum-Knowledge computations. A duances in @pto~og# %oceedings of CRYP TO 87, Lecture 
Notes in Computer Science 293, Springer-Verlag (1987). [JVV-86] M. Jerrum, L. Valiant and V. Vazirani. 
Random Gener­ation of Combinatorial Structures from a Uniform Dis­tribution. Theoretical ComputeT Sctence 
43, 169-188 (1986). [LFKN-90] C. Lund, L. Fortnow, H. Karloff and N. Nisan. Algebraic Methods for Interactive 
Proof Systems. Proceedings of the 31st Annual IEEE S~mposzum on the Foundations of Computer Science, 
IEEE (1990). [ost-91] R. Ostrovsky. One-Way Functions, Hard on Average Problems, and Statistical Zero-Knowledge 
Proofs. Pro­ceedings of Structures In Complexity Theorg 6th Annual Conference IEEE (1991). [OW-93] R. 
Ostrovsky and A. Wigderson. One-Way Functions are Essential For Non- IMvial Zero-Knowledge, Proc. 2na! 
Is­raelz Sgmp. on Theory of Computing and Systems, 1993, [OVY-91] R. Ostrovsky, R. Venkatesan and M. 
Yung. Fair Games Against an All-Powerful Adversary. AMS DIMA CS Se­rzes m Dtscrete Mathematics and Theoretical 
Computer Science. Vol 13. (Jin-Yi Cai cd.) pp. 155-169. [Sh-90] A. Shamir. IP=PSPACE. Pvoc. 22nd ACM 
Sgmp. on Theor~ of Computing, pages 11 15, 1990. [Si-S3] M. Sipser. A Complexity Theoretic Approach to 
Random­ness. Proceedings of the 15th Annual ACM Symposzum on the Theorg of Computmg, ACM (1983). [St-83] 
L. Stockmeyer. The Complexity of Approximate Count­ing. Proceedings of the 15th Annual ACM Symposium 
on the Theory of Computing, ACM (1983). APPENDIX: A Flaw in [F-89] In [F-89], Fortnow presents a constructive 
method for prov­ ing that SZK ~f SKC (0) is cent ained in CO-AM. Given an interactive proof (P, V) for 
a languages L and a (sta­tistical) zero-knowledge simulator M (for the honest ver­ifier V), he constructs 
a two-round protocol (P , V ) (for ~). This protocol is claimed to constitute an interactive proof system 
for ~. This claim, as we are going to show, is wrong. Yet, the result SZK ~ CO-AM does hold, since the 
work of Aiello and Hastad contains the necessary refinq ments which enable to present a modified AM-protocol 
for L (see [AH-87, H-94]). Furthermore, Fortnow s basic approach is valid, and indeed it was used in 
subsequent works (e.g., [AH-87, BMO-90, Ost-91, BP-92, OW-93]). Fortnow s basic approach starts with 
the observation that the simulator Ivf must behave differently on z c L and z @ L, Clearly, the difference 
cannot be recognized in polynomial­time, unless L c BPP. Yet, stronger recognition devices, such as interactive 
proofs should be able to tell the differ­ence. Fortnow suggests a characterization of the simulator s 
behavior on x 6 L and uses this characterization in his pro­tocol for ~, yet this characterization is 
wrong. Aiello and 542 Haatad present a refinement of Fortnow s characterization [AH-87], their characterization 
is correct and can be used to show that SZK ~ AM (which is the goal of their paper) as well as SZK ~ 
co-dM. Fortnow s characterization Given an interactive proof (P, V) for L and a simulator M, and fixing 
a common input z c {O, 1}*, the following sets are defined. Let us denote by tthe number of random bits 
that the verifier V uses on input x, and by q the number of random bits used by the simulator M. For 
every conversation prefix, h, we consider the set of the verifier s coin tosses which are consistent 
with h (the conversation so far). We denote this set by R?. Namely, for h = (al, /31, .... ai,,&#38; 
) (or h = (aI, @l, ....ai3i.cu +1)),), r c R? iff V(x, r,cu,..., cq) = @j for every j ~ i, where V(Z, 
r, @) denotes the message sent by V on input x random-tape r and prover message­sequence G. The set R? 
depends only on the verifier V. Next, we consider sets R; which are subsets of the corresponding R~ s. 
Specifically, they contain only r s that can appear with h in an accepting conversation output by the 
simulator M. Namely, r c R; iff r c R? and there exists u c {O, 1}9 so that M (z, w) is an accepting 
conversation with prefi h. (Here M(z, w) denotes the conversation output by Al on input x and simulator-random-tape 
w.) Motivation: For simplicity, suppose that the simulation is perfect (i.e., A4 witnesses that (P, V) 
is perfect zero-knowl­edge) and that (F , V) has one sided error (i.e., perfect com­pleteness ). Then, 
for every z c L and every possible h, we must have R$ = R? (otherwise the simulation is not per­ fect). 
However, if z @ L then there must exist h s so that R; is much smaller than R?. Otherwise the simulator-baaed 
prover (for I@ will always convince V to accept z, thus vio­lating the soundness condition of (P, V). 
The problem with the above dichotomy is that it is too existential and thus it is not clear how to use 
it. Instead Fortnow claimed the dichotomy which is more quantitative. A False Characterization: Let pref(~) 
denote the set of all message-subsequences in the conversation Z. ifx~L then Probw(Vh E pref(M(x, w)) 
lRjl %1 lR~l) > ~  ifx@L then Probti (Vh E pref(M(x, w)) lR~ I X2 lR~ 1) < ~   where the probability 
(in both cases) is taken uniformly over w c {O, I}q. We did not specify what is meant by xi. One may 
substitute xl by ~ ~, and =2 by > $. The gap between the two is needed for the approximate lower/upper 
bound protocols. A Counterexample The mistake is in the second item of the characterization. The false 
argument given in [F-89] confuses between the probability distribution of conversations output by the 
sim­ ulator and the probability distribution of the conversations between a simulator-based prover (denote 
P*) and the veri­ fier. These distributions are not necessarily the same (note that we are in case x 
@ L). Consequently, the probabil­ ity that igood conversations (i.e., conversations for which IRz [ = 
]Rl I for all prefixes) occur in the (P*, V) interaction is not the same aa the probability that the 
simulator outputs good conversations. This point is ignored in [F-89] and leads there to the false conclusion 
that the characterization holds, Bellow, we present an interactive proof (P, V) and a (perfect) zero-knowledge 
simulator for which the characteri­zation fails. The interactive proof that we present is for the empty 
language 0. This interactive proof is perfect zero knowledge for the trivial reason that the requirement 
is vacuous. Yet, we present a simulator for this interactive proof which, for every z G {O, 1}* = ~, 
outputs good conversation with probability close to 1. Thus, the characterization fails, The interactive 
proof (from the verifier s point of view input x G {O,l}n): The verifier uniformly selects a c {O, 
l} and sends a to the prover.  The verifier waits for the prover s message /3 ~ {O, l}W,  Next, the 
verifier uniformly selects ~ E {O, l}n and sends -y to the prover.  The verifier accepts iff either 
a = 0 or ~ = -y.  Regardless of the prover s strategy, the verifier accepts each z c {O, 1}n with negligible 
probability; specifically 2 n + (1 2-n) . 2-n. Thus, the above protocol indeed constitutes an interactive 
proof for the empty language 0. The simulator operates as follows (on input z c {O, I}n): . With probability 
1 q the simulator M outputs a con­versation uniformly distributed in On x {O, 1} 2n. (e is negligible, 
say c = 2-n) With probability q the simulator M outputs a conver­sation uniformly distributed in ({O, 
I}n -On) x {O, l}2n. Claim: In con~radiction to the characterization, for every z e {0,1} = 0, Proof 
It suffices to show that every conversation of the form On@-y satisfies Rz = R1 for all its prefixes. 
First observe that R? = {O, 1}2 = R;, since for every aq c {O, I}zn the simulator outputs the accepting 
conversation a~-y with non­zero probability y. Similarly, R? = On{O, 1}n = R; . Next, for every /3 c 
{O,l}n, we have R~ P = On{ O,l}n = R~n6, since for every ~ E {O, 1 }n the simulator outputs the accept­ 
ing conversation 0 /3~ with non-zero probability. (Here we use the fact that the verifier always accepts 
when a = 0 .) Similarly, R~nP7 = 0 ~ = l?~ d~. O Conclusion The source of trouble is that the definition 
of the sets R$ s does not take into account the probability weight assigned by the simulator to w s that 
witness the assertion the simu­ lator outputs an accepting conversation that starts with h . Indeed, 
this is exactly the nature of the refinement suggested by Aiello and Hastad [AH-87]. 
			