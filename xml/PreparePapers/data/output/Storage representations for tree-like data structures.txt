
 STORAGE REPRESENTATIONS FOR TREE-LIKE DATA STRUCTURES Arnold L. Rosenberg*, Derick Wood**, Zvi Galil*** 
ABSTRACT. We review the motivation underlying the study of data encodings and the formal framework of 
the study. We then present a series of results whose main message is that (complete) trees are materially 
less congenial storage representations for tree-like data structures than they have been shown to be 
for array-like data structures. In response to these results, we pro-pose a new data structure, called 
a dree, which we show to share the advantages of trees, but not to suffer their disadvantages, when used 
as a storage structure. 1. INTRODUCTION Recent years have seen several papers on a new genre of graph-theoretic 
problem motivated by issues involved in finding efficient storage representations for data structures 
(see Section 2B, "Related Work," for citations). The motivating scenario is the following. One has a 
(family of) data structure(s) that, for reasons of machine architecture, ease of programming, etc., is 
inconvenient to represent directly in computer memory. One therefore seeks a (family of) data structure(s) 
that are at once convenient to store and efficient to "encode" one's original structure(s) in. If the 
algorithms one is implementing process data structures primarily by traversing them, then one can reasonably 
abstract the described problem in graph-theoretic terms: the problem is to find embeddings of one (family 
of) graph(s) --called the guest(s) --in another (family) --called the host(s) --that do not "stretch" 
the guest-edges unduly as these edges are replaced by host-paths via the embedding. There are many rea- 
* Mathematical Sciences Dept., IBM Research Center, York-town Heights, NY 10598. ** Dept. of Applied 
Mathematics, McMaster Univ., Hamilton, Ontario, Canada. The research of this author was supported in 
part by the Natural Sciences and Engineering Research Council of Canada under Grant A-7700. *** Dept. 
of Mathematical Sciences, Tel-Aviv Univ., Ramat-Aviv, Tel-Aviv, Israel. The research of this author was 
done while be was visiting the Mathematical Sciences Dept. of the IBM Research Center. sonable measures 
of the amount of stretching caused by an em-bedding: perhaps the'most obvious is the "worst-case" measure 
that focusses on the guest-edge that the embedding stretches maximally; no less natural is the "average-case" 
measure that distributes the cumulative stretching by the embedding uniformly over all the edges of the 
guest graph. It is our thesis, in view of the real-life situation we are attempting to model, that the 
most realistic assessment of the cost of an embedding is a weighted average of the amount that the embedding 
stretches the edges of the guest graph, where the weighting of the guest-edges ranks them in importance, 
say by anticipated frequency of traversal. Such an averaging charges the embedding most heavily for its 
dilation of frequently traversed edges and, therefore, yields the most meaningful notion of cost for 
assessing the merits of a par- ticular storage representation. In order to facilitate comparisons between 
competing embeddings, we shall normalize edge-weightings to make them probability distributions on the 
edges of the guest graph. This paper continues the investigation begun in [13] of encodings of data structures 
in the leaves of complete trees (i.e., embeddings in the trees of the graphs representing the data struc- 
tures). The use of complete trees as storage structures is recom- mended by the facts that trees are 
easy to store and to manipulate in a large variety of computing environments [7] and that repre- sentations 
of many data structures in the leaves of trees often emerge "naturally" from the specifications of the 
structures [18, Â§V]. It is our purpose here to parallel the investigation in [13] with trees as the guest 
data structure as well as the host. The rationale behind the endeavor of encoding trees in trees is two- 
fold. First, we wish to expand our battery of techniques for encoding, manipulating, and understanding 
guest data structures 99 &#38;#169; 1979 ACM 0-89791-003-6/79/0400-099 $00.75 See page ii having varied 
structural characteristics. Second, we wish to study encodings in trees of as many different types of 
guest structures as possible in order to understand, better the strengths and weakness- es of complete 
trees as host structures. One of the main messages of the study in [13] of encodings of multidimensional 
array-graphs in trees was: for each dimen- sionality d, there is a specific strategy for embedding d- 
dimensional array-graphs in the leaves of binary trees that prod- uces embeddings having acceptable costs 
("acceptable" = "independent of the size of the guest graph") relative to a wide range of probability-weightings 
of the array-graphs (1). (These weightings include those arising from most common ways of trav- ersing 
arrays.) In contrast with these predominantly positive findings about array-guests, we find here that 
trees are not partic- ularly congenial hosts for tree-guests. First, we find that different "natural" 
probability-weightings for guest trees demand different encodings of the guest trees in order to obtain 
acceptable costs. Second, we find that certain probability-weightings --in fact, those arising from using 
the guest trees as search trees --cannot be accommodated with acceptable cost by any tree-into-tree encoding! 
Each of our "discoveries" is accompanied by derivations of asymptotically coincident or almost-coincident 
upper and lower bounds on the costs of encodings relative to that probability-weighting. These results, 
which dramatically temper the successes of [13], lead us to suggest a new data structure called a dree 
as a replacement for trees as hosts under data encodings. Drees ac-commodate any guest graph at least 
as well as do trees; and drees accommodate tree-like guest:s (and dree-like guests) almost per- fectly. 
Throughout this paper we shall concentrate on binary trees as both guests and hosts, for the sake of 
expositional simplicity; our results translate immediately to trees of any fixed arity.  2. BACKGROUND 
A. Data Encodings and Their Costs As usual, an undirected graph G comprises a set V of vertices (or, 
nodes) and a set E of 2-element subsets of V called edges. ~)Phrases like "probability-weightings of 
the array-graphs" are to be understood as abbreviations for "probability-weightings of the array-graphs' 
edges." For each integer h >_ 0, the height-h binary tree T(h) is the undirected graph whose nodes comprise 
all strings of length at most h over the alphabet A = {1,2} and whose edges consist of all pairs (x,xa) 
where x is a string of length < h over A, and aEA. The root of T(h) is the string of length 0; and the 
2 h leaves of T(h) are the strings of length h. For each 0_<k<h, T(h) has 2 h-k height-k subtrees, each 
having a different length-(h-k) string x as its root and each comprising the subset {xy I Y is a string 
of length _<k over A} of T(h)'s nodes, together with all edges of T(h) having both termini in that set 
(each of x, xa is a terminus of the edge (x,xa)). An encoding of the graph G in the tree T(g), where 
g>logl Vertices(G) [ (all logs are to the base 2), is an injection t: Vertices(G) --~ Leaves(T(g)). Any 
such injection induces, in a natural way, an injection e : Edges(G) ~ Paths(T(g)) defined for each edge 
(v,v') of G as follows: e(v,v') = the (unique) shortest path in T(e) from t(v) to t(v'). Exposition will 
be simplified if we identify the mappings e and L, so we shall henceforth refer to e as the encoding 
of G in T(C). We shall often call the encoding e an entreeing of G. We want to have a meaningful way 
to measure the amount of time-dilation engendered by an entreeing of the graph G. In our motivating scenario, 
this dilation arises from our having to trav-erse paths in the host-tree in order to simulate crossing 
edges in G. As we noted in the Introduction, any meaningful measure of cost must take into account the 
way that G is to be traversed. As an extreme example, an entreeing of G that is optimally efficient when 
G is to be processed by depth-first traversal may be insuf- ferably inefficient when G is to be processed 
by, say, breadth-first traversal. Now, the germane distinction between these two traver- sal regimens 
is not the specific paths through G that they entail but rather the different relative frequencies of 
traversals of the various edges of G under these regimens: small time-dilation results from associating 
high-frequency edges with short paths. As in [12, 13], we find that the relevant frequencies can be both 
faithfully and conveniently represented by means of an assign-ment of probabilities to the edges of G. 
The intended relationship between traversal frequencies and probabilities is most easily illustrated 
by a simple example. i00 Example. Consider the 5-node line graph depicted in Figure 1. Imagine that 
the line is the tape of a Turing machine (vertices are tape sqoares and edges represent logical adjacencies) 
whose wan- derings are indicated by the zig-zag line below the graph, As the machine meanders along the 
indicated path, it crosses each edge of the graph six times. Since all edges are crossed with equal frequency, 
they would be assigned equal probabilities; namely, each would get probability 1/4. The intended message 
of this edge-weighting is that in any representation of this graph via an encoding, one would have no 
reason to favor any one edge over another (at least on grounds of frequency of traversal). To con-trast 
with this situation, assume now that the Turing machine's walk is terminated when it first encounters 
node 5, at the point indicated by the double arrow in Figure 1. This decaudated tra- jectory crosses 
edge (1,2) three times, edge (2,3) five times, edge (3,4) three times, and edge (4,5) once. Since the 
cumulative number of edge-crossings is 12, the indicated crossing frequencies of the graph's edges would 
mandate assigning them the probabili- ties 1/4, 5/12, 1/4, and 1/12, respectively. The transitions from 
trajectories to crossing frequencies and thence to probabilities are discussed in some detail in [12]. 
Returning to our formal framework, a usage pattern for the graph G is a probability function ~r: Edges(G) 
~ [0,I]. The desired notion of the cost of a data encoding ensues directly. The cost of the entreeing 
e of the graph G relative to the usage pattern Â¢r for G is given by Cost(e;~r) = ~ 7r(e).lgth(e(e)). 
eeEdges(G) One sees easily that Cost(e;~r) is precisely the time-dilation factor that we wanted it to 
be: if the usage pattern ~ arose from a projected trajectory of length t (edges) in the guest graph, 
then the encoding of this trajectory in the host tree has length Cost(e;~r)t. B. Related Work This paper 
continues the study originated in [13] of entree- ings of arbitrary graphs and the costs of such entreeings. 
The study in [13], in turn, evolved from the preliminary investigation in [12] of encodings of arbitrary 
graphs in arbitrary graphs and the costs of such encodings. Two other offspring from [12], which retained 
the generality of guest and host graphs but which restricted attention to only two usage patterns for 
the guest graphs, are [14,15]. The restricted usage patterns of [14,15] lead to the following two costs 
of a data encoding, the worst-case cost WCOST(e) = max lgth(e(e)) and the average-case cost 1 ACOST(e) 
= -~-~ lgth(e(e)) (1) where the indicated maximization and summation are over the E edges of the guest 
graph. These two costs, jointly or separately, are the costs studied in [4,5,11] which study eneodings 
of arrays in lines, in ]8] which considers encodings of arrays in trees, in [I] which treats encodings 
of arrays in both trees and lines, and in [2,6,17] which look at encodings of various families of graphs 
in others. A fundamental tool for studying ACOSTs of encodings of graphs in trees is developed in [9] 
and expounded further in [10]. The term "encoding" occurs only in the first four cited works, but the 
notion of encoding subsumes the types of graph-into-graph mappings studied in all the cited references. 
C. The Highlights of [13] We are concerned here only with the upper bounds estab-lished in [13]. The 
main such results indicate that complete trees are quite congenial hosts for array-like graphs: for each 
dimen- sionality d, there exists a simple strategy for encoding d-dimensional arrays in the leaves of 
complete trees, which yields encodings with O(1) costs relative to a wide range of usage pat- terns for 
the guest arrays. We paraphrase two of these results. Consider the family of entreeings of line-graphs 
which lay the lines out in the leaves of trees in natural order: vertex 1 of the guest line is placed 
in the leftmost leaf of the host tree, vertex 2 in the next leaf, and so on, from left to right. Let 
e n denote the indicated entreeing of the n-vertex line. Let qr be a usage pattern for the line; and 
let us abbreviate by ~r i the probability rr(i, i+l). We find the following results in [13]. I. If each 
~r i < ~ri+ I, then Cost(en;~r) _< 4+o(1). I1. Let {~r n] be a family of usage patterns, ~r n being a 
usage pattern for the n-vertex line. If each ~r n is realized by a trajee- i01 tory on the n-vertex 
line whose average sweep length grows at least as fast as log n (when viewed as a function of n), then 
Cost(en;~r n) = O(1). If ~r n is realized by a trajectory whose average sweep length grows strictly faster 
than log n, then Cost(en;~r n) _< 4+o(1). Results not unlike these can be established for array guests 
of arbitrary finite dimensionality. 3. ENTREEINGS OF TREES Tree-guests do not admit either of the two 
kinds of stability embodied in the results just cited. First, tree-guests do not yield to one layout 
strategy for all usage patterns which can be accom-modated with size-independent cost. Second, there 
are "common" usage patterns that cannot be accommodated with size-independent cost by any entreeing strategy. 
We now introduce two natural entreeing strategies and three (families of) usage patterns. (2) We show 
that each of the entree- ing strategies enjoys size-independent cost for one of the usage patterns but 
not for the others; and each strategy does poorly on the pattern the other strategy does well on, Moreover, 
we prove that the third family of usage patterns, namely those associated with search trees cannot be 
accommodated efficiently by any entreeing strategy. However, we do exhibit a third family of entreeings 
whose cost relative to these "search-tree" usage pat- terns is exponentially smaller than those of our 
two natural en- treeings; and we prove the asymptotic optimality of this family's cost. A. Two Entreeings 
of Trees Our first entreeing strategy is the following recursive (hence extendible) family. Let e h 
denote the following entreeing of T(h) in T(h+l): '(1) e 0 places the unique node of T(0) in the left 
leaf of T(1). (2) e h (h>l) places each of the two height-(h-1) subtrees of the guest-tree T(h) in the 
leaves of one of the two height-h sub- trees of the host-tree T(h+l), in just the way that eh_ 1 would 
lay T(h-1) out in the leaves of T(h); and then e h places the root node of T(h) in the one vacant leaf 
remaining in the (2)Each entreeing "strategy" comprises one entreeing for each T(h), the parameter h 
being the main discriminant among the entreeings in the strategy. The usage patterns in each family differ 
similar- ly in terms of the parameter h. height-h subtree of T(h+ 1) that contains the left height-(h-l) 
subtree of T(h). See Figures 2, 3. Our second entreeing strategy lays the guest-tree out in the leaves 
of the host-tree in a breadth-first manner. Let e h denote the following entreeing of T(h) in T(h+l). 
Index the leaves of T(h+l) from left to right, eh places the root of T(h) in the left- most leaf of T(h+l). 
It places the two sons of the root --call them the level-I nodes --left-to-right in the second and third 
leaves of T(h+l). It places the four sons of the level-I nodes --call them the level-2 nodes --left-to-right 
in the fourth through seventh leaves of T(h+l).... It places the 2 k sons of the nodes at level k-1 --call 
them the level-k nodes --in leaves 2 k through 2k+3-1 of T(h+l), and so on. In this process, for each 
k, the sons of level-k nodes are processed in the reverse of the order in which their parents are laid 
out. See Figure 4. B. Three Families of Usage Patterns and Their Analyses To facilitate computation in 
the remainder of the section, we now calculate symbolically the costs of e h and e h relative to the 
type of usage pattern that we shall be studying, namely, usage patterns 7r that assign the same probability 
~r k to every level-k edge of T(h), i.e., to every edge having one terminus at level k-1 of the tree 
and one at level k. Cost(eh;~r) = 2 h+l ~ (2k + 1)2-k~h_k+l; I<k<h Cost(eh;~r) = 2 ~ (k2 k + 2k--k)~rk 
. l_<ksh These equations indicate that eh'S handling of level k of T(h) is roughly equivalent to eh's 
handling of level h-k. B.l. Each ~r i = 'rri+ 1 The first usage pattern we consider is the all-edges-equally-likely 
usage pattern prescribed by the subsection heading and given explicitly by 1 ~k 2h+i_2  for all levels 
1 <k<_h of T(h); this is the usage pattern which gives rise to the ACOST measure of equation (1). By 
direct calculation one verifies: 102  Proposition 1. If ~r I = .rr 2 ..... ~h, then of T(h)'s edges 
in height-k subtrees of a host tree turns out to be: Cost(eh;~r) = 5 + O(1) 2 h+l + 0(2 -k) mk 2k+l 1 
 as h -~ ~. subtrees "containing" 2k-1 edges each; and Proposition 2. If ~r I = ~r 2 ..... ~r h, then 
2h-k+l _ m k Cost(eh;Â¢r) = ~(h) subtrees "containing" 2k-2 edges each. as h -*- oc. This means that no 
entreeing of T(h) can place more than In order to put the "behavior" of e h in perspective, we now N 
k = 2h+'(1 3"2k--2 ) + O(1) show that no entreeing of T(h) can have appreciably better cost 2k(2k+t_l) 
relative to ~r than e h does. In fact, we conjecture that the cost of edges of T(h) in the same height-k 
subtree of the host tree, and so e h relative to ~r is optimal, i.e.: Cost(e;~r) _> 2 + 2 E 3"2k--2 + 
o(1), i s:k_<h 2k(2k+l-- 1) Conjecture. If qr I = ~r 2 ..... qr h, then for any entreeing e of T(h), 
whence the result. Cost(e;~) > 5 + o(1) ash ~ z. B.2. Each ~i = 2~ri+l The second usage pattern we consider 
is that specified in the Improving the upcoming result to settle the conjecture seems, subsection heading 
and given explicitly by however, to demand quantifying certain effects that have eluded us. 1 Theorem 
3. If ~r I = qr 2 ..... lr h, then for any entreeing e of for all levels 1 <k_<h of T(h). T(h), The usage 
pattern ~r arises in a number of natural situations. Cost(e;~r) > 4.786 + + o(1) Consider first a complete 
height-h binary search-tree that has 2 h ash* ~. equiprobable keys at its leaves. When accessing a key 
in this tree, one traverses one of its 2 h length-h root-to-leaf paths, all such Proof Sketch. The proof 
employs a packing argument similar to paths being equally likely to be traversed. Each level-k edge in 
those used in Â§Â§4,5 of [13], the general strategy of which pro-the tree enters into precisely 2 h-k of 
these paths, and, so, has ceeds as follows. An edge of T(h) is dilated under an entreeing e traversal 
probability ~r k. Similar reasoning indicates that ~r is also by a factor not exceeding 2k if and only 
if e places both of the (at least asymptotically) the usage pattern that arises from a edge's termini 
in the same height-k subtree of the host tree. search tree that has equiprnbable keys at its internal 
nodes. Fi-Hence, by bounding from above the number of edges of T(h) that nally, ~r can be shown to arise 
from one possible trajectory of an e can so place, we can bound from below the number of edges of "oblivious" 
Turing machine whose tape is a complete binary tree. T(h) that e dilates by a factor of more than 2k; 
and we can there-Direct calculation yields: by bound from below the cost of e. Now, since T(h) is a tree, 
an n-element subset of its nodes Proposition 4. If ~r 1 = 2~r 2 = .... 2h-I'rrh , then cannot "contain" 
more than n-1 edges. Thus we cannot hope for Cost(eh;rr) = ~(h) any entreeing of T(h) to place more than 
2k-I of T(h)'s edges in as h~Â¢. any single height-k subtree of the host tree. In fact, by studying the 
numbers of connected subgraphs of T(h) of various cardinali- Proposition S. If ~r 1 = 2~r 2 = .... 2h-I~rh, 
then ties, we can show that no encoding can place even this many Cost(eh;ir) = ~(h) edges in every height-k 
subtree of the host. The optimal packing as h~o~. 103  In view of the importance of the usage pattern 
~r, it would be desirable to find some entreeing of T(h) with size-independent cost relative to this 
pattern. None exists! However, there do exist entreeings of T(h) whose costs relative to ~r are exponentially 
smaller than those of e h and eh. The weakness of these more efficient encodings (at least of the ones 
we know) is their com-plexity of specification. Theorem 6. If ~r I = 2qr 2 ..... 2h-l~rh, then for any 
entreeing e of T(h), Cost(~:;~r) = ~(log h) as hoot. Moreover, there exist entreeings e[h] of T(h) in 
T(h+ 1) such that Cost(e[h];~r) = O(log h) as h--~. Proof Sketch. The lower bound is proved by a packing 
argument similar to that of Theorem 3, but complicated by the nonuniform probability distribution on 
the edges of T(h). In broad outline, the argument proceeds as follows. Let S be any set of nodes of the 
guest tree T(h) that does not contain 'the root node. The cumulative probability of those edges of T(h) 
that have only their bottom terminus in S is at least log(ISI +1) times the cumulative probability of 
the edges that have both their termini in S. Now let e be any entreeing of T(h). Focus on those sets 
of nodes of T(h) that e places in the same height-k subtree of the host tree. Using the indicated bound 
in turn on each one of these sets that doesn't contain the root of T(h) (i.e. let each of these sets 
in turn be the set S), we find that the cumulative probability of those edges of T(h) that ~ stretches 
by a factor of more than 2k is at least (roughly) 1/(k+l). The lower bound follows by summing the derived 
probabilities over k, since the entreeing e was arbitrary. The upper bound follows from an encoding technique 
that recursively decomposes the guest tree into subtrees of (roughly) half the height. Specifically, 
the encoding decomposes T(h) into the tree obtained by taking T(h)'s top fh/2"l-1 levels as one block 
of the decomposition and each of T(h)'s height-~Lh/2J subtrees as another block. The encoding then stores 
all of these blocks, save one of the last, by recursive calls to its height-(r h/2l-1) and height-I h/2 
J brethren; and it distributes the nodes of the one subtree not submitted to the recursion among the 
vacant leaves of the height-(h+l) host tree obtained by unit- ing the outputs of the recursive calls. 
See Figure 5. An analysis of this recursive encoding establishes the following recurrence for its cost: 
if we abbreviate by C(h) the cost of the indicated en- treeing of T(h) relative to the usage pattern 
~r, then L h/2 J ~J~ C(h) <_ ~ C([h/2J)+ C(rh/2]-l) 2 + 2 + h 2 ~ (h(Lh/2J+l)+l). One proves by induction 
that C(h) = Cost(e;rr) < 41og(h+l).  B.3. Each ~i -~ c'rri+l, c>2 Having looked at a usage pattern that 
eh works well on while e h does not, and a usage pattern that neither entreeing works well on, let us 
turn now to a family of usage patterns that e h works well on while e h does not. These usage patterns 
are specified in the subsection heading and are given explicitly by C h ,~c-k for all levels l<k<h of 
T(h), and for arbitrary fixed c > 2. By direct calculation, one verifies: Proposition 7. If ~r I = cw 
2 . . . . . ch-I~rh , c>2, then Cost(eh;Ir) = f~(h) as h~oe. Proposition 8. If ~r! = car 2 . . . . . 
eh-I~'h , c>2, then Cost(eh;rr) = 3 + -~ + 0 1 as c, h--~Â¢. Now, it is not hard to verify that the entreeing 
e h is not optimal in cost relative to each of the usage patterns specified in (2). However, we were 
not able to find a more efficient entreeing of T(h) that yielded to as simple a description, specification, 
and analysis as did e h. Since ease of programming is a real concern when studying and using various 
data representations (see the long discussion of this issue in [15]), we have decided to use e h as the 
"top-down" entreeing to contrast with eh'S "bottom-up" structure. Of course if e h were very far from 
optimal, this argu- ment favoring orderliness over efficiency would be very much 104  weakened. But, 
in fact, eh's cost relative to the usage pattern ~r is asymptotically optimal as c grows without bound. 
Theorem 9. If ffl = cqr2 ..... ch-lqrh , c>2, then for any entreeing e of T(h), Cost(e;~r)_> 3+-!+c O((c-~2) 
) as c, h--,.~c. The theorem is proved by an argument parallelling very closely that of Theorem 6. 4. 
DREES: A NEW HOST DATA STRUCTURE We wish to find a data structure that shares the benefits of trees, 
namely, ease of storage, manipulability, and analysis, but that is a more congenial host under data encodings. 
The following modification of trees seems to satisfy our list of desiderata. For each integer h _> 0, 
the height-h dree D(h) is the undi- rected graph whose nodes comprise all strings of length at most h 
over the alphabet A = {1,2}; and whose edges consist of all pairs (x,xa) where x is a string of length 
< h over A, and a~gA, as well as all pairs (x,xl2 a) or (y,y21 b) where x (resp., y) is a string of length 
h-a-I (resp., h-b-l) over A, and 2 a (resp., 1 b) denotes a string of a>0 2's (resp., b>0 l's). See Figure 
6. In order to emphasize the similarities between drees and trees, we shall call the length-h nodes of 
D(h) leaves, and we shall calJ encodings in drees endreeings. An encoding of the graph G in the dree 
D(h), where h_>log I Vertices(G)I, is an injection e: Edges(G) --Paths(D(h)) that induces an injection 
t: Vertices(G) .*- Leaves(D(h)). The notions of a path in a dree and the cost of an endreeing are defined 
by direct analogy with the corresponding tree-based notions. Clearly the "shortcuts" in dree-hosts cannot 
decrease their efficiencies when compared to tree-hosts: Proposition 10. Let ~r be a usage pattern for 
the graph G. For any entreeing e of G in T(h), there is an endreeing e' of G in D(h) with Cost(e';~r) 
< Cost(e;ir). When the guest-graph G is a tree, these shortcuts in fact render the cost independent 
of ~r! And this size-independent cost persists when drees are used to encode drees. Proposition 11. For 
each h _> 0, there is an endreeing e(h) of T(h) in D(h+ 1) such that, for any usage pattern ~r for T(h), 
Cost(e(h);~r) < 3. Proposition 12. For each h _> 0, there is an endreeing e(h) of D(h) in D(h+l) such 
that, for any usage pattern ~r for D(h), Cost(e(h);~r) _< 3. The proofs of Propositions 11 and 12 are 
both refined ana- lyses of the entreeing e h viewed as a tree-into-dree encoding (see Figure 7). In closing, 
we note that the "average-case" cost of the en- dreeing e(h) of Proposition 12 is strictly less than 
its worst-case cost: in the terminology of equation (1), ACOST(e(h)) = 2.5. On the basis of these preliminary 
results about drees, these storage structures would appear to merit further study.  REFERENCES 1. R. 
A. DeMillo, S. C. Eisenstat, and R. J. Lipton: Preserv-ing average proximity in arrays. C. ACM 21 (1978) 
228- 231. : On small universal data structures and related combinatorial problems. Proc. Johns Hopkins 
Conf. on Inf. Sci. and Syst., 1978, pp. 408-411. C. C. Gotlieb and F. W. Tompa: Choosing a storage schema. 
Acta Inform. 3 (1974) 297-319. 4. L. H. Harper: Optimal assignments of numbers to vertic- es. J. Soc. 
Ind. Appl. Math. 12 (1964) 131-135. 5. --: Optimal numberings and isoperimetric problems. J. Comb. 
Th. 1 (1966) 385-393.  6. M. A. Iordansk'ii: Minimalnye numeratsii vershin dere-vyev (in Russian). Problemy 
Kibernetiki 31 (1976) 109-  132. 7. D. E. Knuth: The Art of Computer Programming I: Fun-damental Algorithms, 
Addison-Wesley, Reading, MA, 1968. R. J. Lipton, S. C. Eisenstat, and R. A. DeMillo: Space and time hierarchies 
for classes of control structures and data structures. J. ACM 23 (1976) 720-732. 9. R. J. Lipton and 
R. E. Tarjan: A separator theorem for planar graphs. Proc. U. Waterloo Conf. on Theoretical Comp. Sci., 
1977, pp. 1-10. 10. -: Applications o!f a planar separator theorem. Proc. 18th Annual Symp. on Found. 
of Comp. Sci., 1977, pp. 162-170. 11. A. L. Rosenberg: Preserving proximity in arrays. SIAM J. Comput. 
4 (1975) 443-460. 12. --: Data encodings and their costs. Acta Inform. 9 (1978) 273-292. 13. --: Encoding 
data structures in trees. J. ACM, to appear; see also Proc. Johns Hopkins Conf. on Inf. Sci. and Syst., 
1978, pp. 380-384.  < 14. A. L. Rosenberg and L. Snyder: Bounds on the costs of data encodings. Math. 
Syst. Th. 12 (1978) 9-39. 15. A. L. Rosenberg, L. Snyder, and L. J. Stockmeyer: Uni-form data encodings. 
Theor. Comp. Sci., to appear; see also Proc. Johns Hopkins Conf. on Inf. Sci. and Syst., 1978, pp. 412-417. 
 16. P. Scheuermann and J. Heller: A view of logical data organization and its mapping to physical storage. 
Proc. 3rd Texas Conf. on Comp. Syst., 1974. 17. M. A. Sheidvasser: O dline i shirine razmeshchenii grafov 
v reshetkakh (in Russian). Problemy Kibernetiki 29 (1974) 63-102. 18. T. A. Standish: Data structures 
-an axiomatic approach, Cap. 3 in Current Trends in Programming Methodology IV: Data Structuring (R.T. 
Yeh, ed.), Prentice-Hall, Engle- wood Cliffs, NJ, 1978.  Figure 1. A sample trajectory on the 5-vertex 
line-graph. The double arrow indicates the first time vertex 5 is en-countered. Figure 2. The tree T(3); 
nodes have been given letter-names rather than string-names to enhance readability. Figure 3. The entreeing 
e 3 of T(3) in T(4); cf. Figure 2. Figure 4. The entreeing e 3 of T(3) in T(4); cf. Figure 2. Figure 
5. The entreeing e[3] of T(3) in T(4); cf. Figure 2. Figure 6. A skeletal rendering of the dree D(4). 
 Figure 7. The endreeing e(3) of T(3) in D(4); cf. Figure 2. 
			