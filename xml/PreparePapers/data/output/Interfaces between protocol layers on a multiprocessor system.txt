
 Interfaces Between Protocol Layers on a Multiprocessor System Wilfredo A. Colon-Castro Deborah A. Kirkman 
 American Bell Holmdel, New Jersey 07733 A multi-layer, X.25 based protocol has been implemented on 
a multiprocessor system. The higher layer protocol resides in the system processor while the lower level 
protocol (X.25 levels 2 and 3) runs on a peripheral processor. This paper focuses on the boundary between 
the system and peripheral processors. It discusses how flow control is done, how control information 
is passed across the boundary, and the synchronization problems that arose. In addition, it describes 
effects on performance resulting from splitting the protocol across the two processors. 1. Introduction 
This paper describes aspects of a protocol layer[|] interface that is implemented on a multi-processor 
system. The performance constraints of the system precluded putting all of the protocol on a single processor. 
Instead, software was partitioned between a 16 bit system processor and an 8 bit peripheral processor. 
Because processors run independently of each other, the partition creates information flow problems. 
On the system processor, an operating system imposes even further constraints on passing information 
across this boundary. 1.1 Requirements The purpose of this protocol implementation or subsystem is to 
provide communications services over virtual circuits in a star network (refer to Figure I). User programs 
on the sTstem processor require the high-level services of formal connection and disconnection, and a 
guarantee of message delivery and message order. This paper discusses the architecture of the protocol 
subsystem in the terminal nodes. Due to differences in hardware and.software environments, the architecture 
of the protocol subsystem in the central node is significantly different. In addxtxon, there is a fixed 
set of user pairs--thus there is no need for dynamic allocation of virtual circuits. Instead, circuits 
are allocated statically, with a" particular circuit being assigned to a pair of users. Permission to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. 1.2 Hardware Architecture 
The X.2512] [3] [4] protocol subsystem executes in a multi-micro processor environment (refer to Figure 
2). CI~qTRAt. 9 9 // ~.% v" / ~\ Figure I. Network TOpology SYSTEM PROCESSOR 32K PERIPHERAL OR 64K 
PROCESSOR (46 bit} 2 MB 32K PERIPHERAL OR  MAIN M E)4OiqY 64K PROCESSOR Figure 2. System Configuration 
 The system processor is an 8 megahertz (MHz), 16 bit general purpose microprocessor with access to two 
million bytes of random access memory (RAM) plus the local memories of the peripheral processors. Each 
peripheral processor is an 8 bit micro-computer with 32 or 64 thousand bytes (KB) of RAM. Specifically, 
the peripheral processor used by the protocol subsystem is equipped with 64KB of RAM, a 4 MHz general 
purpose microprocessor, a counter-timer chip, and a universal synchronous-asynchronous receiver- transmitter 
(USART) chip. 229  &#38;#169; 1983 ACM 0-89791-113-X/83/0010/0229500.75 The system and peripheral processors 
communicate on a master-slave basis. The system processor is always the master and requests service by 
writing to a dedicated area of the peripheral processor's local memory. A peripheral processor, although 
unable to affect main memory, can interrupt the system processor to get service for requests it places 
in a second dedicated area of its local memory. The performs all data moves peripheral processor memory. 
system between processor main and 1.3 Software Environment Programs on the system processor do not have 
access to the details of the hardware architecture but instead run under a multi-tasking, time-shared 
operating system. One service provided by the operating system is a driver that manages communications 
between software on the system and peripheral processors. System processor software uses the driver 
to access the peripheral processor as a device with several entry ways or sub-channels. The only operations 
programs can perform on these sub- channels are open (initialize and make available for data transfer), 
close (terminate data transfer and make idle), read (receive data), and write (send data). Another operating 
system function related to the driver is a data notification service. With this, software running on 
the system processor can arrange to receive a notification whenever data is available on a sub- channel 
opened by the software. In contrast, there is no operating system on the peripheral processors. The 
software on each of these processors is tailored to one specific task and is written to directly control 
the processor which is executing it. All code for the protocol is written in C,[5] a structured high-level 
language. This language provides a rich set of control constructs (refer to Figure 3) and a rich set 
of data types such as signed and unsigned integers, bit fields, pointers, arrays, and records or structures. 
C is well suited for microprocessor work because it produces compact, efficient object code. if (condition) 
{statement(s)} else {statement(s)} while (condition) {statement(s)) switch (expression) { case value-l: 
statement(s); break; case value-j: statement(s); break; o.. case value-n: statement(s); break} function(param-1 
..... param-n); Figure 3. Sample C control constructs Programs for the system processor are written 
entirely in C. For the peripheral processor, C code provides adequate performance while maintaining high 
levels of readability and maintainability. In the peripheral processor only some microprocessor specific 
assembly language is used for subroutines that must deal directly with the hardware and/or meet stringent 
real-time constraints. 2. Boundary Solutions 2.1 Software Partitioning The first design decision was 
to determine the physical location of all software modules. The three main objectives were: I. to offload 
the system processor as much as possible; 2. to avoid overloading the peripheral processor; and  3. 
to minimize the complexity of the interprocessor interface.  After consulting with other implementors 
of the Link and Network layers,[6] [7] it was decided that the peripheral processor could support both 
layers. The higher-level Drotocol, ~ which must interface to user processes on the system processor, 
was placed in a process running under the operating system. This system structure works well because 
of the complexity of the higher level protocol and the application interface. 2 However, about half of 
the higher level protocol code was dedicated to interfacing to the user applications and the lower levels. 
Much of this extra code could have been avoided if there had been enough processing power in the peripheral 
processor.  2.2 The Interface Structure Due to the needs of the user pairs, virtual circuits are assigned 
a (static) one-to-one mapping to sub-channels on the peripheral processor (refer to Figure 4). I LINK 
Figure 4. Structure of the Interface Thus the higher level protocol can instruct the Network layer[8] 
to transmit data on a particular virtual circuit by writing to its assigned sub- channel; it can likewise 
receive data on a virtual circuit by r~adlng its assigned sub-channel. i I. This is the BX.25 Session 
Layer. "Session Layer" and "higher level protocol" are treated £nterchangeably, as well as the term "lower 
 level protocols" with the Link and Network layers. 2. The higher level protocol takes 37KB of executable 
object code plus 45KB for buffer space. The lower levels take 19.5KB of executable object code and use 
the remainder of the 64KB of memory for buffer space.  230 In addition to these sub-channels, one sub- 
channel is reserved for control transactions between the two separated layers. For example, this channel 
is used by the high-level software to instruct the network layer to reset a virtual circuit. This sub-channel, 
called the "control channel", is also used by the peripheral software to pass diagnostics, notifications, 
acknowledgements, and statistics to the higher layer. The operating system device driver performs the 
message packetization and assembly required by the network layer. TO the higher level protocol, the driver 
appears to deal with contiguous messages. Thus when data is passed to the network layer over a sub-channel, 
it is broken up automatically into fixed length (128 bytes) packets with additional space for protocol 
headers and internal information. When data is passed upwards to the high level protocol, the operating 
system constructs a contiguous message from network layer packets. Data notifications from all sub-channels 
are concentrated into one operating system message queue (refer to Figure 5).  I SUIB-~ ~ TtMEfl CHANNEL 
~1 i NOTIFICATIONS  glERVICE Figure 5. Operating System Enqueueing This is the same queue used by applications 
interacting with the high level protocol and by the service process that provides timing information 
for it. The high level protocol polls this queue with a system call that returns the highest priority 
message in the queue. If the queue is empty it waits for work to do. This method of receiving transactions 
provides an automatic scheduling for the high level protocol. 2.3 Flow Control and Synchronization across 
Processor Boundaries The separation of control and data information provides intrinsic flow control 
between processors. The high level protocol does not have to read data from sub-channels. It may choose 
to ignore a data notification, for example, if its own buffer space is full. If the Network layer runs 
low on buffer space, it can then invoke peer flow control. Control information is always available through 
the control sub-channel even if a data sub-channel is flow controlled. Separate paths, however, create 
synchronization problems. There is no guarantee that, for example, an indication of a reset procedure 
on a virtual circuit will reach the session layer before an indication that more data has arrived on 
the same virtual circuit. This condition was remedied by assigning a higher priority to control over 
data notifications. Additional handshaking is needed when the  X.25 network layer detects missing or 
out of order data. 3 The network layer re-establishes synchronization through the reset and restart procedures. 
A reset forces a particular virtual circuit to a known state, and may result-in lost data. A restart 
is roughly equivalent to a reset on each virtual circuit of the network layer, and again may result in 
lost data. The higher level protocol can retransmit lost data;, it does not discard a message until the 
network layer indicates that the last packet of the message has been acknowledged. During a reset procedure 
the high level protocol is blocked from writing to the affected sub-channel until it acknowledges that 
it has received a reset indication from the network layer. This blocking prevents the high level protocol 
from inadvertently transmitting messages out of sequence in the case that it attempts to transmit before 
receiving a reset indication. After acknowledging the reset indication the session layer can retransmit 
all unacknowledged messages and any new messages it has to transmit since the reset. 3. Where the Boundary 
Becomes a RoadBlock... 3.1 Compilers and Code Creation Software for both processors is written in C. 
Thus many C features, such as data structures, could be shared by the modules running on each side of 
the processor boundary. One problem came from the structure padding that is done by the compilers. Padding 
is not consistent between the compiler used for the system processor and the one for the peripheral processor. 
As a result, the data structures shared by both modules have to be explicitly padded so that the alignment 
of members does not change.  3.2 Interface Shortcomings To send a message, the higher level protocol 
must execute the following steps: 1. Write the message to the data sub-channel, 2. Receive a data notification 
from the message service about the control channel, and 3. Read the message acknowledgement from the 
control channel.  This is a total of three system calls per message plus internal processing. 3. This 
can occur when the retransmission and error recovery procedures of the link layer are unable to correct 
a problem.  231 To receive a message, the higher level protocol must: I. Receive a data notification 
from the message service about the data sub-channel, and 2. Read the message from the data sub-channel. 
 Although this interface is fully asynchronous, the higher level protocol spends more of its processing 
time executing system calls than processing protocol data. Ideally, only three system calls would be 
needed, one to write data to the sub-channel, one to read data from the sub- channel, and one to read 
acknowledgments from the control chanhel. 3.3 Driver Shortcomings The protocol between the device driver 
and the peripheral processor software created very inefficient transactions. Each operation by the system 
software, (eg, a write request), requires two transactions, one to allocate buffers in the peripheral 
and one to write data into the buffers. In addition, transactions across the driver interface occur 
sequentially. Each side must wait for the current transaction to be acknowledged before initiating the 
next transaction. This driver/peripheral interface creates a synchronous coupling when most other operations 
on the two processors are asynchronous. 3.4 Performance The performance characteristics of the interface 
were studied by exercising it at three levels (refer to Figure 6): SESSION ! UtW.~ *Ut~l~ I UO~a~ IE 
   --®1i °. R Figure 6. Levels of Exercise for Performance Studies I. at the peripheral processor 
level with no device driver interaction, 2. at the device driver level with no higher level protocol 
interaction,  3. at the higher level protocol with no application interaction.  For these studies, 
the hardware interface to the communications link was bypassed by an in-memory loopback. 4 This eliminates 
the major bottleneck in the peripheral processor. First, the peripheral processor code was altered 
so that it generates its own data instead of receiving it via the driver. Under this circumstance, the 
peripheral processor (running the network and link layers), achieves a total throughput of 82.3K bits/sec.' 
Next, the peripheral processor and the device driver were exercised by a program that did no higher level 
protocol processing. Control data was ignored and the data notification service was not used. The message 
size used is 128 bytes. These conditions made the driver the bottleneck of the system. Total throughput 
for this case is 24K bits/sec. Finally, the full higher protocol was used to exercise the driver and 
peripheral processor. Messages sent by the higher protocol, also 128 bytes long, were generated internally 
to eliminate the application interface. This setup includes processing of the data notifications and 
control data. With this additional processing, throughput drops to I0.2K bits/sac. More measurements 
were made without bypassing the communications link. 6 Figure 7 shows peripheral processor throughput 
versus line speed when it was driven e, internally (ie, without the device driver), and I, by the device 
driver, but without higher protocol or control channel processing.[9] At the higher bit rates the throughput 
does not increase linearly because the peripheral processor can not keep up with the instantaneous volume 
of data. Using the device driver always results in lower throughput. At the  higher bit rates the device 
driver approaches its maximum throughput very quickly. At the lower bit rates the difference results 
from the synchronization mechanism between the higher layer and the network layer. Once the window of 
the network layer is full it must wait for acknowledgements from its peer to resume transmission. Its 
peer, however, must wait for the device driver to read each message before acknowledging. This added 
delay limits throughput. i 4. This is roughly equivalent to an infinite bandwidth link that consumes 
no processor time. 5. Thoughput was measured as the total data transmitted and received per second over 
full duplex data paths. 6. Multiply throughput values from the graph by four (4) to compare with results 
bypassing the physical link. The source of the data for the graph was a series of tests using two full 
duplex links (~£nes) simultaneously.  232 t5 I ] ! ! t0 i' a w  S 10 t5 20 25 LINE SPEED, Kbits/sec 
NO DEVICE DRIVER INTERFACE  WITH DEVICE DRIVER NOTES, 1. THROUGHPUT IS GIVEN PER LINE PER DIRECTION 
Z. HIGHEST MEASURED THROUGHPUT THROUGH THE DEVICE DRIVER, IN TESTS BY PASSING TIRE LINK, IS G Kbits/sec 
PER LINE PER DIRECTION Figure 7. Throughput versus Line Speed 4. Conclusions This implementation is 
designed for a system that does not have enough resources for executing it in either the system or peripheral 
processor. The resulting interface creates separate data and non-data channels that invite race conditions. 
The driver has an inherent limitation as to how many requests it can satisfy. Further, the structure 
of the interface makes heavy use of system calls, three for every message transmitted and two for every 
message received. This makes the boundary between processors the bottleneck of the subsystem. On the 
positive side, the placement of the layers balances the utilization of processors and provides good flow 
control and asynchronous operation. The implementation forced at least one protocol boundary to be totally 
transaction oriented due to the unfriendly interactions with a device driver. The high level protocol, 
residing on the system processor, provides services that lower layers cannot provide to users and insulates 
them from low-level failures. Even a failure of the peripheral processor is insulated from users since 
the high-level protocol acts as a central interface to the services of the lower layers on the peripheral 
processor. Further, as protocols become more complicated, either module at this boundary can be changed 
without change in the other. References I. International Standards Organization, "Reference Model of 
Open Systems Architecture" Document ISO/TC97/SC16/N227, June 1979. 2. Bell Laboratories, "OSN Communications 
Protocol Specification BX.25" Issue 3, June !982. 3. M.S. Sloman, "X.25 explained" Computer Communications 
Vol. I no. 6, December 1978. 4. "CCITT Recommendation X.25" Rev. 1980 (Yellow Book).  5. Kernighan 
&#38; Ritchie, "The C Programming Language" Prentice-Hall, Inc. 1978.  6. S.G. Chady, G.W. Lankford, 
D.E. Woolf, "A Multiprocessor Approach to New Microprocessor Applications" Proceedings of the 1980 Bell 
Laboratories /.Western Electric Microprocessor  Symposium. 7. F.M. Burg, "Design Considerations for 
Using the X.25 Packet Layer in Data Terminal Equipment" Proceedings IEEE INFOCOM April 1983.  8. F.M. 
Burg, "Standardizing the User Side of the  X.25 Interface" Computer Coz~municatdon$ Vol. 5 no. 5, October 
1982.  9. Comparable results for a different implementation were reached by L. Leske and D. Grothe, 
"Software Tailors Z80-based System to Interface Demands of X.25 Network" Electrondcs June 30, 1982. 
 5. Acknowledgements We would like to thank some of the many people who have contributed to this project; 
John Morris and Phil Wisoff, who were involved in the initial design, John Hutchinson, for fixing "the 
last bugs" in the high level protocol; G.W. Lankford, for his consultation and help in estimating code 
sizes, Harry Moore and Fred Burg for their protocol expertise, and finally, Andy Salazar, for his inspiration 
and support during the project and while producing this paper. 233  
			