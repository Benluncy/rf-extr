
 GRADIENT ESTIMATION FOR RATIOS Peter W. Glynn Pierre L Ecuyer Michel Ad&#38; Operations Research Department 
D6partement d IRO D.4partement de Math. et Info. Stanford University Universit6 de Montr&#38;d Universit4 
du Qu6bec ~ Montr+al Stanford, CA 94305-4022, USA C.P. 6128, SUCC. A C.P. 8888, Succ. A Montr&#38;d, 
H3C 3J7, Canada Montr6al, H3C 3P8, Canada ABSTRACT The ratio estimation problem arises in many different 
applications settings. This paper is concerned with the interplay between gradient estimation and ratio 
estima­ tion. Given unbiased estimators for the nnmerator and the denominator of the ratio, as well as 
their gradients, joint central-limit theorems for the ratio and its gradient are derived. The resulting 
confidence regions are of poten­ tial interest when optimizing such ratios numerically, or for sensitivity 
analysis with respect to parameters whose exact value is unknown. The paper also briefly discusses low-bias 
estimation for the gradient of a ratio. 1 INTRODUCTION Let (,4, B) be a pair of jointly distributed real-valued 
random variables. The estimation of the ratio a = E[A]/E[B] is known, in the simulation literature, as 
the m t io estimation problem. Such ratio estimation problems arise in many different applications settings. 
For example, it is well known that the steady-state mean of a positive recurrent regenerative stochastic 
process can be expressed as such a ratio of expectations; see, for example, Section 3.3.2 of Bratley, 
Fox, and Schrage (1987) or Chapter 2 of Wolff (1989). In Section 2 of this paper, we will discuss the 
ratio estimation problem in greater detail and offer addi­tional examples. It will turn out that the 
infinite-horizon discounted cost of a non-delayed regenerative process can also be expressed in terms 
of an appropriately chosen ra­tio estimation problem. This fact was first pointed out by Fox and Glynn 
(1989). Recently, the simulation community has devoted a great deal of attention to the use of simulation 
as an opti­mization tool. An important component of this research effort has been the development of 
estimation method­ology for computing the gradient of a real-valued per­formance measure with respect 
to a (finite-dimensional) decision parameter vector. Such gradients play an im­portant role in many iterative 
algorithms for performing both constrained and unconstrained mathematical opti­mization. This paper is 
intended as a study of the ques­tion of how to use this gradient estimation methodology in the setting 
of the ratio estimation problem. The paper is organized as follows. In Section 2, a number of different 
applications in which ratio estimation problems arise are discussed, and the mathematical frame­ work 
for the remainder of the paper is described. Section 3 is devoted to deriving a confidence interval methodol­ 
ogy for estimating the partial derivative of a ratio. In ad­dition, a joint central-limit theorem for 
the simultaneous estimation of the entire gradient is obtained. In Section 4, low-bias estimation issues 
are discussed. Finally, Section 5 discusses some experimental results related to gradient es­timators 
for ratios, and Section 6 concludes the paper with a brief summary. The proof of our main theorem (Theo­rem 
1) is given in the Appendix. The other proofs are not given here. A (future) more elaborate version of 
the paper will contain all the proofs, derive a joint central-limit the­orem that can be used to simultaneously 
estimate the gra­dient and the Hessian of mixed second-partial derivatives of a ratio, and provide further 
numerical illustrations. 2 EXAMPLES OF RATIO ESTIMATION PROB-LEMS As discussed in the introduction, 
the ratio estimation problem is concerned with the estimation of the ratio E[A] a = E[13] where (A, 1?) 
is a pair of jointly distributed real-valued random variables. We now proceed to offer several exam­ples 
of this estimation problem. EXAMPLE 1. Let X = {X(t), t ~ O} be a real-valued (possibly) delayed regenerative 
process with regenerative times O~ 7 (0) < T(1) . .... For z>1, let T(, ) ii, = lX(s)jds / T(I-1) T(c) 
A, = X(s)ds / T(i-1) B, = T(i) T(g 1). 986 If E[~l -FBI] < co, then it can be shown (see, for example, 
case T(F) would typically correspond to the system failure Asmussen 1987, or Wolff 1989) that time, and 
T(1) to a time at which the system is brought back to an as good as new state. Let lim: t X(s)ds a= (r= 
EIAl]/E[B,]. t-m t ~ Al = min[r-(F), T(l)] I B1 = IIT(F) < T(l)], Hence, as discussed in the introduction, 
the steady-state mean of such a process can be expressed as the ratio of where 1 denotes the indicator 
function. If P[r(F) < co] > the two expectations EIAI] and E[l?l]. 0 (note that this is equivalent to 
requiring that P[T(F) < EXAMPLE 2. Let X = {X(t), t z O} be a non-delayed T(l)] > O), it is easily shown 
that regenerative process, taking values in a state space S, with EIA1] regenerative times O = T(O) < 
T(l) < . . .. Let f and g =~ be two real-valued non-negative (measurable) functions defined on S, and 
set See Goyal et al. (1991) for additional details. Thus, the mean hitting time of a regenerative process 
can be formu­ t v(t) = g(x(s))ds lated in terms of the ratio estimation problem. J o EXAMPLE 4. Let 
X be a real-valued random variable cl . E exp[ V(t)]~(X(t) )dt . and let C be an event with P(C) > 0. 
Suppose that we [Jm0 1 wish to estimate Then, a is the infinite-horizon expected discounted cost, @ 
= E[x I c], the process g(X(t)) corresponds to the (state-dependent) namely the conditional expectation 
of X, given that the discount rate at time t, and ~(X(t)) is the (undiscounted) event C has occured. 
If E[l X 1] < co, then we can express rate at which cost is incurred at time t.A common choice a in terms 
of the ratio a = EIAl]/EIBl], where for g is the one in which g(.) is constant and equal to p >0, in 
which case Al = x I(c) B1 = I(c). (ICE exp[-pt] f (X(t))dt [./ o 1 Hence, conditional expectations are 
expressalble in terms of the ratio estimation problem. is the infinite-horizon p-discounted cost. Let 
Thus, the ratio estimation problem arises in a variety of different applications contexts. We shall nclw 
introduce a decision parameter vector 0 into the discussion. For each  1 = L:exp [-ltg(x(s))dsl$(x(t))d 
O G IRd, let Pe be the probabfity measure associated withcl = exp [ V(T(l))] the parameter value 0, and 
let EO be its ccmresponding BI = l cl. expectation operator. In addition, we shall permit the random 
variables A(0) and B(0) to depend explicitly on Because of the regenerative structure of X, it is evident 
 8 c R.d. Then, for each 8 c IRd, the ratio of expectations that a satisfies the equation a = EIAI] + 
EICl]a. Thus, if can be expressed in the form EICI] <1, it follows that a is finite and can be expressed 
as EIA1] a=~ Hence, the infinite-horizon discounted cost for a regenera-where u(O) = Ee[A(0)] and 1(13) 
= EoIB(0):I. Given our tive process can be expressed in terms of a ratio estimation above examples, computing 
the gradient of such a ratio problem; see Fox and Glynn (1989) for further details. a(0) is useful for 
sensitivity analysis or optimization of any of the following : steady-state costs or rewards in EXAMPLE 
3. Let X be a regenerative process as in regenerative processes; infinite-horizon disccmnted costs; Example 
2, and assume that X has right-continuous paths mean time to failure in reliability systems; conditional 
ex­with left limits. Let F be a non-empty subset of the state pectations and probabilities. space S, 
and let T(F) = inf{t ~ O I X(t) c F} be the first hitting time of the subset F. Then, 3 CONFIDENCE INTERVALS 
FOR GRADI­a = ENT ESTIMATORS OF RATIOS E[T(F)] Let (?oc lRd be fixed. In order for the gradient esti­is 
the mean hitting time of F. Such expectations are of mation problem to make sense, we shall require that 
both interest, for example, in the reliability y set ting, in which u(. ) and l(. ) have gradients at 
O = 60. We shall fur­ther assume that there exists unbiased estimators for not only U(OO1(8o), but also 
their gradients VU(OO ) and ) and VI(60 ). Focussing now on the i-th component of the gra­dient, we shall 
specifically assume that there exist jointly distributed random variables (A, B, C, D) such that E[A] 
= ?J(80) .E[B] = 1(60) where t3, denotes the partial derivative with respect to t?;, and 8, is the i-th 
component of 8. There is now a great deal of literature on various ways of constructing unbiased estimators 
for and 6 ,zL(OO)i3,t(O0). The two principal approaches that have been ex­plored are likelihood ratio 
gradient estimation (see Glynn 1990 for a survey) and infinitesimal perturbation analysis (see Glasserman 
1991). For links between the two meth­ods and for a general survey, see L Ecuyer (1990, 1991). We shall 
now assume that it is possible for the sim­ulator to generate a sequence {( A,, Bj, Cj, Dj ), j ~ 1} 
of i.i.d. replicates of the random vector (A, B, C, D). In each of the problem settings described in 
Section 2, this is typically straightforward. To estimate f(&#38;J)f3itt(OO) Boil L3,CY(60) = f2(oo) 
= ~j?t(do) Cr(OO)d:t(OO) qeo) the natural estimator to use is C. ffnDn Sa( n)= ~ , n where ,=1 and 
0 . = An/ B.. Our first proposition states that under reasonable con­ditions, &#38;i(n) is a consistent 
estimator for ~, cr(OO).The proof is straightforward and therefore omitted. PROPOSITION 1. Suppose that 
EIIA1 I + IBII + lCll + lD~(j < co and that EIB1] # O. Then, To develop a confidence interval methodology 
for ~i (n), we need a central-limit theorem (CLT) for the estimator. Let and note that under the assumptions 
of Proposition 1, E[ZJ] = E[Wj ] = O. This observation is an important element in the proof of the following 
theorem. THEOREM 1. Assume that E[Zf + W:] < W. If, in addition, the conditions of Proposition 1 are 
in force, then as n ~ CO, where E[W, -(EIDI]/E[BI])ZI]2 CT2= (E[B,])2 Theorem 1 has been previously established, 
using dif­ferent methods, by Reiman and Weiss (1989) in the con­text of likelihood ratio gradient estimation 
for regenera­tive steady-state simulation. Their expression for the vari­ance constant U2 is formally 
different, but algebraically identical. The final step needed to develop a confidence interval methodology 
for &#38; (n) is the construction of an appropri­ate estimator for a2. Let :5 [m-(waJz,]2 J=l v(n) = 
(Bn)z where -2, = AJ onQ, WJ = CJ crnDJ -&#38;(n)Bj. The next proposition gives conditions under which 
v(n) is strongly consistent for a2. The proof is straightforward and therefore omitted. PROPOSITION 2. 
Suppose that E[A~ + B: + C; + D:] < cm. IjEIBI] # O, then Iim v(n) a= a . ~ n-m We note that if v(n) 
is computed via a two-pass ap­proach in which cr~ and &#38;(n) are computed in the first pass through 
the data {(Aj, l?j, Cj, Dj), 1< j < n} and the sum of squares computed in the second pass, then it is 
essentially guaranteed that v(n) will be computed as a non-negative quantity on any finite-precision 
computer. More importantly, this means of computing v(n) is likely to be more stable numerically than 
that associated with the computation described in Reiman and Weiss (1989). We are now ready to describe 
a general confidence in­terval methodology for estimating partial derivatives of ratios. Suppose that 
we wish to compute a 100(1 $)~o confidence interval for ~i cr(OO ). We use the following pro­cedure 
: Algorithm CI. 1. Generate {( Aj, Bj, Cj, Dj), j > 1}. 2. Compute an and 6; (n). 3. Compute v(n) (using 
the two-pass approach de­scribed above). 4. Find z(6) such that PIN(O, 1) ~ z(6)]= 1 8/2. 5. Compute 
 Ln = 6t(n) -z(qym u. = 6,(.) + %(6)/-. m Then, [L., Un] is an (approximate) 100(1 6)% confidence 
interval for OiCY(OO). In particular, if the conditions of Proposition 2 are in force and U2 >0, then 
lim P[~:~(Oo) c [L~, U~]] = 1 6. n-co We conclude this section with a brief discussion of the problem 
of generating a confidence region for the vector (Cr(oo), txcr(oo), . . . . 6 da(OO )). A joint confidence 
region could be of potential interest in a number of optimization settings, since virtually ail iterative 
(deterministic) opti­mization algorithms choose their search direction, at each iteration, by considering 
the full gradient. Let C(Z) and D(i) be unbiased estimators for tltt(OO ) and tJ , /(00), so that E[c(a)] 
= a,u(eo) E[D(i)] = U(80).  If {( A3, B$, CJ(l), D~(l),. ... CJ(d), DJ(d)), 1 ~ j ~ n} is a set of n 
i.i.d. replicates of the random vector (A,l?, C(l), D(l) ,. ... C(d), D(d)), then the estimators cr~, 
&#38;(n), . . . . 6d(?Z) can be constructed from the sample in the obvious way, namely an = An/B. b_i(n) 
= (Cn( i) cYnD*(2))/Bn. Define Wj(i) = Cj(i) -cY(eo)Dj(i) 13,cr(eo)tlj. We are now ready to state 
a joint CLT for (an, 61(n), . . . . 6~(n)). THEOREM 2. Assume that EIA~+B~+C~(l)+D~ (l)+ 0.. + C?(d)+ 
D;(d)] <00. It E[13] # O, then fi[a~ cx(OO), 61(n) t% Q(OO),..., 6d(n) ~dcr(80)] E[.IA] + IV(O, C) 
 as n + co, where C = (C,j, O< i, j < d) is 01covariance matrix whose elements are given by coo = E[Z:] 
Coi = C,o = E [( l(i)  EIDl(i)lE[~l] )1 ZI ZI c,, = C,i =E [( l(i) EIDI (01 Z1 E[~,] ) EID1 (j)] 
~1 ( W1 (J  qq )1 forl<i, j~d. I The proof of this theorem mirrors that of Theorem 1 and is therefore 
omitted. A procedure for producing asymptotically valid con­fidence regions for (a(80), ~1 CY(80), . 
. . ~d@(60)) can now easily be derived, using the same ideas as those described earlier in this section 
for ~i a (OO ). We leave the details to the reader. 4 LOW BIAS ESTIMATION FOR THE GRA-DIENT OF A RATIO 
Since the gradient of the ratio is a nonlinear function of the expectations E[A], E[B], .EIC(l)], II[D(l)], 
. . . . E[C(rf)], E[D(d)], itfollows that the estimator 6,(n) is, in general, biased for ~,cY(OO). We 
will now proceed to (formally) derive a bias ex­pansion for ii, (n). The proof of Theorem 1 sk~ows that 
 w. (D./B.)z. 6,(n) = 13,cr(f30) (1) l?. We would like to approximate the expectation of that. We 
note that since &#38; is close to p ~f EIBI] for large n, we can use the power series expansion for j(z) 
= (1 z)-l to obtain + = +-(+]- = ,-1[1+(1-+)+(+2  +...] = - 1+(1-%)1 2,.-B. = fJ2 Using this approximation 
in (l), we find that 6,(TJ) -ihr(do) 2wn znDn Bnwn 2znDn = + P P2 -pBn 2wn znDn Bnwn 2znD.(2/l -B.)N 
i- P P2 P3 2wn znDn + Bnwn ~ 2znDnBn = _ (2) P flz P3 where &#38; = &#38; p. Recall that E[Wj] = E[Zj] 
= O. Observe that for i #j, .E[13, W3] = E[B:]E[Wj] = O, since B, and Wj are independent. Therefore, 
Similarly, E[i?nDn] = EIZ1 Dl]/n. Also, E[Zt Dj(Bk p)] = O whenever i # k. Therefore, JZIZ,DI (BI -p)] 
E[Z .D.I3.] = nz + (n -l) EIZ,(B, -f4)]E[D,] nz = EIZI BI]EIDIJ + o(l/n). n Now, taking the expectation 
in (2) yields E[6i (rL)] 6 ;CY(O~) ~ z~[zl&#38;]~[~l] @[Bl W, + ZID1] nps This bias approximation suggests 
an obvious means of re­ducing the bias of gradient estimators for ratios. The idea is to estimate the 
bias term and correct for it by subtract­ing off the estimated bias. In this case, this approach leads 
to the estimator where Z] and Wj are defined just before the statement of Proposition 2 in Section 3. 
Under appropriate regularity hypotheses, and by ap­plying techniques similar to those used in Glynn and 
Hei­delberger (1991), one can rigorously prove that $,(n) re­duces the asymptotic bias, in the sense 
that E[&#38;(n)] = 6 , cr(60) + o(l/n). A second approach that is frequently used to correct for nonlinearity 
bias of the above type is to jackknife the estimator. Specifically, for 1 ~ j < n, let k=l, k#J c, D3 
x-~n(j) x k=l, k#J ksll kjt~ () nn n %(,) = k=l, k+> = Wn(j) (n l),&#38;(j). %3) Then, J=l is the jackknife 
estimator for 6 ,CY(60). Also, -~iC2(O~)) fi(~t(n) * IV(O,1), sJ(n) where ,=1 is a consistent variance 
estimator. As in the case of the estimator &#38;(n), one can prove rigorously (under suitable regularity 
hypotheses) that the estimator 6,J(n) reduces asymptotic bias, in the sense that E[6~(n)] = ~,cr(eo) 
+ o(l/n). It turns out that the improved bias characteristics of these estimators are costless relative 
to the variance, in the sense that the estimators $, (n) and 6:(n) obey precisely the same CLT as does 
6,(n). Hence, the estimators exhibit the same degree of asymptotic variability. THEOREM 3. Assume that 
E[A~ +Bf+Cf +Df] < co and that EIBI] # O. Then, fi(&#38;(n) -atCY(&#38;J))+ aN(O, 1) @(b:(n) acl(eo)) 
= aN(o,1) where 02 is the same constant as in Theorem 1. ~ Table 1: Bias, Half-Widths, and Coverages 
of Confidence Intervals for 8 = 0.2 (cr(0) = 0.25 and a (d)= 1.5625) I n=l(l fJ = 100 n = 1000 bias half-width 
cover. bias half-width cover. I bias half-width­ cover, an -.010+.002 .129+.002 .77+.01 -.001+.001 .059+.001 
.90+.01 -.000*.001 .021+.001 .94*.01 cl: -.001+.002 .149+.002 .80+.01 -.000+.001 .061+.001 .90+.01 -.000+.001 
.021+.001 .94+.01 ti(n) -.401+.024 .914+.021 .43+.01 -.113+.013 .857+.014 .74+.01 \ -.004+.005 .391+.004 
.88+.01 6J(n) -.120+.035 1.345+.038 .52+.01 -.014+.013 .921+.017 .76+.01 -.001+.005 .395+.004  .88+.01 
 Table 2: Bias, Half-Widths, and Coverages of Confidence Intervals for O = 0.5 ( O) = 1.0 and n=lo bias 
half-width cover. bias ffn -.135+.009 .440+.005 .57+.01 -.019+.004 cl: -.036+.011 .634+.012 .65&#38;.01 
-.001*.004 6(n) -2.072+.050 1.692+.057 .26&#38;.01 -.407+.048 6J(n) \ -1.152+.089 2.6942c.084 .37+.01 
-.049+.063 5 A NUMERICAL EXAMPLE We will now illustrate some of the ideas developed in this paper with 
a numerical example. We consider the steady-state sojourn time of a customer in an M/M/l queue with arrival 
rate A = 1 and mean service time 0, where O < 0 < 1. The sojourn time is the sum of the time spent by 
a customer waiting for service, plus that customer s service time. Let X. = O and, for i > 1, let X, 
be the sojourn time of the i-th customer, starting from an empty system. It is well known that x, := 
(x,-l -2/,)+ + 0(,, where {VI, [I, VZ, ~z, . . .} is a sequence of i.i.d. exp(l) ran­dom variables. 
For this model, the mean steady-state so­journ time a(e) can be computed in closed form: a(e) = 0/(1 
 e). Hence, a (e) = 1/(1 0)2 This system regenerates when customers arrive to an empty queue. Consequently, 
as discussed in Example 1 of Section 2, the steady-state mean sojourn time of a cus­tomer can be expressed 
in terms of a ratio estimation problem, and the methodology of this paper is therefore applicable. It 
is also straightforward to apply the likeli­hood ratio method for gradient estimation to this problem 
a (0) = 4.0) n= 100 n= 1000 half-width cover. bias half-wic~ ~ -T-­.313+.004 ,82+.01 -.003+.002 .125+.001 
.92+.01 .339+.004 .84+.01 -.001+.002 .126+.001 .92+.01 2.333+.051 .57+.01 -.056+.019 1.493+.022 .81+.01 
2.919+.077 .63+.01 -.012+.020 1.541+.022 .82+.01 (see L Ecuyer, Giroux, and Glynn 1991), thereby obtain­ 
ing the required unbiased estimators for the numerator and denominator of the ratio (as discussed in 
Section 3). It turns out that while infinitesimal perturbation analysis can be applied to obtain strongly 
consistent steady-state gradient estimators for this problem, it fails to give unbL ased estimators of 
the gradient of the numeratc)r and of the gradient of the denominator of the regenerative ratio for­ 
mula. See Heidelberger et al. (1988) for further details. As a consequence, the theory of this paper 
is not applicable to the infinitesimal perturbation analysis steady-state gradi­ ent estimator for this 
problem. But on the other hand, the infinitesimal perturbation analysis derivative estimator is itself 
the estimator of a ratio of expectations, so that one can apply the standard theory relative to the construction 
of confidence intervals for ratios of expectations (Iglehart 1975, Wolff 1989). Tables 1 and 2 report 
the experimental results ob­ tained for this example. Simulation runs were carried out at two parameter 
values, namely O = 0.2 and O = 0.5, using n = 10, 100, and 1000 regenerative cycles. A to­ tal of four 
estimators were considered in this experiment, namely the ratio estimator rr~ for a(~) and its jackknifed 
analog o: (see Iglehart 1975), and the derivative estima­ tor 6(n) (Section 3) for o (O) and its corresponding 
jack­ knifed analo~ $J(n) (Section 4). Standard regenerative confidence intervrds were constructed for 
the estimator cr., and the confidence interval met hodology of Section 3 was used to analyze 6(n). For 
the jackknifed versions, confidence intervaJs were constructed based on the vari­ ance estimator (s (n))2 
given in Section 4. At each of the two parameter vahes and three choices of n (the number of regenerative 
cycles), a tot zd of 10,000 $J5~0 confidence intervals was replicated for each of the four estimators. 
From that, we are able to report estimates for the bias, ex­ pected half-width, and coverage (the probability 
that the quantity being estimated lies in the confidence intervrd), as well as 9570 confidence intervals 
for the bias, expected half-width, and coverages themselves. One can observe that for small n, for all 
estimators, the coverage is really lower that what is to be expected. This bad behavior gets worse when 
0 increases (heavier traffic). Jackknifing clearly reduces the bias significantly. It also gives a better 
coverage for small n, but usually at the expense of a wider confidence interval. For small n, the coverage 
is too low anyway. For larger n, jackknifing still helps reducing the bkis, but (perhaps surprisingly) 
does not improve the coverage significantly. Of course, this is just a particular illustration, and one 
must be care­ful about drawing any general conclusions from these nu­merical results. CONCLUSION Ratio 
estimation problems arise in many different ap­plications settings. When estimation is to be used to 
an­alyze the sensitivity of (or to optimize) a system in which the ratio estimation problem occurs, the 
results of this paper become pertinent. We have derived a numerically stable confidence interval procedure 
for computing partial derivatives of such ratios, and have developed the appro­priate joint CLT S necessary 
to extend this methodology to the computation of confidence regions for the full gradi­ent of the ratio. 
In addition, we have discussed low-bks es­timators for computing such partial derivatives. We have also 
described preliminary computational experience with some of the methods developed in this paper. ACKNOWLEDGMENTS 
The work of the first author was supported by the U.S. Army Research Office under Contract DAAL03-91­G-O1O1. 
The work of the second author was supported by NSERC-Canada grant rm. OCPO1100S0 -d F CAR 6..A no. EQ2831. 
APPENDIX Proof of Theorem 1. We note that  l%[6t(n)-acr(eo)] = C?. -O .D. -~iff(9~)B. = w. -(a. -Cr(el))pn 
= w. -(D./Bn)z.  = w. (EIDl]/EIBJzn -(Dn/Bn -EIDl]/E[B,])2.. Clearly, @Z. ~ (EIZ~])l/2N(0, 1) as n 
~ 00 and Dn/Bn ~ EID1]/EIB1] as n ~ co. It follows, by the converging-together principle, that fi (WE. 
 JqDl]/EIBl])z + o as n -cm. The CLT for i.i.d. random variables also proves that m (w. -(E[lA]/q&#38;])zn) 
+ J?qBl]aN(o, 1) asn+m. A second application of the converging­together principle then yields One final 
application of the converging-together principle (note that &#38; ~ .EIBI] as n ~ co) proves the theorem. 
 m REFERENCES Asmussen, S. 1987. Applied Probability and Queues, Wi­ley. Bratley, P., B. L. Fox and L. 
E. Schrage. 1987. A Guide to Simulation, Springer-Verlag, New York, second edi­tion. Fox, B. L. and P. 
W. Glynn. 1989. Simulating Discounted Costs. Management Science, 35, 1297 1315. Glasserman, P. 1991. 
Gradient Estimation via Perturba­tion Analysis, Kluwer Academic. Glynn, P. W. 1990. Likelihood Ratio 
Gradient Estima­ tion for Stochastic Systems. Communications of the ACM, 33, 10, 75 84. Glynn, P. W. 
and Heidelberger, P. 1991. Jackknifing Un­der a Budget Constraint. ORSA Journal on Comput­ing, To appear. 
Goyal, A., P. Shahabuddin, Heidelberger, P., Nicola, V. F., and Glynn, P. W. 1991. A Unified Framework 
for Simulating Markovian Models of Highly Depend­able Systems. IEEE Transactions on Computers. To appear. 
Heidelberger, P., X.-R. Cao, M. A. Zazanis, and R. Suri. 1988. Convergence Properties of Infinitesimal 
Per­turbation Analysis Estimates. Management Science, 34, 11, 1281-1302. Iglehart, D. L. 1975. Simulating 
Stable Stochastic Sys­tems, V : Comparison of Ratio Estimators. Navai Research Logi.rtics Quarterly, 
22, 553-565. L Ecuyer, P. 1990. A Unified Version of the IPA, SF, and LR Gradient Estimation Techniques. 
Management Sciences, 36, 11, pp. 1364-1383. L Ecuyer, P. 1991. An Overview of Derivative Estimation. 
In these proceedings. L Ecuyer, P., N. Glroux, and P. W. Glynn. 1991. Stochas­ tic Optimization by Simulation: 
Convergence Proofs and Experiment al Results for the GI/G/ 1 Queue in Steady-State. In preparation. 
Miller, R. G. 1974. The Jackknife A Review. Biometrika, 61, 1-15. Reiman, M. I. and Weiss, A. 1989. Sensitivity 
Analysis for Simulations via Likelihood Ratios. Op. Res., 37, 5, pp. 830-844. Wolff, R. 1989. Stochastic 
Modeling and the Theory of Queues, Prentice-Hall. AUTHOR BIOGRAPHIES PETER W. GLYNN is an associate professor 
in the Department of Operations Research at Stanford Univer­sity, Stanford, California. He received the 
Ph.D. degree form Stanford University in 1982. From 1982 to 1987, he was an assistant professor in the 
Department of Indus­trial Engineering at the University of Wisconsin-Madison. His research interests 
include stochastic systems, compu­tational probability, and simulation. He is an Associate Editor for 
Management Science, Stochastic Models, and Journal of Discrete Event Systems. PIERRE L ECUYER is an associate 
professor in the department of Informatique et Recherche Op&#38;ationnelle (IRO), at the University of 
Montreal. He is also associated with the GERAD research group. He received a Ph.D. in operations research 
in 1983, from the University of Mon­treal. From 1983 to 1990, he was a professor in the com­puter science 
department, at Laval University, Ste-Fey, Qu6bec. His research interests are in Markov renewal de­cision 
processes, sensitivity analysis and optimization of discrete-event stochastic systems, random number 
genera­tion, and discrete-event simulation in general. He is an As­sociate Editor for Management Science 
and for the ACM Transactions on Modeling and Computer Simulation. He is also a member of ACM, IEEE, ORSA 
and SCS. MICHEL ADES is associated with the University of Qu6bec at Montr&#38;l (UQAM), where he is teaching 
prob­ability and statistics in the Department of Mathematics and Computer Science. He is also a Ph.D. 
student in Elec­trical Engineering at McGill University and is associated with the GERAD research group. 
His research interests are in stochastic processes (where he published several pa­pers), simulation, 
and optimal control.  
			