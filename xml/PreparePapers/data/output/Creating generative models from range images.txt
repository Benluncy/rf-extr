
 Supplemental materials for this paper can be found in this directory. 3D point cloudbest approximation 
 construction of generative model model hierarchy curve editor modified object Figure 2: Overview of 
generative model creation. The algorithm takes range data in the form of a point-cloud and a generative 
model hierarchy as input. An appropriate model is then chosen, and parameters are optimized to output 
an accurate and concise generative model that can subsequently be edited. Compactness: Generative models 
provide a concise represen­tation; we need only store an algebraic model description, and con­trol points 
of the model s parametric curves. This representation can be orders of magnitude smaller than a triangle 
mesh. Intuitiveness: Since the model is expressed in terms of para­metric curves corresponding to logical 
features of the object, it is easy to understand, manipulate, and edit. Related Work Many methods have 
been explored, especially in computer vision, for recovering object shape for speci.c primitives such 
as gener­alized cylinders [1, 15], superquadrics [16, 23] and blended de­formable models [7]. Terzopoulos 
and Metaxas [24] have proposed a computational physics framework for shape recovery in which globally 
deformed superquadrics model coarse shape and local de­formations add .ne detail. Superquadrics have 
also been used for model-based segmentation [9, 11], and for recognition of geons using relationships 
between superquadric parameters [19, 27]. De-Carlo and Metaxas [8] introduced shape evolution with blending 
to recover and combine superquadrics and supertoroids into a uni.ed model. Debevec et a. [6] considered 
architectural scenes and devel­oped a system for recovering polyhedral models from photographs. Our approach 
is somewhat more general than these previous al­gorithms in that it is based on a general user-speci.ed 
generative hierarchy rather than a particular parametric model. This allows automatic construction of 
more complex and varied shapes, with­out segmentation, than is possible with current computer vision 
al­gorithms. Further, many standard primitives used in computer vi­sion can be recovered using our method 
since generative models are a superset of traditional shape representations such as globally deformed 
superquadrics, straight homogeneous generalized cylin­ders, and blended deformable models, all of which 
have been re­covered using our system. Our method is also automatic, with no user intervention required. 
However, model-speci.c algorithms, especially those that allow user-intervention, may out-perform our 
algorithm on the shapes to which they apply by exploiting model­speci.c information. For instance, by 
considering only polyhedral models, and having the user manually specify the edges of interest, Debevec 
et al. [6] are able to work with only photographs, while we require range data. This paper deals primarily 
with shapes represented by a sin­gle generative model. At present, we do not add local detail [24], nor 
address automatic model-based segmentation [8, 9, 11] or im­age interpretation [3]. However, our results 
suggest that generative models may be useful for these tasks in lieu of superquadrics or generalized 
cones. In contrast to some object recognition methods [19, 27],which estimate speci.c model parameters 
to classify an object as a mem­ber of some class, our method .rst determines which degrees of freedom 
in the model hierarchy are most suitable for the acquired data, and then re.nes the associated parameters. 
Recent work on simplifying polygonal meshes shares one of our objectives providing a more compact representation. 
For ex­ample, Hoppe et al. describe techniques to optimize meshes [13], while Eck and Hoppe [10] and 
Krishnamurthy and Levoy [14] .t spline surfaces to dense meshes. However, mesh-based methods do not yield 
compact high-level models. The rest of this paper is organized as follows: Section 2 gives an overview 
of our algorithm and describes our framework for re­covering the appropriate model within a user-speci.ed 
hierarchy. In section 3, we discuss our methods for optimization. Section 4 brie.y outlines the various 
models used in our tests. In section 5, we discuss our results and section 6 presents our conclusions 
and directions for future work. 2 Algorithm Framework In this section, we give a high-level overview 
of the entire algo­rithm, pictured in .gure 2, and describe our method for automati­cally choosing the 
appropriate generative model from within a user­de.ned class. This is essentially a recognition task 
as it requires the measured data to be classi.ed as one of the models in the user­speci.ed hierarchy. 
The recognition process is based on a simple tradeoff between accuracy and simplicity. For ef.ciency, 
a greedy algorithm is employed that starts with the simplest model in the input hierarchy, and then considers 
more complex models at the next level in the hierarchy. The system selects the model provid­ing the greatest 
bene.t, and repeats the process in a greedy fashion, moving through the hierarchy from simple to more 
complex mod­els. The process stops when none of the more complex models signi.cantly improves the accuracy, 
or the most complex model is reached. Although the .rst model that is .t to the data is trivial, the 
algorithm then bootstraps itself by using information obtained in .tting previous models, improving at 
each stage until an accurate and suitably complex model is recovered. For illustrative purposes, we will 
often refer to the speci.c hierarchy shown at the bottom of .gure 2 and on the left of .gure 8, which 
is inspired by the spoon model created by Snyder [21, p. 83]. The model hierarchy has several levels. 
For our class of mod­els, the root node of the hierarchy is level zero, which consists of a half-cylinder 
with two global parameters controlling width and depth. This object essentially de.nes a bounding volume 
for the data. Deeper levels consist of re.ning one or more of the param­eters by representing them as 
curves instead of global values. In general, one curve is added at each level so the number of curves 
corresponds to the level. For example, the edge to the depth node in .gures 2 and 8 corresponds to re.ning 
the depth parameter by representing it as a curve. The hierarchy can also be thought of as a tree; going 
from parent to child corresponds to adding a single curve. For instance, the root is the parent, while 
the model with re.ned depth is the child. The tree representation implies an order in which curves are 
added. The curve providing the most bene.t is added .rst, and a child node inherits initial parameter 
estimates from optimized results for the parent node. Input to the System: Part of specifying the model 
hierarchy is to supply functions that perform the following tasks. Initial Guess for Root Model: Starting 
values must be sup­plied for the parameters of the root model, which typically consists of a simple primitive 
object. The initial values for both the intrinsic parameters and the extrinsic parameters (translation, 
rotation, and scale) of the root model may be very crude, since they merely provide a starting point 
for sub­sequent re.nement and optimization. Parameter estimates for more complex models are obtained 
automatically from those of the parent model in the tree.  Model Evaluation: A function must be supplied 
to evalu­ate any model in the input hierarchy at given uv-parameters. Ef.cient routines can be automatically 
generated from an al­gebraic model description.  Curve Constraints: The model hierarchy may optionally 
contain additional constraints on the curves in the .nal model, such as .xing their values at speci.c 
points, or penalty terms to ensure, for instance, that a particular curve remains positive everywhere. 
 This information is encapsulated as user-supplied functions along with the code that de.nes the model 
hierarchy. Thus, the algorithm may proceed without any manual user intervention. A summary of our algorithm 
is shown in .gure 3. Below, we discuss each step in detail. The reader may wish to refer to the results 
in .gure 8 and the left of .gure 9 for examples of applying the algorithm. Step 1. Acquire Range Data: 
We have used a number of dif­ferent methods to acquire range data for our experiments, including two 
structured light techniques a method which uses a sequence of alternating dark and light patterns projected 
onto the object [25], and the highly portable method described by Bouguet and Perona, in which shape 
is inferred from the shadow of a rod swept over the object [2]. We have also used a mechanical probe 
and a laser range scanner. This variety of sources demonstrates that our algorithm is amenable to a wide 
assortment of data acquisition methods. Overview of the Algorithm Figure 3: Overview of the algorithm 
with the greedy algorithm used for recognition highlighted. Step 2. Fit to root model: Initialize: Let 
. denote our current model initially the root node of the hierarchy. The root node s intrinsic and extrinsic 
parameters are initialized using a user-speci.ed function.  Optimize: An error-of-.t function f is computed 
based on the spatial deviation between the data and the model as de­.ned in equation 4. Optimization 
is used to adjust the root node to minimize the error-of-.t. Details are given in the next section. 
 Cost: After minimization, f is used to compute the deviation D which represents the RMS distance between 
model and data as de.ned in equation 5. The total cost C is initialized to this deviation.  Step 3. 
Fit children to Data: For each child of the current model ., denoted by .i(.), we calculate the deviation 
D(.i)after optimization. For instance, if . = root, the children are .1 = shape,.2 =depth,.3 =bend. We 
then calculate a cost function for each child: C(.i)=D(.i)+.(.i), (1) where . is a penalty for model 
complexity. We use a very sim­ple but effective heuristic to assess the complexity of a model: .(N)=NQ 
where N is the level in the hierarchy of a speci.c model and Q is a constant that allows the user to 
control the trade­off between simplicity and accuracy. In progressing from the current model . to a child 
.,we add a single curve. The entire process is explained in detail with results in subsection 3.3 on 
curve re.nement. The steps are: Initialize: Initial parameter estimates for .are set to param­eter values 
of its parent .. The new curve to be added is initialized to a constant inherited from ., and control 
points are added at the ends.  Optimize: A .rst optimization step yields a coarse curve estimate. In 
all optimization steps, all model parameters are simultaneously varied to minimize the objective function 
in equation 4.  Re.ne: A few interior control points are automatically added based on the heuristic 
de.ned in equation 16.  Optimize: Optimization is repeated with the additional con­trol points added, 
which improves the quality of the new model.  Cost: We compute the deviation D using equation 5 as in 
step 2, and use equation 1 to compute the total cost of ..  Step 4. Reset .: The previous stage calculated 
the cost function for all the children of .. If the child with lowest cost C(.i(.))has a lower cost than 
., we make it the new best .t (. =.i) and go back to step 3. Otherwise, exit to step 5. For ef.ciency, 
we use a greedy algorithm to choose the best model. We consider only the descendants of the current model 
.to choose the next model. Conversely, a node is considered only if it is linked to the best guess .at 
some point. Thus, curves are added in order of importance, with the one reducing the objective function 
the most added .rst. This approach works best when a particular curve is clearly more important than 
other choices, or when curves may be re.ned in any order with similar results. In cases where two curves 
produce similar results early on, but one branch later proves to be clearly superior, a more exhaustive 
search algorithm with backtracking would achieve better results. Steps 2-4 constitute the Recognition 
Phase of the algorithm where an appropriate model is chosen by identifying a path through the model hierarchy 
as shown in .gure 8. The goal is to quickly choose the appropriate model in the hierarchy i.e: to identify 
which curves and deformations are required to model the data. Since this process merely chooses a suitable 
model, it is appropriate to repre­sent the curves at a coarse level of detail. However, since we wish 
to eventually recover an accurate .nal model, we further re.ne the recognized model .in the next step. 
Step 5. Re.ne curves further and add curve constraints: Re.ne: Using the heuristic in equation 16, control 
points are automatically added where necessary. More control points are added than in the re.ne phase 
of step 3 above, as this allows the curve to be represented at a .ner resolution; the number of control 
points used is given by equation 19.  Curve Constraints: We then add user-speci.ed constraints to the 
curves such as .xing the values at the end-points. Typ­ically, these constraints improve the visual accuracy 
of the .nal model, but have little impact on the overall shape.  Optimize: Optimization is used to get 
a re.ned model.  Step 6. Smoothness: Finally, we add a term given by equa­tion 21 to the objective function, 
which enforces smoothness of the curves, and repeat the optimization process. This reduces kinks in the 
model that result from over-.tting noisy input data.  3 Optimization In this section, we describe our 
optimization techniques for .tting a model to measured data. First, we de.ne an objective function to 
assess the deviation between data and model, and describe a pro­cedure for ef.ciently computing the gradient 
of this function. We then describe methods for re.ning local features of the model. 3.1 Error of Fit 
To de.ne a practical measure of .t between a model and the corre­sponding data, we begin with the notion 
of such a measure for two arbitrary surfaces. For any point x . R3 and subset S . R3,let .(x,S)= inf|| 
x - y || , (2) y.S where ||·|| is the Euclidean 2-norm, which is the distance from x to the surface S.If 
S1 and S2 are two integrable surfaces in R3 , we de.ne a symmetric measure of closeness by .2.2 f(S1,S2)=(x,S1)dx 
+(x,S2)dx, (3) S2 S1 which is zero if and only if S1 = S2. This function imposes an equal penalty for 
either surface deviating from the other, or for ei­ther surface covering too little of the other. If 
S1 and S2 are discrete point sets with unit weight, this becomes f(S1 ,S2 )=.2(x,S1 )+.2(x,S2 ). (4) 
x.S x.S 21 Moreover, if S1 . S1 and S2 . S2 are sets of discrete samples from the respective surfaces, 
then f(S1 ,S2 )can be used to ap­proximate f(S1,S2). To determine how well a generative model matches 
an actual object, we employ two point sets in exactly this manner, as equation 3 is typically impossible 
to evaluate exactly 1 . One point set is obtained from direct measurement, such as a range image, and 
the other by sampling the parameter space of a model. By optimizing with respect to this objective function, 
we in effect minimize the RMS deviation of the two surfaces: f(S ,S ) D(S1,S2 )=12, (5) |S | +|S | 12 
where |S| denotes the number of elements in the set S.  3.2 Computing the Gradient Since a generative 
model is typically a nonlinear function of its constituent curves, we use a general optimization technique 
to esti­mate the model s shape parameters. For simplicity and ease of im­plementation, we use a conjugate 
gradient method [18] to minimize the functional f(Sd ,S )with respect to the model parameters. Let m 
S denote the .xed data, and S the model samples, which depend d m on intrinsic shape parameters as well 
as extrinsic parameters con­trolling translation, scale, and pose. Speci.cally, =S Smm(c0,c1,...,ck,t,q), 
where c0,c1,...ck are model parameters, such as global deforma­tions and the y-components of curve control 
points, t . R3 is the 1Simple analytic formulae for . are seldom known, and numerical evaluation, though 
precise, is typically too slow for the inner loop of an optimization algorithm. global translation, and 
q is a quaternion encoding global scale and rotation. Thus, optimization is guided by gradients of the 
form .f .f .f .f.f .f = , ,..., ,, . (6) .c0 .c1 .ck .t .q To compute this gradient, .rst observe that 
|S m| .f .f.xi (Sd,Sm)= , (7) .cj .xi .cj i=1 where x1,x2,... are elements of Sm. Because .f/.xi and 
.xi/.cj are row and column vectors of dimension three, respec­tively, the summation is over inner products. 
We next express the partial derivatives of f in equation 7 in terms of the nearest neigh­bor function 
.d : Sm . Sd,where .d(x) is the element of Sd nearest to x . Sm. The function .m : Sd . Sm is de.ned 
analo­gously. Then, equation 4 becomes f(Sd,Sm)= || x - .d(x) ||2 + || y - .m(y) ||2 . (8) x.Sm y.S d 
Since the nearest neighbor functions are piecewise constant, their derivatives are zero almost everywhere. 
Hence 1 .f =[x - .d(x)]T +[x - y]T , (9) 2 .x -1 y..(x) m for all x . Sm, where the inverse relation 
.-1(x) denotes the set m of points in Sd whose nearest neighbor in Sm is x. The nearest­neighbor correspondences 
are ef.ciently computed using a kd-tree updated at each major iteration of the conjugate-gradient solver. 
Suppose now that c is a control point of a curve G. Then, to compute .x/.c, we must account for the composition 
of nonlinear transformations that may be applied to the curve as part of the cur­rent model. For example, 
suppose that the point x is obtained by evaluating the model at the parameter values u and v.Then x(u,v)= 
F(u,v,G(u; c1,...,cq)), (10) where, F(u,v,·): R . R3 is the parametric mapping de.ned by previous levels 
in the model hierarchy and applied to curve G;we assume G to be a function of the parameter u as well 
as the control points c1,...,cq. It follows that .x(u,v) .x(u,v) .G(u) = , (11) .c .G(u) .c where .x/.G(u) 
is the 3×1 Jacobian matrix of F at the parameter values u and v. The partial derivative on the right 
of equation 11 is easily evaluated, given that G is simply a spline curve. The par­tial .x/.G(u) can 
be evaluated symbolically by differentiating the current model. We have found that numerical approximation 
by a .nite difference is equally effective, and may be simpler to com­pute. Thus, we can also use .x(u,v) 
F(u,v,G(u)+ h) - F(u,v,G(u) - h) , (12) .G(u)2h where h is a suitably small step. When c is a global 
parameter, controlling a bending deformation for example, .x/.c is obtained directly from the algebraic 
model speci.cation using either sym­bolic or numeric differentiation, and the second factor on the right 
of equation 11 is no longer necessary. The extrinsic parameters t and q map canonical model coordi­nates, 
in which the computations are initially performed, into the world-space coordinates of the measured data, 
in which the gradi­ent .f is computed. More precisely, x = t + M(q)x0, (13) where the point x0 is in 
canonical coordinates, and M is a scale and rotation matrix parametrized by q. All partials of x are 
also transformed by .x .G(u) = M(q) .x0 .G(u) . (14) Finally, to compute .f/.t and .f/.q in equation 
6, we substitute partials of x with respect to t and q in place of .x/.cin equation 7, where .x .x dM 
= I and = x0. (15) .t .q dq Here I is the 3 × 3 identity matrix, and the derivative of each ele­ment 
in the matrix M with respect to q is itself a quaternion. Equa­tion 7 becomes a summation over row vectors 
or quaternions after the respective substitutions. procedure ComputeGradient Use new point correspondences. 
1 P.Ø 2 for all x . Sm and y . Sd do 3 add (x,.d(x)) to P 4 add (.m(y),y) to P 5 endfor Compute E, extrinsic 
&#38; global partials. 6 g . 0; E . 0 7 for all (x,y) .P do 8 (u,v) . parameters of x 9 w . 2(x - y)T 
Eq. 9 10 p . w [.x/.c0] Eq. 7 11 g . g +[p 0ww .Eq. 7, 15 Mx0] 12 Eu . Eu + w [.x/.G(u)] Eq. 16 13 endfor 
Fill in partials wrt control points. 14 for all u samples do 15 for each cj affecting G(u) do 16 gj . 
gj + Eu [.G(u)/.cj] Eq. 17 17 endfor 18 endfor 19 return g Figure 4: Computing the gradient g of the 
objective function f.We as­sume a single curve G with control points c1, c2,..., ck, parametrized with 
respect to u. The parameter c0 is assumed to be a global shape parameter. The model is sampled at discrete 
parameter values in u and v. Ef.ciency: From equations 6, 7 and 9, it appears that the gra­dient computation 
requires O(nk) time per curve, where n is the number of sample points, and k is the number of shape parame­ters 
controlling a curve. By exploiting sparsity, we can reduce the time to essentially O(n) since each sample 
point of the model is affected by only a small number of shape parameters. In particular, when c1,c2,... 
are control points, their effects are very localized, so each .G(u)/.c in equation 11 is nonzero only 
for a small num­ber of shape parameters c. 0.1 0.05 0 -0.05 -0.1 -0.15 -0.2 -0.25 0.05 0 -0.05 -0.1 
-0.15 -0.2 -0.25  20 18 16 14 12 10 8 6 4 2 0  -1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1 -1 -0.8 -0.6 
-0.4 -0.2 0 0.2 0.4 0.6 0.8 1 -1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1 Figure 5: The process of curve 
re.nement. Left: Depth curve of spoon model as control points are added in recognition phase. The straight 
blue dotted line is the global value at root node, and the blue dotted curve is the initial coarse version. 
The red dashed curve results after adding four control points shown by circles, which greatly improves 
the approximation. For comparison, the .nal curve is shown by a black solid curve. Middle: Further re.nement 
of the depth curve. Constraints force the curve to be 0 at the end-points and additional control points 
increase the accuracy of the curve, but also introduce undesirable kinks. These are essentially eliminated 
in the smoothed version shown with a solid line on the left. Right: The blue dash-dot curve indicates 
the initial error heuristic before any interior control points are added and the red solid line indicates 
the error after re.nement and optimization. The optimized version has a much lower and .atter error according 
to the heuristic. The pseudo-code in .gure 4 summarizes the gradient computa-3.3 Curve Re.nement tion. 
Here, g denotes the gradient, which is a row vector, w is a Each curve is adaptively re.ned during optimization. 
Re.nement contribution to the row vector .f/.x, as de.ned in equation 9, and in this context differs 
from previous curve-.tting approaches in sev­eral ways. First, generative models are composed of spline 
curves .f .f.x(u,v) Eu == (16) with local control, whereas optimization techniques typically used .G(u) 
.x(u,v) .G(u) v in computer vision entail global shape parameters. Secondly, the curves of a generative 
model describe characteristics of a 3-D sur­is a scalar associated with the parameter value u. The summation 
face rather than approximating sets of 2-D points [17]. Our ap­in equation 16 is over the discrete samples 
of v. Finally, we have proach to curve re.nement most closely resembles the techniques for optimizing 
trajectories used in animation [4, 20]. .G(u) .f = Eu , (17) When a curve is added during the recognition 
phase in step 3 of .cj .cj .gure 3, it is initialized to a constant with a global parameter inher­u ited 
from the parent node in the model hierarchy. Multiple control where the summation is over discrete samples 
of the u parame-points are added at the ends to construct a valid spline curve. After ter. The computation 
is broken down in this way for ef.ciency. the .rst optimization pass, four or .ve additional interior 
control Note that the .rst element of the gradient vector g is a partial with points are added and optimization 
is repeated. See .gure 5. During respect to global parameter c0, while the next k elements of the recognition, 
a coarse approximation of the curve suf.ces, as it is gradient are partials with respect to curve control 
points. The con-used only to choose a suitable model in the hierarchy. struct [p 0ww .Our approach to 
curve re.nement is to add control points gradu- Mx0] in line 11 of the pseudocode denotes the ally, and 
only where needed. We use Eu, as de.ned in equation 16, concatenation of the elements into a single row 
vector, where the .as an error term for a curve G, and insert new control-points that zero vector 0 
has k entries, and M is the derivative of the scale and equidistribute the error; that is, we select 
the points so segments rotation matrix with respect to the quaternion q. between them have equal net 
error. In this algorithm, we recompute the point correspondences us-Since .f =0 at a minimum, .f/.c =0 
for all c. As the num­ing a kd-tree2. We then loop through all the point pairs computing ber of control-points 
increases, Eu approaches .f/.c for some the contributions to Eu, the partial with respect to the global 
pa­control point c, and is therefore 0 when the curves are represented rameter c0, and the partials with 
respect to the extrinsic parameters exactly. A large |Eu| indicates that the approximating curve needs 
t and q. Rather than explicitly computing the set .-1(x),as shown m re.nement. We can also use a variational 
argument. Since f atin equation 9, we simply accumulate the contribution of each data a minimum should 
be 0 to .rst order for variations in the curve point in a single pass through the point set. G, |Eu| 
is equivalent to the Euler-Lagrange [20, 28] error, which should be 0 when the curve is represented precisely. 
The error fDiscussion: The objective function f described above is fairly by itself does not necessarily 
indicate where curves need re.ning, crude as it depends on the distribution of sample points, and the 
as the model may be fundamentally incapable of representing the nearest neighbor function may fail to 
make the most meaningful data; this is especially so for simpler models in the hierarchy. correspondences. 
Further, we do not interpolate between sample points for greater accuracy, nor do we use connectivity 
information Producing the Final Curves: In step 5 of the algorithm available in the model. While physically-based 
heuristics such as shown in .gure 3, we re.ne the curves further and add constraints. momentum and inertia 
can improve the situation somewhat [24], First, we compute the total error normalized by the size of 
the data our simple objective function suf.ces to guide the traversal of the set separately for each 
curve: model hierarchy for the examples described in this paper. 2Actually, this is done earlier as 
a result of evaluating the objective function. |Eu| E = u (18) |S. Sm| d Based on this total error, we 
calculate the number of control-points we wish to add to each curve using the heuristic E Nc = , (19) 
E which adds one control point for each E of error. We have found that a value of E =10-3 is suitable 
for objects of unit dimensions. The control points are again added to equidistribute the error. Then, 
user-speci.ed constraints such as curve end conditions are added. Refer to the middle of .gure 5 for 
an example. The objective func­tion is minimized again to yield a high-accuracy solution satisfying the 
constraints. In the .nal stage, step 6 in .gure 3, we ensure that noise in the data does not lead to 
extraneous kinks in the model. We do this by introducing a penalty based on the integrated curvature 
ß given by ß = |.(u)| du, (20) u where .(u)is the curvature of Gat the parameter value u. We esti­mate 
ß using numerical quadrature and approximate the derivatives of ß with respect to the curve control points 
using .nite differences. These values are summed over all curves in the model. The objec­tive function 
is then augmented with an extra term f =f +aß, (21) where a is a positive weight chosen so that the smoothness 
term and the original objective function are of approximately the same magnitude. Thus, f0 a =K, (22) 
ß0 where the subscript 0denotes the value after step 5 in the algorithm framework, but before optimizing 
with respect to the augmented objective function. Here, K is a constant that controls the relative importance 
of the two terms, which was .xed at 10 in our tests.   4 Model Hierarchies Used This section brie.y 
reviews the model hierarchies used in our ex­periments. The hierarchy for the spoon is patterned after 
the model given by Snyder [21, p. 83]. The generative modeling equation is .. sx(v) spoon(u, v)= . arcx(sy(v), 
dy(v),u) . , by(v)+arcy(sy(v), dy(v),u) where s is the width or shape curve, d is the depth curve, and 
b is the bend, parametrized so sx =dx =bx. arc(a, b, u)de.nes a parametric arc passing through (-a, 0), 
(0,b),and (a, 0)in the xy-pane. The above equation is obtained at the deepest level of the hierarchy, 
regardless of the path, since all the operators commute. In the root model, s and d are global parameters 
and b is 0.As more complex models are reached, these constants are replaced by curves. Curves are constrained 
for this model so that s and d are 0 at the end-points, where s is also perpendicular to the x-axis; 
since the model is symmetric about the x-axis, this last constraint avoids introducing a kink. To complete 
the representation, we also require a thickness. Since the thickness is typically small and dif.cult 
to discern from range data, we use a constant value derived from the projection of the acquired data 
in the yz-plane. For a ladle-like shape, the arcs are translated by the bend only after .rst rotating 
them about the y-axis by an angle equal to that of the bend curve from the horizontal. This forces the 
arcs to remain perpendicular to the bend curve. A shape suitable for a cup handle is obtained by making 
the circular cross-section arc rectangular. 3 We also used a rotating generalized cylinder the banana 
model de.ned by Snyder [21, p. 69] to represent many differ­ent objects. This model rotates a cross-section 
while scaling and translating it, and generalizes common primitives in computer vi­sion known as pro.le 
products or simple homogeneous generalized cylinders. The parametric equation is .. S(v)Cx(u) banana(u, 
v)= yrot(R(v)). S(v)Cy(u) . Z(v) where yrot(.)is a rotation of . about the y-axis, R is the para­metric 
rotation angle, S the scale, and C the 2D cross-section. The root model is a right circular cylinder 
with unit radius and no ro­tation. The curves R, S,and C are added at more complex levels in the hierarchy. 
This class of models can also be used to represent surfaces of revolution, such as the bowl example that 
is shown. As the previous model hierarchy demonstrates, our approach subsumes some common primitives 
used in computer vision such as simple homogeneous generalized cylinders. We have also recov­ered globally 
deformed superquadrics with our approach. Figure 6: Fitting of a blended model [7] to synthetic randomly 
perturbed samples of a sphere/torus blend with variable cross-section. This example shows how blended 
models .t directly into our framework, with the blend curve being treated like any other generative curve. 
It also shows that non­spherical and variable topology can be handled. The model eliminates most of the 
noise in the data without introducing signi.cant errors. The leftmost image is the initial model, which 
is simply a sphere. To the right are two views of the rough input data and the smooth .nal model. DeCarlo 
and Metaxas [7] present a method for using blended deformable models. Models of variable topology can 
be created us­ing their method. Their ideas .t directly into our framework since the blend curve is just 
another curve in the generative model. Since our objective function does not directly consider topology 
at all, no effort is needed to incorporate variable topology. We note that DeCarlo and Metaxas require 
certain constraints on the blending function to obtain a consistent model, which are naturally incorpo­rated 
into the curve constraints phase of our algorithm. The general formula for a blended model [7] is blend(u, 
v)=G(u)b1(u, v)+(1- G(u))b2(u, v), 3The actual handle is not exactly rectangular, leading to the overly 
squared results. The data is also too sparse to reliably estimate the cross-section from scratch. where 
G is the blending curve that can be treated just as any other curve in the generative model. Here b1 
and b2 are simply con­stituents of the generative model, which can be any shape at all, in­cluding as 
a special case, the superquadrics and supertoroids used in [7]. Figure 6 shows an example of recovering 
blended models with our approach. Although this paper deals primarily with shapes that can be rep­resented 
by a single generative model, we have carried out some experiments on simple articulated objects. The 
watering-can in .gure 1 was modeled by .rst manually segmenting it into body, handle and spout, and then 
.tting a rotating generalized cylinder to each part. Minor imperfections are primarily due to errors 
in segmentation. We may also de.ne a single composite generative model by combining existing parts, each 
controlled by separate ex­trinsic and intrinsic parameters. The cup in .gure 1 is an example. If the 
extrinsic transformations of the individual parts are left free and not constrained to ensure correct 
connectivity the user may need to make some minor adjustments at the end to ensure the parts connect 
properly. While the user-supplied initial guess function can still be crude, it needs to be more accurate 
for an articulated object since a data point can otherwise be incorrectly associated with the wrong model 
part. 5Results Parameters: For our tests, the complexity constant Q de.ned below equation 1 was set to 
a deviation of .01 after scaling the models to have a major axis range from -1 to +1. Thus, Q cor­responds 
to a percentage error of approximately .5%. The results demonstrate that the algorithm is not very sensitive 
to the precise value of Q. We report the percentage error using a 64×64 tessella­tion of the model. For 
illustrative purposes only, both range images and the model were meshed to create the .nal images for 
display and colors are arti.cial. Snyder [21] describes alternate methods to image generative models 
without mesh creation, but at the cost of loss of interactivity. Data: The range data used in our experiments 
was obtained from a variety of sources. Of the objects in .gure 7, the spoon and bowl data are single 
range images obtained using structured light [25], while 6 cylindrical scans are aligned for the cup 
data. The ladle is a single range image obtained using the method of Bouguet and Perona [2]. Data for 
the banana and candle-holder were obtained using a mechanical probe, and the watering-can data is a cylindri­cal 
scan obtained from a laser range-scanner. For the data obtained from the probe, connectivity information 
was not available, so the meshes for the .gures were obtained using the approach of Hoppe et al. [12]. 
Our algorithm operated directly on the range data, and the results demonstrate the bene.t of recovering 
a model as op­posed to a mesh, especially in cases of noisy and incomplete data. Recognition Trees: Figure 
8 shows recognition trees for two objects a spoon acquired using structured light, and synthetic data 
for a banana-like object. Data on errors are given in .gure 9. The root models are trivial, and the user-supplied 
initial guess func­tions need not specify accurate initial estimates; nonetheless the algorithm is able 
to bootstrap itself to produce an accurate .nal model. Paths that are not ultimately selected can sometimes 
pro­duce strange and interesting results as a curve is trying to adjust to match data that it is incapable 
of matching. This effect will be especially noted in the tree for the banana. Accuracy and Robustness: 
A visual comparison indicates that the method produces a good match to the data, even when the data is 
noisy and/or incomplete. As a con.rmation of the accuracy of the method, on the synthetic data of the 
banana shown in .g­ure 8, the technique produces results accurate to within .4%.As shown in the left 
of .gure 10, even if the input hierarchy is unable to adequately represent the object, the algorithm 
does the best it can, producing a simple model that conveys some of the dominant aspects of the shapes. 
Finally, we demonstrate the robustness of the technique by run­ning it on a sparse sampling of the spoon 
data; after removing 90% of the spoon data, a visually appealing reasonably accurate model is still obtained 
as shown in .gure 9. Compactness: Our models typically had fewer than a hundred parameters, primarily 
curve control points. This is at least two or­ders of magnitude smaller than the corresponding meshes. 
Editing: An example of editing a recovered spoon model into a ladle-like shape is shown on the right 
of .gure 10, demonstrating how easily new models can be constructed by simple and intuitive curve editing 
from shapes already recovered. Computation Time: The entire algorithm took between 20 and 30 minutes 
on a 150 MHz SGI MIPS R4400, depending on model complexity and the size of the data set. Each iteration 
of the conjugate gradient took 1-2 seconds, with each optimization pass taking about 50 iterations. The 
process was entirely automatic; no manual intervention was required. The total number of points (range 
data and tessellated model) was typically about 15000. 6 Conclusions and Future Work We have presented 
a new method for creating concise generative models from incomplete range data, given a user-supplied 
model hierarchy. Advantages of our approach are simplicity, robustness to noise, and creation of an intuitive 
compact model. We extend tradi­tional computer vision algorithms for recovery of speci.c shapes in that 
curves of a user-supplied generative model are estimated; the user can supply a model of their choice 
and immediately obtain an automatic recovery algorithm. Our work currently has many limitations. The 
.ts obtained are not perfect, especially when the model inadequately describes the real object. Even 
for the synthetic banana-like data used in .g­ure 8, there is some residual error. Our method also does 
not pre­serve local detail, and there may be artifacts from under-or over­smoothing, such as the squaring 
near the ends of the spoon model. Further, the algorithm requires the user to specify an appropriate 
model hierarchy, and currently does not allow different hierarchies to be combined. If the wrong hierarchy 
is input, a simple model that mimics the original to the extent possible will be output as shown on the 
left of .gure 10, but those results may not always be useful. Also, while the models shown are complex 
compared to single parametric models previously used in computer vision, they are still fairly simple 
for graphics as we do not provide automatic segmentation for recovery of complex articulated objects. 
Solving the above problems de.nes some important directions for future work. Improvements could also 
be made in using more complex objective functions and minimization algorithms, more .exible tradeoffs 
between accuracy and simplicity, and more ex­haustive non-greedy methods for traversing the input hierarchy. 
Fi­nally, the model hierarchy used could be learned from examples or created automatically from a model 
database. While many challenges remain, we believe that algorithms for recovering high-level models are 
an important direction of research for both computer vision and computer graphics.  Figure 7: Data (above) 
and models (below) for the objects in the scene of .gure 1. The models are robust to noise and incomplete 
data, and are a smooth compact representation. Acknowledgements: Special thanks to Jean-Yves Bouguet 
for reviewing early drafts, and for help with data acquisition. Pre­liminary discussions with Al Barr 
were of immense help. We are also grateful to the anonymous Siggraph reviewers (especially #2) and committee 
for their helpful comments, and to members of the graphics groups at Caltech and Stanford, for their 
support. This work was supported by the NSF Science and Technology Center for Computer Graphics and Scienti.c 
Visualization (ASC­8920219), an Army Research Of.ce Young Investigator award (DAAH04-96-100077), the 
Alfred P. Sloan Foundation, and a Reed-Hodgson Stanford Graduate Fellowship. All opinions, .nd­ings, 
conclusions or recommendations expressed here are those of the authors only and do not necessarily re.ect 
the views of the sponsoring agencies and individuals.   References [1] T. O. Binford. Visual perception 
by computer. In Proceedings of the IEEE Conference on Systems Science and Cybernetics, 1971. [2] Jean-Yves 
Bouguet and Pietro Perona. 3D photography on your desk. In ICCV 98 proceedings, pages 43 50, 1998. [3] 
R. A. Brooks. Model-based three-dimensional interpretations of two­dimensional images. IEEE Transactions 
on Pattern Analysis and Machine In­telligence (PAMI), 5(2):140 150, 1983. [4] M.F. Cohen. Interactive 
spacetime control for animation. In SIGGRAPH 92 proceedings, pages 293 302, 1992. [5] Brian Curless and 
Marc Levoy. A volumetric method for building complex mod­els from range images. In SIGGRAPH 96 proceedings, 
pages 303 312, 1996. [6] Paul E. Debevec, Camillo J. Taylor, and Jitendra Malik. Modeling and rendering 
architecture from photographs: A hybrid geometry-and image-based approach. In SIGGRAPH 96 proceedings, 
pages 11 20, 1996. [7] D. DeCarlo and D. Metaxas. Blended deformable models. PAMI, 18(4):443 448, Apr 
1996. [8] D. DeCarlo and D. Metaxas. Shape evolution with structural and topological changes using blending. 
PAMI, 20(11):1186 1205, Nov 1998. [9] S.J. Dickinson, D. Metaxas, and A. Pentland. The role of model-based 
segmen­tation in the recovery of volume parts from range data. PAMI, 19(3):259 267, Mar 1997. [10] Matthias 
Eck and Hugues Hoppe. Automatic reconstruction of B-Spline surfaces of arbitrary topological type. In 
SIGGRAPH 96 proceedings, pages 325 334, 1996. [11] F. Ferrie, J. Lagarde, and P. Whaite. Darboux frames, 
snakes, and super-quadrics: Geometry from the bottom up. PAMI, 15(8):771 784, 1993. [12] Hugues Hoppe, 
Tony DeRose, Tom Duchamp, John McDonald, and Werner Stuetzle. Surface reconstruction from unorganized 
points. In SIGGRAPH 92 proceedings, pages 71 78, 1992. [13] Hugues Hoppe, Tony DeRose, Tom Duchamp, John 
McDonald, and Werner Stuetzle. Mesh optimization. In SIGGRAPH 93 proceedings, pages 19 26, 1993. [14] 
Venkat Krishnamurthy and Marc Levoy. Fitting smooth surfaces to dense poly­gon meshes. In SIGGRAPH 96 
proceedings, pages 313 324, 1996. [15] R. Nevatia. Structured Descriptions of Complex Curved Objects 
for Recognition and Visual Memory. PhD thesis, Stanford, 1974. [16] A. Pentland. Toward an ideal 3-D 
CAD system. In Proc. SPIE Conf. Machine Vision Man-Machine Interface, 1987. San Diego, CA. [17] Michael 
Plass and Maureen Stone. Curve-.tting with piecewise parametric cu­bics. In SIGGRAPH 83 proceedings, 
pages 229 239, 1983. [18] W. Press, S. Teukolsky, W. Vetterling, and P. Flannery. Numerical Recipes in 
C: The Art of Scienti.c Computing (2nd ed.). Cambridge University Press, 1992. [19] N. Sriranga Raja 
and A. K. Jain. Obtaining generic parts from range images using a multi-view representation. Computer 
Vision, Graphics, and Image Pro­cessing. Image Understanding, 60(1):44 64, July 1994. [20] R. Ramamoorthi 
and A. H. Barr. Fast construction of accurate quaternion splines. In SIGGRAPH 97 proceedings, pages 287 
292, 1997. [21] J. Snyder. Generative Modeling for Computer Graphics and CAD. Academic Press, 1992. [22] 
John M. Snyder and James T. Kajiya. Generative modeling: A symbolic system for geometric modeling. In 
SIGGRAPH 92 proceedings, pages 369 378, 1992. [23] F. Solina and R. Bajcsy. Recovery of Parametric Models 
from Range Images: The Case for Superquadrics with Global Deformations. PAMI, 12(2):131 147, February 
1990. [24] D. Terzopoulos and D. Metaxas. Dynamic 3D models with local and global deformations: Deformable 
superquadrics. PAMI, 13(7):703 714, July 1991. [25] Marjan Trobina. Error model of a coded-light range 
sensor. Technical Report BIWI-TR-164, ETH, Zurich, 1995. [26] Greg Turk and Marc Levoy. Zippered polygon 
meshes from range images. In SIGGRAPH 94 proceedings, pages 311 318, 1994. [27] K. Wu and M. D. Levine. 
Recovering parametric geons from multiview range data. In CVPR, pages 159 166, June 1994. [28] D. Zwillinger. 
Handbook of Differential Equations. Academic Press, 1989. Root Input Data Original Input Data Root (Cylinder) 
      Figure 9: Left: Percentage deviation errors (D) and total costs (C) for the spoon (left) and 
banana (right). Middle: Fitting of model to very sparse data. On top is a pointcloud with fewer than 
900 points. The middle shows the recovered model while the bottom is a mesh obtained from Hoppe s [12] 
algorithm on the same data. A comparison indicates the robustness of our approach. Right: The top shows 
a superquadric .t to the banana data while the bottom shows our model, indicating the bene.t of generative 
models. 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 -1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1 0.1 0.05 0 -0.05 
-0.1 -0.15 -0.2 -0.25 -0.3 -1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1  
			