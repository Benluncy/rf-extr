
 Almost Optimal Set Covers (P 1 re iminary HERVE BRONNIMANN* Department of Computer Science Princeton 
University Princeton, NJ 08544, USA E-mail: hbr@cs. princeton. edu Abstract We give a deterministic polynomial 
time method for finding a set cover in a set system (X, 7?) of VC-dimension d such that the size of our 
cover is at most a factor of 0 (d log (de)) from the optimal size, c. For constant VC-dimension set systems, 
which are common in computational geometry, our method gives an O (log c) approximation factor. This 
improves the previous @(log IX 1) bound of the greedy method and beats recent complexity­theoretic lower 
bounds for set covers (which don t make any assumptions about VC-dimension). We give several applications 
of our method to compu­tational geometry, and we show that in some cases, such as those that arise in 
3-d polytope approxi­mation and 2-d disc covering, we can quickly find O(c) -sized covers. Introduction 
A set system (X, 7?) is a set X along with a collec­tion R of subsets of X, which are sometimes called 
ranges [24]. Such entities have also been called hy ­pergraphs and range spaces in the computational 
*Supported in part by NSF Grant CCR-90-02352 and Ecole Normale Sup6rieure. t This research supported 
by the NSF and DARPA under Grant CCR-8908092, and by the NSF under Grants IRI­ 9116843 and CCR-9300079. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and. its date appear, and notice is given that copying is by permwlon of the Association of Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.  in Finite 
Vc-Dimension Version) MICHAEL T. GOODRICHt Department of Computer Science Johns Hopkins University Baltimore, 
MD 21218, USA E-mail: goodrich@cs. jhu. edu  geometry literature (e.g., see [5, 9, 10, 11, 12, 13, 14, 
15, 18, 23, 24, 33, 35, 34, 40, 36, 38, 39]), and they can be used to model a number of interesting computational 
geometry problems. There are a host of NP-hard problems defined on set systems, with one oft he chief 
such problems being that of finding a set cover of minimum size (e.g., see [20, 22]), where a set cover 
is a subcol­lection C G 7? whose union is X and the size of C is simply the number of sets in C. A related 
(in fact, equivalent) problem is that clf finding a hitting set of smallest size, where a hitting set 
is a subset 11 S X such that II has a non-empty inter­section wit h every set 1? in 7?. There are a num­ber 
of problems that can be reduced to these two problems, and many of these problems are formu­lated as 
computational geometry problems. Thus, our interest is in finding minimum set covers and smallest bitt 
ing sets as quickly as possible. Unfortunately, the corresponding decision problems, SET COVER and HITTING 
SET, as we will call them, are both NP-complete [22, 28]. Moreover, even if each element of X is contained 
in just two sets, the HITTING SET problem is still NP­complete [28] (and is known as VERTEX-COVER). Thus, 
unless P = NP, if we desire a polynomial­time algorithm, we must content ourselves with an approximation 
algorithm, which, if we let c denote the size of a minimum set cover, produces a set cover of size czc 
for some (hopefully) small approx­imation factor a. The only known polynomial­time approximations algorithms 
for SET COVER with guaranteed performance ratios are the greedy algorithm [16, 27, 31], which achieves 
an approxi­mate ion factor of Q = (1 + in A), where A denotes the size of the largest set in R, and an 
algorithm of Hochbaum [25], which achieves an approximation 10th Computational Geometry 94-6/94 Stony 
Brook, NY, USA O 1994 ACtd 0-89791 -648-4/94/0006..$3.50 293 factor of a = max.ex {17?.\}, where l?. 
denotes the set of all R E 7? containing x. Note that in the former case a can be as large as (1+ in 
1X1) and in the latter a can be as large as Il?l. Thus, as worst case bounds, the greedy algorithm achieves 
the best approximation factor, and Johnson [27] shows there are set systems where the greedy algorithm 
does indeed produce a set cover with approxima­tion factor a = Q(ln 1X1 + 1). Interestingly, Lund and 
Yannakakis [32] have recently shown that, un­less NP ~ D TIME [rLPO1y10g ], no polynomial time algorithm 
can approximate SET COVER within a factor better than a = ~ In IX I in the worst case, and, unless NP 
< D TIME [nlOg 10g ], Bellare et al. [4] showed that no polynomial time algorithm can approximate SET 
COVER wit hin a factor bet­ter than Q = 6 in IX I in the worst case, for any constant 6< 1/8. Our results. 
In this paper we give a (determin­istic) polynomial-time algorithm that finds a set cover of size within 
a factor of a = O(d log(dc)) of the size c of the minimum set cover, where d stands for the VC-exponent 
of the set system (see Section 2 for definitions). Thus, for set systems wit h bounded VC-exponent, we 
actually beat the complexity-theoretic lower bounds [4, 32] (which make no assumptions about the VC-exponent 
). In section 4, we indicate some examples on which Hochbaum s method [25] or the greedy meth­ods [16, 
27, 31] perform poorly, and show that our met hod outperforms them in some cases. Our algorithm, which 
is actually for the dual HITTING SET problem, is based upon a deter­ministic analogue of a randomized 
natural selec­tion technique used by Clarkson [17, 19], Little­stone [30], and Welzl [44]. This technique 
can be viewed as algorithmic Darwinism, for we it era­tively select, in polynomial-time, a small-sized 
sub­set of X (known in the literature as an E-net [24]) that intersects all highly-weighted sets in 73, 
and, if this set is not a bitting set, then we increase the weight of the elements in an R E 7? missed 
by this set. By continuing this process over sev­eral generations ) we guarantee that the fittest elements, 
which belong to the optimal bitting set, eventually are included. Fortunately, the number of generational 
iterations we must perform is at most O(c log ( IX I/c) ); hence, this approach yields a (relatively 
simple) polynomial-time algorithm. We show the utility of our approximation algo­rithm by giving several 
applications of our method to problems in computational geometry and learn­ing theory, including polytope 
approximation, geo­metric point-probe decision tree construction, and disk cover. Our methods improve 
the running time and/or the approximation factors of previ­ous met hods. In fact, for 3-d polyt ope approxima­tion 
and 2-d disc covering we show how to adapt our method to achieve a constant approximation factor. We 
also describe an implementation of our approach, and show that it indeed beats the greedy met hod in 
practice in some cases. Before we describe our methods, however, let us first review the relevant properties 
and defini­tions regarding the VC-dimension notion. 2 Set Systems of Finite VC-Dimension In this section 
we recall the basic facts about set systems of finite VC-dimension. Let (X, 7?) be a given set system. 
Given Y ~ X, all the subsets of Y obtained as the intersection of Y and R ranging over 7?, form a set 
system called the system in­duced by 7? on Y, and denoted by RIY. Y is shat­ tered by 7? if Rly = 2Y. 
(X, 7?) is said to have VC­dirnension d, if d is the smallest integer such that no d+ 1 point subset 
Y C X can be shattered. If Y is finite, it is well known [42, 43] that the number of sets of 7?IY is 
less than ( [ ) ++( ; ) s Iyld) where d is the VC-dimension of (X, 7?). We call the VC-eqxmentl the infimum 
of all numbers s such that I F+Y[ = O(IYIS) for any finite subset Y of X. The aforementioned result shows 
that s s d, but equality does not always occur, as there are sys­ tems in which the VC-exponent is non 
integral [2]. However, the VC-dimension is finite if and only if the VC-exponent is finite as well; s 
never takes values in the interval [0, 1], and it is O if an only if T? is finite [2] (whereas d is O 
if and only if 7? con­sists of one set). In particular, the VC-exponent concept only makes sense for 
an infinite set sys­tem, whereas the VC-dimension is more general. Consider, for the sake of an example, 
a common set system arising often in computational geome­try applications the hal~space set system. In 
this 1This value has also gone by the names real density [2] and sca~old dimension [23]. 294 system 
X is taken as a set of halfspaces in lR~ and %! is taken to be all combinatorially distinct ways if intersecting 
halfspaces in X by a simplex. It is well known (e.g., [2]) that this system has a VC-dimension and a 
VC-exponent of d. The dual set system (R, X*) is defined by x* = {7?. : z c X}, where % consists of all 
the sets R c R that contain x. One way to look at dual systems is to consider (X, 77,) as a (possibly 
infinite) boolean matrix &#38;f that has a column for each z E X and each row corresponds to an inci­dence 
relation for a set R c %!, and view the dual as a transpose of this matrix. It is also well known (e.g., 
see Assouad [2]) that the VC-dimension d* of the dual (%?, X*) is less than 2~+1, where d is the VC-dimension 
of the primal (X, R). Let (X, 7?) be a set system. If a subset N c X intersects each set R E R of size 
bigger than sIX 1, then we call N an e-net [24]. As has been observed by Haussler and Welzl [24], set 
systems of VC­dimension o! admit (l/r) -nets of size O(dr log(dr)). This bound has been improved by Blumer 
et al. [7] to O(dr log r) and this has been proved tight by Kom16s et al. [29]. We can generalize this 
defini­tion by putting an additive2 weight function w on 2X. In this formulation, an e-net is required 
to intersect every set of weight at least sw (X). To allow for efficient comput at ion, we need that 
the set system be described somewhat more efficiently than by the list of its subsets. Definition 2.1 
We say that a set system (X, 7?) has a subsystem oracle of degree D if there is an algortthm wh~ch, 
given a subset Y G X, returns (Y, R]y) (as a boolean matrix) m time O(\Y\~+ ). It is a witnessed oracle 
if, for any set R of R/Y, it can provide a set R of R such that R = R (l Y in O(IXI) time. If (X, 7?) 
has a subsystem oracle of degree D, and VC-exponent d, it is clear that d s D. Un­der this assumption, 
it has also been shown [9] that one can find a (l/r)-net for (X, 7?) of size O(dr log(dr)) in time 0(d)3DrD 
logD (rd) 1X1, for both the uniform and weighted cases. The term additive refers to the fact that w(Y) 
= 2Y=Y w(y), with the usual abuse of notation w(y) = ~({11}). 295 3 The Main Algorithm The goal of 
this section is to prove our main the­ orem. Let s be a non decreasing function, let n= 1X1, and let 
m= 17?[. Definition 3.1 An s-net finder for (X, %?) is an algorithm A that, given r and a weight distribu­tion 
w on X, returns a (l/r) -net of size s(r) for (X, l?) with weights w. Also, a verifier is an algo­rithm 
B that, given a subset H ~ X, either states (correctly) that H is a hitting set, or returns a nonempty 
R E 1? such that RnH =0. Using size(z) to denote the length of the en­coding of an object z, let us 
say that A runs in TA(siZe(X, 7?), size(w), r) time3 and that B runs in TB(size(X, 7?), size(H)) time. 
We will suppose that both TA and TB are (non constant) polynomi­als, so that T(O(Z)) = O(T(0)) and ~~<ZT(2~) 
=  0(T(2Z)). Theorem 3.2 Let (X, 73) be a set system that admits both an s-net finder A and a veri­fier 
B. Then there is an algorithm A(A, B) that computes a hitting set of size at most s(4c), where c stands 
for the size of an op­ t~mal hitting set. The time taken by A is O(CIOg(Tt/C) (TA(nm, nlOg(n/c), c) + 
TB(n7n, c)). If X has finite VC-dimension, then we may im­plement the net finder using the greedy method 
[13], and the verifier by inspecting all of (X, 7?), both in polynomial time (in either the real RAM 
or bit models). But under standard computational assumptions, there are better implement at ions of the 
net finder and verifier. Corollary 3.3 Let (X, R) be a set system given by a witnessed subsystem oracle 
of degree D, whtch admzts a hitting set of size c. Let d stand for the VC-exponent of (X, R), and as­sume 
0 $2 R. Then one can find a hitttng 3Throughout the literature in computational geometry, the unit-cost 
(or real RAM) model is usually assumed. In this case, size(w) is simply n. However, due tc, to the partic­ular 
relevance of our algorithm in the realm of NP-hardness, and since the weights can (and will) become ,exponential 
in the forthcoming algorithm, we have to be careful that the algorithm still runs in polynomial time 
in the bit model. As it turns out, our running time is the same in both mod­els, but the choice of the 
encoding and the value of TA are different. set for (X, R) of size O(dclog(dc)) in Z (lXl) = O (C2D+1 
logD (clc) log(lX1/c) 1X1) time in the real RAM model, or O (cT(lX\) log([X1/c)) time in the bit model. 
Proof: It suffices to show how to implement the net finder and the verifier and show their complex­ity 
bound. But one can find a (l/r)-net for (X, 7?) of size O(dr log(dr)) in 0(d)3Dr2D log~(rd) 1X1 time, 
for both the uniform and weighted cases, us­ing the algorithm of Bronnimann, Chazelle, and Matou5ek [9], 
in the real RAM model. In the bit model, the complexity of the weights would have to be taken into account, 
which may add at most an O(c log(l X1/c)) factor to the running time, as proven in the next section. 
As for the verifier, one simply runs the witnessed subsystem oracle for H. If the oracle fails to list 
0 as being in T?lH, we may conclude that H is a hitting set. Otherwise, we ask for a witness R of the 
fact that 0 G %?lH. Thus RnH = 0, and R is nonempty as 0 # 7?. The time spent by the verifier is O(\Hl~+l 
+ \X[). Plugging these bounds into Theorem 3.2 yields the corollary. 0 Remarks. (1) If we change the 
definition of the VC-exponent to fit better the VC-dimension con­cept, by requiring that for all finite 
Y C X we have [l?l Yl= O ((1~1) +.-. + (1~1)) which is also O([Y1/d + 1)~, then we can reduce the size 
of the hitting set to O(dc log c) [14]. (2) For a particular c, the algorithm will either say that there 
is no hitting set-of size c, or it will output a hitting set of size O(dc log (de)), which, of course, 
is different than saying that there is a hitting set of size c. (3) The corollary can be stated with 
d as the dual VC-exponent, with an oracle for the dual set system, and as yielding a set cover of size 
O(dclog(dc)).  We now turn to the proof of Theorem 3.2. 3.1 The algorithm Let us assume, for the time 
being, that we know the size c of a smallest hitting set (we will show later why this is a reasonable 
assumption). Our strategy can be thought of in terms of evo­lutionary biology, in that it is based upon 
a notion of survival of the fittest . Intuitively, we want to simulate the growth of a population where 
some el­ements are advantaged because they hit more sets than others. The idea is to put weights on the 
el­ements (initially uniformly) and use the net finder A to select a (1/2c)-net of size s(2c). If it 
doesn t hit a particular set R c ??., as returned by the ver­ifier B on the net, we double the weights 
of the points in R. Because of the definition of a hit­ting set, at least one point in an optimal hitting 
set falls in R, and has its weight doubled. How­ever, the property of a ( l/2c)-net implies that the 
weight of R is at most a fraction l/2c of the total weight, and the tot al weight does not increase too 
much. Therefore, we soon expect an optimal hit­ting set to be included in the chosen set. The next lemma 
shows that this is indeed the case. Lemma 3.4 1~ there is a hitting set of size c, the doubling process 
cannot iterate more than 4C log(n/c) times, and the total weight will not ex­ceed n4/c3. Proofi Our proof 
follows arguments of Clark­son [17, 19], Littlestone [30], and Welzl [44]. Let H be a hitting set of 
size c. Because the set R returned by B at each iteration satisfies w(R) s w(X) /2c, the weight of X 
is not multiplied by more than a factor 1 + l/2c in any iteration. How­ever, HfUl is not empty, by definition 
of H. There­fore, after k iterations, if each h 6 H has been doubled z~ times, we have lk w(X) < 72( 
1+-) < ne+, and 2C w(H) = ~ 2Zh, where ~ Zh> k. hEH hEH Using the convexity of the exponential function, 
we conclude that w(~) > c2k/c. Since w(H) < w(X), we finally have &#38; c2c ~ne&#38;<n2%, from which 
k < 4C log(~) follows. The bound of n4/c3 on w(X) is an immediate consequence. 0 If the process exceeds 
this guaranteed number of iterat ions, that only means that there is no cover 296 of size c. Thus, we 
can use this procedure to ac­tually determine an approximate bound for c. To start with, we conjecture 
a value c of c, which ini­tially can be set to 1. In general, if our routine fails to find a hitting 
set, there is no hitting set of size c , so we increase c by a factor of two. At the stage when we find 
a hitting set, c < 2c, so that the hitting set returned is of size at most s(4c). 3.2 e-nets with or 
without weights? Typically, E-net algorithms are designed for the uniform case not for the weight ed 
case. Here we mention a simple method for reducing the weighted case to an unweighed one, as outlined 
by Matoui5ek [35]. First scale the weights such that w(X) = n. Then take [w(x) + 1] copies of each element 
z E X. Note that the multiset X thus obtained contains all the elements of X and has a cardinal of at 
most 2n. Take then an s-net for the set X : it is also an e-net for the original set X wit h weights 
w.  3.3 Time analysis For a given c , it is clear that there can be at most 4c log(n/c ) iterations, 
each of which takes time O (T~(size(X, 72-), size(w), c ) + T~(size(X, 7?), c )), But the total weight 
can never exceed n4/c3, which proves that size(w) = O (n log (n/c )). When c in­creases geometrically, 
by our choice of polynomial functions for TA and TB, the sum of all running times is dominated by their 
last term, for which C5C 52C. Finally, a standard encoding of (X, R!) gives that size(X, 7?) = O(nrn), 
conclud­ing the proof of Theorem 3.2. Note that in real RAM model, the size of the weights is irrelevant, 
and one simply accounts for the number of arithmetic operations and not their complexity. As argued in 
Section 6, the weights almost never go past a few digits in practice, so such an assumption is not unrealistic. 
In any case, since our weights are always multiples of 2, we can encode each weight using a register 
of O(log n) bits and we can use such registers to per­form any weight arithmetic in O(c log(n/c)) time 
(by Lemma 3.4).  4 Lower bounds for other meth­ods In this section we give some specific CZLSeSwhere 
our method improves the previous methods, We begin with the greedy method. 4.1 The greedy method The 
following example has been communicated to us by JiH Matou5ek (private cOmmLInicEitiOn). Let : i=l,2, 
j= l... 2~+1 1} be a set s = {Pt,J of n = 2P+2 2 distinct points, and let its valid subsets be S j 
= {pi,k : i = 1,2, k = 2~...2~+l 1}, for z ~ {1,2}, j E {O. . p}, as well as the two particular sets 
T = {p~,j : j = 1...2~+1 1} (see Figure 1). The greedy method will pick the cover (S~)J=l,,,P, which 
is of size p = log(n + 2) 2. The optimal cover is (T, ),=1,2 and is of size 2 The dual VC-dimension 
of our example is 2, as every point is covered by exactly 2 subsets, and our algorithm (in a dual setting 
to obtain a set cover) will pick the optimal cover for a value of c = 2. Figure 1: A greedy method s 
worst case that has finite VC-dimension. 4.2 Hochbaum s method In Hochbaum s method, one denotes the 
set sys­tem of m sets over n elements as a O-1 (n, m)­matrix A each column Al of which is the inci­dence 
vector of one of the sets. The algorithm then solves the linear program max e~.y subject to yT.A < em, 
g > (0,...,0), where e~ is a k­vector whose components are all 1. Let J denote the sets of tight constraints 
at the optimum y (in mathematical notation, j c J if and only if (y*)T.Al = 1). Then J is a set cover 
within j times the optimum, where ~ is the maximum row sum of A. Take k to be any constant. Let us put 
n = (~) and take for A the (n, rn)-matrix whose rows are made up of all possible vectors with m k 1 
s and k O s (in no particular order). The corresponding set system has n elements and m sets. By symmetry, 
yJ7 the method will pick all the sets in the cover, which gives a cover of size m, guaranteed within 
m k off the optimum. Any k + 1 elements will constitute an optimal cover. This example has both dual 
VC-exponent and dual VC-dimension k, so our algorithm will return a cover of size 0(k2 log k). Remark. 
Interestingly enough, the bad example for the greedy (resp. Hochbaum s) method can be solved efficiently 
with our as well as Hochbaum s (resp. the greedy) method. We don t know of an example for which our method 
would outperform both of them.  5 Applications In this section, we cover mainly computational ge­ometry 
applications, therefore it is customary to assume the real RAM model where all the integers and their 
elementary arithmetic operations have unit complexity. 5.1 Separating polyhedra Let Q ~ P be two convex 
polytopes in lR~. The problem of finding a separator polytope between P and Q with as few facets as possible 
is believed to be IVP-hard, even in the three-dimensional case [21], but one can find good approximations 
for it. In [41] Mitchell and Suri cast the problem as a hitting set problem. Let ?-i = M(Q) denote the 
set of supporting hyperplanes of Q. Let the cover set system be (%!, {%P : p 6 6 P}), where, for any 
point p, %P consists of those hyperplanes in ?-t for which p and Q lie on opposite sides. (For definiteness, 
we agree that if p is on h, then h. is not in ?tP. ) They show that a bitting set for the cover set system 
gives a subset of facets of Q whose bounding halfspaces define a polytope be­tween Q and P. A polytope 
Q between Q and P such that each facet of Q contains a facet of Q is called canonical. The smallest (with 
respect to the number of facets) canonical polytope con­tained in P can be obtained from a minimal hit­ting 
set of this set system and is within d times the optimal separating polyhedron (in number of faces). 
Therefore the greedy strategy returns a polyhedron within 0(d2 log IQ\) of the optimal. In a recent twist, 
Clarkson [19] applies ideas he used for small-dimensional linear programming to give a polynomial-time 
randomized method that pro­ duces an approximation within 0(d2 log(dc)) of the optimal c. In fact, the 
algorithm of this paper is a deterministic analogue of Clarkson s method in our more general framework 
4. Interestingly, how­ ever, for the important case of d = 3, we are able to improve on Clarkson s result 
to achieve an ap­ proximation factor that is O(1). But let us first describe our method for gen­ eral 
d >4. We need to exhibit an appropriate net finder and a verifier. Note that since P contains Q, @ is 
not in the cover set system. The basic observation is that the cover set system is a sub­ system of the 
halfspace set system, and therefore has VC-dimension and VC-exponent d (since d+ 1 hyperplanes define 
at most 2~+1 1 regions of the space, and the complexity of an arrangement of m halfspaces is O(m~)). 
Therefore our hope is to find an s-net finder, where S(Z) = O(da log(dx)). To find a (l/r)-net for the 
weighted cover set system, we simply use the algorithm of Bronnimann et al. [9], which computes a weighted 
(l/r)-net in O(n# log~(dr)) time, using the reduc­tion of Section 3.2 to take care of the weighted case. 
This provides a (1 /r)-net for the more gen­eral set system consisting of all halfspaces, but this is 
a jbrtiori a (l/r)-net for the cover set system, and the bound on its size is still O(dr Iog(dr)). As 
for the verifier, let Y denote the canonical polytope with k faces associated with the hyper­planes of 
some Y ~ % of size k. In particular, %!(Q)n = Q. All we are asking for is whether Y is entirely cent 
ained in P, or else to give a point of 8P which is in Yn. We can simply compute the intersection of all 
the halfspaces defined by the planes Y U ?-l(P) and test whether there is a facet that belongs to P. 
If so, we can return %P where p is, e.g., the centroid of this face. Otherwise, Yn is cert airily cent 
ained in P. We can find a (l/r)-net in O (r~ log~(dr)lQl) time and verify k halfspaces in O(k + [P]) 
1~1 time (d ~ 4) or in O((k + IPI) log(k + IPI)) time (d= 2, 3). Plugging those bounds into our main 
theorem, we get that Theorem 5.1 Let Q ~ P be two convex nested polytopes in IRd (d > 4) with a total 
of n facets. 4Clarkson s exposition is restricted to ~olYtoPal problems. It is possible to find a separator 
of size within 0(d210gc) of the optimum c, in a deterministic time of O (nl~~ + cdn logd(dc)) c log(n/c), 
which is always O n +2 logd n . () Note that the case where c = fl(n ) is of lit­tle interest, because, 
in this instance, our algo­rithm offers no better a performance ratio than the greedy method (at least 
asymptotically). Thus we could make the algorithm faster (for the same guaranteed ratio) by switching 
to the greedy method when c becomes too large. But in three dimensions, we can actually do much better. 
In particular, we recall from [38, 37] that the three dimensional halfspace set system admits e-nets 
of size O (1/s), and as indicated in Section 3.2, their algorithm can be extended to the weighted case 
as well. The cost of the com­putation of a (l/c)-net of size O(c) is O(nc), if c ~ na [37], and the cost 
of verifying is O(n log n) as argued above. Therefore we obtain the follow­ing strengthening of our previous 
theorem: Theorem 5.2 Let Q G P be two nested polyhedra in IR3 with a total of n facets, one of them being 
convex. It is possible to deterministically jind a separator of size within 0(1) from the size c of an 
optimum separator in O(nc(c + log n) log(n/c)) time, if c < na for some a >0. In particular, it should 
be noted that the run­ning time is always O (n1+2a log n), which improves on the O(n4) time bound of 
Mitchell and Suri s method [41] for the general case. However, for large c > nff, we have to switch to 
a O (n3) method to find the net [38], yielding O (cn3 log(n/c) ) time. Note that this is still 0(n4), 
whereas the time consumed by the greedy method is strictly O (n4) (though Mitchell and Suri reduce it 
to 0(n3) when both polyhedra are convex.)  5.2 Decision Trees In [1], Arkin et al. describe how to construct 
a point-probe decision tree for a set of non­degenerate polygons in the plane whose height is s 1 + 
[log(k/(s 1))1, when given a hitting set of size s. For some applications, the result serves to decide 
the position of a polygon in a scene [1]. While their approach is more general, 299 the next result shows 
that we can get better per­formance ratio in the height of a decision tree for non-degenerate (i.e., 
general posit ion) inputs. We define the point set system of a family S of plane objects by all subsets 
SD of S for all points p, where SP consists of all objec&#38; in S containing p. Lemma 5.3 Let P be a 
polygon in the ylune, S be a family of congruent copies of P, and let (S, l?) be the point set system 
of S. Then (S, l?) has VC­exponent at most 2 (the constant 2 cannot be im­proved in general), and admits 
a witnessed subsys­tem oracle of degree 2. The exponent is still 2 if P convex. Proofi Clearly, the number 
of sets of (S, 7?) is at most the number of cells is the arrangement of S. If all m polygons in S have 
k vertices each, their arrangement has complexity O (k2m2 ), which corresponds to the complexity of the 
arrangement of their supporting lines. The complexity drops to 0(krn2 ) if the polygons are convex, which 
pro­vides somewhat better constants for the shatter function. However, it is easy to come up with ex­amples 
for which those bounds are tight and also reflect the number of different subsets in the point set cover. 
This also provides the construction of the witnessed oracle: The oracle constructs the arrangement and 
simply picks a point in each of the cells. If asked to provide a witness, ithe point is tested against 
all the polygons, in O(rn IIog k) time. (Here, we treat k as a constant, and we are only interested the 
number of elements of S.) 0 Remark. Clearly, the VC-dimension depends on the number of sides of P. If 
S consists of congruent copies of a single convex set, even a convex poly­gon with infinitely many sides, 
then its point set system (S, 7?) need not have finite VC-exponent (resp. VC-dimension). Our algorithm, 
combined with the! above ob­servation, and the result of Arkin et al. [1] gives us a decision tree of 
smaller asymptotic depth than the greedy method for the non-degenerate arrange­ment of Arkin et al.5 
Moreover, our method can also be used to derive point-probe decision trees 5For degenerate arrangements 
they design a new greedy strategy, which seems not to be describable i~ a set cover strategy. of improved 
depth for any set of general-position k-gons in the plane, for constant k, since this point set system 
also has bounded VC-dimension (as the proof above shows as well).  5.3 Disc cover Let S be a set of 
n points in the plane and let D be a family of discs. The disc cover problem is to find a minimum number 
of discs in D that cover the points in S [26]. This problem is motivated by VLSI design criteria as well 
as viewing prob­lems in astronomy. MatouSek et al. [38] show that this set system admits O(r) sized (l/r)-net 
and, as indicated in Section 3.2, one can extend their algorithm to weighted point sets. The resulting 
al­gorithm runs in O(rn log n) time, and implies the following: Theorem 5.4 Let S be a set oj points 
in the plane, and D be a set of discs whose union con­tains S. It is possible to jind a disc cover of 
S from D (a subset of D whose union still contains P) whose size is no more than O(1) times the opti­mal 
size c of such a cover in 0(c2n log n log(n/c)) time. Note that our method never takes more than O(n3 
log n) time. This bound contrasts the bound of Hochbaum and Maas [26] for finding a constant­factor approximation 
to a disc cover, as their method requires all the discs in D to have the same radius and, even when all 
the parameters in their method are optimized for the running time, their method takes 0(n5) time. 5.4 
Learning a Union of Halfspaces in Fixed Dimension Let H be a set of s halfspaces in 111~, and write 
11+ for their union, and H-for its complement. Let D be an (unknown) probabilistic distribution on Etd. 
A learning algorithm A for H+, given m examples drawn from D, outputs a hypothesis G such that, with 
confidence 1 d (on the examples fed to the algorithm), G verifies D(H+ A G+) < c. (A denotes the symmetric 
difference.) An example is labeled positive if it falls in H+, negative other­wise. This ensures that, 
for subsequent examples, the label as computed with G will be correct (ac­cording to H) with probability 
at least 1 E. 300 It has been proved by Blum and Rivest [6] that this problem admits no proper learning 
algorithm (for which the hypothesis also consists of s halfs­paces) whose running time is polynomial 
in d, s, &#38; 1, 6 1, even if s = 2 (unless P = jlp). How­ever, Baum [3] argues that this only shows 
that we should look for hypotheses with more halfspaces. Indeed, Blumer et al. [7] and Baum [3] have 
pro­posed algorithms that output a hypothesis of size 0(s log m). These algorithms are polynomial in 
fixed dimension (however, the dependence in the dimension is exponential). Unfortunately, with the purpose 
of training a neural net in mind, we see that each halfspace of the hypothesis corresponds to a gate 
of the neural net, and therefore the size of the neural net increases with precision. The algorithm 
of Blumer et al. proceeds by first labeling the examples, then forming a set sys­tem of the halfspaces 
containing only positive ex­amples, and finally returning a small set of halfs­paces covering all the 
positive examples. For this last step we can use our method: The hypothesis is guaranteed to have size 
O(ds log(ds) ), independent of the number of examples. Moreover, we can im­prove on the results in two 
and three dimensions. This proves Theorem 5.5 For any jixed d >1, given s half.s­paces H in IRd, and 
any distribution on points in IRd, there exists a neural net of size O(ds log(ds)) which can be trained, 
in time polynomial in s, E, 6 and with confidence 1 6, to recognize whether a point belongs to the union 
of H with a probability of en-or less than c. The size of the neural net can be brought down to O(s) 
if d = 2,3. The result, of course, is also valid for learning the union of concepts taken from a concept 
class that has finite VC-dimension. 6 Experimental Results Our algorithm has been implemented and the 
re­sults will be described in [8]. There are many pos­sible choices for implementation, as we have many 
ways to compute an &#38;-net in practice, and they result in different performances. The first consists 
in choosing a random sample of size O (dc log c). It turns out that this performs badly against the greedy 
method, as the values of n we consider are never big enough to justify the use of our method with the 
random sampling against the greedy method. The second possible choice is to use a com­puted e-net, with 
the algorithm of Chazelle and Matou3ek [14], and this seems to yield results com­parable to the greedy 
method. The third method of choice is to compute the net using the greedy method [13]. Even though this 
does not guarantee the same performance as the second choice, it performs well in practice, and never 
returns anything bigger than that returned by the greedy set cover method. Moreover, the lower bound 
as returned by our method is sub­stantially higher than that returned by the greedy method. Therefore, 
if it doesn t produce better hitting sets, at least it is able to give better lower bounds in practice. 
For our three choices, the fear that weights might increase exponentially and therefore require a multi-precision 
treatment is completely dispelled by empirical observation. In the largest example we tried (of size 
about 10002), after some 700 iter­ations, the maximum weight was a bare 16384 as opposed to a possible 
2700. This strongly suggests that the normal precision (of 32 bits) will suffice in all reasonable instances 
of the problem. This is due, of course, to the fact that only small weights tend to be doubled through 
the algorithm. One last issue concerns the generation of ran­dom set systems of finite VC-dimension. 
As this is a hard problem, we simply generated random set systems in such a way that the generation process 
itself guaranteed the finite (parameterizable) VC­dimension. We also tested the method on more natural 
set systems such as the cover set systems of two polyhedra.  Conclusions We have shown an approximation 
algorithm for the hitting set and set cover problems, and proved that it performs well if the VC-dimension 
of the set system is bounded. Furthermore, our algo­rithm defeats known complexity-theoretic lower bounds 
[4, 32] (which make no assumptions about the VC-exponent ), by being adaptive: the com­petitive ratio 
depends on the size of the optimal solution. We have exhibited a variety of compu­tational geometry problems 
that reduce to or use hitting sets, and for which the set systems have bounded VC-dimension. Our algorithm 
has been implemented, and the practical results are encouraging. The main open question pertaining to 
this re­search is whether our algorithm can be made to run in parallel in polylogarithmic time and polyno­mial 
number of processors. It seems that the main problem lies in the iteration process: if we are to double 
the weights of many sets at once, we are unable to enforce that the weights of many points in an optimal 
bitting set double at each stage. An s-net is a hitting set for the heavy subsets. The algorithm can 
be thus adapted to find an al­most minimum sized c-net. A related problem t hat would be of great practical 
interest is tcl find a sim­ilar algorithm for c-approximations. It is not even known if finding a minimum 
sized approximation is iVP-complete, much less if there is aqy algorithm that returns an almost optimal 
E-approximation. The greedy method is shown to attain an O(log n) approximation ratio in the polytope 
sepa­ration, but it might be possible to use the geometry to show that it in fact yields a constant ratio. 
Such a claim has neither been proved nor disproved. Finally, in the decision tree problem, we were unable 
to find a strategy that would work for de­generate arrangements. Is such an adaptation pos­sible? Acknowledgements 
We would like to thank Dan Boneh, Bernard Chazelle, S. Rao Kosaraju, Jiil MatouSek, Joseph Mitchell, 
and Neal Young for helpful discussions concerning the topics of this paper. References [1] E. M. Arkin, 
H. Meijer, J. S. B. Mitchell, D. Rappa­port, and S. S. Skiena. Decision trees for geometric models. In 
Proc. 9th Annu. ACM Sympos. Comput. Geom., pages 369-378, 1993. [2] P. Assouad. Densitr5 et dimension. 
Ann. Institut Fourter, Grenoble, 3;232 282, 1983. [3] E. Baum. On learning the union of halfspaces. J. 
Compl., 6:67-101, 1990. [4] M. Bellare, S. Goldwasser, C. Lund, and A. Russel. Efficient probabilistically 
checkable proc,fs and appli­cations to approximation. In Proc. 25th Annu. Symp. Theory Comput., pages 
294 304, 1993. [5] B. Berger, J. Rompel, and P. W. Shor. Ejficient NC al­gorithms for set cover with 
applications to learning and geometry. In Proc. 30th Annu. IEEE Sympos. Found. Comput. SC,., pages 54 
59, 1989. 301 [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] 
[24] A. Blum and R. Rivest. Training a 3-node neural net­work is rip-complete. In Proc. 1st Workshop 
Comput. Learning Th., pages 9-18, 1988. A. Blumer, A. Ehrenfeucht, D. Haussler, and M. War­mut h. Classifying 
learnable geometric concepts with the Vapnik-Chervonenkis dimension. J. A CM, 36:929­965, 1989. H. Bronnimann. 
An implementation of MIN HITTING SET heuristics. Manuscript, 1994. Herv6 Bronnimann, Bernard Chazelle, 
and Jiii Ma­tou~ek. Product range spaces, sensitive sampling, and derandomization. In Proc. 3dth Annu. 
IEEE Sympos. Found. Comput. SCZ. (FOCS 93), pages 400-409, 1993. B. Chazelle. An optimal convex hull 
algorithm and new results on cuttings. In Proc. 3%d Annu. IEEE Sympos. Found. Comput. Set., pages 29-38, 
1991. B. Chazelle. Cutting hyperplanes for divide-and­conquer. Discrete Comput. Geom., 9(2): 145 158, 
1993. B. Chazelle, H. Edelsbrunner, M. Grigni, L. Guibas, and M. Sharir. Improved bounds on weak e-nets 
for convex sets. In Proc. .25th Annu. ACM Sympos. Theory Comput. (STOC 93), pages 495-5o4, 1993. B. Chazelle 
and J. Friedman. A deterministic view of random sampling and its use in geometry. Combma­torzca, 10(3):229 
249, 1990. B. Chazelle and J. Matou5ek. On linear-time deter­ministic algorithms for optimization problems 
in fixed dimension. In Proc. ,/th ACM-SIAM Sympos. Dtscrete Algorithms, pages 281-290, 1993. B. Chazelle 
and E. Welzl. Quasi-optimal range search­ing in spaces of finite VC-dimension. Dzscrete Comput. Geom., 
4:467 489, 1989. V. Chvatal. A greedy heuristic for the set-covering problem. Math. Oper. Res., 4;233 
235, 1979. K. L. Clarkson. A Las Vegas algorithm for linear pro­gramming when the dimension is small. 
In Proc. 29th Annu. IEEE Sympos. Found. Comput. Scz., pages 452 456, 1988. K. L. Clarkson and P, W. Shor. 
Applications of ran­dom sampling in computational geometry, II. Discrete Comput. Geom., 4:387 421, 1989. 
Kenneth L. Clarkson. Algorithms for polytope covering and approximation. In Proc. 3rd Workshop Algorithms 
Data Struct., volume 709 of Lecture Notes m Computer Science, pages 246-252, 1993. T. H. Cormen, C. E. 
Leiserson, and R. L. Rlvest. ln­troductzon to Algorithms. The MIT Press, Cambridge, Mass., 1990. G. Das. 
Approximation schemes m computational ge­ometry. Ph.D. thesis, University of Wisconsin, 1990. M. R. Garey 
and D. S. Johnson. Computers and Intractability: A Gutde to the Theory of NP-Completeness. W. H. Freeman, 
New York, NY, 1979. M. T. Goodrich. Geometric partitioning made easier, even in parallel. In Proc. 9th 
Annu. ACM Sympos. Comput. Geom., pages 73-82, 1993. D. Haussler and E. Welzl. Epsilon-nets and simplex 
range queries. D%screte Comput. Geom., 2:127 151, 1987, [25] D. Hochbaum. Approximation algorithms for 
the set covering and vertex cover problems. SZA M J. Comput., 11(3):555-556, 1982. [26] D. S. Hochbaum 
and W. Maas. Approximation schemes for covering and packing problems in image processing and vlsi. J. 
ACM, 32:130 136, 1985. [27] D. S. Johnson. Approximation algorithms for combi­natorial problems. J. Comput. 
Syst. Sci., 9:256 278, 1974. [28] R. M. Karp. Reducibility among combinatorial prob­lems. In R. E. Miller 
and J. W. Thatcher, editors, Complexity oj Computer Computations, pages 85-103. Plenum Press, New York, 
1972. [29] J. Kom16s, J. Path, and G. Woeginger. Almost tight bounds for e-nets. Discrete Comput. Geom., 
7: 163 173, 1992. [30] N. Littlestone. Learning quickly when irrelevant at­tributes abound: A new linear-threshold 
algorithms. In Proc. 28th IEEE Sympos. Found. of Comput. Sci., pages 68 77, 1987. [31] L. Lov&#38;z. 
On the ratio of optimal integral and frac­tional covers. Discrete Math., 13:383 390, 1975. [32] C. Lund 
and M. Yannakakis. On the hardness of approximating minimization problems. In PTOC. g?sih Annu. Symp. 
Theory Comput., pages 286-293, 1993. [33] J. MatouSek. Construction of e-nets. Discrete Comput. Geom., 
5:427-448, 1990. [34] J. MatouSek. Approximations and optimal geometric divide-and-conquer. In PTOC. 
23rd Annu. ACM Sym­pos. Theory Comput., pages 505 511, 1991. Also to appear in J. Comput. Syst. SCZ. 
 [35] J. Matou5ek. Cutting hyperplane arrangements. Das­crete Comput. Geom., 6:385 406, 1991. [36] J. 
Matou5ek. Range searching with efficient hierarchi­cal cuttings. In Proc. 8th Annu. ACM Sympos. Com­put. 
Geom., pages 276 285, 1992. [37] J. Matoukek. Reporting points in halfspaces. Comput. Geom. Theory Appl., 
2(3):169-186, 1992. [38] J. Matou5ek, R. Seidel, and E. Welzl. How to net a lot with little: small e-nets 
for disks and halfspaces. In Proc. 6th Annu. ACM Sympos. Comput. Geom., pages 16 22, 1990. [39] J. Matou5ek, 
E. Welzl, and L. Wernisch. Discrepancy and ~-approximations for bounded VC-dimension. In PTOC. 32nd Annu. 
IEEE Sympos. Found. Comput. Sci., pages 424-430, 1991. [40] J. MatouSek. Efficient partition trees. Discrete 
Com­put. Geom.j 8:315 334, 1992. [41] J. S. B. Mitchell and S. Suri. Separation and approx­imation of 
polyhedral surfaces. In Proc. 3rd A CM-SIAM Sympos. Discrete Algorithms, pages 296-306, 1992. [42] N. 
Sauer. On the densities of families of sets. Journal of 6 ombznator zal Theory, 13: 145 147, 1972. [43] 
V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of events to 
their probabilities. Theory f%obub. Appl., 16:264-280, 1971. [44] E. Welzl. Partition trees for triangle 
counting and other range searching problems. In Proc. dth Annu. ACM Sympos. Comput. Geom., pages 23-33, 
1988. 302  
			