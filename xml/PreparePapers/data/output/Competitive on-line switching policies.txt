
 Competitive On-line Switching Policies Arnotz Bar-Noy* Ari Freund t Abstract A switch, or server, serves 
n input queues, processing messages arriving at these queues to a single output channel. At each time 
slot the switch can process a single message from one of the queues. The goal of a switching policy is 
to minimize the size of the buffers at the input queues that maintain the messages that have not yet 
been processed. This is a typical on-line setting in which decisions are made based on the current state 
without knowledge of future events. This general sce- nario models multiplexing tasks in various systems 
such as communication networks, cable modem systems, and traffic control. Traditionally, researchers 
analyzed the performance of a given policy assuming some distribu- tion on the arrival rates of messages 
at the input queues, or by assuming that the service rate is at least the aggre- gate of all the input 
rates. We use competitive analysis to analyze switching service policies, thus avoiding any prior assumptions 
on the input. Specifically, we show O(log n)-competitive switching policies for the problem and demonstrate 
matching lower bounds. Introduction A basic switching problem in communication networks is the task of 
delivering messages arriving at multiple input channels through a single output channel. The main objective 
is to minimize the buffer size needed for the input channels to store messages before they are served 
(delivered) by the switch. In the simplest model, all messages are of the same size and in one unit of 
time the server has the choice of serving a message from one of the input channels. In a worst case scenario, 
many messages may arrive at the same time, whereas the server can serve only one of them. This would 
require an unbounded buffer size at the input channels. Traditionally, such pathological scenarios are 
avoided by assuming some structure on the arrival "-'-rAT~T research, Shannon Lab, 180 Park Ave., Florh~m 
Park, NJ 07932. E-maih arnotz@research.att.com. tComputer Science Dept., Technion, Haifa 32000, Israel. 
E-mail: ~rief@cs.technion.ac.iL IComputer Science Dept., Technion, Haifa 32000, Israel. E-maih landa@cs.technion.ae.il. 
§Computer Science Dept., Technion, FIaifa 32000, Israel. F-mail: naor@cs.technion.ac.iL Shirnon Lands 
t Joseph (Seffi) Naor§ patterns of messages. The most common assumption is that the aggregate arrival 
rate of the input channels is at all times less than the serving rate of the switch. Another common assumption 
is that the arrival rate in each individual input channel is either constant over time or drawn from 
some distribution. The most common distribution assumed is Poisson inter-arrival (see, e.g., [6]). This 
scenario models client-server situations where a server provides service to a set of input queues. Cus- 
tomers arrive at the queues and wait to be served. At each time unit the server selects a queue and serves 
the customer at the head of the queue. The goal is to serve the customers in such a way that the maximum 
queue length, taken over all queues and times, is mini- mized. Many network applications deal with such 
prob- lems. For example, consider a cable modem system [1]. The system has a star-like architecture controlled 
by the Cable Modem Terminating System (CMTS), located at the star's center, and the end-users are subscribers 
con- nected via Cable Modems (CM). A common standard supporting Ethernet-framed message transport between 
the CMTS and the CMs is Data Over Cable Service In- terface Specification (DOCSIS) [7]. The cable network 
is an example of a shared medium that shares its ca- pacity between the subscribers. In the upstream 
direc- tion, only one CM may communicate with the CMTS at any given moment. In the downstream direction, 
the CMTS is the sole transmitter and every CM sore every bit transmitted by the CMTS. The CMTS arbitrates 
the use of the upstream link by periodically announcing which CM is entitled to transmit its messages 
in the up- coming transmission slots. We can view each CM as a separate queue feeding onto the upstream 
link. (In fact, it is expected that the CMs will support multiple QoS classes, in which case several 
queues may be associated with each CM.) There is a buffer associated with each queue for storing overflow 
traffic. A major considera- tion for the CMTS when deciding which queue to serve is minimizing queue 
{or buffer) size. Our goal in this paper is to explore the above switching problem without making any 
a-priori assump- tions about the arrival patterns of messages. That is, at any point of time, messages 
may arrive at an arbitrary subset of the input channels. The server may serve at most one message at 
any point of time, and it has no knowledge of future arrival patterns at any of the input channels. As 
mentioned earlier, this may necessitate un- bounded buffers regardless of the switching policy used. 
We therefore evaluate the performance of switching poli- cies using competitive analysis, as is common 
in on-line settings. Thus, for a given switching policy, we com~ pare the maximum buffer size it uses 
with the maximum buffer size used by an optimal off-line policy that knows the entire sequence of arrivals 
in advance. Specifically, the competitive ratio of an algorithm is the supremum, taken over all finite 
inputs, of the ratio between the algorithm's maximum queue length and the maximum queue length in an 
optimal service schedule for the same input. We view the system as a game between an ad- versary and 
the server. The adversary decides at the beginning of each round how many messages will ar- rive, and 
in what input queues, and the server decides which input queue to serve. In a more general setting, message 
sizes may be non-uniform. We assume without loss of generality that some granularity still exists, that 
is, messages are com- posed of equal sized frames. In every time unit the server may transfer one frame 
from an input queue to the output channel. If the server is allowed to preempt its serving, i.e., switch 
between input channels in the middle of a message transmission, then this generaliza- tion is essentially 
equivalent to the basic setting. How-ever, the problem is different if once the server starts serving 
a message, it must continue to serve it until all of its frames are delivered. We address the preemptive 
case. 1.1 Our Contribution. We analyze the natural greedy on-line policy Longest Queue First (LQF) for 
our problem. This policy stipulates that the switch always serve the longest queue. Our main result is 
an upper bound of O(log n) on the competitive ratio of this policy. We complement this result by proving 
a matching lower bound. To facilitate the proof of the upper bound, we define a continuous model. In 
this model, the server is allowed to simultaneously process fractions of frames belonging to different 
queues. However, the sum of the fractions processed in one time unit cannot exceed 1. In this setting 
the LQF policy is to serve equally all the longest queues. Specifically, if at a given time the number 
of queues with maximum length (among all queues) is k, then the server will process a fraction of l/k 
(of a frame) from each queue. We show that the fractional LQF policy is H,-competitive (where H= = ~=a 
1/k ~ In n is the nth harmonic number). We also prove a lower bound of Hn on the competitive ratio of 
every on-line algorithm (even randomized). We use these results to bound the competitive ratio of an 
LQF-like policy for the discrete setting. Specifically, we show that the cost of this discrete policy 
is only an additive term of 1 + log 2 n away from the cost of the fractional LQF policy. We also prove 
logarithmic lower bounds ranging from H, to 1 + log 2 n for the discrete model. We believe that the 
continuous model is of indepen- dent interest. For example, suppose that the size of a frame is "one 
bit" and that the server, per one unit of time, is capable of serving at most B bits (in units of bandwidth) 
from all the input queues. Then, if B is large, we converge to the continuous model. Finally, we also 
provide an efficient off-line algo- rithm to compute the optimal service policy. The run-ning time of 
the algorithm is polynomial in the number of frames and time units. 1.2 Related Work. A switching model 
similar to ours is considered in [6]. They assumed that the aggregate arrival rate at the input channels 
at any point of time is no more than the serving rate, and that each queue has a fixed arrival rate. 
In addition, they assumed non-uniform size messages and disallowed preemption when serving a message. 
Under these assumptions, they showed that the Least Time to Reach Bound policy bounds the size of the 
longest queue by a constant 2L, where L is the maximum message size. Note that we cannot adopt similar 
ideas, since we make no assumptions on the arrival rates, and therefore do not know which buffer would 
reach the bound of 2L first. References [10, 12] achieve the same bound in the same model with a more 
complicated policy that could also be applied to other models. Reference [9] showed that the Longest 
Queue First policy fails to bound the longest queue with a constant factor (even under the above assumptions). 
They proved a logarithmic upper bound on the size of the longest queue. Other papers [8, 13] explored 
versions of the Round Robin policy in which queues are served in a predetermined cyclic order. They assumed 
further that the arrival rates at all queues are the same. With this additional assumption, they were 
able to bound the size of the longest queue by a constant. Minimizing the delay messages incur before 
being delivered is another important optimization goal. For example, reference [5] explores the First 
Come First Served switching policy, which is natural for this op- timization goal. On-line policies for 
minimizing buffer overflow in Quality-of-Service switches were studied in [11]. They used competitive 
analysis to evaluate var- ious policies. A problem similar to our switching problem arises in the context 
of on-demand data broadcasting (see, e.g., [2]). Clients communicate with a server through two independent 
networks: a network for sending re- quests to the server (up-link), and a "listen only" net- work from 
the server to the clients (down-link). Clients send requests to the server for data items that, say, 
they cannot find locally. Client requests can be queued up at the server upon arrival. The server chooses 
(iteratively) a data item among the unsatisfied requests, broadcasts it, and removes the request from 
the queue. Once a client makes a request, it monitors the down-link until it receives the data item it 
is waiting for. We can think of the data items as defining input queues and the cus- tomers requesting 
a data item are queued in the appro- priate queue. The main difference between this model and the switching 
model is that here, all the customers queued in a particular queue can be served together by broadcasting 
the data item they are waiting for. The main issues studied in this model are average and max- imum waiting-time 
of customers. Load balancing problems are also related to our switching problem. In traditional load 
balancing prob- lems, a number of servers are ready to provide service to a set of customers that arrive 
over time. Each cus- tomer can be handled by all, or by a subset, of the servers. Customem arrive one 
by one, each with a differ- ent amount of required service, and the goal is to assign each customer to 
an appropriate server in a manner that minimizes the maximum load on the servers. (See e.g., [4, 3].) 
Using switching terminology, in the load balanc- ing problem, messages arrive over time, and the switch 
has to decide in which buffer to place them so as to minimize the size of the largest buffer. In our 
switching problem the serving policy has no control over where the messages go, but can reduce buffer 
size by serv-ing the buffers. In this sense, load balancing problems are "dual" to the switching problem 
studied in this pa- per. The lower bounds for both models are very similar. However, upper bounds for 
load balancing do not seem to carry over to our problem. 1.3 Paper Organization. In Section 2 we define 
the problem formally and introduce some of the notation and terminology used later on. In Section 3 we 
analyze the continuous model. In Section 4 we deal with the discrete model. 2 Preliminaries Informally, 
the switch system consists of n input queues through which messages arrive at the switch, and an output 
channel through which messages are delivered. Several messages may arrive simultaneously at different 
queues. Each message consists of a number of equal sized frames. At every time unit the switch may transmit 
at most one frame from one of the queues. To be precise, the order of events in each time unit is that 
first any new frames arrive at the queues, and then the switch decides which queue to serve. We assume 
the preemptive model in which the switch may deliver some of the frames belonging to one message, then 
switch to another message, and later return to complete the delivery of the first. An on-line algorithm 
is an algorithm that decides which queue to serve at each time unit without knowl- edge of future arrivals. 
Given a finite sequence of events (i.e., message arrivals), the cost of an algorithm is the maximum length 
of a queue, taken over all queues and times. We denote the optimal off-line cost by OPT. We assume that 
messages arrive instantaneously, that is, a message arrives at a certain moment and the length of the 
queue increases instantaneously by the message's length. This models a situation in which the trans-mission 
of a message may not commence until all of its frames have arrived. We think of the moment of the last 
frame's arrival as the moment in which the en- tire message arrives. We can map this simplified model 
onto a more realistic model in which messages arrive one frame at a time, by splitting each queue (in 
the more re- alistic model) into a frame-queue, for holding frames of partially arrived messages, and 
a message-queue, into which a message is transferred once its last frame ar- rives. The queues in our 
model reflect the behavior of the message-queues in this setting. Note that cost in the second model 
takes into account the size of the frame- queues as well as the message-queues. However, since the size 
required for the frame-queues only depends on the input (and not on the switching algorithm, be it on- 
line or off-line), there is little meaning to a comparison that takes them into account. In Section 3 
we consider a continuous model, which is a relaxation of the discrete model we have just de- scribed. 
In this model time is continuous, message lengths are arbitrary positive reals, messages may ar- rive 
at arbitrary (non-integer) times, and, most impor- tantly, the switch transmits messages in a continuous 
manner rather than in discrete frames. In particular, at every point in time the switch transmits from 
all queues simultaneously, at different rates from different queues. Formally, there are n queues, named 
for sim- plicity 1,..., n. The input is an alternating sequence R1,7"1, R2, T:,..., Rm_ 1, Tin_ 1, R~. 
Each Tj in the se- quence is a service interval and each Rj is a request. A service interval is simply 
a time interval. We denote Tj = (tj, ~j+l), and for concreteness, tl : 0. A request is a vector in I~.. 
We denote R i = (rjl, rj2,..., rjn). We say that Rj arrives at time tj. Each component rjk represents 
a message of length rjk arriving at queue k. The response of the algorithm to the input is a vector 
of n non-negative integrable functions of time (f,,...,f,) such that for all times t: (1) y'~=~ f~(t) 
< 1, t and (2) f0 fl (v) dr < Y~jlt~<t rj~ for all i. The length of queue i at timer is ~-]~jltjst rJl-f 
t f~ (~-)dr. We use the terms length and load interchangeably (e.g., we speak of the total load on the 
queues, meaning the sum of their lengths). We say that at time ~, the algorithm consumes load from queue 
i at a rate of fi(t)- The cost of the al- gorithm is the maximum queue length, taken over all queues 
and times. Finally, in the sequel we consider the responses of an on-line algorithm and an off-line algo- 
rithm to the same input sequence. We will speak of the on-line queues, on-line load, etc., at a given 
moment, as compared with the off-line queues, off-line load, etc., at the same moment. The discrete model 
can be viewed as a restriction of the continuous model in which: (1) all service intervals have integral 
lengths; (2) requests are vectors in H"; and (3) for all i and r E 1~I, either f~ it) = 0 in the time 
interval (r, r + 1) or f~(t) = 1 in that interval. 3 The Continuous Model In this section we address 
the continuous model defined in Section 2. Our main result is an analysis of the LQF heuristic in this 
model showing that its competitive ratio is H~ (the nth harmonic number). We present it in Section 3.2, 
omitting most proofs to accommodate the page limit. We also prove that H, is a lower bound on the competitive 
ratio of every on-line algorithm (even randomized). We prove this first. 3.1 A Lower Bound. Let e > 0. 
We show that for every on-line algorithm there exists an input sequence with optimal off-line cost e 
such that the algorithm in- curs a cost of at least /am e. We describe the con-struction of the sequence 
in terms of the following cruel adversary. The idea is that the adversary generates new messages at the 
queues that were not served by the on- line algorithm (in a certain window of time). 1. Generate request 
R1 = (e,e,..., c) at time tl = 0. 2. For j= 1,2,...,n-l: 3. Generate service interval Tj = (~j,tj+l), 
where tj+l = tj + c(n -j). 4. Let Ij be the set of the n -- j on-line queues with maximum load (breaking 
ties arbitrarily) at the end of service interval Tj. During Tj consume all the load from all queues i 
E [j. 5. Generate request Rj+I: the ith component of Rj+I is c if i Elj, and is 0 otherwise.  It is 
easy to see that the total load on the on-line queues in Ij at time tj+l {after request Rj+I arrives) 
is j-1 at least e(n -j)(1 + )"~k=0 ~-k)" Thus, the length of the single queue in In-1 at the end of the 
sequence is at least c(1 + E =0 = H,.c. Turning to randomized algorithms, the same con-struction works 
(even with respect to oblivious adver- saries) if we define Ij as the set of n -j queues with maximum 
expected load. Thus, we get the fo|lowing theorem. THEOREM 3.1. The competitive ratio of every algo-rithm 
is at least Hn. This is true for deterministic ab gorithms as well as randomized ones (even with respect 
to oblivious adversaries}. 3.2 Analysis of the LQF Policy. Having shown a lower bound of H,~, we now 
show that the LQF policy achieves this bound. In the continuous model, Algorithm ContinuousLQF is the 
following. Let l(t) be the set of queues with maximum length at time t. At time t the algorithm consumes 
load at a rate of 1/]I(t)l from each of the queues in lit). The remainder of this section is dedicated 
to the proof that Algorithm ContinuouskQF is Hn-competitive. The idea of the proof is to approach the 
problem from the adversary's point of view. Rather than analyze the behavior of Algorithm ContinuousLQF 
when faced with a generic adversary, we search for an adversary that will maximize the algorithm's cost, 
given that the optimal (off-line) cost is fixed at some value. Essentially, we prove that the adversary 
described in the lower bound construction (Section 3.1) is the worst adversary possible (from the algorithm's 
point of view). This implies that the competitive ratio of the algorithm is H.. Without loss of generality, 
we assume that the cost of ContinuousLQF is always determined by the arrival of the last request, and 
only by it. In other words, the maximumqueue length, taken over all queues and times, occurs only after 
the arrival of the last request. DEFINITION. The load profile A = (A(1),...,A(n)) of the on-line queues 
at a given moment is the list of the on-line queue lengths sorted in non-increasing order. TERMINOLOGY. 
The arrival of a request R at a given time t changes the system's state (i.e., queue lengths, load profile, 
etc.) instantaneously. In order to distin- guish between the state of the system immediately prior to 
R's arrival and the one immediately following it, we use the phrase when R arrives or simply at time 
t to describe the former, and the phrase due to R for the latter. Note that a given load profile can 
correspond to dif- ferent load distributions, but these distributions will be identical up to permutations 
of the queue names. The load profile captures the essence of the load distribution (at least as regards 
Algorithm ContinuousLQF), freeing us of the need to track changes in the length of any specific queue. 
We extend this idea to requests as well. DEFINITION. Let A = (A(1), ..., A(n)) be the load pro- file 
when a request R = (rl,..., r,) arrives. The request profile of R is the unique list ~ = (~(1),..., 7~(n)) 
such that there exists a permutation ~r on {1,...,n} such that 1. for all i, ~(i) -r~r(i); 2. for all 
i, the length of on-line queue i when R arrives is .A(~(i)); 3. for all i < j, if.A(/) = .A(j) then 
~(i) > ~(j).  If ~(1) > 7~(2) _> ..- _> 7~(n), the request profile is said to be monotone. Note that 
a given request R may have different profiles, depending on the load profile at the time of its arrival, 
but these profiles will be identical up to a permutation. Conversely, a given request profile may describe 
different requests (depending on the load profile), but these will be identical up to a permutation of 
the queue names. NOTATION. If D is a load profile or request profile, its entries are denoted (~D(1),..., 
~D(n)). Similarly, if R is a request, its components are denoted (rl,..., r~). The following observation 
allows us to conduct the discussion in terms of load and request profiles, rather than specific queue 
lengths and requests. OBSERVATION 3.1. Consider two input sequences such that the load profile is identical 
for both at some time t, and such that: (1) the sequence of service intervals following time t is identical 
for both sequences; and (2) the sequence of request profiles following time t is identical for both sequences. 
Then at all times t' > t the load profile is identical for both sequences. Our analysis revolves around 
the level of imbalance in the load profile. Intuitively, the more imbalance present in the profile at 
a given moment, the more the on-line algorithm will he forced to pay somewhere down the road. To formalize 
the idea of imbalance, we define a binary relation between load profiles. DEFINITION. Let A and B be 
two load profiles. Then .A ~13 if E,%1 .A(i) _< 13(0, 2. there exists 1 < z < n such that A(i) 5 B(i) 
for all i < x and A(i) > B(i) for all i > x. To better understand how this relation expresses imbal- 
ance, note that if A N B, then 13 can be obtained from ,4 by a sequence of steps in which we transfer 
some load from a short queue to a long queuc, or simply increase the load on along queue. (The classification 
of short and long queues is determined by the choice of x.) The salient property of Algorithm ContinuouskQF 
is that when viewed as a function on load profiles, the algorithm is monotone with respect to 4-By this 
we mean that if load profile .4' results from A (by executing the algorithm for a certain duration), 
and B' results from 13, then A ~ 13==~ A' ~ B'. To show this, we must first lay down some groundwork. 
NOTATION. For a given load profile A and s _> 0, let l~t(i,s) = max{A(i)-s, 0} for all i. Denote l~t(s) 
= E7=1 l (i, s). OBSERVATION 3.2. Let A be a load profile. Then, if s < s' <_ A(1), the. l (s) > LEMMA 
3.1. Let .A and 13 be two load profiles such that ,4 ~ 13. Then l~(s) <_ IB(s) [or all s >_ O. LEMMA 
3.2. Let A and B be two load profiles. Consider the following two scenarios in which Algorithm Continu-ousl_QF 
is allowed to run in a time interval (t, t'), dur-ing which no requests arrive. In the first scenario 
the load profile at time t is A, and in the second it is B. Let A' and 131 be the resultant load profiles 
at time t' in both scenarios, respectively. Let s~ = A'(1) and Sb = Br(1). Then, if A ~ 13, then: (1) 
E~=, A'(i) < En=a 13'(i), and (2) sa < Sb. LEMMA 3.3. Referring to the scenarios and notation of Lemma 
3.$, ira ~ 13 then A' ~ 13'. Proof. Suppose A ~ B. By Lemma 3.2, ~-'~.in__~ A'(i) _< ~-~q=113 (I) and 
Sa < Sb. Thus A'(1) <_ 13'(1). If .A(i) < 13(i) for all i, then A' Z B' and we are done. Otherwise, let 
y = min{i [A'(i) > 13'(i)} -1. We claim that y plays the role of "z" in the definition of 4- First, by 
construction, A'(i) < 13'(i) for all i < y. Next, consider any i > y. To see that 13'(i) < .AV(i), observe 
that 13'(0 <-13'(Y + 1) < A'(y + 1) < Sa _< sb. Thus, if A'(i) = sa then 13'(i) _< A'(i). Otherwise, 
A'(i) < sa and, as we have seen, B'(i) < B'(y + 1) < sb. Since A' can be obtained from A by replacing 
every A(j) with rain {A(j), sa}, and a similar statement holds for B', we conclude that At(i) = .A(i), 
B'(i) = B(i) and 13'(y + 1) = B(y + 1). It therefore suffices to show that B(y+l) < A(y+l}, which implies 
B(i) _< `4(0 (because `4 ~ B and i > y + 1). But this is certainly true since B(y + 1) = B'(y + 1) < 
A'(y + 1) _< A(y + 1). II LEMMA 3.4. Let A and 13 be two load profiles. Consider the following two scenarios. 
In the first, the load profile is A and a request with request profile ~ arrives. In the second, the 
load profile is 13 and a request with request profile g arrives (the same 7~ in both scenarios). Let 
`41 and 13~ be the resultant load profiles, respectively. Then, if`4 ~ 13 and 7~ is monotone, then .41 
~ B I. LEMMA 3.5. Consider two input sequences 11, I2 such that there exist two times tl, t2 such that 
the service intervals and the request profiles in the suffix of I1 starting at time tl are identical 
to those in the suffix of I2 starting at time t2, and such that said request profiles are all monotone. 
Let ,4 and B be the load profiles at times tl and t2 in 11 and 19, respectively, and suppose ,4 ~ 13. 
Let 5 > O, and let let`46 and13~ be the load profiles at times tl + J and t2 + ~, respectively, for 11 
and Is. Then .A6 4 13~- Thus the on-line cost for I2 is at least as high as it is for I1. Having established 
the basic facts about load pro- files, we are now ready to analyze the competitive ratio of ContinuousLQF.Rather 
than analyzing the behavior of ContinuousLQF given an off-line adversary, we azaalyze the best off-line 
strategy given the behavior of Contin- uousLQF. Fix any c > 0. We aim to show that the maximum cost ContinuousLQF 
can be made to pay for a sequence whose off-line optimum is c is H. -c. DEFINITION. An adversary is c-opt 
if its cost is c. DEFINITION. Adversary A is said to be better than adversary B if A causes ContinuousLQF 
to pay at least as much as B does. (Note that every adversary is better than itself.) A c-opt adversary 
is best if it is better than every e-opt adversary. Henceforth we deal exclusively with c-opt adver-saries, 
even when we neglect to say so explicitly. Our work-plan is to identify five properties of adversaries 
and show that for any given c-opt adversary there is a bet- ter c-opt adversary that has all five properties. 
We will then prove that the best adversary among those having all five properties exacts from ContinuousLQF 
a cost of precisely /am c. The names we give the five properties are simply A, B, C, D, and E. PROPERTY 
A. An adversary has Property A if at all times during every service interval it consumes load at a rate 
of 1. PROPOSITION 3.1. For every e-opt adversary there is a better c-opt adversary that has Property 
A. PROPERTY B. A single request has Property B if its arrival causes all off-line queues to reach length 
c. Otherwise, it is said to violate Property B once per queue whose length does not reach c. A c-opt 
adversary has Property B if all the requests it generates have Property B. If it does not have Property 
B, it is said to violate Property B k times, where k is the total number of times its requests violate 
Property B. PROPOSITION 3.2. For every c-opt adversary there ex-ists a better c-opt adversary that has 
Properties A and B. PROPERTY C. A request profile ~ has Property C if there exists 1 <_ x < n such that 
c = 7~(1) ----- ~(2) = .. = -1) >_ >_ + I) = + 2) = .---- ~(n) --0. A request has Property C if its 
profile has Property C. Otherwise, the request is said to violate Property C. A c-opt adversary has Property 
C if all the requests it makes have Property C. OBSERVATION 3.3. Suppose that a given request arrives 
at time t. Consider the possibilities for the next request, given that: (1) it must arrive at a given 
time t I > t, (2) it must have Property B, and (8) the adversary is e-opt and has Property A. Given these 
constraints, it is easy to see that among all request profiles possible for the request at time t', exactly 
one has Property C, and the adversary can achieve it by following Rule C below. (Note that the load profile 
at time t r is independent of what the adversary does between t and t'.) Rule C: Let A' be the load profile 
at time t t and let ql,q2,...,qn be an ordering of the queues such that A'(i) is the load on on-line 
queue qi at time t ~. Consume load during the interval (t,t I) as follows. Start by consuming load from 
queue ql. When it empties, proceed to queue q2, then to qa, etc. At time t t generate a request that 
will restore all off-line queue lengths to c. Henceforth, we assume that if an adversary has Proper- 
ties A, B, and C, then it always operates by Rule C. PROPOSITION 3.3. For every c-opt adversary there 
ex. ists a better c-opt adversary that has Properties A, B, and C. PROPERTY D. A request has Property 
D if the support of its profile (i.e., the set of indices of the profile's non-zero entries) is strictly 
contained in the support of the request profile that precedes it. Otherwise the request is said to violate 
Property D. A c-opt adversary has Property D if all the requests it makes have Property D (the first 
request is always considered to have Property D). Note that if an adversary has Property C, the sup- 
port of every request profile has the form {1,2 .... , z}. DEFINITION. A load profile ,4 is said to be 
k-flat with height s if A(1) --..= A(k) = s. PROPOSITION 3.4. For every c-opt adversary there ez- ists 
a better c-opt adversary that has Properties A through D. PROPERTY E. A request has Property E if every 
entry in its profile is either 0 or c. Otherwise, it violates Property E. A c-opt adversary has Property 
E if all of the requests it generates have Property E. PROPOSITION 3.5. For every c-opt adversary there 
ex-ists a better c-opt adversary that has Properties A through E. Proof. Consider an adversary. By Proposition 
3.3 we may assume it has Properties A through D. We show that if it does not have Property E, it can 
be changed into a better adversary that makes one less request violating Property E (and still retains 
Properties A through D). Let R be the last request that violates Property E, let ~ be its request profile, 
and let t be its time of arrival. From Properties A through D it follows that 7Z has the form e = ~(1) 
= --. = ~(z-1) > 7~(2) --c - g and ~(z + 1) =-.. --7~(n) = 0, for some z. It is also easy to see that 
these properties imply that when R arrives, the load profile is z-fiat with some height s. By Property 
B, R is not the first request in the input sequence. Let A be the load profile at time t. There are three 
cases to consider. Case 1: x = 1. Then by Property D request R is the last request in the input sequence, 
and the cost of ContlnuousLQF is z + c -~. We delay the request's arrival by d. As a result, the load 
profile at time t + d will be 1-fiat with height at least s-d, and by Rule C the request profile will 
become (c, 0, 0 .... ,0). Thus, the cost of ContinuousLOF does not change. Case 2: x > 1 and either R 
is the last request or the support of the profile of the request following R is {1,...,='} where z' < 
t-2. Let Bbe the load profile due to R. We shorten the service interval preceding R's arrival by c - 
d and replace R with a request whose profile ~ satisfies 7~'(1) = ---= ~'(2-1) = c and 7~'(z) =...= ~'(n) 
= 0. The effect of this modification is that the load profile when 7~' arrives is x-flat with height 
s' > s. It is easy to see that from this point onward, the length of every queue i < z -1 will be greater 
by s' -s than its length in the original scenario. This is so because all of the requests following ~ 
satisfy Properties A through D. Case 3: Otherwise, x > 1, R is not he last request, and the support 
of the request R t following R is {1,...,x-1}. Let ,4' be the load profile when ~' arrives. The length 
of the service interval between and ~' is e(z - 1). Thus ,4' is z-flat with height s' = s + (c -ti)/z 
and A'(i) --A(i) for all i > 2. We change the adversary by delaying the arrival of :~ for tf time units 
and replacing it with /~ whose profile satisfies fi(1} = -.. = = c and :~(2 +I) ---.-= ~(n) = 0. The 
load profile when 7~ arrives is x-flat with height g > s -ti/x and it satisfies .A(i) < A(i) for all 
i > z. The load profile .A' when ~' arrives is therefore z-flat with height ~' = ~+c/z > s+(c-g)/x = 
s'. In addition, .A'(i) = A(i) < A(i) = A'(i) for all i > 2. Thus, ,4' ~ A', and the new adversary is 
better than the original one by Lemma 3.5. | PROPOSITION 3.6. Among all adversaries having Prop- erties 
A through E, the following adversary is best: Gen-erate n requests such that the support of the ith re-quest's 
profile is {1,..., i}. This adversary causes Con-tinuousLQF to incur a cost of Hn . c. Proof. The proof 
is by induction on the number of queues n. For n = 1 it is trivial. Assuming the claim holds for n -1 
> 1, we prove it for n. Consider an adversary with Properties A through E. The support of its first request 
is {1 .... ,n}. If this is also the last request, then surely we can add a service interval of length 
c followed by a request with Properties A through E, and increase the cost of ContinuousLQF. Otherwise, 
let k -c be the length of the first service interval (k is an integer). The load profile at the end of 
this interval is n-fiat with height e(n -k)/n. It is easy to see that the cost incurred by ContinuousLQF 
is therefore (n -k)/c plus the cost incurred by it had it been run on the remainder of the input sequence 
with n -k queues. By the inductive hypothesis this cost is maximized at H,-k c and can be achieved by 
the adversary described in the claim. Thus the maximum total cost is c((n -k)/n + Hk), which is maximized 
at Hn - c by taking k = n -1 and using the adversary described in the claim, g COROLLARY 3.1. The competitive 
ratio of Algorithm ContinuousLQF is precisely Ha. 4 The Discrete Model In this section we consider the 
discrete switching prob- lem. We start by presenting an off-line algorithm for finding an optimal service 
schedule. Following that we discuss lower bounds, and then analyze a variant of the LQF policy, showing 
that its cost is within an additive term of 1 + log~ n of the cost of Algorithm Continu- ousLQF. Thus, 
its competitive ratio is asymptotically (when OPT>> n) Ha. 4.1 An Off-line Algorithm. Our algorithm is 
based on the following observation. Fix L > 0 and consider a switching policy that leads to an event 
where some queue length exceeds L. Consider the frame f at the head of the queue when that happens. It 
must be true that in the duration since this frame's arrival, at least L new frames have arrived at the 
queue, but the frame in question has still not been served. This leads to the following observation. 
OBSERVATION 4.1. No queue exceeds length L if, and only if, every frame is served before L additional 
frames arrive at the same queue. Given L, the following procedure finds a solution with cost at most 
L, if such a solution exists. 1. Construct a bipartite graph G = (U, V, E), where U is the set of all 
frames; V is the set of all relevant time units, i.e., V = { 1,..., tm~x + N }, where tr~x is the arrival 
time of the latest message and N is the number of frames; and E connects each frame f to time units tl,t 
! + 1,...,t~], where t! is the arrival time of f and ~ is the latest time such that less than L frames 
arrive at the queue (following f) up to time t~. 2. Compute a maximum matching M in G. 3. If all the 
vertices in U are matched, M defines the desired solution (up to a permutation of the time units assigned 
to frames which is necessary to ensure that they are served in the order in which they arrive). Otherwise, 
there is no solution of cost at most L.  We find the minimal L for which a solution exists by performing 
a binary search using the above procedure, which also returns a valid service schedule for that L. 4.2 
Lower Bounds. The deterministic lower bound construction given for the continuous model in Sec-tion 3.1 
can easily be seen to hold in the discrete model as well, by taking e to be an integer. In fact, the 
same construction can be seen to work even if we restrict the allowable messages to each consist of exactly 
one frame. We simply replace each message of length e by c single- frame messages arriving one after 
another. (The time it takes for all of these messages to arrive is deducted from the service interval 
following them.) A nearly identical analysis holds for this case, except that the last round (c message 
arriving at the longest queue) might only contribute 1, rather than c, to the final cost, because the 
c units of time required for the messages to arrive may be used by the algorithm to consume them as they 
come in. Thus, in this case the lower bound drops to H,-1. For small values of OPT we can give tighter 
bounds. In particular, for a given on-line algorithm, the following sequence hem OPT = 1, but an on-line 
cost of at least 1 + log 2 n. We assume n is a power of 2. The sequence consists of l+log 2 n rounds. 
In the ith round one single- frame message arrives at each of the n/2 i-1 longest queues, and a service 
interval of n/2 i time units follows. It is easy to see that after the arrival of the ith round of messages, 
the total load on the n/2 i-1 longest queues it at least i. n/2 i-1. Thus the on-hne cost is at least 
1 + log 2 n. The optimal off-line algorithm uses every service interval to consume one message from each 
of the queues about to be "hit" in the next round, and thus maintains a maximum queue length of 1. 4.3 
A Competitive LQF-like Switching Policy. We first consider the special case OPT = 1 and show that the 
LQF policy incurs a cost of at most 1 + log 2 n. We then use this result to bound the cost of a variant 
of LQF in the general case. 4.3.1 Analysis of LQF in the Special Case OPT = 1. Consider Algorithm DiscreteLQF: 
at each time slot, ff there is a non-empty queue, transmit one frame from the longest queue (breaking 
tie~ arbitrarily). We claim that in the special case OPT = 1 the cost of Algorithm DiscreteLQF is at 
most 1 + log 2 n. Note that OPT = 1 implies that every request is a 0-1 vector. The proof proceeds along 
the same lines as the proof for the continuous model, with c = 1. Specifically, all of the claims made 
in Section 3.2 up to Proposition 3.3 (inclusive) hold for our case as well, and the proofs are the same, 
except that Lemma 3.3 and Proposition 3.2 require slightly more elaborate proofs. We now restate Proposition 
3.5 and prove it for our case. We use some of the terminology introduced in Section 3. PKOPOSITION 4.1. 
For every l-opt adversary there ex- ists a better 1-opt adversary that has Properties A through E. Proof. 
Consider a 1-opt adversary. By Proposition 3.3 we may assume it has Properties A, B, and C. Since requests 
are 0-1 vectors, it also has Property E by definition. If it does not have Property D, we show how to 
change it so that it makes one less request and at the same time becomes better (and retains Properties 
A, B, C, and E). Let R ~ be the first request in the input sequence that violates Property D and let 
R be the request preceding it. Let t ~ and t be their arrival times, respectively. Let 7~ be the request 
profile of R and let .A be the load profile at time t. Then = (1, 1,..., 1,0, 0,..., 0), where the number 
of l's in ~, denoted k, satisfies k < t t - t. One can easily verify that there exist 1 < l < k and s 
such that .A(1) = .. = ~t(l) = s ang,4(l + 1) = ... = .4(k) = s-1. This is a consequence of the fact 
that all of the requests up to R have Properties A through E. Thus, the load profile A due to R satisfies 
A(12 .... = .~(l) = s + 1, ,4(l+1) =...= .,4(k) -s, and A(i) < s-1 for all i > k. Hence, k time units 
into the service interval separating R and R ~, the load profile is identical to A. We omit R and the 
service interval following it, and replace them with a delay of t ~ -t - k time units. By Lemma 3.5 the 
modified adversary is better than the original one. 1 NOTATION. Consider a given adversary that has Prop- 
erties A through E. The request profiles it generates have the form (1, 1,..., 1,0,0 .... ,0). Let m 
denote the number of requests it generates and let kj denote the number of l's in the jth request profile. 
PROPOSITION 4.2. Among all adversaries having Prop- erties A through E, the following adversary, described 
in terms of the request profiles it generates, is best: kl = n; k,~ = 1; and kj+l = [kff2J for all 1 
<_j < m. This ad- versary causes ContinuousLQF to incur a cost of at most 1 + log 2 n. Praof. Consider 
a 1-opt adversary that has Properties A through E. Then kl = n by Property B, and we may assume km "- 
1, for otherwise we can extend the input sequence by a service interval of one time unit followed by 
a request whose profile is (1, 0, 0,..., 0). If kj+l = [kj/2J for all j, we are done. Otherwise, Let 
j' be minimal such that equality does not hold. Observe that Properties A through E and the fact that 
k/+l = [kj/2J for all j < f ensure that the load profile due to the fth request is kj,-flat. If kj,+x 
< [kj,[2] we extend the j'th service interval by [kj,/2J -kj,+l time units, and if kj,+l > [kf J we shorten 
it by k2+1 -[kj,/2J. In either case we adjust the adversary to comply with Rule C (and consequently the 
(j' + 1)th request changes such that kj,+l becomes equal to [kj,/2J). It is easy to see that in either 
case the original load profile due to the (j' + 1)th request is ~ the new one. Thus by Lemma 3.5 the 
new adversary is better than the original one. There might be a problem, though, if kj,+2 >_ [kj,/2J 
(which is possible if originally kj,+l > [kj,/2J). The problem is that Property D will now be violated 
by the (j' + 2)th request. In this case we apply the transformation described in the proof of Proposition 
4.1, which shortens the input sequence by eliminating the (j~ + l)th request and possibly some additional 
requests following it, but not the last request (and thus retaining kl = n and k,~--1). We have thus 
managed to either eliminate one occurrence of kj+l ~£ [kj/2J without changing the length of the input 
sequence, or shorten the sequence. Thus, in a finite number of iterations we can obtain a better adversary 
with all the desired properties. | COROLLARY 4.1. If OPT = 1 then the cost of Dis-creteLQF is at most 
1 + log 2 n. 4.3.2 An LQF Variant for the General Case. Consider the following algorithm. The algorithm 
main- tains a simulation of Algorithm ContinuousLQF. At the end of each time unit it computes the load 
distribution that would be seen by ContinuousLQF at that point in time. Let It im and li be the load 
on the simulated and actual queue i, respectively. The algorithm selects any queue i such that li > 1~ 
im and consumes one unit of load from it. Note that the algorithm has a degree of freedom in the choice 
of queue i. We call this algorithm GenericSimulatedLQF. The next Lemma follows by an easy induction on 
the time units. LBMMA 4.1. For every time unit: 1. At the beginning el the time unit (after any possible 
request arrives) the total simulated load equals the total actual load. 2. At the beginning of the time 
unit Ii > [l~imJ for all i. 3. At the end of the time unit (before GenericSimulat-edkQF consumes load) 
there is at least one queue i such that li > l~ im, unless the total load is O.  PROPOSITION 4.3. The 
cost of GenericSimulatedLQF is less than Hn OPT+ n -1. Proof. Consider the beginning of a time unit. 
Let j be such that lj -l~ im is maximized. By Lemma 4.1, rs l n /sire sire n l sim  o = =lj-l ).By the 
same lemma, Ii > I/sirn I and thus Ii -l~ im > -1, for -- Li J~ all i. It follows that lj -l~ 'r* < 
n -T. Thus the cost of GenericSimulatedLQF is less than n --1 plus the cost of ContinuousLQF, which 
is at most H,. OP~ ~_ Hn" OPT, where OPT* is the optimum in the continuous model. | Recall Algorithm 
DiscreteLQF from Section 4.3.1. It is not difficult to see that this algorithm is an instance of GenericSimulatedLQF, 
and thus Proposition 4.3 applies to it. Next consider Algorithm GreedySimulatedLQF, which is the instance 
of GenericSimulatedI.QF that al-ways consumes load from the queue i that maximizes li -[l~ira] (breaking 
ties arbitrarily). Again, Propo- sition 4.3 applies, but this time we cma give a better bound, Define 
the residual load on queue i at a given moment to be li -l~im at that moment. The resid- ual loads can 
be viewed as in instance of the switching problem: when the simulation of ContlnuousLQF con- sumes load 
from a set of queues their residual loads increase (and we interpret this as the arrival of a resid-ual 
request); when GreeclySimulatedLQF (or any other instance of GenericSimulatedlQF) consumes load from 
a queue its residual load drops by 1 (and we interpret this as consumption of one unit of residual load). 
Note that the arrival of a request increases the actual loads and the corresponding simulated loads by 
the same amount, so the residual loads do not change. Thus, if we restrict our attention to the residual 
loads, we see that Algo- rithm GreedySimulatedLQF acts on them as Algorithm DiscreteLQF. Thus the cost 
of Algorithm GreedySimu- latedLQF is at most the cost of ContinuousLQF plus the cost of DiscreteLQF with 
respect to the residual loads. We claim that the optimum for the residual loads is 1, and therefore, 
by Corollaries 3.1 and 4.1, the cost of GreedySimulatedLQF is at most Hn OPT+ 1 + log 2 n. LBMMA 4.2. 
The optimum .for the residual loads is 1. Proof. First observe that at any given time unit the total 
drop in the simulated load is at most 1, and thus the residual load on any given queue cannot increase 
by more than 1. Thus the residual requests are 0-1 vectors. Furthermore, by Lemma 4.1, the total residual 
load is never greater than n. Thus the (off-line) algorithm that always consumes load from the non-empty 
queue that is about to be "hit" earliest achieves a cost of 1. I COROLLARY 4.2. The cost of Algorithm 
GreedySimulat- edLQF is at most H,~. OPT+ 1 + log2 n. The best upper bound we have been able to prove 
is that of Corollary 4.2. However, we were unable to demonstrate that Algorithm GreedySimulatedlQF (or, 
for the matter, Algorithm Di~reteLQF) actually ever incurs this cost. It seems that the competitive factor 
depends on the value of OPT. As we have seen, for OPT= 1 it is 1 + log 2 n, and it seems to monotonically 
decrease towards Hn as OPT increases. We conjecture the following. CONJECTURE 4.1. The cost of GreedySimulatedLQF 
is at most Hn OPT+ f(OPT, n), where I(OPT, n) is a .function that decreases monotonically with respect 
to OPT and satisfies f(1,n) : 1 +log 2n- [In and limoPT-.~ f(OPT, n) = O. The same is true for DiscreteLQF. 
 References [1] G. Armitage. Quality of service in IP networks. Pearson Higher Education, 2000. [2] D. 
Askoy and M. Franklin. Scheduling for large scale on-demand data broadcasting, in Proc.o] In]scorn, pp. 
651-659,1998. [3] Y. Azax, J. Naor and R. Rom. The competitiveness of on-line assignments, in Journal 
o1 Algorithms, Vol. 18, pp. 221-237, 1995. [4] Y. Azar. On-line load balancing. In On-line Algo- rithms: 
The State o] the Art, Editors A. Fiat and G. Woeginger, LNCS 1442, Springer, pp. 178-195, 1998.  [5] 
A. Birman, P. C. Chang, J. S. C. Chen, R. Guerln. Buffer Sizing in an ISDN Frame Relay Switch. IBM Research 
Report, RC14386, 1989. [6] A. Birman, H. R. Gall, S. L. Hantier, Z. Rosberg, and M. Sidi, An Optimal 
Service Policy for Buffer Systems. In Journal o] the Association Computing Machinery (JACM), Vol. 42, 
No. 3, pp. 641-657, 1995.  [7] CableLabs. Data-over-Cable Service Interface Specifi- cations. Radio 
Frequency Specifications, SP-RFIvl.1-101-990311." (1999). [8] I. Cidon, I. Gopal, G. Grover, and M. Sidi. 
Real-Time Packet Switching: A Performance Analysis. In IEEE Journal on Selected Areas In Communication, 
Vol 6, pp. 1576-1586, 1988. [9] H. R. Gall, G. Grover, R. Guerin, S. L Hantler, Z. Roa- berg, and M. 
Sidi. Buffer Size Requirements un-der Longest Queue First. In Performance Evaluation, Vo]. 18, No. 2, 
pp. 133-140, 1993. [10] A. G Greenberg and N. Madras. How Fair is Fair Queuing? In Journal of the Association 
Computing Machinery (JACM), Vol. 39, No. 3, pp. 568-598, 1992. [11] A.Kessekman, Z. Lotker, Y. Mansour, 
B. Patt-Shamir, B. Schieher, and M. Sviridenko. Competitive buffer overflow management in QoS switches. 
In Proceedings o] 33rd Annual Symposium on Theory o] Computing,  2001. [12] A. K. Parekh and R. G. 
GMlager. A Generalized Processor Sharing Approach to Flow Control in Inte- grated Services Networks: 
The Single-Node Case. In IEEE/A CM Transactions On Networking, Vol 1, No 3, pp. 344--357, 1993. [13] 
G. Sasaki; Input Buffer Requirements for Round Robin Polling Systems. In Proceedings of ~7th Annual Con- 
.ference on Communication, Control and Computing, pp. 397-4O6, 1989.   
			