
 IMPROVING AND STRENGTHENING INTER-INSTITUTIONAL PRESERVATION David Minor Katherine Skinner Tyler Walters 
UC San Diego Libraries and Educopia Institute Virginia Tech Supercomputer Center 1230 Peachtree St., 
Ste 1900 University Libraries La Jolla, CA 92093-5004 Atlanta, GA 30309 Blacksburg, VA 24062-9001 minor@sdsc.edu 
katherine@metaarchive.org tyler.walters@vt.edu ABSTRACT The focus of this paper is to examine the tools 
and methods used to automate the exchange of data, in particular large data collections, between the 
MetaArchive Cooperative,1 which uses LOCKSS, and the Chronopolis preservation system2, which uses The 
Storage Resource Broker (SRB, the precursor to iRODS). By creating such tools, we are assembling a highly 
robust, easy to use preservation system, which will allow digital objects to be shared among two of the 
most established preservation networks in the United States. In addition these tools will be usable by 
anyone seeking to exchange data between LOCKSS and iRODS. 1. INTRODUCTION Preservation Frameworks: From 
Silos to Interoperability Large-scale digital preservation is increasingly viewed as a core technology 
need in the scientific and academic communities. Indeed, the vast 1 http://metaarchive.org/ 2 http://chronopolis.sdsc.edu/ 
majority of the world s information is now produced as digital files, not print documents. If we do not 
take the time to preserve this information it will be lost, and along with it significant scientific 
and cultural resources will vanish. This is not an imaginary or theoretical threat: every day events 
occur which result in the loss of data collections. These events range from the smallest and most mundane 
to the catastrophic, and they cannot be totally prevented indeed they are in many ways inherent in any 
large technology enterprise. Our job is to protect important data in the face of these events, preserving 
it for future scientists, researchers, students, and society at large. Several projects and technologies 
have focused on this need in the last decade. Two of the most successful technologies are the Integrated 
Rule-Oriented Data System (iRODS)3 and the Lots Of Copies Keep Stuff Safe (LOCKSS)4 platform. These technologies 
are in use in many different environments. Another new suite of preservation and curation tools are being 
developed at the 3 http://www.sdsc.edu/srb/index.php/Main_Page 4 http://www.lockss.org/lockss/Home California 
Digital Library (CDL), under the rubric of curation micro-service technologies.5 While each of these 
technology sets is powerful, they currently share one liability: their isolation from each other. Bridging 
this gap would provide a more comprehensive suite of interoperable tools and would allow the preservation 
community to leverage the power of each system in a modular fashion. It would also enable practitioners 
using each system to take advantage of tools and services created for either LOCKSS or iRODS a win for 
the preservation community overall. This paper examines the tools and methods used to automate the exchange 
large data collections between the MetaArchive Cooperative s LOCKSS足based preservation network, and Chronopolis 
iRODS-based preservation system. By creating such tools, we are assembling a highly robust, easy to use 
preservation system, which will allow digital objects to be shared among two of the most established 
preservation networks in the United States. In addition these tools will be usable by anyone seeking 
to exchange data between LOCKSS and iRODS. 2. PRESERVATION SYSTEMS The MetaArchive Cooperative and the 
Chronopolis Digital Preservation Program are two of the preeminent digital preservation programs in the 
United States. At the highest level, both enterprises have the same goal: to preserve vital digital content 
for future use by a wide spectrum of people. Both enterprises are focused on keeping this content safe 
and preserved for decades, if not centuries. 5 http://www.cdlib.org/inside/diglib/ The need for such 
long-term preservation services is vital, and is becoming increasingly recognized as a key component 
to safeguarding future research and scholarly needs. A report issued 2002 by the NSF and the Library 
of Congress states: Solutions are urgently needed to prevent further loss of valuable digital information. 
These problems are urgent... action is needed now, not some time in the future... 6 Finding these solutions 
is at the philosophical core of both the MetaArchive and Chronopolis. As stated by the MetaArchive: Today, 
more than 93% of the world s information is produced as digital files, not print documents. How do we 
care for these new digital resources from government websites to corporate emails and from scanned images 
to born-digital recordings? As evidenced by such catastrophic events as blackouts, fires, and hurricanes, 
as well as basic hardware and software failures, we need to act now to begin providing long-term digital 
preservation services for our digital history or we risk losing them altogether. 7 The management teams 
of both enterprises believe that it is not enough to create preservation silos 6 Hedstrom, Margaret. 
It's about time: Research challenges in Digital Archiving and Long-term Preservation: Final Report. The 
National Science Foundation and The Library of Congress, August 2003. 7 http://metaarchive.org/ which 
are focused only on specific content, technologies or organizations. As the work of each group has matured 
and broadened, they have begun to create shared initiatives between their groups. Bridging these infrastructures 
serves a number of purposes, including allowing their user communities to benefit from the strengths 
of both technological frameworks rather than having to choose between them. It also would provide a ready 
exit strategy for either service if such a strategy became necessary in the future something that all 
responsible preservation services must consider as they plan for the sustainability of the resources 
they safeguard. Interoperability will serve as an added guarantee that our preservation efforts will 
be successful. It is a goal of a shared future that has led to this investigation regarding how to bring 
together two philosophically similar but technologically different projects. LOCKSS is a pull system 
that uses web足harvesting techniques to capture content and host it in a set of related servers that are 
spread over a wide geographical space. This approach enables content contributors to move their content 
directly from their own infrastructures and into the preservation repository using xml scripts (called 
plugins in LOCKSS terminology) rather than using additional hard storage media as an intermediary to 
do so. It also enables content ingested by the distributed network to be periodically revisited so that 
new versions of content may be captured and preserved alongside the initial version. The SRB/iRODS system 
is a push system that moves files from one storage medium to another through physical drives and without 
the use of the Internet. This approach enables the efficient exchange of data without reliance on bandwidth, 
which can be a limiting factor for large collections. It accomplishes this by requiring content contributors 
to transfer their data out of their existing systems prior to being stored in the data-grid-based preservation 
repository. This data may be replicated and stored in a distributed manner. Both of these preservation 
systems are strong and proven in their effectiveness; bridging the approaches would enable each framework 
to take advantage of the capabilities of the other when needed. 2.1. The MetaArchive Cooperative The 
MetaArchive Cooperative, formed in 2004, provides low-cost, high-impact preservation services to help 
ensure the long-term accessibility of the digital assets of universities and other research institutions. 
It is currently comprised of 48 institutions in four countries and two continents. The Cooperative is 
steadily growing in terms of both its membership and the amount of content that it preserves. Its network 
capacity is already nearing 300TB and it is slated to continue its growth at a rapid pace in the next 
three years. The MetaArchive Cooperative has built its trustworthy digital repository8 using the open 
source LOCKSS software to provide long-term care for digital materials. The Cooperative functions as 
a community-owned, community-led initiative. Its collaborative networks are comprised of libraries, archives, 
and other cultural memory organizations that seek to cooperatively preserve their digital materials, 
not by outsourcing to other organizations, but by 8 The MetaArchive Cooperative completed a self足audit 
in 2009 using the Trustworthy Repository Audit and Checklist and was found to be compliant in all 84 
categories. A checklist version of the TRAC audit is available at http://www.metaarchive.org/TRAC_2009, 
and the summary and full versions are available upon request. actively participating in the preservation 
of their own content. To preserve digital assets, the MetaArchive Cooperative uses a systemic, forward-looking 
technological approach called distributed digital preservation. The member institutions identify collections 
that they want to preserve. Using a technical framework that is based on the LOCKSS software, these collections 
are then ingested into a geographically distributed network where they are stored on secure file servers 
in multiple locations that are housed by the member institutions. These servers do not merely back up 
the materials, but rather provide a dynamic means of constantly monitoring content through the LOCKSS 
software足driven network which uses ongoing cryptographic SHA-1 hashes to compare the copies, determine 
if any have degraded in any way, and to provide repairs whenever necessary. Such redundancy and monitoring 
minimize the risk that information might be lost due to human error, technology failure, or natural disaster. 
The MetaArchive network uses subject- and genre足based archival designations to organize its content. 
New archives are created at member requests, and there is one generic archive that encompasses content 
that does not yet have a subject-or genre足based designation. The collections currently housed in the 
MetaArchive include: . The MetaArchive s Southern Digital Culture Archive, which was established in coordination 
with the Library of Congress s National Digital Information Infrastructure and Preservation Program in 
2004. In this network, institutions collaborate to preserve a wide range of digital content, including 
music, video, images, photographs, artwork, text documents, websites, e-journals, and other digital files 
related to the history and culture of the American South. . The Electronic Theses and Dissertations Archive, 
created through a partnership with the Networked Digital Library of Theses and Dissertations, which preserves 
the born足digital and digitized student output of academic institutions. . The Newspaper Archive, created 
through work funded in part by the National Endowment for the Humanities to study and document good practices 
for digitized and born-digital newspaper collections. . The Transatlantic Archive, which preserves an 
international collection on Transatlantic topics, including collections of maps, ship logs, manifests, 
images and other materials relating to slave trade voyages across the Atlantic Ocean.  2.2. Chronopolis 
Digital Preservation Network Chronopolis is a digital preservation data grid framework developed by the 
San Diego Supercomputer Center (SDSC) at UC San Diego, the UC San Diego Libraries (UCSDL), and their 
partners at the National Center for Atmospheric Research (NCAR) in Colorado and the University of Maryland's 
Institute for Advanced Computer Studies (UMIACS). A key goal of the Chronopolis framework is to provide 
cross-domain collection sharing for long足term preservation. Using existing high-speed educational and 
research networks and mass-scale storage infrastructure investments, the partnership is designed to leverage 
the data storage capabilities at SDSC, NCAR and UMIACS to provide a preservation data grid that emphasizes 
heterogeneous and highly redundant data storage systems. Specifically, the current partnership calls 
for each Chronopolis member to operate a grid node containing at least 50 TB of storage capacity for 
digital collections related to the Library of Congress' National Digital Information Infrastructure and 
Preservation Program (NDIIPP). For reference, just one terabyte of information would use up all the paper 
made from about 50,000 trees. The Chronopolis methodology employs a minimum of three geographically distributed 
copies of the data collections, while enabling curatorial audit reporting and access for preservation 
clients. The key underlying technology for managing data within Chronopolis is the Storage Resource Broker, 
a preservation middleware software package that allows for robust management of data. The partnership 
is also developing best practices for the worldwide preservation community for data packaging and transmission 
among heterogeneous digital archive systems. Chronopolis has concentrated on building a wide range of 
content that is not tied to a single community. Currently there are four significant collections housed 
in Chronopolis. Some significant examples include: . A complete copy of the data collection from The 
Inter-university Consortium for Political and Social Research (ICPSR), based at the University of Michigan. 
Established in 1962, ICPSR is the world's largest archive of digital social science data. . Data from 
The North Carolina Geospatial Data Archiving Project, a joint project of the North Carolina State University 
Libraries and the North Carolina Center for Geographic Information and Analysis. It is focused on collection 
and preservation of digital geospatial data resources from state and local government agencies in North 
Carolina. . Scripps Institution of Oceanography at UC San Diego (SIO) has one of the largest academic 
research fleets in the world, with four research vessels and the research platform FLIP. Since 1907, 
Scripps oceanographic vessels have played a critical role in the exploration of our planet, conducting 
important research in all the world's oceans. SIO is providing data from several decades of data from 
its cruises. . The California Digital Library (CDL) is providing content from its "Web-at-Risk" collections. 
Web-at-Risk is a multi-year effort led by CDL to develop tools that enable librarians and archivists 
to capture, curate, preserve, and provide access to web-based government and political information. The 
primary focus of the collection is state and local government information, but may include web documents 
from federal and international government as well as non-profit sources.  2.3 Technological underpinnings 
for digital preservation Staff from the MetaArchive and Chronopolis are investigating technologies that 
allow data exchange between LOCKSS and iRODS, based on real-world, practical implementations within MetaArchive, 
Chronopolis and CDL. Three methods of exchange are being developed and evaluated. The first method utilizes 
BagIt9 and related technologies to package and transfer large collections efficiently and reliably. This 
method requires the development of tools to automate the creation, transfer, and ingest of the BagIt 
data into 9 http://www.cdlib.org/inside/diglib/bagit/bagitspe c.html Chronopolis. BagIt is a simple 
packaging format that 2.4 Metadata Capture and Interoperability Framework incorporates a human-readable 
manifest file. This file lists the digital objects in the package as well as their checksums and serves 
as an authoritative inventory list. We are developing tools that automate the steps needed to create 
a BagIt-based data package at the data provider and ingest it into the joined MetaArchive/Chronopolis 
system. For example, we are creating a somewhat simple tool that when pointed at a directory or LOCKSS 
Archival Unit, will generate a BagIt package (a bag ) of the directory or unit. A second more sophisticated 
tool will allow the user to identify an existing BagIt bag, transfer its contents, ingest these objects 
into a storage zone and perform quality assurance testing for the whole process. For this work we are 
using strategies currently being developed at the California Digital Library in its micro-services framework. 
The CDL framework uses an emergent approach to preservation infrastructure by devolving function into 
a set of small, granular, independent, but interoperable services that can be flexibly deployed in strategic 
combinations to provide complex behaviors. The second proposed method for data exchange will utilize 
the iRODS technology. iRODS has a new rule-based framework and functionality that uses its own micro-services 
infrastructure. We will investigate creating appropriate micro-services, actions and rules to ingest 
and share LOCKSS-based content into an iRODS system. The third proposed method will utilize a LOCKSS 
plugin. LOCKSS has its own technical architecture that can be enhanced using custom-created, xml足based 
plugins, which allow for data to be manipulated according to defined rules. We will create plugins that 
will allow the LOCKSS system to interact with an iRODS system. Capturing and recording metadata upon 
ingest is essential to the long-term prospects for preserving digital content. Networked digital preservation 
systems such as iRODS and LOCKSS have standardized mechanisms for ingestion and replication of data files, 
but to date have not incorporated the many emerging tools for analyzing and validating technical metadata 
of files. The advent of the DROID software10 and the JHOVE software11 provide standardized tools for 
identification, validation, and characterization of file formats at the point of ingest. Similarly the 
creation this year of the Unified Digital Formats Registry12 offers the opportunity to record such metadata 
with authoritative reference to a standard registry of types. CDL is a partner in the NDIIPP-funded JHOVE2 
project to develop a next-generation format-aware characterization framework.13 JHOVE2 provides significant 
new features including support for arbitrarily-nested container formats and formats instantiated across 
multiple files, and rules足based assessment for determinations of acceptability on the basis of local 
policies in addition to validation conformity based on the normative requirements of format specifications. 
Both the MetaArchive Cooperative and the Chronopolis project have catalog databases as well as frameworks 
for automated processing of files 10 http://droid.sourceforge.net/wiki/index.php/Intro duction 11 http://hul.harvard.edu/jhove 
12 http://www.udfr.org 13 http://confluence.ucop.edu/display/JHOVE2Info/ Home upon ingest. What is lacking 
is a standardized interoperability framework for exchange of both data and metadata between LOCKSS and 
iRODS infrastructures. The availability of such a framework and a shared understanding of how to incorporate 
modular tools for format validation would enable a powerful synergy between these two broad solutions 
to digital preservation. We plan to develop such a framework and shared practice between our projects 
and document both for the benefit of other projects that may wish to jointly preserve data using LOCKSS 
and iRODS infrastructures. Outcomes of this development activity will include the following: 1) A well-defined 
XML-standardized representation of the common technical data that needs to be tracked to facilitate both 
exchange and preservation of data and metadata. This standard will minimally include format metadata 
(recorded using the emerging standards from the UDFR initiative), preservation metadata (using the PREMIS 
data dictionary), and relevant administrative metadata concerning replication decisions and technical 
information required for interoperable exchange of data files. 2) An ingestion reference model and framework 
that will enable the automated and interoperable capture of metadata from the files under preservation 
in both the MetaArchive and Chronopolis networks. This mechanism would automate the task of tracking 
files that are transferred between the two networks. The model and framework will also address the incorporation 
of modular format validation tools like JHOVE2. 3) Software development plans for improving data transfer 
methods between iRODS and LOCKSS, specifically based upon iRODS micro-service-based transfers, LOCKSS 
plugin-based transfers, and CDL micro足service-based transfers. 4) We will also seek to make the tools 
generic and re-usable for other preservation technologies, through documentation and open source licensing/release. 
As part of these efforts, we will research and document the current and emerging standards and tools 
that are available for the automated capture of metadata.  3. TECHNICAL PROCESSES In order to determine 
the most effective process for integrating the two systems, this project will investigate three different 
procedures: writing an iRODS micro-service, writing a LOCKSS plugin, and using BagIt as the underlying 
and unifying technology. During all three of these processes, the metadata necessary for linking the 
collections will also be a foremost concern. 3.1. Using an iRODS Micro-service One of the hallmarks of 
iRODS is its rich rule-based architecture. On top of an advanced preservation environment, this rule-based 
architecture allows iRODS administrators to create a customized environment that follows certain rules 
and uses certain triggers to designate actions that need to happen based on certain events. This rule-based 
process has three layers. In the most granular layer is a system of micro-services. In the iRODS context, 
micro-services are functions that have been written to accomplish a specific task. There is a large set 
of micro-services that ship with the default iRODS installation, but additional ones can be written by 
administrators of iRODS systems as needed in their particular environment.14 Micro-services can be chained 
together to form longer processes, called actions. 15 Actions are macro-level tasks. They typically call 
on multiple micro-services. Actions are called or started based on predefined rules. These rules are 
tasks that the iRODS system needs to perform when certain conditions arise. The iRODS system has a rule足engine 
built-in that interprets rules and calls the underlying actions (and hence the micro-services) when appropriate. 
An example of a rule might be: when a new file of type x is added to the system, rename it with a timestamp 
in its filename and copy it to another location. The rule in this case is calling two actions (the renaming 
process and the copying process). Each of these actions is constituted by multiple micro-services (which 
do the actual underlying work to make changes to the file and filesystem). We will first examine what 
rules would be necessary within an iRODS environment to share data with a LOCKSS environment. This will 
involve building and documenting a thorough understanding the differences in filesystems, file naming 
conventions, directory structures, and file movements within the systems. Each of these differences will 
likely impact what kinds of micro-services, actions, and rules are needed. We anticipate that there will 
be some default micro-services available that will be part of this process, but that there will also 
be significant custom work needed. In addition the project will 14 https://www.irods.org/index.php/Micro-Services 
15 https://www.irods.org/index.php/Actions need to keep track of which metadata is specific to each of 
the systems and which might need to be added or modified based on the iRODS actions. 3.2. Using a LOCKSS 
plugin The LOCKSS software effects its data transfers by harvesting data from web-accessible servers. 
It functions through a plugin developed to define the parameters of a collection (in effect, instructing 
the webcrawler as to what content is relevant to the crawl), and a manifest page that tells the plugin 
the starting location and provides a permissions statement for the capture of a collection. There are 
two categories of LOCKSS data transfers: a) collecting data for preservation; and b) accessing preserved 
content via a web proxy. A. Collecting data for preservation: LOCKSS collects content from target web 
sites using a web crawler similar to those used by search engines. It only collects data from web servers 
and is not set up to use ftp or to receive .tar or other archiving formats. LOCKSS preserves the directory 
structure of the content and uses a plugin module that tailors the process of collecting and preserving 
data from each target web site. LOCKSS gathers the web content by pulling the data into a designated 
set of LOCKSS servers. This differs significantly from the BagIt approach, which is a push model, in 
which data publishers ask a third-party to archive their packages. The data is not inventoried by LOCKSS 
before LOCKSS ingests it. It is instead inventoried at ingest and in an ongoing manner as the servers 
that contain the data are united through the LOCKSS software, and iteratively come together to poll (using 
SHA-1 checksums) and vote on the completeness and validity of the data they contain. LOCKSS requires 
the following to ingest content: The base URL of the web site where the content is located  A plugin 
with the rules for what content to ingest from the base URL  A LOCKSS harvesting permission statement 
(stored in the manifest page on the web server)  The LOCKSS plugin is a set of regular expressions 
or rules that include a pattern of directories or files found in the base URL. The rules or expressions 
may also exclude a pattern of directories or files. The plugin is turned into an XML-formatted file, 
which is then signed with a Key and turned into a JAR file. The JAR file is used by the LOCKSS software 
as each cache ingests the specified content. The following specifications can be made in the plugin: 
1. Plugin name / ID 2. Plugin Version 3. Start URL 4. Pause time between fetches 5. Content re-crawl 
interval 6. Crawl Window 7. Crawl Depth 8. Data ranges and/or volume numbers  B. Accessing preserved 
content via a web proxy: LOCKSS can act as a web proxy or web cache, providing browsers with access to 
the preserved content as appropriate. This function is handled at the cache level through the LOCKSS 
User Interface (UI), which authorized users may use to access the LOCKSS daemon. LOCKSS is open source 
software and is a pure JAVA application. We will investigate these two ways of transferring data using 
LOCKSS to determine which is the most appropriate for interactions with iRODS. We will also be tracking 
what types of metadata are created in the different scenarios and what needs to be used within an iRODS 
system. 3.3. Using CDL Curation Micro-service-based Data Transfer In the California Digital Library 
(CDL) context, curation micro-services are an evolving suite of granular, decentralized components providing 
highly available, comprehensive, and sustainable services for access to and use of authentic digital 
assets over time. Being small and self-contained, these services are easier to develop, maintain, and, 
when necessary, replace; they offer an unbundled alternative to all-in-one repositories that are expensive 
to support and modify. 16 One product of the CDL curation micro-service development that Chronopolis 
and MetaArchive have each worked with is BagIt. This experience forms the basis of the third technology 
option we are exploring currently. BagIt is a file packaging specification for the exchange of generalized 
digital content, based on a pre-determined hierarchy. The main unit of storage within BagIt is a bag. 
 The bag in this context has minimal descriptive information in it ( tags ) and an opaque content 16 
http://www.cdlib.org/inside/diglib/ payload of arbitrary size.17 The Library of Congress, which co-developed 
BagIt with CDL, has used it to transfer over 80TB of highly heterogeneous materials between differing 
storage systems. The BagIt specification was written to provide a simple, generic, easy to use method 
to accomplish this. BagIt is: A specification for the packaging of digital content for transfer. Content 
is packaged (the bag) along with a small amount of machine-readable text (the tag) to help automate the 
content's receipt, storage and retrieval. There is no software to install. A bag consists of a base directory 
containing the tag and a subdirectory that holds the content files. The tag is a simple text-file manifest, 
like a packing slip, that consists of two elements: 1. An inventory of the content files 2. A checksum 
for each file.18  To enable fast parallelizable network transfers, a large bag can be transferred with 
holes in it, that is, with files that are missing but that can be retrieved by URL. The transfer of a 
large holey 17 http://www.cdlib.org/inside/diglib/bagit/bagitspe c.html#anchor1 18 http://www.digitalpreservation.gov/partners/reso 
urces/tools/index.html#b bag can be greatly sped up by fetching the missing files with multiple parallel 
retrievals using ordinary HTTP-aware tools. BagIt enables organizations to send large amounts of information 
between their systems with minimal work and overhead to reformat them. This means that the transfer process 
gets out of the way as much as possible. We will be working with the CDL s more generalized micro-service-based 
replication and transfer services. This involves a new approach to sharing data that is based on their 
experience using the BagIt specification. This new methodology will allow for a transfer process that 
is not dependent on the specifics of divergent storage systems (which indeed may not be reconcilable). 
Using this technology will make the process more transparent and possibly useful to a larger number of 
digital preservation organizations.  4. BROADER IMPACT The work in this project will impact science 
and society in several ways. First, the technical advancements that will be made will make significant 
contributions to the preservation field: . Enhancing these two distributed digital preservation systems 
(LOCKSS and iRODS) with shared, open exchange mechanisms and incorporating format identification and 
metadata extraction tools, leverages technical developments in both systems communities and from other 
institutions across the world. A wide diversity of data and information management organizations and 
institutions will be able to improve their data access, preservation, and management strategies by combining 
these preservation system, data exchange, and format identification developments. . Scientists have 
stated that their advances are limited by the existing range of data formats, data management approaches, 
visualization tools, preservation strategies, and the like. This project will integrate two major digital 
data preservation platforms, which will improve multi-disciplinary and multi-institutional scientific 
exploration that is highly data-driven. An integrated LOCKSS/iRODS infrastructure will better support 
the growing diversity in formats, visualization, and analytical tools that empower researchers to more 
effectively utilize information and data. The end result is that significant improvements to education 
and research institutions will be made in their ability to share and preserve digital data between themselves 
and with researchers. . Ensuring sustained access to data and information for all research communities. 
The integrated LOCKSS/iRODS infrastructure will be an even more highly distributed preservation infrastructure 
than currently exists. The extensibility of both sets of technologies will be encouraged and innovations 
in research data and information management will be accelerated across many domains. . Enhances specific 
communities, such as those employing private LOCKSS networks (PLNs) like the MetaArchive, as well as 
the growing number of iRODS communities, by leveraging the organizational developments, sustainability 
plans, and best practices of each community. . The software tools developed by this project for data 
and metadata exchange will be made available as open source software for the digital data preservation 
community and other communities to use via sourceforge.net. Aside from these specific technical impacts, 
there will be important results based on the content within MetaArchive and Chronopolis being more broadly 
preserved and thus available for future use. Networks such as Chronopolis and the MetaArchive preserve 
data that represent research into the rich diversity of life and work in the United States and the Americas. 
 
			