
 A Functional Theory of Local Names Martin Odersky Universitat Karlsruhe 76128 Karlsruhe, Germany oderskyQira.uka. 
de Abstract the ~-calculus [9]. However, Milner relies on names and processes alone, and requires an 
implementation map­ping to recapture functional programming [8]. This im- Au is an extension of the A-calculus 
with a binding con­plementation is not fully abstract in that it invalidates struct for local names. 
The extension has properties observational equivalences that hold in a purely func­ analogous to classical 
A-calculus and preserves all ob­tional programming language. servational equivalences of A. It is useful 
as a basis for modeling wide-spectrum languages that build on a func-By contrast, this paper presents 
a syntactic theory for tional core. names that builds directly on (call-by-name) A-calculus. The basic 
idea is to generalize the notion of constant symbol already present in applied ~-calculus, by intro­ducing 
an abstraction vn.M that binds a name n. Con- Introduction stant symbols in classical applied ~-calculus 
then be­ come a special case of names that are not bound any-Recent years have given us a good deal 
of theoreti-where. The new calculus, Av, is pleasingly symmetric: cal research on the interaction of 
imperative program-Names can be bound just like placeholder identifiers in ming (exemplified by variable 
assignment) and function-~-abstractions, and both names and identifiers are sub­al programming (exemplified 
by higher order functions) ject to a-renaming. The difference between the two lies [3, 6, 18,20, 23]. 
The common method of all these works in the operations that can be applied to them. One can is to propose 
a ~-calculus extended with imperative fea-substitute a term for an identifier, and one can compare tures 
and to carry out an exploration of the operational two names for equality, but not vice versa. semantics 
of the new calculus. In a sense, names are the greatest common denomina-Based on our own experience in 
devising such an ex-tor of all programming languages that are not purely tended J-calculus [13], the 
present work singles out the functional. Hence, one expects a theory that combines name, whose only observational 
property is its identity, names with A-abstractions to help in understanding de­as an essential component 
of any such extension. We sign issues of wide-spectrum languages that build on a present a simple extension 
of the pure A-calculus with functional core. So far, the main results of this work names; we show by 
examples how much of the flavor are: of imperative programming is captured by this simple extension, 
and we prove compatibility of the extended @ Names can be added to the A calculus in a refer­calculus 
with the pure calculus in terms of both opera-entially transparent way. Full ~ remains a valid tional 
and denotational semantics. reduction rule. We are in good company; for instance Milner s Turing The 
resulting calculus, Av, is confluent and admits Award Lecture emphasizes naming as the key idea a standard 
evaluation function. The addition of names is fully compatible with * Most of this work was done while 
at Yale University. functional programming: Every observational Perrrission to copv without fee efl or 
part of this material is equivalence in A carries over to Av. This has im­ grented provided that the 
copies are not made or distributed for direct commercial advantege, the ACM copyright notice and the 
portant practical consequences. We are guaranteed title of the publication end its date eppear, and notice 
is given that every equational technique for verifying, trans­that copying is by permission of the AS60CifJtiOf? 
for Computing forming, or compiling functional programs is also Machinery. To copy otherwise, or to republish, 
requires e fee applicable to programs with local names. end/or epecific permission. POPL 94-1B4, Portiand 
Oregon, USA ~ 1994 ACM O-69791 -636-01 94/Wl ..$3.50 The extension property also applies to denotational 
semantics. There is a model of (simply typed) }V that is a conservative extension of the continuous function 
model of PCF. Related work. A theory with a scope close to Av has also been developed independently 
by Pitts and Stark [16]. The term languages of both theories are strikingly similar, but their operational 
semantics are quite differ­ent. The nu-calculus of Pitts and Stark is intended to model names as they 
arise in ML-style references, for instance. It is not intended to be a referentially trans­parent extension 
of a functional core (this is discussed further in Section 2). Recent work on monads [10, 21,22, 15, 
5] shares with JV the motivation to extend functional programming lan­guages to new application domains. 
Monads solve the problem of making sequencing explicit, which is needed if state is to be updated destructively. 
Jv solves the or­thogonal problem of expressing and encapsulating refer­ences. The two techniques complement 
each other well, as is shown in Example 3.2. Some of the more syntactic themes of this paper have also 
been addressed in the context of ~..r [13]. The present work extends the scope of [13] with an inves­tigation 
of models for ~v. It also achieves considerable simplifications by isolating the treatment of names from 
all other issues of imperative programming. This sep­aration of concerns helped simplify the (rather 
hard) proofs on the observational equivalence theories of the imperative language. For this reason, we 
have based an extended version of the &#38;aT-report on Av [12]. The rest of this paper is organized 
as follows. Sec­tion 2 describes term syntax and reduction rules of b. Section 3 presents two applications 
of local names, a type reconstruction algorithm and an implementation of state. Section 4 shows properties 
of Av, in particular its confluence and its standard evaluation order. Sec­tion 5 discusses the observational 
equivalence theory of Av and shows that it is a conservative extension of the corresponding theory of 
}. Section 6 gives a denotation­al semantics for ~v. Section 7 concludes. 2 The AV Calculus Terms. The 
term-forming productions of Av are giv­en in Figure 1. The three productions on the first line are those 
of classical, pure A-calculus. The three pro­ductions on the next line are particular to Av. Besides 
Abound identifiers there is a new, countably infinite al­phabet of names. Names fall into two classes, 
global and local. A global name n is an atomic constant. We assume that there are two such constants 
denoting the Boolean values true and ~cdse. A local name n is a name that is bound in a name abstraction 
vnv.M. In contrast to the case of A-bound identifiers, nothing is ev­er substituted for a name. Rather, 
names can be tested for equality, as in nl == n2. Both constants and local names can be operands of (==). 
We study here an applied variant of b. Accordingly, we have on the last line productions for pairs (Ml, 
M2) and applied primitive operators p M. Primitive operators are always unary, but operators of greater 
arity can be simulated by currying. We assume that at least the following operators are defined: pair? 
(Ml, Mz) = true pair? -= false name? n = true name ? . = false fSt (Ml, M2) = MI snd (Ml, M2) = M2 Notational 
conventions. We use J3V(M) and FV(M) to denote the bound and free identifiers in a term M, respectively. 
Analogously, BIV(lkf) and FIV(iV) denote bound and free local names in a term M. A term is closed if 
FV(M) = FN(M) = 0. Closed terms are also called programs. Note that programs do not contain free local 
names n , but they may contain constants. We use M s N for syntactic equality of terms (modulo a-renaming) 
and reserve M = N for convertibility. If R is a notion of reduction, we use ~ to express that M reduces 
in one R reduction step to N, and M ~ N to express that M reduces in zero or more R-steps to N. We also 
use M ~ N to express that M reduces to N by contracting redex A in M. The syntactic category of values 
V comprises constants, names, pairs, and A abstractions. An obse? vable value (or answev) A is an element 
of some nonempty subset of the alphabet of constants. v ::= n I (M1, Mz) I kc.M Ac Answevs ~ Namesc 
A context C[ ] is a term with a single hole [ ] in it. C [M] denotes the term that results from replacing 
the hole in (7[] with M. Following Barendregt [1], we take terms that differ only in the representatives 
of bound identifiers and names to Idents h-bound identifiers x E n E n= e nv 6 P= M e M ::= I I @ 6 eq 
Z-q VP Vn  Names = Namesc U Names names Names constants Names v-bound local names Primops primitive 
operators Au terms z I~x.M IMl Mz nlvn.MIMl==M, (MI, M,) I pM Figure 1: Syntax of Av (Xr.M) N + [N/z] 
M pv + 6(p,v) n==n -+ true n==m. -+ false (n # m) vn. Az. M 4 Ax.vn.M vn. (M1, M2) --+ (vn.Ml, vn.M2) 
vn.m -+m (n # m) Figure 2: Reduction rules for Jv be equal. That is, all terms we write are representa-ues 
V to terms. 6 can be arbitrary, as long as its result tives of equivalence classes of a-convertible terms. 
To does not depend on the body of a an argument func­avoid name capture problems in substitutions we 
re-tion, or the value of a local argument name. That is, strict ourselves to representatives in which 
bound and we postulate that for every primitive operator p there free identifiers are always distinct, 
and we employ the exist closed terms N: (c e Namesc ). N;, N: and N~,, same conventions for names. such 
that for all values V for which 6(p, V) is defined: Reduction Rules. Figure 2 gives the reduction rules 
of Av. They define a reduction relation between terms in INP if V is a local name the usual way: we take 
(--t) to be the smallest relation 6(p,v)= N; if V is a A-abstractionA on Av x Av that contains the rules 
in Figure 2 and that, N~,,, Ml Mz if V E (Ml, M2) for any context C, is closed under the implication 
Note that all primitive operators are strict, since 6 re- M-+ N ~ C[M] -+ C[N]. quires its arguments 
to be values, Rule ~ is the usual reduction rule of pure A-calculus. The remaining rules of Figure 2 
are particular to Av. Rule 6 expresses rewriting of applied primitive opera-Rule eq defines (==) to be 
syntactic identity. Rule VA tors. To abstract from particular primitive operators says that v-and A-prefixes 
commute. Rule VP says that and their rewrite rules, we only require the existence of v-prefixes distribute 
through pairs. Finally, rule Pm says a partial function 6 from primitive operators p and val-that a v-prefixes 
is absorbed by any name that differs 50 from the name bound in the prefix. Taken together, these rules 
have the effect of pushing names into a term, thus exposing the term s outer structure and allowing it 
to interact with its environment. An important consequence of these rules is that the term vn. n cannot 
be reduced further, but is not a value ei­ther, and hence cannot be decomposed or compared. In other 
words, the identity of a name is known only within its (dynamic) scope. This does not restrict expressive­ness 
since it is always possible to extend the scope of a variable by passing the rest of the computation 
as a continuation (see the examples in the next section). An Alternative. Instead of pushing v-prefixes 
into a term, one might also consider to pull them out of a function application. I.e. rather than with 
the v rules of Figure 2 one might want to work with the rules VL (zm.M1) M2 + zm. (M1 M2) ~R Ml (zm.M2) 
-+ zm. (M1 M2). These rules can be regarded as an axiomatization of gensym in Scheme. They closely correspond 
to the op­erational semantics of the nu-calculus [16]. Rule VL is q-equivalent to rule VA. But adding 
rule v~ to the A calculus breaks the Church-Rosser property. For instance, (XZ.(Z, z)) (vn.n) reduces 
(with @ to (vn.n, vn.n) but also reduces (with v~ and then P) to vn. (n, n), and the two reducts do not 
reduce by ~vL VR to a common term. Hence, ~ needs to be abandoned if we want to have a confluent calculus 
with VR. The difference between the the nu-calculus and Av can also be illustrated by looking at their 
reductions on the term (~z.z == z) (vn.n). With va and a suitably restricted /3-rule this reduces to 
true, while in Av this reduces to vn.n== vn.n, a term in normal form that is not a value (such terms 
are often called stuck ). Intuitively, reduction gets stuck since the value of a symbol is undefined 
outside its scope. This restriction is required to ensure that all equalities of the underlying A-calculus 
are preserved. Indeed, the preservation law even extends to all observational equiv­alences (Theorem 
5.9). A Note on Church-Encoding Pairs. We have cho­sen to make the pairing function (., .) a primitive 
term constructor with associated primitive projections fst and snd. What would have happened if we had 
en­coded pairs as functions instead? The Church-encoding of pairs defines a pairing function P = Ax. 
Ay.Af.j x y and associated projections 7rl = +2.p (k. Ay.z) T2 = Ap.p (Ady.y). The crucial question 
is what happens to VP, or, rather its Church-encoded form zm.P M N = P (m.M) (zm.iV). (1) It is easily 
verified that this not an equality derivable from the other reductions. On the other hand, if we apply 
a projection ~i to each side of (1) then we do get an equality that is derivable from /3 and VJ. This 
is shown by some straightforward computation: ml (zm.P M N) = (by definition of ~1, P) (Ap.p (Atz.Ay.z)) 
(wz.Af.f M N) = (by /f?) (vn.~~.~ M N) (Az.Ay.z) = (by v,) (~~.vn.~ M N) (Az.Ay.x) = (by /?) zm. M = 
(by definition of rl, P and /3) ml (P (vn.M) (zm.N)) The case where the projection is Tz is completely 
analo­gous. In summary, the VP rule for Church-encoded pairs is subsumed by VA and ~, as long as pairs 
are used as intended (i.e. only projections are applied to them). 3 Applications To demonstrate how 
the Av-extensions can be used in a functional programming language, we study two exam­ple applications: 
a type reconstruction algorithm and an implementation of state transformers. We use a pro­gramming notation 
that extends Haskell with a new construct new n -> M, the ASCII form of zm. M. A name has type Name a, 
for some type a, The typing rule rule for new is: ll.n:Namer k M:r l?tnewn->M:T data Id = String unify 
:: Type -> Type -> SubstTran a data Term . ID Id I AP Term Term I LAM Id Term unify tl t2 k s = case 
mgu (s tl) (s t2) of data TID . Name () Suc s > k (S . S ) data Type . TV TID I Type :-> Type Err -> 
Err dataE a . Suc a I Err tp :: TypeEnv -> Term -> Type type TypeEnv = Id -> Type -> SubstTran a type 
Subst . Type -> Type type SubstTran a = (Subst -> E a) -> Subst -> E a tp e (ID n) t = unify (e n) t 
tpe(APab)t =newn-> upd :: (a-> b) ->a->b->(a->b) tpea(TVn:-> t). upd f x a y = if y == x then a else 
f y tp e b (TV n) tpe(LAMxa)t= newn->newm-> mgu :: Type -> Type -> E Subst unify (TV n :-> TV IU) t . 
-­ most general unifier; definition 1s left out tp (upd e x (TV n)) a (TV m) Figure 3: Type reconstruction 
algorithm for the simply typed ~-calculus. Example 3.1 (Type Reconstruction) Type recon­struction algorithms 
for polymorphically typed lan­guages need to define fresh identifiers for type vari­ables on the fly 
. To this purpose, a name supply is usually passed along as an additional argument to the type reconstruction 
function. As an alternative, we present here a type reconstruction algorithm for the sim­ply typed ~-calculus 
that replaces the name supply by bound Av names. The code for the type checkeris given in Figure3. Types 
are either variables fV n or function types t I : > t2. The identifying part n of a type variable TV 
n is a name (of type TID, which is a synonym for Name ()). The main function tp constructs aprooffor 
agoale 1-a:t, where e is a typing environment, a is a term, andt is a type. e, a and t are the first 
three arguments of tp. Fresh names are created in the clauses of tp that have to do with function abstraction 
and application. tp is written in continuation passing style in order to extend the scope of names as 
far as needed. Its result is a substitution transformer (of type SubstTran), which is a mapping that 
takes a continuation and a substitution and yields either failure or succeeds with some result type that 
is determined by the continuation. Example 3.2 (St ate Transformers) Using state-transformers, one can 
write imperative pro­grams in a functional programming language, by treat­ing an imperative statement 
as a function from states to states (and, possibly, intermediate results). State trans­formers can be 
classified according to whether they are global or local, and according to whether state is fixed or 
dynamic. [21] and [22] describe local state-transformers that can be embedded in other terms and that 
operate on a ,fized state data structure. By contrast, [15] describes global state-transformers that 
act as the main program and thus cannot be embedded in another term. State in [15] is dynamic, i.e. it 
consists of a heap with dynamically created references. Figure 4 shows an implementation of local state­ 
transformers with dynamic state. This is to my knowl­edge the first fully formal treatment of this class 
of state­transformers, even if [4] and [5] contain similar informal proposals. State is represented as 
a polymorphic function from names of type Name a to terms of type a. Its type is: all a.Neme a > a A 
state-transformer of type ST a is a function that takes a continuation and a state as arguments, and 
returns the result of the continuation. Its type is: all b. (a -> State -> b) -> State -> b Note that 
the polymorphic types of state and state transformers exceed the capabilities of first-order type syst 
ems such as Haskell s or ML s. However, an efficient implementation of state transformers would treat 
type type type State ST a = = all all a. b. Name a -> a (a -> State -> b) -> State -> b -- Monadic Operators: 
-- State-Based Operators: return (>>=) pure ::a :: :: -> ST a STa->(a->STb)->ST STa->a b newref (:=) 
deref :: ,,. . :: ST (Name a) Name a -> a -> Name a -> ST a ST () return (p>>=q) pure p bot a k s ks 
=kas = p(\x->qxk)s = p (\X > = bot \S > X) bot neuref (n:=a) deref upd s n n x ks= ks= ks= n = new n 
-> k n s k () (upd s n a) k(sn)s if n == a then x else s 10 Figure4: State Transformers ST aasanabstract 
datatype andwould hide type state altogether in order to guarantee that state is single­ threaded. Such 
an implementation could do with just ML-style let-polymorphism. State transformers form a Kleisli monad, 
with return as the monad unit, and with infix (>>=) as the bind op­erator. If we leave out the redundant 
state parameter s this is just the standard continuation monad. The result type of a continuation is 
an observer of type State -> a (as in [20]). Function pure, of type ST a -> a, allows one to get out 
of the ST monad. pure runs its state transformer argu­ment in an empty initial state with a continuation 
that yields its first argument as answer. The remaining operations access state. newref returns a freshly 
allocated reference as result. Its implementa­tion is based on u-abstraction. (n : = a) updates the state, 
returning the unit value as result, while deref n returns the current value of the state at reference 
n. This concludes our first implementation of state in Av. It is perhaps surprising how simple such an 
implementa­tion can be, once the problem of expressing local names is taken care of. However, one could 
argue that we have oversimplified, in that the implementation of Figure 4 does not really describe state! 
Indeed, there are two trouble-spots. The first problem is caused by the fact that the state ar­gument 
s is not linear in the definition of deref. There­fore, access to state is only single-threaded if the 
appli­cation s n in the body of deref gets resolved before control is passed to the continuation. But 
nothing in the implementation forces this evaluation order! One could solve the problem by making continuations 
strict in their first argument. However, this forces s n to be reduced to a value, which is needlessly 
drastic. To en­sure single-threadedness, it is enough to just perform the function application without 
further evaluation. Another problem concerns the meaning of readers and assignments that involve names 
from some outer block. In the implementation of Figure 4, such accesses are not errors. Instead, the 
read or write is performed on a lo­cally allocated cell that is named by the non-local name. Therefore, 
the same name might identify several loca­tions in different states. This approach, which is similar 
to the semantics of state in [19], is perfectly acceptable from a theoretical standpoint. But it raises 
some imple­mentation problems, since it prevents the identification of names with machine addresses. 
Both problems are solved by a slightly more refined im­plementation that marks stored terms with a data 
con­structor. We modify the type of state as follows: type State =alla, Nsmea->Da data Da =Da The implementation 
of the state-based operators then becomes: nmiref Ks = newn > k n (upd s n (D bottom)) (n := a)ks= case 
s n of Confluence Db->ko(updsn (Da)) deref n k s = case s n of We show in this section analogues for 
Au of the Finite Da->kas Developments and Church-Rosser theorems for the J­ calculus. In the new implementation, 
body of deref forces s n to is passed to the case-branch. the case construct be evaluated before This 
takes care of in the control the first Definition labeled reduction 4.1 redexes rules Let AOV (Aoz.M) 
be the N and extension p. V and of with Av with labeled problem. Moreover, both readers and that an entry 
for the accessed reference local state, and newref allocates such writers require exists in the an entry 
for a Po : &#38; : ( A@.A q Po v N + -+ [N/2J] M 6(p, v). freshly created reference. This takes care 
of the second problem. The contribution of ~v to this implementation is rather subtle. It consists of 
the v-abstraction in the code of newref and the equality test in function upd. Never­theless, the presence 
of local names is important for modeling dynamic local state in a simple way. To see this, let s try 
to model local state without local names, by representing heaps as arrays with references as in­dices, 
say. Now, any implementation of local state has to distinguish between variables that are defined in 
dif­ferent pure-blocks. This is necessary to guard against access to non-local variables and against 
export of lo­cal variables out of their block, both referentially opaque operations. A straightforward 
scheme to distinguish be­tween variables defined in different blocks would pass a name supply to each 
block, such that the block, and all the variables defined in it, can be tagged with a unique identifier. 
The problem with this scheme is that it has a poisoning effect on the environment that surrounds a block. 
Each function now has to pass along name­supply arguments even if the function itself does not contain 
pure-blocks as subterms. It is not clear what is gained by this method over a program that contains a 
single, global state, and hence is imperative all the way to the top.  Reduction This section details 
the fundamental laws of Av­reduction: reduction is confluent and there is a standard evaluation order. 
The treatment largely follows [1], and we assume that the reader is familiar with some of the more fundamental 
definitions and theorems given there. Most of the proofs in this and the following chapters are sketched 
or left out; for a more detailed treatment, see [11]. Let ~ be the reduction relation generated by PO, 
60, eq, VA, VP) Vn. Theorem 4.2 (Finite Developments) ~ is strongly normalizing. Proof: The proof is 
similar to the proof of finite de­velopments in the pure ~ calculus ([l], CH.ll, \2). We construct a 
family of non-negative decreasing weighi­ngs and show that each reduction step maps a term with a decreasing 
weighting to a term with a smaller decreasing weighting. Theorem 4.3 The notion of reduction in ~v is 
Church- Rosser: if M -+ Ml and M + M2 then there is a term M3 s.t. Ml -+ M3 and M2 -+ M3. Proof: Using 
a case analysis on reduction rules, cou­pled with a case analysis on the relative position of redexes, 
one shows that the notion of reduction 6V is weakly Church-Rosser and commutes with ~. Then by Theorem 
4.2 and Newman s lemma ([l], CH.3,jl) 6V is Church-Rosser, and together with the lemma of Hind­ley/Rosen 
([1] ,CH.3, 33) this implies the proposition. Evaluation As programmers, we are interested not only in 
proving equality of terms, but also in evaluating them, i.e. re­ducing them to an answer. We now define 
a computable evaluation function that maps a term to an answer A iff AU 1-M = A. Following Felleisen 
[2], the evalua­tion function is defined by means of a context machine. At every step, the machine separates 
its argument term deterministically into an evaluation context and a redex and then performs a reduction 
on the redex. Evaluation stops once the argument is an answer. Evaluation con­texts for Av are defined 
as follows: E ::= []1 EM IPE/vn.E (2) The first three clauses generate evaluation contexts for the applied 
call-by-name A-calculus, whereas the last clause is particular to Av. Definition. Thedeterministic reduction 
relation~on terms in Avis the smallest relation that satisfies M-%N * E[M]~E[N]. A simple inspection 
of the productions for E establishes that ~ is indeed deterministic: Proposition 4.4 For any redexes 
Al, A2 and evalua­tion contexts El, E2, El[Al] a E2[A2] + El a E2 AAl s A2. A redex A is a head redez 
of a term M if M E E[A], for some evaluation context E, A redex that is not head redex is called an internal 
rede~. Reduction of internal redexes keeps head and internal redexes separate, in the sense of Lemma 
4.5 Let M be a program s.t. M ~ N where A is an internal redex of M. Then, (i) If N has a head redex 
then so has M, (ii) the residual of M s head redex is head redex in N, (iii) the residuals of every internal 
redex in M are in­ ternal redexes in N. Theorem 4.6 (Correspondence) For every program M c AU and every 
answer A, M+ AwM--j+A. Proof: Direction + follows immediately. To prove + , assume that M ~ A. One shows 
first as an inter­mediate result that, whenever M + A, there is a term N s.t. M ~ N ~ A, where the reduction 
sequence N ~ A from N to A consists of only internal reduc­tions. This result corresponds to the main 
lemma for the Curry /Feys standardization theorem ([l], CH.11,$4) and has exactly the same proof. That 
proof uses only the theorem of finite developments (Theorem 4.2 for b) and a lemma equivalent to Lemma 
4.5. The proposition then follows from the observation that no internal Jv re­duction ends in an answer, 
hence we must have N z A.  5 Observational Equivalence Observational equivalence is the most comprehensive 
notion of equivalence between program fragments. Intu­itively, two terms are observationally equivalent 
if they cannot be distinguished by some experiment. Experi­ments wrap a term in some arbitrary context 
that binds all free identifiers and local names in a term. The only observation allowed in an experiment 
is whether the resulting program reduces to an answer, and, if so, to which one. We define observational 
equiva­lence for arbitrary extensions of applied J calculus. In the following, let T be an equational 
theory that ex­tends ~ and has term language Terms(T) and a set of answers Ans(7) C Namesc (7). We assume 
that Namesc (7)\ Ans(T) is infinite. Definition 5.1 Two terms M, N ~ Terms(T) are ob­servationally equivalent 
in T, written T + M E N, iff for all contexts C in T erms(T) such that C[M] and C [N] are closed, and 
for all answers A c Ans(T), 7 b C[M] = A~T1-C[N]=A. Proposition 5.2 The following are observational equivalences 
in Av: vn.vm.M Z um.vn. M (n # m) vn. M %M (n~FN(M)) Definition 5.3 T is an observational extension of 
To if Terms(T) ~ Z erms(To) and, for all M ~ Terms(To), 70~MSN+T~MSN. The extension is conservative if 
the implication can be strengthened to an equivalence. The main result of this section states that h 
is an ob­servational extension of A. The proof relies on the con­struction of a syntactic embedding from 
Av to A. Syn­tactic embedding were first defined in [13]; we use here the following, simplified definitions. 
Definition 5.4 Given an inductively defined term lan­guage Terms, an extended term is formed from the 
in­ductive definitions of Terms and []. (Hence, both terms and contexts are extended terms). Definition 
5.5 A term M is J-closed iff FV(M) = 0. M may contain free occurrences of local names. Definition 5.6 
(Syntactic Embedding) Let 7 and 70 be extensions of J such that Terms(T) ~ Terms(To) and Ans(T) = Ans(To). 
Let &#38; be a syntactic mapping from extended T-terms to extended To-terms. Then &#38; is a syntactic 
embedding of T in To if it satisfies the following two requirements. 1. ~ preserves Xclosed To-subterms. 
For all T­contexts C, ~-closed To-terms M, 70 E &#38;[c[M]]=&#38;[c][ikt]. 2. 8 preserves semantics. 
For all closed T-terms M, answers A, 7t-M=A+70t-&#38;[M]=A. Theorem 5.7 Let T and To be extensions of 
A such that Z emns( T) ~ Tem-ns(To) and Ans(T) = Ans(70). If there is a syntactic embedding of T in TO 
then T is an observational extension of To. The next lemma was shown in [11]. Lemma 5.8 There exists 
a syntactic embedding of Av in A. Together with Theorem 5.7, this implies: Theorem 5.9 b is a conservative 
observational exten­ sion of A. Proof: By Lemma 5.8, $ is a syntactic embedding of Av in A. By Theorem 
5.7 this implies that Av is an observational extension of A. That the extension is conservative follows 
directly from the observation that Av-convertibility is a conservative extension of A convertibility. 
 6 Denotational Semantics We develop a denotational semantics for a typed version of Jv that results 
from adding v-abstractions to PCF terms. The semantics is an extension of the continuous function model 
for PCF [17]. In that sense, it follows the spirit of previous sections, where Jv was studied as an extension 
of ~-calculus, rather than as a theory of its own. We use a possible worlds semantics [14], where a world 
is characterized by a finite set of names. Intuitively, these are the names available for program evaluation. 
As a new twist, the meaning of the term vn.M in a world W is the intersection of the meaning of M in 
all possible worlds that extend W with a new suitable location. A location is suitable if it does not 
clash with locations used in other parts of the program. Instead of trying to trace these locations explicitly, 
we simply choose the best) co-finite set L of possible candidate locations inthe information ordering. 
I.e. It is a consequence of Theorem 6.6 that the least upper bound always exists. The meaning of all 
other con­structs is the same as in PCF. Example 6.1 The meaning of vn.n is bottom: [won] P = u~.@..f..(me)e) 
(16L z =L This corresponds to the term vn.n being stuck in the reduction semantics. It reflects on the 
fact that the identity of a name is known only within its scope. Example 6.2 The meaning of vn.vm.n == 
m is false. Indeed, [zm.vrn.n == m] p = (_JK nk.KUL nz.L~=z COf~~(Name). If K, k, and where K and L range 
over p L are chosen, then nle~ k = 1 is either 1 (if k e L) or false (if k + L). Hence, for any given 
K and k, the value of l_jLEPcOtl.(~a~ej (ll.L k = 1 is false. But this implies [vn. vm.n == m] p = false. 
 In the rest of this section, we make these notions precise. In particular, we need to give a semantic 
characteriza­tion of the functions that belong to a world W infor­mally, these are the functions that 
access only locations in W. We also have deal with the fact that the lub of a chain of functions that 
access strictly increasing sets of locations accesses an infinite number of locations, and hence is not 
a member of any world. As a consequence, our domains form a locally complete partial order (icpo) [7] 
rather than a cpo. We base our discussion on a typed version of Av, given by the typing rules in Figure 
5. We also assume the usual constants and operations of PCF, without listing their typing rules explicitly. 
Definition 6.1 Let Name be a countably infinite set of names, and let m, n e Name. The ezclu.mge Xm,n 
is the unique logical relation such that for names z, y, zX~,~Y u m==z Ay=n V m,=y Az=nv m#z=y #n, for 
elements of other ground types, x Xm,n y e X=y, and such that 1 Xm,n l-. (ID) (NAME) 17, n: Name 1-n 
: Name (ABS) (NU) I , n: Name 1­ M:r I 1-vn.M:r PI- M:u-+T I FN:u 17t M: Name I FN: Name (APPL) (EQ) 
rt-MN:~ 17t M== N: Bool Figure 5: Typing Rules for Av (NAME) [1 , n: Name D n :Name] p = pn (NU) [r 
D vn.M : 7-] p = UL6pc0f*m(Na7ne)nt,~ [r, n:Name D M: T] p[n H 1] (EQ) [1 PM== N: Bool]p = [1 DM:Name]p= 
[r PN:Name]p Figure 6: Semantic Function ~.] Exchanges have the property that they are closed under intersections 
and unions: Lemma 6.2 (i) If, for all i ~ 1, AZ X~,n B,, then A; X~,n  n (w ieI i&#38;I (ii) If {AZ 
I i c 1} and {B, I i e 1} are directed sets and for all i c I, Ai X~,n B,, then iel id Definition 6.3 
The smooth set of a value z e D, smooth(z) = {m : Name 13L ~ pcO~in(Name). Vn cL. zXm,n z}. The support 
of z is the complement of its smooth set, support(z) = Name \ smooth(z). Informally, suppmt(z) is z if 
z is a name, and is the set of names accessed by x if x is a function. A character­ization of suport 
and smooth that is easier to use in proofs is given by: Lemma 6.4 m c smooth(z) * Vn ~ smooth(z). z Xm,n 
z. This equivalence cannot be used to define smooth, how­ever, since its right hand side is not monotonic 
in smooth(z). Example 6.3 The support of the name n is {n). The support of the function f ~t Az. x == 
m is {m]. This can be derived as follows: Let n be any name differ­ent from m. Then m Xm,. n. But ~m 
# ~n, which proves 7( f Xm,n f ) and hence shows that m is not in smooth(f). On the other hand, let k, 
1 be ar­bitrary names different from m. It is easy to check that ~ Xk,l ~. Hence, by Lemma 6.4, smooth(~) 
~ Name\{ m}. In summary, smooth(f) = Name\{ m}, and hence support(f) = {m}. Definition 6.5 For type r 
and finite name set W, the domains [~] ~ and [T] are defined as follows: [Name]w = VVl. For all other 
ground types o, [o] ~ is the usual in­ terpretation of o in PCF. [(J -+ T]w = {f : [0] A [T] j Suppo? 
t(f) g w}, 7 Conclusions where D ~ E denotes the locally continuous func­tions from D to E. We have studied 
reduction semantics, observational equivalence theory and denotational semantics of }v, [~1 = a theory 
for functions that create local names. Each of Uw,pqvame)udw these three equational theories for ~v 
is a conservative The interpretation of Av terms is defined in Figure 6. extension of the corresponding 
standard theory for A Let 17 be a set of type hypotheses and let W be a finite (respectively PCF). Avis 
in that sense fully compatible set of names. A (l_ , W)-environment is a function p with functional programming. 
There is also good evi­on identifiers and names that maps each identifier z ~ dence that it is a useful 
foundation for modelling many dom(l?) to a value in [I (z)], and that maps each name constructs that 
so far were outside the domain of func­n c dom(I ) to a unique name in W. The semantic tional programming. 
For instance, Example 3.2 shows function [o] takes as arguments a type judgement r D how imperative programming 
with mutable local vari- M : ~ and a (17, W)-environment p. It yields a value in ables can be expressed 
in Av. It would be interesting to [T]~. see other applications of the calculus, such as in logic or concurrent 
programming. Theorem 6.6 For all valid type judgments 17 1-M : ~, finite name sets W and (I , W)-environments 
p, Acknowledgements This work was supported in part by grant NOO014-91-J-4043 from DARPA. I thank [r 
FM: T]pe[T]w. Vincent Dornic, Paul Hudak and Dan Rabin for their comments on earlier versions of the 
paper. Dan Rabin Proof: A standard induction on type derivations. The in particular helped to improve 
its presentation consid­following lemma is needed for the abstraction case. erably. John Launchbury, 
Jayadev Misra, David Turner and Phil Wadler also commented on this work in helpful discussions. Lemma 
6.7 Let m,n e Name. Let I t-M :~ be a valid type judgement. Let p, p be (I , W) environments such that, 
for all z e dom(I ), p z X~,~ p z. Then References <RefA>[rD&#38;f:T]pXm,. [rb&#38;.f:~]p . [1] H. P. Barendregt. 
The Lambda Catculus: its Syntax Theorem 6.8 [.] defines a computationally adequate and Semantics, volume 
103 of Studies in Logic and the model of W. Fozmdations of Mathematics. North-Holland, Amster­dam, revised 
edition, 1984. PToof: One verifies easily that all reductions in ~v are [2] E. Crank and M. Felleisen. 
Parameter-passing and the equalities in the model. To show adequacy, we adapt lambda-calculus. In Proc. 
18th A C34 Symposium on Plotkin s adequacy proof for PCF [17]. Say M is com- Principles of Programming 
Languages, Orlando, Flori­ putable if one of conditions (l)-(4) holds. da, pages 233-244, January 1991. 
M+A. (1) M is closed of ground type, and [M]= [A] implies [3] M. Felleisen and R. Hleb. The revised report 
on the (2) M is closed, of type u + ~, and M N is computable syntactic theories of sequential control 
and state. The­ for all closed, computable terms N of type a. oretical Computer Science, 103:235 271, 
1992. (3) z : ~ is free in M, and [N/z]M is computable for all closed, computable terms N of type T. 
[4] P. Hudak and D. Rabin. Mutable abstract datatypes (4) n.: Name is free in AK, and vn.M is computable, 
-or how to have your state and munge it too. Re- Using structural induction on M, one shows that every 
search Report YALEU/DCS/RR-914, Yale University, term in Av is computable, which implies the proposition. 
Department of Computer Science, July 1992. [5] J. Launchbury. Lazy imperative programming. In The model 
seems to be rather close to the observational SIPL 93 ACM SIGPLAN Workshop on State in Pro­equivalence 
theory of Av, even if the question whether it is fully abstract is still open. For instance, adaptations 
gramming Languages, Copenhagen, Denmark, pages of the equivalences of [7] to the simpler setting of Av 
46-56, June 1993. Yale University Research Report can all be validated. YALEU/DCS/RR-968. [6] I. Mason 
and C. Talcott. Axiomatizing operational equivalence in the presence of side effects. In IEEE Symposium 
on Logic in Computer Science, pages 284­303, Asilomar} California, June 1989. [7] A. R. Meyer and K. 
Sieber. Towards fully abstract se­mantics for local variables: Preliminary y report. In Proc. 15th A 
Cikl Symposium on Principles of Programming Languages, pages 191-203. ACM, ACM Press, January 1988. [8] 
R. Mdner. Functions as processes. Rapport de Recherche 1154, INRIA Sophia-Antipolis, February 1990. [9] 
R. Mdner. Elements of interaction. Communications of the A CM, 36(1):78 89, January 1993. Turing Award 
lecture. [10] E. Moggi. Computational lambda-calculus and mon­ads. In Proceedings 1989 IEEE Symposium 
on Logic in Computer Science, pages 14-23. IEEE, June 1989. [II] M. Odersky. A syntactic theory of local 
names. Re­search Report YALEU/DCS/RR-965, Department of Computer Science, Yale University, May 1993. 
[12] M. Odersky and D. Rabin. The unexpurgated call­by-name, assignment, and the lambda-calculus. Re­search 
Report YALEU/DCS/RR-930, Department of Computer Science, Yale University, May 1993. [13] M. Odersky, 
D. Rabin, and P. Hudak. Call-by-name, call-by-value, and the lambda calculus. In Proc. 20th ACM Symposium 
on Principles of Programming Lan­guages, pages 43-56, January 1993. [14] F. J. Oles. A Category-Theoretic 
Approach to the Se­mantics of Programming Languages. PhD thesis, Syra­cuse University, August 1982. [15] 
S. L. Peyton Jones and P. Wadler. Imperative func­tional programming. In Proc. 20th A Clf Symposium on 
Principles of Programming Languages, pages 71 84. ACM Press, January 1993. [16] A. Pitts and I. Stark. 
On the observable properties of higher order functions that dynamically create lo­cal names. In SIPL 
93 A Cll SIGPLA N Workshop on State in Programming Languages, Copenhagen, Den­mark, pages 31-45, June 
1993. Yale University Research Report YALEU/DCS/RR-968. [17] G. D. Plotkin. LCF considered as a programming 
lan­guage. Theoretical Computer Science, 5:223-255, 1977. [18] J. C. Reynolds. Preliminary design of 
the programming language Forsythe. Technical Report CMU-CS-88-159, Carnegie Mellon University, June 1988. 
 [19] J. G. Riecke. Delimiting the scope of effects. In Proc. Conf. on Functional Programming and Computer 
Ar­chitecture, pages 146 155, June 1993. [20] V. Swarup, U. S. Reddy, and E. Ireland. Assignments for 
applicative languages. In J. Hughes, editor, Func­tional Programming Languages and Computer Archi­tecture, 
pages 192-214. Springer-Verlag, August 1991. Lecture Notes in Computer Science 523. [21] P. Wadler. Comprehending 
monads. In Proc. ACM ~ Conf. on Lisp and Functional Programming, pages 61­78, June 1990. [22] P. Wadler. 
The essence of functional programming. In Proc. 19th ACM Symposium on Principles of Program­ming Languages, 
pages 1 14, January 1992. [23] S. Weeks and M. Felleisen. On the orthogonality of as­signments and procedures 
in Algol. In Proc. 20th AC&#38;l Symposium on Principles of Programming Languages, pages 57-7o. ACM Press, 
January 1993.</RefA> 59  
			
