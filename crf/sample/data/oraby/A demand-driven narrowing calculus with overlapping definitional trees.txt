
 A Demand-driven Narrowing Calculus with Overlapping Definitional Trees Rafael del Vado Vírseda Dpto. 
Sistemas Informát. y Prog. Universidad Complutense de Madrid Av.Complutense,28040Madrid,Spain rdelvado@sip.ucm.es 
 ABSTRACT We propose a demand-driven conditional narrowing calculus in which a variant of definitional 
trees [2] is used to efficiently control the narrowing strategy. This calculus is sound and strongly 
complete w.r.t. Constructor-based ReWriting Logic (CRWL) semantics [7] for a wide class of constructor-based 
conditional term rewriting systems. The calculus mantains the optimality properties of the needed narrowing 
strategy [5]. Moreover, the treatment of strict equality as a primitive rather than a defined function 
symbol, leads to an improved behaviour w.r.t. needed narrowing.  Categories and Subject Descriptors 
D.1.1 [Programming Techniques]: Applicative (Functional) Programming; D.1.6 [Programming Techniques]: 
Logic Programming; D.3.3 [Programming Languages]: Language Constructs and Features Control structures; 
D.3.4 [Programming Languages]: Processors Optimization; F.4.2 [Mathematical Logic and Formal Languages]: 
Grammars and Other Rewriting Systems; G.2.2 [Discrete Mathematics]: Graph Theory Trees; I.1.1 [Algebraic 
Manipulation]: Expressions and Their Representation Simplification of expressions; I.2.2 [Automatic 
Programming]: Program transformation. General Terms Algorithms, Languages, Performance, Theory.  Keywords 
Functional Logic Programming Languages, Rewrite Systems, Narrowing, call-time choice, definitional trees. 
 Permission to make digital or hard copies of all or part of this work for personal or classroom use 
is granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, 
to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. PPDP 
03, August 27-29, 2003, Uppsala, Sweden. Copyright 2003 ACM 1-58113-705-2/03/0008 $5.00. 1. INTRODUCTION 
Many recent approaches to the integration of functional and logic programming take constructor-based 
conditional rewrite systems as programs and some lazy narrowing strategy or calculus as a goal solving 
mechanism and as operational semantics (see [8] for a detailed survey). On the other hand, non-deterministic 
functions are an essential feature of these integrated languages, since they allow problem solving using 
programs that are textually shorter, easier to understand and maintain, and more declarative than their 
deterministic counterparts (see [3], [7] or [13] for several motivating examples). In this context, efficiency 
has been one of the major drawbacks of the functional logic programming paradigm, where the introduction 
of non-deterministic computations often generates huge search spaces with their associated overheads 
both in terms of time and space. Actually, the adoption of a demand-driven narrowing strategy can result 
in a large reduction of the search space [15]. A demand-driven strategy evaluates an argument of a function 
only if its value is needed to compute the result. An appropriate notion of need is a subtle point in 
the presence of a non-deterministic choice, e.g., a typical computation step, since the need of an argument 
might depend on the choice itself. For the case of rewriting, an adequate theory of neededness has been 
proposed by Huet and Lévy [12] for orthogonal and unconditional rewrite systems and extended by Middeldorp 
[17] to the more general case of neededness for the computation of root-stable forms. The so-called needed 
narrowing strategy [5] has been designed for Inductively Sequential Systems (ISS), a proper subclass 
of orthogonal rewriting systems which coincides with the class of strongly sequential constructor-based 
orthogonal TRSs [11] and defines only deterministic functions by means of unconditional rewrite rules. 
Both needed narrowing and the demand driven strategy from [15] were originally defined with the help 
of definitional trees, a tool introduced by Antoy [2] for achieving a reduction strategy which avoids 
unneeded reductions. The needed narrowing strategy is sound and complete for the class ISS, and it enjoys 
interesting and useful optimality properties, but has the disadvantage that it refers only to a closed 
version of strict equality [5] where the goals are often solved by enumerating infinitely many ground 
solutions, instead of computing a single more general one. Example 1. Consider the following ISS, and 
let sk(t) be the result of applying the constructor s, k consecutive times, to the term t. X + 0 . X 
X + s(Y) . s(X + Y) For the goal X + Y == Z, needed narrowing as presented in [5] enumerates infinitely 
many ground solutions {Y a s(0), X a sn(0), Z a sn+1(0)} (for all n = 0) instead of computing an open 
solution {Y a s(0), Z a s(X)} which subsumes the previous ground ones. The reason of this behaviour is 
the formal treatment of == as a function defined by rewrite rules. In this example: 0 == 0 . true true, 
Z . Z s(X) == s(Y) . X == Y p A more recent paper [3] has proposed an extension of needed narrowing called 
inductively sequential narrowing. This strategy is sound and complete for overlapping inductively sequential 
systems, a proper extension of the class of ISSs which permits non-deterministic functions, but conditional 
rules and an open strict equality are not adopted. The optimality properties of needed narrowing are 
retained in a weaker sense by inductively sequential narrowing. Even more recently, [10] has proposed 
a reformulation of needed narrowing as a goal transformation system, as well as an extension of its scope 
to a class of higher-order inductively sequential TRSs. Higher-order needed narrowing in the sense of 
[10] is sound and relatively complete, and it enjoys optimality properties similar to those known for 
the first-order case. In spite of the good results from the viewpoint of neededness, [5, 2, 10] stick 
to a simplistic treatment of strict equality as a defined function symbol. Other recent works [14, 18, 
7] have developed various lazy narrowing calculi based on goal transformation systems, where an open 
semantics of strict equality does not require the computation of ground solutions, as illustrated by 
Example 1. Moreover, [7] allows non-deterministic functions with so-called call-time choice semantics, 
borrowed from [13], and illustrated by the next example: Example 2. Consider the TRS consisting of the 
rewrite rules for + given in Example 1 and the following rules: coin . 0 double(X) . X + X coin . s(0) 
Intuitively, the constant function coin represents a non­deterministic choice. In order to evaluate the 
expression double(coin), call-time choice semantics chooses some possible value for the argument expresion 
coin, and then applies the function double to that value. Therefore, when using call-time choice, double(coin) 
can be reduced to 0 and s2(0), but not to s(0). p As argued in [7, 13], the call-time choice view of 
non­determinism is the convenient one for many programming applications. However, the narrowing methods 
proposed in [5, 2, 14, 18] are unsound w.r.t. call-time choice semantics. In [7], the Constructor-based 
ReWriting Logic CRWL is proposed to formalize rewriting with call-time non-deterministic choices, and 
the Constructor-based Lazy Narrowing Calculus CLNC is provided as a sound and strongly complete goal 
solving method. Therefore, CLNC embodies the advantages of open strict equality and call-time choice 
non-determinism. The aim of this paper is to refine CLNC in order to enrich its advantages with those 
of needed narrowing. We will combine goal transformation rules similar to those in [14, 18, 7] with the 
use of definitional trees to guide the selection of narrowing positions, in the vein of [15, 5, 3, 10]. 
As a result, we will propose a Demand-driven Narrowing Calculus DNC which can be proved sound and strongly 
complete w.r.t. CRWL s semantics (call-time choice non-determinism and open strict equality), contracts 
needed redexes, and maintains the good properties shown for needed narrowing in [5, 3]. All these properties 
qualify DNC as a convenient and efficiently implementable operational model for lazy FLP languages. The 
organization of this paper is as follows: Section 2 contains some technical preliminaries regarding the 
constructor-based rewriting logic CRWL. Section 3 defines the subclass of rewriting systems used as programs 
in this work. In Section 4 we give a formal presentation of the calculus DNC. We discuss the soundness, 
completeness and optimality results in Section 5. Finally, some conclusions and plans for future work 
are drawn in Section 6. 2. PRELIMINARIES The reader is assumed to be familiar with the basic notions 
and notations of term rewriting, as presented e.g. in [6]. We assume a signature S= DCS.FSS where DCS=Un.Ù 
DCS n is a set of ranked constructor symbols and FSS= Un.Ù FSS n is a set of ranked function symbols, 
all of them with associated arity and such that DCSn FSS=Ø. We also assume a countable set V of variable 
symbols. We write TermS for the set of (total) terms built over S and V in the usual way, and we distinguish 
the subset CTermS of (total) constructor terms or (total) c-terms, which only make use of DCS and V . 
The subindex S will usually be omitted. Terms intend to represent possibly reducible expressions, while 
c-terms represent data values, not further reducible. The CRWL semantics also uses the constant symbol 
., that plays the role of the undefined value. We define S. =S . {.}; the sets Term. and CTerm. of (partial) 
terms and (partial) c-terms respectively, are defined in a natural way, by using the symbol . just as 
a constant for syntatic purposes. Partial c-terms represent the result of partially evaluated expressions; 
thus, they can be seen as approximations to the value of expressions in the CRWL semantics. As usual 
notations we will write X,Y,Z for variables, c,d for constructor symbols, f,g for functions, a,b,e for 
terms and s,t for c-terms. Moreover, Var(e) will be used for the set of variables occurring in the term 
e. A term e is called ground term, if Var(e) =Ø. A term is called linear if it is does not contain multiple 
occurrences of any variable. A natural approximation ordering m over Term. can be defined as the least 
partial ordering over Term. satisfying the following properties: . m e for all e . Term., and h(e1,...,en) 
m h(e1 ,...,en ), if ei m ei for all i . {1, ,n}, h . DCn . FSn. To manipulate terms we give the following 
definitions. An occurrence or position is a sequence p of positive integers identifying a subterm in 
a term. For every term e, the set O(e) of positions in e is inductively defined as follows: the empty 
sequence denoted by e, identifies e itself. For every term of the form f(e1,...,en), the sequence i·q, 
where i is a positive integer not greater than n and q is a position, identifies the subterm of ei at 
q. The subterm of e at p is denoted by e|p and the result of replacing e|p with e in e is denoted by 
e[e ]p. If p and q are positions, we write p Ç q if p is above or is a prefix of q, and we write p || 
q if the positions are disjoint, i.e. neither p Ç q nor q Ç p. The expression p·q denotes the position 
resulting from the concatenation of the positions p and q. The set O(e) is partitioned into Õ(e) and 
OV (e) as follows: Õ(e) = {p . O(e) | e|p . V } and OV (e) = {p . O(e) | e|p . V }. If e is a linear 
term, pos(X,e) will be used for the position of the variable X occurring in e. The notation Varc(e) stands 
for the set of all variables ocurring in e at some position whose ancestor positions are all occupied 
by constructors. The sets of substitutions CSubst and CSubst. are defined as applications s from V into 
CTerm and CTerm. respectively such its domain Dom(s) = {X . V | s(X) . X} is finite. We will write .,s,µ 
for substitutions and {} for the identity substitution. Substitutions are extended to morphisms on terms 
by s(f(e1,...,en)) = f(s(e1),...,s(en)) for every term f(e1,...,en). The composition of two substitutions 
. and s is defined by (.°s)(X) =.(s(X)) for all X . V. A substitution s is idempotent iff s°s = s. We 
frequently write {X1 a e1, ,Xn a en} for the substitution that maps X1 into e1, , Xn into en. The restriction 
s .V of a substitution s to a set V . V, is defined by s .V (X) =s(X) if X . V and s .V (X) = X if X 
. V. A substitution s is more general than s , denoted by s d s , if there is a substitution t with s 
= t°s. If V is a set of variables,wewrite s =s [V] iff s .V =s .V, and we write s d s [V] iff there is 
a substitution t with s = t°s [V]. A term e is an instance of e if there is a substitution s with e =s(e). 
In this case we write e Å e . A term e is a variant of e if e Å e and e Å e. Given a signature S, a CRWL-program 
R is defined as a set of conditional rewrite rules of the form f(t1,...,tn) . r . a1 == b1, ..., am == 
bm (m = 0) with f . FSn, t1,...,tn . CTerm, r,ai,bi . Term, i = 1,...,m, and f(t1,...,tn) is a linear 
term. The term f(t1,...,tn) is called left hand side and r is the right hand side. Example 3. For instance, 
we consider the following CRWL­program defining a non-deterministic function bits, where we use the function 
coin from Example 2 and the Prolog syntax for the list constructors (i.e. [ ] denotes the empty list 
and [·|·] denotes a non-empty list consisting of a first element and a remaining list). bits . [ X | 
bits ] . coin == X bits generates an infinite list with a non-deterministic choice of each element (0 
or s(0)). p From a CRWL-program we are interested in deriving sentences of two kinds: approximation statements 
a . b, with a . Term. and b . CTerm., and joinability statements a == b, with a, b . Term.. We formally 
define a goal-oriented rewriting calculus CRWL [7] by means of the following inference rules: BT Bottom: 
e .. for any e . Term.. RR Restricted Reflexivity: X . X  for any variable X. DC DeComposition: e1 
. t1 ... en . tn c(e1,...,en) . c(t1,...,tn) for c . DCn, ti . CTerm.. OR Outer Reduction: e1 . t1 ... 
en . tn C r . t f(e1,...,en) . t if t .. and (f(t1,...,tn) . r . C) . [R]. where [R].= {.(l . r . C) 
| (l . r . C) .R, .. CSubst.} is the set of all partial c-instances of rewrite rules in R. JN Join a 
. tb . t a == b for total t . CTerm. Rule BT corresponds to an implicit rewrite rule X .., meaning that 
. approximates the value of any expression. Rules RR, DC and OR implicitly encode reflexivity, monotonicity 
and transitivity of the rewriting relation, while rule JN is used to establish the validity of conditions 
in the case of conditional rewrite rules. The rule OR uses partial data substitutions . to instantiate 
rewrite rules from R, while classical rewriting would use arbitrary substitutions of total expressions 
for variables. It is because of this difference that CRWL expresses call-time choice semantics. Moreover, 
BT and OR (in cooperation with the other inference rules) also ensure that CRWL expresses a non-strict 
semantics for function evaluation. Example 4. As a concrete example of CRWL-derivability, we show a CRWL-proof 
for the approximation statement bits . [s(0)|[0|.]], using the CRWL-program of Example 3. DC 0 . 0 OR 
DC DC BT coin . 0 0 . 0 JN 0 . 0 bits . . DC 0 . 0 DC coin == 0        [ 0 | bits ] . [ 0 | . 
] OR s(0) . s(0) DC 0 . 0 DC 0 . 0 DC coin . s(0)   OR s(0) . s(0)    DC s(0) . s(0)     
DC bits . [ 0 | . ] coin == s(0) JN [ s(0) | bits ] . [ s(0) | [ 0 | . ] ] OR DC bits . [ s(0) | [ 
0 | . ] ] p In the sequel we will use the notations R | CRWL . to indicate that . (an approximation statement 
or a joinability statement) can be deduced from the CRWL-program R by finite application of the above 
rules. In the following lemma we collect some simple facts about provable statements involving c-terms, 
which are needed for the proofs of the main results in this paper. The proof is straighforward by induction 
over the structure of c-terms or over the structure of CRWL-proofs (see [7] and [19] for details). Lemma 
1 (basic properties of CRWL-deductions). Let R be a CRWL-program. For any e . Term., t,s . CTerm. and 
.,. . CSubst., we have: a) R | CRWL t . s . t } s. Furthermore, if s . CTerm is total, then t } s can 
be replaced by t = s. b) R | CRWL e . t, t } s .R | CRWL e . s. c) R | CRWL .(e). t, . m . .R| CRWL . 
(e).t, with the same length and structure in both deductions. d) R | CRWL e . s .R | CRWL .(e) ..(s), 
if . is a total substitution. e) R | CRWL e . s . there exists t . CTerm. such that R | CRWL e|p . t 
and R | CRWL e[t ]p . s, provided that p . O(e). 3. OVERLAPPING DEFINITIONAL TREE AND COISS The demand-driven 
narrowing calculus that we are going to present works for a class of CRWL-programs in which conditional 
rewrite rules with possibly overlapping left hand sides must be organized in a hierarchical structure 
called definitional tree [2]. More precisely, we choose to reformulate the notion of overlapping definitional 
tree and overlapping inductively sequential system introduced in [3], including now conditional rules. 
Definition 1 (ODT). Let S= DC . FS be a signature and R a CRWL-program over S. A pattern is any linear 
term of the form f(t1,...,tn), where f . FSn is a function symbol and ti are c-terms. I is an Overlapping 
Definitional Tree (ODT for short) with pattern p iff its depth is finite and one of the following cases 
holds: I= rule(l . r1 . C1 | ... | rm . Cm), where l . ri . Ci for all i in {1, ,m} is a variant of 
a rule in R such that l =p..  I= case(p,X,[I1,...,Ik]), where X is a variable in p, c1,...,ck . DC for 
some k > 0 are pairwise different constructors of R, and for all i in {1, ,k}, Ii is an ODT with pattern 
si(p), where si = {X a ci(Y1,...,Ymi)}, mi is the arity of ci and Y1,...,Ymi are new distinct variables. 
 We represent an ODT I with pattern p using the notation Ip. An ODT of a function symbol f . FSn defined 
by R is an ODT I with pattern f(X1,...,Xn), where X1,...,Xn are new distinct variables. Definition 2 
(COISS). A function f is called overlapping inductively sequential w.r.t. a CRWL-program R iff there 
exists an ODT If of f such that the collection of all the rewrite rules l . ri . Ci (1=i=m) obtained 
from the different nodes rule(l . r1 . C1 | ... | rm . Cm) occurring in If equals, up to variants, the 
collection of all the rewrite rules in R whose left hand side has the root symbol f. A CRWL-program R 
is called Conditional Overlapping Inductively Sequential System (COISS, for short) iff each function 
defined by R is overlapping inductively sequential. Example 5. The following CRWL-program R defines a 
function merge that merges two given lists. We use Prolog s syntax for the list constructors and we omit 
the rewrite rules needed for defining the function compare. merge ([ ], Ys)  . Ys merge ([X|Xs], [ 
]) . [X|Xs] merge ([X|Xs], [Y|Ys]) . [X| merge (Xs, [Y|Ys])] . compare (X, Y) == less_than . [X| merge 
(Xs, Ys)] . compare (X, Y) == equal . [Y| merge ([X|Xs], Ys)] . compare (X, Y) == greater_than  since 
the defined symbol merge has the following ODT, merge is overlapping inductively sequential w.r.t. R. 
case(merge (Xs, Ys), Xs, [ rule(merge ([ ] , Ys) . Ys), case(merge ([X|Xs], Ys), Ys, [ rule(merge ([X|Xs], 
[ ]) . [X|Xs]), rule(merge ([X|Xs], [Y|Ys]) .    [X| merge (Xs, [Y|Ys])] . compare (X, Y) == less_than 
|    [X| merge (Xs, Ys)] . compare (X, Y) == equal |    [Y| merge ([X|Xs], Ys)] . compare (X, 
Y) == greater_than)] )]) This tree can be illustrated by the following picture: merge (Xs, Ys) merge 
([ ], Ys)       merge ([X|Xs], Ys) Ys merge ([X|Xs], [ ])     merge ([X|Xs], [Y|Ys]) [X|Xs] 
[X| merge (Xs, [Y|Ys])] . compare (X, Y) == less_than |                   [X| merge 
(Xs, Ys)] . compare (X, Y) == equal |                   [Y| merge ([X|Xs], Ys)] . compare 
(X, Y) == greater_than p Let R be any COISS. For our discussion of a demand-driven narrowing calculus 
with ODTs over COISSs we are going to use a presentation similar to that of the CLNC calculus (see [7]). 
So, goals for R are essentially finite conjunctions of CRWL­statements, and solutions are c-substitutions 
such that the goal affected by the substitution becomes CRWL-provable. The precise definition of admissible 
goal includes a number of technical conditions which will be defined and explained below. The general 
idea is to ensure the computation of solutions which are correct w.r.t. CRWL s call-time choice semantics, 
while using ODTs in a similar way to [5, 3, 10] to ensure that all the narrowing steps performed during 
the computation are needed ones.  4. THE DNC CALCULUS In this section we present a Demand-driven Narrowing 
Calculus (shortly, DNC) for goal solving. We give first a precise definition for the class of admissible 
goals and solutions we are going to work with. Definition 3 (Admissible goals). A goal for a given COISS 
R must have the form G =. U. S p P p E, where the symbols p and , must be interpreted as conjunction, 
and: EVar(G) = def U is the set of so-called existential variables of the goal G. These are intermediate 
variables, whose bindings in a solution may be partial c-terms.  S = X1 s1 , ... , Xn sn is a set 
of equations, called solved part. Each si must be a total c-term, and each Xi must occur exactly once 
in the whole goal. This represents an idempotent c-substitution sS = {X1 a s1, ... , Xn a sn}.  P = 
t1 . R1 , ... , tk . Rk is a multiset of productions where each Ri is a variable and ti is a term or 
a pair of the form <p,I>, where p is an instance of the pattern in the root of an ODT I. Those productions 
l . R whose left hand side l is simply a term are called suspensions, while those whose left hand side 
is of the form <p,I> are called demanded productions. PVar(P) = def {R1,...,Rk} is called the set of 
produced variables of the goal G. The production relation between G-variables is defined by X pP Y iff 
there is some 1=i=k such that X . Var(ti) and Y = Ri (if ti is a pair <p,I>, X . Var(ti) must be interpreted 
as X . Var(p)).  E = l1 == r1 , ... , lm == rm is a multiset of strict equations. DVar(P p E), called 
the set of demanded variables of the  goal G, is the least subset of Var(P p E) which fulfills the following 
conditions: - (l == r) . E . VarC(l) . VarC(r) . DVar(P p E). -(<t, case(p,X,[I1,...,Iq])>. R) . P with 
t|pos(X,p) = Y . Var(t) and R . DVar(P p E) . Y . DVar(P p E). Additionally, an admissible goal must 
satisfy the following properties, called admissibility conditions: LIN Each produced variable is produced 
only once, i.e. varia­   bles R1,...,Rk must be different. EX All the produced variables must be existential, 
i.e. PVar(P) . EVar(G). CYC The transitive closure of the production relation pP must be irreflexive, 
or equivalently, a strict partial order. SOL The solved part S contains no produced variables. DT For 
each demanded production <p,I>. R in P, the variable R is demanded (i.e. R . DVar(P p E)), and the variables 
in I do not occur in other place of the goal. Admissibility conditions are natural in so far they are 
satisfied by all the goals arising from initial goals G0 =.Ø. Ø p Ø p E by means of the goal transformations 
presented below. We note that an equivalent formulation for the admissibility condition CYC can be obtained 
by requiring that it is possible to reorganize the productions of P in the form P = t1 . R1 , ..., tk 
. Rk where Ri . U1=j=i-1 Var(tj) for all 1=i=n (if tj is a pair <p,I>, Var(tj) must be interpreted as 
Var(p)). On the other hand, the following distinction between the two possible kinds of productions is 
useful: Demanded productions <t, I> . R are used to compute a value for the demanded variable R. The 
value will be shared by all occurrences of R in the goal, in order to respect call-time choice semantics. 
Note that t is always an instance of the pattern in the root of I. Moreover, if I= case(p,X,[I1,...,Ik]), 
p = pos(X,p) must be a position in t such that all symbols in t at positions above p are data constructors. 
 Suspensions f(t1,...,tn) . R eventually become demanded productions if R becomes demanded, or else 
disappear if R becomes absent from the rest of the goal. See the goal transformations SA and EL in Subsection 
4.2. Suspensions X . R and c(e1,...,en) . R are suitably treated by other goal transformations.  Definition 
4 (Solutions). Let G =. U. S p P p E be an admissible goal for a COISS R, and . a partial c-substitution. 
We say that . is a solution for G with respect to R if: For each X . PVar(P), .(X) is a total c-term. 
 For each solved equation (Xi si) . S, .(Xi) =.(si).  For each suspension (t . R) . P, R | CRWL .(t) 
..(R).  For each demanded production (<p, I> . R) . P, R | CRWL .(p) ..(R) (i.e. the definitional tree 
I is only used to control the computation).  For each strict equation (l == r) . E, R | CRWL .(l) == 
.(r).  A witness M for the fact that . is a solution of G is defined as a multiset containing the CRWL 
proofs mentioned above. We write Sol(G) for the set of all solutions for G. The next result is useful 
to prove properties about DNC and shows that CRWL semantics does not accept an undefined value for demanded 
variables. Lemma 2 (Demand lemma). If . is a solution of an admissible goal G =.U. S p P p E for a COISS 
R and X . DVar(P p E), then .(X) ... Proof. Let G =.U. S p P p E be an admissible goal for a COISS R 
and X . DVar(P p E). We use induction on the transitive closure pP + of the production relation, which 
is a well founded ordering, due to the admissibility condition CYC. We consider the two cases for X. 
a) X . VarC(l) . VarC(r) with (l == r) . E. We suppose that X . VarC(l) (analogous if X . VarC(r)). There 
are a finite number k=0 of constructor symbols above X in l. Since . is a solution of G, R | CRWL .(l) 
== .(r) and exists u . CTerm with R | CRWL .(l) . u and R | CRWL .(r) . u using the CRWL-rule JN. Since 
R | CRWL .(l) . u, where .. CSubst. and u is a total c-term, it is easy to see that u and .(l) must have 
the same constructors at all the positions in the path from the root to the position of X in l. So, the 
CRWL-deduction takes the rule DC k times on .(l) . u to obtain R | CRWL .(X) . t with t . CTerm. Then 
.(X) = t follows from Lemma 1 a), and this entails .(X) ... b) X = t|pos(Y,p) with (<t, case(p,Y,[I1,...,Ik])>. 
R) . P and R . DVar(P p E). In this case, t = f(t1,...,tn) with f . FSn, and since . is a solution, R 
| CRWL f(.(t1),...,.(tn)) ..(R). By Definition 3, X pP R and hence X pP + R. Since R . DVar(P p E), the 
induction hypothesis yields .(R) ... Moreover, pos(Y,p) = i·p with 1=i=n and p . O(ti) because p Å t. 
Therefore, the CRWL-deduction R | CRWL f(.(t1),...,.(tn)) . .(R) must be of the form OR: .(t1) . t1 ... 
.(ti) . ti ... .(tn) . tn C r ..(R) f(.(t1),...,.(tn)) ..(R) where (f(t1 ,...,ti ,...,tn ) . r . C) . 
[R].. Due to the form of the ODT in the demanded production, ti has a constructor symbol cj (1=j=k) in 
the position p. Moreover, there must be only constructor symbols above cj in ti . So, ti ... Moreover, 
since R | CRWL .(ti) . ti where ti . CTerm. and .. CSubst., there must be the same constructor symbols 
and in the same order above .(X) in the position p of .(ti) (recall p Å t with X = ti|p). It follows 
that R | CRWL .(ti) . ti applies the CRWL-rule DC over .(ti) . ti to yield R | CRWL .(X) . cj(...). We 
conclude that .(X) ... ¸ The aim when using DNC is to transform an initial goal into a solved goal of 
the form . U. S pp with S = X1 s1,...,Xn sn representing a solution sS = {X1 a s1,...,Xn a sn}. The 
notation ü, used in failure rules, represents an inconsistent goal without any solution. The calculus 
DNC consists of a set of transformation rules for goals. Each transformation takes the form G k G , specifying 
one of the possible ways of performing one step of goal solving. Derivations are sequences of k-steps. 
In addition, to the purpose of applying the rules, we see conditions a == b as symmetric. In the next 
subsections we give succint explanations justifying the formulation of the different kinds of rules that 
compose the DNC calculus. 4.1 Rules for Strict Equations In this first subsection we describe the transformation 
rules supporting the treatment of == as a built-in symbol with the meaning of open strict equality, rather 
than a defined function symbol. Given a strict equation s == t with s,t terms in a goal, the rules try 
to specify all the possibilities in the reduction of both terms to the same constructor term (a finite, 
totally defined value). In this sense, we distinguish the following different cases and rules according 
to the sintactic structure of s (analogously for t, due to the symmetry of ==). If s is f(s1, ,sn) with 
f . FSn, we introduce in the goal a new demanded production decorating s with an appropriate ODT If to 
guide the evaluation in a needed narrowing style (see the goal transformations RRA, DN, CS and DI in 
Subsection 4.2). This is performed by the rule DPI.  If s is c(s1, ,sn) with c . DCn, the term t has 
also a constructor symbol in the root or is a variable (any other case is collected in the item above). 
In the first case, the constructor symbol must be c to obtain an adequate descomposition of their corresponding 
arguments in smaller strict equations (see rule DC); otherwise rule CF fails. If t is a variable, we 
can suppose that is not produced (otherwise, we must wait until other rules become applicable producing 
an appropriate instantiation) and not occurs in s (otherwise, the rule CY fails). In this situation, 
if s represents a data value (i.e. a c-term without produced variables), it is possible to propagate 
the binding X a t to the rest of the goal, by means of rule BD. Otherwise, it is possible to instantiate 
t with an outermost imitation of the sintactic structure of s to guide the descomposition of the strict 
equation, as is performed by the rule IM.  Finally, it may happen that s and t are both variables. If 
any of them variables is produced, we must wait until other rule becomes applicable producing an appropriate 
instantiation. Otherwise, we can either eliminate a trivial strict equation using rule ID, or propagate 
a binding by means of rule BD.  DPI Demanded Production Introduction .U . S p P p f(s1,...,sn) == t, 
E k .R, U . S p <f(s1,...,sn), If(X1,...,Xn)>. R, P p R == t, E if f . FS, and both R and all variables 
in If(X1,...,Xn) are new variables. DC DeComposition .U . S p P p c(s1,...,sn) == c(t1,...,tn), E k 
.U . S p P p s1 == t1, ... , sn == tn, E if c . DC. ID  IDentity .U . S p P p X == X, E k .U . S p 
P p E if X . PVar(P).  BD BinDing IIM Input IMitation .U . S p P p X == t, E k .U . X t , s(S p P p 
E) if t . CTerm, Var(t) n PVar(P) =Ø, X . PVar(P), X . Var(t), and s= {X a t}.  IM IMitation .U . S 
p P p X == c(t1,...,tn), E k .X1,...,Xn, U . X c(X1,...,Xn) , s(S p P p X1 == t1,...,Xn == tn, E) if 
c . DC, c(t1,...,tn) . CTerm or Var(c(t1,...,tn)) n PVar(P) .Ø, X . PVar(P), X . Varc(c(t1,...,tn)), 
and s= {X a c(X1,...,Xn)} with X1,...,Xn new variables.  4.2 Rules for Productions The goal transformation 
rules concerning productions are designed with the aim of modelling the behaviour of lazy needed narrowing 
with sharing. Let us first comment the rules for suspensions t . R. Rule EL is applied only if R becomes 
absent from the rest of the goal and then is unnecessary. In other case, the rule IB is applicable if 
t is a data value (i.e. a c-term, not further reducible), propagating this obtained value to all occurrences 
of R in the goal. If t is not yet a c-term, only transformations IIM or SA are applicable, propagating 
partially the obtained value to all the occurrences of R if t has a constructor symbol in the root, or 
awakening the suspension if t has a function symbol in the root decorating t with the appropriate definitional 
tree, respectively. Both cases require that R is a demanded variable, whose value in any solution must 
be different from . because of Lemma 2. If R is not demanded, nothing can be done with the suspension 
but waiting until goal solving progresses by means of other rules. This will eventually happen, as shown 
by the completeness results in Section 5. The goal transformation rules for demanded productions <t, 
I> . R encode the needed narrowing strategy guided by ODT I, in a vein similar to [10]. If I is a rule 
ODT, then the transformation RRA chooses one of the available rules for rewriting t, introducing appropriate 
suspensions in the new goal so that lazy evaluation with call-time choice is ensured. If I is a case 
tree, one of the transformations CS, DI or DN can be applied, according to the kind of symbol u occurring 
in t al the case-distinction position p. If u is a constructor ci, then CS selects the appropriate subtree 
(if possible; otherwise UC fails). If u is a non-produced variable Y, then DI non-deterministically selects 
a subtree, generating an appropriate binding for Y. Finally, if u is a demanded function symbol g, DN 
introduces a new demanded production in the new goal, in order to evaluate t|p. In any other case, selection 
of the subgoal <t, I> . R must be delayed until a further stage of the computation. IB Input Binding 
.R, U . S p t . R, P p E k .U . S p s(P p E) if t . CTerm, and s= {R a t}. .R, U . S p c(t1,...,tn) . 
R, P p E k .R1,...,Rn, U . S p s(t1 . R1, ... , tn . Rn, P p E) if c(t1,...,tn) .CTerm, R. DVar(P p E), 
and s= {R a c(R1,...,Rn)}   with R1,...,Rn new variables. SA Suspension Awakening .R, U . S p f(t1,...,tn) 
. R, P p E k .R, U . S p <f(t1,...,tn) , If(X1,...,Xn)>. R, P p E if f . FS, R . DVar(P p E), and all 
variables in If(X1,...,Xn) are new   variables. EL ELimination .R, U . S p t . R, P p E k .U . S 
p P p E if R . Var(P p E). RRA Rewrite Rule Application (don t know choice: 1=i=k) .R, U. S p <t, rule(l 
. r1 . C1 | ... | rk . Ck)>. R, P p E k . , R, U. S p sf(R1) . R1,...,sf(Rm) . Rm, sc(ri) . R, P p sc(Ci), 
E where s=sc .sf with Dom(s) = Var(l) and s(l) = t.  sc = def s . Domc(s), where Domc(s) = {X . Dom(s) 
| s(X) . CTerm}.  sf = def s . Domf(s), where Domf(s) = {X . Dom(s) | s(X) . CTerm} = {R1,...,Rm}. 
 = Var(l . ri . Ci) \ Domc(s).  CS Case Selection .R, U . S p <t, case(p,X,[I1,...,Ik])>. R, P p E 
k .R, U . S p <t, Ii>. R, P p E if t|pos(X,p) = ci(...), with 1=i=k given by t, where ci is the constructor 
  symbol associated to Ii. DI Demanded Instantiation (don t know choice: 1=i=k) .R, U . S p <t, case(p, 
X, [I1,...,Ik])>. R, P p E k .Y1,...,Ymi,R, U . Y ci(Y1,...,Ymi), s(S p <t, Ii>. R, P p E) if t|pos(X,p) 
= Y, Y . PVar(P), s= {Y a ci(Y1,...,Ymi)} with ci (1=i=k) the constructor symbol associated to Ii and 
Y1,...,Ymi are   new variables. DN Demanded Narrowing .R, U . S p <t, case(p, X, [I1,...,Ik])>. R, 
P p E k .R ,R, U . S p <t|pos(X,p), Ig(Y1,...,Ym)>. R , <t[R ]pos(X,p) , case(p, X, [I1,...,Ik])>. R, 
P p E if t|pos(X,p) = g(...) with g . FSm, and both R and all variables in Ig(Y1,...,Ym) are new variables. 
 4.3 Rules for Failure Detection In this subsection we collect the failure rules already mentioned above, 
namely: failure in the unification of strict equations (conflict constructors and occurs check) and failure 
for constructor non-cover in demanded productions. We note that the failure rule CY for occurs check 
requires the condition X . Varc(t) instead of only X . Var(t). The reason is that X == t may have solutions 
when X . Var(t) \ Varc(t). For instance, X == f(X) certainly has solutions if f is defined by the rewrite 
rule f(X) . X. CF ConFlict .U . S p P p c(s1,...,sn) == d(t1,...,tm), E k ü if c,d . DC and c . d. CY 
CYcle .U . S p P p X == t, E k ü  if X . t and X . Varc(t). UC Uncovered Case .R, U . S p <t, case(p,X,[I1,...,Ik])>. 
R, P p E k ü if t|pos(X,p) = c(...) and c . {c1,...,ck}, where ci is the constructor symbol associated 
to Ii (1=i=k). Finally, the section is closed with several examples of goal solving which highlight the 
main properties of the DNC calculus. At each goal transformation step, we underline which subgoal is 
selected. Example 6. We compute the non-ground solution {Y a s(0), Z a s(X)} from the goal X + Y == Z 
in Example 1. This illustrates the use of an open equality to compute general answers rather than having 
to enumerate over an infinite set. pp X+Y == Z k DPI .R . p <X+Y,IA+B>. R p R == Z k{Y a s(U)} DI .U,R 
. Y s(U) p <X+s(U),IA+s(C)>. R p R == Z k RRA .U,R . Y s(U) p s(X+U) . R p R == Z k{R a s(R )} IIM 
.R ,U . Y s(U) p X+U . R p s(R ) == Z k SA .R ,U . Y s(U) p <X+U,IA +B >. R p s(R ) == Z k{U a 0} DI 
.R ,U . U 0, Y s(0) p <X+0,IA +0>. R p s(R ) == Z k RRA .R ,U . U 0, Y s(0) p X . R p s(R ) == Z 
k{R a X} IB .U . U 0, Y s(0) pp s(X) == Z k{Z a s(X)} BD .U . Z s(X), U 0, Y s(0) pp computed solution: 
s= {Y a s(0), Z a s(X)}. p Example 7. We compute the solutions from Example 2. This illustrates the use 
of productions for ensuring call-time choice and the use of ODTs for ensuring needed narrowing steps. 
pp double(coin) == N k DPI .R . p <double(coin),Idouble(X)>. R p R == N k RRA .X,R . p coin . X, X+X 
. R p R == N k AS .X,R . p coin . X, <X+X,IA+B>. R p R == N k AS .X,R . p <coin,Icoin>. X, <X+X,IA+B>. 
R p R == N k RRA .X,R . p 0 . X, <X+X,IA+B>. R p R == N k{X a 0} IB .R . p <0+0,IA+B>. R p R == N k CS 
.R . p <0+0,IA+0>. R p R == N k RRA .R . p 0 . R p R == N k{R . 0} IB pp 0 == N k{N a 0} BD N 0 pp . 
computed solution: s1 = {N a 0}. pp double(coin) == N k DPI .R . p <double(coin),Idouble(X)>. R p R == 
N k RRA .X,R . p coin . X, X+X . R p R == N k AS .X,R . p coin . X, <X+X,IA+B>. R p R == N k AS .X,R 
. p <coin,Icoin>. X, <X+X,IA+B>. R p R == N k RRA .X,R . p s(0) . X, <X+X,IA+B>. R p R == N k{X a s(0)} 
IB .R . p <s(0)+s(0),IA+B>. R p R == N k CS .R . p <s(0)+s(0),IA+s(C)>. R p R == N k RRA .R . p s(s(0)+0) 
. R p R == N k{R a s(R )} IIM .R . p s(0)+0 . R p s(R ) == N k AS .R . p <s(0)+0,IA +B >. R p s(R ) == 
N k CS .R . p <s(0)+0,IB +0>. R p s(R ) == N k RRA .R . p s(0) . R p s(R ) == N k{R a s(0)} IB pp s(s(0)) 
== N k{N a s(s(0))} BD N s(s(0)) pp . computed solution: s2 = {N a s(s(0))}. We note that both computations 
are in essence needed narrowing derivations modulo non-deterministic choices between overlapping rules, 
as in inductively sequential narrowing [3]. p Example 8. We compute the solutions from the goal head 
(bits) == Z, where we use the non-deterministic function bits from Example 3 and the rule head ([X|Xs]) 
. X. We use again Prolog s syntax for the list constructors. This example illustrates the use of productions 
to achieve the effect of a demand-driven evaluation. pp head (bits) == Z k DPI .R . p <head (bits),Ihead>. 
R p R == Z k DN .R ,R . p <bits,Ibits>. R , <head (R ),Ihead>. R p R == Z k RRA .X,R ,R . p [X | bits] 
. R , <head (R ),Ihead>. R p coin == X, R == Z k{R a [Y|Ys]} IIM .X,Y,Ys,R . p X . Y, bits . Ys, <head 
([Y|Ys]),Ihead>. R p coin == X, R == Z k RRA .X,Y,Ys,R . p X . Y, bits . Ys, Y . R p coin == X, R == 
Z k{Y a X}.{R a Y} IB×2 .X,Ys . p bits . Ys p coin == X, X == Z k EL .X . pp coin == X, X == Z k{X a 
Z} BD .X . X Z pp coin == Z k DPI .R ,X . X Z p <coin,Icoin>. R p R == Z k RRA .R ,X . X Z p 0 (or 
s(0)) . R p R == Z k{R a 0 (or s(0))} IB .X . X Z pp 0 (or s(0)) == Z k{Z a 0 (or s(0))} BD .X . 
Z 0 (or s(0)), X 0 (or s(0)) pp computed solutions: s1 = {Z a 0} and s2 = {Z a s(0)} p   5. PROPERTIES 
OF DNC To prove soundness and completeness of DNC w.r.t. CRWL semantics we use techniques similar to 
those used for the CLNC calculus in [7]. Some proofs omitted here can be found in [20, 19]. The first 
result proves correctness of a single DNC step. It says that transformation steps preserve admissibility 
of goals, fail only in case of unsatisfiable goals and do not introduce new solutions. Lemma 3 (Correctness 
Lemma). Assume any admissible goal G for a given COISS R. Then: a) If G k ü, then Sol(G) =Ø. b) Otherwise, 
if G k G , then G is an admissible goal. Moreover, if . . Sol(G ) then there exists .. Sol(G) with .=. 
[V - (EVar(G) . EVar(G ))]. The following soundness result follows easily from Lemma 3. It ensures that 
computed answers for a goal G are indeed solutions of G. Theorem 1 (Soundness of DNC). If G0 is an initial 
goal and G0 k G1 k ... k Gn, where Gn =.U. S pp, then sS . Sol(G0). Proof. If we repeatedly backwards 
apply c) of Lemma 3, we obtain .. Sol(G0) such that .=sS [V - U0=i=n EVar(Gi)]. By noting that EVar(G0) 
=Ø and Var(G0) n U0=i=n EVar(Gi) =Ø, we conclude .=sS [Var(G0)]. But then, since sS is a total c-substitution, 
sS . Sol(G0). ¸ Completeness of DNC is proved with the help of a well-founded ordering > for admissible 
goals and a result that guarantees that DNC transformations can be chosen to make progress towards the 
computation of a given solution. A similar technique is used in [7] to prove completeness of CLNC, but 
the well-founded ordering there is a simpler one. Definition 5 (Well-founded ordering for admissible 
goals). Let R be a COISS, G =. U. S p P p E an admissible goal for R and Ma witness for .. Sol(G). We 
define: a) A multiset of pairs of natural numbers W (G,.,M) = def {||.||G,. | .. M}, called weight of 
the witness, where for each CRWL-proof .. M, the pair of numbers ||.||G,.. Ù×Ùis: if .=R | CRWL .(t) 
..(R) for (< t,I>. R) . P, then ||.||G,.= def ( |.|OR , |.| ).  if .=R | CRWL .(t) ..(R) for (t . R) 
. P, then ||.||G,.= def ( |.|OR , 1 + |.| ).  if .=R | CRWL .(t) == .(s) for (t == s) . E, then ||.||G,.= 
def ( |.|OR , |.| ).  In all the cases, |.|OR is the number of deduction steps in . which use the CRWL 
deduction rule OR and |.| is the total number of deduction steps in .. b) A multiset of natural numbers 
D(G) = def { |I| | (< t,I>. R) . P }, called weight of the definitional trees of the goal G, where each 
|I| . Ù is the total number of nodes in the tree I. Over triples (G,.,M) such that G is an admissible 
goal for R and M is a witness of .. Sol(G), we define a well-founded ordering (G,.,M) > (G ,. ,M ) .def 
(W (G,.,M), D(G)) >lex (W (G ,. ,M ) , D(G )), where >lex is the lexicographic product of >mul1 and >mul2, 
>mul1 is the multiset order for multisets over Ù×Ù induced by the lexicographic product of >Ù and >Ù, 
and >mul2 is the multiset order for multisets over Ù induced by >Ù. See [6] for definitions of these 
notions. Lemma 4 (Progress Lemma). Assume an admissible goal G for some COISS, which is not in solved 
form, and a given solution .. Sol(G) with witness M. Then: a) There is some DNC transformation applicable 
to G. b) Whatever applicable DNC transformation is chosen, there is some transformation step G k G and 
some solution . . Sol(G ) with a witness M , such that .=. [V - (EVar(G) . EVar(G ))] and (G,.,M) > (G 
,. ,M ). Proof (a). If G =.U. S p P p E is not a solved form, then P or E is not empty. We will proceed 
by assuming gradually that no rule, except one (namely EL), is applicable to G, and then we will conclude 
that this remaining rule EL must be applicable. Note that failure rules cannot be applicable because 
otherwise G would have no solution, due to Lemma 3 a). Assume that DPI, DC, ID, BD and IM are not applicable. 
Then, all the joinability statements in E must be of one of the following two forms: X == Y or X == c(s1,...,sn), 
with an occurrence of a variable R which is both produced and demanded. All the productions in P must 
be of one of the following forms: t . R or <t, I> . R. Now assume that IB and RRA, CS, DI, DN are not 
applicable. Then it must be the case that all the productions in P are of the form t . R with t . CTerm 
or <t, case(p, Z, [I1,...,Ik])>. R with t|pos(Z,p) a produced (and demanded) variable R . Now assume 
that IIM and SA are not applicable. Then, there are no demanded productions in P (otherwise, we could 
find a demanded production of the form mentioned above and a suspension t . R . Since t . CTerm, must 
be d(t1,...,tm) with d . DC, and in this case IIM must be applicable, or f(t1,...,tm) with f . FS, and 
in this case SA must be applicable. Contradiction in both cases). So, all the productions in P must be 
suspensions of the form t . R where t . CTerm and R is not a demanded variable. At this point E must 
be empty, because we had previously concluded that any strict equation in E must demand some produced 
variable. Finally, let R be minimal in the pP + relation (such minimal elements do exist, due to the 
finite number of variables occurring in G and the property CYC of admissible goals). Such R cannot appear 
in any other approximation statement in P, and therefore EL can be applied to the condition t . R where 
R appears. Proof (b). See [20, 19].              ¸ By reiterated application of Lemma 4, 
the following completeness result is easy to prove. The proof reveals that DNC is strongly complete, 
i.e. completeness does not depend on the choice of the transformation rule (among all the applicable 
rules) in the current goal. Theorem 2 (Completeness of DNC). Let R a COISS, G an initial goal and .. 
Sol(G). Then there exists a solved form .U. S pp such that G k* .U. S pp and sS d . [Var(G)]. Proof. 
Thanks to Lemma 4 it is possible to construct a derivation G = G0 k G1 k G2 k ... for which there exist 
.0 =., .1, .2, ... andM0,M1,M2, ...suchthat .i =.i-1 [V -(EVar(Gi-1) . EVar(Gi))], Mi is a witness of 
.i . Sol(Gi) and (Gi,.i,Mi) > (Gi-1,.i-1,Mi-1). Since > is well founded, such a derivation must be finite, 
ending with a solved form Gn =. U. S pp. Since EVar(G0) =Ø and Var(G0) n EVar(Gi) for all i = 1, ..., 
n it is easy to see that .n =. [Var(G)]. Now, if X . Var(G) and there is an equation X t in S, we can 
use the facts .n =. [Var(G)] and .n . Sol(S) to obtain .(X) =.n(X) =.n(t) =.n(sS(X)). It follows that 
.=.n°sS [Var(G)], and thus sS d . [Var(G)].      ¸ Let us now briefly analyze the behaviour of DNC 
computations from the viewpoint of needed narrowing. Obviously, the goal transformation rules for demanded 
productions which deal with ODTs already present in the goal (namely, RRA, CS, DI and DN) lead to performing 
needed narrowing steps. On the other hand, the goal transformation DPI and SA are the only way to introduce 
demanded productions <p, I> . R into the goal. In both cases, R is a demanded variable in the new goal. 
From the definition of demanded variables within Definition 3, it is easily seen that any demanded variable 
always occurs at some position of the goal which is needed in the sense of needed narrowing (viewing 
== as a function symbol, so that the conceptual framework from [5, 3] can be applied). Therefore, DNC 
derivations actually encode needed narrowing derivations in the sense of [5, 3], with an improved treatment 
of == as open strict equality and call-time non-deterministic choice. Regarding the range of applicability 
of DNC, the restriction to the class of COISSs is not a serious one. Using techniques known from [4, 
15, 16] we have proved in [20] that any CRWL-program R can be effectively transformed into a COISS R 
using new auxiliary function symbols, such that for all e . Term. and t . CTerm. in the original signature 
of R one has R | CRWL e . t .R | CRWL e . t. The combination of this transformation techniques with the 
DNC calculus offers a sound and complete narrowing procedure for the whole class of the left-linear constructor-based 
conditional rewrite systems. 6. CONCLUSIONS AND FUTURE WORK We have presented a demand-driven narrowing 
calculus DNC for COISS, a wide class of constructor-based conditional TRSs. We have proved that DNC conserves 
the good properties of needed narrowing [5, 3] while being sound and strongly complete w.r.t. CRWL semantics 
[7], which ensures a call-time choice treatment of non-determinism and an open interpretation of strict 
equality. Because of these results, we believe that DNC contributes to bridge the gap between formally 
defined lazy narrowing calculi and existing languages such as Curry [9] and T.Y [1]. As future work, 
we plan to extend DNC and COISS in other to include more expressive features, such as higher-order rewrite 
rules and constraints. 7. ACKNOWLEDGEMENTS The author is thankful to Mario Rodríguez-Artalejo and Francisco 
J. López-Fraguas for their collaboration, comments and contributions during the first stages of the development 
of this work and for the help in preparing the final version of this paper. 8. REFERENCES <RefA>[1] M. Abengózar-Carneros 
et al. T.Y: a multiparadigm declarative language, version 2.0. Technical report, Dep. SIP, UCM Madrid, 
January 2001. [2] S. Antoy. Definitional trees. In Proc. Int. Conf. on Algebraic and Logic Programming 
(ALP 92), volume 632 of Springer LNCS, pages 143-157, 1992. [3] S. Antoy. Optimal non-deterministic functional 
logic computations. In Proc. of ALP 97, pages 16-30. Springer LNCS 1298, 1997. [4] S. Antoy. Constructor-based 
conditional narrowing. In Proc. PPDP 01, ACM Press, pp. 199-206, 2001. [5] S. Antoy, R. Echahed, M. Hanus. 
A needed narrowing strategy. Journal of the ACM, 47(4):776-822, 2000. [6] F. Baader, T. Nipkow. Term 
Rewriting and All That. Cambridge University Press, 1998. [7] J. C. González-Moreno, F.J.López-Fraguas, 
M.T. Hortalá-González, M. Rodríguez-Artalejo. An approach to declarative programming based on a rewriting 
logic. The Journal of Logic Programming, 40:47-87, 1999. [8] M. Hanus. The integration of functions into 
logic programming: From theory to practice. Journal of Logic Programming, 19&#38;20:583-628, 1994. [9] 
M. Hanus (ed.). Curry: An Integrated Functional Logic Language. Version 0.7.1, June 2000. Available at 
http://www.informatik.uni-kiel.de/curry/report.html. [10] M. Hanus, C. Prehofer. Higher-Order Narrowing 
with Definitional Trees. Journal of Functional Programming, 9(1):33-75, 1999. [11] M. Hanus, S. Lucas, 
A. Middeldorp. Strongly sequential and inductively sequential term rewriting systems. Information Processing 
Letters (Elsevier), vol. 67, nº 1, pp. 1-8, 1998. [12] G. Huet, J. J. Lévy. Computations in orthogonal 
term rewriting systems I, II. In J. L. Lassez and G. Plotkin, editors, Computational Logic: Essays in 
Honour of J. Alan Robinson, pages 395-414 and 415-443. The MIT Press, 1991. [13] H. Hussmann. Nondeterministic 
Algebraic Specification and non confluent term rewriting. Journal of Logic Programming, 12:237-255, 1992. 
[14] T. Ida, K. Nakahara. Leftmost outside-in narrowing calculi. Journal of Functional Programming, 7(2):129-161, 
1997. [15] R. Loogen, F. J. López-Fraguas, M. Rodríguez-Artalejo. A demand driven computation strategy 
for lazy narrowing. In Proc. Int. Symp. on Programming Language Implementation and Logic Programming 
(PLILP 93), volume 714 of Springer LNCS pages 184-200, 1993. [16] F. J. López-Fraguas, J. Sánchez-Hernández. 
Functional logic programming with failure: A set-oriented view. In Proc. LPAR 01, pages 455 469, Springer 
LNAI 2250, 2001. [17] A. Middeldorp. Call by Need Computations to Root-Stable Form. In Proc. POPL 1997, 
ACM Press, 1997. [18] A. Middeldorp, S. Okui. A deterministic lazy narrowing calculus. Journal of Symbolic 
Computation, 25 (6), pp. 733­757, 1998. [19] R. del Vado Vírseda. Estrategias de Estrechamiento Perezoso. 
A Master s Thesis Directed by Dr. M. Rodríguez-Artalejo. Dpto. Sistemas Informáticos y Programación. 
Facultad de CC. Matemáticas, U.C.M. September 2002. [20] R. del Vado Vírseda. A Demand Narrowing with 
Overlapping Definitional Trees. Technical Report SIP 132/03, UCM Madrid, 2003.</RefA>  
			
