
 A Framework for Testing Security Mechanisms for Program-Based Attacks Ben Breech and Lori Pollock Department 
of Computer and Information Sciences University of Delaware Newark, DE 19716 fbreech,pollockg@cis.udel.edu 
 ABSTRACT Program vulnerabilities leave organizations open to mali­ cious attacks that can result in 
severe damage to company .nances, resources, consumer privacy, and data. Engineer­ ing applications 
and systems so that vulnerabilities do not exist would be the best solution, but this strategy may be 
 impractical due to .scal constraints or inadequate knowl­ edge. Therefore, a variety of program and 
system-based solutions have been proposed to deal with vulnerabilities in a manageable way. Unfortunately, 
prop osed strategies are often poorly tested, because current testing techniques fo­ cus on the common 
case whereas vulnerabilities are often exploited by uncommon inputs. In this paper, we present the design 
of a testing framework that enables the e.cient, automatic and systematic testing of security mechanisms 
designed to prevent program-based attacks. The key insight of the framework is that dynamic compilation 
technology allows us to insert and simulate at­ tacks during program execution. Thus, a security mecha­ 
nism can be tested using any program, not only those with known vulnerabilities. 1. INTRODUCTION Program 
vulnerabilities leave organizations open to at­ tacks that can result in severe damage to company .nances, 
 resources, consumer privacy, data, etc. Exposing and identi­ fying security vulnerabilities is notoriously 
di.cult; research e.orts in software testing focus almost exclusively on com­ mon case; i.e., the program 
behavior that users are likely to encounter when they use the program correctly. This approach is not 
conducive to exposing security .aws as vul­ nerabilities are typically found using inputs that users 
would not normally enter. Consider the typical stack smashing at­ tack [1] which seeks to over.ow a 
program bu.er and trick the program into running arbitrary code. Such an attack would require the user 
to enter the binary code for particu­ lar instructions which is improbable at best. Permission to make 
digital or hard copies of all or part of this work for personal or classroom use is granted without fee 
provided that copies are not made or distributed for pro.t or commercial advantage and that copies bear 
this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers 
or to redistribute to lists, requires prior speci.c permission and/or a fee. Software Engineering for 
Secure Systems Building Trustworthy Applica­tions (SESS 05) St. Louis, Missouri, USA The lack of testing 
strategies targeted towards security concerns results in the software community being more re­ active 
than proactive with respect to security vulnerabilities. Software engineers currently have no easy way 
of testing for security problems, thus problems are typically found after the software has been released, 
unfortunately when they can result in large amounts of damage. Once a program's vulner­ ability has 
been discovered, programmers typically modify the code to add a security mechanism tailored to the known 
 vulnerability and that program. The best solution would be to engineer programs so that vulnerabilities 
are not present, but this is not entirely feasi­ ble, primarily because attackers continue to .nd new 
vulner­ abilities. A variety of strategies for preventing vulnerabili­ ties have been proposed (see, 
for instance, [14, 13, 23, 21]) involving all aspects of the program and its execution envi­ ronment. 
These techniques can be broadly termed program­ based as they focus upon the program or its execution 
en­ vironment. Testing of these techniques is often poor. A program with a known vulnerability is found 
and recompiled with a partic­ ular protection scheme. The particular input that exploited the vulnerability 
is then provided to the program to deter­ mine whether the protection mechanism succeeded. This testing 
strategy does not inspire great con.dence in the se­ curity mechanism since it could only be tried on 
a few pro­ grams with one particular input triggering one particular vulnerability. In this paper, we 
present the design of a framework which enables the automatic and systematic testing of various se­ 
curity mechanisms. The key insight is that such mechanisms can be tested without resorting to specially 
designed test cases by utilizing dynamic compiler technology. Dynamic compilers are particularly well 
suited for this problem be­ cause they can enable a user to modify program state and instructions during 
the execution of the program. The broad impact of this framework will be increased con­ .dence in security 
mechanisms developed for program-based vulnerabilities as well as a framework for experimental in­ vestigation 
into new security mechanisms. This paper is organized as follows: section 2 presents necessary background 
on program-based attacks. Section 3 gives the design of our framework, with section 4 showing an example 
of using our framework. Section 5 describes our prototype and preliminary results, while section 6 gives 
an overview of various issues we are currently addressing. Fi­ nally, section 7 presents some concluding 
remarks and work Copyright 2005 ACM 1-59593-114-7/05/05 ...$5.00. 2. PROGRAM-BASED ATTACKS Loosely 
de.ned, program-based attacks are attacks that are maliciously initiated on a program as input. These 
at­ tacks are usually possible because of a vulnerability intro­ duced by a programming .aw. This distinguishes 
the types of attacks, and asso ciated preventative measures that our framework tests from other attacks, 
such as network attacks. over.ow attack wherein an attacker attempts to write past theTheendmostof 
an commonarray (\over.ow"). One program-based ofattack the earliestis the exam-bu.er ples is the Morris 
Worm [22], although there is anecdotal evidence of earlier attacks [11]. Part of the worm attempted 
 to spawn a shell by over.owing a bu.er in thefingerd Unix program. Languages that provide runtime array 
bounds checking will typically throw an exception when an over.ow occurs. The exception can either 
be caught or will terminate the program. In other languages, especially C, writing past the end of 
the array will not necessarily cause program termi­ nation. Instead, other data is overwritten. This 
enables an attacker to write arbitrary values into variables. A favorite target for bu.er over.ow attacks 
is stack al­ located variables. These are variables de.ned locally in a function. Space for them is 
allo cated automatically by the compiler as part of the activation record (AR) of the called function. 
Also included in the activation record are the pa­ rameters passed to the function and the return address, 
i.e., where program control should go when the function ends execution. Figure 1 shows the beginning 
of a function code along with the asso ciated activation record. By convention, call stacks \grow down" 
(i.e., the next AR pushed is at a lower address than the previous AR). When a call is made to function 
 foobar, the caller pushes the parameters, from right to left, 1 onto the stack; followed by the return 
address. The next pushed item is the saved frame pointer (fp). The frame pointer is used to determine 
o.sets to function parame­ ters and local variables. The saved fp is the caller's frame pointer. The 
callee will create its own fp as part of the function initialization. Finally, the function allo cates 
space for the locally de.ned variables, in this case, a 5 character array, buf1, an integer, z, and 
a 20 character array buf2. An access tobuf2[0] throughbuf2[19] would be legit­ imate as there is space 
allo cated on the stack. However, ac­ cessingbuf[20] would not be legitimate. This is a bounds error. 
C does not check array bounds, however, so the ac­ cess is permitted. The actual used value will be 20 
bytes (20 *sizeof(char)) away frombuf2[0]. This address ref­ erences the .rst byte ofz. A value written 
into buf2[20] will overwrite the .rst byte ofz causing mysterious errors. This is an example of a bu.er 
over.ow. We can continue this overwriting. We can overwrite the second byte ofz by writing tobuf2[21]. 
By writing to buf2[24], we can overwrite buf1[0]. Clearly we can place arbitrary values into z and 
alsobuf1. However, there is no reason to stop with overwriting buf1. Data can still be writ­ ten pastbuf1 
and into the saved fp and, .nally, the return address. By modifying the return address, an attacker 
can This is the standard C calling convention. Other languages, such as Pascal and Fortran push parameters 
left to right. int foobar (int a, int b, int c) { char buf1 [5]; int z; char buf2 [20]; ... } Call 
stack grows "down"  Figure 1: Example activation record make program control jump to an arbitrary 
point and exe­ cute instructions. This is the classic stack smashing attack. Many tutorials [1, 15, 
19] exist providing canned implemen­ tations of this kind of attack. Typically, the input used to over.ow 
the bu.er includes code to spawn a shell process (\shell code"). The return address is modi.ed to point 
to the shell code, which is stored on the stack and gets executed when the function returns. Stack 
allo cated variables are not the only target. Attacks exist against variables stored on the heap [10], 
the frame pointer [18], allo cated bu.ers upon the call tofree and even format strings passed to theprintf 
family of functions. The most obvious technique for handling these vulnera­ bilities is to change programming 
practices so that common vulnerabilities are not possible. This can be accomplished by using a language, 
such as Java, that provides array bounds checking, adding bounds checking to the language [17, 3], 
or by auditing the code to .nd potential vulnerabilities and .xing them by using facilities, such as 
string in C++, that allo cate more space as needed, or by carefully using \safe" library functions, 
such as strncpy in C. While this is the pre­ ferred approach, it su.ers from several drawbacks: the per­ 
formance penalty may be signi.cant; the knowledge, experi­ ence and e.ort needed may be .nancially expensive, 
and, most importantly, this approach does nothing for legacy code or for software comp onents for which 
source code is not available. Mechanisms have been proposed to address these concerns [13, 16, 9, 12, 
23, 2], but they are usually aimed at stopping one particular attack. The usual method for testing these 
 protection mechanisms is to .nd programs with known ex­ ploits, add the mechanism to the program, and 
then run the exploit against the program to determine if the mechanism successfully prevented, or detected 
the attack. 3. FRAMEWORK DESIGN Our research is focusing on building a security testing framework for 
applications that will provide automated, gen­ eral support for security testing by allowing engineers 
to sim­ ulate particular attacks and examine how a prop osed strat­ egy protects their software. Furthermore, 
such a framework could allow an engineer to rapidly prototype a possible strat­ egy to handle newly 
discovered vulnerabilities for which no strategy exists as well as attempting new attacks that have 
 not yet been addressed. section 2. In the RAD security mechanism [9], copies of the return address 
are maintained in a special area of memory, a sort of `ghost' stack. When a function is called, the 
return address is put onto both the call stack and the ghost stack. When the function returns, the 
return address is read from the ghost stack instead of the call stack, which overrides damage done 
to the return address by any over.ow. In order to test such a scheme, attacks against the re­ turn address 
must be performed. One method of attack generation would be to attempt to .nd bu.er over.ow vul­ nerabilities 
in a program, construct an exploit, and try it. This is a very time consuming task that, if done success­ 
fully, would eliminate the need for the security mechanisms in the .rst place. Another approach would 
be to modify the compiler to insert attacks. This approach requires the source to the compiler and 
also excellent knowledge of the compiler's source to insert the proper code. This can be too costly 
as di.erent attacks require di.erent modi.cations to the compiler. The key insight for the framework 
is that it exploits the technology of dynamic compilation which has typically been used to optimize 
a compiled program as it executes. With the capability to monitor and compile on-the-.y, we foresee 
 other uses for this technology, including the framework for security testing. By using a dynamic compiler, 
attacks could be inserted dynamically, without modifying the source code or binary stored on disk. 
Binary rewriting tools, such as DynInst [8], might also be used, although we feel that the dynamic 
compiler approach a.ords an easier implementa­ tion. Furthermore, this approach requires no modi.cation 
 to the static compiler, and engineers need not audit code bases looking for possible vulnerabilities. 
Figure 2 shows the phases in a dynamic compiler. We stress that these phases are performed entirely 
at runtime. The input to the compiler is usually an intermediate pro­ gram created by a static compiler, 
although compiling the source code on the .y is possible (usually in interpreters). If source code 
is being compiled, it is done on an on-demand basis, i.e., functionfoo will be compiled whenfoo is .rst 
 called. When execution .rst begins, the dynamic compiler per­ forms any necessary source compilation. 
Sequences of in­ structions, called basic blocks, are constructed. A basic block is a contiguous sequence 
of instructions that would be executed sequentially by the CPU. A basic block can be optimized or analyzed 
online (during execution) and then given to the CPU for execution. The process of dynamic translation, 
basic block construction, online optimization and analysis and then execution keeps repeating until 
the program terminates. Within the testing framework, the RAD scheme would be tested by compiling the 
ghost stack code into the original application and then running the modi.ed code with the standard 
test cases through a dynamic compiler. The engi­ neer can instruct the framework to modify return addresses 
 of any or all functions; this allows the ghost stack idea to be tested in the general case rather than 
in speci.c instances. As the program executes, the framework would monitor the execution to determine 
how many attacks were made and how many were defeated. When the program is .nished, the engineer would 
be provided with a coverage report de­ tailing the methods executed by the test case, success rates 
of the program that are still vulnerable. Thus far, we have discussed only the stack smashing at­ tack. 
We will continue to use stack smashing as an example throughout the rest of the paper. However, we note 
that the framework is not limited to simulating only stack smash­ ing attacks. The framework should 
also be able to simu­ late other attacks, such as those against function pointers. In general, we expect 
any attack that can be simulated by adding or modifying executable instructions to be handled. Attacks 
involving subtle data manipulations, such as the for­ mat string attacks againstprintf [20], may pose 
a problem for our framework. The requirements we set for such a framework include 1. Generality { The 
framework must support a variety of source languages, di.erent kinds of vulnerabilities and must be 
able to test a wide variety of program-based security mechanisms. 2. Systematic testing { The framework 
must be able to insert attacks at any appropriate point in the program. This allows for more thorough 
and systematic testing of program-based security mechanisms. 3. Automatic { A user should only need 
to specify the kinds of attacks that should be attempted and have the option of specifying the program 
points to be attacked. After that, the framework should perform all its tasks automatically without 
need for user intervention. 4. Robustness { The framework should report the places where the mechanism 
failed to protect the program while reporting few false positives. In our case, a false positive would 
occur if the framework reported the mechanism under test successfully protected the program where it 
actually did not. 5. Low overhead { The framework must have reasonable overhead, in terms of both space 
and time to be con­ sidered practical. Framework Architecture. Figure 3 shows a diagram of the prop 
osed framework. The key comp onents of the frame­ work are modules within a dynamic compiler. During 
ex­ ecution, the dynamic compiler gives the instructions that are about to be executed to each module 
for modi.cation or analysis. The comp onents are: . Attack Generator { Resp onsible for producing and 
in­ serting the attacks. The attacks may modify program instructions or program state. . Execution Monitor 
{ Gathers information about the program's execution as instructions are executed. These instructions 
could have been modi.ed by the attack generator. . Oracle { Determines if the actual program behavior 
 deviates from the expected behavior under the speci­ .ed security policy. Each of those comp onents 
has inputs that are read upon the initialization of the framework. The inputs describe the speci.c 
actions that each comp onent should perform. The inputs are:  Figure 2: Dynamic Compilation Phases 
  Framework Inputs Framework Outputs  Figure 3: Prop osed security framework 4 should be attempted, 
perhaps a change to return ad­ dresses or return values. . Security Policy { Describes the proper behavior 
of the program e.g., calls that the program is or is not allowed to make. . Monitoring Speci.cation 
{ Describes behavior that should be checked, such as a particular function being called that indicates 
the attack was successful. The monitor­ ing speci.cation is dependent on the attack speci.ca­ tion and 
security policy. There are two outputs produced by the comp onents of the testing framework: . Vulnerability 
Report { Describes the attacks that were  successful, or the tests that failed. . Coverage Report { 
Details the possible attack loca­  tions that were checked by the test suite. The cover­ age report 
is derived from coverage analysis and static analysis tools in conjunction with the execution mon­ itor's 
output. The other comp onents of the framework deal with aspects of the software maintenance cycle. 
The vulnerability report along with the security policy may dictate that changes be made to either 
the program or the selected security mech­ anism. Other maintenance requirements may also dictate that 
program changes be made. These changes also must be tested. The test cases and attacks that should be 
re-run are selected during the regression testing phase. 4. THE TESTING PROCESS As an example of testing 
a security mechanism within the framework, we consider the RAD example discussed earlier. We can test 
RAD by compiling it into any program that is convenient. That program is then run through a dynamic 
 compiler with the framework modules loaded to test the mechanism. The program is run with a typical 
test case selected either by hand or by the test case selector. We note that the test case may be one 
that would normally be used in the testing phase. It does not need to be a case that attempts to exploit 
any vulnerability. Upon starting up, the framework modules would read their particular inputs. Since 
RAD is designed to protect against the stack smashing technique, the attack speci.ca­ tion would describe 
attacking the return addresses of a set of functions (perhaps the functions de.ned in the program, 
or all functions including those in libraries). The monitoring speci.cation describes simply examining 
function returns. During execution, the dynamic compiler starts creating basic blocks and hands them 
to the attack generator. The attack generator can examine each block to determine if it is the start 
of a function that is protected by the RAD mechanism, and thus, should be attacked. If so, code can 
 be added to the start of the function to change the return address, thus simulating the e.ects of a 
bu.er over.ow at­ tack. The monitor then examines the code. In this case, the monitor would record how 
many times return addresses were adjusted, the return instructions that were executed and the di.erent 
return addresses that were used. The in­ formation on how many return addresses were modi.ed and to 
the coverage analyzer after the program has terminated. The information on what return addresses were 
used can be passed to the oracle, which then decides if an attack suc­ ceeded. The entire process continues 
until the program terminates. Upon termination, the coverage and vulnerability reports are written. 
Based on these reports, the e.ectiveness of the RAD technique in preventing stack smashing attacks can 
be determined. 5. PROTOTYPE IMPLEMENTATION We have started building a prototype of the framework. 
The DynamoRIO [6] dynamic compiler, which we have used for other work [4, 5], is the keystone of the 
framework. Fig­ ure 4 shows a simpli.ed overview of DynamoRIO (readers interested in more details of 
the construction and underlying architecture of DynamoRIO should see [7]). Native Binary Code  Initialization 
 Analysis/Optimization Cleanup and Exit  Client Module Figure 4: Simpli.ed Overview of DynamoRIO 
DynamoRIO is a native dynamic compiler that accepts statically compiled binaries as input. Thus, using 
DynamoRIO enables any compiled language to be used with the prototype testing framework. Additionally, 
DynamoRIO allows a user to write a client module to analyze or change instructions online. This capability 
provides a layer of abstraction to a user, enabling one to perform online analysis without modi­ .cation 
to the DynamoRIO compiler itself. Thus, knowledge of the inner workings of the compiler is not required. 
Upon startup, DynamoRIO initializes itself and then makes a call to the client module telling the client 
to initialize it­ self. DynamoRIO then begins executing code by building basic blocks from the program 
instructions. A basic block is simply a contiguous sequence of instructions that will be executed by 
the CPU. Each basic block is then passed to the client module for analysis or other adjustments. The 
block is returned to DynamoRIO, which passes the block to the the client module's cleanup routine and 
then exits. The testing framework's key comp onents can be imple­ mented as a DynamoRIO module. Upon 
initialization, the framework inputs are read. During execution, the basic blocks are examined, and 
attacks can be inserted as desired. Additionally, the monitor can examine the blocks looking for the 
appropriate information. Finally, at exit, the framework writes the desired output reports. The attack 
generator is currently in the early stages of implementation. Using DynamoRIO, we have successfully 
 been able to simulate attacks against the return addresses in several test programs. This was done 
by writing a Dy­ namoRIO module that determined when a particular func­ tion was called. Code was then 
added to modify the return address of a test function,foo, simulating the results of a stack smashing 
technique. The return address of the func­ tionfoo was changed to be another function,bar, already in 
the test program. Upon return,foo jumped tobar. Thus a successful attack was carried out. 6. ISSUES 
We acknowledge that there are several outstanding issues that we are currently addressing. 1. Simulation 
of attacks. We are using a dynamic com­ piler to simulate attacks by modifying existing code or by adding 
new code into the running program. A drawback to this approach may be that the generated attacks may 
not perfectly mimic existing attacks. For example, a dynamic compiler can insert code into a function 
to change the return address, which simulates the end result of a stack smashing attack. However, an 
actual bu.er over.ow will overwrite everything be­ tween the start of the bu.er and the return address. 
Mechanisms, such as StackGuard [13], that rely upon this behavior may fail in the simulation. The solu­ 
tion to this issue remains to be investigated. It can be argued that the simulated attack is more subtle 
and mechanisms should be able to guard against the simu­ lation (in the case of StackGuard, this would 
represent a case where the canary value was correctly determined by an attacker). Alternatively, the 
injected code could overwrite values between ranges, though this may be expensive to do. 2. E.ciency. 
In order to be practical, the framework must have minimal overhead. The attack generator and monitor 
examine instructions during their execu­ tion. If the overhead is too large, the performance penalty 
will make the framework almost useless. 3. Monitoring Information. The monitor is resp onsible for 
extracting information about the execution of the program during runtime. Its goal is to determine cov­ 
erage information and to give the oracle enough infor­ mation to determine if an attack was successful. 
 In the case of stack smashing attacks, one possibility is for the framework to attack the program in 
such a way that a function is called completely out of order (e.g. for functionQ to call functionZ even 
though no code exists inQ to cause that call). The monitor could oracle would then verify. 4. Goals for 
the Attack Generator, Monitor and Oracle. At this preliminary stage, there are two goals for the design 
of the attack generator, monitor and oracle: (1) no extra code should have to be compiled into the bi­ 
nary and (2) the program should not be terminated after the .rst successful attack. The .rst goal follows 
from the desire to have the framework perform its du­ ties at any stage of the development cycle. This 
implies that a program binary potentially could be shipped to customers once it has passed the .nal tests 
performed by the framework. Furthermore, the framework could be applied to binaries that customers are 
actually us­ ing rather than trying to simulate the same conditions on a development workstation. Both 
of these ideas are compromised if the framework requires code to be compiled into the binary. The second 
goal is for the framework to keep perform­ ing even after a successful attack. The motivation is that 
to get a sense of how well a particular mechanism is protecting a program, all possible attack points 
must be examined. Killing the program early does not allow for this examination. The framework cannot 
simply jump to theexit() system call as part of a successful attack. 5. Automatically specifying attacks. 
Finally, issues re­ garding automatically specifying the attacks will be explored. It is simply unreasonable 
to expect a soft­ ware engineer to devise code for the attack genera­ tor. Instead, a method allowing 
an engineer to provide some meta data about an attack, while the attack gen­ erator handles the details 
will be developed.  7. CONCLUSIONS AND FUTURE WORK We have presented the design of a framework allowing 
the testing of security mechanisms for program-based attacks. Such a framework would allow for the 
more e.cient testing of these mechanisms, without resorting to complex method­ ologies. The key insight 
of the framework is that dynamic compilation technology allows us to insert and simulate at­ tacks during 
program execution. Implementation work has begun on the framework itself, starting with the attack generator. 
Several simple attacks have been implemented on small test programs. These at­ tacks need to be expanded 
in a general fashion to work with all programs. Research into the monitor and oracle will also performed, 
in particular, investing what information is needed to determine successful attacks and coverage infor­ 
mation. 8. REFERENCES <RefA>[1] AlephOne. Smashing the stack for fun and pro.t. http://www.insecure.org/stf/smashstack.txt 
. [2] A. Baratloo, N. Singh, and T. Tsai. Transparent run-time defense against stack smashing attacks. 
 USENIX Annual Technical Conference, 2000. . [3] R. Bod ik, R. Gupta, and V. Sarkar. ABCD: Eliminating 
array bounds checks on demand. Programming Language Design and Implementation, 2000. [4] B. Breech, 
A. Danalis, S. Shindo, and L. Pollock. Information Assurance Workshop, 2004. Online impact analysis 
via dynamic compilation technology. International Conference on Software Maintanence, 2004. [5] B. Breech, 
M. Tegtmeyer, and L. Pollock. A comparison of online and dynamic impact analysis algorithms. European 
Conference on Software Maintenance and Reengineering, 2005. [6] D. Bruening, T. Garnett, and S. Amarasinghe. 
An infrastructure for adaptive dynamic optimization. In International Symposium on Code Generation and 
Optimization, 2003. [7] D. L. Bruening. E.cient, Transparent, and Comprehensive Runtime Code Manipulation. 
PhD thesis, M.I.T., 2004. [8] B. Buck and J. K. Hollingsworth. An API fro runtime code patching. Journal 
of Supercomputing Applications and High Performance Computing, 2000. [9] T. Chiueh and F. Hsu. RAD: A 
compile-time solution to bu.er over.ow attacks. International Conference on Distributed Computing Systems, 
2001. [10] M. Conover. w00w00 on heap over.ows. http: //www.w00w00.org/files/articles/heaptut.txt . [11] 
C. Cowan. Re: Bu.er over.ow and the OS/390. http://cert.uni-stuttgart.de/archive/bugtraq/ 1999/02/msg00081.html, 
1999. [12] C. Cowan, S. Beattie, J. Johansen, and P. Wagle. PointGuard: Protecting pointers from bu.er 
over.ow vulnerabilities. USENIX Security Symposium, 2003. [13] C. Cowan, C. Pu, D. Maier, J. Walpole, 
P. Bakke, S. Beattie, A. Grier, P. Wagle, Q. Zhang, and H. Hinton. StackGuard: Automatic adaptive detection 
and prevention of bu.er-over.ow attacks. USENIX Security Symposium, 1998. [14] S. Designer. NonExecutable 
user stack. http://www.openwall.com/linux . [15] DilDog. The tao of windows bu.er over.ow. http: //www.cultdeadcow.com/c{D}c_files/c{D}c-351 
. [16] H. Etoh and K. Yoda. GCC extension for protecting applications from stack-smashing attacks. http://www.research.ibm.com/trl/projects/ 
security/ssp/, 2000. [17] R. W. M. Jones and P. H. J. Kelly. Backwards-compatible bounds checking for 
arrays and pointers in C programs. Automatic and Algorithm Debugging, 1997. [18] Klog. Frame pointer 
overwrite. http://www.phrack.org/show.php.p.55&#38;a.8 . [19] Mudge. How to write bu.er over.ows. http://www.insecure.org/stf/mudge_buffer_ 
overflow_tutorial.html, 1995. [20] T. Newsham. Format string attacks. http://www. lava.net/~newsham/format-string-attacks.pdf 
. [21] R. Sekar, C. R. Ramakrishnan, I. V. Ramakrishnan, and S. A. Smolka. Model-carrying code (MCC): 
A new paradigm for mobile-code security. New Security Paradigms Workshop, 2001. [22] E. H. Spa.ord. The 
Internet worm program: An analysis. Computer Communication Review, 1988. [23] G. Zhu and A. Tyagi. Protection 
against indirect over.ow attacks on pointers. International 
</RefA>			
