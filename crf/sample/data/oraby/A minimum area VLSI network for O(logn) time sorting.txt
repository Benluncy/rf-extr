
 A MINIMUM AREA VLSI NETWORK FOR O(LOGN) TIME SORTING EXTENDED ABSTRACT G. Bilardi and F. P. Preparata 
Coordinated Science Laboratory University of Illinois at Urbana-Champaign Urbana, Illinois 61801 USA 
 Summary A generalization of a known class of parallel sorting algorithms is presented, together with 
a new interconnection to execute them. A VLSI implementation is also proposed, and its area-time performance 
is discussed. It is shqwn that an algorithm in the class is executable in O(logn) time by a chip occupying 
O(n-) area. The design is a typical instance of a "hybrid architecture", resulting from the combination 
of well-known VLSI networks as the orthogonal trees and the cube- connected-cycles; it also provably 
meets the AT 2 = ~(n21og2n) lower bound for sorters of n words of length (l+s)logn(e > 0). i. Introduction 
 Any VLSI sorter of n terms, with wordlength q = (l+c)logn, e > O, must satisfy the relationship AT 2 
 = ~(n21og2n), since it must support a flow of = ~(nlogn) bits through a suitable bisection, and AT 2 
 = ~(2). This lower bound holds in a suitable VLSI model of computation whose basic assumptions are that 
the chip is synchronous (transmission time is independent of wire length) and semellective- unilocal 
(input data are read only once, at pre- specified input ports). Originally proved by Thompson [2] under 
the word-local restriction [i] for the input format (all the bits of the same word enter the circuit 
at the same point), the lower bound has recently been extended to nonword- local designs by F. T. Leighton 
[14]. In a previous paper [3] we have shown that AT 2 optimal VLSI sorters can indeed be constructed 
for all computations times T E [~(log3n),O( n~ogn)]. In this paper we concentrate on "very fast" sorting, 
i.e., the class of VLSI sorting Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1984 ACM 0-8979i-133-4184/004/0064 $00.75 algorithms whose running time 
is T = B(logn). So far only one VLSI design is known to achieve e(logn) computation time: it is based 
on the or- thogonal-trees architecture [5],[6] and implements an algorithm due to Muller and Preparata 
[7]. (1) The optimal layout of the orthogonal trees has area A = O(n21og2n) [6], while the lower bound 
 yields A = ~(n 2) for T = O(logn). On the other hand, a closer analysis of the algorithm shows that 
the information flow ~ is O(nlogn), so that the gap between upper and lower bounds is not due to a gap 
between actual flow and a flow-based lower bound, but rather to the fact that the length of the layout 
bisection of the orthogonal trees is O(logn) times as large as the graph bisection. We will show in 
this paper that not only the lower bound on the flow, but also the one on the AT 2 measure is tight, 
by exhibiting a new net- work capable of sorting in A = O(n 2) and time T = O(logn). The rather complex 
network is a typical in- stance of "hybrid architecture", resulting from the careful interplay of more 
standard VLSI networks, as the cube-connected-cycles machine, the mesh-connected machine, and the binary-tree 
machine. The implemented algorithm is of the type first introduced by Preparata [8], although the recursion 
strategy has been modified to optimize the network area. We also introduce a new hybrid architecture, 
called the mesh- of-CCCs, which has very interest- ing computational features. The cascade of one O(logn) 
sorter and one mesh-of-CCCs of proper size will allow us to construct an AT2-optimal sorter for any 
computation time T E [~(logn),O(log3n)] Thus we are able to conclude that optimal AT 2 = e(n21og2n) 
sorting is achievable in the (l/Subsequent~ to the research leading to this paper, we learned of the 
construction of Aitai, Komlos, and Szemeredi [13], which also achieves e(logn) time; in addition we 
have devised a VLSI implementation of their scheme also achieving AT 2 = B(n21og2n) [15]. 64  entire 
"meaningful" range of computation times T E [~(logn),O( nl~o~)]. (Simple fan-in arguments show that ~(logn) 
is a lower bound for the compu- tation time, and A = ~ (nlogn) is a consequence of the semellective assumption 
[14], so that compu- tation times slower than 8(n~ogn) cannot result in smaller area.) 2. A Class of 
Parallel Sorting Algorithms  (mi,ti_I)-COM~INER, i < i < d, performs the combi- nation of m.1 (sorted) 
sequences of length ti_l; A here t O = i and ti_ I = mlm2...mi_ I for i > i. Note that each level of 
the tree corresponds to a stage of the combination scheme, and that there are n. = n/t. nodes at level 
i, i < i < d. 1 l  Several sorting algorithms can be viewed as particular cases of a rather general 
scheme, which we now describe. We call COMBINATION the operation that produces from m sorted sequences, 
of t elements each, one sorted sequence of mt elements. A net- work implementing this operation is called 
an (m,t)-COMBINER. When m = 2, COMBINATION reduces to conventional merging. A parallel algorithm for 
the (m,t)-COMBINER has been introduced in [8], and is based on the following idea. (2) The m input sequences 
 S0,...,Sm_ I are pairwise merged to compute for each i,j 6 {0,i .....m-l}, and each £ 6 {0,i ..... 
t-l}, the number C°.(£) of elements of sequence S. that 13 3 are less than the £-th element of sequence 
S.. 1 The integer Cij(£) is readily obtained as the difference of the ranks of this element in the 
 merge of S. and S. and in S.. By summing the l 3 1 Cij(~)'s over j we then obtain the rank of the £-th 
 element of S i in the output sequence of the COMBINER: thus, to complete the operation, we simply need 
to store each element in the position specified by its rank. The primitive operation of the scheme 
-- the merging of two sequences --can be done, for example, by means of Batcher's bitonic merger [4]. 
 Given n = mlm2...m d elements, we can sort them  in d stages according to the following scheme that 
 we call COMBINE-SORT. At stage i we perform n/m I combination opera-  tions, each on m I sequences 
of i element each. At stage 2 we perform n/mlm 2 combinations, each on m 2 sequences of m I elements 
each, and at stage i we perform n/ml'''m'1 combinations, each on m.1 sequences of length ml...mi_ I. 
Finally, at stage d we combine m d sequences of length n/m d into one sequence of length n, which is 
the output of the COMBINE-SORT scheme. A diagrammatic illustration of the scheme is given in Figure 
i in the form of a rooted tree. Each node of this tree is a suitable combiner. An (2)A COMBINATION algorithm 
based on k-way merging has been recently proposed by F. T. Leighton [14], for several interesting applications, 
including optimal VLSI sorting. n l mIll It Figure i. Diagram of the COMBINE-SORT scheme. Several 
known sorting algorithms, such as MERGE-SORT and various forms of ENUMERATION SORT [7,8], can be cast 
in the COMBINE-SORT scheme. Each algorithm is characterized by a particular factorization of n = ml...m 
d (note that the order of the factors is relevant here), and by the specification of how the combination 
is to be performed. In this paper we shall explore new significant choices of d and ml,m2,...,m d that 
 minimize the complexity of a VLSI implementation of COMBINE-SORT. 3. An (m,t)-COMBINER Network  In 
this section we propose a parallel network for an (m,t)-COMBINER, where m = 2 ~ and t = 2 T are powers 
of two. This network will accept as input m sorted sequences of t elements each, S i = (si(0),si(1) 
..... s.(t-l))l i = 0,i .....m-i and produce as output a single sorted sequence S, which is the combination 
of S0,...,Sm_ I, and has N = mt ~ 2 ~ elements, S = (s(0),s(1) ..... s(N-l)).  The (m,t)-COMBINER 
will execute the algorithm based on pairwise merging as outlined in the pre- ceding section. It consists 
of m 2 modules (each capable of merging two sequences of length t and of computing partial ranks), 
laid out as a square m × m mesh and indexed as M.. (i,j =0,1,...,m-l). lJ  65 The modules of each 
row are interconnected as the leaves of a binary tree of bandwidth t; so are the modules of each column. 
Thug, the combiner has the structure of an orthogonal-trees machine [5,6], whose leaves are merging modules. 
As is typical of the orthogonal-trees machine used for sorting, the interconnecting trees broadcast a 
sequence to all leaves, compute global ranks from partial ranks, and route the elements according to 
their ranks. We shall now describe in some detail the merging modules and the interconnecting trees. 
  3.1. Merging Modules. Merging module M.. lj merges sequences S. and S° and computes Cij(~) for = 
0..... t-l. ~ J  Each module is realized (Figure 2) as a cube ~- connected-cycle (CCC) interconnection 
of smaller processing elements, called micromodules (each micromodule has a bandwidth of i bit). Specifically, 
 RT-i~es CT-llnes I First sorted sequemca Second sorted ~equence Figure 2. Merging unit Mij realized 
by a (3,23) - CCC, used to merge two sequences with four elements each. the merging module is a (T+i,2T+I)-ccc 
(i.e., it has 2 T+I cycles each of length T+I). We number the micromodules of M.. as M..(h,k), with 
0 <h<T+l lJ ij and 0 < k < 2 T+l, so that the merging module may be thought of as a (T+i) x 2 T+I array 
(rows are numbered from bottom to top, columns from left to right). The columns of this array are connected 
as cycles with a link between Mij(h,k) and Mij(h,(k+l)mod(T+l)). The rows 0,I ..... are  respectively 
associated with the dimensions E0,E I .... ,E T of a (T+l)-dimensional binary cube [9], and there is 
a link between Mij(h,k I) and Mij(h,k 2) if and only if the binary expansions of k I and k 2 differ exactly 
in the coefficient of 2 h. It is well known [i0] that the CCC is an efficient emulator of the binary 
cube interconnec- tion, and the latter is naturally suited to execute a wide class of algorithms, including 
bitonic sorting. The reader is referred to [I0] for a detailed explanation; he must be warned, however, 
that in the present application the CCC is not used at its full capability, since we deploy a network 
with 2t(log2t) (rather than 2t) micro- modules to merge two sequences of length t. In other words, a 
2 T+I binary cube is emulated by a (T+i,2T+i)-ccc. This is done by reducing the bandwidth of the CCC 
connection from q (the word- length) to I, thereby achieving bit-serial trans- mission. Thus the pipelining 
through the modules of a given dimension concerns the different bits of a word, rather than different 
words of a sequence. (Note that T+I need not be a power of 2. See Figure 2.) Recalling from [I0] that 
a CCC with N processing elements of constant area can be laid out in area O(N2/log2N), we conclude that 
a merging module can be laid out in area O(A0t2), where A 0 is the constant area of the micromodule. 
 3.2. Interconnectin$ Trees. As indicated earlier, the merging modules are interconnected by two families 
of N = mt full binary trees, each with m = 2~ leaves and bandwidth i. We will refer to these families 
as the row trees and column trees. The lines of the row trees and the column trees are respectively 
labelled RT.(£) and CT.(~), l l i = 0 .... ,m-l; £ = 0..... t-l. The leaves of RT°(~) i are,from left 
to right, connected to the CCC micro- modules Mio(O,£),Mil(O,~ ) .... ,Mi,m_l(O,£); the leaves of CT.(~) 
are connected to the CCC micromod- J ules M0~ (0, t-l+%) ,Mij (0, t-l+~) ..... Ms_ I ,j (0, t-l+~). 
4. The COMBINATION Algorithm We now describe how the sorting algorithm of [8], based on pairwise merging, 
can be executed on the network introduced earlier. This analysis will elucidat e the structure of the 
CCC micromodules. We recall that the inputs are m = 2 ~ sorted se- quences of t = 2 T elements each, 
with N = 2 ~ = mt. For convenience we split the algorithm into several phases. (A) Input of Data and 
Broadcasting to Merging Modules. Element s.(~) is input at the l root of tree RTi(~), and is then broadcast 
to all leaves of the tree. At this point, the left half of row(O) in module M.. contains the sequence 
S.. i] i To fill the right halves of row(0) of all modules, we proceed as follows. First, in each "diagonal" 
module Mii the sequence S i is copied in the second half of row(0). (This can be done by using the connection 
of row(r) between the left and the right half of the machine.) Next, from micromodule M..(0,t-l+~), which 
is a leaf of CT.(~), element JJ J  66 s.(£) is broadcast (through the root) to all the J other leaves 
of the same tree. At this point, the merging module Mij contains S i and S. in the O-th J row and merging 
can begin. (B) Merging and Rank Computation. Merging can be executed by resorting to the bitonic algo- 
rithm, which complies with the DESCEND paradigm of the binary cube (see [i0]). It is not diffi- cult 
to program the CCC to emulate a pipelined merging network (with serial comparison) in time of O(T+q), 
where q is the length of the input words. At the end of merging, the sorted se- quence resides in row(0) 
of the CCC~ i.e., the element in M..(0,~), 0 < ~ < 2t-l, has rank % in ij MERGE(Si,Sj). To transmit 
the ranks of s.(O),...,l si(t-l) to processors Mij(0,0) ..... Mij(0,t-l), respectively, the path traversed 
by each element si(J) is retraced backwards: This is easily done with an ASCEND algorithm if each M..(~,k) 
keeps ij track of whether it exchanged or not the operands during the merging process. At the end of 
this phase, processor Mij(0,~), 0 < ~ < t-l, stores the number of elements in MERGE(Si,Sj) that are 
less than s.(~). If from this number we subtract i we obtain C..(~), number of elements of S. which 
 J J are less than si(~). We call the Cij .'s partial ranks (stored at the leaves of row trees). The 
row trees can now be used in a straight- forward manner [6] to compute the total ranks Ci(~) of si(~) 
in time O(B+T), where ~ = logm is the depth of the tree and (T+i) is the number of bits of the ranks. 
 (C) Output of the Sorted Sequence. Our  objective is to output element s(j2T+~) from the root of tree 
CT.(~). Consider element s.(h) with j i rank C.(h), h = j2T+~. The binary spellings of i the integers 
j and ~ are the ~ most significant bits and the r least significant bits of C.(h), i respectively. Thus, 
as a first step, we "acti- vate" in M.. the elements of sequence S. that ij l have to emerge from trees 
CT.'s, and "inhibit" J all other elements. (The active elements are those whose rank C.(h) agrees in 
the ~ most significant bits with the column number j of the merging module.) Next, we rearrange the 
active elements in M.. so that s.(h) is sent to M..(O,%), with ~ = C.(h)mod t. This operation is essentially 
a permutation of the active (and nonactive) elements, and can be done by using the CCC as an emulator 
of the Benes network. The setting of the switches, although nontrivial, is greatly simplified with respect 
to the general case by the fact that the active elements do not change their relative order. The desired 
rearrangement can be done by using the ideas of concentration introduced in [ii], and expansion, which 
could be viewed as the inverse of concentration. If k elements are active in a given module, they are 
first sent to the k left- most columns of the CCC (concentration), and then routed to the destination 
columns (expansion). A straightforward adaptation of the algorithm that is proposed in [ii] for concentration 
in the cube- machine shows that an ASCEND and a DESCEND phase is all that is required to rearrange data 
on our CCC. Some bits required to set the switches must be precomputed. This task could be performed 
by the CCC, or (to keep the micromodule structure as simple as possible), the task can be assigned to 
a binary tree of full adders whose leaves would be contained in the interface between the CCC and the 
row trees. During the entire rearrangement task, compu- tation takes place only in the left-half of 
the CCC without using dimension E . We then transfer T each active element from Mij (0,~) to Mij (0,t-l+~), 
 with a straightforward use of dimension E . T  At this point element s(j2T+~) is in M..(0,t-l+~), 
(where the value of i is determined ij by the input sequence to which s(j2T+~) originally belongs), 
and is ready to be transmitted to the root of CT.(~) where it is output. J  4.1. Performance Analysis 
and Modification Of the Network. Since both the CCCs and the interconnecting trees work in pipeline in 
bit- serial mode, any operation takes time proportional to the sum of the operand length and the pipe 
depth. For the CCC, the depth is T+I and the operand length is either q (input words) or T+i (partial 
ranks). Since a constant number of ASCEND and DESCEND algorithms are executed, we conclude that O(T+q) 
total time is spent in the CCCs. For the trees the depth is ~+I, and the operand length is either q (input 
words) or T+B (total ranks). Since a constant number of fan-in and fan-out algorithms are executed, 
we conclude that O(T+~+q) total time is spent in the trees. Thus the time spent in the interconnecting 
trees dominates that spent in the CCCs. Recalling that a full binary tree on m aligned leaves is laid 
out in area e(mlogm) and that there are t row and column trees, we conclude Lemma i. A full-tree (2~,2T)-COMBINER 
of words of length q can be laid out in a square of width 0(~2 (T+~})" and operates in time T = O(T+~+q). 
 We now observe that when q = ~(2~), then T = O(~+q). In this case the time performance of the trees 
is insignificantly degraded if we real- ize them as comb-trees, rather than as full binary trees. The 
depth increases from ~ to 2 ~ (which is tolerable in time since 2 ~ = O(q)), but the layout area decreases 
by a factor O(~2). We conclude: Lemma 2. A comb-tree (2~,2~)-COMBINER of words of length q = ~(2 B) 
can be laid out in a square of width 0(2 (T+~)) and operates in time T = O(~+q). 67 5. A Network for 
COMBINATION-SORT The COMBINER can be used to construct a general network for COMBINATION-SORT. As an 
inter- mediate step in the construction, we introduce a new operation called COALESCENCE. Given a collec- 
tion of n elements, partitioned into n/ti_ I sorted subsequences each containing ti_ I elements, and 
given a multiple t i of ti_ I, which is also a divisor of n, we call (n;ti_i:ti)COALESCENCE the operation 
of combining (in the sense defined earlier) consecutive blocks of m i = ti/ti_ I subsequences. If we 
refer to the tree of Figure l, we can easily see that each level of the tree corresponds to a coalescence 
of the input sequence. If we call COALESCER a network that performs a coalesence, we can build a COMBINATION-SORTER 
by cascading a suitable set of coalescers, as shown in Figure 3.  (n;l:ml) I COALESCER (n;ml:mlm2) 
1 COALESCER | ! ; m  l(n;ml-.-md_2:ml"" d_l ) I COALESCER (n;mi'''md-I:n)COALESCER I Figure 3. 
COMBINATION-SORTER as a cascade of COALESCERS.   5.1. The COALESCER. An (n;ti_i:ti)-COALESCER can 
be easily constructed by using n i = n/t i (mi,ti_i)-COMBINERS. Let us assume, for simplicity, that 
n. is a perfect square. We can then lay out the combiners in a ~ x n~. array with input and l i output 
lines running in a chosen direction, say, parallel to the rows. TO estimate the area of the COALESCER, 
we first assume to use full-tree COMBINERS, so that the side of the COMBINER has a length of O(tilogm 
i) (parallel to the rows). Using Lemma i we have l°gmi) Height = O( n~. tilogmi+niti)~ =O(n(l + ), 
 i l°gmi) Width = O( n~ =O(n tilogmi)m  68 The computation time is readily found as = O(~+q+logmi). 
We conclude T F Lemma 3. An (n;ti_l:ti) full-tree COALESCER can be laid out in a rectangle O(n(l+logmi/n~) 
× )~ O(nlogmi/n~i) and operates in time T = O(T+q+logmi) (q is the input wordlength, n i = n/ti, m 
i= ti/ti_l). When q = 9(logn), then T = O(logn). Similarly, Lemma 2 yields the following result: Lemma 
4. An (n;ti_l:ti) comb-tree COALESCER can be laid out in a rectangle O(n) × O(nlogm./n~.) l i and operates 
in time T C = O(~+q+mi). If both q and m i are O(logn), then T C = O(logn). 5.2. An Optimal VLSI Sorter. 
We now show that there is a COMBINATION-SORTER for words of length q = e(logn) that sorts n elements 
in time T = O(logn) and area A = O(n2), thus achieving the known lower bound for this problem. The sorter 
we propose is given by the block diagram in Figure 4. By the previous Lemmas 2 and 3 we see  (n;l : 
n/log2n) COALESCER full-tree (n;n/log-n : n/lo~) COALESCER  full-tree I ' 1 (n;n/logn : n) COALESCFER 
 comb-tree i Figure 4. A CO~INATION-SORTER with three COALESCERS, for optimal VLSI sorting. that the 
coalescers take area (width × height) O(n) × O(n), O(nloglogn/ logn) × O(n), and O(n) × O(n) respectively. 
It is also clear that the total time is O(logn). So we have: Theorem I. A VLSI sorter of n words of 
length q = (l+e)logn can be constructed whose area and computation time are A = O(n 2) and T = O(logn). 
 This network is AT2-optimal in the chosen model of computation. 6. Area-Time Trade-Off The COMBINATION-sorter 
proposed in the previous section has optimal area among sorters with minimum computation time. We will 
now describe a network, which, by choosing an appro- priate value for a design parameter, allows us to 
 sort in A O(n21o~/T for any time = 2)~ T E [~(logn),O(dnlogn)]. The network is the cascade intereonnection 
of two components. The n first component is a COMBINATION-sorter for -- s inputs. The second component 
is a new network, called the mesh-of-CCC (MCCC) and obtained by suitably "hybridizing" known networks 
(the mesh and the CCC). (3) This network will now be described in detail. An (n,s)-MCCC, with n = 2 
~ , s = 2 ° , and A r = n/s 2 = 20(0 ~-2o) consists of s 2 CCC modules, each with r cycles of length 
0- The n x 0 processing elements of the MCCC are con- veniently indexed as Mij(h,k): 0 ~ i,j < s, 0 
~ h < p, 0 ~ k < r.  For a fixed pair (i,j) the set {M..(h,k):O < h < p, 0 < k < r} is connected as 
a CCC-~dule, exactly as--described in Section 3. Then CCC modules are arranged as an s x s mesh, and, 
for a fixed k, the set of micromodules {M..(O,k):0 < i,j < s} is .i . mesh-connected (wlth i ~nd j 
as Vow and column indices,respectively). The MCCC graph can be laid out in a square of area O(n2/s2), 
since each CCC requires O(n2/s 4) area and channels of width O(n2/s 2) allow a straightforward implementation 
of mesh-connections. The mesh of CCCs has very interesting comput- ing capabilities as illustrated by 
the following theorems, stated without proof: Theorem 2. The MCCC can emulate the ASCEND (or DESCEND) 
paradigm [i0] of the Binary-Cube in optimal AT 2 = 0(n21og2n) for any T 6 [a(log2n),O( n~ogn)].  Theorem 
3. The MCCC can emulate the BITONIC SORTING paradigm [3] in optimal AT 2 = 8(n21og2n) for any T E [~(log3n),O( 
n~ogn)]. To obtain networks faster than the MCCC we start from the following observation. A COMBINE- 
sorter with n/s input can sort (in time O(slogn)  and area O(n2/s2)) s sequences of n/s elements each. 
 These sequences can then be fed, say one per column, into an MCCC with parameter s. At this point, 
the sequence in each CCC module is already sorted, and the MCCC is ready (after inverting the order 
of some sequences to comply with bitonic sorting rules) to execute the last 2o merging phases. (For 
the sake of simplicity we will ignore the fact that only o phases would be really necessary after the 
work done by the COMBINE-sorter.) A simple analysis allows us to conclude that, in the process, the 
MCCC executes O(logs+s) steps using O(logn) time for each, thus running for a total time T = O(slogn). 
We can then state: Theorem 4. A VLSI sorter of n words of length  (3)A similar network has been proposed 
by Aggarwal [16] who proves a variant of Theorem 2 given below. (l+e)logn can be constructed with optimal 
 AT 2 = e(n21og2n) for any computation time r [~(logn),O( n~ogn)]. The reported research leaves the 
following open problems (among others): i. Which are the upper and lower bounds to AT 2 for sorting 
n words of length ~ logn or considerably larger than logn? 2. Is there a suitable general framework 
of analysis encompassing number of words, length of key, and length of record? AcknoWledgement We would 
like to thank Tom Leighton for invaluable discussions on parallel sorting. This work was supported in 
part by the Joint Services Electronics Program under Contract N00014-79-C-0424 and in part by an IBM 
Predoctoral Fellowship. References <RefA>i. C. D. Thompson, "The VLSI complexity of sorting," IEEE Trans. 
Comp., vol. C-32, no. 12, Dec. 1983. 2. C. D. Thompson, A Complexity Theory for VLSI, Ph.D. Thesis, 
Computer Science Department, Carnegie-Mellon Univ., Aug. 1980.  3. G. Bilardi, F. P. Preparata, "A VLSI 
optimal architecture for bitonic sorting," Proc. 7th Conf. on Information Sciences and Systems, The Johns 
Hopkins University, Baltimore, MD,  (March 1983); pp. 1-5.  4. K. E. Batcher, "Sorting networks and 
their applications," Proe. AFIPS Spring Joint Computer Conference, vol. 32, pp. 307-314, April 1968. 
 5. D. D. Nath, S. N. M~heshwari, and P. C. P. Bhatt, "Efficient VLSI networks for parallel processing 
based on orthogonal trees," IEEE Trans. Comp./vol. C-32, no. 6, pp. 569-581, June 1983.  6. F. T. Leighton, 
"New lower bound techniques for VLSI," Proc~ 22nd Symp. on the Founda- tions of Computer Science, IEEE 
Computer Society, pp. 1-12, Oct. 1981.  7. D. E. Muller, F. P. Preparata, "Bounds to complexities of 
networks for sorting and for switching," JACM, vol. 22, pp. 195-201, April 1975.  8. F. P. Preparata, 
"New parallel sorting schemes," IEEE Trans. Comput., vol. C-27, no. 7, pp. 669-673, July 1978.  9. M. 
C. Pease, "The indirect binary n-cube microprocessor array," IEEE Trans. Comput., vol. C-26, no. 5, pp. 
458-473, May 1977.   69 i0. F. P. Preparata, J. Vuillemin, "The cube- connected-cycles: A versatile 
network for parallel computation," Com. of the ACM, vol. 24, no. 5, pp. 300-309, May 1981. ii. D. Nassimi, 
S. Sahni, "Parallel permutation and sorting algorithms and a new generalized connection network," JACM, 
vol. 20, no. 3, pp. 642-667, July 1982. 12. F. T. Leighton, Layouts for the Shuffle- Exchange Graph 
and Lower Bound Techniques, Ph.D. Thesis, Dept. of Mathematics, MIT, August 1981.  13. M. Aitai, J. 
Komlos, E. Szemeredi, "An O(nlogn) sorting network," Proc. 15th ACM Symposium on Theory of Computing, 
Boston, MA, April 1983, pp. 1-9.  14. F. T. Leighton, "Tight bounds on the complex- ity of parallel 
sorting," Prod. 16th ACM SymposiumonTheory Of Computing, Washington, D. C., April 1984. 15. G. Bilardi, 
F. P. Preparata, "The VLSI optimality of the "AKS sorting network," Coordinated Science Laboratory, University 
of Illinois, Urbana, Report R-1008, UILU- ENG 842202, February 1984.  16. A. Aggarwal, "On I/O placement 
in VLSI circuits," Prod. 21St Annual Allerton Conferenceon communication, control, and  Computing, 
Monticello, Illinois, pp. 236-243, October 1983.</RefA>  70  
			
