
 A n~ar nnt.imal alonrit.hm fnr wlw wnara.tnrs . . +.../w. v= ... ..W. w.~v. . ..... . . . .=~. .-y...-. 
-.-3 (Preliminary Version) F. R. K. Chung Bell Communications Research Morristown, New Jersey 07960 Abstract 
We give a characterization for graph separators. The problem of approximating the separator within a 
constant factor can then be reduced to a mini­ mization problem of convex functions. We discuss polynomial 
time algorithms for the corresponding minimization problems.  1 Introduction The concept of a graph 
separators have proved to be one of the most useful tools in the design and analysis of algorithms, and 
in applications in ex­ tremal graph theory, since its introduction in 1979 by Lipton and Tarjan in their 
seminal paper [13]. Basically, a separator of a graph G is a set of ver­ tices (or edges) of G whose 
removal disconnects G into two parts which are not too unequal in size, e.g., with neither part more 
than twice as large as the other. Here, size refers to some appropriate measure on graphs, such as the 
(weighted) number of vertices or edges. Often, a problem can be re­ cursively decomposed using graph 
separators into successively smaller ones, so that in a logarithmic Permission to cop without fee all 
or part of this materiai is granted provided ti at the copies are not made or distributed for direct 
commercial advanta e, the ACM copyright notice and the f title of the publication and ts date appear, 
and notice is given that copying is by permission of the Association of Computing Machinety. To copy 
otherwise, or to republish, requires a fee and/or specific permission. STOC 94-5/94 Montreal, Quebec, 
Canada 0 1994 ACM 0-89791-683-8/94/0005..$3.50 S.-T. Yau Harvard University Cambridge, Massachusetts 
02138 (in the size of G) number of steps, only trivial sub­problems remain. We point out that a separator 
is a special case of a cut , which is just any set of vertices (or edges) whose removal disccmnects G. 
Although the problem of determining the small­ est graph separator is known to be NP-complete, we can 
distinguish several goals as far as finding separators goes. We might like to know that we can always 
find a small separator. For example, Lipton and Tarjan [13] show that any planar graph G with n vertices, 
there is a polynomial time al­ gorithm which will always produce a separator of size O(@). On the other 
hand, we may require the more stringent condition of approximating the smallest possible separator of 
G (a planar graph on n vertices might actually have a separator of size log n or even O(l)). As an example 
of a result of this type, Rao [18] has given a polyr]omial time algorithm which always find to within 
a constant factor the optinum separator for any planar graph. More generally, Leighton and Rao [12] have 
given a polynomial time algorithm which finds for any graph on n vertices, a separator with size at 
most O(log n) as large aa the optimum. In this paper, we consider the following problems: The separator 
problem Remove as few edges as possible to disconnect a graph G into two parts so that each part contains 
at least one-third of the vertices of G. The bisection problem Remove as few edges as possible to disconnect 
a graph into two parts each of which has about the same number of vertices. The edge separator problem 
Remove as few edges as possible to disconnect a graph G into two parts so that each part contains at 
least one-third of the edges of G. The edge bisection problem Remove as few edges as possible to disconnect 
a graph into two parts each has about the same number of edges. The generalized isoperimetric problem 
Remove as few edges as possible to disconnect a graph into two parts so that the ratio of the number 
of edges removed and the smaller of the two sums of the degrees of vertices in the two parts is minimized. 
For regular graphs, the above problem is equiva­lent to the following problem: The isoperimetric problem 
Remove as few edges as possible to disconnect a graph into two parts so that the ratio of the number 
of edges removed and the number of vertices in the smaller of the two parts is minimized. For weighted 
graphs, the objective of the separa­tor problems is to remove edges with the least pos­sible total weight 
so that a graph is partitioned into parts of sizes as specified as in the above problems. As we will 
see, our methods for dealing with un­weighed graphs can easily be extended to weighted graphs as well. 
Our approach is based on the use of potential functions and has a similar flavor to techniques used in 
the study of the eigenvalues of the Laplacian of graphs [5]. The relations between eigenvalues of the 
Laplace operators and the isoperimetric prop­erties of manifolds have been extensively studied in the 
literature. Recently, the discrete analog of the relationships between the eigenvalues of the ad­jacency 
matrices of a graph and the isoperimetric properties of the graph has led to many results for expander 
graphs with applications to communica­tions networks, approximation algorithms and com­putational complexity 
[1], [7], [11], [14]. However, there are many obstacles in using eigenfunctions for separators. For example, 
the connection between the (dominant) eigenvalue A and the isoperimetric constant hG (which is the ratio 
of edges removed and the size of the smaller part) can sometimes be very weak. The discrete version of 
Cheeger s in­ equality can be stated as follows: There are many examples of graphs with A N h% and hence 
the lack of a tight connection be­tween the eigenfunctions achieving A and functions achieving hG. Also, 
the derivation of isoperimet­ric properties from eigenvalues usually requires the graphs to be regular 
( see [1] ,[1 1]). Nevertheless, the power of separators rests on recursive applica­tions and regularity 
is obviously not preserved af­ ter removing separators from a graph. It is there­ fore essential to consider 
general graphs. In order to overcome these difficulties, we consider a po­ tential function which is 
a modified version of the Laplacian or adjacency matrix of a graph. We will show that the function which 
minimizes the poten­tial function leads to a near-optimal solution to the generalized isoperimetric problems 
and the separa­tor problem. We remark that previously heuristic algorithms using eigenfunctions were 
considered by Mohar [14] for bandwidth problems and their variations, and some empirical evidence was 
presented. Ravi Bop­pana [2] also used eigenfunctions in his bisection approximation algorithms for random 
graphs. Hen­drickson and Leland [10] used eigenfunctions in their bisection algorithms for parallel computing 
while comparisons are made on various partition­ing methods for several examples. The complex­it y of 
determining eigenvalues and eigenfunct ions ranges from O(n 2376 log ~) for sequential meth­ods to parallel 
approximation algorithms in time O(log n log ~), where e is the desired accuracy [6] [19]. The reader 
is referred to [6] for an extensive survey on computing eigenvalues. This paper is organized as follows: 
In Section 2, we define introduce a potential function and de­fine some basic terms. In Section 3, several 
isoperi­metric inequalities are proved on which the edge separator algorithms are based. In Section 4 
we discuss the minimization problem for the potential functions. Section 5 includes a number of separator 
algorithms.  Preliminaries Let G denote a (loopless) graph with vertex set V= V(G) ={zq,... , v.} and 
edge set E = E(G). For {u, v} E E, we say u and v are adjacent and we write u w v. The degree of a vertex 
is denoted by dv. and we sometimes write d%= dv,. d. ifu=v L(u, v) = 1 if u and v are adjacent { o otherwise 
Let S denote the diagonal matrix with the (v, v)-th entry having value . The Laplacian C of G is &#38; 
defined to be L = SLS. In other words, we have 1 ifv=v if u and v are adjacent &#38; o otherwise /C(u, 
v) = { The eigenvalues of L are denoted by O = AO < AI < ... < An_l. When G is k-regular, it is easy 
to see that L= I ~A where A is the adjacency matrix of G. Let h denote a function which assigns to each 
vertex v of G a real value h(v). Then (h, Zh) = (h, SLSh) (h, h) (h, h) (f, Lf) = (s- f, S-1.f) ~(m -f(v)) 
(1) = u-v ~cLJ (v) v where h = S lj and (~, g) = ~Z ~(x)g(z). Let 1 denote the constant function which 
assumes value 1 on each vertex. Then S-l 1 is an eigenfunction of L with eigenvalue O. Also, ~(f(u) -f(v)) 
(3) = m~n fls- l  =dvf(U)2 v For two vertex-disjoint subsets, say, A and B, of V, let E(A, 1?) denote 
the set of edges with one vertex in A and one vertex in B. For a subset S C V, we define E(S, ~) (4) 
hG(S) = min(~dz,~dv) ZES ?@ where ~ denotes the complement of S. The Cheeger constant hG of a graph G 
is defined to be (5) hG = m? hG(S) If we adapt the terminology of differential geom­etry by viewing a 
graph as a discretization of a manifold, then E(S, $ corresponds to the bound­ay of S and ~ dz is regarded 
as the volume of S xes and is denoted by vol (S). In particula~r, the total volume of G is denoted by 
We remark that for a regular graph the Cheeger constant is sometimes called the conductance of the graph. 
For a fixed value c, O < c < 1, and for a subset S c V, we define where m-m Zcs Yes =C m We consider 
the set of all functions which assign real values to vertices of G, i.e., Rv := {f : V + R}. For a fixed 
value c, O < c, and for f E Rv satisfying ~ f (z)d$ = m, ~ f(z)d. = cm, z we introduce a potential 
function Wf a) for a fixed value a,O< a<1: ~(f(~) -f(Y))2 (C,cu) _ ~-v  +42 f4(z)cL/m 1) f ~(f(z) 
-C) d. z _ ;f, Lf) (1 ~ )m +4X f4(~)d./m 1) z Also, we define and we = m~wf ~(f( J -f(v)) z-y  
+ a(~ f4(z)dz/m 1) ~(f(z) -7)2&#38; z z where (7) We note that wf = w; for c= ~. Isoperimetric inequalities 
 and the potential functions Lemma 1. For any graph G, we have 2h~) > W$+d Proofi Omitted. For a function 
f GRv, let u and v be two vertices with f(u) < f(v) and we define Suv := {z: f(u) < f(z) < f(v)} and 
hf = ~rn$v ha (Suv ). f(u )g(v) Also, we define Sf so that hG(S~) = hf. Clearly hf > hG. Theorem 3.1 
For f G Sv, we have wf,a > Cahf for same appropriate constant C ( e.g., C = .05). Proofi Omitted. Combining 
Lemma 1 and Theorem 1, we have the following Theorem 3.2 For f with U@ > C wf, we have 2hG > WG,m > Cwf,a 
> CC ahf > Cc ahc where C and C are absolute positive constants. Remark 1: Our separator algorithms are 
mainly breed upon Theorem 3.2. First we find a function g such that w~ is within a constant factor of 
wG. Then we can easily compute S~ and h~ which is within a constant factor of hG. Remark 2: A random 
graph or a random regular graph has eigenvalues satisfying Therefore for random graphs, the eigenfunction 
f achieving ~G can then be used to generate a near optimal separator. A weighted undirected graph G. 
with loops al­lowed has associated with it a weight function n : V x V -+ R+ U {O} satisfying 7r(u, ?J) 
= m(v, u) and m(u, v) = O if {u, v} @E(G) The previous definitions for unweighed graphs can be easily 
generalized to weighted graphs as fol­lows . We define d., the degree of a vertex v of Gn bv dV = ~7T(V, 
U). u The matrix L is defined as follows: dv ifu=v L(u, V) = 7T(U, v) if u and v are adjacent o otherwise 
{ The Laplacian L of G. is defined to be L = SLS where S is defined as before. Let A. = O < Al s ... 
~ An_l denote the eigenvalues of L. Then v The Cheeger constant is defined the same way as in (3) with 
the modification that The potential function for weighted graphs has ex­actly the same formulation as 
in (5). To sim­plify discussions, we will mainly discuss the case of unweighed graphs. The statements 
and proofs can easily be carried over to the case of weighted graphs. For a positive constant a satisfying 
O < a s 1/2, we define (8) $6s where S c V(G) satisfies Lemma 2. Suppose a is a fixed constant and S1, 
S2,. ... St are vertex-disjoint subsets of V(G) satisfying the following: (1) hGz = h~, (S,), for z = 
1,. -. ,t where G, = G Uj<i St denotes the subgraph of G resulted from removing vertices in Uj <,S, 
and edges in­cident to Uj<l Si . (2) For some positive e,  4 Critical functions and the minimization 
problems In this section, we focus on finding a function ~ which achieves Wf a) = w;) for some positive 
a z .5. One possible approach is to apply the standard techniques in convex programing. There is a great 
deal of literature in convex optimization problems for a constaint domain [15, 16]. Although our min­imization 
problem is defined for functions on the sphere, it can be modified into a convex minimiza­tion problem 
on the ball and perhaps there are sim­ple ways for applying such techniques. Here, we propose a straightforward 
approach by further an­alyzing the critical functions. Lemma 3. If ~ ~ R is a local minimum of w(c), 
then for all x ~ V, we have ~f(z) + 2a(f2(z) I)(f(z) c)dz(l -C ) 2a~(f3(z) f(z)) rlz(l /z)/m x = 
[Wf + a~(f (x) -:1)/Tn, x 4CCI ~(f3(z) f(z)) dz/m](j(z) C) z Proofi The proof follows from a straightforward 
application of Lagrange methods. Here we set P=of = a~(f (z) -1)/~ z 4ca ~(f3(z) f(z))d./m z and Y~ 
= 2a~(.f3(z) f(z))dz(l c2)/rn z  We say ~ ~ Rv is (a c)-critical, if ~ satisfies the statement in 
Lemma 3. Lemma 4. If ~ c Rv is (a, c)-critical , then for all zcV, wehave Wf + Pf p(~) s 1+ 2a(l -C2) 
 Lemma 5: Suppose ~ is (a, c)-ciritical and ~ is (a+ q c)-critical where Then g satisfies Lg(z) + [2a(p(z) 
 1) +4a.f(z)(f(z) C)](I C2)9(Z) Xwf + Bf)9(~) a(w +e) = 2(p(z) I)(j(z) c) + ( da )f(f(~) -C) +(~)f 
+ 0(6) After calculating and substituting the partial derivatives of ~, -y, the above equation can be 
rewritten as:  Lg=Ff + (~)f(f C) We need to show that the above equation haa solutions. This means 
that the value of ~ can be chosen so that F ~ + ( #)f (~ c) is othogonal to the kernal of the dual 
of L, denoted by L*. To prove this, there are two cases: Lemma 6: If L*h = O, and ~ h(z)(~(z) c) = O, 
 z then xFfW) + (#) f(f(z) -C)h(s) = o z  Lemma 7: If L*h = O, and ~ h(z) (.f(z) c) #O, z g#o Details 
of computation for proofs of Lemma 6 and 7 will be included in the full version of the paper. Remark 
3: Lemma 5-7 reduce the minimization problem to the path-following approach which is quite stan­dard 
in the literature (see [15]). It is enough to fol­low the critical functions from the range of a = O 
to a = .5. Note that when a = O, the critical func­tions are exactly the eigenfunctions of the Lapla­cian 
which can be easily computed. The tracing can be done when all eigenspaces are l-dimensional. However, 
if there are eigenfunctions with the same eigenvalues, we can play the usual trick of perturb­ing the 
entries of the matrices while the (weighted) separators change little and the multiplicities of eigenspaces 
are eliminated. Roughly speaking, we start at a = O with n eigenfunctions. (In fact, we can restrict 
ourselves to those eigenfunctions with eigenvalues less than V.) At each point of a, there is a gradient 
field as described by Lemma 5 and it is enough to trace the critical functions using the gradient field 
until a = .5. 5 Edge separator algorithms A set T of edges is said to be an a-edge-separator if removing 
edges in T disconnects G into two parts A and B such that x ZEA ZEB We first consider algorithms for 
the generalized isoperimetric problems for a connected graph G on n vertices. A. Algorithms for the generalized 
isoperi­metric problem: Let g denote an approximate solution, i.e., CW9 < ming Wg for some constant C 
which depends on the desired accuracy e in the path-following methods in the previous section as well 
as the sam­plying (with gaps c) of c for all w(c). Rearrange the vertices so that g(vl) 2 g(vz)~... 
 For 1s i < n, we compute ~,, =1{{~~, ~t}GE:j Sz<kand(t<jmt>i)}l rein{ ~ djl ~ dk} j<s<i t>ioTt<j Choose 
ZO, j. such that hiO,jO = min hij = hf. ~,~ Let S = SiO,jO and let T denote E(S, ~). Then T is the solution 
to the generalized isopermetric problem for the graph G. B. Algorithms for the edge-separator prob­lem. 
 We repeatedly apply alogrithm A (if necessary) to get an a-edge-separator of G, for a fixed a, O < Fori=l,2,... 
, we iterate the following: Step 1 Apply algorithm A to the graph G~ = G -Uj<iSj andobtain Si such that 
hG,(SJ = hG,. x and d.< dx. E ZGS, zev(G, ) S, Step 2 If ~ ~ dz 2 a ~ d., stop; the solution j<i xGS, 
 x isS = Uj<i Sj. Otherwise, set Gi+l = G Uj<t Sj ~d go to Step 1 (after setting i +-i + l.). The above 
process will stop after at most n/2 it­erations. The performance analysis of Algorithm B is based on 
Lemma 3. Namely, an a-edge-separator given by Algorithm B is within a constant factor (depending only 
one) of an optimum (1+ c)a-edge­separator for any positive e. C. Algorithms for the edge-bisection prob­lem. 
 We will repeatedly use an a-edge-separator for a fixed a. Step O Begin with S1 = V(G), T = O,A = 0. 
For 2 =1,2,..., we continue the following process: Step 1 Find an a edge-separator which separates the 
graph G~, the induced subgraph on Vi into two parts Xi and Yi with Set Tz = T(J{Xi}lJ{K}. Step 2 Order 
elements of T, in decre~sing order of their volumes, say S1, S2, ..., where volume is given by vols := 
~ d=. ZES Place S1 in bin A. For i >1, if VOIA (which is the total volume of elements in A) is no more 
than VOIB, then we place Si in A. Otherwise, we place Si in B. Step 3 Choose the bin with the larger 
volume. Without loss of generality, say A has the larger volume. Pick the S j with the least volume in 
A. If \Sj\ = 1, stop. The solution is Us, GB Sj. Otherwise, set T = T, -{Sj} and S = Sj. Then, go to 
Step 1 (after i -z + 1.). The above process will stop after at most log n steps since the volume of 
Sj in Step 3 decreases by a factor of 1 a after each iteration. D. Algorithms for the separator problem 
We will use an a-edge-separator of a graph G on n vertices to obtain an (a c)-separator for any positive 
~, which separates G into two parts the smaller of which contains at least (a -e)n vertices. For a graph 
G, we form the graph G by attaching t d. leaves to each vertex z of G where t is some large number to 
be chosen later. We then apply the edge separator algorithm to G . An cr-edge­separator disconnects G 
into two parts A and B such that where d z denotes the degree of vertices x in G . Let S denote vertices 
in G which are contained in A. Since = (t-l)ISI + IAI  z . XEA = (t-l)\S[ + ~(t --dm) XGS = (2t I)lst 
 ~d., XEs we have [8] cl((2t l)n ~d.) < (2t l)ISI ~d.. x Zes  Therefore [9] an s [S1 + +-JW)I By 
choosing t z $, we obtain an (a c)­separator. [10] E. Bisection algorithms We will repeatedly use the 
separator algorithms in a similar way as the algorithm in C. Acknowledgement [11] The authors wish to 
thank Margaret Wright, Linda Kauffman, Mike Overton, Ding Z. Du, John Reif, Nimrod Megiddo for valuable 
discussions. References [12] <RefA>[1]Noga Alon, Eigenvalues and expanders, Com­binatorics 6 (1986) 83-86. 
 [13] [2] R. B. Boppana, Eigenvalues and graph bi­section: An average-case analysis, FOG S 28 (1987) 
280-285. Math. Compu~. 19 (1965) 577­ [14] 593 [3] J. Cheeger, A lower bound for the smallest eigenvalue 
of the Laplacian, Problems in Anal­ysis, (R. C. Gunning, cd.) Princeton Univ.  [15] Press (1970) 195-199. 
 [4] F. R. K. Chung and S.-T. Yau, Eigenvalues of graphs and Sobolev inequalities, preprint. [16] [5] 
James W. Demmel, Michael T. Heath and Henk A. van der Vorst, Acts Numerics 1993 ( A. Iserles cd.) Cambridge 
University Press, 111-197.  [17] [6] W. E. Donath, A. J. Hoffman, Lower bounds for the partitioning 
of graphs, IBM J. Res, [18] Revelop. September 1973,420-425 [7] M. R. Garey, D. S. Johnson and L. Stock­meyer, 
Some simplified NP-complete graph problems, Theor. Comput. Sci. 1 (1976) 237­267 J. R. Gilbert, J. P. 
Hutchinson, and R. E. Tarjan, A separator theorem for graphs with bounded genus, J. Algorithms 5 (1984) 
391­ 407. Bruce Hendrickson and Robert Leland, An im­proved spectral graph partitioning algorithm for 
mapping parallel computations, Sandia Re­port 1992. M. Jerrum and A. Sinclair, Approximating the permanent, 
SIAM J. Computing 18 (1989). 1149-1178. F. T. Leighton and Satish Rae, An approx­imate max-flow rein-cut 
theorem for uniform multicommodity flow problem with applica­tions to approximation algorithms, FOCS, 
29 (1988) 422-431. R. J. Lipton and R. E. Tarjan, A separator the­orem for planar graphs, SIAM J. Appl. 
Math. 36 (1979) 177-189. B. Mohar, Isoperimetric number of graphs,J. of Comb. Theory (B) 47 (1989), 274-291. 
Y. E. Nesterov and Arkadii Nemirovskii, Interior-Point Polynomial algorithms in Con­vex Programming, 
SIAM Studies in Applied Math. (1994). A. S. Nemirovsky and D. B. Yudin, Prob­lem Complexity and Method 
Efficiency, Wiley, New York (1983) J. Nocedal, Theory of algorithms for uncon­strained optimization, 
Acts Numerics 1992 ( A. Iserles cd.) Cambridge University Press, 199-242. Satish Rae, Finding near optimal 
separators in planar graphs, FOG S, 28 (1987) 225-237. S. T. Yau and Y. Y. Lu, Reducing the symmet­ric 
matrix eigenvalue problem to matrix mul­tiplications, SIAM J. Scientific Computing 14 (1993) 121-136 </RefA>
 
			
