
 An Analysis of Gang Scheduling for Multiprogrammed Parallel Computing Environments Mark S. Squillante 
Fang Wang, Marios Papaefthymiou IBM Research Division Computer Science Department T.J. Watson Research 
Center Yale University Yorktown Heights, NY 10598 New Haven, CT 06520-8285 mss@watson.ibm. com {wang-fang,papaefthy 
miou-marios} @es. yale.edu Abstract Gang scheduling is a resource management scheme for paral­lel and 
distributed systems that combines time-sharing with space-sharing to ensure short response times for 
interactive tasks and high overall system throughput. In this paper, we present and analyze a queueing 
theoretic model for a general gang scheduling scheme that forms the basis of a multipro­gramming environment 
currently being developed for IBM s SP2 parallel system and for clusters of workstations. Our model and 
analysis can be used to tune our scheduler in or­der to maximize its performance on each hardware platform. 
Introduction Researchers and users of parallel and distributed systems have long realized that effective 
resource management is es­sential for achieving high performance in a multiprogrammed environment. Unfortunately, 
current multicomputing sys­tems either dedicate all of their resources to one task, in which case they 
are not multiprogrammed, or they use sim­ple resource scheduling mechanisms that provide no guaran­teed 
service times for each task executing on the system. Several scheduling schemes for multlprogrammed parallel 
systems have been proposed over the last decade. Based on how they share resources, these schemes can 
be in general classified as time-sharing, space-sharing, or mixed. In purely time-shared systems, all 
processors work on a single job for a specified amount of time. Thus, time-sharing ensures that all jobs 
will get the system s attention, and it is particularly suit able for interactive tasks. There are sit 
uations, however, in which jobs may not need all the available processors in the system. It has been 
argued, for example, that performance does not increase as the number of processors dedicated to a job 
increases past a certain limit [3, 14]. Thus, simply allo­cating the total number of available processors 
to a job may underutilize a system s resources, To address this problem, several systems employ space-sharing 
in which jobs share the system resources at any given time instead of each tak­ing up all processors. 
Space-sharing helps decrease resource fragmentation and increase throughput. Studies have also shown 
that space-sharing can yield higher throughput than time-sharing in some environments [25, 29]. Gang 
scheduling is a mixed scheduling scheme that com­bines time-sharing with space-sharing [6, 7, 8]. Under 
gang scheduling, jobs with the same resource requirements are Permission to make digital/hard copies 
of all or patt of WIS material for personal or classroom use is granted without fee provided that the 
copies are not made or distributed for pmftt or commercial advantage, the copy­right notice, the title 
of the publication and its date appear, and notice is given that copyright is by permission of the ACM, 
Inc. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires specific 
penniaaion andlor fee. SPAA 96, Padua, Italy @ 1996 ACM 0-89791-809-6/96/06 ..$3.50 collected in groups. 
Each group is assigned to a partition of the system for a specific amount of time. When the time allocated 
to a group is up, a context switch occurs, resources are reallocated, and the jobs in new groups are 
scheduled to execute. Even though gang scheduling can be difficult to implement due to its system-wide 
context switches, it has several advantages and is becoming increasingly popular. In particular, gang 
scheduling promotes efficient fine-grain in­ teractions among threads in the same gang and provides interactive 
response time for short jobs. Moreover, gang scheduling allows space sharing by flexible partitioning 
and time sharing in fixed partitioning. A number of commercial systems such as the CM-5 and the Intel 
Paragon support simple gang scheduling schemes with fixed partitions. In this paper, we formulate a mathematical 
model of a novel gang scheduling scheme that features flexible parti­tions and flexible time slices for 
each partition. In our scheduler, each job is allocated to a certain configuration of processors so that 
there is a thread of that job on each processor. The threads of each job execute concurrently and are 
preempted at the same time when the time slice of the job is used up. Several jobs can be executing on 
different processors at the same time. We derive a mathematical analysis of our gang scheduling model, 
and we examine the performance characteristics of such a parallel system based on various system variables 
such as workload, arrival rate, and service rate. To our knowl­edge, such an analysis of gang scheduling 
has never been done before. Moreover, such an analysis is not straightfor­ward, since our gang scheduling 
model does not fall into the class of conventional queueing models. Our model and re­lated analysis is 
being used to guide the implementation of a gang scheduling scheme for real multiprogrammed parallel 
systems. In particular, we are currently participating in the development of multiprogramming environments 
for IBM s SP2 and for clusters of workstations [27, 1 I]. The scheduling mechanism for these systems 
is a variant of the basic gang scheduling scheme we analyze in this paper. Previous work on parallel 
gang scheduling has been em­pirical and concentrated on systems issues without analyzing the quantitative 
properties of the systems. Our analysis can be used to identify fundamental properties of parallel gang 
scheduling and to maximize the performance of this parallel system in multiprogrammed environments by 
tuning vari­ous system parameters, such as the length of the time slice allocated to each partition. 
The theoretical gang schedul­ing problem we consider is related to problems that have been studied for 
many years in the area of polling/vacation and communication systems. There is an extensive body of literature 
on the analysis of these systems (e.g., see [4, 24] and the references therein), but these solutions 
and meth­ods are not sufficiently general to directly address the prop­erties of our gang scheduling 
problem. In particular, our model differs from these approaches in that we simultane-2.2 Stochastic Processes 
ously consider multiple servers, context-switch overheads, and more general distributions for processing 
times, quan­tum lengths and context-switch overheads. Our solution is therefore a generalization of some 
previous results in this area, and our methods could thus have an impact in the area of polling/vacation 
and communication systems in addition to parallel gang scheduling systems. The remainder of this paper 
has five sections. In Section 2 we give some background on our approach. In Section 3 we present our 
gang scheduling model, and in Section 4 we give a mathematical analysis of the model. In Section 5 we 
show how our model can be used to tune the performance of a multiprogrammed parallel system. We conclude 
our paper with directions for future research. 2 Technical Preliminaries In this paper we formulate a 
general queueing theoretic model of gang scheduling in parallel computer systems, and we derive a solution 
of the model and its corresponding per­formance measures. This section briefly develops a series of technical 
results that provide the background for our ap­proach. Additional technical details can be found in numer­ous 
excellent texts, including [9, 12, 13, 18, 20, 28] Through­out this paper we use 111+ and Et+ to denote 
the set of non­negative and positive real numbers, respectively. Similarly, we use Z!+ and ZZ+ to respectively 
denote the set of non­negative and positive integers. 2.1 Queueing Systems We consider a dynamic system 
in which an arbitrary stream of customers Cn, n E 72+, arrive to a service facility, possibly wait in 
a queue for service, and depart the system after being served. Let an E JR+ denote the arrival epoch 
of C ~, where uo < al < az < ., uo ~ Oby convention and hm~+~ an = cm, let Sn c JR+ denote the service 
requirement of G *, and let dn E JR+ denote the departure epoch of Cn, where d~ > an +s~. We also let 
T~ = d~ u~ denote the time spent m the system by Cn (i.e., the response time of Cn), we let A(t) = max{n: 
an g t}and A(t) = ~~~~ ~n(t) respectively denote the number of customer arrivals and departures by time 
t, where ~~(t) = 1 if d~ ~ tand In(t) = O otherwise, and we let N(t)= A(t) A(t) denote the number of 
customers in the system at time t. Now define the average customer response time ~ as (1) the average 
customer arrival rate A as (2) and the average number of customers in the system ~ as (3) We then have 
the following important relationship between these performance measures, called Little s result [17]. 
Theorem 2.1 Ij the limzts in (1) and (2) exasts and are firwte, then the limzt in (3) exists and m gwen 
by ~ = AT. We desire to characterize the long-run behawor of the dy­namic queueing system described above, 
from which we can obtain important performance measures. This system is rep­resented by a stochastic 
process {X(t) ; t. ~ O] defined over a countable state space O. Definition 2.2 A stochastic process {X(t) 
; tE T} zsa collection of random vurmbles, z.e., for each t c T, X(t) is a (vector of) random variable(s). 
The index set T (most often interpreted as t%me) M ezther countable, resultzng m a discrete-time process, 
or an r.nterval of the real lzne, yzeldmg a continuous-time process. The set of all possible values that 
X(t) can take on as called ats state space, where bezng m state x at time t means that the event {X(t) 
= Z} has occurred. Note that {N(t) ;t z O}, {A(t) ;t 2 O} and {A(t) ;t Z 0} are stochastic processes. 
For the purposes of this paper, we need only consider the important case where the stochastic process 
{X(t) ; t > 0} is a homogeneous, continuous-time Markov chain. Definition 2.3 Given a continuous-time 
stochastic pTocess {X(t) ; t > 0} wtth state space Z+, the process zs a continuous-time Markov chain 
zf for every s, t,u E JR+ and ~,~,~(u) ~ ~+ P[x(t+s) =i]x(s) =j, x(u) ==z(u), u <s] = P[x(t+s) =ilx(s)=j]. 
(4) If the r,h. s. of (4) zs independent of s, then {X(t) ; t ~ 0} has stationary or homogeneous transition 
probab.dzhes. The transitions among the states of {X(t) ; t ~ O} are defined by the elements of the uaj%n.teszmal 
generator matrzx Q z [g,,j] for this Markov chain, where = li&#38;PIX(t +h)=jl X(t) =i]/h, i#j, (5) 
 q,,3 and q,,, = }:o(PIX(t+ h.) =i lX(t)=i] l)/h. (6) The quantity q,,, is the instantaneous rate at 
which the process moves from state i to state j, i # j, and the quantity q,,, is the instantaneous rate 
at which the process leaves state i when it is in this state. We define c = lim P[l?(s) = n]/t ds, (7) 
t-m ~ Pn / ~. = pir PIIv(t) =72], (8) and m = [To, rl, ~z, . . .]. As long as the integral in (7) is 
finite for every finite tand the pointwise limit in (8) exists, it can be easily shown that these limits 
are the same, and thus xn represents the long-run proportion of time the process spends in state n. The 
limiting probability vector T is the stationary distribution for the Markov chain {X(t) ; t ~ O}, and 
we can use the following classical result to obtain the values of its elements. Theorem 2.4 If a continuous-tzme 
Markov process u irre­ducible (i. e., there M a path from every state to every other state) and ergodzc 
(a. e., the states are posztwe recurrent and aperzodzc), then zts stationary probability vector x extsts, 
 each of the components of ~ are positive, and these compo­ nents are uniquely determmed by solrnng the 
global balance equatzons ~Q=o (9) together with the normalzzzng constraint 7re = 1, (lo) wheree is a 
column vector of the appropriate dimension con­ tammg all ones. The equations in (9) are called the global 
balance equations of the process because they equate the prob­ abdity flow rates into and out of every 
state. 2.3 Performance Measures The components of the invariant probability vector T com­ pletely characterize 
the behavior of the system, which is the reason that much of our mathematical analysis will focus on 
determining this vector. In particular, we can obtain vari­ ous performance measures of interest from 
the elements of m. For example, the average number of customers in the system can be calculated as 03 
N = ~nr.. (11) n=o The mean_customer response time~an then be calculated in terms of N using Theorem 
2.1 as T = ~/A. 2.4 Uniformization our mathematical analysis also uses the technique of uni­ formization. 
This basically consists of constructing a par­ ticular discrete-time version of a continuous-time Markov 
chain. Consider the generator matrix Q = [q,,~ ] for the Markov chain {X(t) ; t ~ 0}, and define qma= 
s max{ qi,i}. Rec­ all that qi,i is the total instantaneous rate of leaving state i. As long as qm.= 
is finite, we can discretize the original continuous-time Markov chain {X(t) ; t > O} to form an equivalent 
discrete-time Markov chain {~n ; n > O}. Specifically, the transition probability y matrix for this discrete-time 
chain is given by .P = Q/qmzX + 1, where I is the identity matrix. The discrete-time analog of Theo­rem 
2.4 shows that the stationary probability vector n-p for the uniformized Markov chain {Xn ; n > ()} is 
uniquely de. termined by the solution of TPP = Tp and mpe = 1. lJPon substitution of P = Q/qm&#38;X + 
I in the discrete-time global Pp = ~p ), simplifying the resultbalance equations (i.e., r and multiplying 
both sides by qm.., it follows directly that rp is equivalent to T.  2.5 Phase-Type Distributions The 
generator matrix Q for the Markov chain {X(t); t > O} is determined by the probability distributions 
assumed for the parameters of the queueing system. In this paper we ex. ploit a particularly general 
class of probability distributions called phase-type distributions [19, 26]. Consider a Markov chain 
defined on the states {1, 2,..., m, m + 1} with the generator matrix  [1(12)c?=::, where the (i, j) 
k element of Q is the rate at which the system moves from state i to state j, S is an m x WI matrix, 
$ is a column vector of order m, the states 1, 2, . . . . m are transient (i.e., the probability that 
the system ever returns to the state is less than 1), and the state m + 1 is absorbing (i. e., the probability 
that the system will leave the state once entered is O). Let (~, O) be the initial probability vector 
for Q (i. e , g(z) M the probability that the system starts in state i at time O), where :e = 1. Since 
the non-diagonal elements of a generator matrix are non-negative and the diagonal element of each row 
is the negative sum of the non-diagonal elements on that row [10], we have that Se + ~ = O. The distribution 
of the time until absorption (into state m + 1) in this Markov chain defines an order m phase-type distribution 
with parameters (~, S) whose mean is given by @ Le. We use the notation PH( , S) to refer to such a phase-type 
distribution. As a simple example, consider a K­stage Erlang distribution with mean I/p [13]. This is 
easily shown to be a very simple phase-type distribution with Kp K,LL O .. 0 K,u Kp ... ... s= .  
0 .:. Kp I1} ~~~ S= [o,..., O, Kp]T, g=[l, O,..., O], andm=K. Our mathematical analysis exploits the 
form of the convo­ lution of phase-type distributions. The following basic result for the c~nvolut~on 
of two phase-type distributions can be easily established [19]. Theorem 2.5 If F(. ) as an order 7ZF 
phase-type distribution with parameters (ZJF, SF) and G(. ) is an order nG phase-type dzstrr.button wzth 
parameters (VG, SG), then thew convokd%on F * G(. ) as an order nF + nG phase-type distribution with 
parameters [VF, O] and Since &#38; and VG have dimensions ?ZF x 1 and 1 x nG, respec­ tively, &#38;VG 
= [bi,j] where bi,j E $F(i) L G(j), 1 < i < 7ZF, l<j<?JG. 3 Parallel System Model We model a parallel 
processing system consisting of P iden­tical processors and L different classes of jobs. Each job class 
p, O < p < L, divides the P processors into equal-size disjoint sets, or partztzons, and each set can 
accommodate a job that requires g(p) processors, O s g(p) < P. An infinite­ capacity queue is associated 
with each job class, from which the processors select work for execution under a particular gang scheduling 
policy (described below). A first-come first­ served (FCFS) queueing discipline is employed at each of 
these L queues. Arrivals to the class p queue are representative of jobs that request to be executed 
on g(p) processors. Such jobs are as­sumed to arrive from an exogenous source at time epochs {a=,~ ; 
O S P < ~, n ? 1}. The interarrival time between the n lS and n h arrival to the class p queue is given 
by TP,n = aP,n aP,n_l. All jobs of class p are executed on g(p) processors, and the corresponding service 
times at these processor partitions are given by {sP,~ ; O ~ p < L, n ~ 1}. The interarrival times {rP,~ 
; O < p < L, n > 1} and ser­ vice times {sP,m ; O ~ p < L, n > 1} are assumed to form two independent 
sequences of independent and identically distributed (i id ) lR+-valued random variables with proba­ 
bility distributions AP( ) and BP() (defined precisely m 3.2), respectively, whose means I/Ap and I/pP 
are both finite. Multiple job arrivals, multiple job departures, and both an arrival and a departure 
within a small time interval h are all assumed to occur with probability of order o(h) [13]. Under our 
assumption ofphase-type distributions, this leads toaparticular class of Markovchams called quasz-bzrth-decsth 
processes [19] (although our mathematical analysis is easily extended to handle batch arrivals and/or 
departures as long as the batch sizes are bounded), which is a generalization of broth-death processes 
from classical queueing theory [13]. 3.1 Gang Scheduling Policy The above system employs a general gang 
scheduling policy under which for each job class p, up to P/g(p) jobs space­share all of the P system 
processors. Processors are dedi­catedtoeach of the Ljobclasses ina time-sharing manner by rotating the 
time allocated tothejob classes. Without loss of generality, we define a tzmeplexzng cycle to be the 
interval of time between successive time-slices, or quantums, for class O. Then h timeplexing cycle consists 
ofafixed execution quan­tumforeach jobclassp of length TP,~, O <p < L, n ~ 1, as well as context-switch 
overheads C p,n for switching between classes p and (p + 1) mod L. The length of the n$b time­ plexing 
cycle is therefore given byZ n = ~~~~(TP,~+CP,~). Let ?, be a random variable that denotes the generic 
quan­tum length for class p given that there is sufficient work to keep the processors busy, having distribution 
GP(. ) with mean E[?P ] = I/yP, and let 8P be the random variable that denotes the generic overhead for 
switching from class p to class (p + 1) mod L, having distribution CT(. ) with mean E[@p]=l/6p,0SP <L. 
During each time slice for class p, the first P/g(p) jobs on the class p queue are each executed m parallel 
on g(p) processors. Upon the service completion of one such job, the released partition of size g(p) 
is allocated to the next job on the class p queue (if any). An arriving job of class p that finds a queue 
length (including the jobs in service) less than P/g(p) is immediately allocated one of the available 
partitions of size g(p). Otherwise, the job waits in the queue until a processor partition becomes available. 
If the class p queue becomes empty before its quantum expires (i. e., there are no class p jobs in the 
system), then the system context-switches to the jobs of class (p + 1) mod L. Thus, TP,~ is the minimum 
of the ntfi replica of TP and the time required to empty queue p on its n h time slice, O ~ p< L,n~l. 
Observe that the allocation of processors to jobs of class p can be viewed from the perspective of class 
p as an alternating vector process {TP,~, ZP,~ } where Zp,~ = ~~~~ ~~p Tmn + ~~~~ c~,~. We will exploit 
this ob­ servation in our mathematical analysis in Section 4. 3.2 Parameter Distributions The probability 
distributions assumed for the parameters of our model are important in that they determine both the generality 
of our solution and the usefulness of our model in practice, To obtain a general and accurate model of 
a wide range of real parallel computer systems under gang scheduling, we assume that each of the model 
parameters have a phase-type distribution (see Section 2.5). This (gen­eral) assumption is fundamental 
to our aDmoach and it is /. based on two important facts: (i) phase-~y-pe distributions have important 
mathematical properties that can be ex­ploited to obtain a tractable analytic model while captur­ing 
the fundamental aspects of our parallel gang scheduling system, and (ii) any real distribution on R+ 
can in prin­ciple be represented arbitrarily close by a phase-type dis­tribution. Moreover, a considerable 
body of research has examined the fitting of phase-type distributions to empirical data, and a number 
of algorithms have been developed for doing so [2, 5, 15, 16]. It is also well known that some steady­state 
measures (e. g., mean response time) often depend only upon the first few moments of the parameter distributions 
(as opposed to their detaded forms) in a general class of probability models [21, 22, 26]. In this section 
we define the phase-type distributions for our model parameters, and we refer the reader back to Section 
2.5 for additional details. The class p interarrival distribution A=( ) is given by the order mAp phase-type 
distribution PH(gP, ~dp) with l/&#38; = CYpS~~ e. Simi­ larly, the distribution Bp( ) of class p service 
requirements on g(p) processors is given by the phase-type distribution PH(~o, SBP ) of order m~p with 
1 /pP = ~~s~~ e. The class ~ quantum length distribution Gp(. ), when there is sufficient work to keep 
the processors busy, is given by the order MP phase-type distribution Gp = PH(~P, SGP) with I/yP = ~PS~~e, 
and the distribution Cp(. ) of the over­ heads for switching between classes p and (p + 1) mod L is given 
by the phase-type distribution PH(~P, SCP) of order mcp with l/6P = ~PS;~e. 4 Mathematical Analysis The 
parallel gang scheduling system model presented in the previous section is represented by a continuous-time 
Markov process {X(t) ; t > O} defined over a countable state space Q. The main difficulty in solving 
the Markov process that records the state of each system queue is the size and com­plexity of its state 
space. To create a tractable formulation, we decompose the system by viewing it as L alternating vec­tor 
processes {T,,=, Z=,n} that model the system from the perspective of each job class p, O s p < L, n > 
1. Each of the resulting quasi-birth-death processes can then be solved in isolation by modifying its 
distribution for ZP!~ to reflect the system behavior of the other job classes. This forms the basis for 
a fixed-point iteration that is used together with uniformization to calculate the stationary probability 
vector for each class. Steady-state performance measures for the entire parallel system are then obtained 
from these invariant probability vectors in a manner analogous to the description in Section 2.3. 4.1 
Per-Class Processes The parallel system model from the perspective of class p is represented by the Markov 
process {Xp(t) ; t > O}. The state space of this process is given by t2P = ~P,o U Op, +, where x a {1, 
... ,??2Ap}, ii(i,p) = {(jl, ...?mBp)p) :0 < .ln s ~/9(p))l S ~ < mi9p,Xff fj. = min(i~/9(p))}1 c ­{1, 
. . . . IvfP + NP}, iP denotes the total number of class p jobs in the system, ~~ denotes the phase of 
the class pmterarnval process, j~n denotes the number of class p jobs whose ser­vice time process is 
in phase n, and kP denotes the phase of the current timeplexing cycle for the system from the per­ spective 
of class P Note that kp records the state of the alternating process {Z p,n, ZP,~}m>l by which the processors 
are allocated to jobs of class p, ~here kp &#38; {1,2, . . ..MP} indicates when class p is receiving 
service whereas kp ~ {~p+l, MP+2,..., Mp+Np} indicates when the other job classes are receiving service, 
To help clarify our description of the class p Markov chain {XP(t); t L 0}, weprovide in Figure 1 anexample 
of the state-transition diagram for this Markov chain in the special case of Poisson arrivals (i. e., 
jP A = 1), exponential service times (i. e., j: = 1), exponential context-switch overheads (i.e., mcP 
= 1), a K = ill, stage Erlang quantum-length distribution, and 3 servers. The above formulation assumes 
that the times {Zp,~}n21 have a phase-type distribution Fpo of order Ifp. To sim­plify the presentation 
of our mathematical analysis, we show this result in the next theorem for the case where each class has 
sufficient work to keep the processors busy throughout its allotted quantum. We refer to this case as 
the heavy­traffic regime, and throughout the remainder of this section and the next section we focus 
on the case where the system is operating in the heavy-traffic regime. We complete our solution in Section 
4.3, where we consider the distribution F=(. ) when the system is operating in the non-heavy-traffic 
regime. Theorem 4.1 The cktrzbutzon Fpo of the tzmes {Zp,~}. >, when the model ZS operating in the heavy-trafic 
., .=­ reg~me u an order NP phase-type distribution with parame­ ters ([~p, O],Vdp)) where L 1 L 1 (13) 
?Z=O ??=0 : n#p class uses its entire quantum because there is sufficient work to keep the processors 
busy throughout each allotted tlme­shce, It therefore follows directly from the definitions in Section 
3 that the distribution FP(. ) is equal to Cp * GP+l * Cp+l*, ..* GL-l*CL_l *GO* CO*. ..* GL*Cp CIOl 
O in this heavy-traffic regime. Equations (13) and (14) then follow from multiple applications of Theorem 
2.5. U and &#38;p SCJP+l . . 0 0 c$G,p+l . . . 0 0 0 0 v~(P) = . (14) 1 o 0 ,..~G,P l$y I . . . Sc,p 
1 Proofi By definition, when the system is operating in the heavy-traffic regime (e.g , consider the 
limit as the traffic intensities for every class tend toward their critical value where the queue length 
of each class tends to infinity), every We define (15) and O~p<L. (=)SYp,i, l<y<Dt p) ]]%]], fori>l, 
Letzt Y = i > 0, be a lexicographical ~rdering of the elements of YP,,. Using this ordering we then define 
for O ~ P < L  7+) E [Tp, 7+, 7r:), ...]. (17) where for i~ O denotes the number of states on level 
i. We also define D(p) a ~:g:p) 1 ~~) 4.2 Per-Class Stationary Distribution The limiting probability 
vector m(p) is the stationary distri­ bution for the Markov process {XP(t); t > 0}, and the value of 
each of its components r(p) (i, z~p~ ) represents the long-run proportion of time the system spends in 
state (i, z~~) ) E f2P, O g p < L. In this section we show how to exploit tke struc­ture of the Markov 
process {X,(t); t > O} to efficiently solve equations (9) and (10) to obtain m(p). We partition the generator 
matrix Q(p) for this Markov chain according to the same order as the elements of the stationary probability 
vector m(p), O s p < L. This yields a structure given by Q(P) = , (20) .. .. 1 where ~$) , B&#38;) , 
~f:) , ~[:) and AY), n = O, 1,2, are finite matrices of dimensions D(p) x D(p), D(p) x D$)9(P), D~~g[p) 
~(P), &#38; ) P,g{p) and D(p) ~,g(p), respectively. P/g(p) x ~(p) P/g(*) x ~(p) Note that I&#38;) describes 
the transitions among the states in s\ 2, ... .,,,, ?, 3; i, 3p 1. 3P Figure 1: State-transition diagram 
for class p with 3 servers, j: = 1, jf = 1, mcp = 1 and MP = K. levels O, 1,. . . , P/g(p) 1, B~~) describes 
the transitions from where RP is the minimal non-negative matrix that satisjies states in levels O, . 
. . P/g(p) 1 to states in level P/g(p), R;A$ ) + RPA~) + A$) = O (23)l?f~) describes the transitions 
from states in level P/g(p) to states in levels O, . . . . P/g(p) 1, and 11~~) describes the having 
spectral radius~ sp(RP) < 1, together with the nor­transitions among the states in level P/g(p). Similarly, 
for malizing constraint i z P/g(p) + 1, A~) describes the transitions from states in (P)level i to states 
in level i + 1, A~) describes the transitions (T$ ), rep),... I P/9( P)-l)e y ~%)g(p)(~ Rp)- e = I. 
(24)from states in level i to states in level i 1, and A~) describes the transitions among states in 
level i. Furthermore, observe that the structure of the process repeats from level P/g(p)+ 1 Proofi 
It follows directly from the definition in (17) and the onward, and thus we term this the repeating portion 
of the structure in (20) that the global balance equations in (9) can process. We refer to levels O through 
P/g(p) as the boundary. be rewritten as It follows directly from our assumptions of a phase-type distribution 
for each model parameter that {XP(t) ; t ~ O} (&#38;), @,. . . . Xs~,(P)_l )~%) + ~$?),(p)~[;) = 0, (25) 
is a Markov process, O s p < L. We assume in what follows that each of these processes are irreducible 
and ergodic, and we address verifying these conditions in Section 4.4. The (?r$ ),7rp),...,#P) P/g(p)-l 
M) + 7$1,(P) ~i? + next step is to exploit the structure of {.XP(t) ; t ~ 0} to *(P) A~) = 0, (26: obtain 
its invariant probability vector mt$ ) as shown in the P/g(p)+l next theorem, and for n~O Theorem 4.2 
When the Markov process {X,(t) ; t ~ 0} *(P) &#38;) = (). with generator Q(p) in the form of equation 
(20) is irre-p/9(P)+n A&#38;) + T$;g(p)+n+l -@ + n(p)P/9(p)+n+2 (27; ducible and ergodic, then the stationary 
probability vector The transitions in the reDeatine L. Dortion are identical and are m(p) exists and 
its components are given by between adjoining levels; and thus it is reasonable to expect that there 
exists some unknown matrix Rp such that T(P)*(P)  72>0. (28) P/g(p)+?a+l = P/g(p)+?l R P, The spectral 
radius of Rp is the eigenvalue with the largest mod. UIUS, which is real and positive provided that Q(P) 
is irreducible. Since from Theorem 2,4 there is only one solution to equa­ tions (9) and (10), all we 
need to do is verify that this solu­ tion is indeed given by (28). Upon substitution of (28) into equations 
(26) and (27) and ., simplifying, we obtain (n$), . . . . 7r$)g(p)_ , )B$) (B~~) + RPAf )) = O,  + 
Wg(p) (29) and for n~O #P) P/g(p) +71 (A~) -t RPA~) + R;Af)) = 0. (30) Since Theorem 2.4 ensures that 
m~)of~)~n > 0, n > (), -,.,.-,!­ equation (30) implies that RP must satisfy (23). Combin­ ing (25) and 
(29) yields equation (21), and (22) follows di­ rectly from (28). Finally, we can rewrite equation (10) 
as J /9(P)-l w 7r~)e + x x%!,,,+. = 1 n=o ?3=0 and upon substitution of (28) and simplifying we obtain 
7Z=0 The infinite matrix series in this expression converges to (1 RP)- provided that sp(Rp) <1 (analogous 
to the geo­metric scalar series). Since sp(RP) < 1 must be satisfied in order for the Markov process 
to be positive recurrent (see Section 4.4), equation (24) directly follows. 0 The solutions to equations 
(21) -(24) can be numerically computed in an efficient manner [23]. These equations form the solution 
to our parallel system model from the perspec­tive of class p, O ~ p < L, provided that the distributions 
F? are known. We initialize Fp via equations (13) and (14), and thus obtain an exact solution to our 
parallel system model when it is operating in the heavy-traffic regime. In the next section we complete 
the solution of our parallel system model by extending our analysis for the non-heavy-traffic regime. 
4.3 Non-Heavy-Traffic Regime The L model solutions from equations (21) (24), based on the initialization 
of (13) and (14), are used to express the distribution Fp in the non-heavy-traffic regime.2 This forms 
the basis for a fixed-point iteration that is used together with uniformization to complete the solution 
to our parallel system model. Consider the state space flP of the class p Markov process {xP(t) ; t > 
O}, and partition it into the two sets and W 0 {(F)~P) l(v7~P) eQp, M.+l<kp<M, +Np}. (32) 2An exact 
solution of our parallel system model when it is operat. ing in the non-heavy-traffic regime generally 
requires FP(. ) to be the conditional distribution of the times { ZP, m}n> ~ given the population of 
the other classes, which we will address in-an extended version of this paper. Observe that fl~ contains 
the states of XP(t) in which class p jobs are receiving service and fly contains the remaining states 
of XP(t) in which class p jobs are waiting. We construct a new process {X;(t); t ~ O} from the orig­inal 
process {XP(t) ; t > O} by replacing all transitions from states in O; to states in fly with transitions 
that go from the states in O; to a new state (O, O) (maintammg the same transition rates). All other 
transitions from the states in O; for the process {X;(t) ; t > O} are identical to the corre­sponding 
transitions of the original process. Note that state (O, O) is absorbing. Let LJbp denote the generator 
matrix for the Markov process {X;(t); t ~ O} which is defined over the state space C?; U {(O, O)}. We 
then uniformize the original Markov chain {XP(t); t > O} to construct an equivalent discrete-time version 
{~~; n > O}, as described in Section 2.4. The transition probability matrix for this discrete-time Markov 
chain is given by P@) = Q(p)/qm.. + I, where q~.= a max{ qz,z}. We denote the stationary probability 
vector of P(p) by rep (p), and recall that Tp)(p) is equivalent to m(p). Let Z$p) be a lexicographic 
ordering of the states in S_2p, 1 > 1, let Z9(P) be a lexicographic ordering of the states in {(O, O)} 
U O;, m > 1, and define j(m) to be the map­state in .ZS,(p) to the index e of the ping from the m corresponding 
state in Z(P). We then define the probabil­ ity vector $ on the states in Z* (p) such that ~~(m) ~ 11{(0,and 
observe that ~j(~) 0)}u %11,p(p) 0 [Pk,n]k,n>l. defines the steady-state probability that a class p quan­tum 
begins in state f(m) of the original Markov process {xP(t) ; t > o}. We can now state the following result 
that forms the fixed­point iteration of our model solution. Theorem 4.3 The clzstr~button Fpo oj the 
tames {zp,~}n>l for the non-heavy-h-afic regzme, obtumed from the L m~del solutzons, M an order N: phase-type 
dzstrzbutaon unth parameters ([{p, o], VF (P)) where L 1 L 1 (33) 7Z=0 ?a=o:?a#p , (34) . . &#38;p_l~p_, 
o 0 . Scfp -l and (35) Proofi It follows directly from the construction above that Q&#38;P defines the 
distribution of the quantum times {TP,~ }n21 in steady state, including the switching to class (p+ 1) 
mod L when the class p queue becomes empty before its quantum expires (see Section 3.1), and that [0, 
~~] defines its initial probability vector. Furthermore, a trivial reordering of the states of Q&#38; 
(i. e., equation (35)) in which (O, O) is placed at S!(P) the end of the ordering defined in Zm wdl organize 
Q ~p in the form of equation ( 12), and thus the distribution it defines is of phase-type, Note that 
this phase-type distribution has a mean of l/~~ = ~~S&#38;P le. It also follows from the above construction 
and the def­imtions in Section 3 that the distribution Fp( ) is equal to Cp*G~+i *CP+l*. ..* Gl l *CL 
l*G~ *Co*... * G~_l * Cp_l (.) in the non-heavy-traffic regime. Equa­tions (33) and (34) then follow 
from multiple applications of Theorem 2.5. 0 We construct the distributions FP( ) from Theorem 4.3 us­ing 
the L model solutions obtained via the analysis of Sec­tion 4.2. The parallel system model is solved 
again using these distributions and equations (21 ) (24) to obtain the corresponding stationary probability 
vector T(p). This so­lution yields new values for Fp(. ) via Theorem 4.3 and the model is solved again 
with these new values. This fixed­point iteration continues until the differences between the values 
of an iteration and those of the previous iteration are arbitrarily small. 4.4 Irreducibility and Ergodicity 
The irreducibility of the Markov chain {Xp(t); t > O} can be verified for any specific instance of our 
model by determining whether the first P/g(p) + 2 levels of the state space (the boundary plus the first 
level of the repeating portion) are strongly connected [I]. This follows directly from the fact that 
transitions between the states of levels F /g(p) + 1 and F /g(p) + 2 are identical to those between the 
states of levels P/g(p) and P/g(p) + 1 (see equation (20)), and the fact that there are no transitions 
between states of levels z and i + 1, i ~ O, ~ > 1, that do not first visit level z+l (i. e., OUI model 
is a quasi-birth-death process). Hence, upon verifying that the (finite) boundary plus the first level 
of the repeating portion is irreducible, it follows that the entire process is irreducible. The following 
result captures the remaining stability con­dition for the L systems. Theorem 4.4 When {Xp(t) ; t > O} 
IS zrreduczble, then the Markov chain is positive recurrent if and only if there ex­ (P) zsts a pos2tzve 
vector (7r0 , . . . . 7r~jg[P) ) that satzsfies equa. tion (21), and yA$)e < yA~)e, (36) where y is 
the stationary probabdity vector of A(PJ s AT) + A~) + A~), I.e., the solution of yA(P) = O and ye = 
1. Proof: A state of a Markov chain is positive recurrent if and only if the process is guaranteed with 
probability 1 to return the state (given it starts out in this state) and the mean time for this return 
is finite. Since the states of an irreducible Markov chain all have the same classification, we need 
only consider a single state of the chain, say the lih state of level i > ~/9(p) + 1. The mean recurrence 
time for this state is ~iven by the l h element of the vector ~~=1 R;e, which is finite if and only if 
sp(Rp) < 1. It can be easily shown that equation (36) is a necessary and sufficient condition for SP(RP) 
< 1 whenever the matrix A(p) is irreducible [19]. The generator A(p) for our models will be irreducible 
provided that the phase-type distributions Ap, BP) Cp and Gp have 18 class O 16 classl * class2 * 14 
class3 12 w 0 10 8 6 4 2 0 1 23456 mean quantum length Figure 2: Mean number of jobs N, versus mean 
quantum length l/~ for a system with 8 processors and utilization factor P = 0,4, irreducible representations, 
O s p < L. Since we can always obtain an irreducible representation of a phase-type distrib­ution [19], 
the condition for positive recurrence M given by (P) p) ) that equatlOn (36). Fmfly, the vector (To 
t.. . ~~Pi9(P) satisfies equations (21) and (24) is strictly positive when­ever sp(RP) < 1. 0 4.5 Performance 
Measures Given the components of the invariant probability vectors *(P), o < p < L, we can directly obtain 
performance mea­ sures of interest for each job class. The mean number of class p jobs in the system, 
denoted by ,~P, can be calculated via equation (11). Using (22) and the condition sp(Rp) < 1, we can 
rewrite this equation in closed form as p/9(P) l N, = i~~p)e + P/9( P)m~j9(P) (1 -R,)- e + z ,=1 m$)g(p)(.f 
-Rp)-2RPe. (37) The expected response time for class p, denoted by TP, is then given by Np/hp. 5 Results 
In this section we discuss the numerical results we obtained from the application of our model for an 
8-processor system. We investigated the effects of various system parameters on the mean number of jobs 
in the system which is a good in­dicator of overall system performance. We focused on three system parameters: 
the mean quantum length, the mean service rate, and the relative quantum length of each class within 
a timeplexing cycle. Figures 2 and 3 show the mean number of jobs in a lightly and a heavily loaded system, 
respectively, as a function of the mean quantum length I/y, In both figures, data have been obtained 
for P = 8, four classes p = O, 1,2,3 and 23-P servers in each class. For each p, the mean quantum length 
I/-yp equals l/~, and the context switch overhead is fixed to 0.01. The mean service rates ~P satisfy 
p. : pl : p2 : p3 = 0.5:1:2:4. For each class p in Figure 2, the mean arrival 18 class O 16 class2 * 
14 12 . 0 10 8 6 4 2 0 12345 6 mean quantum length Figure 3: Mean number of jobs ,\-P versus mean 
quantum length l/v for a system with 8 processors and utilization factor p = 0.9. rate h is 0.4, and 
therefore, the total utilization factor D = ~, Pp = ~p(~p ~g(p)/pP ~P) equals 0.4. For each class p in 
Figure 3, however, the mean arrival rate &#38; is 0.9, and the utilization factor p equals 0.9. Our results 
show that as quantum lengths start increasing from zero, the mean number of jobs decreases very fast. 
As quantum lengths increase past a certain point, however, the curves bend , and the mean number of jobs 
increases monotonically. The heavier the system load, the closer to each other are the knee points of 
the curves. The surprising fact about these curves is that longer quanta result in more jobs in the system. 
This seemingly counterintuitive behavior can be explained as follows. When the quantum length is close 
to zero, the context switch overhead dominates system performance. As quantum lengths become longer, 
switching takes a smaller portion of each quantum, and more time is allocated to Job service. As long 
as the quantum length of a class does not exceed the mean service time of each job in that class, every 
server is busy during its time slice, and it pays off to let it run longer. When the quantum length increases 
way past the mean service time of each job, however, the situation becomes similar to an exhaustive service 
model. where newlv arriving jobs in other job classes keep jumping in until the end of the corresponding 
time quantum. In this case, most of the servers in these classes are idling, and switching to another 
class with a full queue is delayed. Thus, the average number of jobs in the system increases The results 
of our second experiment are shown in Figure 4 which gives the mean number of jobs in an 8-processor 
system as a function of the mean service rate of each server. For each class p, the quantum length l/~P 
equals 5, the ar­rival rate &#38; equals 0.6, and the mean service rate I+ equals p. Our experiment shows 
that the mean number of jobs de­creases dramatically as the mean service rate starts increas­ing. After 
a cert~in point, however, the rate of decrease becomes very low, and there is no significant benefit 
from any further increase in the service rate. Our third experiment studied the mean number of jobs Np 
as a function of the fraction of the timeplexing cycle devoted to the time quantum of each class p. The 
results of this experiment are shown in Figure 5 and were obtained assuming that for every class p, the 
arrival rate &#38; equals 0.6, and that the total utilization factor p is 0.6. Our graphs show that for 
every class, the mean number of jobs decreases \ 4 246810121416 18 20 mean service rate Figure 4: Mean 
number of jobs N. versus mean service rate x for a system with 8 processors. 10 class O  classl ~ class2 
8 class3 6 4 2 n o 0.2 mean qua 0.4 0.6 ntum length/cycle 0.8 time 1 Figure quantum 5: Mlength ean nover 
umber of timeplexing jobs .V P versus cycle length. the fraction of mean monotonically as the quantum 
length of that class becomes a larger fraction of the timeplexing cycle length. Similar graphs can be 
obtained for any specified cycle length, arrival times and service times. 6 conclusion In this paper 
we formulated a general queueing theoretic model of gang scheduling in parallel computing environ­ments, 
and we derived a mathematical analysis of the model. We plan to use our model to maximize the performance 
of gang scheduling in a specific parallel multiprogrammed en­vironment that we are currently developing 
in collaboration with other researchers [27]. The operation of the scheduler in our system is based on 
the general gang scheduling scheme we presented in this paper. The main deviation of our sys­tem implementation 
from our model is that context switches are not necessarily system-wide. As soon as a partition be­comes 
idle in a given class, it switches to the next class, while other partitions of that class may still 
be busy. Extending our model to accommodate these details is potential future work. Nevertheless, our 
current model is still needed to de­termine the optimal length of the timeplexing cycle and the worst-case 
length of each time quantum. References <RefA>[16] A. Lang and J. L. Arthur. Parameter estimation for [1] [2] 
[3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] A. V, Aho, J. E. Hopcroft, and J. D. Unman. 
The Des%gn and Analysis of Computer Algorithms. Addison-Wesley, 1974. S. Asmussen, 0. Nerman, and M. 
Olsson. Fitting phase type distributions via the EM algorithm. Technical Re­port 1994:23, Department 
of Mathematics, Chalmers University of Technology, May 1994. V. D. Cung et al. Concurrent data structures 
and load balancing strategies for parallel branch-and-bound/a* algorithms. In The Thwd DIMA C S International 
Al­gorathm Implementation Challenge on Parallel Algo­rithms, October 1994. E. de Souza e Silva, H. R. 
Gail, and R. R. Muntz. Polling systems with server timeouts and their appli­cation to token passing networks. 
IEEE/ACM Trans­actions on Networking, 3(5):560 575, October 1995. M. J. Faddy. Fitting structured phase-type 
distribu­tions. Technical report, Department of Mathematics, University of Queensland, Australia, April 
1994. To appear, Applted Stochastic Models and Data Analysts. D. G. Feitelson and L. Rudolph. Distributed 
hierar­chical control for parallel processing. Computer, May 1990. D. G. Feitelson and L. Rudolph. Mapping 
and schedul­ing in a shared parallel environment using distributed hierarchical control. In Proceedings 
of the International Conference on Parallel Processing, volume I, pages 1-8, August 199o. D. G. Feitelson 
and L. Rudolph. Gang scheduling per­formance benefits for fine-grain synchronization. Jour­nal of Parallel 
and Distributed Computing, 16(4):306 318, December 1992. W. Feller. An Introduction to Probabihty Theory 
and Its Applications, volume I. John Wiley and Sons, Third edition, 1968. l?. R. Gantmacher. The Theory 
of Matrzces. Chelsea, 1959. N. Islam, A. Prodromldis, and M. S. Squillante. Dy­namic partitioning in 
different distributed-memory en­vironments. In Proceedings of the 2nd Workshop on Job Scheduling Strategies 
for Parallel Processing, April 1996. S. Karlin and H. M. Taylor. A First Course in Stochas­tic Processes. 
Academic Press, Second edition, 1975. L. Kleinrock. Qrseuezng Systems Volume 1: Theory. John Wiley and 
Sons, 1975. A. Krishnamurthy et al. Connected components on dis­tributed memory machines. In The Third 
DIMA CS International Algorzthm Implementation Challenge on Parallel Algorithms, October 1994. A. Lang. 
Parameter estimation for phase-type distri­butions, part I: Fundamentals and existing methods. Technical 
Report 159, Department of Statistics, Ore­gon State University, 1994. phase-type distributions, part 
II: Computational evalu­ation. Technical Report 160, Department of Statistics, Oregon State University, 
August 1994. [17] J. D. C. Little. A proof of the queuing formula L = AW. Operations Research, 9, 1961. 
[18] R. Nelson. Probability, Stochastic Processes, and Queueing Theory -The Mathematics of Computer Per­formance 
Ivlodelzng. Springer-Verlag, 1995. [19] M. F. Neuts. Matrix-G eometrzc Solutzons m Stochastic Models: 
An Algortthmtc Approach. The Johns Hopkins University Press, 1981. [20] S. M. Ross. Stochastic Processes. 
John Wiley and Sons, New York, 1983. [21] R. Schassberger. Insensitivity of steady-state distribu­tions 
of generalized semi-Markov processes, part I. The Annals of Probability, 5(1):87-99, 1977. [22] R. Schassberger. 
Insensitivity of steady-state distribu­ tions of generalized semi-Markov processes, part II. The Annals 
of Probability, 6(1):85-93, 1978. [23] M. S. Squillante, MAGIC: A computer performance modeling tool 
based on matrix-geometric techniques. In Proceedings of the F~fth International Conference on Modellzng 
Techniques and Tools for Computer Perfor­mance Evaluation, pages 411 425, February 1991. [24] H. Takagi. 
Queuetng Analysis A Foundation of Per­formance Evaluation, volume I.: Vacation and Priority Systems, 
Part 1. North Holland, 1991. [25] A. Tucker and A. Gupta. Process control and schedul­ing issues for 
multiprogrammed shared-memory multi­processors. In Proceedings of the Twelfth ACM Sympo­sium on Operating 
Systems Principles, pages 159 166, December 1989. [26] J. Walrand. An Introduction to Queuemg Networks. 
Prentice Hall, 1988. [27] F. Wang, H. Franke, M. Papaefthymiou, P. Pattnaik, L. Rudolph, and M. S. Squillante. 
A gang schedul­ing design for multiprogrammed parallel computing en­vironments. In Proceedings of the 
2nd Workshop on Job Scheduling Strategies for Parallel Processing, April 1996, [28] R. W. Wolff. Stochastic 
Modelzng and the Theory of Queues. Prentice Hall, 1989. [29] J. Zahorjan and C. McCann. Processor scheduling 
in shared memory multiprocessors. In Proceedings of the ACM SIGMETRICS Conference on Measurement and 
Modehng of Computer Systems, pages 214-225, May 1990.  </RefA>
			
