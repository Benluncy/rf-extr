
 Accurate Modeling of The Hybrid Hash Join Algorithm* Jignesh M. Patel Michael J. Carey Mary K. Vernon 
Computer SciencesDepartment, University of Wisconsin, Madison {jignesh, carey, vernon}Qcs.wise.edu Abstract: 
The join of two relations is an important oper­ation in database systems. It occurs frequently in relational 
queries, and join performance is a sigmficant factor in over­all system performance. Cost modek for join 
algorithms are used by query optimizers to choose efficient query execu­tion strategies. This paper presents 
an efficient analytical model of an important join method, the hybrid hash join al­gorithm, that captures 
several key features of the algorithm s performance including its intra operator parallelism, inter­ference 
between disk reads and writes, caching of disk pages, and placement of data on disk(s). Validation of 
the model against a detailed simulation of a database system shows that the response time estimates produced 
by the model are quite accurate. Introduction Relational database systems organize information into a 
collection of tables. The relational join operator is used to relate information from two or more tables. 
Thus, joins are a frequently occurring operation in relational queries. Additionally, joins are one of 
the most expen­sive operations that a relational database system per­forms. Joining two large tables 
can consume a signif­icant amount of the system s CPU cycles, disk band­width, and buffer memory. For 
this reason, efficient join algorithms are a critical factor in determining relational database system 
performance. .4ccurate and efficient join algorithm cost models are also important, as they are needed 
by relational query optimizers (which employ cost-based optimization algo­rithms) in order to derive 
eflicient processing plans for relational queries. Furthermore, simulation is currently used extensi~ 
ely for studying parallel execution strate­gies for complex queries [CLYY92] and for e~aluating strategies 
for handling complex multiuser workloads in centralized database systems [B CL93, MD93]. Most simulation 
studies of parallel database systems have not explored truly large systems (e.g. 100 s of nodes) due 
to the prohibitive costs of simulating such s,vstems in detail. If accurate analytical models could be 
de­\-eloped, such scheduling strategies could be ~~,aluated This work was partially supported by the 
IBM Corpormt,on through a Research Initiation G~-wit, ancl by the NSF Grants CC!R 9024144 and CDA 902461S 
 Permission to copy without fee all or part of this material is granted provided that the copies are 
not made or distributed for direct commercial advantaqe, the ACM copyright notice and the title of the 
publication and its date appear, and notice is given that copying is by permission of the Association 
of Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
SIGMETRICS 94-5/94 Santa Clara, CA. USA 0 1994 ACM 0-89791 -659-xJ9410005..$3.5O more quickly and over 
wider regions of the system de­ sign space, including more realistic system sizes. As a starting point, 
accurate analytical models that capture centralized query performance are required. Our focus here is 
the development of such a model for the hybrid hash join algorithm that was introduced in [DKO+84]. Simple 
analytic cost models for hash based join algo­rithms were first presented in [D KO+84, Sha86]. These 
models only count the total number of page 1/0 opera­tions in the algorithm. A more complete model, recently 
presented in [HCL93], breaks up the cost of perform­ing disk 1/0 operations into various parts and carefully 
counts each part. However, intra operator disk con­tention and CPU costs are not addressed in this model. 
In [LY90], the authors investigated the effectiveness of parallel hybrid hash join algorithms for a system 
run­ning a single join. However, their model of the individ­ual processing nodes is quite simplistic, 
e.g., it does not consider the impact of intra operator disk contention. This paper develops an accurate 
model of the h~-brid hash join algorithm that includes these costs and is nev­ertheless efficient to 
evaluate. We develop an analytical model of the hybrid hash join algorithm for the case of a single join 
operation, implemented using two processes, running on a single node of a database system. This situation 
presents two particular challenges for creating an accurate analyti­cal model. First, the intra-operator 
disk interference patterns are more complex to analyze than the ran­dom interference that typically occurs 
between unre­lated processes, Second, disk seek times are influenced by file placement as well as by 
interference. The model also captures other significant system behavior. such as intra operator synchronization 
and caching of disk pages, which also affects the performance of the algo­rithm. Our model is based on 
the approximate mea~l value analysis. an approach that has pro~ren accurate in modeling parallel architectures 
[VLZ88, WrE90, C!S91]. Specific system eflect,s are captured hy modifying the re­sponse time equations. 
Validation of the model against the simulator used in [BCL93. MD93] shows that the model yields accurate 
results. The remainder of the paper is organized as follows: Section 2 describes the hybrid hash join 
algorithm. Sec­tion 3 describes the analytical model for the hybrid hash join. The results of the validation 
of the model and several other experiments, including a comparison with previous models, are described 
in Section 4. Finally, Section 5 contains our conclusions. Background The tables in a relational database 
system are called relations. Each relation is structured as a set of tu­ ples, with each Luple consisting 
of an ordered list of attributes. A (binary) join operator; one of thp funda­ mental operations in a 
relational database ~yi+em, re­lates tuples from two relations by matching one cmmore attributes of the 
tuples according to some specified con­dition. For example, the condition for the equijoin op­erator, 
by far the most common form of join, is that the attribute values be equal. I arious join algorithms 
have been proposed for per­forming the equijoin operation [ME92, Gra93]. In some cases, the process of 
matching tuples is made faster bv the existence of an access structure, such as a B­tree [Com79], on 
the join attribute of one of the rela­tions. However, in the case of an unanticipated join, or when the 
relations to be joined are both very large, an ad hoc join algorithm is normally used. More­over, as 
database sizes increase, and interest in run_ ning complex decision support queries grows, the im­portance 
of efficient ad hoc join algorithms continues to increase. Sort merge and hash based join algo­rithms 
[BE77, BraW, DKO+84, Sha86] are favored for ad hoc joins. .4. hash based algorithm known as hybrid hash 
has been shown to be particularly effective for per­forming ad hoc joins [DKO+84, Sha86]. The details 
of this algorithm and key aspects of its implementation are discussed in the next two sections. 2.1 The 
Hybrid Hash Join Algorithm Hybrid hash, like other hash-based join algorithms, uses hashing to improve 
the speed of matching tuples. That is, hashing is used to partition the two input re~ations such that 
a hash table for each partition of the smaller input relation can fit in main memory. Corresponding partitions 
of the two input relations are then joined by building an in memory hash table for the tuples from the 
smaller input relation, and then probing the hash table with the tuplw from the corresponding partition 
of the larger input relation, The tasks involved in a hybrid hash join are frequently implemented as 
a collection of processes, particularly in parallel database systems [D G92]. One benefit of doing so 
is that the construction (and later probing) of the hash table for a given join operation can pro­ceed 
in parallel with the reading of the input relations from disk. .4 more substantial benefit, particularly 
for complex queries, is that scalable parallel data flow im­plementations are possible. For example, 
the tasks of reading the input relations and of building/probing the hash table can each be implemented 
as a set of paral­lel processes, with each process running on a separate node. Each process in the set 
performs the same task on different data (e.g.. the data that is stored on its node), passing its output 
tuples to the process responsible for performing the next task on those tuples. In a parallel database 
system. such a multiple process implementa­ tion allows for pipelining between multiple join opera­tors. 
For these reasons, we will focus our attention here on the multiple process implementation of the hy-brid 
hash algorithm. The details of the hybrid hash join algorithm for a centralized database system, or for 
a node of a parallel database system, are as follows. Let R and S b~ th~ two input relationti to be joined 
and let Ili?l and IS I denote the number of pages in each relation. J$rithout, 10SSof generality, we 
assume that IRI < ISI. The smaller re­ lation, R, is called the building relation, and the larger relation, 
S, is called the probing relation. The join is implemented by two processes. a scan process and a join 
process 1. The scan process reads pages from the input relations and passes them to the join process 
via a buffer.z Frequently, join queries also involve selection predicates that restrict the tuples of 
the base relations (R and S) that participate in the join. When such predi­ cates are present, the scan 
process applies the predicates to the tuples of the input relations and only passes on those trrples 
that satisfy the predicates. Let 1? + 1 be the number of partitions of each in­put relation. The join 
process divides the two relations into these partitions and then processes each partition. The execution 
of the join proceeds in B + 1consecutive phases, with each phase having two consecutive opera­tions called 
the build and probe operations. Phase O is illustrated in Figure 1. In the first part of this phase (phase-O-build), 
the scan process scans the pages of the building relation R and applies any selection predicate. Tuples 
that satisfy the predicate, and are thus eligible for the join, are buffered and passed to the ,join 
process in page-size chunks. The join process reads the pages from the buffer and hashes each tuple to 
a value between O and B. Tuples that hash to the value O are inserted into an in memory hash table. Tuples 
that hash to the values 1..B are written to a page-sized output buffer that is allocated for that partition. 
Each of t,he parti­tions, 1..B, has a file on disk (called a bucket file ) to which the corresponding 
output buffer page is flushed each time it becomes full. In the second part, of phase O (phase-O-probe), 
the ~can process scans the probing relation S, applies any selection predicate, and writes the selected 
tuples to the buffer. The join process reads pages from the buffer and applies the same hash function 
used in phase-O-build. If a tuple hashes to the value O, the join process probes the in memory hash table 
for matching tuples and outputs any matching tuple pairs; these constitute the result of the join. The 
join process writes tuples that hash to the values 1..B to the appropriate output buffer pages, which 
are flushed to corresponding S bucket files on disk when full. .&#38;t the end of phase-O. the R and 
S tllples in partition .Ictltzdly. the join is usually implemented by tbww processes a 5cz11 pmress 
for each of tbe input relltlons znd a Join process, HrNv. ever, tbc two scan processes are USWI serIcLlly, 
He,,~e, ~Ol]~eptll~ilY Xnd for tbe l>,,,.rl, )s(s of model in p,. .J~e C.T1. tre.lt tlua two .,.1,, p,. 
oc. e,, e, as 2 single process with a Syncbronlz ation step In the mldclle. 2FOL an ,mple, nentatton 
of tbe bvbnd basb join on a parallel d~tzbzse m:wblne, tbe JOLn mcl wan processes n13.y be on dlffer(,nt 
nodes h tlmt c,w,e. tbe I]tlff e,.is used for sending .wld L-eceiv]ng pages over the network, Ohave been 
joined and the remaining tuples are waiting in appropriate pairs of bucket files on disk. In each of 
the remaining B phases, the corresponding partitions of the building relation R and the probing relation 
S are joined by the join process. Each phase-i (1 < i < 1?) has two parts, phase i build and phase i 
probe. ln PhaSe i build, the join process reads the it~ partition of the building relation R from disk, 
one page at a time, and builds an in memory hash table containing its tuples. The join process then moves 
to phase i probe, where it reads the it ~ partition of the probing relation S one page at a time. For 
each tuple in the partition, the join process probes the in memory hash table for matches, and it appends 
any matching tuple pairs to the result of the join. Build Phase O Build Probe The In Memow L  1 Phase 
O Probe Figure 1: Phase-O of the hybrid hash join. It should be noted that if the hash junction used 
by the join results in a non-uniform distribution of tuples across the B + 1 partitions, then some partitions 
may not fit entirely in main memory. This may happen if the hash function is imperfect or if the values 
of the join at­tribute in the building relation R. are skewed. To handle most such cases, the database 
system typically allocates a few extra pages to the hash table (i.e., it plans for a small number of 
overflow pages when deciding how many partitions are needed). Techniques for handling more significant 
data skew while joining two relations are discussed in [Sha86, KNT89]. The model developed in Section 
3 assumes that no partitions overflow, but it could be extended to model overflows if desired. 2.2 Salient 
Aspects of the Algorithm In this section we discuss several special characteristics of the implementation 
of the algorithm that must be considered when constructing the model. First, the bufler that is used 
for passing pages between the scan and join processes (illustrated in Figure 1) is of finite size. As 
a result, in phase O, the scan process must block whenever this buffer is full. Furthermore, the scan 
process can never get more than N pages ahead of the join process (where N is the size of the buffer 
in pages). Second, to reduce the cost of sequential reads, disks often have a disk cache for prefetching 
data. With a disk cache of size K, a disk read can prefetch up to K sequential blocks of additional data 
when processing a read request. Subsequent sequential reads will find the requested data in the disk 
cache and will not have to actually perform a disk 1/0. Furthermore, in current systems, disk scheduling 
is done by the operating system (which does not know which pages are available in the disk cache). Thus, 
all read requests will actually queue for the disk, but requests that are serviced from the disk cache 
complete quickly once the read request is issued. (Future disk controllers may become responsible for 
disk scheduling and may eliminate the unnecessary queueing.) Third, the placement of files on the disk(s) 
can have a significant effect on the execution time of the join. If the input relations (R and S) and 
the temporary bucket files are on the same disk, then typically the input relatio~~ are read from one 
cylinder while the bucket file pages are written on another cylinder. Compared to the case where a separate 
disk is used for the bucket files, when a single disk is used the disk seek times can be highly non-uniform 
and the disk arm may experience a lot of movement in phase O. Specifically, read requests that do not 
have intervening write requests will have much smaller seek times than read requests that occur imme­diately 
after an intervening write request. The same holds for write requests with and without intervening read 
requests. Thus, interleaved read and write requests increase each other s service times.3 , -Queuing 
delay -. Figure 2: The Read/Write Interference Patterns. Finally, when the R and S data files and the 
tempo­rary bucket files are on the same disk, particular 1/0 interference patterns occur between the 
scan and join processes in phase O. These interference patterns are illustrated in Figure 2. Recall that 
in phase O, the scan process repeatedly reads a disk page, applies a selection predicate to the tuples 
on the page, and then writes the selected tuples to a buffer. Thus, the scan performs very little computation 
between two disk read requests. This implies that when a write operation queues be­hind a read request, 
it will cause the next read request (which will arrive vay soon after the write i. initiated) to queue 
for nearly the entire time of the write opera­tion. Furthermore, the read request behind which the write 
queues is likely to be a read miss, because read hits have negligible service times. In addition, since 
the scan process is 1/0 bound, the write operation that 3From this description, it would seem advantageous 
to use a sepa­ rate disk for the temporary bucket files, thereby avoiding interference between the disk 
reads and writes. However, with current technologi­ cal trends, a data placement strategy that fully 
declusters *1 I (except for very small) relations across all available disks actually achieves the best 
performance [MD]. queues behind the read miss is likely to queue for most, of the read access time. 
This scenario is depicted in Figure 2(a). Figure 2(b) shows the case where a write arrives at an idle 
disk; the write request will also cause the next read request (a read--hit or a read miss) to queue for 
nearly the entire write access time. 3 The Analytical Model This section develops an approximate mean 
value anal­ ysis (MV.4) model of a single hybrid hash join query executing on a stand-alone system consisting 
of a Singk? CPU and a single disk. The specific behaviors of the processes discussed in Section 2.2, 
such as their 1/0 in­ terference pattern and the non-uniform seek times, are captured by modifying the 
MVA response time equa­ tions. Two models, a process model and a system model, are used to define the 
behavior of the join. The process model is used to capture the overall synchronization be­ havior of 
the processes as they move from one phase of the algorithm to the other, while the system model rep­ 
resents the physical resources in the database system as service centers in a queueing network. 3.1 The 
Process Model The process model represents the process structure (i.e., the phase behavior of the scan 
and join processes) in the algorithm s implementation. Both processes are simul­taneously active throughout 
phase O of the join. As explained in Section 2, the scan process performs the disk reads and does some 
computation on the tuples in the pages read, while the join process performs other computation on the 
pages received from the scan and occasionally writes data pages to the disk. The two processes are modeled 
as two customers in the queue­ing network model, each in a separate class, switching classes as processing 
progresses from the build phase to the probe phase. The class switching, illustrated in Figure 3, is 
necessary so that different resource require­ments can be specified in the different phases. In phases 
1..B, only the join process is active, and there is no inter­ference from other customers; the time spent 
executing these phases, denoted by D5 and De, can be computed by simply summing their resource requirements. 
k Phase-O-BuildPhase-O-Probe Phase-i-Build Phase-i-Probe Scan/ Reader class 1 class 3 Join/ Join/ 
Class 2 class 4 class 5 class6 writer Reader Figure 3: The process model. To determine the overall 
response time (i.e. execution time) for the join, we use the system queueing network model described 
in the following section to compute the mean response times for classes 1 through 4, denoted by RI ...R4. 
The overall mean response time of the jc,in (R) 4For systems with multiple queries ancl/or transactions, 
of course, the join proces~ would experience i,,terfere,,ce in these ~1, ases. Thue. the custome~-,-epresenting 
the join process would cycle in the queue­ ing network during these phases, whereas the customer represe*lfii,,gtile 
scan process would visit a delmy centek-to represent its period of inactivity. The meal} time Lt the 
delay centel WIJUICI be c~,,,p~ted from an iterative solution of the overall model, is then estimated 
by R = max(R1, R2) + max(Rs,Ra) + D,s + DO (1) We note that the overall mean response time (1?) is an 
approximation, as each of the first tv,o terms is t,he max. imum of two mean response times (and not 
the mean of the maximum response time). 3.2 The System Model The system that we are modeling consists 
of two re­ sources, a CPU and a disk. The simple queueing net,­work model that represents the system 
is shown in Fig­ure 4. The delay center in the network represents time during which either the scan process 
or the join process blocks due to synchronization on the buffer that they use to communicate. A similar 
approach was used to model synchronization delays in [HT93]. The scan pro­cess blocks if the buffer is 
full, whereas the join process blocks if the buffer is empty, as described in Section 2. Since the processes 
are fairly tightly synchronized (i.e., the size of the buffer is assumed to be fairly small), we assume 
that in fact both processes complete almost, si­multaneously. We thus determine the mean time at the 
delay center for the faster process by iteratively solving the model and setting this value to the difference 
be­tween the estimated mean execution times of the two processes. For example, in a phase where the join 
is the faster process, a synchronization delay is added for the join; this delay is set to a value that 
makes the over­all mean response time of the join the same as that of the scan. The queueing network 
model is solved using approximate MVA techniques [RL80, LZGS84]. To cap­ture the specific interference 
patterns and service times of the customers at the disk, we create customized re­sponse time equations 
for the disk requests. These cus­tomized equations are presented in Section 3.3.2. Scan Process Join 
Process Synchronization Delay ~ -. . ... -.. - . . - R CPU Disk Figure 4: The queueing network model. 
 3.3 The Queueing Model Equations The inputs to the model, shown in Tables 1 and 2, con­sist of the system 
hardware and the software parame­ters. The seek factor mentioned in Table 1 is a con­stant that, when 
multiplied by the square root of the seek distance (in cylinders), determines the seek time in milliseconds 
[B G88]. The settle time is the average time that it takes for the disk arm to settle over the appropri­ate 
cylinder after a seek. When the hash table of a par­tition of the building relation is formed, some additional 
memory is required due to data structure overhead (i.e., this is additional memory beyond the space required 
to simply hold the R tuples of the partition). The hash factor in Table 2, Fha.h, gives the factor by 
which the memory allocation is expanded. In other words, when 59 multiplied by the number and size of 
the tuples in the R partition being built, this factor gives the total amount of memory required for 
holding the partition s hash ta­ble. (Note that Fh,fl,,l, is sometimes referred to as the fudge factor 
in the database literature). Si~etVULein Table 2 gives the size of the R and S tuples in bytes. In general, 
of course, the tuple sizes of relations R and S will be different; for simplicity, we assume here that 
the two relations have tuples of the same size, though generalizing the model in this regard is straightforward. 
The meanings of the remaining parameters should be clear from t~eir descriptions in ~he tables. Parameter 
MIPS rating of the CPU Main memory size (in pages) Size of a page (in bytes) Seek factor Num. of pgs. 
fetched by a disk read (incl. the requested and prefetched pgs) Maximum rotational latency Transfer rate 
Settle time Table 1: Hardware Input Parameters. Meaning Extra space required by a hashed tuple #instr 
to initiate a page send #instr to initiate a page receive #instr for applying the select predicate to 
a tuple #instr for inserting a tuple into a hash table #instr for probing the hash table once #instr 
for a byte copy #instl for starting a disk 1/() Size of a tuple (in bytes) Size of the building relation 
(in pages) Size of the probing relation (in pages) Table 2: Software Input Parameters. 3.3.1 Estimating 
The Mean Visit Counts for the Queueing Network In this section, we derive the mean visit colmts for the 
resources in the queueing network using the parameters presented in the previous section and the algorithm 
description of Section 2.1. Let: IRo I = the size (in pages) of the in-memory portion of R during phase 
O IR I = the number of pages of R that are written to the disk [s [ = the number of pages of S that are 
written to the disk B = the number of buckets for each input relation excluding the in-memory bucket, 
In terms of these quantities, the numbers of visits to the CPU and disk for each customer class are given 
in Ta­ble 3. Note that the number of visits by class c to center k is denoted by b~,k, where k is either 
the CPLT or the disk. Table 3: Visit Counts for the Queueing NIodel, For the workloads considered in 
the simulation exper­iments that we have used to validate the model, all of the R and S tuples participate 
in the join, i.e. the se­lection predicate applied by the scan process does not eliminate an,y tuples. 
In this case. IR I = IRI -]Rol The values for the quantities IR. ] and ]S \ are com­puted as follows 
[Sha86, HCL93]. During the processing of partition O, the building relation R has to be scanned and B 
buckets of relation R have to be written to the disk. If we assume one input buffer for reading R and 
one output buffer for each of the B buckets, we have S%ze~..,, B 1 pages for holding the hash table 
for partition O of R. In phases 1..13 of the algorithm, we will have Size ~D~Tn 1 memory pages for holding 
the hash table (with one page being reserved for the input buffer). Thus, taking hash table overheads 
into account, the optimal value of B will he the smallest value satis­fying the equation: Size~em B 
 1+B x (Szze,n,ri 1) ~ IRI x F},.~l, which yields Assuming that the fraction of tuples in S that hash 
to buckets 1 through B is the same as the corresponding fraction of tuples in R, IS(I = [151 x Ml 3.3.2 
Disk Response Time Equations To reflect the read/write disk interference patterns and the non-lmiform 
average seek times described in Section 2.2, we modify the standard NI1~.\ response time equations for 
the disk as described below-. The notation used in this section is given in Table 4. TI1,,lt, includes 
the average rotational latency the settle time, and the time required to transfer a page cluring a disk 
write. Since a disk read miss reads a to­tal of Fl,, ~~ pages, the transfer time in T~,o ~ represents 
the time for transferring all of these pages. Since ~ represents the number of read misses in the phas~~~j­ 
build, ~ represents the ratio of writes to read misses in this phase. R(LttOw represents the fraction 
of write re­quests that incur extra seek time due to an interfering read miss. .4gain, since the scan 
process is 1/O bound, Symbol T1tJ, zic TR.<,<l w Ratiow Ratiog Ratio% fcw See~+O_B Seekd_o_l, Seekclw 
Meaning Value 1 Average disk accesstime for a write (excluding seek time) * + Tsettl, + T.fer ~ Average 
disk accesstime for a read-miss (excluding seek time) + ~,ettk + ,fe T x Fpref 2 lR /x F,,, ,f Ratio 
of writes to read misses !Rl fraction of write requests that find the arm over the read cylinders rnin 
(l,+) fraction of read requests that find the arm over the write cylinders min(l. d) lR 1 # writes between 
two reads lFi­ mm[o,m-1] Fraction of writes that occur consecutively Tmz[o>ti-1]+1 Average seek time 
of an interfered disk request in a Phase-O-Build ~.4V~seekPh_O_B X Fs.,~ Average seek time of an interfered 
disk request in a Phase-O-Probe JAvgSeekPl, _O-~ x Reek Average seek time seen by consecutive writes 
in a Phase-O ~.4vgSeekcw x F,,.k Table 4: Notation for the Disk we assume that writes are interleaved 
with reads in an approximately uniform way. If ~ > 1, there is (on aver­age) more than one read miss 
between two writes. Since only the last read-miss interferes with the write, we take the minimum of ~ 
and 1 in computing ratiov. Simi­ larly, Ratio% represents the fraction of read miss re­quests that incur 
extra seek time due to an interfering write. Furthermore, since most writes cause a read to queue (recall 
Figure 2), Ratio% represents the frac­tion of read requests that have to queue behind a write request. 
Note that Ratio% is always less than one since the number of reads always exceeds the number of writes. 
If the number of writes exceeds the number of read misses, there will be sequences of writes that are 
not interfered with by read misses. However, these writes are to random bucket files, as opposed to consec­utive 
read operations, which are sequential. Thus, ~CIV of the writes incur a relatively low seek cost equal 
to Seekcw. TO explain the last three terms of Table 4, We must consider the particular placement of data 
on disk. For the experiments in Section 4, we will assume that the building and probing relation files 
are laid out on the disk in file groups as shown in Figure 5. A file group consists of a collection of 
files of the same size, ancl input relation files are randomly picked from the files in their file group. 
Thus, the building relation R is randomly chosen from the building file group while the probing re­lation 
S is randomly chosen from the probing file group. The bucket files produced during the join are written 
at the end of the disk. Knowing the layout of the files, the average seek distances for interfered disk 
requests can be estimated as indicated in Figure 5. For phase­O build, the estimated seek distance includes 
half of the cylinders in the building file group, all of the cylinders in the probing file group, and 
half of the cylinders used for the bucket files. For phase-i, the average seek distance is estimated 
as ~ of the total number of cylinders used for writing the bucket files [B G88]. (Although here we assume 
detailed knowledge of the data layout, we will show later that the model is quite accurate even when 
knowledge of exact file locations is not assumed.) Given the notation and calculations described above, 
the disk response time equation for phase-O-build is de- Response Time Equations. mHle group for the 
building relabon (R) ~cfifefi live wrtes UFlle group for the probing relatlon (S) in Phase-O U eucket 
Hles (parttt!on 1.,N) (AvgSeekcw ) Figure 5: File layout and average seek distances. rived as follows. 
First, the average time that it takes to service a read miss is: $,adM~S~ = T~,ad + Ratio% x Seek@ -o-~, 
(2) where TRead includes the rotational latency, settle time, and transfer time, and the second term 
represents the average seek time. Similarly, the average time that it takes to service a write request, 
including the seek time for consecutive writes, is: S, r,,te = TwTzt, + Ratio% x Seekd_O_B +.fcw x Seekcw 
(3) We can now express the disk response time equations for classes 1 and 2, in terms of S.~~dMt~$ and 
SWr,t,, as follows: &#38;.dMas. R1,Dt3k = + Ratio% Fpref R2,Di,k = s,ti~itr + Ratto~ x Both response 
time equations have time required to perform the disk 1/0, spent waiting in the disk queue. The of a 
read at the disk in equation ( 4) x S,.T,,, (4) SreadMqss (5) two parts: the and the time queueing time 
is estimated as Ratio% x Sw.it, because most writes cause a read to queue (refer to Section 2.2). Ratio% 
gives the fraction of reads that queue behind a write, while Slo.,t, gives the queueing time of such 
read requests. Similarly, in equa­tion 3, RatioW x smdMtss gives the average queueing time of a write 
at the disk. Disk response time equations for classes 3 and 4 in phase-O-probe (R3,Di,k and R4,D;5k ) 
can be derived sim­ilarly. The only changes required are using ISI instead 61 of 11? and IS I instead 
of II?] in computing the ratios, and using seek~ o p instead of Seek@ _O B. Since phase i consists only 
of disk reads that are largely sequential, the mean phase i disk response times can be estimated as: 
T,,.d (6) 5 D2 L = G D sk = FPr.f  3.3.3 Per Visit CPU Service Requirements To compute the CPU service 
requirements, we first calculate the number of tuples per page as: (7) Using this and the other input 
parameters listed in Tables 1 and 2, the per visit CPU service time require­ments can be expressed by 
the following equations: % ;c:Pu = R;;CPU = (Nt.,t.. x Szzet~p~, x I.~Pv) /JJIPS + (Ntupl,s x IseI + 
1,,.d) /MIPS R;;cpu = (~w + Ntup[,s x (~s,~ + 1~.s~)) /MIPS R~ >pu = (Ltart~o + Ntuptes X (~set + ~tiasti)) 
/J.JIPS The service requirements R~~Cpu and R~~Cpu are similar to R~~c,pu and R~~Cpu, respectively, with 
the only difference being that the term 1/,.$h is replaced by &#38;Ob, 4 Validation of the Model In this 
section, we first evaluate the accuracy of our base analytical model by comparing it against a detailed 
simulation of a database system. ~ e then describe the results of several experiments where we change 
some of the model assumptions. Finally, we compare the model with two previous models and highlight the 
differences in their accuracy. 4.1 Simulation Model The simulator that we used for validating our analytical 
model, ZetaSim [Bro92], is a detailed simulation model of the Gamma parallel database machine [DGS+ 90]. 
For the purpose of validating the analytical model, the sim­ulated system is configured with a single 
node consist­ing of one CPU and a 1.2GB disk, which is similar to the configuration used to study memory 
management issues in [B C!L93]. The parameter settings of the sim­ulator are listed in Table 5. The parameters 
for the disk closely match the characteristics of a Fujitsu disk model Iv12266, while the instruction 
counts are largely based on measurements from the Gamma database ma­chine implementation. The simulation 
model includes details of data placement, buffer management, the el­evator disk scheduling algorithm, 
disk cache behavior, and so on [Bro92, BCL93]. For validation purposes, the relations were laid out on 
the disk in two file groups, the building and probing groups, as assumed in the analytical model (see 
Fig­ ure 5). We varied the size of the relations in the file groups while keeping the total size of each 
file group at Tuple size (in bytes) 200 Hardware Parameters Value Mips rating of the CPU 20 MIPS Page 
size (in bytes) 8192 Main memory size (in pages) 4096 Size of buffer between the join and the scan processes 
8 pages Disk size 1.2GB .Additional number of pages prefetched by a disk read 4 Seek factor 0.617 L laximum 
rotational latency time 16.667 ms Transfer rate 3.09 hlB/sec Settle time 2.0 ms Algorithm Cost Parameters 
Value Hash factor 1.2 # instr to initiate a page send 1000 # instr to initiate a page receivo 1000 # 
instr for applying the select pred. 300 # instr for inserting a tuple into the hash table 100 # instr 
for probing the hash table 200 # instr for a byte copy 1 # instr for starting a disk 1/0 1000 Table 5: 
Simulation Parameters. 0.5 GB. Since the largest relation that we evaluate has 500K tuples (= 100MB), 
the configured disk of size of 1.2GB was sufficient for joining the relations. The sys­tem workload consists 
of a single join query which ran­domly chooses its building and probing input relations from the corresponding 
file groups. Workloads similar to this were used in [B CL93, MD93]. 4.2 Results of the Validation In 
our initial model validations, we let the build and probe relations be of equal size. The graphs in Fig­ures 
6 to 9 compare \arious measures estimated by the analytical model and by the simulator as the size of 
the relations is varied. A key point, to note in each of the graphs is that there is a discontinuity 
in the curve at the point where the build relation becomes too large to fit in memory (i.e., just after 
100K tuples). Figure 6 gives the overall join execution time predicted by the model and by the simulation, 
showing that the overall predictions of the analytical model are highly accurate. Looking at a more detailed 
measure, Figure 7 shows that the qualitative behavior of the mean response time for disk write operations 
in phase (I is also accurately predicted by the analytical model; however the model overestimates the 
mean write response time in the probe part of phase O for relation sizes that are slightly larger than 
the allocated memory. The reason for the model overestimating the write times for these relation sizes 
is as follows. In the response time equations for the disk (equation 3), we assumed that the queueing 
time of a write behind a read miss is nearlv the same as the read access time. This is not entirely true 
foI small re­lations; small relations have few buckets and hence do + + sim lat~,-(bui]d) ~ 800-w - 
100.0 a 30.0~ a + + Simulator [build) ---Our model (bui]d) * % Simu]awy ; % ; 700 (n 27.0 .--: Our 
model (build) k X Simulator (probe) -. E = 60.0 X X Simulator (p~-obe) E _ r>---<> O r model (p,-obe) 
. g 600 .G 24.0 . fi 0---0 Our model (probe) + 2 L g 21.0 ~ 60.0 -­500 1­ !,, , fe.o 400 \ 4 ..._ 
 15.0 300 40,0 - 0.. --.: .........­. . ..-. ---12.0 200 . 20,0 -­ 9.0 100 0 IIII 1 o.o~- 3.0 0 
100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500 Relation sizes (in #Ktuples) Relation 
sizes (in #Ktuples) Relation sizes (in #Ktuples) Figure 6: Join Execution Time Figure 7: Disk Write Time 
for Figure 8: Disk Read Time for (/R/ = /s1) Phase-O (IR] = /S1) Phase-O (IRI = /S1) 6.4 m 1200 + + 
Simul;mx 8 $ x * Simulator o ---our ,,,,,dd % ~ 1100 E 56 0.--0 Our model % % Sh&#38;pil [] Y !modd 
r :--- . Our model ,5 *000 ~,--. HaWCw cy/L!vny model 900 x F 800 ,/ &#38; 700 / ,, 600 ,+ ,, ~ ,,? 
 jL : __ 500F / 100 200 300 400 500 SW 0 100 200 300 400 500 Relation sizes (in #Ktuples) Relation sizes 
(in #Ktuples) Relation sizes (in #Ktuples) Figure 10: Join Execution Time Figure 11: Join Execution TimeFigure 
9: Disk Read Time for With Inner Relation Size of 250K of Various Models Using One Phase-i, 1< z ~ ~ 
(IRI = ISI) (IRI = ~50K, ]Sl varied) Disk (IR] = ISI) In ,J 900 ,K X Shapmo s model ~oo+ + Simulator 
~ g ;<. --X HaaslCareylLlvny model ~ ,----Our model % m 800 K ./ c :OuI . model A % Shapiro s model 
; 700 ~ I --/ HaasfCareylLivny model . E* 3+ 200 E­ + F 600 500 A ,,, % 400 . .­* * 100 300 % , % 
~~ 200 [:OL + 100 %; ,/. + 0 ILo --- 0 100 200 0 100 200 300 400 500 100 200 300 400 500II Relation 
sizes (in #Ktuples) Relation sizes (in #KtUpleS) Relation sizes (in #Ktuples) Figure 12: Join Execution 
Time Figure 14: Percentage Of Time Figure 13: Join Execution Time of Various Models Using One Spent 
At The CPL When Using a of Various Models Using a SePa­ Di~k (IRI = ISI); blown up ver-Separate Bucket 
File Disk (IR[ = rate Bucket File Disk (IRI = Isl) sion of the lower half of Figure 11 1s/) 63 rela,tivel~ 
few writes per read. In this case, the join may process manl-pages before filling up on~ of its output 
buifers, and the resulting write Inmy therefore arri~-e sig­nificantly after the start of the read access. 
Thus, the difference in time between the arrival of a read miss and a write may be much greater for small 
relations than for larger relations. However, it is not necessary to derive a more complex expression 
to correct, this discrepancy in the model for these relation sizes the scan process is slower t,han 
the join process, so the scan determines the o~erall mecution time. Mean disk read response time is modeled 
accurately for the scan process at all rela­tion sizes (as discussed next ). For larger relation sizes, 
the join process is the slower process and determines the overall join execution tim~: in this case. 
the mean disk write response times are accu~ate. as can be seen in Figure i . .1s shown in Figure 8, 
the mean response times pre­dicted by the model for disk read operations in phase-(1 match closely with 
those of the simulator over the entire range of relation sizes examined. The match is particu­larly close 
for smaller relation sizes, where (as mentioned above) these read response times partially determine 
the total mwcution time. Finally, Figure 9 shows the mean response time for read operations in phases 
other than phase 0. The model assumes that reads are sequential and hence estimates a constant read time 
for phase i (see equation 6). Howe\rer, the reads of the bucket files may involve small seeks, as the 
pages for the bucket files are allocated by the simulated system in extents. These extents may not be 
contiguous, leading to occasional inter extent seeks that our analytical model does not account for. 
To test, the robustness of the model, we carried out a few additional experiments where we changed some 
of the model s assumptions. In the first of these experiments, we modified the as­sumption of ho~v files 
are laicl out on disk (refer to Sec­tion 3.3). While the data for the base relations in a complex multi-join 
query may be laid out in a particu­lar known fashion, the location of intermediate relations created 
during multi-join query processing may not be known a priori. For this experiment, the building and probing 
relations are again assumed to be of the same size, but are selected randomly from a s~,n~lefile group 
of size 1 GB, which is again populated with relations of the specified size. The modifications required 
in the analyti­cal model are in the seek times used in the disk response time eqllation in ~hase O (equations 
2 t,hrough 3). In this case, the arm seek in each part of phase O is equal to the average of the values 
that we used previously for phase O build and phase-O probe (i.e., Seekd o B and Seek@-o_ p). The join 
execution times predicted by the model for this experiment matched the simulation es­timates even more 
closely than in Figure 6. Since the curves are very similar to those in Figure 6, and space is limited, 
we do not include the graph here. In the experiments thus far, the building and prob­ing relation have 
both been of the same size. We now present an experiment where w( ~ ary the relative size of the building 
and probing relations. For this experi­ment. we used building and probing tile gr ouph of the same size 
(about O.5 GB each). We fixed the building relation size to 250K tuples (50 LIB). which is consid­erably 
larger than the size of the main memory hash table. and varied only the probing relation size. Fig­ure 
10 shows the join execution times from the model and the simulator; the x axis in this graph represents 
the size of the probing relation (S). .4s can be seen from the graphs, the predictions of the model are 
again in close agreement, with the results of the simulatm. 4.3 Comparison With Previous Join Cost Models 
To furthel illustrate the value of our relatively complete analytical model, we next compare this model 
with two previous hash join cost models. We use the same pa­rameter values for all of the models, namely 
the values listed in Table 5, and we let the two input relations have equal size for these experiments. 
The first model for comparison is the one proposed by Shapiro [Sha86]. Using the notation defined in 
this paper and letting 10 denote the average time for an 1/0 reclrrest, and q denote the ratio ~, the 
hyblid hash cost derived in [Sha86] is: costs = (]RI+ 1s1)x Ntupk!sx Ihu,h+  + (\Rl+ Is l)x Ntupk.x 
(1 q) x I copy x Sa.zetuple + 2x(lRl +lsl)x(l-q)x Io + (IR + ISI) x ~tuple<, x (1 ~) x J/t. s17 + 
IRI x Nt~pl.. x I~Opy x st~etuple  t 11$[ x Nttipies x F Lash x IP~obe (8) Because the costs derived 
in [Sha86] were used for con­paring alternative ,join algorithms, they did not include the 1/0 costs 
for reading the base relations (which were the same for all join algorithms). To reflect the total cost 
of the join, we add this additional cost, (Il?l + ISI) x 10, to the above formula. Also, to be precise, 
we compute IO to be the arithmetic mean of the following two quan­ tities: Tr,.d + ~ total # cylinders 
x F~t,L IOR..d = FPref (9) and Io~r=Tw+- ~ 0) The other model that we compare our results to is the 
one recently developed by Haas et. al. [HCL93]. This model, which we shall refer to as the HCL model, 
estimates the cost of the join by computing the num­ber of seeks (N.), the number of (possibly multi-page) 
1/0 s (Ntu), and the number of page transfers (NZ ), and then multiplying each of these counts by the 
cost of the corresponding action (T., T,O and T,). The HCL model has input parameters for the size of 
the input and the output buffers. Since four pages are prefetched by the (lisk on every read (refer 
to Table .5), we set the input buffer size to five5. The output buffer size is one. LTsing the notation 
in Table 5. the various terms in the HCL cost model are computed as follows: TJ = 2.52 rrIS(T= fe,. = 
3.09 Jib/s, SzzeJ,og, = 81:B) Trot  T,O= ~ (11) N. = IRI+ Isl+2 xIR I+2 xIs A )o = gl +pl +@ +pl +B+&#38; 
 ,+,!E, +[E!, +2XB 1V5 n 1  The cost of the join, ~ost~~~L, is then given by­ ~o.~tff~L = Nz XT. + 
N,. x Tzo + AT, x T,; The results of the three models for \ arious input re­lation sizes are shown in 
Figures 11 and 12. .4s can be seen from equation 8, the disk cost in the Shapiro model is based solely 
on the number of pages transferred from the disk. The effect of interference between reads and writes 
is not considered. Also, a simple average 1/0 cost is used in the model: the model does not account for 
sequential 1/0s. .As a result, the Shapiro model over­estimates the join cost. The HCL model treats the 
disk costs more carefully than the Shapiro model. However, since it does not consider the effect of intra 
operator contention, it ends up under-estimating the cost of the ,join, as shown in the figures. Note 
that the error in the Shapiro model is 193% at relation size 100, and that the absolute error increases 
for relation sizes beyond 150. Note also that the error in the HCL model is as nigh as 38X (at, relation 
size 150), and that the absolute error increases (gradually) as the relation sizes increase. The reason 
that the HCL model does not ccmsider interference between reads and writes is that they as­sumed (for 
simplicity) a disk configuration in which the bucket files are on a separate disk from the base relation 
files (R and S). In the next experiment, we adapt our model to this configuration and again report the 
com­parison. Here we will assume that the base files are held on a 1GB disk and that the bucket files 
are written to a separate 200 MB disk. The cost, formula for the Shapiro model here is simi­lar to the 
one used in the previous experiment, except that we now use the total number of cylinders in the 200NIB 
disk for computing the seek time in ~(]rt ~tt~ (equation 10) and the total number of cylinders in the 
lGB disk in computing l~Re,,d (equation 9); the two are then averaged, as before, to compute the average 
1/0 cost term. Similarly, for the HCL model, the number of cylinders in the 200MB disk was used in equation 
12 for cornpllting the swk cost T,. 5Tbe HCL model does not consider disk caching precisely, but set­ 
~mg the Input buffer SIZQ to five models tbe effect of wading five-page blocks The changes required 
for our own model in this case include setting SeekCL~,to represent, t,he average seek for the writes 
on the 200i v~Bdisk and removing the queue­ing terms from the disk response time equations, yield­ing 
s,p~d~l,s, = TRea~ Suv-?tc = T1,rrlff + 1.0 X SeekrIi SreudM1ss R13D,,k = Fl,,ef R2,D,8k = S,,,rlte 
The results of this final comparison are shown in Fig­ure 13. The Shapiro model behaves in the same way 
as before, while the HCL model and our model match surprisingly closely. One would have expected the 
join times estimated by the HCL model to be lower than the join times of our model, as the HCL model 
does not include CPU costs. LIoreover, as shown in Figure 14, which plots the CPU cost for performing 
a join as a percentage of the total join execution time, the CPU cost can be significant. 6 (The CPU 
cost that con­tributes to the total join execution time in our model is estimated in Figure 14 by adding 
the CPU costs of the slower process in each phase. ) Another modeling differ­ence, however, is that the 
HCL model does not consider the intra--operator parallelism that arises here with two processes (joins 
and scans) being simultaneously active in the system. As an example, in counting the number of 1/0s (N,o), 
the HCL model adds together the 1/0s for reading the building relation ( (W1 ) and for writ­ing the bucket 
files ( [91). However, these 1/0s could be occurring in parallel, as they are issued to different disks. 
Our model captures the intra operator paral­lelism by separately accounting for the two processes (the 
joins and the scans) and using the process model to predict the final execution time. For the system 
pa­rameters used here, the HCL model s overly high 1/0 cost estimate, due to not considering the intra 
operator parallelism, seems to offset its lack of a CPU cost con_­ponent. .5 Conclusions and Future Work 
In this paper we have developed an analytical model of the execution time for the hybrid hash join algorithm 
in the case of a single join running stand-alone on a sin­gle node. Even this simple case required that 
complex behavior be accounted for, including intra-operator disk interference patterns, disk seek times 
that are influenced by file placement as well as interference, intra-operator synchronization, and caching 
of disk pages. Through comparisons with results from a detailed database sys­ tem simulator, the model 
was shown to be highly ac­curate -not only in predicting overall join processing The CPU contributions. 
shown in Figure 14. are bigb fol-joins of small l-elations because the building relation C,MI be held 
entirely in memory. Since tbe reads are sequential and not Interfered with In this case. the cost of 
recdi,,g a pagQ ], qmall: the CPLJ time tl,txs becomes compal.able to tbe disk tlnle, Beyond a sw,e of 
100K. however, the hllilding relztion is too big to fit In memory mid bucket writes fire incurred Since 
writes take longer than re~ds, the contribllt ian of the ( PU cost as n percentage of tbe total join 
rest tbeu decre.wes 65 times, but also for more detailed performance measures such as I/0 res~onse times. 
The model was also shown to he more accurate than previously published join cost models. It is interesting 
to note that, in the course of devel­oping and validating the analytical model, various as­sumptions 
that were made implicitly when building the simulator were exposed and reexamined. In some cases, the 
simulator was modified as a result of these reflec­tions. As one example, the simulator initially assumed 
that the buffer used for communication between the scan and join processes was unbounded. As another 
exam­ple, it assumed that tuples could span page boundaries (i.e., that a 200 byte tuple could have its 
first 50 bytes on one page and the remaining 150 bytes on the next page). While simulations are often 
used to validate an­alytical models, these sorts of assumptions are easily overlooked when implementing 
a simulator. Thus, it is important to note that analytical models can actually be quite useful for improving 
confidence in the validity of the simulator (rather than only the vice versa). The model that we have 
developed thus far is intended primarily as a proof of concept and as a starting point for developing 
models for studying query scheduling and memory management strategies for multiprogrammed systems and/or 
parallel systems. As pointed out in the Introduction, accurate and efficient analytical models of such 
systems would facilitate a more complete explo­ration of the system design space as well as enabling 
the study of very large systems. As an example of how much more efficient analytical models might be, 
a sin­ gle data point for the case of joining two 500K tuple relations (in Figure 6) required approximately 
29 min­ utes to simulate; evaluating the analytical model took only 0.75 milliseconds for the same case. 
(Note that we ran the join 20 times in the simulation and then aver­ aged the resulting join execution 
times. ) L foreover, the system that w-e were simulating was relatively simple, consisting of a single 
node and a small amount of main memory (4096 8K pages), and the cost of simulation grows rapidly as systems 
become more complex. Acknowledgement We would like to thank Kurt Brown for inspiring this work, for 
many useful comments, and for taking time to explain various details of the simulator (ZetaSim) that 
was used to validate the model presented here. We would also like to thank all of the ZetaSim developers 
for having provided us with an excellent simulator: without it. much of this work would not have been 
possible. References <RefA>[BCL93] <SinRef><author>K. P. Brown</author>, <author>M J. Carey</author>, and <author>hl. Livny</author>. (<title>Llanag­ing LIemor-yto Meet Multiclass 
\Vorkload ResponseTime Goals </title>. <booktitle>In Proc. VLDB</booktitle>,<location> Dublin, Ireland</location>, <date>August 1993 </date></SinRef>[BE77] <SinRef><author>M. Iv Blasgen </author>and <author>K. 
P. Eswaran</author>. <title>storage and access in Relational Databases IBM</title> ,!@. <journal>,~ownd</journal>,<volume> 16(4)</volume>, <date>1977</date></SinRef>. [BG88] <SinRef><author>D. Bitton </author>
ancl ,<author>J, Clray</author>, <author>Disk Shadowing </author>. <booktitle>In Proc. VLDB. Los .kngeles</booktitle>, .<date>August 1988</date></SinRef>. [Bra84] <SinRef><author>B. Bratbergsengen</author>. 
<title>Hashing Methods and Rela­tional Algebra Operations </title>, <booktitle>In Proc. VLDB</booktitle>, <date>August 1984</date></SinRef>. [Bro92] <SinRef><author>K. P. Brown</author>. 
<title>PRPL A Database Workload Specifi­cation Language, Version 1.3 </title>. <tech>Master s thesis</tech>,<booktitle> Computer Sciences Department</booktitle>, 
<institution>University of Wisconsin </institution>,<location>Madison</location>, <date>November 1992</date></SinRef>. [CLY1-92] <SinRef><author>M. S. Chen</author>, <author>M. L. Lo</author>, <author>P. S. Yu</author>, and <author>H. C. 
Young</author>. <title>Using Segmented Right Deep Trees for the Execution of Pipelined Hash Joins </title>. <booktitle>In Proc. VLDB</booktitle>, <date>August 
1992</date></SinRef>. [Com79] <SinRef><author>D. Comer</author>. <title>The Ubiquitous B-Tree </title>. <journal>ACM Com­putmg Surveys</journal>, .<date>June 1979 </date></SinRef>[CS91] <SinRef><author>M-C Chiang </author>and 
<author>G. S. Sohi</author>. <title>Experiences With Mean Value Analysis Models for Evaluating Shared Bus Throughput-Oriented 
Multiprocessors</title> . <booktitle>In Proc. SIG-METRICS</booktitle>, <date>May 1991</date></SinRef>. [DG92] <SinRef><author>D. J. DeWitt </author>and <author>Jim Gray</author>. <title>Parallel Database 
Systems: The Future of Database Processing or a Passing Fad? </title>. <journal>Communtcatton of the ACM</journal>, <date>June, 1992</date></SinRef>. 
[DGS+90] <SinRef><author>D. J. DeWitt</author>, <author>S. Ghandeharizadeh</author>, <author>D. Schnei­der</author>, <author>A. Bricker</author>, <author>H. Hsiao</author>, and <author>R. Rasmussen</author>. <title>tThe 
Gamma Database Machine Project </title>. <journal>IEEE Transactions on Knowledge and Data Engtneertng</journal>, <date>March 1990</date></SinRef>. [DKO+84] 
<SinRef><author>D. J. DeWitt</author>, <author>R. H. Katz</author>, <author>F. Olken</author>, <author>L. D. Shapiro</author>, <author>M. R. Stonebraker</author>, and <author>D. Wood</author>. <title>Implemen­tation Techniques 
for Main Memory Database Systems </title>. <booktitle>In Proc. SIGMOD</booktitle>, <date>June 1984</date></SinRef>. [Gra93] <SinRef><author>G. Graefe</author>. <title>Query Evaluation Techniques 
for Large Databases </title>. <journal>ACM Computmg Surveys</journal>,<volume> 25(2), </volume><date>June 1993</date></SinRef>. [HCL93] <SinRef><author>L. Haas</author>, <author>M. J. Carey</author>, and <author>M. Livny</author>. 
<title>SEEKing the Truth .kbout Ad Hoc Join Costs </title>. <tech>Technical Re­port 1148</tech>, <institution>Computer Sciences Department</institution>, [<institution>University 
of Wisconsin-Madison</institution>, <date>May 1993</date></SinRef>. [HT93] <SinRef><author>P. Heidelberger</author> and <author>K. S. Trivedi</author>. (.<title>knalytlc Queue­ing Models 
for Programs with Internal Concurrency</title> . <booktitle>In IEEE Transactions on Computers</booktitle>, <date>January 1993</date></SinRef>. [KNT89] <SinRef><author>M. 
Kitsuregawa</author>,<author> M. Nakayama</author>, and <author>M Takagi</author>. <title>The Effect of Bucket Size Tuning in the Dynamic Hy­brid GRACE 
Hash Join Method </title>. <booktitle>In Proc. VLDB, Ams­terdam</booktitle>, <publisher>The Netherlands</publisher>, <date>August 1989</date></SinRef>. [LY90] <SinRef><author>M S. Lakshmi </author>and<author> P. 
S. Yu</author>. <title>Effectiveness of Paral­lel Joins </title>. <booktitle>In IEEE Transactions on Knowledge and Data Eng~neermg</booktitle>, <date>December 
1990</date></SinRef>. [LZGS84] <SinRef><author>E. D. Lazowska</author>, <author>J. ZahorJan</author>, <author>G. S, Craham</author>, and <author>K. C. Sevcik </author>[<title>Quant?tattve System Performance </title>
, <publisher>Pren­tice Hall Inc.,</publisher> <location>Englewood Cliffs, New Jersey</location>, <date>1984 </date></SinRef>[MD] <SinRef><author>M. Mehta </author>and <author>D, J. DeWitt</author>. <title>Data Placement 
in Shared-Nothing Parallel Database Systems </title>. Submitted for publication</SinRef>. [MD93] <SinRef><author>M. Mehta </author>and <author>D. J. DelVitt. </author>
<title>Dynamic Memory Al­location for hIultlple-Query Workloads</title> , <booktitle>In Proc. VLDB</booktitle>,<date> August 1993</date>, </SinRef>[ME92] <SinRef><author>P. Mishra </author>
and <author>M. Eich</author>. <title>Join Processing in Relatlon Databases </title>. <booktitle>In Communacatzon of the A CM</booktitle>, <date>March 1992</date>. </SinRef>[RL80] 
<SinRef><author>M Reiser </author>and <author>S. Lavenberg</author>. <title>Mean \ alue Analysis of Closed Multichain Queuing Networks ). </title><booktitle>In Journal of 
.4 CM</booktitle>, volume <volume>27, </volume><date>April ]980</date></SinRef>. [Sha86] <SinRef><author>L. Shapiro</author>. <title>Join Processing In Database Systems with Large Mam 
Memories ACM TODS</title>, <volume>11 (3), </volume><date>Septem­ber 1986</date></SinRef>. [vLz88] <SinRef><author>hf. K. Vernon</author>, <author>E D. Lazowska</author>, and<author> J. Zahorjan</author>. <title>{An 
.4ccurate and Efficient Performance Anal\,sis Tech­mque for h[ultiprocessor Snooping Cache-Consistency 
Protocols</title> <booktitle>In 15th Annual Int 1. Symp. on Computer Ar­chitecture</booktitle>, <location>Honolulu, Hawaii</location>, <date>May30-June 2 1988</date>. 
</SinRef>[WE90] <SinRef><author>D \Villick </author>and<author> D. Eager</author>. .<title>4n ,4nalVtical Model for Multistage Interconnectio~ Networks </title>. <booktitle>In Proc. 
SIG-METRICS</booktitle>, <date>May 1990</date></SinRef>.  </RefA>
			
