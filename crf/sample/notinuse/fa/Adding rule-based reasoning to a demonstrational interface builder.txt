
 Adding Rule-Based Reasoning to a Demonstrational Interface Builder Gene L. Fisher, Dale E. Busse Department 
of Computer Science California Polytechnic State University San Luis Obispo, CA 93407 David A. Wolber 
Division of Computer Science University of Davis, CA Abstract This paper presents a demonstrational 
interface builder with improved reasoning capabilities. The system is comprised of two major components: 
an interactive display manager and a rule-based reasoner. The display manager provides facilities to 
draw the physical appear­ance of an interface and define interface behavior by graph­ical demonstration. 
The behavior is defined using a tech­nique of stimulus-response demonstration. With this tech­nique, 
an interface developer first demonstmtes a stimulus that represents an action that an end user will perform 
on the interface. After the stimulus, the developer demon­strates the response(s) that should result 
from the given stimulus. As the behavior is demonstrated, the reasoner observes the demonstrations and 
draws inferences to expedite behavior definition. The inferences entail general­izing from specific behavior 
demonstrations and identify­ing constraints that define the generalized behavior. Once behavior constraints 
are identified, the reasoner sends them to the display manager to complete the definition process. When 
the interface is executed by an end-user, the display manager uses the constraints to implement the run-time 
behavior of the interface. Keywords: UIMSS, Interface Builders, Programming by Demonstration, Direct 
Manipulation 1. Introduction In lJYolber 91] we presented a system named DEMO for constructing user interfaces 
by demonstration. The DEMO system allows a developer to draw the graphical components of an interface 
using a standard drawing edi­tor. Once the graphics are drawn, the developer then Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
that copying is by permission of the Machinery. To copy otherwise, or and/or specific permission. @1992 
ACM ().89791 .550. x/92/ool California 95616 defines the behavior of the interface using stimulus­ r-esponse 
demonstration. Stimulus-response demonstration is designed to be a simple and intuitive technique for 
defining the behavior of an interface. In using the technique, the developer tist plays the role of an 
end user by demonstrating a stimulus that represents an action that an end user will perform on the interface. 
Following the stimulus, the developer plays the role of the system by demonstrating the response(s) that 
should result from the given stimulus. Daring the course of demonstrations, DEMO draws inferences about 
the demonstrated behavior so that specific demonstrations can be generalized. In order to make such inferences, 
DEMO may use interactive dialog with the developer to direct its inferencing choices. This paper presents 
a substantially improved version of the DEMO system. The primary goal for the improved system is to increase 
the system s ability to draw inter­fences about interface behavior, without having to rely on dialog 
with the developer. This is accomplished by the integration of a rule-based reasoning component within 
DEMO. As with the original version of DEMO, our primary goal is to allow non-programmers to describe 
interface behavior in reasonably simple and intuitive terms. An interface developer should be able to 
demonstrate behavior to DEMO in a fashion similar to how the behavior would be demonstrated to another 
hutnan being. In DEMO II, we move a stop closer to this goal. The new reasoning com­ponent is implemented 
using expert system techniques, so it possesses the capabilities typical of an expert system. Namely, 
within a restricted domain, it can duplicate some of the intelligence of a human expert. In targeting 
non-programmers, simplicity of use is an important goat for DEMO II. As with any computer-based tool, 
a user needs some understanding of system capabili­ties to use the tool effectively. With DEMO II, the 
developer should understand that the system attempts to infer significant relationships between stimulus-response 
appear, and notice ie given Association for Computing to republish, requires a fee l/oc)~9...$l .~o 
objects in a display. Each significant relationship will become a constraint that DEMO II will enforce. 
With this basic understanding, a high-level demonstration strategy is the following: Present a sequence 
of demonstrations that intui­tively define the desired behavior. To help DEMO II recognize a significant 
rela­tionship, demonstrate two different versions of the same relationship in two successive demonstrations. 
 If necessary, repeat the demonstration of a significant relationship additional times until DEMO II 
recognizes it. If DEMO II infers an undesired relationship, correct the inference by changing the objects 
that DEMO II incorrectly placed on the display. The main example of the paper shows how this strategy 
is employed. 2. Overview of the New DEMO System Figure 1 shows the high-level architecture of DEMO II. 
The display manager contains the drawing editor, and manages the end-user interface. From the developer 
s per­spective, the basic display appears largely unchanged from the original version of DEMO. The appearance 
of the display is shown in Figure 2. The new rule-based reasoner runs as a separate pro­cess from the 
display manager. As shown in Figure 1, the G/q)h;cu/f(ws (1/70 [<( objecr.s oppeul-itlg it! w II DEMO 
[1 Rule-Based ke~ RPa Q<,rmr Graphim[ comoaims that de,fim the appeor- G (ItIce of the display. cI 1I 
I Runtime Editor Drawing Constraint Solver Figure 1: DEMO II Architecture. -  q l .A II w.I K r cl, 
/-2 Figure 2: DEMO 11User Screen. basic communication into the reasoner is facts about the state of the 
display. The facts are transmitted after each stimulus and each response demonstration. The reasoner 
uses these facts to draw inferences about the state of the display. The primary goal of the inferences 
is to determine the significant graphical relationships that exist between objects in the display. Relationships 
identified as significant are used to generate constraints in conditional stimulus-response behaviors. 
The concept of a conditional stimulus-response was developed in the originaJ DEMO system. A condition 
defines a behavior constraint. Consider the following example for the stimulus-response behavior of a 
slider bac STIMULUS S1 iderBar. Lef tDown ( ) RESPONSE SliderBar. InitiateMove ( ) WHERE (SliderBar .ContainedIn 
( Slide rRect) ) This conditioned behavior defines the constraint that the moving slider bar must stay 
within the outer rectangle of the slider as the bar is moved. The stimulus-response definition is in 
an object-oriented form. In the above definition, the STIMULUS specifies that the Le f tDown mouse operation 
is performed on the object S 1 iderBar. The RESPONSE operation is an In i t i at eMove mouse operation 
performed on the S 1 iderBar. In the WHERE clause, the Cent a inedInf predicate is applied to the S 1 
iclerBar object, with the S 1 iderRect object as the predicate parameter. For more complex behaviors, 
more complex condi­tions are generated. For example, it was shown in Wolber 91] how conditioned behavior 
can be used to define the rubberbanding of edges in a graph editor interface. As a node in the graph 
is moved, the conditional response defines how the edges connected to the node are reshaped to remain 
connected to the node. In the original DEMO, demonstration of conditional behaviors always requires dialog 
with the user. For each condition that the system identifies, a dialog box is displayed to the developer, 
such as that shown in Figure 3. Because conditions are identified at a low-level, dialogs may be lengthy. 
The system uses a number of heuristics to order conditions from the most likely to apply, so that the 
developer can end the dialog after all relevant conditions have been identified. However, the problem 
remains that the developer, not the system, must determine which con­ditions should be used. The primary 
objective for DEMO II is to shift the burden for condition selection horn the developer to the system. 
To accomplish this, the DEMO II reasoner will observe demonstrations and identify which conditions are 
significant to the behavior being demonstrated. The exam­ple development in the following sections of 
the paper describes in detail how this reasoning is conducted. To assist the reasoning component in its 
determina­tion of significant conditions, the notion of successive refinment is added to the stimulus-response 
technique. In practice, an explicit user dialog is replaced by additional graphic demonstrations, so 
that a behavior is fine tuned in a Objectl is related to object 2. Figure 3: Condition Selection Dialog. 
stepwise fashion. An important goal for DEMO 11 is to ensure that the number of refining demonstrations 
is com­mensurate with the complexity of the interface being developed. That is, a simple behavior should 
be demonstr­able in a small number of demonstration, while more com­plex behaviors will require more 
refinement. For the examples we have developed thus far, this goal has been met, as we will discuss shortly. 
The use of successive refinement in DEMO II per­mits the definition of interfaces that could not be defined 
in the original DEMO, even with user dialog. While the ori­ginal DEMO did allow some refinement, it was 
only used in the context of interfaces containing dynamic objects. In DEMO II, the refinement is an integral 
part of the develop­ment technique. A secondary task of the reasoner is in the area of object naming. 
In the original DEMO, mnemonic names must be explicitly given by the developer. For example, the names 
shown in the slider bar example above were chosen by the developer. Without the naming, DEMO would have 
generated the following: STIMULUS Obj 1 .Lef tDown ( ) RESPONSE 0bj2 . InitiateMove ( ) WHERE (Obj2 .ContainedIn 
(Objl) ) The new reasoning component of DEMO II assists in object naming by applying rules that infer 
names based on object shapes, relative object positions, and other relevant facts. Mnemonic object names 
are not always of interest to a developer. However, in cases where DEMO H explains its reasoning, the 
names are quite useful. A final new feature of DEMO II is the notion of demonstration guide wires . A 
guide wire is a component of the graphical display that is visible during development but invisible to 
the end-user when the interface is actually in use. A guide wire allows the developer to express graphical 
relationships easily during development. Without guide wires, more complex graphical relationships are 
required to express relationships that are expressed in simple and direct terms when guide wires are 
used. The following list summarizes the specific shortcom­ings of the original DEMO system have keen 
addressed in the DEMO II research: 1. Conditional demonstrations always require dialog with the developer 
to contirm what conditions are used as constraints; in DEMO II, the reasoner determines significant condi­tions 
without explicit dialog. 2. The ability to define demonstrations @ Suc­cessive r~finement is limited 
in DEMO II, successive refinement is an integral part of the interface development process, allowing 
new forms of interfaces to be defined.  3. All object naming must be done manually by the developer; 
the DEMO II reasoner derives reasonably mnemonic object names automat­ically. 3. An Example To illustrate 
the capabilities of DEMO II, we present the demonstrational development of a familiar graphical interface 
from the X-Windows system --xeyes. Figure 4 shows the xeyes interface. The xeyes interface simulates 
the behavior of cartoon-like eyes. As a mouse pointer is moved on the screen, the pupils move within 
the balls of the eyes with the effect that they watch the mouse. To simulate normal behavior, the movement 
of the pupils is constrained within the eye balls. While the mouse moves outside of the balls, the pupils 
move along the inside border of the balls. When the mouse moves within a ball, the pupil within the ball 
tracks the mouse directly. While xeyes is more of a diversion than a serious tool, it exhibits interesting 
behavior that requires reasoning mouse pointer that xeyes watches / xeyes display r background screen 
 Figure 4: Xeyes Display. 92 UIST 92 to develop. In particular, the interface has several noteworthy 
properties. First, the behavior is not com­pletely uniform, but rather it varies depending on different 
graphical contexts (viz., the tracking of the mouse varies depending on whether the mouse is outside 
or inside of the eye ball). Also, the interface behavior can be described by a stepwise explanation, 
that successively refines the behavior until the precise form is reached. Finally, while a programmed 
implementation of the interface uses mathematical computation to compute the behavior, the behavior can 
be defined in simpler graphical terms when a demonstrational technique is used. These properties are 
representative of real-world interfaces from specitic application domains. For example, the behavior 
of game pieces on a board, such as chess, have such properties. Another example is the behavior of objects 
in a science lab simulation, such as molecular motion or collisions of bodies in space. Hence, with the 
xeyes example we seek to illustrate how the stimulus­response technique can be used to define behaviors 
for interface objects in real-world application domains. Such behaviors are more involved than the typical 
interface widgets found in library-based interface builders and toolk­its. Another noteworthy property 
of xeyes is the size of its implementation --approximately 750 lies of C code. This size measure includes 
the code for both the drawing of the interface and the logic of its behavior. The code uses the standard 
X windows library, but its size would not be manifestly reduced with the use of a more advanced toolkit, 
such as InterViews IJhton 89]. An interface builder, such as NeXT Step mexT], or InterViews [Stan­ford], 
would not solve the coding problem, since the behavior of xeyes does not match any of the standard interactors 
available in library-based interface builders. Given the size of the existing xeyes implementation, it 
has been gratifying to find that DEMO II can define the xeyes appearance and behavior in simple and intuitive 
terms, using the power of its built-in graphics editor and the stimulus-response demonstration technique. 
3.1. Demonstration Strategy The iirst step in demonstrating the behavior of xeyes is to determine an 
intuitive graphical explanation of the behavior. From a mathematical perspective, one might explain the 
movement of the pupils using a trigonomernc formula that describes the pupil position with respect to 
the eyeball and mouse. This is in fact how the implementation of the interface is defined. A simpler 
graphical explanation of the behavior is to view a pupil on an invisible line the extends horn the center 
of the eyeball to the mouse pointer (see Figure 5). As the mouse pointer moves, the invisible line reshapes 
to .k -..:, , ... ,. ()()/-/. ... : .,- ,.. , ,.,.. / ;.,/ .. ..is::. ...?. . Figure 5: How Pupils Track 
the Mouse Pointer. remain connected to the center of the ball and the pointer. The graphical constraints 
on the pupil are then two: (1) the pupil remains centered on the invisible Iinq (2) the pupil remains 
on the inner edge of the eyeball. The preceding two constraints define the pupil behavior when the mouse 
pointer remains outside of the eyeballs. When the pointer moves inside of a ball, a third constraint 
is enforced: the pupil tracks the pointer directly. That is, while the pointer moves within an eyeball, 
the pupil remains directly on top of it. Given this view of how the interface behaves, the following 
overall strategy is followed to build the interface in DEMO II First, draw the interface, including the 
invisi­ble line that is used to explain the tracking. Next, demon­strate the interface behavior by showing 
how the tracking works outside of the eyeballs, and then inside of the eye­ball. Finally, after the initial 
drawing and demonstration are done for a single eyeball, copy the graphics and behavior to create a second 
eyeball. The remainder of this section of the paper describes how the steps of this strategy are carried 
out in DEMO II. This description focuses strictly on the user-level view of the system. In the next section 
of the paper, we describe the internal reasoning employed by DEMO 11 to infer the demonstrated behavior. 
3.2. Drawing the Initial Interface As in the original DEMO system, the first step in creating an interface 
is to draw the interface components. Figure 6 shows the initial drawing. The initial state of the drawing 
has the pupil within the eyeball. The initial Ball Pupil \ Invisible Tracking Line/ Invisible Guide 
Ellipse Figure 6: Initial Xeyes Drawing. position of the pupil is vertically centered on the tracking 
line to the mouse pointer. The invisible tracking line is an example of a guide wire component of the 
interface. As introduced earlier, a guide wire is a part of the interface that remains visible during 
the development phase, but disappears when the interface is in use. During the initial drawing, the developer 
explicitly delineates the guide wires, and the sys­tem draws them in a distinguished pattern, such as 
a dashed line. The actual pattern is selectable, so that guide wires can always be dktinguishable from 
visible parts of the interface that may be drawn in some non-solid pattern. Physically, guide wires are 
never actually removed from the display. Their invisibility is rendered by chang­ing their pattern to 
none . It is necessary not to remove them, since DEMO II depends on their existence at runtime in order 
to compute the proper operational constraints that govern interface behavior. There is an additional 
guide wire drawn in the initial interface shown in Figure 6. It is the invisible ellipse just inside 
of the ball. This ellipse is used in the demonstra­tions to define the proper position of the pupil on 
the inside edge of the eyeball. In general, guide wires are used to define direct graphical relationships 
between components in the display, rather that having the system infer indirect relationships. The detailed 
description in the next subsec­tion will rationalize and justify the use of guide wires in general. The 
drawing editor provides sufficient tools to align and center objects accurately. However, such alignment 
is not strictly necessary, since subsequent computations will be based on the relative positions of objects 
in the initial scene. Hence, if the initial drawing is a little off with respect to exact object positioning, 
the xeyes behavior will not be substantially affected. In normal use, a developer can first produce a 
rough drawing of the interface to work out the demonstrations. Once the precise behavior has been defined, 
the developer can redraw the graphics accu­mtely, and redemonstrate the worked-out behavior. 3.3. The 
Demonstrations With the initial display in place, the following demonstrations define the xeyes behavior 
(see Figure 7): Demonstration No. 1: STIMULUS:Move the mouse pointer to another location outside of the 
eyeball. RESPONSE: Reshape the endpoint of the tracking line to stay on the pointev move the pupil to 
stay on both the tracking line and the invisible ellipse. Demonstration No. 2: STIMULUS: Move the pointer 
farther away from the eyeball, RESPONSE: Move the pupil again to stay on both the tracking line and the 
invisible ellipse. Demonstration No. 3: STIMULUS: Move the ~in ter inside of the eyeball. RESPONSE: 
Move the pupil onto the pointer. Demonstration No. 4: STIMULUS: Move the pointer to another point inside 
the eyeball. RESPONSE: Move the pupil again onto the pointer. After each demonstration, a partially 
correct version of the desired behavior has been defined. To explain how the behavior is refined, the 
following basic development rules should be noted: (A) In the absence of other information, DEMO II infers 
a linear proportional constraint between the stimulus -*.A 0 ... ,...,,.,. ..-)j /-----­.,.. ,. ... 
/­.,. .. . ?. .,,,* :: , , ... ,. ., ., ,., 1:. . . Demo...... STIM: move pointer RESP: reshape tracking 
line, move pupil ont; line and guide ellipse O ;> ----------%,.,. %......------­,> . $. -----­;\, \ ......-....­. 
..---­ . ;. +--- ...----. .  \ : . ,. .. .,. .., Demo 2: .-.....-.. STIM: move pointer farther RESP: 
reshape tracking line, move pupil onto line and guide ellipse .. Demo 3: STIM: move pointer inside ball 
RESP: move pupil onto pointer ,..,. ,. . .  : :\ ., ; ., ~~ ( ,., . ,.+ .... /= -....- O Demo 
4: and response objects. STIM: RESP: move pointer inside ball move pupil onto pointer (B) DEMO II is 
most effective in reasoning about simple graphical relationships between objects in a display. Figure 
7: The Four Xeyes Demonstrations. (C) As demonstrations are successively refined, all constraints that 
have been inferred so far remain enforced in successive demonstrations, unless such constraints are explicitly 
changed by the developer. (D) A demonstration in which a previously inferred constraint is explicitly 
changed by the developer causes DEMO H to refine the constraint. (E) Two successive demonstrations that 
repeat the same graphical relationships, with all other dationships unchanged in the display, will lead 
DEMO to infer the repeated relationships as significant.  Rule A is the basic inference mechanism from 
the original DEMO system (see Nolber 91]). In the xeyes example, a linear proportion constraint is inferred 
after Demonstration No. 1. Speci6cally, the stimulus object is the mouse pointer and the response objects 
are the tracking line and the pupil. The inferred linear proportion is that the parameters of the line 
reshape and the pupil move are pro­portional to the parameters of the pointer move. Formally: STIMULUS 
MousePointer. InitiateMove (x, y) RESPONSE TrackingLine. RightReshape ( C1 *X, c2 *y) Pupil .Move(cl 
x, c2*y) where cl and C2 are proportional constants computed by the precise amount of movement that 
occurred on the screen. Hence, after the Demonstration No. 1, whenever the mouse pointer is moved, the 
tracking line will follow it, and the pupil will stay on the tracking line. However, the pupil will not 
be constrained to stay within the eyeball. Rule B defines the general strategy for the use of guide wires. 
Viz., rather than demonstrating a complex relationship between two objects, the developer should add 
a guide wire that allows a simpler relationship to be demonstrated. The use of the invisible ellipse 
illustrates this strategy in the xeyes example. Without the guide ellipse, the desired relationship between 
the pupil and the ball must be expressed in terms of a distance from the center of the pupil to the edge 
of the ellipse. This dktance dationship is much more difficult for the system to recog­nize than the 
simpler relationship Intersects (invisible-ellipse, pupil) Hence, in xeyes Demonstration 1, the developer 
moves the pupil onto the guide ellipse to define the desired location of the pupil within the eyeball. 
Rule C defines a basic property of demonstration refinement. In the xeyes example, Rule C means that 
the constraint inferred in Demonstration 1 will be enforced when the pointer is stimulated in Demonstration 
2. Unless and until the developer explicitly changes the position of a response object, all previously 
computed response con­straints will remain in effect. Rule D is another important refinement property. 
This feature is used in xeyes Demonstmtion 2 to refine the behavior of the pupil, Specifically, in the 
response to Demonstration 2, the pupil is automatically moved to a position outside of the eyeball, via 
the constraint that was inferred in Demonstration 1. When the developer expli­citly changes a response 
object, the system notices the change and refines the constraint that was previously inferred. In this 
case, the refinement is to constrain the pupil onto the invisible guide ellipse. Rule E defines a third 
important refinement property. This feature is used in Demonstrations 3 and 4 to help the system infer 
the key constraint that the pupil stays on the pointer while pointer moves within the eyeball. During 
Demonstrations 3 and 4, the system retains the inferences from earlier demonstrations, since these are 
not contrad­icted. Hence, at the end of the fourth demonstration, the desired behavior has been defined. 
4. Internals of DEMO II Reasoning The rule base of the DEMO II system is composed of approximately 75 
rules in the following basic categories: Object naming Constraint identification o Constraint refinement 
 Constraint satisfaction Communications and control These rules are applied in phases that correspond 
to phases of development that transpire in the display manager. The phases are identified on the Behavior 
menu shown in Fig­ure 2: Draw Mode, Demonstrate Stimulus, Demonstrate Response, and Test Interface. During 
Draw Mode the rules are dormant. The reasoner is sent its initial information when the first stimulus 
demonstration is performed. The information is in the form of facts about the display. The following 
are excerpts of the initial facts for the xeyes exampkx (deffacts initial-state (object objl ellipse) 
;Pupil (object obj2 ellipse) ;Guide Ellipse (object obj3 multi line) ;Arrow (object obj4 line) ;Guide 
Line (object obj5 ellipse) ;Eyeball (obj-attr invisible obj2) (obj-attr invisible obj4) (init-fact obj4 
intersects obj5) (init-fact obj5 intersects obj4) (init-fact obj5 intersects obj2) ... (init-fact obj4 
rt-endpt-contained obj3) ) The initial facts contain non-mnemonic names that are gen­erated by the display 
manager. An initial firing of the nam­ing rules will produce names using information about the initial 
facts of display. Following the initial facts, stimulus facts are sent to the reasoner. These facts are 
preceded by a phase tag the indicates the development phase to which the facts apply. Here is an excerpt 
of the stimulus tration No. 1: (phase (stim-obj (stim-fact move (stim-fact stimO ulus) multiline multi 
line 2 ) invisible-line rt-endpt-contained (stim-fact multiline contains rt endpt (stim-fact ellipse 
facts for xeyes Demons­ 1 ) 1 multiline l ) 1 invisible-line ) 1 intersects invisible-ellipse ) (stim-fact 
invisible-ellipse intersects ellipse l ) (stim-fact ellipse 1 contained-by ellipse 2 ) (stim-fact ellipse 
2 contains ellipse l ) After receipt of the stimulus facts, the reasoner awaits the arrival ofthe response 
facts. Response facts have the same general format as stimulus facts, preceded by a response indicator. 
After each stimulus-response pair, therules fire for constraint identification, refinement, and satisfaction. 
These rules encode the general development rules outlined in thexeyes example. Theresult ofconstra.introle 
applica­tionis anencoding oftheconstraints suitableforuseby the display manager. This information is 
returned to the display manager, where the information is installed in the internal representation of 
the stimulus-response code for each demonstration. For example, hereis anexcerpt of the encoded constraints 
forthefinalxeyes demonstration: y-invisible-line.left.y ((invisible-line. invisible-line (invisible-line. 
invisible-line = left.y ­.right.y) left.x ­.right.x (x -invisible-line. left.x WHERE NOT (multiline-l 
.contained-by invisible-ellipse) (x**2 / (invisible-ellipse.horizradius invisible-ellipse .center.x) 
(y**2 / (invisible-ellipse.vertradius invisible-ellipse. center.y) WHERE NOT (spline I.contained-by( 
invisible-ellipse) This constraint pair defines the enforcement (the pupil) intersects the invisible-line 
(the The equations are in a form that the display process at runtime. This runtime processing ) / )) 
* ) ( - **2) ­-**2) =1 ) that ellipse-1 guide line). manager can includes the solution of constraint 
equations and the evaluation of constmintpredicates. The most complex encodingof con­straints is as pairs 
of quadratic simultaneous equationson two variables, that are solved by well-known numeric tech­niques. 
WHERE clauses are used as response preconditions, as describedin NVolber 91]. The code for one stimulus­response 
demonstration can have zero or more WHERE clauses. With zero, the response is executed uncondition­ally 
whenever the stimulus occurs. With one WHERE clause, the response is txxecuted only when the WHERE clause 
is true. If the WHERE clause is false, the response is not executed, and the performed action of the 
stimulus is retracted on the display. If more than one WHERE clause exists, the clauses must be mutually 
exclusive, and the response isexecuted whenoneofthe conditionsistrue. With the current rule set, the 
reasoner prioritizes multiple response preconditions in the order that they are discovered. For somebehaviors, 
it mightbe advantageous to prioritize preconditions inother orders. This prioritize­tioncouldbedone with 
auklitionalrules orby user dialog. While the main focus of tlhecurrent research is to eliminate developer 
dialog, allowing such dialog in generalis not entirely negative. The importantp ointistoraise the level 
of the dialog, so that the reasoner does as much of the low-level r easoninga spossible. Continuing experimen­tation 
with the system will help determine exactly what constitutes low-level reasoning, and when dialog with 
the developer is advantageous. The challenge isto strike the most effective balance between graphical 
demonstration and textual dialog. DEMO 11 uses an object-oriented framework for packaging interface behaviors. 
With suchpackaging, each user-level operation is defined with asequence ofrefining demonstrations. The 
developer explicidy controls the sequencing of demonstrations using a selection from the Behavior-Operations 
menu. Selecting Start Operation Definition puts the system in refinement mode. In this mode, each successive 
demonstration is assumedto be a refinement of the preceding demonstrations. When the developer selects 
End Operation Definition the refinement sequence is completed, so that the next stimulus-response demonstration 
will be interpreted as the first in anew refinement sequence. 5. Related Work As noted earlier, DEMO 
II has advantages over existing standard interface builders, such as NeXT Step meXT1. Such interface 
builders arelibrary-based, in that altavailable interactors arepre-defined. DEMO II allows entirely new 
interface components to be drawn and defined demonstrationally. The IBuild interface builder Wlissides 
91] provides advantages over other builders in terms of the generality of interfaces that can be constructed. 
The interface objects that the builder manages are simulations rather than direct instances. This allows 
more flexibility in the construction process. However, IBuild is still fundamentally based on an interface 
library (InterViews Kinton 89]). IBuild has no mechanism to extend the fundamental semantics of InterViews 
objects. Any interface system that uses demonstration must be compared to Peridot [Myers 88], as well 
the systems that have built on Peridot s basic demonstrational capabili­ties: Lapidary [Myers 89] and 
Gilt Myers 91]. In these systems, new interface objects can be built by demonstra­tion, and customized 
for specific application requirements. These systems also share a common goal with DEMO --to reduce the 
amount of programming that must be performed to build an interface. The stimulus-demonstration tech­nique 
is a somewhat diHerent approach than Peridot, and the rule-based reasoner of DEMO 11 is more fully decou­pled 
than the Peridot inference. Metamouse [Maulsby 89] is a system that uses rule­based techniques to infer 
interface behaviors. It notices iterative behaviors when developers perform repetitive tasks. Metamouse 
also employs the notion of invisible objects to express behaviors in gmphical terms. The DEMO 11 reasoner 
focuses on specific stimulus-response demonstrations, so it does less looking over the shoulder than 
does Metamouse. The DEMO II reasoner is not lim­ited to repetitive behaviors. The work reported in [Hudson 
91] describes the integration of rule-based reasoning into an interface builder. The focus there is on 
interface layout constraints, whereas in DEMO the focus is on generating constraints to control dynamic 
interface behavior. In a broad sense, DEMO II can be compmxl to intel­ligent CAD systems, such as in 
[Gero 85], where the goal is to infer significant graphicaJ relationships between objects in a display. 
The specific focus of such systems is clearly different than an interface builder, but the use of rule-based 
support for reasoning about graphical objects is a found in many intelligent CAD systems. References 
<RefA>[Gero 85] <SinRef><editor>John S. Gero </editor>(Ed.), <title>Knowledge Engineering in Computer--Aided Design</title>, <location>North Holland, Netherlands </location>
(<date>1985</date>). </SinRef>llludson 91] <SinRef><author>Scott H</author>. <author>Hudson</author> and <author>Andrey K. Yeatts</author>, <title>Smoothly Integrating Rule-Based Techniques 
into a Direct Manipulation Interface Builder </title>, <booktitle>Proceedings of the ACM SIGGRAPH Symposium on User Intetiace 
Software and Technology, UIST </booktitle><volume>91 </volume>(<date>Nov. 1991</date>), <pages>145-154</pages></SinRef>. Kinton 89] <SinRef><author>Mark A. Linton</author>, <author>John M. Vlissides</author>, 
and <author>Paul R. Calder</author>,<title> Composing User Interfaces with Inter-Views </title>, <journal>IEEE Computer </journal><volume>22(2) </volume>(<date>Feb. 1989</date>), <pages>8-22</pages>. </SinRef>
 [Maulsby 89] <SinRef><author>D. Maulsby</author>,<title> I Wittten, and K Kittlizt, Metamous~ Specifying Graphical Procedures by Example 
</title>, <booktitle>Proceedings of the ACM 1989 SIGGRAPH Conference</booktitle>, (<date>July 1989</date>), <pages>127-136</pages></SinRef>. [Myers 88] <SinRef><author>Brad A. Myers</author>, <title>Creating 
User Interface by Demonstration</title>, <publisher>Academic Press</publisher>, <location>Boston</location>, <date>1988</date></SinRef>. [Myers 89] <SinRef><author>Brad A. Myers</author>, <author>Brad Vander 
Aznden</author>, and <author>Roger B. Damtenberg</author>, <title>Creating Graphical Interactive Application Objects by Demonstration </title>
,<booktitle> Proceedings of the ACM SIGGRAPH Symposium on User Inte#ace Software and Technology, UIST </booktitle><volume>89 </volume>(<date>Nov. 1989</date>), 
<pages>95­ 104</pages></SinRef>. [Myers 91] <SinRef><author>Brad A. Myers</author>, <title>Separating Application Code from Toolkits: Eliminating the Spaghetti 
of Call-Backs </title>, <booktitle>Proceedings of the ACM SIGGRAPH Sym­posium on User Interface Software and Technology, 
UIST </booktitle><volume>91 </volume>(<date>NOV. 1991</date>), <pages>211-220</pages>. <publisher>meXTl lnterj$ace Builder, NeXT</publisher>, Inc., <location>Palo Alto, CA. </location></SinRef>[Vlissides 91] <SinRef><author>John 
M. Vlissides </author>and <author>Steven Tang</author>, <title>A Unidraw-Based User Interface Builder </title>,<booktitle> Proceedings of the ACM SIGGRAPH 
Symposium on User Inte~ace Software and Technology, UIST </booktitle><volume>91 </volume>(<date>Nov. 1991</date>), <pages>201-210</pages></SinRef>. llVolber 91] <SinRef><author>David 
Wolber </author>and <author>Gene Fisher</author>, <title>A Demons­trational Technique for Developing Interfaces with Dynamically Created 
Objects </title>, <booktitle>Proceedings of the ACM SIGGRAPH Symposium on User Interface Software and Technology, UIST </booktitle><volume>91 </volume>
(<date>Nov. 1991</date>), <pages>221-230</pages></SinRef>.</RefA> 
			
