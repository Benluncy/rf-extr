
 An Of.ine Foundation for Online Accountable Pseudonyms Bryan Ford Jacob Strauss Massachusetts Institute 
of Technology ABSTRACT Online anonymity often appears to undermine accountabil­ity, offering little 
incentive for civil behavior, but account­ability failures usually result not from anonymity itself but 
from the disposability of virtual identities. A user banned for misbehavior e.g., spamming from a free 
E-mail account or stuf.ng an online ballot box can simply open other ac­counts or connect from other 
IP addresses. Instead of cur­tailing freedom of expression by giving up anonymity, on­line services and 
communities should support accountable pseudonyms: virtual personas that can provide both anonymity and 
accountability. We propose Pseudonym parties, a scheme for creating accountable pseudonyms, which combine 
in­person social occasions (parties) with technical infrastruc­ture (a pseudonymous sign-on service) 
to enforce the rule that one real person gets one virtual persona on any partic­ipating online service. 
Pseudonym parties enable the user to adopt different personas in different online spaces with­out revealing 
the connection between them, while ensuring that each user has only one accountable pseudonym in each 
space. Pseudonym parties can be started incrementally in a fully decentralized fashion, can run on volunteer 
labor with minimal funds, and may even be fun. 1. INTRODUCTION The right to anonymity, often seen as 
a necessary compo­nent of free expression, has long seemed at odds with the principle of accountability, 
an equally basic foundation of social justice and the rule of law [37]. The ability to partic­ipate anonymously 
in online communities is a widely cher­ished feature of the Internet [30, 34], particularly in that it 
enables people and groups with controversial or unpopular views to communicate and interact without fear 
of personal Permission to make digital or hard copies of all or part of this work for personal or classroom 
use is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage 
and that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, 
to post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. SocialNets 
08, April 1, 2008, Glasgow, Scotland, UK Copyright 2008 ACM 978-1-60558-124-8/08/04 ...$5.00. reprisal 
[27]. Opponents on the other hand contend that this anonymity often harbors and encourages antisocial 
or crim­inal behavior [7]. Indeed, many of the Internet s current maladies reduce to failures of accountability: 
given the ability to create online identities at will, there is little incentive for the user control­ling 
any given identity to behave. Because open-access mes­saging systems cannot reliably identify a message 
s source for the purpose of suppressing abuse, spam has already rele­gated USENET to historical obscurity 
[31], threatens the us­ability of E-mail [36], and is advancing on voice-over-IP [6]. The automated Turing 
tests many web sites now employ to prevent automated abuses [33] also lock out visually im­paired users 
[5, 22] and are vulnerable to attack using arti­.cial intelligence [4] or social engineering [9]. Wikipedia 
progressively tightens its editing rules to combat the rising tide of anonymousvandalism [13,18,32]. 
Online voting and peer review systems like Slashdot operate reliably only to the extent that nobody cares 
about the results enough to bother opening multiple accounts and stuf.ng the ballot boxes [15]. Banning 
detected abusers by IP address frequently prevents access by other legitimate users on the same ISP [17], 
and many attacks come from compromised zombie machines not under the control of their owners [11]. This 
tension between anonymity and accountability may not be fundamental, but merely an indication that our 
cur­rent mechanisms to provide them are too primitive. Con­sider a masquerade ball in which everyone 
dresses unrecog­nizably in costume, and no latecomers are admitted once the event has started. If some 
attendee, Bob, breaks the rules of the event, the ball s organizers have at least two avenues of punishment. 
First, they could strip off Bob s mask in front of everyone as in the .lm Eyes Wide Shut, destroying 
his anonymity and potentially exposing him to reprisals in the real world. Alternatively, they could 
merely eject him from the ball, holding him accountable for his actions and pre­venting him from further 
disrupting the event while respect­ing his anonymity. The rule against latecomers is a crucial mechanism 
enabling the latter, anonymity-preserving form of punishment: without it, Bob could merely change cos­tumes 
and re-enter after ejection. The Internet s vulnerability to spam, ballot stuf.ng, and many similar 
attacks results not directly from the anonymity of users, but rather from the disposability of online 
identi­ties. As if changing costumes, an attacker can create a new online identity and evade accountability 
simply by signing up for a new web account, connecting from another IP ad­dress, or sending spam from 
another compromised host. If an online community could reliably enforce the rule that one real person 
may obtain only one virtual persona over some signi.cant period of time, then these online personas could 
still be anonymous but would no longer be disposable, pro­viding a degree of user accountability. Online 
communities could revoke the access rights of abusers, for example, such as E-mail spammers or Wikipedia 
vandals, without affecting innocent users or permitting an abuser to reappear immedi­ately under a different 
name. Voting systems for peer review or online deliberation could protect voter anonymity while preventing 
ballot box stuf.ng. We will refer to online identities that combine anonymity with accountability in 
this way as accountable pseudonyms. We might create accountable pseudonyms in many ways: here we explore 
one mechanism, pseudonym parties, which takes advantage of the fact that real humans can be in only one 
place at a time. On a speci.c day every year, participat­ing organizations or ad hoc groups of people 
host parties in their local areas, at which they pass out certi.cates to any­one who shows up in person. 
The physical presence require­ment, combined with suitable procedures, ensures that each user may obtain 
only one such certi.cate per year. Given this certi.cate, a user can create any number of pseudonymous 
identities at a variety of participating online services but only one such identity per service. Accountable 
pseudonyms need not be deployed pervasively before they bene.t users. Online services might still permit 
access by unauthenticated users, but offer privileges to hold­ers of accountable pseudonyms, such as 
the right to partic­ipate in votes protected from ballot stuf.ng, and automatic exemption from IP blacklists, 
waiting periods, and other in­vasive protections against anonymous abuse. Though pseudo­nym parties require 
some real-world infrastructure, the costs of this infrastructure should be small enough initially to 
be borne by voluntary donations of time and resources, and should scale in proportion to the number of 
participants. The rest of this paper is organized as follows. Section 2 outlines previous proposals for 
user accountability in more detail. Section 3 then presents and discusses pseudonym par­ties. Section 
4 brie.y outlines deployment issues, focusing more on the scheme s social aspects than on its technical 
details in order to promote discussion. Finally, Section 5 concludes.  2. BACKGROUND AND RELATED WORK 
The abuse of an online system by creating many virtual personas has become known in the peer-to-peer 
community as a sybil attack [10]. Although peer-to-peer systems ap­pear especially vulnerable to sybil 
attacks due to their de­centralized nature, variants of sybil attacks currently plague many online services 
such as E-mail, web-based discussion forums, and other online public spaces. Existing proposals addressing 
the sybil attack generally fall under four categories: associating users with network endpoints, authenticating 
users real-world identities, limit­ing the rate or extent of attacks, and removing incentives to engage 
in sybil attacks. A related work from the economics .eld is a discussion of unreplaceble pseudonyms [12]. 
Authenticating Users by IP Address:. Many online services attempt to protect themselves from abuse by 
associating users with the IP addresses from which they connect. Despite such protections, MIT students 
suc­cessfully rigged a Slashdot poll via ballot stuf.ng in Novem­ber 1999 [33], and later a Doonesbury 
poll in 2006 [15]. Such feats are facilitated by MIT s inheritance of a vast, still mostly unused block 
of 224 IP addresses from the early days of the Internet. Legitimate users behind large NATs or web proxies 
[3], on the other hand, may be unable to cast even one vote if another user already voted from the same 
shared IP address. In effect, your voting power depends on how early your organization joined the Internet. 
E-mail spam is a form of sybil attack that has largely de­feated attempts to control abuse through IP 
address black­lists [24]. As a result of modern botnets that send spam from a constantly-changing set 
of compromised hosts, the volume of spam continues to rise [8, 26] even as legitimate E-mail disappears 
into increasingly sensitive spam .lters [19, 25]. Authenticating User Identities:. Many proponents of 
accountability see anonymity as the root of the problem, and propose disclosure of the user s true identity 
as the solution [7]. Public certi.cate author­ities such as Verisign offer personal, authenticated digital 
IDs for use in secure E-mail, but few users are even aware of these services, let alone willing to bother 
buying and us­ing one. A few web sites such as PayPal ask the user to enter a credit card or bank account 
number for identi.cation purposes, even if the user is not (immediately) making a pur­chase. Most web 
site operators however are reluctant to im­pose any unnecessary barriers to attracting new users. PGP 
key signing parties [2] authenticate user identities in a de­centralized manner, but these identities 
cannot be pseudony­mous, and are typically used only for signing E-mail. Single sign-on initiatives such 
as Windows Live ID [35], the Liberty Alliance [20], and OpenID [23] address the in­convenience to the 
user of entering personal information ev­erywhere by centralizing the user s information at a single 
identity provider, which various online services contact to authenticate the user. In addition to the 
practical and se­curity challenges to widespread deployment, however, these schemes create new privacy 
concerns [14]. Limiting Attack Rate or Extent:. Another defense against sybil attacks is to increase 
the cost of creating new identities. On-line Turing tests such as CAPTCHAs [33] can prevent fully-automated 
attacks when they are effective [4], but cannot protect against determined (or paid) users who simply 
solve puzzles repeatedly [28]. Computational puzzles [1] similarly slow down attacks only by some factor, 
and are easily countered by an abuser with a large botnet. Out-of-band approaches such as sending an 
invitation to a cell phone limit accessibility to users who have cell phones, don t exclude attackers 
who could sim­ply purchase multiple cheap phone accounts, and break the anonymity goal. Heuristics based 
on social network graph properties can similarly limit the power of large clusters of sybil identities 
[39]. These rate-and extent-limiting defenses may counter large-scale automated abuse, but do not prevent 
widespread small-scale attacks on systems in which every­one has an incentive to cheat just a bit, such 
as with online ballot stuf.ng or sock puppetry [29]. Removing Attack Incentives:. It may be possible 
to design certain applications so that users have no incentive to engage in sybil attacks by creat­ing 
multiple identities. This idea has been studied formally for combinatorial auctions, yielding some positive 
results to­gether with negative results suggesting that there is no gen­eral substitute for accountability 
[12, 38].  3. PSEUDONYM PARTIES Pseudonym parties are a scheme for creating accountable pseudonyms that 
preserve the user s ability to be anonymous while keeping him accountable for his actions. Pseudonym 
parties ensure that a given real-life person can only operate under one accountable pseudonym at a time 
within the con­text of a given online service. An online service for our purposes could be a web-based 
community like Wikipedia or Slashdot, a traditional application such as digitally signed E-mail, or a 
fully decentralized peer-to-peer system. We .rst introduce pseudonym parties in the context of a geographi­cally 
localized community, then explore how it can be de­centralized and scaled over larger geographical regions. 
3.1 One Body, One Pseudonym We can imagine many ways of enforcing a one person, one persona rule by leveraging 
various secondary labels associated with people: e.g., require the user to provide a unique and veri.able 
credit card number, cell phone number, home address, social security number, etc. Privacy issues aside, 
this approach suffers from the fact that people often have more (or fewer) than one such label. The number 
of such labels one can acquire is usually limited only by effort, .nancial resources, and in the case 
of labels that are legally required to be one-to-one risk of getting caught. People can acquire several 
credit cards, several phone numbers, sev­eral home addresses, several government identity cards un­der 
different names, several national citizenships with a sep­arate passport for each. Using secondary labels 
is also un­fair to the disadvantaged: not everyone has any credit card, phone, home address, or national 
citizenship [21]. Bar­ring certain sci-. scenarios, however, everyone still has one and only one body. 
Pseudonym parties leverage the of.ine foundation of a user s physical presence at an event to guar­antee 
a one-to-one relationship with online pseudonyms. On a particular day every year let s call it Pseudonym 
Day people who desire accountable pseudonyms gather locally and throw a party. Everyone who shows up 
at the party re­ceives a pseudonym certi.cate and a hand stamp that takes a few days to wear off, ensuring 
that they can obtain only one such certi.cate until next year s party. Each pseudonym certi.cate confers 
upon its holder the right to create one and only one accountable pseudonym on each of any number of online 
services that support such pseudonyms. A user might for example use his certi.cate to create one accountable 
pseudonym on Wikipedia, a second one on Slashdot, and a third on a peer-to-peer storage cloud. The user 
cannot create two separate Wikipedia accounts with the same certi.cate, however, or two identities on 
the same P2P storage cloud. One reason why online communities can grow so quickly is that signing up 
for new services is quick and easy a few clicks online is a much lower barrier to entry than any phys­ical 
transaction. Since a single certi.cate can be used on multiple services, including ones which did yet 
exist when the certi.cate was issued, pseudonym parties do not inhibit this ease of growth, so long as 
users already have a certi.cate to re-use from some other service.  3.2 Anonymous Single Sign-On A pseudonym 
certi.cate itself is simply a paper with a lo­gin name and password usable on a designated pseudonym 
server run by the pseudonym party s organizers. Suppose the user wishes to create an accountable pseudonym 
on a web-based online service such as Wikipedia. Wikipedia s web server temporarily redirects the user 
to his pseudonym server, where he logs in using his pseudonym certi.cate. The pseudonym server then returns 
the user to Wikipedia, where he .nds himself in his new pseudonymous account. When the user later logs 
into Wikipedia again with the same certi.­cate, the pseudonym server sends him back to the same ac­count. 
The user s pseudonym server might in similar fashion provide the user with sybil-proof identities for 
peer-to-peer systems the user may join. The pseudonym server acts like an identity provider in a single 
sign-on service [20, 23, 35], except that it does not identify the user but merely enforces the one person, 
one persona rule. The pseudonym server cannot directly reveal the user s identity even if compromised, 
since the user never provided any identi.cation or personal information when ob­taining his certi.cate. 
 The pseudonym server hides not only the true identity of the user, but also the association between 
the user s vari­ous pseudonyms for different online services, from both the users and operators of those 
services. If Bob uses his cer­ti.cate to create a professional pro.le on LinkedIn.com and a steamy personal 
pro.le on AdultFriendFinder, for example, no one can tell that the two pro.les represent the same person 
even if the two web sites collude or are hacked unless, of course, Bob gives away the connection. Online 
services could still allow traditional unauthenti­cated access, but offer special privileges to users 
of account­able pseudonyms, permitting incremental transition toward stronger accountability. A web-based 
forum like Slashdot may subject unauthenticated users to CAPTCHA puzzles [33] to deter automated attacks, 
impose initial waiting periods [13] and posting rate limits to discourage uncivil behavior, and disallow 
voting by unauthenticated users to prevent ballot stuf.ng. Users with accountable pseudonyms would be 
ex­empt from these restrictions, since misbehavior using an ac­countable pseudonym can be halted for 
the year merely by disabling that pseudonym. E-mail from users of account­able pseudonyms could be exempt 
from heuristic spam .l­ters, avoiding loss due to false positives [19, 25]. Peer-to­peer protocols might 
prioritize information obtained from neighbors with accountable pseudonyms over information from unauthenticated 
neighbors, since only the former can be trusted to represent a real person and not a sybil identity. 
 3.3 Security and Trust Model Although a user need not trust her pseudonym party s or­ganizers or servers 
not to divulge her personal information directly, she must trust them to protect the relationship be­tween 
the different accountable pseudonyms she obtains from the same certi.cate. If there are multiple pseudonym 
parties in her area on Pseudonym Day, she may freely choose which party to attend and thus which pseudonym 
provider to trust. Operators of online services must similarly trust pseudo­nym providers to enforce 
the one person, one persona prin­ciple. A web service s administrators might simply con.g­ure their site 
with an explicit list of pseudonym providers it considers trustworthy, in the same way a web browser 
ven­dor chooses the default set of SSL root certi.cates for its browser. Bringing the nodes of a decentralized 
peer-to-peer sys­tem into agreement on a set of pseudonym providers to trust might be more of a challenge. 
One approach is to slice the peer-to-peer cloud by pseudonym provider, so that instead of one large DHT 
for example, each node joins one DHT for each pseudonym provider it trusts, each DHT contain­ing all 
nodes that trust a particular provider. Each node then performs a given lookup in the DHTs for each of 
its trusted providers and combines the results. More ef.cient solutions are obviously desirable, however. 
 3.4 Federated Pseudonym Parties Not everyone can show up at one location on the same day, of course, 
so to scale geographically, many pseudo­nym parties must occur in different locations. If Pseudonym Day 
occurs at approximately the same time everywhere and all pseudonym parties follow adequately standardized 
proce­dures, a user should be able to drop into any nearby pseudo­nym party wherever he happens to be 
on Pseudonym Day to obtain his yearly certi.cate. In theory any group could independently organize a 
pseudo­nym party anywhere in the world, generating its own cer­ti.cates and running its own pseudonym 
servers. In prac­tice, however, groups will need to federate into larger or­ganizations with procedural 
controls and peer review, in or­der to persuade operators of online services that the federa­tion s certi.cate 
handout procedures and pseudonym servers are trustworthy. With inadequate security or organizational 
transparency, for example, malicious organizers could gen­erate more certi.cates than the number of people 
who showed up to a party and use the extras themselves, or insert a back door in a pseudonym server allowing 
themselves to gener­ate certi.cates on demand. The accountability problem thus shifts from keeping users 
accountable to keeping groups of organizers accountable. The organizational and security challenges of 
adminis­tering a federation of pseudonym parties resemble in some ways those of administering a democratic 
election, suggest­ing similar considerations and structures. All pseudonym parties need not .t under 
a single administration, however: several federations might evolve independently, covering dis­tinct 
or overlapping geographic regions, each with its own policies and pseudonym server infrastructure.  
3.5 Operating Costs If the organizational shape of a federation of pseudonym parties vaguely resembles 
an election administration, we might likewise expect the costs of running pseudonym parties to bear some 
similarity to the costs of administering an elec­tion. Pseudonym parties present three notable differences 
in cost model, however: Election costs are over once the election is decided, but a pseudonym party 
federation must operate pseudo­nym servers throughout the subsequent year. These costs should be predictable 
and not very labor-intensive, however, since the servers merely need to be kept run­ning and provisioned 
to meet the demand of the .xed number of users who obtained certi.cates that year.  On the other hand, 
governmental elections involve reg­istering voters and verifying citizenship and voting el­igibility; 
the costs of these procedures do not apply to pseudonym parties since by de.nition anyone who shows up 
is eligible.  Election commissions must be provisioned to handle all eligible voters who might show 
up to vote. If a  pseudonym party reaches capacity, however, people can go to other parties in the 
area or, in the worst case, wait and organize their own party next year. Starting a new party should 
be relatively easy and inexpensive, and costs should scale together with available volun­teer time and 
funding, in proportion to the number of active local participants. A recent UN study of several countries 
found election costs to be typically $1 3 per voter in developed countries and $4 8 per voter in stable 
countries with less electoral experience [16]. If costs can be kept to similar levels per capita, pseudonym 
parties should be able to cover their costs through voluntary donations or a nominal cover charge.  
 4. DEPLOYMENT Unlike identity-based single sign-on services or traditional public-key infrastructure 
(PKI), pseudonym account services do not need to be widely deployed all at once before they become useful 
at all. Non-pro.t organizations and special-interest groups that operate primarily within a local geographic 
region, for ex­ample, might initially both run online services of interest to the local public and organize 
pseudonym parties to pro­vide pseudonymous credentials for accessing their own on­line services, protecting 
their own online community forums from abusers both geographically local and remote. Ad hoc groups and 
organizations might in this way start with a purely local focus and gradually expand the useful geographical 
scope of the pseudonymous credentials they hand out by federating with other similarly developing groups 
and orga­nizations in other geographic areas. Ideally a pseudonym account obtained on Pseudonym Day anywhere 
in the world should eventually be usable to create accountable pseudony­mous identities on online services 
anywhere else in the world, but this long-term ideal need not be achieved all at once. Popular web sites 
that represent global participatory com­munities operating using deliberative democratic procedures, 
such as Wikipedia and Slashdot, are particularly sensitive to sybil attacks in the form of ballot stuf.ng 
or sock puppetry, but these same communities also tend to have many users who are concerned with preserving 
privacy and the ability to participate anonymously. Since pseudonym parties currently appear to be the 
only proposed solution that can address both strong accountability and privacy at the same time, these 
on­line services could bene.t greatly from such a scheme, and might therefore represent a likely context 
for initial experi­mentation with and deployment of pseudonym parties. There are of course many additional 
issues and details to work out in the implementation of such a scheme, though we wish to avoid specifying 
too many technical details at this point in the interest of focusing the discussion for now on higher-level 
social and usability issues. Here are a few such areas for discussion: Is there a safe way to give new 
users .rst-time pseudo­nym accounts immediately when they learn about the system, without forcing them 
to wait up to nearly a year until the next Pseudonym Day?  Should there be backup mechanisms to obtain 
pseudo­nym accounts in case a person is sick or otherwise im­mobile on Pseudonym Day, or is at a location 
where there is not yet any organized pseudonym party?  Might pseudonym parties be allowed to give users 
the choice of showing ID and attaching personal informa­tion to their pseudonym account, so that they 
could use the same account for both anonymous and identity­based single sign-on if they wish to?  Can 
we (and should we try to) prevent a rich person or organization from paying people to attend pseudonym 
parties and collecting the resulting certi.cates?  What speci.c software do pseudonym account servers 
and participating online services need, and what is the protocol by which they interact? Could existing 
identity­based single sign-on infrastructure be reused and adapted to this purpose?  Can we avoid requiring 
that pseudonym accounts be accessible at all times in order to log in to services, thus risking reduced 
availability?  To what extent, if any, should pseudonym parties and af.liated supporting organizations 
be allowed or en­couraged to build ties or accept the support of govern­ments or for-pro.t corporations? 
  5. CONCLUSION Combating the sybil attacks at the heart of many online problems such as spam, wiki 
vandalism, and online ballot box stuf.ng, need not and should not force us to give up our privacy. Pseudonym 
parties would protect users ability to maintain multiple disconnected, potentially anonymous online personas, 
while ensuring accountability and allowing online services to enforce the democratic one person, one 
vote principle when appropriate.  Acknowledgements We would like to thank Frans Kaashoek, Robert Morris, 
and the anonymous reviewers for their many helpful comments. This research is sponsored by the T-Party 
Project, a joint re­search program between MIT and Quanta Computer Inc., Taiwan, by the National Science 
Foundation under Cooper­ative Agreement ANI-0225660 (Project IRIS) and the NSF FIND program, with additional 
support from Nokia Research Center Cambridge. 6. REFERENCES <RefA>[20] Liberty Alliance Project. http://www.projectliberty.org/. 
[1] Adam Back. Hashcash a denial of service counter-measure, August 2002. http: //www.cypherspace.org/adam/hashcash/. 
[2] V. Alex Brennen. The keysigning party howto. http://cryptnet.net/fdp/crypto/ keysigning party/en/keysigning 
party. html. [3] Martin Casado and Michael J. Freedman. Peering through the shroud: The effect of edge 
opacity on IP-based client identi.cation. In 4th NSDI, Cambridge, MA, April 2007. [4] Kumar Chellapilla, 
Kevin Larson, Patrice Simard, and Mary Czerwinski. Computers beat humans at single character recognition 
in reading based human interaction proofs (HIPs). In 2nd Conference on E-mail and Anti-Spam, July 2005. 
[5] Curtis Chong. Graphical veri.cation: Another accessibility challenge. The Braille Monitor, November 
2003. [6] Ram Dantu and Prakash Kolan. Detecting spam in voip networks. In Proc. SRUTI, 2005. [7] David 
Davenport. Anonymity on the Internet: why the price may be too high. Communications of the ACM, 45(4):33 
35, April 2002. [8] Distributed Checksum Clearinghouse. http: //www.dcc-servers.net/dcc/graphs/. [9] 
Cory Doctorow. Solving and creating CAPTCHAs with free porn. Boing Boing, January 2004. [10] John R. 
Douceur. The sybil attack. In 1st International Workshop on Peer-to-Peer Systems, March 2002. [11] Joris 
Evers. ISPs versus the zombies. CNET News, July 2005. [12] E. Friedman and P. Resnick. The Social Cost 
of Cheap Pseudonyms. Journal of Economics and Management Strategy, 10(2):173 199. [13] Katie Hafner. 
Growing Wikipedia re.nes its anyone can edit policy. New York Times, June 2006. [14] Rosa R. Heckle and 
Wayne G. Lutters. Privacy implications for single sign-on authentication in a hospital environment (poster). 
In Symposium on Usable Privacy and Security, July 2007. [15] Hannah Hsieh. Doonesbury online poll hacked 
in favor of mit. MIT Tech, 126(27), June 2006. [16] IFES and UNDP. Getting to the CORE: A global survey 
on the cost of registration and elections, June 2006. [17] Adam Kalsey. Why IP banning is useless, February 
2004. http://kalsey.com/2004/02/ why ip banning is useless. [18] Will Knight. Wikipedia tightens editorial 
rules after complaint. New Scientist, December 2005. [19] Gene J. Koprowski. Spam .ltering and the plague 
of false positives. TechNewsWorld, September 2003.    [21] M. Lynch. Lives on hold: the human cost 
of statelessness, February 2005. [22] Matt May. Inaccessibility of CAPTCHA: alternatives to visual turing 
tests on the web, November 2005. W3C Working Group Note 23. [23] OpenID. http://openid.net/. [24] Anirudh 
Ramachandran, David Dagon, and Nick Feamster. Can DNS-based blacklists keep up with bots? In 3rd Conference 
on Email and Anti-Spam, July 2006. [25] Russell Shaw. Avoid the spam .lter. iMedia Connection, June 2004. 
[26] Spamnation. Spam statistics. http://spamnation.info/stats/. [27] Edward Stein. Queers anonymous: 
Lesbians, gay men, free speech, and cyberspace. Harvard Civil Rights-Civil Liberties Law Review, 38(1), 
2003. [28] Brad Stone. Breaking Google Captchas for some extra cash. New York Times, March 2008. [29] 
Brad Stone and Matt Richtel. The hand that controls the sock puppet could get slapped. New York Times, 
July 2007. [30] Al Teich, Mark S. Frankel, Rob Kling, and Ya ching Lee. Anonymous communication policies 
for the Internet: Results and recommendations of the aaas conference. Information Society, May 1999. 
[31] Brad Templeton. I remember USENET. O Reilly Network, December 2001. [32] Bill Thompson. Not as wiki 
as it used to be. BBC News, August 2006. [33] Luis von Ahn, Manuel Blum, Nicholas J. Hopper, and John 
Langford. CAPTCHA: using hard AI problems for security. In Eurocrypt, 2003. [34] Jonathan D. Wallace. 
Nameless in cyberspace: Anonymity on the internet, December 1999. Cato Institute brie.ng paper No. 54. 
[35] Windows Live ID. http://www.passport.net/. [36] Paul Wouters. Personal spam statistics 1997-2004, 
January 2005. http://www.xtdnet.nl/paul/spam/. [37] The constitutional right to anonymity: Free speech, 
disclosure and the devil. Yale Law Journal, 70(7):1084 1128, June 1961. [38] Makoto Yokoo, Yuko Sakurai, 
and Shigeo Matsubara. The effect of false-name bids in combinatorial auctions: New fraud in Internet 
auctions. Games and Economic Behavior, 46(1):174 188, January 2004. [39] Haifeng Yu, Michael Kaminsky, 
Phillip B. Gibbons, and Abraham Flaxman. SybilGuard: defending against sybil attacks via social networks. 
SIGCOMM Computer Communications Review, 36(4):267 278, 2006.  
			</RefA>
