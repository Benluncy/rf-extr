
 Analyses of Load Stealing Models Based on Differential Equations Michael Mitzenmacher Digital Systems 
Research Center 130 Lytton Ave. Palo Alto, CA 94301 michaelm~pa.dec.com Abstract In this paper we develop 
models for and analyze several randomized work stealing algorithms in a dynamic setting. Our models represent 
the limiting behavior of systems as the number of processors grows to infinity using differen-tial equations. 
The advantages of this approach include the ability to model a large variety of systems and to provide 
accurate numerical approximations of system behavior even when the number of processors is relatively 
small. We show how this approach can yield significant intuition about the behavior of work stealing 
algorithms in realistic settings. 1 Introduction Work stealing is a natural paradigm for distributing 
work-load in a parallel system in which underutilized processors seek out work from other processors. 
In contrast, in the zuorlc sharing paradigm overloaded processors attempt to pass on some of their work 
elsewhere in the system. In many cases work stealing can be a more effective means of balancing load 
than work sharing, especially in terms of communica- tion efficiency: when all processors are busy, no 
attempts are made to migrate work across processors. Work stealing has therefore been a popular strategy 
for multithreaded compu-tation. Several systems using the work-stealing idea have been implemented (see 
[4, p.6]), including the Cilk system F, 81. In this paper we analyze several simple randomized work stealing 
algorithms in a dynamic setting using simple Marko- vian models and an approach that has similarly been 
used to study work sharing algorithms [28, 29, 30, 37, 381. Pri- marily we study variations of the WS 
algorithm described by Blumofe and Leiserson [8]. We focus on the dynamic Permission to make digital 
or hard copies of all or part of this work for personal or classroom use is graoted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or 
to redistribute to lists, requiresprior specific permission and/or a fee. SPAA 98 Puerto Vallarta Mexico 
Copyright ACM 1998 o-89791-989-01981 6...$5.00 model where tasks enter the system over time according 
to a Poisson arrival process and require exponentially distributed service times. This model proves simplest 
for our analysis; however, as we explain, we can also use this technique to analyze other arrival and 
service distributions. Our models capture the limiting behavior of work stealing systems as the number 
of processors grows to infinity, repre-senting their behavior by differential equations. The advan-tages 
of this approach include the ability to model a large variety of systems and to provide accurate numerical 
ap-proximations of system behavior even when the number of processors is relatively small. The goals 
of this paper are to both demonstrate the effective- ness of this modeling technique for work stealing 
algorithms and to develop insight into work stealing algorithms based upon these models. We demonstrate 
the effectiveness of this technique by showing how a number of variations of work stealing algorithms 
and different system parameters can be modeled and by comparing the results of these models with simulation 
results for systems with a small number of pro- cessors. 1.1 Previous Work Work stealing has been treated 
extensively in a series of papers by Blumofe, Leiserson, and others [5, 6, 7, 81, who use work stealing 
in their Cilk system for parallel process-ing. Their models, which include not only computation time 
but also memory usage and communication costs, demon-strate that their work-stealing algorithms are optimal 
up to a constant factor in terms of execution time, and existen-tially optimal up to constant factors 
in terms of space and commlmication. Their experiments further show that their algorithms work well in 
practice. Other work stealing algo-rithms have also been developed and analyzed by Rudolph, Slivkin-Allalouf, 
and Upfal [34] and Karp and Zhang [15]. Work stealing has also been the subject of attention in the queueing 
theory literature, most notably in the early work by Eager, Lazwowska, and Zahorjan [Q] and the later 
work by Mirchandaney, Towsley, and Stankovic [24,25]. Our work is similar to theirs, although both our 
approach and our focus are different. The approach of using differential equations to study lim-iting 
versions of load balancing processes has been applied previously in several cases [2, 11, 22, 29, 37, 
381. Techni- tally, the relationship between the limiting system consist-ing of a family of differential 
equations and systems with a finite number of processors can be derived using the theory of large deviations; 
see, for instance, the body of work of Kurtz [lo, 17, 18, 19, 201, or a more modern treatment by Shwartz 
and Weiss [35]. The use of this approach in the study of algorithms dates back to work by Karp and Sipser 
[13], and has since been used to analyze several other al-gorithms, for example in [I, 11, 14, 21, 31, 
32, 391. Note that here we focus on how to use the technique and what insight it, in conjunction with 
simulations, gives us about work stealing algorithms, rather than on the technical rela-tionship between 
the limiting and finite systems. The rest of the paper is organized as follows. In Section 2, we describe 
the basic model used in our analysis. We then derive a family of equations describing the performance 
of a basic work stealing algorithm in this setting. We also demonstrate how to modify our analysis for 
simple varia-tions of the work stealing algorithm. In Section 3, we con- sider how to extend our analysis 
to more complex and real- istic models, including for example models where the service time is constant 
(instead of exponentially distributed) and where there is a transfer time associated with moving a task 
from one processor to another. Convergence issues are dis- cussed in Section 4. 2 Simple Work Stealing 
Systems In this section, we consider variations of the WS algorithm described by Blumofe and Leiserson 
[8] in a dynamic set-ting. These variations share an interesting property: in the limiting model, the 
fraction of processors with load at least i decreases geometrically for sufficiently large i. 2.1 A Dynamic 
Model We describe our initial model of a work stealing system. The system has n processors that execute 
dynamically generated tasks, generated at each processor as a Poisson process of rate X < 1. Tasks require 
an amount of service that is exponentially distributed with mean 1 before completing. The service times 
required by the tasks are not known to the processors. Tasks are served according to a First In First 
Out (FIFO) policy. The load of a processor is the number of tasks at that processor. At certain times, 
a processor may attempt to steal a task from another processor. Following the terminology of [8], we 
call a processor attempting to steal a thief, and say that it attempts to steal from a victim processor. 
We assume that stealing is accomplished instantaneously, so that the stolen task joins the queue of the 
thief immediately. Tasks will be stolen from the end of the victim s queue. We now provide a representation 
of the system useful for our analysis. We define ni(t) to be the number of processors with exactly i 
tasks at time t; mi(t) to be the number of pro- cessors with at least i tasks at time t; pi(t) = ni(t)/n 
to be the fraction of processors of size i; and si(t) = Cr=, pi(t) = mi(t)/n to be the tails of the pi(t). 
We drop the reference to t in the notation where the meaning is clear. As we shall see, the si prove 
much more convenient to work with than the pi. Note that SO = 1 always, and that the si are non-increasing 
as si-1 -si = pi. For the well-behaved systems we will be considering, we also have that limi,, si = 
0. The state of the system at any given time can be represented by an infinite dimensional vector s = 
(SO, sr, ~2,. . .), Note that our state only includes information regarding the num-ber of processors 
of each size. Since we are not making use of locality, the processors are indistinguishable, and this 
is all the information we require. Also, under the assumption that service times are exponential and 
arrivals are Poisson, the entire system is Markotian: the future of the system depends only on its present 
state, and not on the past that brought it to that state. 2.2 A Simple WS algorithm We initially study 
a variation of the WS algorithm described by Blumofe and Leiserson [8]. When a processor finds itself 
empty, it attempts to steal a task from a processor chosen uniformly at random. If a task is available 
-that is, the victim processor has more than one task -a task is stolen. For any n, it is easy to show 
that a system using this al-gorithm in our model is stable, in that its expected queue length is bounded 
as the time t + co, by a straightforward comparison with a system without stealing. To gain insight into 
how to set up the appropriate limiting system, let us first consider a system without load stealing. 
Let dmi represent the expected change in mi over a small interval of time dt. We think of dt as being 
a small enough interval of time so that only one event (an arrival or depar- ture) can happen at each 
processor in the interval. Let us first consider arrivals; an arrival increases rni if it occurs at a 
processor with load i -1. Since we have a Poisson arrival process of rate X at each processor, the probability 
an arrival occurs at each processor with i tasks is Xdt. Hence the ex-pected change in mi due to arrivals 
is just X(mi-1 -mi)dt. Similarly, the expected change in mi due to departures is (mi -mi+l)dt. Hence, 
the expected behavior of the system over short intervals is given by % = X(77%-1 - mi) -(mi -mi+l). 
Canceling the factor of n permeating the equations we find: 2 = X(Si-1 -Si) -(Si -Si+l). (1) Note that 
the system of differential equations (1) are in-dependent of n, the number of processors in the system. 
Instead, the are determined by densities of processors with a certain size. Further, the differential 
equations no longer describe a random process, but a deterministic one: given an initial condition, the 
solution of the system can be shown to be unique. Again, these differential equations describe the expected 
behavior of the system over small periods of time. When a family of Markov processes has transition rates 
in-dependent of n, the system size, and dependent only on the densities, it is called a density dependent 
jump Markov process. Kurtz s work demonstrates that, as n --$ 00, the behavior of the Markov process 
converges to that of the de- terministic process given by the corresponding differential equations (subject 
to certain conditions). That the system behaves according to its expectation in the limit is hardly surprising; 
essentially, it is a variation of the law of large numbers for density dependent Markov processes. Rather 
than focus on the technical details of this convergence, we explore how to use this methodology. The 
details of the the- ory behind this convergence can be found in many sources, including [lo, 29, 37, 
38, 391. Let us now consider how to modify the above equations in the case of load stealing. A processor 
that completes its final task attempts to find a victim, thereby reducing the rate at which it actually 
empties. The probability of success is just 52, the probability of choosing a victim processor that contains 
at least two tasks. Hence, to the processor, it appears as though it loses its final task only at the 
rate 1 - 32, instead of at the rate 1. The corresponding modified equation is given by da1 = X(30 -81) 
-(91-32)(1-32). (2) -z- For i > 1, ai decreases whenever a processor with load i completes a task, or 
when a task is stolen. The rate at which thieves steal tasks is just (ai -as), the rate at which processors 
complete their final task, yielding Notice that we maintain the property that our system of equations 
is density dependent (independent of n). To un-derstand the long term behavior of the system, we find 
a fixed point for the system of equations given by (2) and (3). A iixed point is a state at which dai/dt 
= 0 for all i; if the system reaches its fixed point, it remains there. Most well-behaved processes follow 
trajectories that converge to their fixed points. To determine the fixed point, we note the following 
facts: 0 se = 1 for all time. l The rate at which tasks complete is sin, the number of busy processors. 
l The rate at which tasks are introduced is Xn. l At the fixed point, the rate at which tasks complete 
and the rate at which they are introduced must be equal. Let us denote the fixed point by the vector 
(ne,ni,. . .). Then the above facts tell us that ~0 = 1 and ~1 = X. From equation (2), and using the 
fact that dal/dt = 0 at the fixed point, we solve for 7~. We find ~2 = 1+ x -d/1+ 2x -3x2 2 Using induction, 
equation (3), and the fact that dsi/dt = 0 at the fixed point, we find that for i > 2, Hence, for i 1 
2, the 7~i decrease geometrically. Let us contrast this result with the case of no stealing, where the 
fixed point is 7~i = Xi, as can be verified by equation (1). In both cases, the fraction of processors 
with load at least i decreases geometrically, but with load stealing the tails decrease faster. It is 
as though the service rate has increased due to the stealing. There is a useful interpretation for this 
phenomenon. Stan-dard queueing theory yields that in a system with no steal- ing, arrival rate X, and 
service rate p, the tails of the load decrease geometrically with a ratio X/p between successive terms. 
(Recall that we have scaled so that p = 1 for the equation (l), and thus the tails of the loads decrease 
geo-metrically as pi = X .) From the point of view of a processor with at least two customers in the 
work stealing system, the apparent service rate II is the standard service rate 1 plus the rate at which 
a task is stolen, which is xi -7~2= X - ~2. Hence we expect the tails to decrease geometrically at rate 
X/p = X/(1 + X - 7rs), and this intuition is verified by the derivation of the fixed point. We briefly 
demonstrate the accuracy of the limiting ap-proach by comparing the predicted results for the expected 
time each task spends in the system with simulations for this simple WS model in Table 1. All simulation 
results are based on the average of 10 simulations of 100,000 seconds esch, with the first 10,000 seconds 
thrown out to mitigate the impact of starting with an empty system. The table demonstrates several important 
features: The prediction improves with the number of proces- sors. The prediction improves as the arrival 
rate decreases. Even at only 128 processors, the predictions are ex-tremely accurate, particularly at 
smaller arrival rates. We now demonstrate the ease with which one can construct systems of differential 
equations describing variations of the basic model we have considered above.  2.3 Threshold Stealing 
It is perhaps more realistic to suppose that thieves will steal only from processors whose load is at 
least some threshold T, in order to improve the chances that the cost of transferring the job is worthwhile. 
In this case, the probability that a steal fails to occur when a processor finishes all pending tasks 
is 1 - ST, and hence the limiting system behavior is described by the following set of differential equations: 
da1 = x(30 -31) -(31 -32)(1 -ST) (4) dr dai = X(ai-1 -ai) -(ai -ai+l) , 2 < i 5 T -1 (5) dt dai = X(3&#38;1 
-Si) -(Si -Si+1) dt (6) -(si -ai+i)(si -32) , i 2 T X ] Sim(16) ] Sim(32) ] Sim(64) 0.50 I 1.631 I 1.626 
1 1.622 0.70 2.153 2.133 2.119 0.80 2.678 2.617 2.586 0.90 3.905 3.711 3.624 0.95 5.936 5.368 5.138 0.99 
17.863 14.368 12.183 Table 1: Simulations vs. estimates for the simplest WS model. and the estimate 
based on the fixed point calculation. Again, we seek a fixed point, beginning with ~0 = 1 and ~1 = X. 
From equation (4) we obtain Rl= 1 -TT . To find the value of TT, we use a recurrence obtained from equation 
(5): Ti+l = Ai -X(T$-1 -Ti). This yields XT -hT m = 1 -r* which allows us to solve for TT: 1+x-&#38;1+X)2--P 
XT = 2 By equation (6) and the fact that the dai/dt are zero at the fixed point, we have for i 2 T that 
(7) We will show that VrT = e; then a simple induction using equation (7) yields i-T > Hence for i 
> T the ni again decrease geometrically at a fester rate than a system without load stealing. This equa, 
tion also matches the intuition develop in Section 2.2; for queues with load at least T, the apparent 
service rate p is again the standard service rate 1 plus the rate at which a task is stolen, which is 
~1 -~2 = X - 7~. To show XT = &#38; we use the fact that foci % = 0 at the fixed point. Most of the terms 
in this summation cancel (that is, we have telescoping sums), yielding ii(KO -TT-1) -(T1 -TT) + TT(Tl 
-74 = 0. Using rre = 1 and 7~ = A, the relation for RT easily follows. 2.4 Preemptive stealing Instead 
of waiting until the task queue is empty, a thief processor may wish to begin attempting to steal work 
when the number of tasks it has left is sufficiently small. In such a ] Sim(128) I Estimate Rel Error 
(%) 1 1.620 1 1.618 0.15 2.114 2.107 0.30 2.576 2.562 0.56 3.586 3.541 1.24  5.000 4.887 2.25 11.306 
10.462 7.46 The relative error is between the simulatins with 128 processors system we have two parameters: 
B, the number of tasks at which a processor begins steal attempts, and T, a threshold such that a processor 
with i tasks will only steal from a processor with at least i + T tasks. The limiting system has the 
following form: dai = X(ai-1 -Si) -(Si -ai+i)(l -Si+T-I), 1 5 i 5 B + 1 dt dai = X(ai-1 -ai) -(ai -ai+l), 
B + 2 5 i 5 T -1 dt dai = X(Si-1 -ai) -(ai -ai+l)dt -(Si -si+i)(Si -%in(B+2,i-T+2)) , i 2 T In this 
case, for i > B + T, the tails decrease geometrically according to i-(B+T) x ri = ITB+T l+~-~B+Z ( > 
 Thii formula can be derived using intuition of Section 2.2, or by an inductive argument from the equivalent 
of equation (7) for this model. 2.5 Repeated Steal Attempts In the WS algorithm as described in [8], 
if the thief fails to find a suitable victim on the first attempt, further attempts are made to find 
a suitable victim. We can model this behav- ior by allowing empty processors to repeatedly make steal 
attempts at a certain rate, say T per unit time. To fit with our standard model, we assume that the time 
between steal attempts is exponentially distributed. If there is a threshold T so that a victim must 
have at least T tasks, the equations describing the limiting system become: da1 = X(30 - al) + r(a0 -31)aT 
-(al -32)(1 -ST) dt dai = X(si-1 -ai) -(ai -ai+i) , 2 < i 2 T -1 dt dai = X(ai-1 -ai) -(Si -Si+l) 
-(31 -32)(3i -Sift) dt -v-(so -sl)(si -si+l) , i 2 T Again, in this system at the iixed point ii the 
xi decrease Table 2: Simulations vs. Estimates for the Constant Time Model compared with the estimates 
using 10 and 20 stage approximations geometrically for i > T, according to the formula i-T x 1+ T-(1-X) 
+ x -7rz . Note that, in the limit as T goes to infinity, ?rT goes to 0. This stands to reason, since 
in the limiting system a processor with load T tasks will have a task stolen immediately. 3 More Complex 
Variations In this section, we examine more complex extensions to the basic models we have described. 
In particular, many of our extensions are motivated by the goal of making the models more realistic. 
For convenience, we consider each modifica- tion separately, although it should be clear from the presen- 
tation that the extensions can be combined as desired (albeit by making the corresponding systems of 
differential equa- tions more complicated and hence more difficult to solve). 3.1 Varying service and 
arrival distributions The need for exponential service and Poisson arrivals ap- pears to limit the usefulness 
of this approach. However, one can approximate other service times and arrival distribu- tions using 
mixtures of these simple distributions. The ap- proach, generally known as Erlang a method of stages, 
is ex- plained more fully in [16][Sections 4.2 and 4.31. We demon- strate the method here by considering 
the case of constant service times. We replace the constant service time with a collection of c stages 
of services; each stage of service is exponentially distributed with mean l/c. A service distri- bution 
of this type is a gamma distribution. As c goes to infinity, the expected time spent in these c stages 
of service remains 1 and the variance approaches zero; that is, the ser- vice appears like a constant 
random variable. In practice, computing the fixed point requires limiting c to a reason- ably small finite 
number, since the number of terms in the fixed point grows proportionally with c. Even for reasonably 
small c, however, the predictions become very accurate. The state will again be represented by avector 
s = (so, al, 52,. . .), but here ai represents the fraction of processors with at least i stages left 
to complete. Note that, when a steal occurs, the values from ai up to ac all change. For the case where 
T = 2, that is, if we steal whenever possible, the resulting equations are: dst = X(30 - 31) -c(s1 -s2)(1 
-sc+l) dt (T = 2): Simulations for 16, 32, 64, and 128 processors are of constant time. dsi dt = X(90 
-Si) + c(s1 -32)9i+c -c(ai -aifl) , 2 I i I c dai dt = X(ai-, -Si) -C(3i - 3i+i) - c(ai-a9i+c)(a1-a2), 
iZc+l In principle, this approach could be used to develop deter- ministic differential equations that 
approximate the behav-ior of any service time distribution or arrival distribution to any desired accuracy. 
This is because the distribution function of any positive random variable can be approxi-mated arbitrarily 
closely by a mixture of countably many gamma distributions. We can thus develop a suitable state space 
for a Markov process that approximates the underly- ing non-Markovian process. There is a tradeoff, however, 
in that the better the approximation we obtain, the larger the state space, and hence the more calculation 
required to numerically evaluate the fixed point. The simulations presented in Table 2 demonstrate that 
for constant service times, taking c = 20 provides good approx-imations for actual systems. These results 
also show that systems with constant service times perform significantly better than systems with exponentially 
distributed service times, in terms of the average time spent in the system. We do not have a proof that 
this holds in general; it would be interesting to prove such a result either using the fixed point (see 
[29, Section 4.31) or other techniques (see, for example, [12, 26, 27, 33, 361).  3.2 Transfer time 
Up to this point we have assumed that a job can be trans- ferred instantaneously to another processor. 
More realisti-cally moving a task from the victim to the thief will require some time for transfer. For 
convenience we model the trans- fer time as an exponentially distributed variable with mean l/r (that 
is, transfers occur at rate T), although it can also be modeled as a fixed constant, or some other distribution, 
using the technique of Section 3.1. In this model we allow a thief processor to only steal one task at 
a time; that is, as long as there is a task on the way from another processor, it will not attempt to 
steal again. We expand our state space to explicitly distinguish thief processors who are awaiting a 
stolen task from other processors. Our state space will hence consist of two infinite dimensional vectors: 
(so, al, . . .) will record the fraction of processors not awaiting a stolen task, where as usual ai 
refers to the fraction of such processors with at least i tasks. A second vector, (we, wi , . . .) will 
similarly record the fraction XI T=3 T=3 T=41 T=41 T=51 T=51 T=6) T=61 Sim( 128) Est. Sim( 128) Est. 
1 Sim(128) 1 Est. 1 Sim 128 1 Est. 0.50 1.986 1.985 1.950 1.950 I 1.955 I 1.954 I 1.967 I 1.967 0.70 
2.973 2.971 2.939 2.938 2.963 2.961 3.011 3.008 0.80 4.038 4.030 4.003 3.996 4.025 4.020 4.082 4.079 
0.90 7.099 7.076 7.056 7.015 7.025 7.001 7.045 7.026 0.95 13.162 13.106 13.089 13.016 13.048 12.956 13.067 
12.925 Table 3: The expected time with transfer times, where r = 0.25, according to simulations and estimates 
from the fixed point of the differential equations. The best threshold is T = 4 = l/ T for small arrival 
rates, but is larger at higher arrival rates. of processors awaiting a stolen task. The variable wi refers 
to the fraction of such processors currently with at least i tasks. We note this change in state space 
calls for changes in the fixed point conditions. For example, we now have that SO + wc = 1 for all time. 
Also, si + w1 = X at the fixed point, as the rate at which tasks are served must equal the rate at which 
tasks enter the system. Finally, the expected number of tasks per queue in the system is xi>, si + ci2o 
wi; this summation accounts for the extra tasks in transit between processors. The equations below describe 
this process when a steal is at- tempted only when a processor empties and a steal happens only when 
the victim processor has at least T tasks: dso = TWO-(31 -32)(3T + WT) dt dsl = X(s0 -31) + rwo -(31 
-32)dt dsi = X(si-1 -si) + rwi-1 -(si -Si+l) , 2 < i 5 T -1 dt dsi = X(Si-1 -Si) + rwi-1 -(Si -Sifl) 
 dt -(si -si+l)(sl -32) , i L T dwo --TWO+ (31 -32)(3T + WT) dt= dwi = X(wi-1 -wi) -rwi -(wi -Wi+l) 
, 1 5 i 5 T -1 dt dwi = X(W(-l-WWi)-TWi-(Wi-Wi+l)- dt (20i -wi+l)(sl -32) > i 1 T Note that we allow 
tasks to be stolen from a processor that is waiting for a task. We might expect that a thief should not 
attempt to steal a task unless in so doing it reduces the expected time that task will remain in the 
system. Such a rule would suggest that the best threshold T must satisfy T x (l/r) + 1. To minimize the 
expected time for all tasks, however, this simple rule is only a rough approximation. As seen in the 
example for r = 0.25 presented in Table 3, the fixed point solutions to the differential equations can 
be used correctly determine the best threshold value for various arrival rates. 3.3 Multiple choices 
In load sharing algorithms, systems that have some choice of where to place new jobs has proven to have 
different per-formance characteristics than systems where jobs are placed randomly [3, 29, 371. For example, 
suppose that, upon en-try, a task chooses two servers uniformly at random, and queues at the one with 
the smaller load. There is an expo- nential improvement in such performance measures as the average time 
in the system and the expected heaviest load in the system over a system where each task queues at a 
ran- dom server. This motivates examining the following work stealing strategy: a thief chooses d random 
potential vic-tims simultaneously, and then (if possible) steals load from the most heavily loaded victim. 
If the victim must have load at least T, the probability that a steal fails to occur equals the probability 
that all d victims have load less than T; this happens with probability (1 -3~)~. Similarly, the probability 
that a victim processor with load i is found is (1 -s~+I)~ -(1 -LQ)~. Hence, if we constrain d to be 
a fixed constant, independent of the number of processors n, then we can write a corresponding limiting 
system with the following form: dsl = x(3,, -31) -(31 - 32)(1 -sT)ddt dsi = X(S~-1 -pi)- (Si -Si+l) 
, 2 < i 5 T-1 dt dsi = X(Si-1 -Si) -(Si -Sifl)dt -((1 -s~+I)~ -(1 -si)d)(sl -32) 9 i 1 T Table 4 compares 
a system where two potential victims are chosen to a system where just one choice is made. Choos-ing 
more victims does improve performance, especially at higher arrival rates, but just choosing a single 
victim gen-erally yields most of the gain possible. The intuition of Section 2 offers helpful insight: 
using d choices makes steals occur at most d times the usual rate for even the most heav-ily loaded queues, 
and hence the best we could hope is that the tails fall geometrically at rate X/(1 + d(X -~2)). Since 
systems where multiple choices are made would require ad-ditional complexity, it is by no means clear 
that the gain would be worthwhile in a real system. Table 4 also shows that again the estimate derived 
fixed point is an accurate prediction for actual systems of 128 processors at reasonable arrival rates. 
Table 4: Simulation results comparing one choice to two (with T = 2, 128 processors) and the corresponding 
estimate from the fixed point. 3.4 Multiple steals In certain situation stealing more than one task 
may be ap- propriate. For example, if the threshold T for stealing is high, then stealing more than one 
process should improve the expected time a task spends in the system. Let us con- sider the WS algorithm 
where when a steal is made /c 5 T/2 tasks are taken. Note that when a steal occurs, not only 31 increases, 
but 32,33,. . . , 8k do as well. Similarly, when a steal is made, many si values decrease. Taking this 
into consideration yields the following family of differential equa-tions: dsl = X(30 -31)-(51 -sz)(l-ST) 
 dt dsi = x(Si-1 -Si) -(Si -3;+1) + (91 -32)ST , 2 5 i 5 k dt dsi X(si-1 -si) -(si -si+l) , k + 1 5 
i 5 T -k dt= dsi = x(Si-1 -Si) -(8i -3i+l) -(31 -32)(3T -3i+k) , dt T-k+l<i<T dsi = x(3&#38;1 -Si) -(8i 
-S:+l) -(81 -32)(3i -8i+k) , dt T+l<i  Other variations for stealing multiple jobs in the WS algo- rithm 
can be modeled similarly. As one might expect, in this model (where the time for a transfer is zero) 
increasing the number of jobs stolen so as to equalize the processor loads improves performance. More 
complicated algorithms that steal multiple items at a time are also possible. For example, we consider 
a varia-tion of a load balancing algorithm suggested by Rudolph, Slivkin-Allalouf, and Upfal [34], in 
which a processor at cer- tain randomly determined steps chooses another processor uniformly at random 
and the two machines balance the load between them. Here, we can model a re-balancing event at a processor 
as a process that occurs at an exponential rate r(i), perhaps depending on the number of items i at the 
processor. When a re-balancing event occurs, the tasks are balanced between this processor and another 
processor chose uniformly at random. (For convenience, the proces-sor with the larger initial load with 
also have the larger final load.) Surprisingly, this system can be represented in a quite straightforward 
manner: for i > i, dsi = X(3;-1 -Si) -(3; -si+l) dt 2i-2 Zi-2-j - y r (r(j) +r(k))(sk-3k+l)(3j -3j+l) 
j=i kc0 i-l OD i- c c (r(j) f T(k))(sk -3k+l)(3j -3i+l) k=O j=Zi-k  3.5 Varying processor speeds, varying 
arrival rates, and static systems Thus far the systems studied have been homogeneous, in that all processors 
run at the same rate and tasks arrive at the system at the same rate. We note that this is not nec-essary; 
we can model different processor types by keeping a separate state vector for each type of processor. 
For exam-ple, if there are two types of processors, fast and slow, then we can represent slow processors 
by a vector s = (SO, ~1~32,. . .) and fast processors by a vector 13= (wc, ~1, wz, . . ,). In our limiting 
model, each processor type must correspond to a fixed &#38;s&#38;ion of the total number of processors. 
We can also enhance the model by introducing the concept of internal and external arrival rates. That 
is, we can replace the arrival rate X by Xszt + Xint, where X,t corresponds to the rate of new tasks 
arriving into the system and Xd,t corresponds to the rate of new tasks being spawned by tasks already 
at the processor. Note Xint can be made to depend on the number of tasks at the processor if desired. 
In particular, by setting X,t = 0 and Xint = 0 when there are no tasks in the queue, we can model a static 
system that starts in some initial state and runs until all queues are empty. For sufficiently large 
systems, the limiting system can give a good approximation for the amount of time until the system completes 
all jobs. 4 Convergence and Stability Thus far, when considering families of differential equations, 
we have focused on finding a fixed point, with the intuition that the system converges to that hxed point. 
To justify this intuition one would hope to prove that, regardless of the starting point, the trajectory 
taken by the path given by the solution of differential equations does in fact approach the fixed point 
quickly over time under some metric. That is, we would like to show convergence of the system to its 
fixed point. Such convergence results have been shown previously for similar systems in [29, 37, 381. 
In some cases where we cannot prove convergence, we can prove a weaker result, namely the stability of 
the jIxed point. For our purposes, we shall say that a fixed point is stable if the L1 distance to the 
fixed point is non-decreasing over time. (This is stronger than the standard definition.) Al- though 
this only shows that the trajectory does not ever head away from the fixed point, it provides some reason 
to believe that the system converges rapidly to its fixed point. Techniques for proving stability are 
also described in [29, Section 4.61. In the work stealing setting, both stability and convergence results 
prove difficult. Even for the simple sys- tem given by equations (2) and (3), we can only prove the stability 
of the fixed point for sufficiently small arrival rates X, as we shall show in the theorem below. We 
note that, in practice, one can check for convergence to the fixed point numerically using various starting 
points to convince oneself that the system is well behaved. Devising proofs for the convergence or better 
proofs for the stability of the work stealing systems described here, however, remains an important open 
question. Theorem 1 The system given by equations (2) and (3) are stable for X such that 1r2 < l/2. Proof: 
Define ti(t) = ai -ni. (Note to(t) is identically 0.) We drop the explicit dependence on t when the meaning 
is clear. The Li distance D(t) is then &#38;,-Iti(t)l. As D(t) = cz_, Iei(t)l, the derivative of D with 
respect to t, or dD/dt, is not well defined if ei(t) = 0. We shall explain how to cope with this problem 
at the end of the proof, and we suggest the reader proceed by temporarily assuming ci(t) # 0. As dcd/dt 
= dsi/dt, we may obtain equations for dci/dt using (2). It is convenient to write the derivatives dti/dt 
in the following form: dtl --At1 -(Cl -E2)(1 -32)+62(Tl -TZ); (8) dt= dti dt = X(6;-1 -Ci) -(ti -ci+l)(l 
+ 7ri -74 (9) -(Cl -tZ)(Si -Si+l), i > 1; Note that dD O dl4 -* dt= c dt i=l Using the above, we examine 
the terms sum of containing ti in adt , and show that the resulting expression is non-positive for each 
i. Let us first consider the case where i 2 3, as the cases i = 1,2 are more difficult. There are several 
subcases, depending on whether c+i,t;, and cg+l are positive or negative. Let us first consider the case 
where they are all positive. Then the terms containing pi in dD/dt are Q[(--x -1 - X1 + 74 + x + (1+ 
7r1 - 7r2)] = 0. Similarly, in all subcases, the sum telescopes to something linear in ci with a coefficient 
that is zero or the opposite sign from Ci. Hence the sum of terms containing ci in dD/dt is always non-positive 
for i 2 3. For the case i = 2, there are ~2 terms in all other y terms. However, the terms from y dominate 
all others. For example, if ~2 is positive, the corresponding terms in y are (-A -(1 -32) -(Tl -X2) -83)62. 
 Even if all other cj are set so that the coefficients of 62 in w are positive, the sum of the other 
.ss terms is just (x+(1 -32)+ (nl -rZ)+ 33)62, and hence the sum of terms containing ~2 in dD/dt is 
always non-positive. The only difficulty lies in the case where i = 1. In this case, if (for example) 
~1 and c2 are both positive, then the sum of terms containing tl from $$ and w is -(l -92)cl. If cj < 
0 for j 2: 3, however, then the sum of cl terms from all other T is 93~1. Hence the total sum of all 
terms could be as much as -(l -2ss)ti, which is positive when 93 > l/2. This case, however, requires 
that 93 < 7r3, since cs < 0. Hence if 7rs 5 l/2, the coefficient of 61 is negative as desired. The worst 
case in this instance is when ~1 and 62 are both negative and cj > 0 for j > 3. Then the corresponding 
sum of terms is (1-283)tl, with the limitation that 93 2 32 5 7r2. Hence, if we restrict X so that 7ra 
< l/2, then the cl terms are always non-positive, so we have stability. We now consider the technical 
problem of defining dD/dt when ci(t) = 0 for some i. Since we are interested in the forward progress 
of the system, it is sufficient to consider the upper right-hand derivatives of ci. (See, for instance, 
[23, p. 161.) That is, we may define @iI dt t=t() and similarly for d@/dt. Note that this choice has 
the fol-lowing property: if e(t) = 0, then %I,=,, 2 0, as it intu- itively should be. The above proof 
applies unchanged with this definition of dD/dt, with the understanding that the case ci > 0 includes 
the case where ti = 0 and dei/dt > 0, and similarly for the case ci < 0. n In the case of threshold stealing, 
we have essentially the same result. Theorem 2 The system @uen by equations (d), (5), and (6) are stable 
for X such that 7rz 5 l/2. ProoE The proof follows the same pattern as Theorem 1, following a case by 
case analysis where the only problem is in bounding the coefficient of the terms of cl. n We leave the 
reader to consider the other systems we have described. 5 Conclusions We have suggested an approach for 
analyzing load stealing systems based on limiting models of such systems that can be represented by families 
of differential equations. The ad-vantages of this modeling technique include simplicity, gen-erality, 
and the ability to accurately predict performance. Our results provide some insight into why simple, 
decen-tralized work-stealing schemes prove effective in practice. In particular, in an idealized dynamic 
setting where steals occur instantaneously, the tails of the task queues at the pro- cessors decrease 
geometrically at a faster rate than without load stealing. We expect that these models will prove useful 
in designing future systems that use load stealing methods to balance load. References <RefA>D. Achlioptas 
and M. Molloy. The analysis of a list- PI coloring algorithm on a random graph. In Proceedings of the 
33th IEEE Symposium on Foundations of Com-puter Science, pages 204-212, 1997. M. Alanyali and B. Hajek. 
Analysis of simple algo- PI rithms for dynamic load balancing. In INFOCOM 95, 1995. Y. Azar, A. Broder, 
A. Karlin, and E. Upfal. Balanced PI allocations. In Proceedings of the 26th A CM Symposium on the Theory 
of Computing, pages 593602, 1994. R. Blumofe. Executing Multithreaded Program Ejj? PI ciently. PhD thesis, 
Massachusetts Institute of Tech- nology, September 1995. R. Blumofe, M. Frigo, C. Joerg, C. Leiserson, 
and 151 K. Randall. An analysis of dag-consistent distributed shared-memory algorithms. In Proceedings 
of the 8th Annual ACM Syposium on Parallel Algorithms and Ar-chitectures, 1996. R. Blumofe, C. Joerg, 
B. Kuszmaul, C. Leiserson, PI K. Randall, and Y. Zhou. Cilk: An efficient multi-threaded runtime system. 
In Proceedings of the 5th ACM SIGPLAN Symposium on Principles and Prac-tice of Parallel Programming, 
1995. R. Blumofe and C. Leiserson. Space-efficient scheduling VI of multithreaded computations. In Proceedings 
of the 25th Annual ACM Symposium on Theory of Comput-ing, pages 362-371, 1993. R. Blumofe and C. Leiserson. 
Scheduling multithreaded PI computations by work stealing. In Proceedings of the 35th Annual IEEE Conference 
on Foundations of Com-puter Science, 1994. D. L. Eager, E. D. Lazokwska, and J. Zahorjan. A com- PI parison 
of receiver-initiated and sender-initiated adap-tive load sharing. Performance Evaluation Review, 16:53-68, 
March 1986. S. N. Ethier and T. G. Kurtz. Markov Processes: Char- PO1 acterization and Convergence. John 
Wiley and Sons, 1986. B. Hajek. Asymptotic analysis of an assignment prob- WI lem arising in a distributed 
communications protocol. In Proceedings of the 97th Conference on Decision and Control, pages 1455-1459, 
1988. M. Harchol-Balter and D. Wolfe. Bounding delays in packet-routing networks. In Proceedings of the 
Twenty-Seventh Annual ACM Symposium on the Theory of Computing, pages 248257, 1995. PI R. M. Karp and 
M. Sipser. Maximum matchings in PI sparse random graphs. In Proceedings of the 22nd IEEE Symposium on 
Foundations of Computer Science, pages 364-375, 1981. P41 R. M. Karp, U. V. Vazirani, and V. V. Vazirani. 
An optimal algorithm for on-line bipartite matching. In Proceedings of the 22nd A CM Symposium on the 
Theory of Computing, pages 352-358, 1990. [W R. M. Karp and Y. Zhang. A randomized parallel branch-and-bound 
procedure. In Proceedings of the 20th ACM Symposium on the Theory of Computing, pages 290-300, 1988. 
L. Kleinrock. Queueing Systems, Volume I: Theory. PI John Wiley and Sons, 1976. T. G. Kurtz. Solutions 
of ordinary differential equations 1171 as limits of pure jump Markov processes. Journal of Applied Probability, 
7:49-58, 1970. T. G. Kurtz. Limit theorems for sequences of jump PI Markov processes approximating ordinary 
differential processes. Journal of Applied Probability, 81344-356, 1971. T. G. Kurtz. Strong approximation 
theorems for den- PI sity dependent Markov chains. Stochastic Processes and Applications, 6:223-240, 
1978. PI T. G. Kurtz. Approximation of Population Processes. CBMS-NSF Regional Conf. Series in Applied 
Math. SIAM, 1981. M. Luby, M. Mitzenmacher, M. A. Shokrollahi, Pll D. Spielman, and V. Stemann. Practical 
loss-resilient codes. In Proceedings of the 29th ACM Symposium on the Theory of Computing, pages 150-159, 
1997. J. Martin and Y. M. Suhov. Fast jackson networks. PI available at www. statslab. cam. ac.uk/ jmb, 
January 1998. A. N. Michel and R. K. Miller. Qualitative Analysis of [231 Large Scale Dynamical Systems. 
Academic Press, Inc., 1977. R. Mirchandaney, D. Towsley, and J. A. Stankovic. P41 Analysis of the effects 
of delays on load sharing. Jour-nal of Parallel and Distributed Systems, 1513-1525:331-346, November 
1989. R. Mirchandaney, D. Towsley, and J. A. Stankovic. P51 Adaptive load sharing in heterogeneous systems. 
Jour-nal of Parallel and Distributed Systems, 9:331-346, 1990. M. Mitzenmacher. Bounds on the greedy 
routing algo- PI rithm for array networks. In Proceedings of the Sixth Annual ACM Symposium on Parallel 
Algorithms and Architectures, pages 248-259, 1994. To appear in the Journal of Computer Systems and Science. 
M. Mitzenmacher. Constant time per edge is optimal P-4 on rooted tree networks. In Proceedings of the 
Eighth Annual ACM Symposium on Parallel Algorithms and Architectures, pages 162-169, 1996. M. Mitzenmacher. 
Load balancing and density depen- PI dent jump Markov processes. In Proceedings of the 37th IEEE Symposium 
on Foundations of Computer Science, pages 213-222, 1996. M. Mitzenmacher. The Power of Two Choices in 
Ran- PI domized Load Balancing. PhD thesis, University of Cal- ifornia at Berkeley, September 1996. 
[30] M. Mitzenmacher. On the analysis of randomized load balancing schemes. In Proceedings of Lhe 9th 
Annual Symposium on Parallel Algorithms and Architectures, pages 292-301, 1997. [31] M. Mitzenmacher. 
Tight thresholds for the pure literal rule. Technical Report Technical Note 1997-011, Digital Systems 
Research Center, June 1997. [32] B. Pittel, J. Spencer, and N. Wormald. Sudden emer-gence of a giant 
k-core in a random graph. Journal of Combinatorial Series B, 67:111-151, 1996. [33] R. Righter. and J. 
Shanthikumar. Extremal properties of the FIFO discipline in queueing networks. Journal of Applied Probability, 
29:967-978, November 1992. [34] L. Rudolph, M. Slivkin-Allalouf, and E. Upfal. A sim- ple load balancing 
scheme for task allocation in parallel machines. In Proceedings of the 3rd Annual ACM Sy-posium on Parallel 
Algorithms and Architectures, pages 237-245, 1991. [35] A. Shwartz and A. Weiss. Large Deviations for 
Perfor-mance Analysis. Chapman &#38; Hall, 1995. [36] G. D. Stamoulis and J. N. Tsitsiklis. The efficiency 
of greedy routing in hypercubes and butterflies. IEEE tinsactions on Communications, 42(11):3051-3061, 
November 1994. An early version appeared in the Proceedings of the Second Annual A CM Symposium on Parallel 
Algorithms and Architectures, p. 248-259, 1991. [37] N. D. Vvedenskaya, R. L. Dobrushin, and F. I. Karpele- 
vich. Queueing system with selection of the shortest of two queues: An asymptotic approach. Problems 
of In-formation fiansmission, 32115~27, 1996. [38] N. D. Vvedenskaya and Y. M. Suhov. Dobrushin s mean-field 
approximation for a queue with dynamic routing. Technical Report 3328, INRIA, December 1997. [39] N. 
C. Wormald. Differential equations for random pro-cesses and random graphs. Annals of Appl. Prob., 5:1217-1235, 
1995.  
</RefA>			
