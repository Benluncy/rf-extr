
 A Parallel Branch-and-Bound Algorithm for MIN-Based Multiprocessors* Department Myung K. Yang and Chita 
R. Das of Electrical and Computer Engineering The Pennsylvania State University University Park, PA 16802 
 Abstract A parallel Decomposite Best-First search Branch­and-Bound algorithm (pdbsbb) for MIN-based 
multipro­cessor systems is proposed in this paper. A conflict free mapping scheme, known as step-by-step 
spread, is used to map the algorithm efficiently on to a MIN-based sys­tem for reducing communication 
overhead. It is shown that the proposed algorithm provides better speed-up than other reported schemes 
when communication over­head is taken into consideration. 1 Introduction Branch-and-Bound( B&#38;B) algorithms 
are very well known techniques to solve combinatorial search prob­lems. These problems, which occur commonly 
in dif­ferent forms in diverse areas, belong to the class of NP-hard problems. A B&#38;B algorithm consis~s 
of four parts -branching rule(s), selection rule(s), elimination rule(s), and termination condition(s). 
The branch­ing rule(s), elimination rule(s), and termination con­dition(s) are problem dependent. The 
selection rule, however, is algorithm dependent. Four different al­gorithms have been proposed according 
to the selec­tion rule. These are Breadth-First search, Depth-First search, Best-First search, and Random 
search. The Best-First search technique is very attractive in terms of the time complexity. Selection 
rule is a critical factor that decides the ef­ficiency of serial as well as parallel implementation of 
B&#38;B algorithms. Wah, et al. [1,2] have proposed a par­allel Best-First search B&#38;B a,lgorithm(pb.sbb) 
and have simulated its behavior on a special architecture, called MANIP. They have shown a linear speed-up 
of N, where N is the number of processors in the system. However, this study does not address remote 
interprocessor com­munication, which has serious impact on speed-up. This research was supported in part 
by the National Science Foundation under grant CCR-8810131. Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM Ocopyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or speclflc permission. o 1991 ACM 089791 -392 -2/9110005 /0222 . 
..S1 .5o We propose here a parallel Decomposite Best-First search B&#38;B algorithm (pdbsbb) for multistage 
intercon­nection network (MIN)-based systems. Mapping of the algorithm onto a Butterfly type architecture 
is consid­ered for reducing the communication overhead. Speed- UP of the algorithm ifi analyzed considering 
both comp­utation and communication issues. 2 The Parallel Algorithm The commercially available Butterfly 
configuration is used in this paper as a representative of MIN-base ar­chitecture. We assume that the 
number of processors in the system is N and all the processors are identical, We also restrict the analysis 
only to binary tree of depth D. The pdbsbb has three distinct phases. The first phase, called the subproblem 
decomposition and distribution, works the same as all other parallel B&#38;B algorithms un­til the original 
problem is divided into N subproblems. Each subproblem is then assigned to one processor that uses serial 
Best-First search (bsbb) for finding a local so­lution of the subproblem in the second phase. Finally, 
all the N local solution values are compared to find the global solution in the third phase. Here in 
the third phase, all the processors may not finish their allocated job simultaneously. A simple approach 
would be to wait until all the N local solutions are computed and then compare those to find the final 
solution. Thie approach would reduce system utilization. We, therefore, propose broadcasting of each 
proces­sor s local solution to achieve moderate load bal­ance with resonable amount of extra remote commu­nications. 
Each processor maintains two solutions: lo­cal solution and global feasible solution (GFS). The first 
processor that completes aseigned process broad­casts the LS to other processors and this value be­comes 
the first GFS for all processors. This broadcasted value is used to achieve the load balance by updating 
each busy processor s local evaluated-but-unexpanded subproblern(eus) listl, and keeps working for finding 
a local solution. When the next LS is obtained, the corre­ lThis can reduce the execution time of other 
busy processors since the local eu$ lists can be shortened using the new GFS. 222 7­ link value range 
= 1­ 10 6­ binary tree depth 12 / a a u :5 a . 4­ 3­-s. @sbb + pbsbb2­ -5 pdrsbb+prsbb 1 ii 1 vI 11 
0102030 40 number of processors Figure 1: Speed-up comparison spending processor broadcasts it, if the 
value is better than the current GFS. Otherwise, a local task-end sig­ nal is broadcasted. This process 
continues until N LS S are computed and the GFS is updated by congruence. Finally, the processor(s) whose 
LS and GFS match send the data set to the host processor. If multiple proces­sors attempt to broadcast 
their LS S at the same time, it would be serialized. This probability, however, is very negligible. Subproblem 
distribution in the first phase and LS broadcasting in the third phase need remote communi­cation while 
evaluation of each decomposed subtree by the assigned processor in second phase is achieved using only 
local communication. On a Butterfly system, each broadcast can be completed by a remote memory write 
access time. Remote communications are not only ex­pensive compared to local access but may experience 
conflict at different stages of the MIN. To avoid net­work conflicts, we propose a step-by-step spread 
map­ping technique for the decomposition and distribution procedure of phase one. During the execution 
of a step-by-step spread, one child node is kept on a local memory and the other child node is sent to 
a selected remote memory. This remote memory selection is based on the interconnec­tion pattern of the 
network.  Speed-up Comparison We classify parallel B&#38;B algorithms into 5 cate­gories based on their 
selection strategies -parallel Best-First search B&#38;B algorithm (pbsbb), parallel Decom­posite Best-First 
search B&#38;B algorithm (pdbsbb), par­ allel Random search B&#38;B algorithm (prsbb), parallel Decomposite 
Random search B&#38;B algorithm(pdrsbb), and parallel Decomposite Depth-First search B&#38;B al­gorit 
hm ( pddsbb). Figure 1 depicts the speed-up comparison of the par­allel B&#38;B algorithms. We have applied 
the conflicts free mapping scheme for all algorithms for fairness of comparison. All the data used here 
are obtained from simulation. The parallel decomposite Random search (pdrsbb) and the parallel decomposite 
Depth-First search (pddsbb) give the same results since these two have almost the same properties and 
speed-up, except that the pddsbb requires less amount of mem­ory space. The parallel Best-First search 
(pbsbb) works better with small number of processors due to less number of node evaluation and tolerable 
communica­tion overhead. As the number of processors increases, the parallel Best-First search needs 
more and more re­mote communication and eventually the communica­tion overhead offsets the advantage 
of less number of node expansions. Same is true for the parallel Ran­dom Search (prsbb). Thus, the parallel 
Best-First search B&#38;B algorithm (pbsldr) shows linear speed-up in terms of number of evaluated nodes 
and sometimes there hap­pens an acceleration anomaly where the speed-up is bet­ter than linear [3]. However, 
when the communication activities are considered, the speed-up drops dramati­cally. The parallel Decomposite 
Best-First search B&#38;B algorithm (pdbsbb) takes advantages of both the serial Best-First search and 
less communication overhead, and provides better speed-up compared to any other algo­rithm. 4 Conclusions 
A new parallel Branch-and-Bound algorithm has been presented in this paper. The algorithm is called parallel 
Decomposite Best-First search B&#38;B algorithm since it divides the original search space into N sub­problems 
and applies serial Best-First search on each subproblem. Speed-up comparison of various parallel B&#38;B 
algorithms shows that, as the number of pro­cessors increases, the parallel Decomposite Best-First search 
performs better than other schemes due to both reasonable number of node evaluations and less com­munication 
overhead.  References <RefA>[1] <SinRef><author>B. W. Wah </author>and<author> Y. W. Eva Ma</author>, ,<title>MANIP A Multicomputer Architecture for solving 
Combina­torial Extremum-Search Problems</title> , <journal>IEEE Trans. on Computers</journal>, <volume>Vol. C-33, No. .5</volume>, pp<pages> 377-390</pages>, <date>May 
1984</date></SinRef>. [2] <SinRef><author>G. -J. Li </author>and <author>B. W. Wah</author>, (<title>Computational Effi­ciency of Parallel Approximate Branch-and-Bound 
Algorithm</title> , <booktitle>Proc. Intl. Conf. on Parallel Process­ing</booktitle>, PP <pages>473-480</pages>,<date> Aug. 1984</date></SinRef>. [3] <SinRef><author>T. -H. Lai </author>and<author> S. Sahni</author>, 
<title>Anomalies of Paral­lel Branch-and-Bound Algorithms </title>, <journal>Comm. of the A CM</journal>, pp <pages>594-602, </pages><date>June 1984</date></SinRef></RefA>. 223 
			
