
 Adaptive Zero and Computational (Extended Donald Abstract. The seminal work of [GMW86] proposed the 
use of zero knowledge proof systems (ZKPS s) as a means to demonstrate adherence to a specified network 
protocol, thereby protecting an interac­ tive network computation against malicious sub­ version. Each 
participant would prove without revealing anything additional that it indeed fol­ lowed the rules. 
We give evidence that both the classical zero knowledge analysis [GMR89] and the particular ZKPS in [GM 
W86] are not sufficient to provide provable security against attacks by an adaptive malicious adversary, 
as follows. If the ZKPS for graph 3-colorability proposed in [GMW86] is provably secure against adversaries 
who can choose whom to corrupt as a protocol progresses, and if factoring is intractable, then the polynomial 
hierarchy collapses. In particular, any language in NP could be solved with access to an oracle for factoring. 
We also consider subtle re­quirements that classical ZKPS S do not address, such as the privacy of the 
verifier, and show that some ZKPS S may permit subtle attacks in which useful knowledge is leaked undetectable. 
To remedy these problems, we propose a robust model for adaptive zero-knowledge proof systems that embodies 
broader security aspects of trans­mitting confidence in the validity of a claim. Within this model, we 
resolve the informal conjec­ture behind [GMW86] by showing that the prove­good-behavior paradigm can 
be employed with provable security against adaptive adversaries. Transarc Corp., Gulf Tower, 707 Grant 
St., Pittsburgh, PA 15219. Email: beaver@transarc. corn. Permission to make digitallhard copies of all 
or pmt of WIS material for personal or classroom use is granted without fee provided that the copies 
are not made or dkibuted for profit or commercial advantage, the copy­ right notice, the title of the 
publication and its date appear, and notice is given lhat copyright ia by permissionof the ACM, Inc. 
To copy otherwise, to republish, to post on servers or to redkibute to lists, requirea specific permission 
andlor fee. STOC 96, Phdadelphia PA, USA Q 1996 ACM &#38;89791 -785-5 i96105. .$3.50 Knowledge Equivocation 
Abstract) Beaver * 1 Introduction Interactive proof systems and zero-knowledge proto­cols have a rich 
background, starting with the founda­tional works of Babai, Goldwasser, Micali and Rack­off [Bab85, GMR89, 
BM88]. Proof systems enable a prover to give a verifier confidence in the truth of a claim. Zero-knowledge 
techniques ensure that the prover does not reveal anything more than the truth of that claim itself. 
In classical zero-knowledge proof techniques, zero-knowledge is shown by a simu­lator that (roughly speaking) 
must construct a pseudo­conversation based on the claim alone, to show that an actual conversation reveals 
nothing more than the truth of the claim itself. Static vs. Adaptive. A significant and early appli­cation 
of zero-knowledge proofs was introduced by Gol­dreich, Micali and Wigderson [GMW86]. Multiparty Secure 
Computation (sometimes referred to as Men­tal Poker ) addresses the problem of evaluating a func­tion 
on a set of inputs provided by various nodes in a network, without revealing anything more than the function 
value itself. Two aspects are important: the ability to compile a function specification into a proto­col 
implement ation; and the ability to force agents to stick to the rules of the protocol. A vast collection 
of works provide solutions under varying models (see eg., [GMW86, GMW87, BGW88, CCD88]). [GMW86] introduced 
a powerful paradigm for pro­tecting a protocol against malicious departures from the rules. In particular, 
after sending a message, each agent would use a zero-knowledge proof [GMR89] to demon­strate that the 
message was generated according to the protocol, and in particular that there existed a private internal 
state (random tape, work tape, input tape) that would give rise to the actual message. In this manner, 
the behavior of the agent could be verified without ac­tually revealing its private, internal state. 
While a proof of security against a static adversary is possible (albeit tedious), a proof of security 
against adaptive) adversaries is a different matter altogether. A static adversary is permitted to choose 
the agents it wishes to corrupt only at the outset of the protocol; an adaptive adversary may make further 
selections as a protocol progresses, adapting its choice according to the specific events and information 
it sees. Although security against static adversaries is of in­terest and provides a convenient stepping-stone 
for un­derstanding and designing security against stronger at­tacks, it is hard to justify a general 
real-life scenario in which an adversary cannot use its corruptive resources in a gradual fashion, picking 
new spies aa time goes by. Proving Adaptive Security. The GMW proof sy5 tern and protocol compiler [GMW86, 
GMW87] may in­deed be secure against adaptive attacks, but a proof has been lacking for some time. One 
reason is the difficulty of finding a simulator robust enough to model adap­tive attacks. While the classical 
ZK approach provides the mathematical tools to analyze static attacks (since one knows in advance whether 
the prover is corrupt or the verifier is corrupt), it is technically insufficient for drawing conclusions 
about adaptive attacks. The challenges in proving security against adaptive attacks are two-fold, since 
the GMW paradigm ad­dresses both the secure transmission of information (in private messages) and the 
secure transmission of con­fidence (in proper behavior). First, it must be shown that the encryption 
used to protect secure communica­tions is secure. This has been the attention of works by Beaver and 
Haber [BH92] and Canetti, Feige, Goldre­ich and Naor [CFGN96]. Second, as considered in this work, the 
ZKPS must be proven robust against adaptive attacks. We give evidence that no simulator for the partic­ular 
ZK proof system employed in [GM W86] will be found without either a significant departure from clas­sical 
zero-knowledge definitions or radical progress in complexity theory. In particular, if the ZKPS is provably 
secure against adaptive attacks, then the polynomial­time hierarchy collapses. Theorem 1 Let E() be a 
secure probabilistic encryp­tion function. If the ZK proof system for graph $ colorability y (3-COL) 
in [GM W86] is provably secure against adaptive attacks, then 3-COL can be solved pro b­abihstica!iy 
with an orac!e for E(J. Corollary 2 If PA CTORING is intractable and the ZKPS for 3-COL in [Gill W86] 
is provably secure against adaptive attacks, then E{ = PH. Naturally, the meaning of provably secure 
requires a generalization of ZK to the adaptive setting. We pro­vide such a definition, which itself 
covers some subtle omitted sspects in the static, classical definition. It should be noted that Theorem 
1 is not an artifact of our proposed definition; indeed, any natural general­ization of ZK in keeping 
with the classical, simulator­based approach is sufficient. Equivocation. In a nutshell, the problem 
is equivo­ cation or the lack of it. The ZKPS for 3-colorability in [GMW86] follows three simple steps: 
the prover encrypts a 3-coloring; the verify challenges him to reveal the colors of a ran­dom edge (i, 
j); the prover does so. It is essential that the prover be unable to change the contents of the en­crypted 
coloring, else he can answer any challenge, even if the graph is not 3-colorable. That is, the encryption 
should be unequivocable. This notion of equivocation is closely related to Shan­non s concept of key 
equivocation [Sha49]: how much does the ciphertext determine the key? Here, we are in­terested instead 
in the message equivocation: how much does the ciphertext determine the message? Naturally, this issue 
is of central importance to pro­tecting communications against an adaptive adversary. Consider a protocol 
in which sender S sends an en­crypted message m c {O, 1} to receiver R. To show that no information is 
leaked, a simulator should construct a faked view of the encryption, without knowing m (unless S or R 
is corrupt, in which case, the simulator is entitled to learn m). If the adversary is static, and neither 
S nor R is corrupt, then the simulator can simply encrypt a O and the adversary will never know the difference. 
An adaptive adversary may, years later, corrupt S or R and challenge the simulator to open the encryption 
(by publishing appropriately faked internal random bits of the sender or receiver) to reveal O or l according 
to the value of m (to which the simulator is now enti­tled). But if the simulator simply encrypted a 
O, then how can the encryption be opened to a 1? If the en­cryption can be opened to a 1, then how can 
R be sure which value he received in real life? In essence, the faked view should be equivocable (con­sistent 
with two different messages) while the real view should be unequivocable; yet the faked view should be 
indistinguishable from a real view, even when full infor­mation is later revealed to the adversary. Recent 
work has addressed this paradox by making sure that the adversary never gains full information . Beaver 
and Haber [BH92] show that erasing certain in­ternal bits hides sufficient information to provide the 
desired equivocation: an attacker gains no evidence that an encryption was an encryption of O rather 
than 1 . Canetti, Feige, Goldreich and Naor, developing a sim­ilar idea expressed as non-committing, 
give the first solution that avoids erasing [CFGN96]. Their methods enable the sender and receiver to 
avoid learning all the unequivocable information in the first place in particu­lar, which keysthe receiver 
actually knows(c~ [DP92]). For example, by dispersing information among several third parties, thereceiver 
places hischoices (of what to learn) permanently beyond anadversary s reach. Atwo­party encryption protocol 
is also possible, using suitable complexity assumptions. A Paradoxical Need For Encryption? The crucial 
problem in the Graph 3-Colorability (3-COL) ZKPS of [GMW86] is that it relies on an unequivocable encryp­tion 
of a graph 3-coloring. In fact, the soundness of the proof system demands that the prover be unable to 
open an encryption to different values. In their seminal work on zero-knowledge, [GMR89] wonder whether 
encryption may be a crucial compo­nent of zero-knowledge proof systems. Indeed, it may well be; but we 
give evidence that if so, it will be in a different form than the traditional notion of an encryp­tion 
function. The paradox lies in the opposing needs of the 3-COL ZKPS, which seeks unequivocable encryption 
to make sure the prover does not change his mind during the protocol, and the zero-knowledge simulator, 
which should be able to create equivocable facsimiles of the encrypted data produced by the prover. Unfortunately, 
the methods of [BH92] and [CFGN96] do not provide a fix. Moreover, even if the interaction between prover 
and verifier is itself protected via a se­cure channel, the issue of equivocation remains. Thus, the 
results of this paper are complementary to those in [BH92, CFGN96]. Adaptively Secure Arguments. On the 
other hand, as discussed within, provable security of other ZKPS S against adaptive adversaries can indeed 
be pro­vided under suitable restrictions, and with suitable modifications. In particular, imposing a 
computational bound on the prover in other words, using zero­knowledge arguments seems to help. This 
require­ment is naturaIly not as broad as one might Iike, but it is well suited to the scenario in which 
[GMW86J first proposed to apply ZKPS S: multiparty computations by computationally-bounded participants. 
Summary. Our results provide the following fuller understanding of adaptive security: Certain restrictions 
permit information to be trans mitted securely against an adaptive adversary (cf. complementary results 
of [BH92, CFGN96]). Certain restrictions permit confidence to be trans­mitted securely against an adaptive 
adversary ( CJ [BC86b, BCC88]).  Classical definitions of ZKPS S do not provide a suf­ficient analytical 
basis for security against an adap­tive adversary.  Although the particular ZKPS for 3-colorability 
in [GMW86] may indeed be secure against an adap­tive adversary, it is unlikely that it will be proven 
 secure.  Paradoxes as described within suggest that the simulator-baaed approach to zero-knowledge 
may itself be insufficient for general analysis, although the successes of [BH92, CFGN96] provide reason 
for optimism.  To seek closure on the foundational work in [GMW86, GMW87], it appears that the particular 
proof system employed there should either be abandoned or signifi­cantly modified, unless surprising 
complexity-theoretic results are proved or a significant departure from the classical simulator-based 
approach to zero-knowledge is made. Outline. ~2 contains definitions; ~3 proves the main results; $4 
achieves a modified GMW paradigm in re­stricted models; ~4.3 discusses effects of omitting veri­fier 
privacy.  2 Adaptive Zero Knowledge The foundational work of Goldwasser, Micali and Rack­off [G MR89] 
provides a formal framework that captures a philosophy we express as follows: Simulation Principle. (Bounding 
Informa­tion) Let Z be an agent in a protocol imple­mentation, and let Vz be a r.v.l describing its view 
(internal tapes; messages sent and seen). If, based only on information X, a polynomial time simulator 
s can generate a distribution S(X) that is (computationally) indistinguish­able from Vz, then the implementation 
leaks at most X. This philosophy forms the basis for analyzing one case of st atic faults, that of a 
fault y verifier (who maybe only curious). The other case of static faults, that of a faulty prover, 
is covered by the completeness and soundness properties of interactive proof systems. 10r rather, family 
of r.v. s. In an ideal specification, we envision a prover supply­ ing a claim to a trusted and computationally-unbounded 
third party, T. If the claim is false or unparsable, T sends O to the verifier. If the claim is true, 
T sends (l . Accordingly, the verifier privately outputs rejector accept. We regard a ZKPS as essentially 
just an implementa­ tion of this specification. Classically, a ZKPS need only be secure against a static 
l-adversary, namely an ad­ versary who chooses at most one participant to corrupt and makes that choice 
before the protocol starts. If the adversary corrupts prover P, soundness comes under scrutiny. If the 
adversary corrupts verifier V, complete­ ness and zero-knowledge come under scrutiny. To generalize the 
static notions expressed in classical ZK, we wish to show that an adaptive attack on the im­ plementation 
achieves substantially the same results as a corresponding attack on the specification. If so, we can 
reasonably invoke a more general Simulation Principle to argue that the security properties of the specification 
are assured in the implement at ion. (This implicitly in­ cludes the privacy of the verifier, among other 
heretofore omitted properties. ) Influence and Information. In a general network setting, an adversary 
issues corruption requests, receives history messages (including input and current view) from each corruption, 
sends outgoing messages from cor­ rupt players, and receives incommg messages to corrupt players. While 
a static adversary must issue all cor­ rupt ion requests before the protocol starts, an adaptive adversary 
can issue them at will (but often up to a spec­ ified limit on the number of corruptions). Through these 
four simple actions, an adversary ex­erts influence and gains information. Its influence is measured 
by analyzing the outputs of uncorrupted play­ers; its information, by its view (internal bits, traffic 
seen, and inputs/histories of corrupted players). For technical purposes, we consider a two-phased pro­tocol 
execution. The online phase encompasses the ex­ecution of the protocol itself, until such time as hon­est, 
players have all terminated. The post facto phase includes attacks performed thereafter. Naturally, only 
corrupt and history messages are relevant to the post facto phase and only when the adversary is adaptive. 
Why distinguish these phases? In particular, after the protocol has run its course, its outputs may be 
used in further protocols. A later protocol may, for whatever reason, deliberately leak some or all of 
these outputs. For example, the verifier may reveal its conclusion about the prover s success or failure, 
Thus, we permit the post facto attack to be stronger in certain ways: a post facto adversary is granted 
all outputs from the online phase, and can then select whom it wishes to corrupt.2 )3 More Formally. 
Let M, N, and Adv be interactive, probabilistic poly-time Turing machines (PPTM s). For convenience, 
we regard Adv as composed of two PPTM s, AdvOnl and AdvPO~t; after Advonl halts, AdvPOst is given the 
outputs of Advonl, M and N, and we take its output to be that of Adv. Let (M(x~, k), N(z~, k), Adv(x~, 
k)) denote the distribu­ tion on triples (yjw, VN, VA) of outputs written by M, N, and Adv when run on 
the given inputs. (Here, k is an (optional) security parameter. ) The output of a corrupt player is taken 
to be * . In particular, an attack on the ideal protocol is de­ noted by (~(zp, k), V(XV, k), Adv(zA, 
k)). Here, zp may cent ain both a claim and a witness for its truth, while Zv would normally contain 
either the claim or nothing. An adversary normally comes from a class of adver­ saries. We typically 
consider m-adversaries, who can issue up to m corruption requests (which are not valid against special, 
trusted hosts ). An adversary is static if it always issues its corruption requests before the pro­ tocol 
starts; otherwise it is adaptive. Simulation. In generalizing the Simulation Principle, we call on simulation 
to analyze both influence and in­formation simultaneously. In addressing adaptive at­tacks, we require 
a t we-phased simulator, or rather a pair of simulators for each phase: S onl, SPOSt. For simplicity, 
we treat Adv as a resettable black-box with which the simulator interacts [Ore87].4 When an adversary 
issues a corruption request, the given simulator must create a fake history for the newly corrupted part 
y, be it P or V. This history message should seem authentic to Adv, else Adv s experience will be distinguishable 
from attacking the implementation itself, and the Simulation Principle will fail. TWO distribution families 
{Dl (x, k)} and {D2(z, k)} are computationally indistinguishable on z if for any PPTM M, Ipr [M(G(z, 
k)) = 1]-F r [M(G(z, k)) = 1] I = k- ( ). We write D1 % D2. 2Naturally, in a sequential composition 
of protocols, this post facto attack is not allowed (except at the utter end). The fact that each module 
would survive such an attack -if made -can be used to prove the security of their composition. 3 Cryptogapfic 
protocols may also specify auzil;a~~ outPuts, such as keys or deduced corruption patterns. These are 
not included when comparing an implementation to a specification, when they are not part of the specification. 
4See 53.2 for weaker conditions. We treat ZKPS simply as a particular network pro­tocol, in which an 
adversary might corrupt V, or P, or even eventually both. Definition 1 Protocol (P, V) is an adaptive 
com­putational zero knowledge proof system for L if there exists a simulator PPTM S = (SOnl, spout) such 
that for all adaptive .2-adversary PPTM s Adv = (Adv~~l, Advp~,t), for ail inputs XP, xv and XA&#38;, 
(@(XP), V(XV), S(AdV(ZAdv)) % (~(XP), V(X ), AdV(XAdv)) In contrast to what might be assumed in classical 
ZKPS S, the corruption of both is not merely an aca­demic case, particularly if P and V are simply bit 
play­ers in a larger network protocol. This missing case is a strong distinction from the classical, 
static, case-by-case approach. 3  The Zero Knowledge Paradox An interesting but easily resolved quasi-paradox 
arises in classical ZK. If z c L, then S(Z) must produce an accurate view. If V* behaves, the view includes 
accep­tance. What if z @ L? If S(x) had to be accurate, then V* would reject. But this would provide 
a means to solve z c L simply by running S(Z). The simple res­olution is that S(Z) still looks as though 
z c L, even though this is quite distinct from what would happen in real life. The same issue is relevant 
here: perhaps it is too strong to require that the view be accurate when x @ L? One crucial difference 
is that, according to the specifi­cation, the simulator is now entitled to learn whether x c L and to 
base its simulation on that fact. When x @ L, the simulator easily simulates an honest prover by reporting 
0. 5 A more central paradox arises in encryption-based ZKPS S, such ss the one proposed in [GMW86]. The 
simulator may have to construct a false view of the en­cryption of an NP-witness such as a graph coloring, 
without knowing the witness. Yet it may later on be forced to open the encryption fully. One resolution 
is that the simulator is then entitled to the prover s inputs, including any such witnesses, and it need 
not compute them from scratch. It need only fill in the heretofore unknown portions in the adversary 
s view. Unfortunately, this partial resolution does not appear to suffice for the 3-COL ZKPS of [G MW86]. 
5A devil s advocate can still experiment with the simulator by telling it that f said 1 , in which case 
an acceptin~ view should be obtained. No properties of this experiment are guaranteed, however. 3.1 
Collapsing the Polynomial Hierar­chy Let x : V + {1,2,3} be a 3-coloring of the vertices of graph G = 
(V, E). The ZKPS for 3-COL in [GMW86] relies on a probabilistic encryption scheme E() and fol­lows three 
steps. P selects a random permutation II on {1,2, 3}, encrypts each vertex color E(II(x(vi )), ri), and 
sends the encryptions to V. V challenges P with a random edge, (vi, Vj ). P responds with (ri, rj ), 
en­ abling V to open the encryptions E(II(x(vi)), ri) and E(II(x(vj )), rj ). If they are identically 
colored, V re­jects; else V accepts. We now show theorem 1: Proof Sketch. Assume that the GM W ZKPS is 
prov­ably secure against adapt ive adversaries. Let AdvOnl cor­rupt V at the outset but behave according 
to the rules. Let vv be V s view as constructed by Sonl. Now, if AdvpOSt were to corrupt P, then Son] 
would have to con­struct a record of P s internal tapes that is consistent with Vv. Regardless of whether 
S..l now learns x (let us assume it does), the internal records that SpO~t must now reveal to AdvPOSt,must 
contain ri values enabling a decryption. Otherwise, the full view will be distinguish­able from a real 
run of the protocol, since an honest P always calculates and retains such ri s. To solve 3-COL from scratch, 
we run S with adversary Advo.1 on a given instance G, and we (tell S that P and T said G is colorable. 
We do not, however, have AdvPO,t request that P be corrupted. Instead, relying on the property that it 
is possible to open the encryption to a coloring (perhaps only with the knowledge of a coloring, of course!), 
we invoke an oracle that breaks the encryption. As required in [GMW86], <decryption is unique, so we 
are then able to extract a 3-coloring. Of course, if G is not 3-colorable, then the results will be garbage. 
(Incid~ntally, this is fully acceptable, since in the ideal case, P and T would not have reported to 
V (ie. S) that G is colorable, hence our instructions to S would not reflect a valid experiment.) Thus, 
with one call to the decryption oracle, we can solve 3-COL with error probability < 1/3. Q Corollary 
2 follows: Proof Sketch. If FACTORING is intractable, then the Rabin encryption scheme suffices for the 
pur­poses of the GMW ZKPS. According to Theorem 1, 3-COL would have a BPP-reduction to FACTORING. But 
FACTORING is in NP n CONP, thus .21~ = PH [KL82, Sip83]. 0 Remarks. It should be noted that the distribution 
of instances produced in a multiparty protocol may be far from including arbitrary graphs. In particular, 
it may not hit on the hard instances with respect to agiven al­gorithm that solves 3-colorability. In 
other words, such an algorithm may in fact run in polynomial time on the graphs that occur when a principal 
attempts to prove good behavior within a specific protocol. To be treated as an independent module if 
not as a full-fledged ZKPS of its own right the 3-COL proof protocol should be held to the same standards 
as any ZKPS. A demonstration that the 3-COL protocol suf­fices just for the needs of the resulting compiled 
mul­tiparty protocols in [G MW86, GMW87], would show (directly or indirectly) that those protocols generate 
graphs that are easy. Given that the multiparty pro­tocols are designed to be complete for any function 
spec­ification, this seems a daunting task. But in any case, the question of whether the 3-COL protocol 
is indeed a full-fledged Z.KPS does not rely on such issues, 3.2 Natural Zero Knowledge The condition 
that the adversary be a resettable black­box is easily weakened. And while post facto corruption may 
seem strong, it is not essential for the demonstra­tion that a proof of GMW ZKPS is a difficult task. 
In­ deed, an adversary can decide to corrupt P immediately after P sends its final message, and the needed 
proper­ ties remain. In general, Adv s decision may be random or based on inputs discovered at other 
newly-corrupted sites. The crucial property is the ability to fill in views (ie, internal tapes) after 
conversations ( ie. sent messages) have been committed. In fact, various treatments of multiparty computations 
come to a common conclusion: filling in views after conversations have been commit­ted is an essential 
component of a simulator-based ap­proach ( cf, [Bea91, MR91], and the protocols given in [BH92] and [CFGN96], 
which are directly motivated by this issue). As Kilian remarks in a similar context, there are related 
situations in which  backing up simulator constructions no longer show zero knowledge. [Ki188] Thus, 
any natural generalization of ZK ought to have the needed property. Of course, a very different approach 
to ZK is possible, and it is one goal of this work to point out that a very different approach may indeed 
be of value. 3.3 Other Fixes Fail The erasure technique of [BH92] will not fix the protocol, since the 
random -bits ii used to encrypt .E(rI(y(vi )), ? i) must be kept for P to answer V s challenge.6 The 
general ideas behind our counterexam­ple thus apply if Adv corrupts P after the first message. Moreover, 
while [BH92] does permit P and V to com­municate via a secure channel, Adv can passively view the communication 
anyway by corrupting V. (Indeed, our example takes this ta~k.) The encryption protocol of [CFGN96] will 
not fix the protocol in a straightforward fashion, either. In par­ticular, if V plays the role of the 
receiver, then zero­knowledge is violated, since V will learn the coloring. If P holds back and somehow 
embodies the role of the receiver, later revealing the receiver s private bits to V for those instances 
that V has challenged P to reveal, then P will have to record one or both of the trapdoors/secret-keys 
that V may later request. In the former case, the simulator can provide an equivocable facsimile of an 
honest prover s view. In either case, how­ever, a dishonest P can choose to learn both trapdoors and 
itself produce an equivocable encryption, thereby tricking an honest V. To avoid this, P would have to 
commit to the trapdoor it honestly chose to learn, leading to a bootstrap problem. 3.4 Third Parties 
If third parties participate (as is the primary case in [C FGN96]), then the protocol can effectively 
use a network-wide bit committal in place of the encryp­tion (either directly, or through modifications 
that one might conceivably apply to bend the third-party case of [CFGN96] to the task). It then becomes 
difficult to say whether the spirit of using encryption in the sense of [GMW87] is satisfied. In other 
words, although third-parties could certainly enable the implementation of committal and ZKPS for multiparty 
settings, it would still not resolve whether the two-party 3-COL ZKPS approach is sufficient and provable. 
In particular, it is valuable to know whether a point-to-point, two-party interaction suffices (with 
an appropriately changed encryption box), since the na­ture and efficiency of the final application may 
well de­pend on it.  4 Arguing Good Behavior It is a difficult or perhaps impossible task to create 
an encryption that a poly-time simulator can equivocate but which an unbounded prover cannot. The essence 
of the GM W construct ion is not, however, to achieve encryption but to achieve commitment. To achieve 
6Naturally, an infinitely powerful prover could calculate these again when they are needed, but the goal 
is to provide a protocol requiring only polynomial-time to execute, yet preserving securit y even if 
the prover is arbitrarily powerful, the prove-good-behavior paradigm, we compromise the model and fix 
up some near-sufficient techniques to achieve the desired equivocation. Achieving commitment in an adaptive 
setting is not trivial. For example, a straightforward use of commit­ment schemes based on Rabin-type 
oblivious transfer [Rab81] will not support a proof of security, because the contents of the OT S cannot 
be changed. Once the prover is compromised, the factors of modulus n will be discovered, and the bits 
sent in each OT are deter­mined by the established view. If those bits represent a 3-coloring, we face 
the same paradox found in Theo­rem 1. A commitment scheme should be content-equivocable to be useful 
for our purposes. That is, given a fac­simile of the traffic between sender and receiver, or of the receiver 
s view, it should be possible for the simu­lator to construct a sender s view to be consistent with having 
committed a O or a 1. While this is similar to the chameleon blobs of Brassard, Chaum and Cr6peau [BCC88], 
we discuss distinctions below. To achieve the desired content-equivocation, however, we are forced to 
place polynomial bounds on provers. Thus, rather than proving good behavior, agents will argue good behavior 
(cf. [BrCr89]). This restriction is neither full y satisfying or general, but it is fairly reason­able 
 since in particular, protocols that rely on encryp­tion to secure the communication channels normally 
as­sume it anyway. 4.1 Stronger Chameleons Chameleon blobs are commitment schemes in which the receiver 
can simulate the opening of the commitments to a O or to a 1, equally well. Yet an adaptive attacker 
may not have corrupted the receiver but may simply be watching the conversation over an open channel. 
It may be possible that opening the commitment to a O or to a 1 requires certain private information 
held by the receiver. A stronger requirement is that the commitments be openable to O or 1 given only 
a record of the traffic be­tween committer and receiver. Whether this is possible depends critically 
on the implementation. For example, the initial quadratic-residuosity-based commitment scheme of Brassard 
and Cr4peau [B C86b] satisfies the chameleon property but not this stronger requirement. In their scheme, 
V sends P a large Blum integer n = pq and a random square s (mod n). P commits to bit b by selecting 
a random z (mod n) and sending s~z2 (mod n). P decommits b by sending the witnemy x to b, It is computationally 
infeasible to find a witness to ~ without factoring n. Thus it is as infeasible for the simulator (given 
only the traffic) as it is for the prover to equivocate. If n is not part of the specification protocol, 
but rather a means for the implementation to achieve its goals, the simulator can be rescued.7 If V is 
currently honest, S invents its own n with known factorization; if V is later corrupted, it uses these 
inventions to fill in V s fake view. If Adv corrupted V before n is generated, S uses the n reported 
by Adv. To obtain the factors of n, we demand that V give a zero-knowledge proof of knowledge of n s 
factors [FFS88, TW87, Ben86, BC86a], in which case S can extract the factors from Adv. The last point 
illustrates a strong difference between the nature of static analysis and adaptive analysis. [BC86b] 
remark that a proof that n is of the proper form is unnecessary, since V only hurts himself when n is 
chosen otherwise. Either P detects that n is a prime, or P can get away with a false proof if n is easy 
to fac­tor. But the idea of V hurting himself also implicitly seems to suggest that P may also depart 
from the pro­tocol. In that case, the zero-knowledge property is no longer necessary in the static analysis 
(since a cheater not only deserves no defense but can freely give away information). Thus, if P were 
to take advantage of V s self-inflicted damages, then no simulation is necessary. Hence there is no need 
to discover the factors of n. In the adaptive case, however, simulation is no longer a moot point, since 
it is required up to the moment that P becomes corrupt (if so). To enable it, one must require not just 
a proof of proper factorization needed but a proof of knowledge of that factorization as well (or at 
least a proof of knowledge of a square root of s [BCC88]). Theorem 3 There is a zero-knowledge argument 
sys­tem that is provably secure against adaptive 2­adversaries, if factoring is infeasible. Proof Sketch. 
We present a few different ways to achieve this goal. As described further in ~4.2, one can use a protocol 
that has the chameleon property (mea­sured against static l-adversaries) and, through the use of adaptively-secure 
encryption ( e.g. [BH92, CFGN96]), encrypt the message traffic or more minimally, a carefully-chosen 
set of auxiliary random bits. The technique of proving knowledge of a square root ofs as in [B CC88] 
will also suffice. For illustration, we modify the BC protocol from [BC86b] to include a zero­knowledge 
proof of knowledge of the factors of n by V. If Adv requests the corruption of V before S has provided 
Adv with a facsimile of message V + P : n , then S extracts the factors of n from Adv s subsequent zero­ 
knowledge proof of knowledge. (If the demonstration ?~ other ~ord~, n may be an auxiliary input /outPut 
Of the implement at ion. fails, Sprovides the accurate response that the honest P aborted.) If Visnotcorrupted 
before Sgenerates V+-P: n, then S itself runs an internal copy of V and generates the factors p, q of 
n. In either case, after a successful initialization stage, S knows the factors of n and is therefore 
able to choose ar­bitrary recommittal witnesses for any quadratic residue modn. The remaining details 
follow the path outlined in [BCC88], since S now has the ability not just to sim­ulate committals but 
to open them arbitrarily to O or 1. c1 4.2 Chameleon Blobs are Insufficient Theorem 3 relies on the 
simulator knowing the factor­ization of n. Because n is an artifact of the implemen­tation, this is acceptable. 
But consider a generalization of the [BCC88] ap­proach in which the modulus n and the quadratic residue 
s = tz mod n are computed by way of a mul­tiparty secure computation (e.g. [GMW87, CDG87, BG W88, CCD88]). 
Say that the network provides V with the factors of n. Except for V, no player or small set of players 
knows the factors of n, nor does the sim­ulator: n is a part of the specification. The BCC approach still 
seems secure: any bounded prover can still argue a claim based on n and s. In particular, P s commitments 
are still chameleon, since V -who knows the factors of n -can open each to (O or 1. But a simulator faces 
the daunting goal of creating a view for P after having seen (or generated) traffic con­sisting primarily 
of quadratic residues. If P is corrupt from the outset, this is not difficult, because S creates the 
honest traffic (ie. from V, if V is still honest) itself, and does not need to fill in P s view. The 
proof against static adversaries applies in a straightforward fashion. But if P is uncorrupted at the 
time P sends its mes­sages, S s task is tantamount to factoring. In particular, S did not generate nor 
s and has no right to obtain V s private information, unless V has been corrupted. Content-equivocable 
com­mit ments rather than chameleon blobs are needed. The simulator must be able to open P s commitments 
even when it can t resort to corrupting V to gain V s specified knowledge. Note that the secure-channel 
methods of [BH92, CFGN96] can be applied in this scenario to encrypt the traffic in an equivocable manner. 
In order to see the clear messages themselves, Adv must corrupt either P or V, in which case the original 
chameleon property will suffice after all. To see this, note that if P is cor­rupted first, S can generate 
its view from the start, on demand. If V is corrupted first, S is indeed permitted to discover the factors 
of n, in which case the chameleon property permits it to open honest P s commitments as needed, later 
on. (Using methods of [Bea96], it suffices to encrypt at most a few bits per committal rather than the 
entire traffic.) 4.3 The Verifier s Privacy We remark that protecting the verifier s privacy is not 
purely academic. In particular, sequential repetitions of the BCC protocol with the same modulus leak 
in­formation that may permit an unexpected attack. By including a residue z of its choice at some point, 
P can discover the residuosity of 2 based on whether V rejects the proof.8 Essentially, P gains an oracle 
for quadratic residuosit y, limited only by V s patience in engaging further proof attempts. While it 
is not yet clear how P might capitalize on this information, a similar attack on a published oblivious 
transfer protocol managed to break it [Bea92].  5 Conclusions We have attempted to resolve the issue 
of proving [GMW86, GMW87] secure against adaptive adversaries (insofar as it employs its specific 3-COL 
ZKPS), pro­vided a starting point for analyzing zero-knowledge against adaptive attacks, and examined 
the robustness of [B CC88] for such purposes. Because equivocation is a central requirement, these issues 
are related but com­plementary to the work of Beaver-Haber and Canetti­Feige-Goldreich-Naor on securing 
communications. In both cases conveying confidence and conveying infor­mation many intriguing paradoxes 
and issues remain, not the least of which being why simulator-based ap­proaches do not accommodate intuitively-secure 
proto­cols such as the 3-COL ZKPS well. Are the protocols actually insecure, does the proof methodology 
require revision, or are we in a Godelian realm of securit y with no hope of proof? References <RefA>[Bab85] 
L. Babai. Trading Group Theory for Ran­domness. Proceedings of the 17fh STOC, ACM, 1990, 421-429. 8 ArWably, 
V might keep his acceptance/rejection of the Proof forever secret, but our post ~acto attack rules out 
thk extraordi­nary excuse, by fiat. [BM88] [Bea91] [Bea92] [Bea96] [BH92] [Ben86] [Ben87] [BGW88] [BrCr89] 
[BHZ87] [BCC88] [BC86a] [BC86b] L. Babai, S. Moran. Arthur-Merlin Games: A Randomized Proof System, and 
a Hier­archy of Complexity Classes. J. Comput. System Sea . 36 (1988), 254-276. D. Beaver. Foundations 
of Secure Inter­active Computing. Proceedings of Crypto 1991, 377-391. D. Beaver. How to Break a Secure 
Oblivious Transfer Protocol. Advances in Cryptology -Eurocrypt 92 Proceedings, Springer-Verlag LNCS 658, 
1993, 285-296. D. Beaver. Equivocable Oblivious Trans­fer. To appear, Advances in Cryptology -Eurocrypt 
96 Proceedings, 1996. D. Beaver, S. Haber. Cryptographic Proto­cols Provably Secure Against Dynamic Ad­versaries. 
Eurocrypt 1992. J. Benaloh. Cryptographic Capsules: A Disjunctive Primitive for Interactive Pro­tocols. 
Advances in Cryptology -Crypto 86 Proceedings, Springer-Verlag LNCS 263, 1987, 213-222. J. Benaloh. Verifiable 
Secret Ballot Elec­tions. PhD Thesis, Yale University, 1987. M. Ben-Or, S. Goldwasser, A. Wigder­son. 
Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation. Proceedings of the 
20~h STOC, ACM, 1988, 1988, 1-10. G. Brassard, C. Cr6peau. Sorting Out Zero-Knowledge. Advances tn Cryptology 
-Eurocrypt 89 Proceedings, Springer-Verlag LNCS 434, 1990, 150-154. R. Boppana, J. H%tad, S. Zachos. 
Does co-NP Have Short Interactive Proofs?. Info. Proc. Letters 25, 1987, 127-132. G. Brassard, D. Chaum, 
C. Cr6peau. Min­imum Disclosure Proofs of Knowledge. J. Comput. System Sci. 37 (1988), 156-189. G. Brassard, 
C. Cr6peau. Zero-Knowledge Simulation of Boolean Circuits. Advances in Cryptology -Crypto 86 Proceedings, 
Springer-Verlag LNCS 263, 1987, 223-233. G. Brassard, C. Crbpeau, Non-Transitive Transfer of Confidence: 
A Perfect Zero-Knowledge Interactive Protocol for SAT and [CFGN96] [CCD88] [CDG87] [DP92] [DH76] [FFS88] 
[For871 [GL89] [GMW86] [GMW87] [GV87] Beyond. Proceedings of the 27ih FOCS, IEEE, 1986, 188-195. R. Canetti, 
U. Feige, O. Goldreich, M. Naor. Adaptively Secure Multiparty Computation. To appear, these proceedings. 
D. Chaum, C. Cr6peau, I. Damg&#38;d. Mul­tiparty Unconditionally Secure Protocols. Proceedings of the 
20th STOC, ACM, 1988, 11-19. D. Chaum, I. Damg5rd, J. van de Graaf. Multiparty Computations Ensuring 
Se­crecy of Each Party s Input and Correct­ness of the Output . Advances in Cryptology -Crypt o 87 Proceedings, 
Springer-Verlag LNCS 293, 1988. A. DeSantis, G. Persiano. Zero-Knowledge Proofs of Knowledge Without 
Interaction. Proceedings of the 33 d FOCS, IEEE, 1992, 427-436. W. Diffie, M. Hellman. New Directions 
in Cryptography. IEEE Transactions of In­formation Theory IT-22 (November 1976), 644-654. U. Feige, A. 
Fiat, A. Shamir. Zero Knowl­edge Proofs of Identity. J. Cryptology 1:2, 1988, 77-94. L. Fortnow. The 
Complexity of Perfect Zero-Knowledge, Proceedings of the 19th STOC, ACM, 1987,204-209. O. Goldreich, 
L. Levin. A Hard-Core Pred­icate for All One-Way Functions. Proceed­ings of the 21St STOC, ACM, 1989, 
25 32. O. Goldreich, S. Micali, A. Wigderson. Proofs that Yield Nothing but Their Va­lidity and a Methodology 
of Cryptographic Protocol Design. Proceedings of the 27th FOCS, IEEE, 1986, 174-187. O. Goldreich, S. 
Micali, A. Wigderson. HOW to Play Any Mental Game, or A Completeness Theorem for Protocols with Honest 
Majority. Proceedings of the 19*h STOC, ACM, 1987, 218-229. O. Goldreich, R. Vainish. How to Solve any 
Protocol Problem An Efficiency Im­provement. Proceedings of Crypto 1987, Springer-Verlag, 1988,73-86. 
 [GM84] [GMR89] [KL82] [Ki188] [MR91] [NY90] [Ore87] [Rab81] [Sha49] [Sip83] [TW87] S. Goldwasser, S. 
Micali. Probabilistic Encryption. J. Comput. System Sci. 28 (1984), 270-299. S. Goldwasser, S. Micali, 
C. Rackoff. The Knowledge Complexity of Interactive Proof Systems. SIAM J. Comput. 18:1 (1989), 186-208. 
R. Karp, R. Lipton. TuringM achinesT hat Take Advice. llnseign. Math. 28, 1982, 191-201. J. Kilian. Founding 
Cryptography on Oblivious Transfer. Proceedings of the 20th STOC, ACM, 1988,20-29. S. Micali, P. Rogaway. 
Secure Compu­ t ation. Proc. of Crypto 1991, page 9.8 [sic], and incomplete preliminary version dis­tributed 
at conference. M. Naor, M. Yung. Public-key Cryptosys­tems Provably Secure against Chosen Ci­phertext 
Attacks. Proc. of 22nd STOC, 1990, 427-437. Y. Oren. On the Cunning Power of Cheat­ing Verifiers: Some 
Observations about Zero Knowledge Proofs. Proceedings of the 28th FOG S, IEEE, 1987, 462-471. M.O. Rabin. 
How to Exchange Secrets by Oblivious Transfer. TR-81, Aiken Compu­tational Laboratory, Harvard, 1981. 
 C. Shannon. Communication Theory of Se­crecy Systems. Bell Syst. Tech. J. 28, Oc­tober 1949, 656 715. 
 M. Sipser. A Complexity Theoretic Ap­proach to Randomness. Proceedings of the 15th STOC, ACM, 1983, 
330-335. M. Tompa, H. Well. Random Self-Reducibility and Zero-Knowledge Proofs of Possession of Information. 
Proceedings of the 28th FOCS, IEEE, 1987, 472-482.</RefA>  
			