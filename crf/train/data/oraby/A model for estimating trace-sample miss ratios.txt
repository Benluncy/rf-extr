
 A Model for Estimating Trace-Sample Miss Ratios* David A. Wood Mark D. Hill Computer Science Department 
University of Wisconsin Madison 1210 West Dayton Street Madison, WI 53706 clavid(lcs.wise.edu Abstract 
Unknown references, also known as cold-start misses, arise during trace-driven simulation of uniprcjcessor 
caches because of the unknown initial conditions. Accu­rately estimating the miss ratio of unknown references, 
denoted by p, is particularly important when simulat­ing large caches with short trace samples, since 
many references may be unknown. In this paper we make three contributions regarding ~. First, we provide 
empirical evidence that p is much larger than the overaH miss ratio (e.g., 0.40 vs. 0.02). Prior work 
suggests that they should be the same. Sec­ond, we develop a model that explains our empirical results 
for long trace samples. In our model, each block frame is either live, if its next reference will hit, 
or dead, if its next reference will miss. We model each block frame as an alternating renewal process, 
and use the renewal-reward theorem to show that p is simply the fraction of time block frames are dead. 
Finally, we ex­tend the model to handle short trace samples and use it to develop several estimators 
of p. Trace-driven simu­lation results show these estimators lead to better esti­mates of overall miss 
ratios than do previous methods. Index Terms Cache memory, performance evalua­tion, cold-start behavior, 
trace-driven simulation, sam­pling techniques *This work is supported in part by the National ScienceFoun­dation 
(MIPS-8957278 and CCR-8902536), A. T.&#38; T. Bell Lab­oratories, Cray Research Foundation, Digital Equipment 
Corpo­ration, and the graduate school at the University of Wisconsin Madkon. R. E. l{essler has been 
supported by a summer in­ternship at Digital Equipment Corporation, and graduate fellow­shipsfrom the 
National ScienceFoundation and the University of Wisconsin-N1adison. Permission to copy without fee all 
or part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM Ocopyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, 1 Introduction A cache is a high-speed parts of main memory not found in the cache contains 
it is transferred in a block frame in the referenced if it contains it as a result of a miss. usually 
partitioned into frames in the reference s way set-associative cache (associativity A) and SA Trace-driven 
simulation technique for evaluating memories [Smit82]. Trace-sampling is a refinement that simulates 
multiple trace samples to estimate the miss ratio of a long base trace[Laha88]. Since most pro­grams 
exhibit non-stationary miss ratios over very long intervals [Borg90], a single long trace sample may 
not be representative of the entire program. Instead, if we call accurately estimate the miss ratio of 
short samples, then the average over multiple short samples should more ac­ curately predict the Any 
estimate of ased (expected error (small mean squared finding an unbiased true miss ratio. the true miss 
ratio should be unbi­of zero) and as accurate as possible error) [Bick77]. A key problem in miss ratio 
 ulator does not know which at the beginning of a trace simulator references a block cannot determine 
whether or R. E. Kessler buffer that holds recently-used [Smit82]. When a reference is (a miss), the 
block of data that from main memory and stored cache. We say a block frame is the requested block or 
obtains Blocks and block frames are S sets so that only the block set must be searched. An A­has A block 
frames per set block frames overall. is the most-com]monly-med the performance of cache estimator is 
that the sinl­blocks reside in the cache sample. Thus, when the frame for the first time, it not the 
reference actually misses. These potential misses have been called cold­ start mwses[East78] because 
they occur at the begin­ ning of a simulation; we prefer to call them unknown references since they may 
or may not be actual misses. Two techniques have traditionally been usecl to cleal with this problem: 
(1) make trace samples long enough so that the cold-start bias is acceptably small, or (2) record metrics 
only after this bias is eliminated. The requiree a fee and/or epecific permission. 0 799J ACM 08979 J.392.2/9J 
/000~/0079... $j .sO first technique works because the number of unknown misses cannot exceed the number 
of block frames in the cache, limiting the absolute error, The second technique exploits the fact that 
the current cache state does not depend upon the initial contents once the trace has ref­ erenced every 
block frame. Thus the bias is eliminated by recording metrics only after the cache is full. Recent trends 
toward larger caches render the above techniques undesirable by requiring extremely long trace samples. 
For example, consider a cache with 512 block frames and a 0.05 miss ratio estimate for a 100 ,000-reference 
trace. The bias in this estimate can­not exceed 10 percent (512/(100, 000 * 0.05) N 10Yo). Future caches, 
however, may have 128K block frames and 0.001 miss ratios, which require one billion refer­ences to achieve 
the same 10 percent maximum bias. The second technique fares no better; filling the large cache requires 
an absolute minimum of 128,000 refer­ences, and many times that in practice. More recently, Laha, et 
al. [Laha88], and Stone [Ston90J have proposed similar techniques that warm­up each set independently. 
Rather than waiting for the entire cache to fill, they record metrics for each set that has filled. By 
not counting unknown references, these approaches implicitly assume that unknown references behave the 
same as randomly selected references. In the central result of this paper we show that un­known references 
are special, and exhibit a much higher miss ratio than random references. We introduce a renewal-theoretic 
model to explain this surprising re­sult. The model defines a block frame as ljve if its next reference 
hits, and as dead if its next reference misses. Using the renewal-reward theorem, we show that the miss 
ratio of unknown references is simply the fraction of time a block frame is dead. We use trace-driven 
sim­ulation to validate this model for traces long enough to reference every block frame. We then extend 
the model to handle shorter trace­samples. However, this second model relies upon the distribution of 
dead times, not just the ratio of means, and is much more difficult to compute. We introduce four approximations 
and show that one yields good re­sults for sufficiently long samples. More work is required to determine 
when samples are long enough to provide acceptable error. For our data, if at least 60% of the bloc]{ 
frames have been touched and there have been as many misses as there are block frames, then the error 
in the overall miss ratio is generally less than 10?10. A second estimate produces slightly less accurate 
results, but is useful since it is trivial to compute. In the next section, we review previously-proposed 
estimators, and show that the true miss ratio is much greater than intuition suggests. Section 3 introduces 
the renewal-theoretic model and explains this surpris­ ing observation. Section 4 applies the model to 
esti­ mate the true miss ratio for long trace samples, and Section 5 generalizes it to support short 
trace samples. Both Section 4 and Section 5 present trace-driven simu­lation results to support our models. 
Finally, Section summarizes our results and proposes future extensions to the model.  2 Estimating Miss 
Ratios of Un­known References To obtain accurate miss ratio estimates using trace sam­pling, we need 
an accurate, unbiased estimator for the miss ratios of short trace samples. To do this, we focus on finding 
an accurate, unbiased estimator for the miss ratio of unknown references. Let the true miss ratio of 
a cache, denoted by m, be the fraction of references that would miss in a real cache during the execution 
of a par­ticular trace sample. The true miss ratio depends upon the miss ratio of unknown references, 
which we denote by p: M+pu m= (1) R where ill is the number of references known to miss, U is the number 
of unknown references, and R is the total number of references in the sample. The only two ways a simulation 
can exactly compute the true miss ratio is to either eliminate the unknown references or exactly compute 
p. Laha, et al, [I, aha S8], have explored the first approach; in this paper, we focus on the problem 
of accurately predicting ~, the miss ratio of the unknown references, While the miss ratio is not usually 
characterized in this way, researchers have commonly used several ap­proximations to ~. The simplest 
and most common esti­mate assumes that all unknown references miss (~ cold = 1). . A !T+lxu _M+u _ (2) 
cold = RR In this case, the unknown references are referred to as cold-start misses. This estimate has 
been widely used, and provides acceptable accuracy if Al is much larger than U. However, this constraint 
is rarely met for large caches, resulting in overly pessimistic estimates of the miss ratio. The other 
extreme is to assume that all unknown ref­erences hit (~hot = O). Intuition suggests that this h Ot­start 
estimate is better for large caches, since they have low steady-state miss ratios. M+OXU _ h{ rnho~ = 
(3) R -z­Table 1: Comparison of Estimates of Miss Ratio m. Trace True m True Estimate cold of m (% Relative 
hot Error) A mult 1 0.024 0.;53 0.039m (61.3%) 0.016 m(-33.4%) 0.016 &#38;.9%) mult 2 0.016 0.339 0.028 
(76.5%) 0.010 (-39.3%) 0.010 (-38.1%) tv 0.035 0.481 0.055 (55.4%) 0.017 (-51.4%) 0.018 (-49.5%) sor 
0.027 0.932 0.028 ( 6.0%) 0.005 (-81.6%) 0.005 (-81.2%) tree 0.010 0.142 0.027 (167.6%) 0.007 (-27.8%) 
0.007 (-26.4%) This table shows the measured and estimated miss ratio m, together with the percent relative 
error (100% *(r?z-m)/m) of the estimates. The true value of p is much greater than m, indicating that 
the steady-state assumption is false. Each data point is the mean of several thousand samples, each containing 
50,000 references. The cache configuration is 64 K-bytes, direct-mapped, with 16-byte blocks. However, 
!hhot has the unfortunate property of always under predicting the true miss ratio, which could lead to 
optimistic cache designs. Nevertheless, the hot-start and cold-start miss ratios are useful as bounds, 
since the true miss ratio must lie between them [Ston90]. For sufficiently large samples, i.e., large 
values of M, the rel­ative difference between fi ~old and fhhot becomes small, making it reasonable to 
ignore the difference, A more intuitive estimate assumes that unknown ref­erences miss at the same rate 
as all other references. If we pick a single reference at random, it is no more or less likely to miss 
than any other, thus it misses with probability m (ji~~ = rh~~): M + rn.ss?I M ti~8 = = (4)R R U Stone 
originally proposed this steady-state estimate for direct-mapped caches [Ston90], which is equivalent, 
to ex­cluding the unknown references from the computation of the miss ratio. He used a different justification, 
arguing that references should only be counted if they access a primed set. As originally defined by 
Laha et al.[Laha88], a set containing A block frames is primed once it has re­ceived A unknown references. 
A simulation can only be sure that a reference hits or misses if it accesses a primed set. Since a set 
in a direct-mapped cache is primed after its first (unknown) reference, Stone ignores a total of U references. 
Stone and Laha et al. generalize this estimate for set­associative caches, but neither model is very 
appealing since both exclude references that are known to hit. For example, suppose the first reference 
to a particular set touches block B. While the first reference is unknown, subsequent references to block 
B will hit (at least during the interval before the set becomes primed). Yet neither Stone s nor Laha 
et al. s model includes these references in the miss ratio estimate. Table 1 presents experimental data 
comparing the true value of m with the three estimates: l~~cold, 7~~/~Ot, and fiss. It contains data 
from five traces on a 64 K­byte direct-mapped cache with 16-byte blocks. Each estimate is the arithmetic 
mean of between 1900 and 3500 contiguous trace contiguous samples, each 50,000 references long. Samples 
are drawn from a set of long traces, described more fully in Section 4.1. The ini­tial references of 
each trace are used only to completely warm up the cache, allowing an exact computation of the true miss 
ratio for the remaining references. The re­maining references, an average of 130 million per trace, are 
then broken into individual samples. Despite the intuitive argument given above, Table 1 shows that the 
steady-state estimate predicts m as poorly as the cold-start and hot-start estimates. The assumption 
that p equals m is clearly false: the data in columns two and three show that the true value of p is 
much larger than the true miss ratio m. Furthermore, the inaccuracy of the estimates for p introduce 
a sig­nificant error into the estimates for the total miss ratio m. How is it possible that p is much 
larger than m? Consider a cache with 1024 block frames and a syn­thetic trace-sample that references 
a block 20 times, then moves to the next block and references it 20 times, etc. The trace s true miss 
ratio, m, is 570, because the probability that a random reference lmisses is 1 in 20. The miss ratio 
for unknown references, p, however, is either 99.9?10 or 100~0, depending upon whether the first reference 
of the sample misses, The first references to all other block frames miss every time. In the next sec­tion 
we develop a model that explains why p and m are inherently different. 3 A Simple Renewal-Theoretic 
Model In this section, we introduce a model for estimating p, the fraction of unknown references that 
actually miss. This section is only concerned with the steady-state be­havior of a single block frame 
in the cache. The next section applies the steady-state model to the behavior of an entire cache. Cache 
performance is traditionally measured with the miss ratio: the fraction of references that miss in the 
cache. However, an equivalent alternative is to view the performance using the reciprocal of the miss 
ratio: the average number of references per miss. This view focuses our attention on the amount of time 
a block spends in the cache. Consider a single block frame. We say that the jth generation Gj begins 
immediately after the jth miss oc­curs, and a new block is brought into the block frame. This generation 
ends, and a new one begins, when the block is replaced. The length of a generation is the to­tal number 
of references in the trace between the misses that begin and end the generation. A generation in­cludes 
the miss that ends it, but not the miss that begins it. A generation Gj consists of two phases, a he 
time Lj and adeadtimeDj,thus Gj =Lj+Dj.Ablock frame is said to be live if the block it contains will 
be referenced again before being replaced. Conversely, a block frame is said to be dead if the next reference 
to it will miss. We say a block frame is referenced only if it contains the requested block or obtains 
it as a result of a miss. Thus each address in the trace references exactly one block frame. A live time 
Lj begins a generation Gj, and a dead time Dj begins immediately after the last reference to the block. 
Both the generation and the dead time end when the block is replaced, Now consider an arbitrary block 
frame at some ran­dom time t, as measured in references to all block frames. If the block frame is live, 
as at time tl in Fig­ure 1, then the next reference to that block frame hits. Conversely, if the block 
frame is dead, as at time t2, then the next reference to the block frame misses. Thus at a random time 
t,the probability that the next refer­ence to a block frame misses is simply the probability that time 
t falls within a dead time. Under this model, a block frame alternates between being live and dead. With 
a few simplifying assump­tions, stated below, we can model the block frame as an alternating renewal 
process, and use standard renewal theory to compute the probability that time t occurs during a dead 
time. Let us assume that a miss to a block frame constitutes a renewal point, that is, that the process 
starts over independent of the past. Fur- Figure 1: Live and Dead Times This figure illustrates the live 
and dead times for an arbitrary block frame in the cache. An M denotes a miss, an H a hit, a - indicates 
a reference to another block frame during a live time, and a blank marks a dead time. Suppose we randomly 
pick time tl.Since it falls within a live time, the next reference to the block frame must hit. Conversely, 
if we randomly pick time t2,the next reference to the block frame will miss, since t2falls within a dead 
time. thermore, assume that the live times Lj and dead times Dj are random variables drawn from two arbitrary 
dis­tributions. Subsequent live times and dead times are in­dependent, and identically distributed, although 
a dead time D1 may depend upon the preceding live time LJ. In practice, these assumptions are rarely 
strictly true for individual cache block frames. Nevertheless, they are close enough that the model yields 
good results, as shown in the next section, The renewal-reward theorem states that random events see 
time-average behavior [Wolf89, Ross83], In other words, the probability that a random time t falls within 
a block frame s dead time is simply the fraction of time that the block frame is dead. Mathematically, 
this is expressed as: P{ Random time tlands during a dead time} (5) E[Dj] E[Dj] _ = E[Lj] + E[Dj] E[Gj] 
where E[X] denotes the expected value of a random variable X. Since the probability of landing in a dead 
time for some block frame i is simply the probabil­ity that the next reference to that block frame misses, 
we can extend our model to provide a theoretical basis for estimating ~. While this result may seem obvious, 
we need the formalism of renewal theory to extend the model in Section 5. In related work, Puzak[Puza85] 
and Mendelson, Thie5baut, and Pradhan[Mend90] define the terms live and dead slightly differently. Their 
definitions apply to blocks, rather than block frames: they call a block live ifit is in the cache and 
will be referenced again, and call it dead otherwise. Puzak analyzes the effect of replace­ment policies 
on dead blocks. Mendelson, Thi6baut, and Pradhan use their definitions as part of an analytic model of 
cache performance. Neither examine i;he re­lationship between dead blocks and the miss ratio of unknown 
references.  4 A Model for Long Trace Sam­ples This section applies the renewal-theoretic model to es­timate 
the miss ratio of long trace samples. We assume here that the trace samples are sufficiently long that 
they reference every block frame in a cache at least once. The next section examines the complications 
caused by short samples, which do not meet this requirement. To calculate the miss ratio for a trace 
sample, we must know the fraction of unknown references that miss, p. But this is just the fraction of 
block frames that are dead at the start of the sample. If we assume that the sam­ple starts at a random 
time t and that live and dead times are identically distributed for all block frames, then we can apply 
our result from the previous section. Let #long be our estimate of ,u for long samples, and let U be 
a random variable that is 1 if the unknown refer­ ence to block frame i misses and O otherwise. Assume 
that the ~ are identically distributed, S is the number of sets, and A is the associativity. Then, = 
E[p] (6) filong _ E Unknown References that Miss Unknown References[ 1 SA  &#38;E ~~ = &#38; ~E[~] 
inl i=l [1 = #$-=&#38;g# t=l 2=1  EIDjl = E[Gj] where E[Dj]i and E[Gj]i are the expected dead and 
gen­eration times for block frame i, respectively. In words, if block frames have identical live and 
dead time dis­tributions, then the fraction of unknown references that miss is simply the fraction of 
block frames that are dead at the start of the sample. But this is simply the frac­tion of time a single 
block frame is dead. Of course the live and dead times may not actually be identically dis­tributed, 
but in the next section we show that this is not a first-order effect. We illustrate the implications 
of this result by pre­senting an intuitive argument that the steady-state as­sumption is false, i.e., 
that p ~ m. An average gen­ eration includes one miss to a particular block frame and E[Gj] references 
scattered across all block frames. Since there are always SA active generations, one for each block frame, 
we expect SA misses for every E[Gj] references. This yields a miss ratio m = &#38;. Now . .. consider 
a fully-associative cache (S = 1) with lcast­recently-used (LRU) replacement. After a block frame becomes 
dead, there must be A other misses before it is selected for replacement. Since there can be at most 
one miss per reference, the minimum dead time is simply A references. EIDJI i~ong = E[Gj] SA  m= EIGYI 
 but min(Dj) = A = SA o Note that jliono equals m if and only if all references miss in the cache. Since 
miss ratios are typically lo\JI, ii] practice ,iilong is much greater than 7n. The argument for direct-mapped 
and set-associntile caches is somewhat weaker. Consider a synthetic ~cf­erence stream that accesses each 
set with equal prob­ability. With such a stream the mean time bctivccw references to a set is simply 
S. Once a block fra]~~e in a particular set becomes dead, there must be A m~ssm to that set before the 
block frame is replaced (assuming LRU). Thus, if the cache never hits the mean dead time is SA references, 
Since caches do hit, and the principles of locality state that references tend to cluster, il~otlfl tends 
to be much larger than m. However, pathologic reference patterns, that allow p less than ?71, are pos­sible 
for set-associative caches. But as we show in the next section, most real programs exhibit the posited 
be­havior. This model provides a theoretical basis for the enlpir­ical observation that p is greater 
than m. However, the simplifying assumptions cast doubt on the accuracy of the model. And without making 
much stronger assump­tions about the reference distribution, we cannot, say anything stronger about ~. 
Instead, we use trace­ -L-,, driven simulation to validate the model and cleternliue the relationship 
between E[Dj], E[Gj], and SA. 4.1 Empirical Validation In this section, we present results from a trace-driven 
simulation experiment in which we computed the ave~­age live times and dead times for various cache sizes. 
We extended our cache simulator to maintain the time (reference number) of the last miss and last reference 
Cache Address Trace Ci :he Address Trace mult 1 mult2 tv sor tree = 4K 1 0.56 0.51 0.77 0.75 0.57 4K 
2 0.57 I 0.50 I 0.81 I 0.72 0.54 41{ 4 0.58 0.50 0.79 I 0.69 0.55 16K 1 0.54 0.66 0.80 [ 0.92 0.50 161( 
2 0.49 161< 4 0.51 64K 1 0.67 w 64K 2 0.62 I 0.74 110.5511 0.! 18 0.63 641< 4 0.63 0.76 Im I 0.98 0.60 
 + Table 2: True Miss Ratio of Unknown References ~ This table presents the measured values of LI for 
5­million reference samples. Each data point represents the arithmetic mean of between 19 and 35 samples. 
The samples are long enough that 95% of the block frames are referenced, on average, for all but two 
of the trace/cache combinations. The two exceptions are outlined with boxes. to each block frame. On 
each cache miss, the simula­tor computes the duration (in references) of the block frame s live and dead 
times, and updates the summary statistics. To eliminate cold-start effects from our vali­dation experiments, 
the simulator does not count gen­erations that begin with an unknown reference. The simulator also ignores 
generations terminated by the end of the trace. Because long generations are more likely to be excluded, 
as a result of the inspection paradox[Wolf89, Ross83] (also known as the residual life paradox [Klei75]), 
these simulation artifacts tend to bias the means downwards. We tried to minimize the effects of this 
bias by using long address traces, We used five address traces gathered from a DEC Titan [Borg90], that 
contain multiprogramming behav­ior, but not operating system references, The traces multl and mult2 are 
multiprogramming workloads, con­sisting of both software development and CAD applica­tions. Tv is a VLSI 
circuit timing verifier, sor is an im­plementation of the successive overrelaxation algorithm, and tree 
is a compiled Scheme program. The traces aver­age 130 million references each (excluding initialization 
references), for a total of 650 million references. For the largest cache presented in this paper, the 
traces average over 500 generations (misses) per block frame. Thus the bias introduced by the simulation 
start-up and ending artifacts should be quite small. Size *Assoc mult 1 = tree 4K 1 9% 10% 1% 370 2!70 
41{ 2 7% 8% 1 % 3% -2% 4K 4 5% 10% 4% 3% -2Y0 16K 1 13% -5% <170 1% <1% 161< 2 18% -3% 1% <lYO 2% 161< 
T 4 16% -8% 4% 4% <lYO 64K 64K 64K T1 2 4 10% 11% 11% -3% -5% -5% 12% 7% 5% <1% <lYO 1% <lYO 11% 30% 
 Table 3: Relative Error in Long Trace Estimate jl 10TIO. This table nresents the relative error in 
the lonz trace , E[D 1 We compute filonq estimate jilona = ~. by Calcu­lating the me&#38; dead and 
generation times o~ the entire trace and taking their ratio. The relative error exceeds 20% in only one 
case, and is less than 5% in over half the cases. Note that since both live and dead times .,. vary 
with cache size and assoclatlwty, p[n~,,~, does not -J necessarily change monotonically. We examine 
nine cache configurations in this pa­per, with sizes ranging from 4K-bytes to 64 K-bytes and associativity 
varying from direct-mapped to four-iiay set-associative. All configurations have 16-byte bl~clis and 
use LRU replacement, writeback (main memo~y only updated on block replacement), and write-allocate (write 
misses bring blocks into the cache) policies To exactly compute the true miss ratios, m and p, we s]m­ulated 
enough references to completely warm-ill> the cache before calculating any metrics. Then we treated the 
remaining trace as a collection of contiguous 5­million reference samples, For most combinations of trace 
and cache configuration, 5 million references is sufficient to meet the long sample requirement of refer­encing 
every block frame. Each data point is the arithm­etic mean of between 19 and 35 samples. Table 2 presents 
the true miss ratio of unkno~vn ref­erences for these samples. The values range from 0.50 to as high 
as 0.98. These data substantiate the observa­tion in Section 2 that p is much higher than m (\vl~ich 
is never greater than 14Y0, and typically much smallet). Note that ~ does not exhibit any clear trends 
as a func­tion of either cache size or associativity. Table 3 presents the relative error in our lonjz 
salnl>le estimate Plon,q = ~,E[~il we approximate E~Dj ] iIIICl E[Gj] using tile mean ~ead time and mean 
generation time, computed over the entire trace. In over 80% of the cases, the relative error of #long 
is within 10 ?ZO,and in only one case does it exceed 2070. The corresponding error in 7n is much lower, 
since U is much less than Al for these long samples. This estimate is substantially better than the other 
estimates discussed in Section 2. The observed error exists in part because the model depends upon the 
po­tentially false independence and identical distribution assumptions. However, even with only a small 
number of samples, the error is acceptably low. We expec~ that increasing the number of samples should 
further reduce the error. The results of these simulation experiments validate the accuracy of our model. 
This model provides a the­oretical basis for the observation that unknown refer­ences miss at a rate 
much higher than the steady-state miss ratio m. However, the model assumes trace sam­ples long enough 
to reference every block frame, But meeting this restriction for multi-megabyte caches re­quires samples 
with hundreds of millions of references, which may be impossible or impractical. Even more important, 
when samples do meet the restriction, the ratio of unknown references to misses, U/Lf, is small. This 
leads to a tight bound for m between rncold and fill ~t. In other words, when U/Al is small, the error 
in L has a negligible effect on the error in ti. Thus, while the long-trace model describes the behavior 
of unknown references, and is useful from a theoretical perspective, it requires generalization to be 
useful in practice. 5 A Model for Short Trace Sam­ples In this section, we extend the model to include 
the be­havior of short trace samples, which do not reference every block frame in the cache. However, 
this new short-trace model depends upon the distribution of dead times, Dj, not just the ratio of means. 
Since we have not been able to characterize this distribution, we ex­amine several approximations, including 
two that yield acceptable results. The long-trace model predicts the fraction of dead block frames at 
a random time t,which is exactly the number of block frames that will miss on their first ref­erence 
after time t.However, a simulation using a short trace sample may only reference a small fraction of 
the block frames. Temporal locality suggests that the first unknown reference is more likely to hit than 
the last unknown reference. Thus, block frames referenced dur­ing a short sample are more likely to be 
live than an average block frame. Therefore, the fraction of dead block frames referenced during a short 
sample begin­ ning at time t is less than the fraction dead at time t. To correct for this effect, we 
need to predict the proba­bility that a block frame is dead at time t given that it is referenced in 
the trace. We do this by applying Bayes Rule[Wolf89] to our alternating renewal process. Consider a trace 
sample containing IV references beginning at some random ti lne t.Let X; be the event that an arbitrary 
block frame i is dead at time t.Let Yi be the event that block f rwnc i is referenced in the interval 
[t, t + N), i.e., is refcrcncrd within the sample. If we assume that the Xi and Yi are mutually independent 
and P{X~} = P {Xi} and P{fi} = P{Yj} for all i and j, then the probability that an unknown reference 
will miss is simply the conditional probability of Xi given Yi: p = P{xilY~} (7) Using Bayes Rule, we 
can express this as: P{ Yilxi}P{.Yi} fi= (8) P{K} But P{ Xi} is simply the fraction of time a block 
frame is dead, or E[Dj]/E[Gj]. And since we know the number of unknown references, U, for a particular 
sample, we can estimate P{Yi} as U/SA, where SA is the number of block frames. Finally, P{filXi } is 
the probability that when time t lands in a dead time Dj for block frame i, the time remaining in DJ, 
known as the excess Yd(t), is less than the sample size N, or P{ Yd(t) < N}. The renewal-reward theorem 
[Wolf 89] st atcs tb at: P{ Yd(t) < N} = &#38;&#38;P{Dj > .r} (9) x-l where the range on the sum begins 
at 1 because by definition P{Dj = O} = O. Combining these equations yields our short sample estimate 
for p: To see why this estimate maybe reasonable, we consicler the two extremes. As N ~ m, the sum converges 
to E[D3 ] and U converges to SA. Thus /is/lort converges ~ At the Ot,]ler ext,rf.lllt~, to our long 
trace estimate ~[~jl the sample contains a single reference (JV = 1). In this case, the sum is exactly 
1, since F {Dj > 1} = 1, and U is exactlY I, yielding an estimate of ~, which is just the miss ratio 
m. As we argued in Section 2, we expect an arbitrary reference to miss with probability m. Since the 
estimate is accurate at the two extremes, we would like to evaluate it for more typical values. However, 
the estimate relies upon the distribution of dead times, Dj, which we have not been able to accurately 
character­ize. Further work is needed to determine whether this approach will yield useful estimators. 
5.1 Estimates for p Rather than try to estimate the distributions of D3, or equivalently l ~(t), we propose 
four simple estimates of IL for short traces. The first estimate is simply our long trace model /OnIJ 
= E[Dj] ~[Gj] (13) which wi 11 give accurate estimates for sufficiently long tlaces. The seconcl estimator 
assumes that the long trace model accurately predicts the number of dead block frames at time t,but that 
all live block frames are ref­erenced before the first dead one. Intuitively, the esti­mate assumes that 
all block frames not referenced by the sample are dead. This yields an estimate of max(O, SAW SA + U) 
(14) u EL?..d_l % + ,?5[Gj] max (o, &#38;,, ) \ SA) Taliing the maximum with O accounts for the possibility 
that not all live block frames are referenced during a short sample. The third estimate is the arithmetic 
mean of ji1071g and P ~ast. The rationale for this estimate, called ~split, comes from the observation 
that the first two estimates are generally larger than p and smaller than p, respec­tively. fl/o T1gis 
larger than p because live block frames are referenced quickly, hence p tends to be less than E[D ] 
*. jila~t is smaller than p because it assumes that all unreferenced block frames are dead, which is 
not nec­essarily true. While ~long and /iiasi are not bounds in a strict, sense, because the long-trace 
model is not pre­cisely accurate, we shall see that the true value of L tends to fall between them in 
practice. Our final estimate, called #tepzd, is the arithmetic mean of jillot and ~cold (i. e., ().5). 
This estimate has the advantage of requiring no computation, and, as we shall see in the next section, 
is also quite accurate.  5.2 El~pirical Validation Figure 2 plots the four short-sample estknates L/oTLJ, 
as a function of U/SA. T2ach filast~ ~split} and ~tepad, graph plots the true value of ~ with the estimates 
for a particular trace simulating a 64 K-byte direct-mapped cache, with 16-byte blocks. Each measured 
data point represents the average values of p and U/SA for a set of samples. Each set contains 19-35 
samples ranging in size from 10 thousand to 5 million references. The samples are evenly spaced throughout 
the base trace, and are non-contiguous (except for the largest sample size). Each sample size, except 
the largest, has multi­ple data points. As in the previous section, we estimate E[D ] ~ with the mean 
dead and generation times com-E[D,] is a puted over the entire trace. Note that since ~ function of both 
cache configuration and address trace, the estimates are not the same in each graph. Figure 2 shows the 
results for the five traces; n17L 111 and rnult2 are combined to save space and because they behave similarly. 
The measured data generally follow the hyperbolic curve predicted by jilasi and fisl)[zt. AS U/SA approaches 
1, p approaches the long trace moclel, as predicted. For smaller values of U/S.4, N decreases rapidly. 
The traces multl and mult2 closely fit the pr~­ diction of ~spltt. The traces sor and free Imore closely 
follow the prediction of jllast. And the trace tv most closely follOwS fliepzd. Note that, as predicted, 
most of the data points fail between P long which and Plast, are much tighter than the bounds provided 
by fit~ot ~ud bcoid. The estimator p~plzt appears to be the best of the alternatives, although it clearly 
overpredicts most traces for small values of U/SA. While better estimators may exist, we believe that 
~ /.t is sufficiently accurate as Sp z long as U/SA is at least 0.6, We also consider j~teplcl because 
it requires no computation. We focus on these estimates for the rest of this paper. The results in Figure 
2 demonstrate the accur~[y,~f the model. However, the model depends upon fi, which we estimated by calculating 
the mean dead and generation times over the entire trace. But this is im­practical when using trace sampling, 
so we must esti­mate ~ using only the short samples. This intro­ duces an additional source of error. 
Accurately esti­ mating this ratio can be difficult since the meau gcnet­ ation time may be very large. 
For example, the aver­ age generation time is 165,000 references for 77tu 1/ f on a 64 K-byte direct-mapped 
cache. Fortunately, Ive have observed that for most traces, especially the multipro­ gramming traces, 
the ratio of mean dead time to mean generation time remains roughly constant regardless of multl and 
mult2 tv 1 1, ,, I 0.8 0.8 I 0.6 0.6 S. A 0.4 0.4 0.2 0.2 I last ;; last , r 0 0 0.2 0.4 0.6 0.8 
1 0 0 , 0.2 / , 0.4 , 0,6 , 0.8 1 UISA UISA tree 11 0.8 0.8 0.6 0.6 3 a. 0.4 0.4 I t i 0.2 0.2 y 
   # ?/// last 00 1 ~lSA UISA o 0.2 0.4 0.6 0,8 1 0 0.2 0.4 0.6 0.8 Figure 2: Estimates of p as a Function 
of U/SA This figure plots the estimates of p as a function of U/SA, the fraction of block frames referenced 
during a sample. Each graph plots the four estimates, ~~ong, Pjasi, fi$Piit, and btepid>as well as the 
measured data points. Each measured data point represents the average p and U/SA of between 19 and 35 
samples of a particular size. The samples sizes range from 10 thousand to 5 million. The cache size for 
all graphs is 64 K-bytes, direct-mapped, with 16-byte blocks. Configuration Address Trace Cache Size 
Assoc mult 1 mult2 tv sor tree 50,000 Reference Samples 4K 1 -17% 9% -4% 19% -36% 8% -35% -8% -11% 14% 
4K 2 -17% 11% -2% 38% -38% 13% -33% 8% -6% 14% 41< 4 -18% 13% -4% 36% -37% 17% -30% 23% -8% 20% 16K 1 
o% 6% 12% -2% -37% 12% -45% -17%~ 32% 28% 16K 2 -2% 22% 8% 24%t -36% 18% -45% 3%j 20% 6% 16K 4 -4% 37%1 
6% 50%t -35% 22% -46% 4%t 9% 26%t 64K 1 42% -15%t 47% -19%t 4% 63%t -46% -33%~ 251% ll%t 641{ 2 45% -3%~ 
45% O%t 9% 106%t -47% -4%t 343% 132%~ 641< 4 46% 133%t 47% 79%t -llYO 71%t -47% -2%t 537% l138%t 500,000 
Reference Samples 641{ 1 -18% -7% -20% -31% 9% 95% -49% -2% 83% 45%~ 641< 2 -21% 4%t -25% -6%t 16% 118% 
-49% 1% 92% 62%t 641{ 4 -24 %0 17%t -27% 14%t -7% 79% -49% 290 1029IO 149%t Table 4: Relative Error of 
fitepzd (left) and J,p~it (right) Using Short Samples This table plots the relative error in ~fepzd and 
~~plzt where we approximate E[Dj] /E[Gj] using only generations entirely contained within the short sam~les. 
Since ~he mean generation time may substantially exceed the sample length, this approximation introduces 
an additional source of error into ~~plti. Data values in the table that do ilot meet the rule-of-thumb 
(U/SA >0.6 and M/SA ~ 1.0) are marked by daggers (t). sample size. Table 4 compares &#38;epad to ~~Plit 
when we estimate E&#38;l~[~jl using the me an dead and generation times from the short samples. The 
error in both estimates is much greater than observed for the long trace model, but is still acceptably 
low for the smaller caches. The error in Dsplaf exceeds 20% in only 10 of the 30 cases. This translates 
to a much smaller error in the overall miss ra­tio, rnspiit (not shown): 28 of the 30 trace/cache com­binations 
have relative error less than 10 %o and none are worse than 20%. The 64 K-byte caches do not fare as 
well, with the error in ~~pllt reaching 1000~o for one data point. The problem, of course, is the small 
sample size. In the extreme example, the cache averages only 12 (known) misses per sample. Clearly a 
longer sample is necessary to predict ~ with any accuracy. Increasing the sample size to 500,000 references 
re­duces the error substantially. Exactly how long the sam­ples must be to achieve acceptable error is 
still an open question. The following experimental rule-of-thumb, however, holds for our data: the error 
in rh~pltt is gen­ erally less than 10% if the samples are large enough to touch at least 6070 of the 
cache (U/SA > 0.6) and aver­age at least one miss per block frame (JI4 > SA). Until we better understand 
the estimator s error, we suggest the conservative strategy of ensuring that Al > 2SA. surprisingly, 
fltePaddSO does quite well for small sam­ples. This simple estimate has lower relative error than fisplit 
in one-third of the cases examined. Since fitepid requires no computation, some designers may choose 
to use it, rather than the more accurate ~split. Both estimates are much more accurate than the steady-state 
estimate tiss. As shown in Table 5, a con­tinuation of Table 1, the error in rnsp~it is much less than 
the error in ti~s. The error in fitepld is much less in four of the five cases, but is worse in the fifth. 
These results clearly show that using fisP1it, or simply m te~j j(l, is much better than using rhss. 
6 Summary and Conclusions In this paper, we showed that accurately estimating the miss ratio of unknown 
references is the key to ol>tain­ing accurate results from trace-sampling. Previous es­timates generally 
assumed that unknown references be­have like randomly chosen references, and miss at the steady-state 
miss ratio. We presented empirical reslllts showing that unknown references miss at a much higher True 
Relative Error Trace m rnss tepid ~splat multl 0.024 -31.9% 13.9% -4.9% mult2 0.016 -38.1% 18.6% -7.4% 
tv 0.035 -49.5% ml 32.3% sor 0.027 -81.2% -37.8% 1-27.0%] tree 0.010 -26.4% 69.9% 13.1%1 Table 5: Comparison 
of rnss, rntePzd, and ~sP~at. This table shows the relative errors in the miss ratio est imat es. Each 
data point is the mean of several thou­sand samples, each containing 50,000 references. The cache configuration 
is 64 K-bytes, direct-mapped, with 16-byte blocks. miss ratio that is independent of the steady-state 
miss ratio. In the key result of this paper, we showed that for samples that reference every block frame, 
the miss ratio of unknown references is simply that fraction of time a block frame is dead, E[Dj] (15) 
i~ng = E[Gj] Trace-driven simulation data demonstrate the accuracy of this model. We extended the model 
to handle short samples, which only reference a fraction of the block frames: However this estimate relies 
upon the distribution of D,, which we have not yet characterized. We examined several estimates for p, 
and show that ( 17) produces good results for sufficiently long samples. We also showed that fitePid 
= 0.5 produces acceptable ac­ curacy for many practical applications, yet requires no computation. Several 
open problems remain. Most importantly, we must determine a robust criterion for estimating the error 
in P split. Preferably, this should be a function of the sample size or the fraction of referenced block 
frames. We plan to examine this issue fully in the near future, using larger caches and longer traces. 
We also plan to examine hierarchical caches and compare our results more fully with other techniques. 
Better estimators of p are also possible, perhaps by successfully characterizing the distributions of 
Dj or Yd(t). We would also like to explore extending this model to multiprocessor caches and stripped 
(filtered) traces. 7 Acknowledgements We would like to thank <RefA>S. Adve, G. Gibson, R. Nel­son, H. Stone, 
M. Vernon, R. Wolff, the students in M. Vernon s Fall 1990 CS 838 class, and the anonymous referees for 
their comments and criticisms that helped improve this paper. And thanks to Anita Borg, David W. Wall, 
and DEC Western Research Lab for providing the use of their excellent, long, traces. [Bick77] Peter J. 
Bickel and Kjell A. Doksum. Mrsthernat­ical Statistics. Holden-Day, Inc., San Francisco, 1977. [Borg90] 
Anita Borg, R E. Kessler, and David W. Wall. Generatiori and analysis of very long address traces. In 
Proceedings of the 17th Annual Inter­national Symposium on Computer Architecture, pages 270-279, 1990. 
[East78] Malcom C. Easton and Ronald Fagin. Cold-start vs. warm-start miss ratios. Communications of 
the ACM, 21(10), October 1978. [Klei75] Leonard Kleinrock. Queueing Systems Volume 1: Theory. John Wiley 
and Sons, New York, 1975. [Laha88] S. Laha, J. H. Patel, and R. K. Iyer. Accurate low-cost methods for 
performance evaluation of cache memory systems. IEEE Transactions on Computers, 37(11):1325-1336, November 
1988. [Mend90] Abraham Mendelson, Dominique Thi6baut, and Dhiraj Pradhan. Modeling live and dead lines 
in cache memory systems. Technical Report TR-90­CSE-14, Dept. of Electrical and Computer Engi­neering, 
University of Massachusetts, 1990. [Puza85] T. R. Puzak. Cache Memory Design. PliD thesis, University 
of Massachusetts, Amherst, MA, 1985. [Ross83] Sheldon M. Ross. Stochastic Processes. John Wi­ley and 
Sons, New York, 1983. [Smit82] Alan Jay Smith. Cache memories. ACM Com­puting Surve~s, 14(3):473 530, 
September 1982. [Ston90] Harold S. Stone. High-Performance Computer Architecture. Addison Wesley, second 
edition, 1990. [Wolf89] Ronald W. Wolff. Stochastic Modeling and the I %eory of Queues. Prentice-Hall, 
1989.</RefA> 
			
