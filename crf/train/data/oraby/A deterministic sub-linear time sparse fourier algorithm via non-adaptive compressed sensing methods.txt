
 A Deterministic Sub-linear Time Sparse Fourier Algorithm via Non-adaptive Compressed Sensing Methods* 
 M. A. Iwen Abstract We study the problem of estimating the best B term Fourier representation for a 
given frequency-sparse signal (i.e., vector) A of length N » B. More precisely, we investigate how to 
deterministically identify B of the largest magnitude frequencies of A , and estimate their coe.cients, 
in polynomial(B, log N) time. Randomized sub-linear time algorithms, which have a small (controllable) 
probability of failure for each processed signal, exist for solving this problem. However, for failure 
intolerant applications such as those involving mission-critical hardware designed to process many signals 
over a long lifetime, deterministic algorithms with no probability of failure are highly desirable. In 
this paper we build on the deterministic Compressed Sensing results of Cormode and Muthukrishnan (CM) 
[26, 6, 7] in order to develop the .rst known deterministic sub­linear time sparse Fourier Transform 
algorithm suitable for failure intolerant applications. Furthermore, in the process of developing our 
new Fourier algorithm, we present a simpli.ed deterministic Compressed Sensing algorithm which improves 
on CM s algebraic compressibility results while simultaneously maintaining their results concerning exponential 
decay. 1 Introduction In many applications only the top few most energetic terms of a signal s Fourier 
Transform (FT) are of in­terest. In such applications the Fast Fourier Transform (FFT), which computes 
all FT terms, is computation­ally wasteful. To make our point, we next consider a simple application-based 
example in which the FFT can be replaced by faster approximate Fourier methods. 1.1 Sub-Nyquist Single 
Frequency Acquisition Let f : [0, 2p] . C be a non-identically zero function of the form .x f(x)= C · 
e consisting of a single unknown frequency . . (-N, N ] (e.g., consider a windowed sinusoidal portion 
of a wide­band frequency-hopping signal [21]). Sampling at the Nyquist-rate would dictate the need for 
at least 2N equally spaced samples from f in order to discover . via the FFT without aliasing [3]. Thus, 
we would have to compute the FFT of the 2N-length vector pj A(j)= f, 0 = j< 2N. N However, if we use 
aliasing to our advantage, we can correctly determine . with signi.cantly fewer f-samples as follows: 
Let A2 be a 2-element array of f-samples with A2(0) = f (0) = C, and A2(1) = f (p)= C · (-1). . Calculating 
A 2 we get that 1+(-1). 1+(-1).+1 A 2(0) = C ·v , and A 2(1) = C ·v . 22 Note that since . is an integer, 
exactly one element of A 2 will be non-zero. If A 2(0) = 0 then we know that . = 0 modulo 2. On the other 
hand, A 2(1) = 0 implies that . = 1 modulo 2. In this same fashion we may use several potentially aliased 
Fast Fourier Transforms in parallel to discover . modulo 3, 5,..., the O(log N)th prime. Once we have 
collected these moduli we can reconstruct . via the famous Chinese Remainder Theorem (CRT). Theorem 1. 
Chinese Remainder Theorem (CRT): Any integer x is uniquely speci.ed mod N by its remainders modulo m 
relatively prime integers m p1,...,pm as long as l=1 pl = N . To .nish our example, suppose that N = 
500, 000 and that we have used three FFT s with 100, 101, and 103 samples to determine that . = 34 mod 
100, . = 3 mod 101, and . = 1 mod 103, respectively. Using that . = 1 mod 103 we can see that . = 103 
· a + 1 for some integer a. Using this new expression for . in our second modulus we get (103 · a + 1) 
= 3 mod 101 . a = 1 mod 101. *Supported in part by NSF DMS-0510203. Therefore, a = 101·b+1 for some 
integer b. Substituting University of Michigan -Ann Arbor for a we get that . = 10403 · b + 104. By similar 
work we can see that b = 10 mod 100 after considering . modulo 100. Hence, . = 104, 134 by the CRT. 
As an added bonus we note that our three FFTs will have also provided us with three di.erent estimates 
of . s coe.cient C. The end result is that we have used signi.cantly less than 2N samples to determine 
.. Using the CRT we required only 100 + 101 + 103 = 304 samples from f to determine . since 100 · 101 
· 103 > 1, 000, 000. In contrast, a million f-samples would be gathered dur­ing Nyquist-rate sampling. 
Besides needing signi.cantly less samples than the FFT, this CRT-based single fre­quency method dramatically 
reduces required compu­tational e.ort. And, it s deterministic. There is no chance of failure. Of course, 
a single frequency signal is incredibly simple. Signals involving more than 1 non­zero frequency are 
much more di.cult to handle since frequency moduli may begin to collide modulo various numbers. Dealing 
with the potential di.culties caused by such frequency collisions in a deterministic way com­prises the 
majority of this paper.  1.2 Compressed Sensing and Related Work Compressed Sensing (CS) methods [4, 
28, 26, 6, 7] provide a robust framework for reducing the number of measurements required to summarize 
sparse signals. For this reason CS methods are useful in areas such as MR imaging [23, 24] and analog-to-digital 
conver­sion [21, 20] where measurement costs are high. The general CS setup is as follows: Let A be an 
N-length signal/vector with complex valued entries, and . be a full rank N × N change of basis matrix. 
Furthermore, suppose that . · A is sparse (i.e., only k « N entries of . · A are signi.cant/large in 
magnitude). CS methods deal with generating a K ×N measurement matrix, M, with the smallest number of 
rows possible (i.e., K min­imized) so that the k signi.cant entries of . · A can be approximately recovered 
from the K-element result of (1.1) M· . · A. Note that CS is inherently algorithmic since a procedure 
for recovering . · A s largest k-entries from the result of Equation 1.1 must be speci.ed. For the remainder 
of this paper we will consider the special CS case where . is the N × N Discrete Fourier Transform matrix. 
Hence, we have -2pi·i·j e (1.2) .i,j = v N . N Our problem of interest is to .nd, and estimate the coe.cients 
of, the k signi.cant entries (i.e., frequencies) of A given a frequency-sparse (i.e., smooth) signal 
A. In this case the deterministic Fourier CS measurement matrixes, M·., produced by [28, 26, 6, 7] require 
super­linear O(KN)-time to multiply by A in Equation 1.1. Similarly, the energetic frequency recovery 
procedure of [4, 9] requires super-linear time in N. Hence, none of [4, 28, 9, 26, 6, 7] have both sub-linear 
measurement and reconstruction time. Existing randomized sub-linear time Fourier algo­rithms [15, 19, 
16] not only show great promise for de­creasing measurement costs, but also for speeding up the numerical 
solution of computationally challenging multi-scale problems [8, 18]. However, these algorithms are not 
deterministic, and so can produce incorrect re­sults with some small probability on each input signal. 
Thus, they aren t appropriate for long-lived failure in­tolerant applications. In this paper we build 
on the deterministic Com­pressed Sensing methods of Cormode and Muthukrish­nan (CM) [26, 6, 7] in order 
to construct the .rst known deterministic sub-linear time sparse Fourier algorithm. In order to produce 
our new Fourier algorithm we must modify CM s work in two ways: First, we alter CM s measurement construction 
in order to allow sub-linear time computation of Fourier measurements via alias­ing. Thus, our algorithm 
can deterministically approx­imate the result of Equation 1.1 in time K·polylog(N). Second, CM use a 
k-strongly selective collection of sets [17] to construct their measurements for algebraically compressible 
signals. We introduce the notion of a K­majority k-strongly selective collection of sets which leads 
us to a new reconstruction algorithm with better algebraic compressibility results than CM s algorithm. 
As a result, our deterministic sub-linear time Fourier algorithm has better then previously possible 
algebraic compressibility behavior. The main contributions of this paper are: 1. We present a new deterministic 
compressed sens­ing algorithm that both (i) improves on CM s alge­braically compressible signal results, 
and (ii) has comparable measurement/run time requirements to CM s algorithm for exponentially decaying 
sig­nals. 2. We present the .rst known deterministic sub­linear time sparse DFT. In the process, we 
ex­plicitly demonstrate the connection between com­pressed sensing and sub-linear time Fourier trans­form 
methods. 3. We introduce K-majority k-strongly selective col­lections of sets which have potential applications 
to streaming algorithms along the lines of [25, 13].  The remainder of this paper is organized as follows: 
 In section 2 we introduce relevant de.nitions and ter-as a sparse Fourier representation and denote 
it minology. Then, in section 3, we de.ne K-majority k-with a superscript s . Note that if we are given 
a sparse ss strongly selective collections of sets and use them to con-Fourier representation, R , we 
may consider R tobea s struct our compressed sensing measurements. Section 4 length-N signal. We simply 
view R as the N length contains our new deterministic compressed sensing al-signal s if (j, Cj ) . R.gorithm 
along with analysis of it s accuracy and run time. Finally, we present our deterministic sub-linear Cj 
R(j)= 0 otherwise time Fourier algorithm in sections 5 and 5.1. Section 6 contains a short conclusion. 
2 Preliminaries Throughout the remainder of this paper we will be interested in complex-valued functions 
f : [0, 2p] . C and signals (or arrays) of length N containing f values for all j . [0,N - 1]. Using 
this idea we may, for s example, compute R from R via the IDFT. A B term/tuple sparse Fourier representation 
is B­optimal for a signal A if it contains B of the most ener­getic frequencies of A along with their 
coe.cients. More precisely, we ll say that a sparse Fourier representation  ()[01] C.-.,C ,N ×jj s 
at various t . [0, 2p]. We shall denote such signals by R 0 = j<B = A, where A(j) . C is the signal s 
jth complex value for   all j . [0,N - 1] . N. Hereafter we will refer to the is B-optimal for A if 
there exists a valid ordering of A s process of either calculating, measuring, or retrieving coe.cients 
by magnitude the f value associated any A(j) . C from machine |A (.0)|= ... =| A (.j)|= ... =| (2.3) 
A(.N-1)| memory as sampling from f and/or A. Given a signal A we de.ne its discrete L2-norm, or Euclidean 
norm, A(.l)) l . [0,B) = s R .so that(.l, Note that a sig­ to be N-1 N nal may have several B-optimal 
Fourier representations if its frequency coe.cient magnitudes are non-unique. For example, there are 
two 1-optimal sparse Fourier rep­ A 2 = |A(j)|2 . j=0 resentations for the signal We will also refer 
to A 22 as A s energy. 2pij 4pij NN For any signal, A, its Discrete Fourier Transform A(j)=5e +5e ,N> 
2. (DFT), denoted A , is another signal of length N de.ned s as follows: However, all B-optimal Fourier 
representations, R opt, for any signal A will always have both the same unique N-1 N N j=0 bth 1 -2pi.j 
 A(.)= Ropt 2 and A - Ropt 2 values. A(j), .. . [0,N). v N e We continue with two .nal de.nitions: Let 
.b be a most energetic frequency as per Equation 2.3. We Furthermore, we may recover A from its DFT via 
the will say that a signal A is (algebraically) p-compressible Inverse Discrete Fourier Transform (IDFT) 
as follows: for some p> 1 if |A (.b)| = O(b-p) for all b . [1,N). If Rs is a B-optimal Fourier representation 
we can see N N-1 e N .=0 -1 1 A(j)= .(j)= A 2pi.j N  A(.), opt .j . [0,N ). v that 8 A-Ropt 22 = N 
N-1b=B A as |A (.b)|2 = Ob-2pdb 2 B We will refer to any index, ., of a frequency. (2.4) . A(.) as 
frequency . sFurthermore, we will refer to coe.cient for each . . [0,N). Parseval s equality tells us 
that A 2 = A 2 for any signal. In other words, the DFT preserves Euclidean norm and energy. Note that 
any non-zero coe.cient frequency will contribute to A s energy. Hence, we will also refer to |A (.)|2 
as frequency . s energy. If |A (.)| is relatively large we ll say that . is energetic. Our algorithm 
produces output of the form (.0,C0),..., (.B-1,CB-1) where each (.j,Cj) . [0,N - 1] × C. We will refer 
to any such set of B<N tuples  (.j ,Cj) . [0,N - 1] × C  0 = j<B  Hence, any p-compressible signal 
A (i.e., any signal with a .xed c . R so that |A(.b)|2 = c · b-p for all b . [1,N)) will have A - Ropt 
22 = c p · B1-2p for some B c p . R. For any p-compressible signal class (i.e., for any choice of p and 
c) we will refer to the related optimal O(B1-2p)-size worst case error value (i.e., Equation 2.4 above) 
as Copt 2. Similarly, we de.ne an exponentially B2 compressible (or exponentially decaying) signal for 
a .xed a . R+ to be one for which |A (.b)| = O(2-ab). The optimal worst case error is then 8 Copt (2.5) 
2 = O4-abdb = O(4-aB). B2 B Fix d small (e.g., d =0.1). Given a compressible input signal, A, our deterministic 
Fourier algorithm will identify B of the most energetic frequencies from A and approximate their coe.cients 
to produce a Fourier s A - R 22 representation Rwith = A - Ropt + 22 2 dCopt 2. These are the same types 
of compressible B signal results proven by CM [6, 7]. 3 Construction of Measurements We will use the 
following types of subset collections to form our measurements: Definition 3.1. A collection, S, of s 
subsets of [0,N) is called K-majority k-strongly selective if for any X . [0,N) with |X|= k, and for 
all x . X, the following are true: (i) x belongs to K subsets in S and, (ii) more than two-thirds of 
Sj .S containing x are such that Sj n X = {x} (i.e., every member of X occurs separated from all other 
members of X in more than two-thirds of the K S-subsets it belongs to). A K-majority k-strongly selective 
collection of sets is a more structured version of a k-strongly selective collection of sets [17, 26]. 
Every K-majority k­strongly selective collection of sets not only isolates rd 2 each x . X, but does 
so a s majority of the time. 3 Thus, our newly de.ned K-majority k-strongly selective collections will 
help us count how many times each signi.cant signal entry is isolated. This added structure allows a 
new reconstruction algorithm (Algorithm 1) with better algebraic compressibility properties than previous 
methods. Next, we will build O(log N) K-majority k-strongly selective collections of subsets. Each of 
these O(log N) collections will ultimately be used to determine ener­getic frequencies modulo a small 
prime <N. These moduli will then be used along with the Chinese Re­mainder Theorem to reconstruct each 
energetic fre­quency in a manner akin to the introduction s simple example. Our technique is motivated 
by the method of prime groupings .rst employed in [25]. To begin, we will denote each of the O(log N) 
collections of subsets by Sl where 0 = l = O(log N). We construct each of these K-majority k-strongly 
selective collections as follows: De.ne p0 = 1 and let p1,p2,...,pl,...,pm be the .rst m primes where 
m is such that mm-1 m m N pl == pl. k l=1 l=1 Hence, pl is the lth prime natural number and we have p0 
=1,p1 =2,p2 =3,p3 =5,...,pm = O(m log m). Note that we know pm = O(m log m) via the Prime Number Theorem, 
and so pm = O(log N log log N). Each pl will correspond to a di.erent K-majority k­strongly selective 
collection of subsets of [0,N)= {0,...,N - 1}. Along these same lines we let q1 through qK be the .rst 
K (to be speci.ed later) consequitive primes such that max(pm,k) = q1 = q2 = ... = qK . We are now ready 
to build S0, our .rst K-majority k­strongly selective collection of sets. We begin by letting S0,j,h 
for all 1 = j = K and 0 = h = qj - 1 be S0,j,h = {n . [0,N) | n = h mod qj }. Next, we progressively 
de.ne S0,j to be all integer residues mod qj, i.e., S0,j = {S0,j,h | h . [0,qj)}, and conclude by setting 
S0 equal to all K such qj-residue groups: = .K S0 j=1S0,j. More generally, for 0 = l = m we de.ne Sl 
to be .K {n . [0,N) | n = h mod plqj } h . [0,plqj) . j=1 Lemma 3.1. Fix k. If we set K = 3(k - 1)llogk 
NJ + 1 then S0 will be a K-majority k-strongly selective collection of sets. Furthermore, if K = O(k 
logk N) sl then |S0| = Ok2 log2 k N · max(log k, log logk N) . Proof. Let X . [0,N) be such that |X|= 
k. Further­more, let x, y . X be such that x = y. By the Chi­nese Remainder Theorem we know that x and 
y may only collide modulo at most llogk NJ of the Kq-primes qK = ... = q1 = k. Hence, x may collide with 
all the other elements of X (i.e., with X -{x}) modulo at most (k - 1)llogk NJ q-primes. We can now see 
that x will be isolated from all other elements of X modulo at least 2K K - (k - 1)llogk NJ= 2(k - 1)llogk 
NJ +1 >q­ 3 primes. This leads us to the conclusion that S0 is indeed K-majority k-strongly selective. 
Finally, we have that K N |S0|= qj = K · qK . j=1 Furthermore, given that K> max(k, m), the Prime Number 
Theorem tells us that qK = O(K log K). Thus, we can see that S0 will indeed contain sl Ok2 log2 k N · 
max(log k, log logk N) sets. Note that at least O(k logk N) primes are required in order to create a 
(K-majority) k-strongly separating collection of subsets using primes in this fashion. Given any x . 
[0,N)a k - 1 element subset X can be created via the Chinese Remainder Theorem and x moduli so that every 
element of X collides with x in any desired O(logk N) q-primes. We next consider the properties of the 
other m collections we have de.ned: S1,..., Sm. Lemma 3.2. Let Sl,j,h = {n . [0,N) | n = h mod plqj }, 
X . [0,N) have = k elements, and x . X. Furthermore, suppose that S0,j,h n X = {x}. Then, for all l . 
[1,m], there exists a unique b . [0,pl) so that Sl,j,h+b·qj n X = {x}. Proof. Fix any l . [1,m]. S0,j,h 
n X = {x} implies that x = h + a · qj for some unique integer a. Using a s unique representation modulo 
pl (i.e., a = b + c · pl) we get that x = h + b · qj + c · qjpl. Hence, we can see that x . Sl,j,h+bqj 
. Furthermore, no other element of X is in Sl,j,h+t·qj for any t . [0,pl) since it s inclusion therein 
would imply that it was also an element of S0,j,h. Note that Lemma 3.2 and Lemma 3.1 together imply that 
each S1,..., Sm is also a K-majority k­strongly separating collection of subsets. Also, we can see that 
if x . Sl,j,h+b·qj we can .nd x mod pl by simply computing h + bqj mod pl. Finally, we form our measurement 
matrix: Set S = .m To form our measurement matrix, l=0Sl. M, we simply create one row for each Sl,j,h 
.S by computing the N-length characteristic function vector of Sl,j,h, denoted .Sl,j,h . This leads to 
M being a O (k2) x N measurement matrix. Here we bound the number of rows in M by noting that: (i) |S| 
<m · K · pmqK , (ii) m = O(log N), (iii) pm = O(log N · log log N), (iv) K = O(k log N), and (v) qK = 
O(K log K). 4 Signal Reconstruction from Measurements Let A be an N-length signal of complex numbers 
with it s N entries numbered 0 through N - 1. Our goal is to identify B of the largest magnitude entries 
of A (i.e., the .rst B entries in a valid ordering of A as in Equation 2.3) and then estimate their 
signal values. Toward this end, set |A (.B)| (4.6) E = v 2C where C> 1 is a constant to be speci.ed later, 
and let B' be the smallest integer such that N-1 N E (4.7) |A (.b)| <. 2 b=Bl Algorithm 1 Sparse Approximate 
1: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: 25: 26: 27: 28: 
29: 30: Input: Signal A, integers B, B' s Output: R , a sparse representation for A s Initialize R .Ø 
Set K =3B'llogBl NJ Form measurement matrix, M, via K-majority B'­strongly selective collections (Section 
3) Compute M· A Identification for j from 0 to K do Sort \.S0,j,0 , A ),..., \.S0,j,qj-1 , A ) by magnitude 
for b from 0 to B' do kj,b . bth largest magnitude \.S0,j,· , A ) r0,b . kj,b s associated residue mod 
qj for l from 1 to m do tmin . mint.[0,pl) |kj,b -\.Sl,j,t·qj +r0,b , A )| rl,b . r0,b + tmin · qj mod 
pl end for Construct .j,b from r0,b,...,rm,b via the CRT end for end for Sort .j,b s maintaining duplicates 
and set C(.j,b)= the number of times .j,b was constructed via line 16 Estimation for j from 0 to K do 
for b from 0 to B' do if C(.j,b) > 2K then 3 C(.j,b) . 0 x = median{real(kjl,bl )|.jl,bl = .j,b}y = median{imag(kjl,bl 
)|.jl,bl = .j,b}s s R. R .{(.j,b,x + iy)} end if end for end for s Output B largest magnitude entries 
in R Note that B' identi.es the most energetic insigni.cant frequency (i.e., with energy < a fraction 
of |A (.B)|). We expect to work with sparse/compressible signals so that B = B' « N. Later we will give 
speci.c values for C and B' depending on B, the desired approximation error, and A s compressibility 
characteristics. For now we show that we can identify/approximate B of A s largest magnitude entries 
each to within E-precision via Algorithm 1. Algorithm 1 works by using S0 measurements to separate A 
s signi.cantly energetic frequencies O = {.0,...,.Bl-1}. [0,N). Every measurement which successfully 
separates an energetic frequency .j from all other members of O will both (i) provide a good (i.e., 
 |A(.B)| within .= v ) coe.cient estimate for .j , and 2 22 (ii) yield information about .j s identity. 
Frequency separation occurs because our S0 measurements can not collide any .xed .j . O with any other 
member of O modulo more than (B ' - 1) logBl Nq-primes rds2 (see Lemma 3.1). Therefore, more than of 
S0 s 3 3B ' logBl N +1 q-primes will isolate any .xed .j . O. This means that our reconstruction algorithm 
will identify all frequencies at least as energetic as .B at least 2B ' logBl N + 1 times. We can ignore 
any frequencies that are not recovered this often. On the other hand, for any frequency that is identi.ed 
more than 2B ' logBl N times, at most B ' logBl N of the measurements which lead to this identi.cation 
can be signi.cantly contaminated via collisions with valid O members. Therefore, we can take a median 
of the more than 2B ' logBl N measurements leading to the recovery of each frequency as that frequency 
s coe.cient estimate. Since more than half of these measurements must be accurate, the median will be 
accurate. The following Theorem is proved in the appendix. Theorem 2. Let R opt be a B-optimal Fourier 
repre­sentation for our input signal A. Then, the B term rep­ s resentation, R , returned from Algorithm 
1 is such that 2 + 6B·|A(.B )|2 A - R 22 = A - Ropt . Furthermore, 2 C Algorithm 1 s Identi.cation and 
Estimation (lines 7 ­30) run time is O(B '2 log4 N). The number of mea­surements used is O(B '2 log6 
N). Theorem 2 immediately indicates that Algorithm 1 gives us a deterministic O(m2 log6 N )-measurement, 
O(m2 log4 N)-reconstruction time method for exactly recovering vectors with m non-zero entries. If A 
has exactly m non-zero entries then setting B ' = B = m and C = 1 will be su.cient to guarantee that 
both eN-1 |A (.B)|2 = 0 and b=Bl |A (.b)| = 0 are true. Hence, we may apply Theorem 2 with B ' = B = 
m and C =1 to obtain a perfect reconstruction via Algorithm 1. However, we are mainly interested in the 
more realistic cases where A is either algebraically or exponentially compressible. The following theorem 
presents itself. Theorem 3. Let A be p-compressible. Then, Al­gorithm 1 can return a B term sparse represen­ 
s 2 tation, R , with A - R 22 = A - Ropt 2 + 2p 2 dCopt 2 using OB p-1 d 1-p log4 Ntotal identi.ca- 
B 2 2p 2 tion/estimation time and OB p-1 d 1-p log6 Nmea­ surements. If A decays exponentially, Algorithm 
1 s can return a B term sparse representation, R , with 2 + dCopt 2 A - R 22 = A - Ropt 2 B 2 using 
both Algorithm 2 Fourier Measure 1: Input: f-samples, integers m, K 2: Output: <.Sl,j,h ,f >-measurements 
3: Zero a O(qK pm)-element array, A 4: for j from 1 to K do 5: for l from 1 to m do 2p 2p(qj pl-1) 6: 
A . f(0),f,...,f qjpl qjpl 7: Calculate A via Chirp z-Transform [27, 2] 8: <.Sl,j,h ,f >. A (h) for each 
h . [0,qj pl) 9: end for 10: end for 11: Output <.Sl,j,h ,f >-measurements a B2 + log2 d -1 · polylog(N) 
measurements and iden­ ti.cation/estimation time. For p-compressible signals, p> 2, CM s al­  6p 6 gorithm 
[6, 7] takes OB p-2 d 2-p log6 N-identi­ p-2 d 2-p .cation/estimation time and OB 4p 4 log4 N­ measurements 
to achieve the same error bound. As a concrete comparison, CM s algorithm requires O(B18d-6 log6 N)-identi.cation/estimation 
time and O(B12d-4 log4 N)-measurements for 3-compressible sig­nals. Algorithm 1, on the other hand, requires 
only O(B3d-1 log4 N)-identi.cation/estimation time and O(B3d-1 log6 N)-measurements. Hence, we have im­proved 
on CM s algebraic compressibility results. All that s left to do in order to develop a deterministic 
sub-linear time Fourier algorithm is to compute our CS Fourier measurements (Algorithm 1 lines 1 -6) 
in sub­linear time. 5 Fast Fourier Measurement Acquisition Our goal in this section is to demonstrate 
how to use Algorithm 1 as means to approximate the Fourier transform of a signal/function f : [0, 2p] 
. C, where th (i) f has an integrable pderivative, and (ii) f(0) = f(2p),f '(0) = f '(2p),...,f(p-2)(0) 
= f(p-2)(2p). In this case we know the Fourier coe.cients for f to be p-compressible [3, 12]. Hence, 
for N = q1 · p1 ··· pm su.ciently large, if we can collect the necessary Algo­rithm 1 (lines 5 and 6) 
measurements in sub-linear time we will indeed be able to use Algorithm 1 as a sub-linear time Fourier 
algorithm for f. Note that in order to validate the use of Algorithm 1 (or any other sparse approximate 
Fourier Transform method [15, 16]) we must assume that f exhibits some multiscale behavior. If f contains 
no unpredictably en­ergetic large (relative to the number of desired Fourier coe.cients) frequencies 
then it is more computationally e.cient to simply use standard FFT/USFFT methods [5, 22, 1, 10, 11]. 
The responsible user, therefore, is not entirely released from the obligation to consider f s likely 
characteristics before proceeding with computa­tions. Choose any Section 3 q-prime qj, j . [1,K], and 
any p-prime pl with l . [0,m]. Furthermore, pick h . [0,qj pl). Throughout the rest of this discussion 
we will consider f to be accessible to sampling at any de­sired predetermined positions t . [0, 2p]. 
Given this as­ 2p 2p(qjpl-1) sumption, we may sample f at t =0, ,..., qjpl qj pl in order to perform 
the following DFT computation: qjNpl-1 -2pihk 12pk qjpl ,f >= f e. <.Sl,j,h qjpl qjpl k=0 Using the Fourier 
expansion for f yields qjNpl-1 8 N 2pi.k -2pihk qjplqjpl <.Sl,j,h ,f >=1 f (.)e e. qj pl k=0.=-8 Finally, 
exchanging the order of summation above, we see that <.Sl,j,h ,f > reduces to 8qjNpl-1 N 2pi(.-h)k N 
qj pl f (.) e = f (.) qjpl .=-8 k=0 .=h mod qjpl via aliasing [3]. Using Sections 3 and 4 we can see 
that these measurements are exactly what we need in order to determine B of the most energetic frequencies 
of f modulo N = q1 · p1 ··· pm (i.e., B of the most energetic frequencies of f s band-limited interpolant 
s DFT). We are now in the position to modify Algorithm 1 in order to .nd a sparse Fourier representation 
for f . Todo so we proceed as follows: First, remove lines 5 and 6 and replace them with Algorithm 2 
for computing all the necessary <.Sl,j,h ,f >-measurements. Second, replace each <.Sl,j,h , A > by <.Sl,j,h 
,f > in Algorithm 1 s Identification section. It remains to show that these Algorithm 1 modi.cations 
indeed yield a sub-linear time approximate Fourier transform. The following theorem presents itself: 
Theorem 4. Let f : [0, 2p] . C have (i) an inte­ th grable pderivative, and (ii) f(0) = f(2p),f '(0) 
= f '(2p),...,f(p-2)(0) = f(p-2)(2p) for some p> 1. Fur­ p p-1 d 1-p thermore, assume that f s B ' = 
OB 1 largest s ) NN magnitude frequencies all belong to -,. 22 Then, we may use Algorithm 1 to return 
a B s term sparse Fourier representation, R , for f such f R 2 f 2 + dCopt 2 that - =- Ropt using 22 
B 2 2p 22p 2 OB p-1 d 1-p log7 N -time and OB p-1 d 1-p log6 N ­ measurements from f. If f : [0, 2p] 
. C is smooth (i.e., has in.nitely many continuous derivatives on the unit circle where 0 is identi.ed 
with 2p) it follows from Theorem 4 that Algorithm 1 can be used to .nd an d-accurate, with sl 1 d = O 
, sparse B-term Fourier representation for N f using O (B2)-time/measurements. This result dif­fers from 
previous sub-linear time Fourier algorithms [15, 16] in that both the algorithm and the measure­ments/samples 
it requires are deterministic. Recall that the deterministic nature of the algorithm s required samples 
is potentially bene.cial for failure intolerant hardware. In signal processing applications the sub-Nyquist 
sampling required to compute Algorithm 1 s ,f >-measurements could be accomplished via <.Sl,j,h O(B) 
parallel low-rate analog-to-digital converters. 5.1 DFT from Inaccessible Signal Samples Throughout the 
remainder of this section we will con­ sider our N-length compressible vector A to be the product of 
the N x N DFT matrix, ., and a non-sparse N-length vector A. Thus, A =.A. Furthermore, we will assume 
that A contains equally spaced samples from some unknown smooth function f : [0, 2p] . C (i.e., A s band-limited 
interpolent). Hence, 2pj A(j)= f ,j . [0,N). N We would like to use our modi.ed Algorithm 1 along with 
Algorithm 2 to .nd a sparse Fourier representation N for A . However, unless . Nfor all qjpl-pairs (which 
qjpl would imply f had been grossly oversampled), A won t contain all the f-samples required by Algorithm 
2. Not having access to f directly, and restricting ourselves to sub-linear time approaches only, we 
have little recourse but to locally interpolate f around our required samples. For each required Algorithm 
2 f-sample at t = 2ph ,h . [0,qjpl), we may approximate f(t) to within qj pl O(N-2.)-error by constructing 
2 local interpolents (one real, one imaginary) around t using A s nearest 2. entries [14]. These errors 
in f-samples can lead to errors of size O(N-2. · pmqK log pmqK ) in our <.Sl,j,h ,f > calculations. 
However, as long as the <.Sl,j,h ,f >­measurement errors are small enough (e.g., O(d · B-p) in the p-compressible 
case) Theorem 4 and all related Section 4 results and will still hold. After some scratch work we can 
see that using 2. = O(log d-1 + p) interpolation points per f-sample ensures all our <.Sl,j,h ,f >-measurement 
errors are O(d · B-p). We have the following result: Theorem 5. Let A =.A be p-compressible. Then, we 
may use Algorithms 1 and 2 to return a B term sparse s representation, R , for A such that A - R 22 = 
A - 2p 2 22 Ropt 2 + dCopt using O B p-1 d 1-p (log d-1 + p)2 - B 2 2p 2 time and O B p-1 d 1-p (log 
d-1 + p) -samples from A. Notice that Theorem 5 no longer guarantees an d = O( 1 )-accurate O (B2)-time 
DFT algorithm for N smooth data (i.e., A s containing samples from a smooth function f). This is because 
as p .8 we require an increasingly large number of interpolation points per f-sample in order to guarantee 
our <.Sl,j,h ,f >­measurements remain O(d·B-p)-accurate. However, for d = O(log-1 N), we can still consider 
smooth data A to be O(log N)-compressible and so achieve a O (B2)-time DFT algorithm. 6 Conclusion Compressed 
Sensing (CS) methods provide algorithms for approximating the result of any large matrix mul­tiplication 
as long as it is known in advance that the result will be sparse/compressible. Hence, CS is po­tentially 
valuable for many numerical applications such as those involving multiscale aspects [8, 18]. In this 
paper we used CS methods to develop the .rst known deterministic sub-linear time sparse Fourier transform 
algorithm. In the process, we introduced a new deter­ministic Compressed Sensing algorithm along the 
lines of Cormode and Muthukrishnan (CM) [6, 7]. Our new deterministic CS algorithm improves on CM s algebraic 
compressibility results while simultaneously maintain­ing their results concerning exponential compressibility. 
Compressed Sensing is closely related to hashing methods, combinatorial group testing, and many other 
algorithmic problems [25, 13]. Thus, K-majority k­strongly selective collections of sets and Algorithm 
1 may help improve deterministic results concerning stream hashing/heavy-hitter identi.cation. Further 
de­velopment of these/other algorithmic applications is left as future work. It is also worthwhile to 
note that Monte Carlo Fourier results similar to those of [16] may be obtained by altering our measurement 
construction in Section 3. If we construct our Sl collections by using only a small subset of O(log B 
') randomly chosen qj s, we will still locate all su.ciently energetic entries of A with high probability. 
The discovered entries coe.cients can then be approximated by using either (i) standard USFFT techniques 
[16, 10, 11, 22], or (ii) another O(log B ') randomly chosen qj-measurement groups. In either case, the 
end result will be a O(B ' · polylog(N))­time/measurement Fourier algorithm that produces the same results 
(e.g., Theorem 4) as above with high probability. 7 Acknowledgments We would like to thank Graham Cormode 
and S. Muthukrishnan for answering questions about their work. We would also like to thank Martin Strauss, 
Anna Gilbert, Joel Lepak, and Hualong Feng for helpful discussions, advice, and comments. References 
<RefA>[1] C. Anderson and M. D. Dahleh, Rapid computation of the discrete Fourier transform, SIAM J. Sci. Comput., 
17:913 919, 1996. [2] L. I. Bluestein. A Linear Filtering Approach to the Computation of Discrete Fourier 
Transform, IEEE Transactions on Audio and Electroacoustics, 18:451 455, 1970. [3] J. P. Boyd, Chebyshev 
and Fourier Spectral Methods, Dover Publications, Inc., 2001. [4] E. Candes, J. Romberg, and T. Tao, 
Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information, 
IEEE Trans. Inform. Theory, 52:489 509, 2006. [5] J. Cooley and J. Tukey, An algorithm for the machine 
calculation of complex Fourier series, Math. Comput., 19:297 301, 1965. [6] G. Cormode and S. Muthukrishnan, 
Combinatorial Algorithms for Compressed Sensing, Technical Report DIMACS TR 2005-40, 2005. [7] G. Cormode 
and S. Muthukrishnan, Combinatorial Algorithms for Compressed Sensing, Conference on Information Sciences 
and Systems, March 2006. [8] I. Daubechies, O. Runborg, and J. Zou, A sparse spec­tral method for homogenization 
multiscale problems, Multiscale Model. Sim., 2007. [9] R. A. DeVore, Deterministic constructions of compressed 
sensing matrices, Preprint at http://www.ima.umn.edu/2006-2007/ND6.4­15.07/activities/DeVore-Ronald/Henryk.nal.pdf, 
2007. [10] A. Dutt and V. Rokhlin, Fast Fourier transforms for nonequispaced data, SIAM J. Sci. Comput., 
14:1368 1383, 1993. [11] J. A. Fessler and B. P. Sutton, Nonuniform Fast fourier transforms using min-max 
interpolation, IEEE Trans. Signal Proc., 51:560 574, 2003. [12] G. B. Folland, Fourier Analysis and Its 
Applications, Brooks/Cole Publishing Company, 1992. [13] S. Ganguly and A. Majumder, CR-precis: A determin­istic 
summary structure for update data streams, ArXiv Computer Science e-prints, Sept. 2006. [14] C. F. Gerald 
and P. O. Wheatley, Applied Numerical Analysis, Addison-Wesley Publishing Company, 1994. [15] A. Gilbert, 
S. Guha, P. Indyk, S. Muthukrishnan, and M. Strauss, Near-optimal sparse Fourier estimation via sampling, 
ACM STOC, pages 152 161, 2002. [16] A. Gilbert, S. Muthukrishnan, and M. Strauss, Im­proved time bounds 
for near-optimal sparse Fourier representations, SPIE, 2005. [17] P. Indyk. Explicit constructions of 
selectors and related combinatorial structures, with applications, SODA 02, pages 697 704, Philadelphia, 
PA, USA, 2002. [18] M. A. Iwen, Unpublished Results, http://www­personal.umich.edu/ markiwen/. [19] M. 
A. Iwen, A. C. Gilbert, and M. J. Strauss, Empirical evaluation of a sub-linear time sparse DFT algorithm, 
Submitted for Publication, 2007. [20] S. Kirolos, J. Laska, M. Wakin, M. Duarte, D. Baron, T. Ragheb, 
Y. Massoud, and R. Baraniuk, Analog-to­information conversion via random demodulation. in Proc. IEEE 
Dallas Circuits and Systems Conference, 2006. [21] J. Laska, S. Kirolos, Y. Massoud, R. Baraniuk, A. 
Gilbert, M. Iwen, and M. Strauss, Random sam­pling for analog-to-information conversion of wideband signals, 
Proc. IEEE Dallas Circuits and Systems Con­ference, 2006. [22] J.-Y. Lee and L. Greengard, The type 3 
nonuniform FFT and its applications, J Comput. Phys., 206:1 5, 2005. [23] M. Lustig, D. Donoho, and J. 
Pauly, Sparse MRI: The application of compressed sensing for rapid MR imaging, Submitted for publication, 
2007. [24] R. Maleh, A. C. Gilbert, and M. J. Strauss, Signal re­covery from partial information via 
orthogonal match­ing pursuit, IEEE Int. Conf. on Image Processing, 2007. [25] S. Muthukrishnan, Data 
Streams: Algorithms and Applications, Foundations and Trends in Theoretical Computer Science, 1, 2005. 
[26] S. Muthukrishnan, Some Algorithmic Problems and Results in Compressed Sensing, Allerton Conference, 
2006. [27] L. Rabiner, R. Schafer, and C. Rader, The Chirp z-Transform Algorithm, IEEE Transactions on 
Audio and Electroacoustics, AU-17(2):86 92, June 1969. [28] J. Tropp and A. Gilbert, Signal recovery 
from partial information via orthogonal matching pursuit, Submit­ted for Publication, 2005.</RefA> A Proof of 
Theorem 2 We begin by proving two lemmas. Lemma A.1. IDENTIFICATION: Lines 7 through 19 of Algorithm 
1 are guaranteed to recover all valid .0,...,.B-1 (i.e., all . with |A (.)|=| A (.B)| -there may be >B 
such entries) more then 2K times. Hence, 3 despite line 22, an entry for all such .b, 0 = b<B, will s 
be added to R in line 26. Proof. Because of the construction of S0 (i.e., proof of Lemma 3.1) we know 
that for each b . [0,B) 2K there exist more then subsets S .S0 such that 3 S n{.bl | b ' . [0,B ')} = 
{.b}. Choose any b . [0,B). Denote the q-primes that isolate .b from all of .0,...,.b-1,.b+1,...,.Bl-1 
by 2K ' qj1 ,qj2 ,...,qjKl , <K = K. 3 We next show that, for each k ' . [1,K '], we get <.S , A > as 
one of the B ' + 1 largest 0,jkl ,.b mod qjkl magnitude <.S0,j, A >-measurements identi.ed in kl ,· line 
10. Choose any k ' . [1,K ']. We know that N-1 v N < v < |A (.B)|- 2 |A (.bl )| EE 22 bl=Bl N =|A (.b)|- 
A(.bl ) bl.[Bl,N),.bl =.b = <.S , A >. 0,jkl ,.b mod qjkl We also know that the (B ' + 1)st largest 
measurement L2-magnitude must be < . Hence, we are guaranteed 2 to execute lines 12-15 with an r0,· = 
.b mod qjkl . Choose any l . [1,m] and set O to be .bl b ' . [B ' ,N),.bl = .bmodqjkl ,.bl = .bmodqjkl 
pl . Using Lemma 3.2 we can see that line 13 inspects all the necessary residues of .b mod plqjkl . To 
see that tmin will be chosen correctly we note .rst that <.S , A > - <.S , A > 0,jkl ,.bmodqj0,jkl ,.bmodplqj 
kl kl N v N = A (.bl ) = 2 |A (.bl )|. .bl .O .bl .O Furthermore, setting r0,· = .b mod qjkl and O' to 
be .bl b ' . [B ' ,N),.bl = .b mod qjkl ,.bl =(r0,·+tqjkl ) mod qjkl pl for t with (r0,· + tqjkl )= .b 
mod qjkl pl , we have N-1 v N v N E 2 |A (.bl )| < v < |A (.B)|- 2 |A (.bl )| 2 bl=Bl .bl .O N =|A (.b)|- 
A (.bl ) . .bl .Ol Finally we can see that N |A (.b)|- A (.bl ) = <.S , A > 0,jkl ,.bmodqj.bl .Ol kl 
 - <.S , A >. 0,jkl ,(r0,·) +tqj=.bmodplqj kl kl Hence, lines 13 and 14 will indeed select the correct 
residue for .b modulo pl. Therefore, line 16 will ' 2K correctly reconstruct .b at least K> times. 3 
 Lemma A.2. ESTIMATION: Every (., A.) stored in s  R in line 26 is such that |A (.) - A.|2 <E. s Proof. 
Suppose that (., A .) is stored in R . This only happens if A (.) has been estimated by N <.S , A > 
= A( .) 0,j,. mod qj . =. mod qj for more then 2K qj -primes. The only way that any such 3 estimate 
can have |A (.)- <.S , A > |= 2 0,j,. mod qj is if . collides with one of .0,...,.Bl-1 modulo qj (this 
is due to the de.nition of B ' in Equation 4.7). By the proof of Lemma 3.1 we know this can happen at 
most K B ' llogBl N J < times. Hence, more then half of the 3 '' 2K estimates, A , must be such that 
|A (.) - A.| < . 3 .2 It follows that taking medians as per lines 24 and 25 will result in the desired 
E-accurate estimate for A (.). We are now ready to prove Theorem 2. Theorem 2 Let R opt be a B-optimal 
Fourier repre­ sentation for our input signal A. Then, the B term s representation R returned from 
Algorithm 1 is such 2 + 6B·|A(.B)|2 A - R 22 that = A - Ropt . Fur­ 2 C thermore, Algorithm 1 s Identi.cation 
and Estimation (lines 7 -30) run time is O(B '2 log4 N). The number of measurements used is O(B '2 log6 
N). Proof. Choose any b . [0,B). Using Lemmas A.1 s and A.2 we can see that only way some .b ./R is if 
B s there exists some associated b ' . [B, N) so that .bl . R and  |A (.B)| + E =| A (.bl )| + E> |A.bl 
|=  |A.b | > |A (.b)|- E =| A (.B)|- E. In this case we get 2E> |A (.b)|-| A (.bl )|= 0 so that (1.8) 
|A (.bl )|2 +4EE + |A (.B)| =| A (.bl )|2+ 4EE + |A (.bl )| > |A (.b)|2 . Now using Lemma A.2 we can 
see that NN A -R 2 = |A (.)|2 + |A (.)-A .|2 < Rs R s (.,·)./(., A.). N |A (.)|2 + B · E2 . R s (.,·)./ 
Furthermore, we have N B · E2 + |A (.)|2 = B · E2+ R s (.,·)./ NN |A (.b)|2 + |A (.bl )|2 . R s R s 
b.[0,B),.b./bl.[B,N),.bl ./ Using observation 1.8 above we can see that this last expression is bounded 
above by N B · (5E2 +4E|A (.B)|)+ |A (.bl )|2+ R s bl.[B,N),.bl . N |A (.bl )|2 = R s bl.[B,N),.bl ./ 
2 A - R opt 2 + B · (5E2 +4E|A (.B)|). Substituting for E (see Equation 4.6) gives us our result. We 
next focus on run time. Algorithm 1 s Iden­ti.cation (i.e., lines 7 through 19) run time is domi­nated 
by the O(KB ' m) executions of line 13. And, each execution of line 13 takes time O(pm). Hence, given 
that m = O(log N), pm = O(log N · log log N), and K = O(B ' logBl N), we can see that Identi.cation requires 
O(B '2 · logBl N · log2 N · log log N )-time. Continuing, Algorithm 1 s Estimation (i.e., lines 20 through 
30) run time is ultimately determined by line 22 s if-statement. Although line 22 is exe­cuted O(KB ')= 
O(B '2 logBl N) times, it can only evaluate to true O(B ') times. Hence, each line 24/25 O(B ' logBl 
N log B ')-time median operation will be evaluated at most O(B ') times. The resulting Esti­mation runtime 
is therefore O(B '2 logBl N log B '). To bound the number of measurements we recall that: (i) the number 
of measurements is <m · K · pmqK ,(ii) m = O(log N), (iii) pm = O(log N · log log N), (iv) K = O(B ' 
log N), and(v) qK = O(K log K). Hence, the number of measurements is O s K2 log K log2 N log log N l 
. Substituting for K gives us the desired bound.   
			
