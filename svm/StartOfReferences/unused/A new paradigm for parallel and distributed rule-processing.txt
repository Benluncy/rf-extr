
 A NEW PARADIGM FOR PARALLEL AND DISTRIBUTED RULE-PROCESSING oun Wolfson Department of Computer Science 
Columbia Uruverslty New York, NY 10027 wolfson@cs columbla edu and Aya Ozen Department of Electrical 
Engmeenng The Techmon - IIT Halfa, Israel ABSTRACT This paper IS concerned with the parallel evaluauon 
of datalog rule programs, mdlnly by processors that arc mterconnected by a commumcatton network We mnoduce 
a paradigm. called data- rcducuon. for the parallel evaluation of a general datalog program Scvcral parallehzatlon 
strategies discussed previously m [CW, GST, W, WS] arc special casts of thts paradigm The paradigm parallehzes 
the evaluation by parutrontng among the processors the tnstantlatlons of the rules After presentmg the 
para&#38;gm, we discuss the followmg lssucs. that we see fundamental for parallch- zatlon stratcgles 
derived from the paradigm propertlu of the stra- teglcs that enable a rcductlon tn Ihe communtcatton 
overhead, dccomposabllrty, load balancmg. and appltcatton to programs wtth ncgatlon We prove that decomposabthty, 
a concept tntroduced prcvmusly m [WS, CW], IS undecidable 1 Introduction A knowledge base IS a relauonal 
database augmented with a rule program, c g datalog (see [MW]) In thts paper we con- unuc the study of 
parallchzatlon m knowledge bases, begun tn [WS,W,CW] The cmphasts m these works was on parallellzalon 
1 This research was supponed u1 part by DARPA Researti Gr.+m #I- 29601 87 C 0074, and by the Center for 
Advanced Technology dl Columbia Ln~vcrs~tyunder contract hYSSTF-CAT(89)J Perm~ssmn to copy wthout fee 
all or pan of thus matenal IS granted prowded that the copsesare not made or dutnbuted for drect commeraal 
advantage, the ACM copyqbt notmz and the btk of the publwatlw and I&#38; date appear. and notme u pen 
(hat copyog IS by pamum of the Asrouatvan for Computmg Mach~ncty To copy otbemse, or to repubhsb, reqwes 
a fee and/or speafic permMMm 0 1990 ACM lW79136.5 WWOOOYO133 $1 SO wtthout commumcatton overhead, namely 
pure parallellzauon Thus type of parallekzatlon 1s restncted m its appllcabllrty. only some classes of 
programs can be purely parallellzed To over- come &#38;us lmutatlon, UI [Cw] we proposed a strategy that 
does recur an overhead, but can be applied to every smgle-rule program wuhout constants We show that 
all the strategies Qscussed m our pevtous works are special cases of the data-reduction paradigm, that 
we tntroduce tn Ous paper It supulates that parallellzation is obtatnedby having each processor evaluate 
the orlgmal program, but with less data Generally, thts 1s also what parallel processors do when addmg 
two vectors m parallel In this paper we demon- strate that &#38;us idea 1s applicable to rule processmg, 
and analyze it III ths amtext In extension to the smategtes discussed 111 our pre- VIOUSworks, data-reductton 
1s applicable to datalog programs with muluple rules. constants, and negation A data-reductron strategy 
1s obtamed as follows Every smgle-processor datalog evaluation method can be regarded as a sequence of 
rule-mstanuatlons, m each rule-mstanhatlon, the van- ables m the rule we replaced by constants from the 
mput The purpose of data-reduction IS to parutton the mstantlattons among multtple processors, such that 
if each processor uses a smgle processor method to evaluate the ongmal program, then it processes less 
data The works on the NCcomplexq of pro- grams (e g [AP, CK, K, UV]) also partttlon the mstantiatlons. 
but they assign one mstanuatton to a processor, assummg a polyno- mm1 (m the database size) number of 
processors The works iden- ufy the programs for which the evaluation can complete tn poly- logarithmic 
ume If the number of processors is COnstant (as we assume), then the NC-type of evaluauon algonthms can 
be adapted, by asstgnmg the work of multiple processors to a single processor However, tt turns out that 
which multiple processors are assigned to a smgle one, 1 e how the pieces of work are grouped. 1s very 
unportant as far as overhead (particularly if the processors do not have shared memory) and evaluation 
cost are concemcd The present paper studies the partltlonmg of work among the processors Smce this paper 
1s devoted to data-reducbon issues, m the next paragraphs we explam the paradigm m detail, and pomt out 
its relatlonshp to other relevant work The database commumty observed that given massive amounts of data, 
a declarative pro- gram, such as datalog, should be evaluated m a set-oriented, rather than tuple-oriented 
(a la Concurrent Prolog [DL, Sh]) fashion The set-oriented, or relational, evaluation of a program P 
amounts to ltcratlvely computmg a relational algebra expression for each rule of P, until a fix-point 
1s reached ([U]) Example 1 Consider the transltlve closure program P 1 ~(x,Y)=~(w).~(z,Y) S(X,Y) =A(x,y) 
The naive evaluation of P1 mltlahzes the relation S to A and then computes the relational algebra expression 
until no new tuples arc added to S 0 Lxdmple 2 The program P2 ~O,)=~(z),A(z,y) S(Y) =A@,Y) that rinds 
all the nodes of a graph reachable from the node a (a constant) The semi-nalvc evaluation of Pz mltiahzes 
AS and S to the tuplcs of A that have the constant a m their first posltlon, and then It evaluates the 
followmg expressions ~(Y)=S(Y)UASO) Itcrdtivcly, until AS = 0 Cl A way of partltlonmg the rule-mstantldtlons 
among the pro- cessors 1s the followmg Assume that there are k processors, all of which have access to 
the cxtenslonal database (it 1s either reph- cdtcd, or resides m some common memory, or can be received 
from a processor thdt owns it) It is possible to parhtlon the computation of relational algebra operahons 
among the proces- sors For this purpose, one can use some technique from the exlst- mg literature on 
pdrallcl evaluahon of relational operations (e g [BBDW]) However, we postuldtc that the work partltlomng 
can bcttcr be pcrformcd by appcndmg some predicate h = J. to the body of each rule, whcrc h 1s some hash 
function, and 1 1s the idcntilicdtion of some processor The function h gets as argu- mLnt\ ,I subset 
or the vdndblcs m the rcldtlonal cxpresslon, and it ni,~ps cdch msldntldtion of the vmldbles mto a umque 
processor of the set of processors {PO, ,pkml J The next p aragraph motivates this postulate Consldcr 
the rclatlonal algebra expression (1) of Example 1 Assume that the optimal way of Jommg s and A on a 
smgle pro- ccssor 1s by a nested loop, whcrc S 1s the outer relanon, and A IS the mner one, each block 
of s, in sequence, IS Jomed with the appropnatc blocks of A This 1s a hkely situation, consldermg that 
A will probably have an index on the column z, whereas S, con- structcd dynamically, ~111 probably not 
In order to dlvlde the work between two processors we can use a hash function (eg x mod 2) that maps 
each x-value mto either pa or p 1 Assume that the hash function maps half the x-values m S to po, and 
the other half to p 1, and the dlstnbutlon of S-facts among the x-values 1s uniform Then the computation 
tune 1s clearly spht m half Suppose now that a smgle processor evaluation method 1s parallehzed by parallehzmg 
each JOT opcrabon as explamed above (and possibly other relatlonal algebra operations as well) This has 
two drawbacks First, the k processors must be synchron- ized at each JOI&#38; they all complete the computation 
of the JO in one iteration. exchange the newly generated tuples, and then begm the next lterabon Second, 
as shown m our previous works (e g [WS]), many tuples are transmltted unnecessanly among the pro- cessors 
However, the evaluation load can be partmoned without the negative side effects, by appendmg the hash 
functions to the rules from which the relanonal expressions are denved, rather than to the expressions 
themselves Then each processor evalu- ates the modified version of the program, obtamed m this fashion 
The hash function appended to each rule depends on the evalua- tion method (semi-naive, Henschen-Naqvl, 
or another (see [BR])), and on the access plan for computmg the relational algebra expression for the 
rule It 1s selected with the purpose of best dlvldmg the processmg load among the processors The questlon 
of how to achieve ths purpose algonthmlcally 1s outside the scope of tlus paper However, we use the semi-nave 
evaluation method for demonstratmg our ideas A vanant of data reduction, named copy and constram , was 
proposed mdependently m the production-system literature ([SMM]), and its ment was demonstrated expenmentally 
usmg OPS5 ([PI) However, the Issues dlscussed III this paper have not been addressed previously In this 
paper, we first Introduce the paradigm for datalog programs without negation, and we discuss how it 1s 
speclahzed to a particular parallel algorithm Then we discuss some desirable properties of strategies 
These are smgle-source and smgle- destmatlon. which enable a lower cornmumcauon overhead For a given 
strategy, we present a sufficient condltlon for each one of these propeties Actually, the decomposablhty 
concept dlscussed [CW] 1s a combmatlon of the smgle-source and smgle-destmation properties Specifically, 
the decomposable programs are the ones for which there exist strategies that have both properties There-fore 
we ask whether these programs can be characterized algo- nthmlcally Unfortunately, we prove that it 1s 
undecidable to determme whether a program 1s decomposable We also pomt out that this result cannot be 
straght-forwardly obtamed from a Rice style theorem m [GMSV] Then we address the problem of load balancmg 
Particularly, we discuss changmg the data-reduction strategy wtilc the parallcl evaluation is m progress 
It turns out that this change of strategy can be performed more efficiently for a lmear program Fmally, 
we discuss how to extend the paradigm to programs with stratified negation The data-reduction paradigm 
for datalog without negation, does not require synchromzatlon among the processors However, the same 
paradigm requires syn- chromzauon when applied to programs with negahon It mdlcates that there 1s a relationstip, 
that we feel 1s fundamental m parallel computation, between monotomclty and synchromzatlon We also show 
that the smgIe source and destmatlon properties, when present, enable the ehmmahon of the need for synchronization 
The rest of the paper 1s orgamzed as follows In section 2 we mtroduce the termmology used throughout 
the paper, and m scctlon 3 we present the paradigm In section 4 we discuss the Vdrldbk of the paradigm 
that have to be fixed m order to obtam a parallel evaluation algorithm In section 5 we discuss one lmpor- 
tant vanable of the paradigm, that determines the overhead, namely the transmlsslon set of tuples, between 
processors In sec- tion 6 WC discuss the smgle-source and smgle-destmatlon proper- tics, and m section 
7 we prove the undecldablhty result In section 8 we address the problem of balancing the load by strategy 
change In secuon 9 we discuss the appllcatlon of the paradigm to datalog programs with stratified negation, 
m section 10 we con- clude, and m secuon 11 we discuss future work 2 Preliminaries In this section we 
define the basic termmology A lrteral IS a predicate symbol followed by a hst of arguments An atom 1s 
a literal with a constant or a vanable m each argument poslhon A constant 1s any natural number (The 
results m this paper are applicable to character strings as well, smce then bmary represen- tation 1s 
a natural number ) The other arguments of an atom are the vurrubks If an atom has a constant m each argument 
pon- tlon, then it IS a fact An R-atom 1s an atom having R as the prcdlcate symbol A rule consists of 
an atom designated as the head, and a conJunction of one or more atoms, designated as the body We assume 
that a rule 1s range restncted, 1 e , every van- able m the head of a rule also appears m the body of 
the rule A datalog program (see [MW]), or a program for short, 1s a finite set of rules whose predicate 
symbols arc dlvlded mto two dlqomt subsets the extensronul predicates. and the rntentlonul predicates 
The cxtcnslonal predicates arc dlstmgulshed by the fact that they do not appear m any head of a rule 
For a rule, r, an arithmetic predicate (see [BR]) of the form h(x,, ,x,1, where xl, ,x~ are dlstmct vanables. 
each of wluch appcdrs m r, 1s called a restrlctrng predicate For example, for a rule that has vanables 
x1 and x7, the predicate (x, +x,)mod 5 > 2 1s a restnctmg prcdlcate A restrrcted version, r , of a rule 
r, 1s obtamed by appending to the body of r a rcstnctmg prcdlcate A restncted version of a program, P, 
1s a collcctlon of rules that 1s obtamed by replacmg each rule of P by a rcstrictcd version of it We 
assume that only restncted versions of programs have anthmetlc predicates, programs do not The input 
I to a program P IS a finite set of R-facts, where R 1s some extensional prcdlcatc symbol Let Q be some 
mtentional prcdlcate m P Given some mput I, we define the Q-query, or the outputfor Q, and denote it 
0 (P,Q,I), lt IS the set of Q-facts that hdvc a denvatlon tree m P given I A derrvutron free for a fact, 
a, 1s a iimtc tree with the nodes labeled by facts, a 1s the root, the leaves arc facts m Z, and for 
each mtemal node, b, with children 01, , bk. there 1s an mstantlatlon of a rule of P that has b as the 
hcdd and b, , , bk, as the body, if r 1s a restricted version, then the mstantlatlon must sahsfy the 
restnctmg predicate The output of P 1s the muon of the outputs for all the mtentlonal predicates The 
set of mput and output facts 1s called the dufubuse of the pro- grdm P A prcdlcdte Q m a program P dwectly 
derrves a prcdlcate R if it occurs m the body of a rule whose head 1s a R-atom Q 1s recurswe If (Q,Q) 
1s m the nonrcflcxlvc transitive closure of the directly derives relabon Predicate Q derives predicate 
R d (Q,R) 1s m the reflexive transltlve closure of the due&#38;y derives relation (particularly, every 
predicate derives itself) A program 1s recursive d it has a recursive predicate 3 The Data-Reduction 
Paradigm We first describe the paradigm assuming that the database resides U-I a memory common to all 
the processors Then we con- sider the case m wluch there 1s no common memory Let P be a program with 
m rules, that we denote {r l, ,r,,,J Let {pa, ,pkSIJ be a set of k>l processors For each rule r,, we 
designate k restricting predicates, h,,(xl. ,x,,), for 0 5 J 5 k-l The arguments x1, ,x~, are the same 
for all the k predicates, and, by definition, all the arguments are variables of r, We require that for 
each mstantlatlon of the vanables xl, ,x,,, the predicate h,, 1s true for exactly one 1 Denote by r,, 
the restricted version of the rule r, havmg the resmctmg predicate h,,(xl, ,x,,) appended to its body 
Denote by P, the restncted version of P conslstmg of the set of rules {r,, I 1 < 1 S mJ The set {Pa, 
,P,-,J IS called a dcztu- reductron purullelrzutron strategy, or, for short, a purullelrzutron strategy 
for P For example, the set of restncted versions S (x,y) -S (x,z),A (z,y), (z +y ) mod k = J S(x,y)-A(x.y),O,+l)mod 
k=j for J = 0, ,k-1, constitutes a parallehzatlon strategy for the pro- gram of Example 1 The set of 
processors {po, ,pkvlJ cooperate m evaluating P m parallel as follows The processors start with a global 
data- base, residing m common memory, conslstmg of the mput Pro-cessor p, performs the mstanhatlons of 
the rules m the restncted version P, (1 e mstanuations that satisfy P, s restnctmg predl- cates) If the 
head of the mstanhated rule IS not m the database, but each one of the facts III the body 1s there, then 
the fact 111 the head IS added to the global database The mstantlatlons of p, can be performed by using 
any smgle-processor evaluauon method on P,, however, the method has to be adjusted, to account for addl- 
hons to the database made by other processors, not Just p, The parallel algonthm ends when none of the 
processors can perform an mstanuatlon of a rule 111 its resmcted version. such that a new fact 1s added 
to the database. Actually, the number of processors can be smaller than the number of resmcted versions, 
111 wluch case more than one restricted version 1s assigned to a processor T~s way the class of mstantlation-partitions 
can be extended For the sake of sunphclty, the discussion 1s restncted to the one- restncted-version-per-processorcase 
Now assume that the there 1s no global database, but a local one for each processor Assume further that 
the mput 1s either rephcated, or transmltted at the outset to all the processors The message-passmg,or 
shared-nothing variation of the data-reduction paradigm 1s as follows Each processor, p,, starts with 
the local database conslstmg of the input to the program, and performs the mstantlatlons of P, as before 
Processorp, transmits to each other processor,p,, the set of tuples that p, computes Actually, this set, 
denoted T,,, may be less than the whole set of tuples computed by p, This Issue 1s addressed m section 
5 The processor p, also receives from each other processor the set of tuples the latter com- puted This 
way common memory 1s sunulated The commumca- uon among the processors 1s totally asynchronous dunng the 
computation, and the only synchromzatlon requirement 1s rekcted m the termmatlon condltlon, specified 
below In other words, correctness of the paradigm 1s mdependent of the time (rclatlve to the computation 
of each processor) at which messages contauung tuplcs are sent and received by the processors The algorithm 
performed by processor p, 1s some vanatlon of the pro- ccdure below The procedure 1s executed iteratively, 
until the ter- mmatlon condltlon 1s satlslied DATA-REDUCTION 1 Add to the local database new tuples obtamed 
by mstantla- tlons of rules of restricted version P, 2 Transmit to some, or all, of the other processors 
the new tuples computed 3 Add to the local database new tuples obtamed by mstantla- tlons of rules of 
rcstncted version P, 4 Recclvc from some, or all, of the other processors new tuples and add them to 
the local database The termmatlon condltlon of the message-passmg para- dlgm IS the followmg no processor 
can generate any new tuples (1 c tuples that do not exist m the global database for the common memory 
architecture, or m the local database for the message passmg architecture), by mstantlatmg rules of 1t.s 
restncted ver- sion, also, there are no m transit tuples, 1 e , tuples that have been sent but not received 
We shall say more about the dlsm- butcd termmatlon protocol m the next section Denote by S the rclauon 
for mtcntlonal predicate S exlstmg at p,, when the ten- nation condmon 1s satisfied The output of the 
program for each mtentlonal prcdlcate, S, 1s 4 Speclalwng the Paradigm to an Algorithm Let P be a program 
In order to obtzun a parallel algorithm on k processors from the data-reduction paradigm, the followmg 
four paramctcrs have to be fixed the resmctmg predicates that dctermmc the strategy, the sets of tuples 
T,, transmitted among the processors (discussed III scctlon 5), the evaluation algorithm of each processor 
(mcludmg how it communicates with other proces- sors), and the distributed termmatlon protocol In ths 
sechon we discuss the last two parameters, startmg with the evaluation algo- rithm In this paper WC consider 
algonthms based on the semi- n,uvc cv iludtlon (see [Ran, Ray]) of each restnctcd version of a strategy 
In [CW] we discuss an evaluation algonthm for a single-rule progrdm. P, without constants Communication 
among thy processors 1s by message passmg Extended to an arbitrary datalog program, the algorithm PSNE 
executed by some proces- sor, p,, 1s given m Fig 1 We use Ullman s notation for the semi- naive evaluation 
algonthm UJI) EVA-L-INCR(S,,R,, ,RJ1, ,S,,,,AQ1, ,A&#38;,) 1s a function that computes the tuplcs of 
S, that can bc obtamed by the mstantla- tlons of rules, glvcn cxtcnslonal relations R 1, , Rk, mtentional 
relations S 1, ,Smr and differential relations PSNE for processor p, 1 for I =l to m do begm, 2 M, =EVAL(S,,RI, 
v&#38;,0, 1 a I* evaluation of resmcted version P, */ 3 s, =a, 4 end, 5 send from the AS, s the subset 
T,,, to each processor p., 6 repeat 7 forr =1 tomdo, 8 AQ, =AS,, /*save old AS s */ 9 for L =l to m do 
begm, 10 &#38;&#38;NCR (S RI, &#38;,Sl, +LAQ,, 3AQA /* evaluahon df restricted version P, */ 11 As, 
=A&#38;-s,, /*remove new tuples that actually appeared before*/ 12 end, 13 send from the AS, s the subset 
T,, , to each processor p., 14 for 1 =l to m do, 15 &#38;Y, t M, v {.$-facts received the other processors 
durrng the last rteratron), 16 s, =.5 VW, 17 end, 18 until AS,=0 for all i s, 19 Walt until termmatlon 
detection, or until some tuples are received from other processors, 20 if termmatlon detection, then 
output the P, s and quit 21 d tuples received, then add them to the S, s, mltlahze the AS, s to them, 
and go to r Figure 1 The parallel semi-nave evaluation algonthm, PSNE, consists of multiple procedures 
as above, one for each processor AQI~ v AQm Slmllarly for the function EVAL Steps 5, 13, 15, and 19-21, 
constitute the mo&#38;ficatlon to the well-known serial semi-nnve evaluation algonthm We shall denote 
by PSNE ths parallel version of semi-naive evaluation The algorithm PSNE can be seen as the followmg 
speclallzation of the data-reduchon paradigm In step 1 of paradigm, one lteratlon of semi-nave evaluation 
1s performed for the restncted version P,, m step 2, a subset of the newly computed tuples m step 1,1 
e of the dlfferen- tmls (A s) for all the mtentlonal predicates, are transmitted to all the other processors 
(whch subset, will be dlscussed m section 5), m step 3 no evaluation takes place, and m step 4, all the 
tuples received from other processors dunng the last iteration are added to the database, and to the 
dlfferenhals If at this pomt the dlffcrcntlals are empty, then processor p, waits until termination 1s 
dctccted, or some tuples are received Another vanabon of the paradigm 1s that m step 1. serm- naive evaluation 
1s performed until a (temporary) fix-point 1s reached Then data-reduction 1s continued as above The algo- 
rithm of Fig 1 1s modified as follows to reflect this vanation Step 5 1s removed, step 13, refemng to 
S, rather than AS,, IS moved to between steps 18 and 19, and step 15 1s removed St111another variation 
of the paradigm 1s to execute step 4 of the parddigm, namely mcorporation of tuples received from the 
other processors, only when a temporary fix-pomt IS reached The algorithm of Fig 1 1s modified to reflect 
this variation, by remov- mg Step 15 The above algonthms do not assume any synchronous operation of the 
network, or that messages, or tuples, are received m the order m wluch they are sent Another parameter 
to fix m order to turn the data-reduction paradigm mto a parallel algonthm 1s the distributed termination 
algorithm However, for tis purpose, one has only to select an algorithm from the many published m existmg 
htcrature ([CM, F, Ml, M2]) There, the dlstnbuted termmatlon problem 1s defined as follows Let po. ,pkml 
be a fimte set of processorsx commum-catmg by messages A processor 1s either &#38; or active Only dctlvc 
processors may send messages, a process may change from active to Idle at any hme, and a process may 
change from idle to active only upon receipt of a message The algonthms provided m the literature supenmpose 
a termination detection algorithm on the computation In our termmology, a processor 1s idle If It reaches 
a temporary fix-pomt, otherwise it 1s active A processor reaches a temporary fix-pomt if by mstannatmg 
rules of its restricted version of the program, new tuples, 1 e tuples that do not exist m the local 
database, cannot be generated 5 Transmission Sets The message-passmg version of the data-reduction para- 
digm transmits between processors more tuples than necessary In simulating common memory, there is no 
pomt m transmitting to some processor tuples that ~111 certainly be ehmmated by its res- tricting predicates 
To illustrate this, consider the the followmg Example 2 (contmued from the mtroductlon) Denote by h some 
hash function, h z + {0, ,k-1J Suppose that there are k pro- cessors, and each p, evaluates the program 
Pa S(y)-S(z),A(z.y),h(z)=r SO,)-A(a.y),h(y)=~ We shall make three observations about tlus example First, 
assume that the relation A has an mdex on the second atm-butt, S does not have an index, and the optunal 
way of Jouung S and A 1s by a nested loop, where S 1s the outer relation, and A 1s the mncr one Then 
partitionmg the work by the above strategy ~111 probdbly result m an optimal speedup, 1 e k Second, in 
a wide-area dlstnbuted envnonment. assume that the relation A (z,y) 1s honzontally partitioned on the 
first column, for example proces- sor L stores the tuplcs for which h(z)=6 Then, the requirement lhdt 
each processor has the whole input at the outset can be r&#38;xcd Thud, which dcmonstratcs the topic 
of tlus section, m order to ensure that cdch output tuple 1s computed by at least one processor, p, has 
to transmit to p, only the tuples S(y) that It com- putes, and for which h (y) = 1 0 Formally, given 
an mput I to a program P, we define the set of tuples T,,, that processor p, sends to p, Let S be an 
mtenhonal pre&#38;cate of the program P, and H a parallehzatlon strategy of it The set of S-facts transnutted 
from p, to p,, denoted ST,, consists of the mtersechon of two other sets, denoted SR, and SC, First we 
define the set SR, An S-fact, 5 IS m SR, If and only d (CondIhon K 1) there 1s some rule of the program 
P, say rg, such thatf 1s not m rs, but there 1s an mstantlation of it that satisfies the predicate hs,, 
and f appears m the body of the mstantiated rule In other words, a tupIe f 1s m SR,. d there 1s an mstantiation 
for wluch p, IS III charge, that uses f Determmm g whether a given fact 1s m SR, can be done m constant 
tune, under the following assumptions (1) The size of the program 1s constant (thu assumphon 1s also 
made m other works, e g [UV]) (2) For any restnctmg predicate h,,(xl, ,x,,), It can be determmed m constant 
time, for any mstantiation of any subset of the x, s, whether or not the rest of them can be mstantlated 
by constants, such that the predicate 1s true  Next we define the set SC, In contrast to the set SR,, 
the set SC, does depend on the input Intuitively, it 1s the set of facts com- puted by processor p, Formally, 
a productrve mstantlation of a rule at processor p, 1s an mstantlabon for which, when performed by p,, 
the head 1s not m the database at p,, but all the facts m the body are there A fact 1s computed by p, 
d It 1s m the head of a productive mstantlatlon Note that the same fact may be com- puted by more than 
one processor Furthermore, it may be com- puted, and later received from another processor Let SC, be 
the set of S-facts computed by p, Then ST,), the S-transmrssron set from t to], IS SR, n SC, We define 
T,, = v ST,, S IS on mlenkmlpndwte The set T,, 1s called the trammlssron set fromp, top, Observe that 
the defimtlon of T,, requires that each proces- sor, p,, knows the whole strategy, not only its own restricted 
ver- sion Furthermore, note that the T,, s are not necessanly disjoint For example, if m the body of 
some rule of P appears the atom S(y), and d the vanable y 1s not an argument of a restnctmg pre&#38;- 
cate, then any processor that computes a fact, S(a), must transmit it to all the other processors Moreover, 
it 1s possible that S (a) 1s computed by more than one processor (Optunizafion 01) An algorithm based 
on the data- reduction paradigm may perform the followmg optunizatlon, to send less than the whole set 
T,, It may elunmate a fact. j from T,,, If it was received at p,, before the latter transmitted f to 
p, In other words, it 1s possible thatp, has computedf, mcluded It m T,,, but has not performed the actual 
transnusslon (a possible reason 1s that It wnted to fill up a buffer) If at this point f 1s being received 
at p,, then f can be ehmmatcd from T,, The reason this optimlza- tlon does not violate corrcctncss 1s 
that the processor that sent f to p, must have also sent it top, 6 Unique Source and Destmatlon PropertIes 
Let P bc a program, and {pO, ,&#38;l] a set of processors, for some ptiallchzatlon strategies for P, 
each possible tuple of an mtcntlonal relation, S, 1s transmitted to a unique-processor Ths IS a desnablc 
situation, since it reduces commumcatlon among the processors Formally, the parallehzatlon strategy H 
has the unrque destrnatron property with respect to the mtenhonal predicate S, if each S-fact belongs 
to a umque SA,, This means that each S-fact, f, 1s transmitted to only one processor, by any processor 
that com- putes f For example, the strategy S(X,Y)-~Pr(x,z),S(z,~),DO~N,(w,y),(z+w)modk=~ S(x,y) -~~z(x,z),S(z,w).~O~N2(w,y),(z+w) 
mod k =J S(x.y)-FLAT(x.y),xmodk=~ has the unique destmatlon property with respect to S For mstance, assuming 
that there are three processors, {pe,p 1 ,p,J, the tuple S (5,3) 1s only transmitted top 2 Now consider 
the strategy ldenh- cal with the one above, except that the restnctmg predicates of the second rule are 
x mod k = 1 This strategy does not have the unique destmatlon property When does a parallehzatlon strategy 
have the unique destl- nation property? This question 1s important because It should be taken mto conslderatlon 
m selectmg one, from several candldate parallehzatlon strateglcs by which to evaluate P Theorem 1 Let 
P be a program, and let H = {PO, ,PkvlJ be some parallehzatlon strategy of P The strategy H has the unique 
destmatlon property W&#38;I respect to intentional predicate S, d there is a set of argument positions 
t 1, ,f, of the predicate S. such that (1) if SO 1s an S-atom m the body of some rule, r,, of P, then 
 the variables denoted x1. ,x6, I e , the arguments of the rcstnctmg prcdlcates h,,, appear m positions 
t 1, ,t, of S,,, respectively (and consequently v = qr) (2) if r, and r, arc two rules of P that have 
an S-atom m the body, then for every sequence of constants, a,, ,a,, and for every m, h,(al, ,uJ IS true 
d and only If  h,&#38;l. .h)s me [I Another unportant property of a strategy 1s the unique-source pro- 
pcrty It ensures that any S-fact, f, 1s transmitted from (rather than to) a umque processor Agam, this 
property reduces commumca- tlon Formally the parallchzatlon strategy H has the unrque- source property 
with respect to the mtentlonal predicate S, If each S-fact, fi can belong to a umque CT,, In other words, 
if fls m the output of the program P, then it 1s computed by the processor P,~, and only by this processor 
For example, the strategy s(x,y) -UP~(x,z),S(z,w),DOWNl(w,y),x mod k = J s(x,y) -UP~(x,z),S(x,w),DOWN~(w,y),x 
mod k = J S (x,y) -FLAT(x,y),x mod k = J hds the unique source property with respect to S Consider the 
strategy ldcntlcal with the one above, except that the restnctmg prcdlcatcs of the second rule, are z 
mod k = J This strategy does not have the unique source property The next theorem, glvmg a sufficient 
condltlon for a strategy to have the umquc-source pro- perty, 1s identical to Thcorcm 1, except that 
it refers to S-atoms m the head, rather than body, of rules Theorem 2: Let P be a program, and let H 
= {PO, ,P,-,J be some parallehzation strategy of P The strategy H has the unique source property with 
respect to mtentlonal predicate S, If there 1s a set of argument ponuons t 1, , t, of the pre&#38;cate 
S, such that (1) d SO 1s an S-atom m the head of some rule, r,, of P, then the variables denoted x1, 
,x,,, 1 e , the arguments of the restnctmg predicates h,,. appear m poslhons t,, ,t, of Se, respectively 
(and consequently v = q,) (2) If r, and r, are two rules of P that have an S-atom m the head, then for 
every sequence of constants, al, ,q, and for every m, h,(al, ,u,J 1s true d and only If  b&#38;l n .dls~e 
[I Assume that a strategy has both, the umque source and des- tmatlon properhes with respect some mtenuonal 
predicate. S. and furthermore the source and destmatlon corncrde, I e are the same processor, for each 
S-fact Then each S-fact 1s produced durmg the evaluation by a umque processor, and no S-fact has to be 
transmit- ted among the processors 7. Decomposable Programs For some programs there exists a strategy 
that has a com- cldmg source and destination property for m mtentlonal predl- cate of the program Such 
programs are called decomposable The processors cooperatmg m the evaluation of a decomposable program 
do not have to transmit any tuples, and the output pro- duced by each processor IS dlsjomt from the output 
of each other processor The advantage of commumcauon-freedom 1s obvious, and output-dlsJomtness implies 
that two processors do not duph- cate the effort of producmg the same fact, this IS appealmg smce It 
means that work-parbtionmg 1s abstracted, mdependently of Implementanon details, such as the mner and 
outer relations of a nested loop Join For example, the followmg parallehzatlon stra- tegy for computmg 
the transltlve closure (a decomposable pro- gram) has the commumcatlon-freedom and output-dlsjomtness 
advantages s(x,y)-S(x,z),A(z,y),xmodk=j S (x,y) -A (x,y ), x mod k= J The data-reduction paradigm 1s 
a syntactic concept How-ever, as we shall show, decomposablhty 1s a semantic property, and m this section 
we study it m this way Specifically, we ask the followmg question Can we algorlthmlcally Iden@ the programs 
for which there 1s a parallel evaluation method (whether or not a speclahzation of the data-reduction 
paradigm) that sahsfies the above condlhons, namely, work dlsjomtness, and commumcatlon freedom In [CW] 
we have taken this semantic approach, defined the decomposablhty property and provided necessary and 
sufficient condltlons for decomposability of a smgle-rule program These condlhons can bc checked algonthmlcally 
In this sectlon we first extend the decomposablhty de&#38;non to arbitrary datalog programs, thu 1s necessary 
since m [CW] the defimtlon was res- tncted to single-rule-programs Then we ask whether there exists an 
algorithm that determmes whether or not an arbitrary program 1s decomposable, and answer negatively We 
start with some prehmmanes, that pave the way to the decomposablhty defimtlon A program 1s Q-mmrmal d 
every predicate m the program denves Q We shall assume without loss of generality that when evaluatmg 
a Q-query, the program IS Q- mmnnal, otherwise rules can be omltted from the program, for answcrmg the 
Q-query Let P be a Q-mwmal program, for some mtentlonal predicate Q The output domarn of P, denoted 0, 
1s the set of all R-facts, for all mtentlonal predicates, R In other words, the output domam IS the mfirute 
set ( R@J 1 R IS an mten- tlonal predicate, and$tls a sequence of constants ) A set of two or more sets, 
Ml, ,k$. , IS a Q-partrtron of the output domam of P, If the followmg requirements are satisfied 1 the 
M, s are prurwise disJomt, and 2 each M, contams at least one Q-atom (otherwlse the member 1s useless 
for the evaluation of a Q-query), and 3 each Q-fact m the output domam belongs to some M, Let D be a 
Q-partition of the output domam for the program P, and let M, be a member of D A Q-fact, g, m M, IS proper, 
d for every mput I such that g 1s m the output 0 (P,Q,I), the fact g has a dcnvatlon tree m which all 
the mtentlonal-facts are m M, In other words, assume that each processor assumes responslblhty for pro- 
ducmg the Q-facts belongmg to one or more members of D Tlcn, for denvmg a proper Q-fact, a processor 
does not need to rccelvc facts derived derived by other processors, regardless of the mput The program 
P IS Q-decomposable If It has a Q-partltlon for which every Q-fact m the output domam 1s proper Then, 
the set D 1s called an ellgrble Q -partbtlon of P For example, consider the program P 1 below Q (x,Y,z) 
-Q (x.Y,w), A 0~) Q(x,y,z) -Rty.x,z) R (x.y,z) -A (x,y,w), 13 (WJ) R(x,y,z) -C(x,y,z) The program 1s 
Q-decomposable One example of an ehglble Q- partltlon 1s the followmg Ml consists of the Q- and R- facts 
m which the sum of the constants m the first two posmons 1s odd, and Mz consists of the ones m which 
the sum 1s even Actually, the program P 1 has an miimte Q-partltlon M1 consists of the facts m whch the 
sum 1s 1, Mz consists of the facts m which the sum 1s 2, etc When the program has a smgle mtentlonal 
predl- catc, It 1s easy to see that the decomposablhty defimnon above reduces to the defimtlon m [CW] 
Decomposable programs are also mterestmg for sequentd processmg Once a fixpomt 1s reached w&#38;m a member 
of the partition, all the facts of the member can be removed from the mtentlonal rclatlons, reducing 
their sizes for further processmg For example, consider the program Pl above If at some iteration of 
scml-muvc evaluation, the differential does not contam any intentional facts m which the sum of the first 
two posltlons 1s 3, (but prior iterations it did), then all such facts can be removed from the mtcntlonal 
relations, rcducmg their size for further ltera- tions WC prove that for an arbitrary datalog program, 
P, and a predicate Q of P, the problem of determmmg Q-decomposablhty of P 1s rccurslvely unsolvable Fust. 
let us pomt out that the result cannot bc obtained tnvlally from [GMSV, Theorem 81 That result IS d Rice 
style thcorcm, that imphes that many mterestmg propcr- ties of datalog programs arc undecidable Spcclfically. 
theorem 8 m [GMSV] states that any scmantlc property that contams bound- Ldncs\, dnd IS strongly nontnvlal 
IS undccldable A property 7~ contams boundedness If every bounded program has the property x However, 
decomposablhty does not contam boundedness In fact, there are nonrecurslve programs that are not decomposable 
For proof we will show that the followmg nonrecurslve program, P 2,~ not decomposable Qky)-E(x,w), R(w,v), 
F(v.y) R(x.Y)-G(x,y) Assume, by way of contradlctlon, that P 2 1s Q-decomposable, and consider two members, 
M, and M,. of an ehglble Q-parhtlon Observe that, smce every member of the Q-partmon contams a Q-fact, 
every member must also contam an R-fact Let Q (a, b) be m M,, and R (c,d) be m kf, Then Q (a,b) 1s not 
proper, smce for the mput (E(a,c),G(c,d),F(d,b)) the fact Q(a,b) has a single denvatlon tree, and R (c,d). 
a fact m this tree, 1s not m M, In [WS] we have shown that every nonrecurslve smgle-rule program (a program 
with one mtenhonal predicate and two nonre- cursive rules). 1s decomposable Actually, a program with 
an arbl- trary number of rules 1s decomposable, provided that It has a sm- gle intentional predicate 
However, the program P2 above has two Theorem 3: The problem of dete rmmng whether a given pro- gram 
1s Q-decomposable, 1s recursively unsolvable Proof idea The theorem 1s proven by a reduction from the 
prob- lem of determmmg equivalence of two datalog programs, shown undecidable m [S] Given two programs, 
P, and P2, we construct a thud, P, that has a new predicate. Q, such that P IS Q- decomposable, d and 
only d P 1 and P, are equivalent [] The negative result 111 this secbon 1s cushioned by a sufficient 
condlhon for decomposablhty, dxscussed m [WS] There we defined a syntactic condltlon, called prvotrng, 
that 1s sufficient for a program to be decomposable 8 Load Balancing In the exposlhon so far, we assumed 
a fixed set of restnct- mg predicates, determmmg a pnon the restncted version executed by each processor 
Clearly, even the best functions will fall to evenly balance the load for some mputs Then load balancmg 
has to occur We shall not discuss the problem of determmmg when to balance the load, but only how to 
do so The way we propose 1s for some processor, p,. to change the parallehzatlon strategy used, m order 
to balance the load Presumably, p, 1s a processor that 1s Idle for more than some prespeclfied amount 
of hme Or, p, knows that there are Idle processors, although p, Itself 1s not Idle How should the strategy 
be changed? We suggest the followmg protocol There IS a processor, e g po, designated as the leader , 
at the outset When some processor decides to change the paralleh- zatlon strategy, it selects the set 
of restnctmg predicates of the new strategy (possibly the next set 111 a list of candldate stra- tegies), 
and sends this set to the leader, requestmg a change The purpose of this step 1s for the leader to be 
able to select a single 1 A program IS bounded If, for each query predxate. tt produces the same output 
as a nonrecurwc program, g*ven the same Input successful processor If multiple processors are sunultaneously 
attempting a strategy-change, each with a dfferent set of restnct- mg predicates Before changing a strategy, 
X, the leader verifies two thmgs First, that all the processors have received X, and second, that at 
least one processor has generated new tuples using X The purpose of the first venficatlon 1s to ensure 
that when the algorithm ends, all the processors use the same strategy, this m turn ensures completeness 
The purpose of the second venficatlon 1s to prevent an miimte loop of strategy-changes, without makmg 
any progress m the computahon of the output Only after the two venficatlons complete posltlvely, the 
leader sends the new strategy to each processor When a processor, p,. receives a new restncted version 
from the leader, It transmits from its local database, to each other processor, pm. the subset that satisfies 
condition Kl (see definition m section 5), accordmg to the new strategy Then, p, sunply proceeds with 
its computation usmg the new restricted version The PSNE algorithm of Fig 1 IS adapted to change the 
strategy dynamically, by addmg the followmg step between steps 6 and 7 6 1) if a new strategy 1s requested, 
then send to each processor, pm, from each one of the mtentlonal relations S. the subset that 1s also 
m SR, (defined accordmg to the new strategy), then change the restnctmg predicates accordmg to the new 
strategy In the full paper we demonstrate the strategy-change pro- ccdure, and prove that it 1s correct, 
namely that no output 1s lost Assume now that the program bemg evaluated m parallel 1s Smear, namely 
a program with at most one mtentlonal predicate m the body of each rule Then we can apply the followmg 
optmuzatlon of the land balancmg scheme At step 6 1 of the PSNE algorithm,, p, should trdnsmlt to each 
other processor, pn, only a subset of the fdLts it transmits m the general case For each intentional 
predl- cute S, it 1s the subset of the last differential, AS, (mstead of all the S-facts m the current 
database) that satisfies condltlon Kl accord-mg to the new strategy Note that this reduction m the size 
of T,, has two posltlve effects Fwt, it reduces the number of tuples transmitted among processors Second, 
it reduces the amount of work performed by the receiving processor, pn, nnce the size of both, the dlfferentlal 
AS, and the relation S, shrmks In the full paper we prove the correctness of the optunizatlon for lmear 
pro- grams, and we demonstrate that It 1s mcorrect if the program 1s not linear 9 Extension to Datalog 
wltll Negation In this sLctlon, WC discuss the apphcatlon of parallel algo- nthms based on datd-reduction, 
to datalog programs for which the rules are defined as before, except that some of the atoms m the body 
of a rule may be negated We shall assume safe negation, namely that each variable m a negated atom also 
appears m a non-negated atom m the body of the same rule Furthermore, we shall assume that the programs 
are strahfied (see [ABW]) Thus means that there 1s no path m the dependency graph from R to Q, if there 
1s a rule whose head 1s an R-atom, and a negated Q-atom appears m 1t.s body (namely - Q defines R) Such 
a program has a 1 A graph that has the predxate symbols as the nodes, and an arc S + T for each pax S. 
T such that there IS a rule whose head IS a T-atom, and an S-atom appears m Its body stratlficatlon, 
1 e a nonnegative numbermg of the premcate sym- bols, such that If S 1s defined by -T. then T has a lower 
number than S. and If S 1s defined by T, then T has a lower or equal number than S The output of such 
a program 1s defined as the set of tuples obtamed by evaluatmg the strata one by one, m mcreas- mg order, 
usmg the complement of a relation S as the set of facts m the database, for the atom -S appearmg m the 
body of some rule A data-reduction algonthm of the type discussed m the pre- vlous sectlons, can be used 
for the evaluation of each stratum Therefore, a parallelization strategy for a program with t strata 
consists of t parallellzatlon strategies each one evaluated by k processors Suppose that mtenhonal predicate 
S 1s at stratum b At the completion of the evaluation of stratum b, each processor, p, transmits to all 
the other processors, the S-facts that are m p, s database, assummg that the atom S appears (possibly 
negated) m higher strata Actually, p, does not have to wait until the comple- tion of stratum evaluation, 
but can transmit the S-facts as they are evaluated by p, Furthermore, only a tuple, f, that satisfies 
the fol- lowmg condition should be transmltted top, Condrtron (KIN) There 1s some rule, rs, whose head 
1s at stratum b or hgher, such that f IS not 111 rs, but there 1s an mstan- hatlon that satisfies the 
predicate he,, and f appears, possibly negated, m the body of the mstanfiated rule Therefore, the transmlsslon 
sets are defined m terms of the currently evaluated stratum, as well as tigher ones Now suppose that 
mtentional predicate S appears negated at stratum s, and the stratum of S 1s u, u < s Then a processor, 
p,, cannot start the evaluation of stratum s before all the processors have completed the evaluation 
of stratum u, otherwise, facts It computes may be mvahdated by S-facts received later In other words, 
there are Inputs, and relative computahon speeds (and commumcation delays), for whch mvahdatlon of tuples 
may occur Therefore, m general, the processors have to be synchron- ized at each stratum Synchromzahon 
means that each processor has to wait unbl all the processors have completed their evalua- tion. and 
there are no tuples m transit , before proceedmg to the next stratum However, thus 1s not always necessary 
For example, con- sider the followmg strategy for parallehzation of the program that computes 111 S the 
translbve closure of A. and m T the tuples of the transitive closure of B, that are not 111 S T(x,Y)-T(x,z),B(z,y), 
-S(x,y),xmodk=~ Tky)-Bky), -S(x,y),xmodk=j s (KY) - S (x,z),A (z,y), x mod k = J S(x,y)-A(x,y), xmod 
k=J for I= 0, ,k-1 In this case there 1s no tuple that has to be transmitted among the processors, and 
m particular the processors do not have to be synchronized at the begmnmg of each stratum evaluation 
A way of lookmg at thn, 1s that the only S-facts that can mvahdate T-facts computed by some processor, 
p,. are S- facts that are also computed byp, In general, it IS possible that for a parallehzatlon strategy, 
the processors have to be synchromzed at the begmnmg of the evaluahon of some, but not all, of the strata 
of a program Such strata are called synchronous, m contrast to others, that are asyn- chronous (Actually, 
It 1s possible that for a parallehzatlon strategy, a stratum 1s asynchronous for some processors, but 
not for others However, for the sake of sunpllclty, we omit ths subtlety from the present dlscusslon 
) For example, If to the stra- tegy above we add the rules for J=o, , k -1, then the third stratum 1s 
synchronous A sufficient condmon for a stratum to be asynchronous 1s the followmg Let P be a program, 
and let H be a parallehzatlon strategy for the evaluation of P Let s be a stratum, and denote by Sit 
, S, the mtentlonal predicates that appear negated at stra- tum s Denote by G the set that consists of 
S,, ,S,,,, and the mtentlonal predicates that derive any of the S, s Denote by t be the highest stratum 
below s. that 1s synchronous, or, if there 1s none, then t = 0 Disregard any rules of the strategy that 
define predicates at a stratum hgher than s, and examme the followmg If each mtentlonal predicate that 
1s m G, and 1s at a stratum bctwecn I and s-l, has a comcldmg unique source and destmatlon properly, 
then s is asynchronous 10 Conclusion In this paper we introduced the data-reduction paradigm for evaluatmg 
datalog programs m parallel It consists of the evalua- tion of a parallelization strategy, i e a partmon 
of the rule- mstantlatlons, such that each processor performs the mstanhatlons m a partition member, 
and adds the newly generated tuples to a common database The common database may be simulated by messdge 
passmg We proposed a protocol for dynamic changmg of strategies dcnved from the paradigm This 1s requved 
for load balancmg For scml-nave evaluation of a lmear program, load balancing can be pcrformcd more efficlcntly, 
smce it IS necessary to redlstnbute only the dlffercntlals, rather than the whole output produced so 
fdr We also dlscussed the extension of the results to datalog programs with stratified negation The asynchronous 
mode of pardllcl computation 1s not guarmteed when the paddlgm 1s extended to this type of programs Some 
strata may bc synchronous, i e require synchronization of the processors, before the evaluation begins 
Others may be asynchronous It turns out that the synchrony of a stratum 1s related to two other unportant 
propcrtics of parallellzation strategies, namely unique source and dcstmatlon They enable a lower commumcahon 
over- head for programs with and without negation, and we provided a sufficient condltlon for each property 
Programs for which there 1s a parall&#38;Ldtlon strategy that has both properties are called dccomposdblc, 
and WC have shown that it 1s undecidable to dcter- mme whether or not a program 1s decomposable 11 Future 
work WC mtcnd to contmue the cxplordtion of the d&#38;d-reduction pdrddlgm, and will concentrate m the 
munedlate future on dlstn- butcd environments The mam devlatlon from our model 1s that m such an environment 
it may not practical to assume that all proces- sors have dcccss to the whole mput However, as we have 
pomtcd out m example 2 at the begmnmg of section 5, this only means that an addmona conslderatlon, 1 
e the fact that the whole data- base may not be accessible locally, contributes to the selection of the 
restrlctmg predicates Spcclfically, we mtend to apply the data-reduction para- digm to rule-processmg 
m databases for network management Net-mate, a project currently under development at Columbia Umverslty 
(see [SDSWY]), suns to develop a software envlron- ment for management of very large (hundreds of thousands 
of mterconnected computers) commumcation networks A fault m such a network IS a falure or an overload 
condltlon, and an lmpor- tant goal m network management IS to automaucally detect and recover from this 
condltlon Rule based programmmg can be employed to attam ths goal, but two factors combme to comph- cate 
this approach First 1s that detection of the fault may reqmre the analysis of very large amounts of statistical 
and configuration data, and second 1s that this data 1s usually dlstnbuted One solu- tion 1s to transmit 
the data, and analyze it 111 a central location However, this would place an unacceptable commumcatlon 
load on the network, and an unacceptable computation load on the sm- gle processor Another solution 1s 
to run a rule based program at muluple processors m the network, with each analyzmg the data produced 
locally However, m this approach, the global view that 1s often required for proper fault detection, 
1s lost The right solu- tion seems to reqmre one rule program that has access to the data m the whole 
network For the rule programmer, this will hide the complexity mtroduced by dlstnbuuon, and enable conceptuahza- 
uon of the fault detecbon problem as bemg centralized However, for performance reasons, the program should 
be processed at many processors m the network, while mmumzmg commumca- bon overhead Data-reducbon satisfies 
these requirements per- fectly It speeds up the evaluation of a rule-based program by usmg multiple processors 
(the nodes m the network), each work- mg on a different subset of the database (the data stored locally 
at the node), while mnumlzmg the reqmred commumcatlon among the processors Data-reduction should also 
prove helpful m the dlstnbuted processmg of triggers For example, assume that the network- configuration 
database 1s partitioned among many processors m the network, and consider the followmg trigger d the 
delay on 20% of the commumcatlon lmes exceeds 5 seconds, then execute a certam alarm Contmuously collecting 
the tuples representmg the lmes that sat&#38;y the condltlon, would place an unacceptable commumcatlon 
and computation load Processmg of the trigger under the data-reduction paradigm will hopefully consist 
of local trigger-evaluation (counting the number of culpnts stored m the processor), with mmunal commurucatlon 
among the processors (transmlsslon of the count rather than the tuples) Fmally, we mtcnd to study the 
enhancement of the data- reduction paradigm with some mterestmg parallehzatlon ideas that appeared m 
the lltcraturc ([AJ, D, HAC, R, RSL, VK]) 12 References K R Apt, H Blan, A Walker Towards a Theory of 
Declarative Knowledge, unpublished memorandum, IBM Yorktown Heights, NY [AJI R Agrawal and H V Jagadlsh, 
Multiprocessor Transitive Closure algonthms , Proc International Symposium on Databases m Distributed 
and Parallel Systems, Austm TX, Dee 1989 . [Al 1 [Ban1 [WI [BBDW] WI KKI VW KW ID1 PLI iFI PST1 [GMSV] 
WAC1 [Kl F Afratl and C H Papadunltnou The Parallel Com- plexity of Simple Cham Quencs . Proc 6th ACM 
Symp on PODS, pp 210-213,1987 F Bancllhon Naive Evaluation of Recursively Defined Relations , m On Knowledge 
Base Manage- ment Systems - Integrated Database and AI Systems, Brodle and Mylopoulos, Eds , Sprmger-Verlag 
R Bayer, Query Evaluation and Recursion m Deductive Database Systems , unpublished manuscript, 1985 D 
BItton, H Boral, D J DeWltt and W K Wllkmson, Parallel Algonthms for the Execution of Relahonal Database 
Operations , ACM TODS, 8(3), 1983 F Bancllhon and R Ramaknshnan Performance Evaluation of Data Intcnslve 
Logic Programs m Foundations of Deductive Databases and Logic Pro- grammmg, Ed J Mmker, Morgan-Kaufman, 
1988 S S Cosmadakls and P C Kanellakls Parallel Evaluation of Recursive Rule Queries , Proc 5th ACM Symp 
on PODS, pp 280-293,1986 K M Chandy and J Mlsra On Proofs of Dlstnbuted Algonthms with Apphcatlon to 
the problem of Ternu- nation Detection , Manuscript, Dept of CS, Umver- slty of Texas S Cohen and 0 Wolfson, 
Why a Smgle Parallehza- tlon Strategy 1s not Enough m Knowledge Bases, Proc 8th ACM Symp on PODS, pp 
200-216, 1989 Also, mvlted and submitted for publication m a spe- cial Issue of the Journal of Computer 
and Systems Sciences G Dong, On Dlsmbuted Processlblhty of Logic Pro- grams by Dccomposmg Databases , 
Proc ACM- SIGMOD conf, 1989 D DeGroot and G Lmdstrom eds Logic Program- mmg - Functions Relations and 
Equations , Prentice Hall, 1986 N Francez, Dlstnbuted Termmatlon , ACM Trun- sactlons on Programmrng 
Languages and Systems, 2(l), pp 42-55, 1980 S Ganguly, A Sllberschatz, S Tsur, A Framework for the Parallel 
Processing of Queries , Manuscript, Comp Scl Dept , Umv of Texas at Austm, 1989 H Gdifmdn, H Malrson, 
Y Saglv, M Y Vardl, Undecldablc Optunlzatlon Problems for Database Log16 Programs. IBM Tcchmcal Report 
RJ 5583 (56702) 4/3/87 M W Houtsma, P M G Apcrs, and S Cen, Paral- lcl Computation of Transltlve Closure 
Queries on Frdgmented Databases , Umverslty of Twente, TR INF-88-56, Dee 1988 P C Kanellakls Logic Programmmg 
and Parallel Complexity , Spnnger-Verlag Lecture Notes m CS Series, no 243, pp l-30, 1986 WV WI WI PI 
[RI tRSL1 PI WI [SDSWY] PMMI WI WV1 WI [WY WI D Maler and D S Warren Computmg with Logic Introduction 
to Logic Programmmg . Benjamm- Cummmgs Pubhshmg Co, 1987 F Mattem, Algonthms for Dlstnbuted Termmahon 
Detection , Dzstrlbuted Computrng, pp 161-175, 1987 F Mattem, Global Quiescence Detechon Based on Credit 
Dlstnbutlon and Recovery . to appear, Znfor- matron Processrng Letters A J Pas&#38;, A Methodology for 
Programmmg Pro- ductlon Systems and its Jmphcatlons on Parallelism , Ph D Thesis, Columbia Umverslty, 
1989 R Ramaknshnan, Parallelism 111 Logic Programs , Umv of Wlsconsm, Computer Sa Dept, TR #892, Nov 
89 L Raschld, T Selhs, and C C Lm, Exploltmg Con- currency m a DBMS Implementation of produchon Systems, 
Proc International Symposium on Data-bases m Dlsmbuted and Parallel Systems, Austm TX, Dee 1989 0 Shmueh 
 Decldablllty and Expressiveness Aspects of Logic Quenes, Proc 6th ACM Symp on PODS, pp 237-249,1987 
E Y Shapiro Concunent Prolog, Collected Papers , MlT Press, 1987 S Sengupta, A Dupuy, J Schwartz, 0 Wolfson, 
Y Yemm, The Net-mate Model for Network Management , m IEEE Network Operatrons and Management Symposrum. 
Feb 1990 S J Stolfo, D P Maanker and R Mills, A snnple pro- cessmg scheme to extract and load balance 
unphclt parallehsm m the concurrent match of produchon rules , In proc of the AFIPS symp on fifth genera- 
tlon computmg, AFIPS.1985 J D Ullrnan, Database and Knowledge-base Systems Volume l , computer Science 
Press, 1988 J D Ullman and A Van Gelder, Parallel Complexity of Logic Programs , TR STAN-CS-85-1089, 
Stanford University P Valdunez and S Khoshafian, Parallel evaluation of the Translnve Closure of a Database 
Relation , International Journal of Parallel Programmmg 17,1, Feb 1988 0 Wolfson and A Sllberschatz, 
Dlstnbuted Pro- cessmg of Logic Programs, Proc of the ACM- SIGMOD Conf , pp 329-336, 1988 0 Wolfson, 
Sharmg the Load of Logic Program Evaluation , F roc of the Intl Symp on Databases m Parallel and Dlstnbuted 
Systems, Austm, TX, Dee 1988
			
