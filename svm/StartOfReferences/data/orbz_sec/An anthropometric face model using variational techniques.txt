
 Copyright &#38;#169;1998 by the Association for Computing Machinery, Inc. Permission to make digital 
or hard copies of part or all of this work for personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. Copyrights for components of this work owned by others 
than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post 
on servers or to redistribute to lists, requires specific permission and/or a fee. An Anthropometric 
Face Model using Variational Techniques Douglas DeCarlo, Dimitris Metaxas and Matthew Stone Department 
of Computer and Information Science, University of Pennsylvania  fjjg dmd@gradient dnm@central matthew@linc.cis.upenn.edu 
Abstract anthropometric pro.le of a population characterize the distinctive features of a likely face 
in that population. We describe a system that automatically generates varied geomet-In the second step, 
our system constructs the best surface that ric models of human faces. A collection of random measurements 
satis.es the geometric constraints that a set of measurements im­of the face is generated according to 
anthropometric statistics for poses, using variational modeling [16, 31, 33]. Variational model­likely 
face measurements in a population. These measurements are ing is a framework for building surfaces by 
constrained optimiza­then treated as constraints on a parameterized surface. Variational tion; the output 
surface minimizes a measure of fairness, which in modeling is used to .nd a smooth surface that satis.es 
these con-our case formalizes how much the surface bends and stretches away straints while using a prototype 
shape as a reference. from the kind of shape that faces normally have. Having a fair­ ness measure is 
necessary, since the anthropometric measurements Keywords: face modeling, anthropometry, variational 
modeling, leave the resulting surface underdetermined. Bookstein [4] uses crowd generation this same 
fairness measure as a method of data interpolation for sparse biometric data, supporting its utility 
for determining the ge­ometry of an underdetermined biological shape. Variational mod­1 Introduction 
eling provides a powerful and elegant tool for capturing the com­ monalities in shape among faces along 
with the differences. Its use A hallmark of the diversity and individuality of the people we reduces 
the problem of generating face geometries into the problem encounter in daily life is the range of variation 
in the shape of of generating sets of anthropometric measurements. their faces. A simulation or animation 
that fails to reproduce this The remainder of the paper describes our techniques in more de­diversity 
whether by design or circumstance deprives its char-tail. We begin in Section 1.1 by introducing the 
problem of repre­acters of independent identities. To animate a bustling scene re-senting and specifying 
face geometry. In Section 2, we summarize alistically or to play out an extended virtual interaction 
believably the research from face anthropometry that we draw on; Section 3 requires hundreds of different 
facial geometries, maybe even a dis-describes how random measurements are generated from these re­tinct 
one for each person, as in real life. sults. In Section 4, we describe our use of variational techniques 
It is a monumental challenge to achieve such breadth with ex-to derive natural face geometries that satisfy 
anthropometric mea­isting modeling techniques. One possibility might be to use range surements. We .nish 
in Section 5 with illustrations of the output scanning technology. This involves all the complexities 
of casting of our system. extras for a .lm: with scanning, each new face must be found on a living subject. 
And although scanning permits detailed geometries 1.1 Background and related work to be extracted quickly, 
scanned data frequently includes artifacts that must be touched up by hand. Another alternative is manual 
Human face animation is a complex task requiring modeling and construction of face models, by deforming 
an existing model or rendering not only of face geometry, but also of distinctive facial having an artist 
design one from scratch; this tends to be slow and features (such as skin, hair, and tongue) and their 
motions. Most expensive. research in face modeling in computer graphics has addressed these This paper 
describes a new alternative: a system capable of auto­ latter problems [21, 23, 25, 26]. matically generating 
distinct, plausible face geometries. This sys-Research on human geometry itself falls into two camps, 
both tem constructs a face in two steps. The .rst step is the generation crucially dependent (in different 
ways) on human participation. of a random set of measurements that characterize the face. The The .rst 
approach is to extract geometry automatically from the form and values of these measurements are computed 
according to measurement of a live subject. Lee, et al. [21] use a range scan face anthropometry, the 
science dedicated to the measurement of of a subject, and produce a physics-based model capable of anima­the 
human face. Anthropometric studies like [11, 12] report statis­tion. Akimoto, et al. [1] use front and 
pro.le images of a subject tics on reliable differences in shape across faces within and across to produce 
a model. populations. Random measurements generated according to the The second approach is to facilitate 
manual speci.cation of new face geometry by a user. A certain facility is offered already by commercial 
modelers (though of course their use demands con­siderable artistic skill); several researchers have 
sought to provide higher levels of control. Parke [25] provides parameters which can control the face 
shape; and Magnenat-Thalmann, et al. [23] de­scribe a more comprehensive set of localized deformation 
param­eters. Patel [27] offers an alternative set of parameters similar in scope to [23] but more closely 
tied to the structure of the head. Di-Paola [8] uses a set of localized volumetric deformations, with 
a similar feel to [23] in their effects. Lewis [22] discusses the use of stochastic noise functions as 
a means of deforming natural objects (including faces). In this case, the control maintained by the user 
is limited to noise generation parameters. In contrast, we adopt a different approach: generating new 
face geometries automatically. More so than interactive methods, this approach depends on a precise mathematical 
description of pos­sible face geometries. Many conventional representations of face shape seem inadequate 
for this purpose. For example, the simple scaling parameters used by manual modeling techniques can perform 
useful effects like changing the width of the mouth or the height of the head; but they are unlikely 
to provide suf.cient generality to describe a wide sampling of face geometries. Meanwhile, for models 
based on principal components analysis (PCA) an alternative representation derived from work in face 
recognition [32] the opposite problem is likely. PCA describes a face shape as a weighted sum of an orthogonal 
basis of 3D shapes (called principal components). This basis is constructed from a large bank of examples 
that have been placed in mutual correspon­dence. (This correspondence is very much like that required 
for image morphing [3]; establishing it is a considerable task, but not one that has evaded automation 
[32].) PCA typically allows faces nearly identical to those in the bank to be accurately represented 
by weighting a truncated basis that only includes a few hundred of the most signi.cant components. However, 
because components are individually complex and com­bined simply by addition, alternative weightings 
could easily en­code implausible face shapes. Identifying which basis weights are reasonable is just 
the original problem (of characterizing possible faces) in a different guise. Bookstein [5] describes 
this problem in terms of latent variables, and notes that principal components of­ten bear little resemblance 
to the underlying interdependent struc­ture of biological forms. (In other words, it is quite dif.cult 
to extract non-linear dependencies between different shape aspects using a linear model like PCA.) At 
the same time, there is no guar­antee that faces considerably outside the example set will be ap­proximated 
well at all. We therefore adopt a representation of face shape based on con­strained optimization. The 
constraints generated as described in Section 3 are based on the anthropometric studies of the face of 
[11, 12, 20] described in the next section; we avoid the dif.culty of learning possible geometries since 
these studies identify the range of variation in real faces. The constraint optimization, as described 
in Section 4, is accomplished by variational surface modeling.  2 Face Anthropometry Anthropometry is 
the biological science of human body measure­ment. Anthropometric data informs a range of enterprises 
that de­pend on knowledge of the distribution of measurements across hu­man populations. For example, 
in human-factors analysis, a known range for human measurements can help guide the design of prod­ucts 
to .t most people [9]; in medicine, quantitative comparison of anthropometric data with patients measurements 
before and af­ter surgery furthers planning and assessment of plastic and recon­structive surgery [12]; 
in forensic anthropology, conjectures about likely measurements, derived from anthropometry, .gure in 
the de­termination of individuals appearance from their remains [12, 30]; and in the recovery of missing 
children, by aging their appearance taken from photographs [12]. This paper describes a similar use of 
anthropometry in the construction of face models for computer graphics applications.1 1An alternative 
source of such information might come from morpho­metrics [5], the study of the overall shape of biological 
forms, their devel­opment, and the interrelations of different aspects of their geometry. Mor­phometric 
analyses also provide detailed characterizations of the variability in the shape of faces. In order to 
develop useful statistics from anthropometric mea­surements, the measurements are made in a strictly 
de.ned way [19]. The rest of this section outlines one popular regime of such measurements and the information 
available from analyses of the resulting data. This provides an overview .rst of the anthropomet­ric 
structure that our model embodies and then of the statistical results our model exploits. Anthropometric 
evaluation begins with the identi.cation of par­ticular locations on a subject, called landmark points, 
de.ned in terms of visible or palpable features (skin or bone) on the sub­ject. A series of measurements 
between these landmarks is then taken using carefully speci.ed procedures and measuring instru­ments 
(such as calipers, levels and measuring tape). As a result, repeated measurements of the same individual 
(taken a few days apart) are very reliable, and measurements of different individuals can be successfully 
compared. Farkas [12] describes a widely used set of measurements for describing the human face. A large 
amount of anthropometric data using this system is available [11, 12]. The system uses a total of 47 
landmark points to describe the face; Figure 1 illustrates many of them. The landmarks are typically 
identi.ed by abbreviations of corresponding anatomical terms. For example, the inner corner of the eye 
is en for endocanthion, while the top of the .ap of cartilage (the tragus) in front of the ear is t for 
tragion. Two of the landmarks determine a canonical horizontal orienta­tion for the head. The horizontal 
plane is determined by the two lines (on either side of the head) connecting the landmark t to the landmark 
or (for orbitale), the lowest point of the eye socket on the skull. In measurement, anthropometrists 
actually align the head to this horizontal, in what is known as Frankfurt horizontal (FH) po­sition [12, 
20], so that measurements can be made easily and ac­curately with respect to this coordinate system. 
In addition to this, a vertical mid-line axis is de.ned by the landmarks n (for nasion), a skull feature 
roughly between the eyebrows; sn (for subnasale) the center point where the nose meets the upper lip; 
and gn (for gnathion), the lowest point on the chin. v . Figure 1: Anthropometric landmarks on the face 
[12] Farkas s inventory includes the .ve types of facial measure­ments described below and illustrated 
in Figure 2: . the shortest distance between two landmarks. An example is en-ex, the distance between 
the landmarks at the corners of the eye the axial distance between two landmarks the distance measured 
along one of the axes of the canonical coordinate system, with the head in FH position. An example is 
v-tr, the vertical distance (height difference) between the top of the head (v for vertex) and hairline 
(tr for trichion). the tangential distance between two landmarks the distance measured along a prescribed 
path on the surface of the face. An example is ch-t, the surface distance from the corner of the mouth 
(ch for cheilion) to the tragus. . the angle of inclination between two landmarks with respect to one 
of the canonical axes. An example is the inclination of the ear axis with respect to the vertical. the 
angle between locations, such as the mentocervical angle (the angle at the chin). We must represent measurements 
of each of these types to apply Farkas s anthropometry in creating models for graphics. Figure 2: Example 
anthropometric measurements [12] Farkas describes a total of 132 measurements on the face and head. Some 
of the measurements are paired, when there is a corre­sponding measurement on the left and right side 
of the face. Until recently, the measurement process could only be carried out by experienced anthropometrists 
by hand. However, recent work has investigated 3-D range scanners as an alternative to manual mea­surement 
[6, 12, 20]. Systematic collection of anthropometric measurements has made possible a variety of statistical 
investigations of groups of subjects. Subjects have been grouped on the basis of gender, race, age, attractiveness 
or the presence of a physical syndrome. Means and variances for the measurements within a group, tabu­lated 
in [12, 15], effectively provide a set of measurements which captures virtually all of the variation 
that can occur in the group. In addition to statistics on measurements, statistics on the pro­portions 
between measurements have also been derived. The de­scription of the human form by proportions goes back 
to D¨urer and da Vinci; anthropometrists have found that proportions give useful information about the 
correlations between features, and can serve as more reliable indicators of group membership than can 
simple measurements [11]. Many facial proportions have been found to show statistically signi.cant differences 
across population groups [19]. These proportions are averaged over a particular population group, and 
means and variances are provided in [11].  3 Generating measurements The rich descriptions of human 
geometry developed in anthropom­etry provide an invaluable resource for human modeling in com­puter graphics. 
This goes for artists as well as automatic systems: Parke and Waters [26] describe the importance of 
having a set of conformation guidelines for facial shape, which draw from artis­tic rules of face design. 
These guidelines provide qualitative in­formation about the shape and proportion of faces, respecting 
the quantitative information found in anthropometric measurements. In using such descriptions, automatic 
systems immediately con­front the problem of bringing a model into correspondence with a desired set 
of measurements. A widely-used approach is to de­sign a model whose degrees of freedom can be directly 
speci.ed by anthropometric measurements. For example, in the early visualiza­tion frameworks for human 
factors engineering surveyed in [9] where anthropometric data .rst .gured in graphics articulated humans 
were made to exhibit speci.ed body measurements by rigidly scaling each component of the articulation. 
Grosso, et al. [17] describe a similar model, but scale physical characteristics (such as mass) as well, 
to produce a model suitable for dynamic simulation and animation. Azuola [2] builds on Grosso s work, 
and generates random sets of (axis-aligned distance) measurements us­ing covariance information (but 
not proportions). The purpose of this generation is to produce a fairly small sampling of differently 
sized people for human factors analysis. Our work represents a departure in that we use anthropometric 
data to constrain the degrees of freedom of the model indirectly (as described in Section 4). This is 
a must for the diverse, abstract and interrelated measurements of face anthropometry. The .exibility 
of generating measurements as constraints offers additional bene.ts. In particular, it allows statistics 
about proportions to be taken into account as precisely as possible. This section describes how our system 
uses published facial measurement and proportion statistics [11, 12] to generate ran­dom sets of measurements. 
The generated measurements both re­spect a given population distribution, and thanks to the use of proportions 
produce a believable face. 3.1 The need for proportions Start with a given population, whose anthropometric 
measurements are tabulated for mean and standard deviation (we later use the measurements from [12]). 
We can assume that the measurements are given by a Gaussian normal distribution, as corroborated by sta­tistical 
tests on the raw data [12]. This gives a naive algorithm for deriving a set of measurements generate 
each measurement inde­pendently as if sampled from the normal distribution with its (es­timated) mean 
and variance. Such random values are easily com­puted [29]; then, given the constraint-based framework 
we use, a shape can be generated to .t the resulting suite of measurements as long as the measurements 
are geometrically consistent. Mere geometric consistency of measurements is no guarantee of the reasonable 
appearance of the resulting face shape, however. Anthropometric measurements are not independent. On 
the face, one striking illustration comes from the inclinations of the pro.le, which are highly intercorrelated. 
In the population described in [11], the inclinations to the front of the chin from under the nose (sn-pg) 
and from the lower lip (li-pg) take a wide range of values, but, despite the many curves in this part 
of the face, tend to agree very closely. Published proportions provide the best available resource to 
model correlations between measurements such as these. For ex­ample, [11] tabulates the mean and variance 
for statistically signi.­cant ratios between anthropometric measurements for a population of young North 
American Caucasian men and women. Given a cal­culated value for one measurement, the proportion allows 
the other measurement to be determined using a random value from the esti­mated distribution of the proportion. 
Since the proportion re.ects a correlation between these values, the resulting pair of measure­ments 
is more representative of the population than the two mea­surements would be if generated independently. 
With many measurements come many useful proportions, but each value will be calculated only once. We 
must .nd the propor­tions that provide the most evidence about the distribution. The next section describes 
the algorithm we use to do that. It assumes that proportions can be applied in either direction (by approximat­ing 
the distribution for the inverse proportion) and that we are gen­erating a set of measurements all of 
which are related by propor­tions. (We can split the measurements into groups before applying this algorithm.) 
The algorithm also assumes that we are given a .xed initial measurement (or measurements) in this set 
from which other measurements could be generated. If we are generating a ran­ dom face, the choice of 
which initial measurement to use is up in the most constrained features to determine the remaining features 
the air. We therefore .nd the best calculation scheme for each pos-via proportionality relationships. 
We can modify Prim s algorithm sible initial measurement, and then use the best of those. Random values 
for this initial measurement are generated by sampling its distribution. Thereafter, randomly generated 
proportions are used to generate the remaining dependent measurements. The same algorithm could also 
be used to .ll in measurements speci.ed by a user (as a rough guide of the kind of face needed) or selected 
to be representative of an extreme in the population (for use in human-factors analysis). In this case, 
the algorithm gives a way of generating a plausible, random variation on this given information.  3.2 
An algorithm for proportions Given base measurements, our goal is to .nd the best way to use an inventory 
of proportions to calculate dependent measurements. We can describe this problem more precisely by viewing 
measure­ments as vertices and proportions as edges in a graph. Figure 3(a) shows a portion of this graph, 
given the measurements and propor­tions from [11, 12] (some edge labels are omitted for the sake of readability). 
The presence of cycles in this graph exhibits the need to select proportions. A particular method for 
calculating measure­ments using proportions can be represented as a branching in this graph an acyclic 
directed graph in which each vertex has at most one incident edge. The edge e from s to d in this branching 
indi­cates that d is calculated by proportion e from s. By assumption, we will require this branching 
to span the graph (this means adding dummy edges connecting multiple base measurements). An exam­ple 
branching is illustrated in Figure 3(b), and contains a single base measurement (the vertex marked with 
a double circle). ex-ex / t-t n-sto / ex-ex (a) (b) Figure 3: Interpreting measurements and proportions 
as a graph (a); Example branching used to compute measurements (b) The algorithm associates each vertex 
v in the branching with a mean µv and variance s2 v . The variance is an indication of the precision 
of the statistical information applied in generating the measurement at v from given information. The 
smaller svµv, the hh more constrained the measurement. We take svµv as the weight of d. For base measurements, 
sv is simply the standard deviation of the measurement. Thereafter, if an edge connects s to d with a 
proportion with mean µe and standard deviation se, and s has mean µs and standard deviation ss, then 
the induced distribution at d is characterized by: µd µsµe s22s22s2 s2s2  e dd dµseµes es (This assumes 
proportions and measurements are independent and Gaussian.) Note that the weight of d is always larger 
than the weight of s this means the precision of the information concern­ing the distribution decreases 
as we go deeper into the branching. Our goal in selecting proportions is to derive a branching TM which 
assigns a minimum total weight to its vertices. This allows for minimum spanning tree to solve this problem. 
Our algorithm maintains a subtree T of some optimal branching. Initially, the subtree contains just the 
root for the initial measurement. At sub­sequent stages, each vertex is associated with the least weight 
in­duced by any edge running from the branching to it. The algorithm incorporates the vertex v whose 
weight is the least into the tree, by the appropriate new edge e. As with Prim s algorithm (c.f. [13]), 
the argument that this al­gorithm works ensures inductively that if T is a subtree of some optimal branching 
TM, then so is Te. If e is not an edge in TM, 0 d then TM contains some other directed path to v, ending 
with a dif­ferent edge e. This path starts at the root of T , so it must at some point leave T . Because 
e was chosen with minimum weight and weights increase along paths, in fact the path must leave T at e; 
since the algorithm chose e, e and einduce the same weight for v. 0 b i w 0 d 0 The inductive property 
is now established, sinceTMee is an optimal branching of which T is a subtree. 4 Variational Modeling 
Using the method outlined in Section 3, we generate complete sets of anthropometric measurements in Farkas 
s system. These con­straints describe the geometry of the face in great detail, but they by no means 
specify a unique geometry for the face surface. For example, Farkas s measurements are relatively silent 
about the dis­tribution of curvature over the face the particular measurement that speci.es the angle 
formed at the tip of the chin (the mentocer­vical angle; as in Figure 2), does not actually specify how 
sharply curved the chin is. What is needed then, intuitively, is a mecha­nism for generating a shape 
that shares the important properties of a typical face, as far as possible, but still respects a given 
set of an­thropometric measurements. This intuition allows the problem of building an anthropometric 
face model to be cast as a constrained optimization problem anthropometric measurements are treated as 
constraints, and the remainder of the face is determined by opti­mizing a surface objective function. 
This characterization allows us to apply variational modeling techniques [7, 16, 18, 24, 31, 33, 34]. 
This section brie.y introduces variational modeling, and de­scribes how we adapt existing variational 
modeling techniques to develop the anthropometric face model. Our approach to varia­tional modeling greatly 
resembles the framework in [33]; a key difference is that we perform most of the variational computation 
in advance and share results across different face generation runs. This amortization of computational 
cost makes it feasible to con­struct larger models subject to many constraints. However, it re­quires 
careful formulation of constraints and algorithms to exploit the constancy of the face model and its 
inventory of constraints. As described in Section 4.1, we begin by specifying a space of possible face 
geometries using a parametric surface suv, and b e w locating the landmark points on the surface. We 
use a B-spline surface [10] to represent s. This surface is speci.ed by a control mesh, where the mesh 
degrees of freedom are collected into a vec­tor p. A particular instantiation pof p provides a prototype 
shape, a reference geometry that epitomizes the kind of shape faces have. b e w 00 Both suvand pare designed 
by hand, but the same parame­terized surface and prototype shape are used to model any set of anthropometric 
measurements. Given this shape representation, the task of the face modeling system is to allow a given 
set of anthropometric measurements m to be used as degrees of freedom for s, in place of p. It does so 
in two logical steps: (1), expressing m as constraints on p in terms of the landmark points as described 
in Section 4.2; and (2), using vari­ational techniques as described in Section 4.3 through Section 4.5 
to .nd a surface that satis.es the constraints and which minimizes bending and stretching away from the 
prototype face shape. 4.1 Surface representation We choose a B-spline surface as a shape representation 
because of the demands both of anthropometric modeling and variational techniques. Our shape must be 
smooth, must permit evaluation of our constraints, and must have surface points and tangent vectors that 
are de.ned as linear combinations of its control mesh points. This scheme meets all of these requirements. 
The speci.cation of suvinvolved the manual construction of b e w a B-spline control mesh for the face, 
shown in Figure 4. The mesh is a tube with openings at the mouth and neck; the geometry fol­lows an available 
polygonal face model and (as required for ac­curate variational modeling) is parameterized to avoid excessive 
distortion of uvpatches.  b e w Figure 4: The prototype face model Anthropometric landmarks are assigned 
.xed locations on the surface in uvparameter space; some are also associated with b e w constraints that 
enforce their .xed geometric interpretations. For example, in the case of the v landmark, which represents 
the top of the head, we ensure that the tangent to the surface at the point representing the landmark 
is in fact horizontal. We likewise add constraints to keep the model in FH position, so that the horizon­tal 
axis of the model is consistent with the axis by which land­marks are identi.ed (and measurements taken). 
These constraints together constitute a set of base constraints which must be satis.ed to apply any anthropometric 
measurement. Further constraints are then added to the model one for each measurement. 4.2 Surface constraints 
Our framework derives a shape by applying both linear and non­linear constraints. The linear constraints 
are derived from axial distance anthropometric measurements and the base constraints on the model; both 
can be represented as a linear function of the de­grees of freedom of the model, p. A matrix A describes 
how the values of all linear constraints are calculated, while a vector b en­codes the intended values 
for those measurements. Thus solutions to these constraints satisfy: Ap b (1) e Because A depends only 
on the types of constraint measurements, A can be solved in advance; then values of p can be computed 
directly from b given particular measurements m. Many of the constraints are non-linear, however. Each 
non­linear constraint is associated with a positive function measuring how far the surface is from the 
correct measurement. These func­tions are summed to give an overall penalty functionP so that non­linear 
constraints impose the equation: P p0 (2) bw r bwe (P p0 for all p). The remainder of this section describes 
the penalty functions associated with each type of measurement con­straint. The shortest distance measurement 
constrains the points xi and x j at a distance r apart using the penalty:  b e we ih i h i e Pdistxix 
jxi x jr 2 (3) The tangential distance constraint, which speci.es the length of a surface curve to be 
r, is approximated using the chord-length approximation of a curve [10] using the points x1xn: n b e 
 e we x n ki p k i b e w Parclenx1xn. 1 xi xi1r(4) i1 The points xi all lie on a predetermined curve 
speci.ed in uv­space (using a B-spline), and are adaptively sampled as to achieve a good estimate of 
the arc length using the chord-length approxi­mation. The inclination measurement constraint .xes a vector 
v at an angle . to a .xed axis a:  bweb i nb e ww 2 Pinclvv Rota.2 (5) Using the rotation Rot, the axis 
a is aligned with the goal direc­tion. v can be the direction between two points on the surface, as well 
as a surface tangent vector. The angle measurement constraint positions the vectors v1 and v2 to be separated 
by the angle .. It is treated as two independent inclination constraints: v2 .2Pangle1 v1 v 1 Rot (6) 
 b w e b i b e i wwww Pangle2 v2v 2 Rotv 1. 4.3 Fairing A fair surface can be constructed by minimizing 
an objective func­tion Es. We will be using the thin-plate functional [7, 18, 33] bw which measures the 
bending of the surface s. It includes the thin­plate term Ep to measure bending, and a membrane termEm 
which ensures the approximation does not become inaccurate: Ep ssuusuu 2suv suv svvsvvdudv  b wwee Z 
b mm dd mm dd m w m 2 w e Emssu su 2susv svsvdu dv where the subscripts on s denote parametric differentiation. 
The overall fairness of the surface is determined by combining these terms together using weights a and 
ß (where typically a is just large enough to prevent approximation error): bwebwdbw (7) EsaEmsßEps(8) 
For linear surface representation schemes (including B-splines), the objective function in (8) can be 
evaluated exactly as a quadratic form 12 pHp [18, 33], where H is determined based on the surface representation 
scheme; the construction for B-splines is given in [33]. Due to the local re.nement property of B-splines,H 
is sparse. The objective function can also be measured with respect to the prototype shape p[33], so 
that the minimization is performed with respect to pp, resulting in 1 ppHpp. The use of b i 0 w 0 b 
i 0 wb i 0 w 2 a prototype shape instructs the fairing process to ignore expected regions of sharp curvature, 
such as the ears and nose on the face. Given H, the problem of fairing given purely linear constraints 
as in (1) is reduced to the following linearly constrained quadratic optimization problem [18, 33]: 1 
min ppHppsubject to Ap b (9) h b i 0 wb i 0 w h e p 2 4.4 Fairing with constraints There are a number 
of approaches for solving the constrained minimization problem in (9) including Lagrange multipliers 
and penalty methods [33] and null-space projection [18], each of which transform the problem to a unconstrained 
problem. The Lagrange multiplier y yields the unconstrained minimiza­tion: 1 min ppHppAp by(10) h b i 
0 wb i 0 wdb i w h py 2 At the minimum, the partial derivatives of the bracketed terms van­ish. Differentiation 
leads to the linear system: HAp Hp  e 0 A 0yb Solving such a system requires selecting a technique 
that is mathematically sound and computationally feasible. For example, interactive modeling, with varying 
constraints and response time demands, requires the use of iterative solution methods, such as the conjugate 
gradient technique [16, 34]. However, we can solve this system without iteration, using a sparse LU decomposition 
tech­nique [14]; producing the decomposition takes On2time given a  bw o bw (11) Onsparse nn system. 
This technique is applicable because the set of constraints is hand-constructed, so we can guarantee 
that the constraint matrix A contains no dependent rows, and hence that the LU decomposition is well 
de.ned. It is feasible because the con­trol mesh topology and the constraint matrix are unchanging, so 
that only one decomposition ever needs to be generated. Finding solutions is then quite ef.cient. In 
general, solving a system given an LU decomposition takes On2time. However, we have found bwbw that the 
LU decomposition is roughly Onsparse given our con­straints. (This is not too surprising given that the 
each constraint involves only a few points on the surface; note that an LU decom­position can be sparse 
even if the actual inverse is dense.) This means that, in practice, solution steps require roughly linear 
time. 4.5 Non-linear constraints As described in Section 4.2, the non-linear constraints are speci.ed 
using the penalty function P p. Since this function is positive, it is simply added into the minimization 
(10) [28, 33]. The extended 0 i bwbw h 0 linear system (11) has Hp.P p.p in place of Hp. Due to the non-linearity 
of P , this system must be solved iteratively. (By contrast, Section 4.2 described a non-iterative method 
for solving the linear constraints.) At iteration i, we determine Ci to be used in place of .P p.p  
i bw h as: .P pi1 Ci Ciµi (12) e n i b n w 1 .p with C0 0. The scalar value µ is a positive weight 
(analogous to a time-step in ODE integration), determined using an adaptive method such as step-doubling 
(for ODE solution) [29]. This results in the iterative linear system: HA pi HpCi (13) e     e 0 
d A 0yb where p0 is the solution corresponding to (11). Note that we still exploit the LU decomposition 
to allow steps to be solved quickly and exactly; this technique is stabler and faster to converge than 
the combination of a conjugate gradient technique with the penalty method. We experimented with linearizations 
of some of the non­linear constraints (and added them into A), but found little gain in ef.ciency, and 
decreased stability in solving. In practice, the simultaneous use of all anthropometric con­straints 
will lead to con.ict. For example, some measurements lead to linearly dependent constraints; they are 
easily identi.ed by in­spection, and culled to keep A invertible. Similarly, when multiple measurements 
place non-linear constraints on similar features of nearby points on the model (without providing additional 
variation in shape), including all can introduce a source of geometric incon­sistency and prevent the 
convergence of C . Our constraint set was selected by following a strategy of including only those constraints 
with the most locally con.ning de.nitions (i.e. constraints which affected fewer facial locations or 
more proximate facial locations were favored).  5 Results and discussion Sample face models derived 
using this technique are shown in Fig­ure 5. To produce the measurements for these models, we ran the 
generation algorithm described in Section 3 on the measurements from [12] and the proportions from [11] 
for North American Cau­casian young adult men and women. Faces for the random mea­surements were realized 
by applying the variational framework to a B-spline mesh (a grid 32 by 32) so as to satisfy the base 
constraints (a total of 15) and 65 measurements that give good coverage both of the shape of the face 
and of the kinds of measurements used in Farkas s system. There were a total of 120 proportions used 
as input to the algorithm in Section 3.2. Producing the LU decomposition used for all these examples 
in­volved a one-time cost of roughly 3 minutes on an SGI 175 MHz R10000. Faces typically found their 
rough shape within 50 itera­tions; our illustrations were allowed to run for up to 200 iterations to 
ensure convergence to millimeter accuracy, resulting in runs that took about 1 minute for each face. 
Models were rendered using RenderMan. Individual variation across the example males and females in Figure 
5 encompass a range of features; for example, clear differ­ences are found in the length and width of 
the nose and mouth, the inclinations of forehead and nose, as well as the overall shape of the face. 
At the same time, traits that distinguish men and women such as the angle at the chin, the slope of the 
eyes and the height of the lower face (particularly at the jaw) vary systematically and correctly (based 
on qualitative comparisons with the anthropomet­ric data). Examining the variation within a population 
group, the thirty generated males in Figure 6 exhibit the expected range of geometric variation. In order 
to quantify this comparison, the proportion-based mea­surement generation algorithm from Section 3.2 
was validated by generating a large number of measurement sets, and comparing the resulting measurement 
distributions to the published .gures from the corresponding population groups. On average, the means 
dif­fered by about 1% (with a maximum deviation of 4 5%) well below the differences in means between 
population groups. The standard deviations agreed comparably, where the generated mea­surements had standard 
deviations that range from being 5% lower to 20% higher than the published values. While this validation 
guarantees the plausibility of measurements on the generated face models, data is unfortunately not available 
for comparing the en­tire geometry (this would require having, for example, a set of measurements of 
an individual along with a corresponding range scan). One would not expect such a comparison to precisely 
agree anyway, as the prototype shape has a measurable effect on the re­sulting geometry. However, this 
effect decreases with the use of additional measurements, which suggests the need to search out additional 
data on face geometry (morphometrics [5] seems to be a good starting point). Despite the many changes, 
a single prototype shape was used for all examples. This gives the models commonalities in shape where 
anthropometric data is silent. Further, all the faces use the same texture so as not to exaggerate their 
differences (having a variety of textures would of course produce nicer results, but would be overlooking 
the main point of this work). The ears remain coarsely modeled (partly as a result of scarcity of measurements 
within the ear). 6 Conclusions This paper has described a two step procedure for generating novel face 
geometries. The .rst step produces a plausible set of con­straints on the geometry using anthropometric 
statistics; the sec­ond derives a surface that satis.es the constraints using varia­tional modeling. 
This fruitful combination of techniques offers broader lessons for modeling: in particular, ways to scale 
up vari­ational modeling a technique previously restricted to modeling frameworks that have seen limited 
use to surface .tting tasks for constrained classes of shapes, and ways to apply anthropometric proportions 
long valued by artists and scientists alike in graph­ics model generation. Of course, our models must 
ultimately be more richly repre­sented. Possible extensions might apply variational techniques to construct 
the face surface and the interior skull simultaneously; this would form the basis of a face animation 
model as in [21]. Simi­larly, landmarks on the face could be used to drive texture synthe­sis, deriving 
distinct but plausible patterns of skin and hair. In the meantime, our work already suggests new computational 
approaches for tasks that rely on anthropometric results, like foren­sic anthropology, plastic surgery 
planning, and child aging. It could also .gure in a user interface for editing face models, by allowing 
features to be edited while related features systematically changed preserving natural proportions or 
ensuring that faces re­spect anthropometric properties common to their population group. Both tasks underscore 
the importance of continuing to gather and analyze anthropometric data of diverse human populations. 
 Acknowledgements We would like to thank Will Welch, Nick Foster, Michael Collins, Max Mintz, Michael 
Gleicher, Scott King, Nathan Loofbourrow and Charles Loop for their helpful com­ments and discussion. 
This research is partially supported by ONR-YIP grant K-5­55043/3916-1552793; ONR DURIP N0001497-1-0396 
and N00014-97-1-0385; NSF IRI 95-04372; NSF Career Award grant 9624604; NASA-96-OLMSA-01-147; NIST grant 
60NANB7D0058; and ARO grant DAAH-04-96-1-007.  References <RefA>[1] T. Akimoto, Y. Suenaga, and R.Wallace. 
Automatic creation of 3D facial mod­els. IEEE Computer Graphics and Applications, 13(5):16 22, September 
1993. [2] F. Azuola. Error in representation of standard anthropometric data by human .gure models. PhD 
thesis, University of Pennsylvania, 1996. [3] T. Beier and S. Neely. Feature-based image metamorphosis. 
In Proceedings SIGGRAPH 92, volume 26, pages 35 42, July 1992. [4] F. Bookstein. Principal warps: Thin-plate 
splines and the decomposition of deformations. IEEE Pattern Analysis and Machine Intelligence, 11(6):567 
585, 1989. [5] F. Bookstein. Morphometric Tools for Landmark Data: Geometry and Biloogy. Cambridge University 
Press, 1991. [6] K. Bush and O. Antonyshyn. 3-dimensional facial anthropometry using a laser­surface 
scanner validation of the technique. Plastic and reconstructive surgery, 98(2):226 235, August 1996. 
[7] G. Celniker and D. Gossard. Deformable curve and surface .nite elements for free-form shape design. 
In Proceedings SIGGRAPH 91, volume 25, pages 257 266, 1991. [8] S. DiPaola. Extending the range of facial 
types. Journal of Visualization and Computer Animation, 2(4):129 131, 1991. [9] M. Dooley. Anthropometric 
modeling programs a survey. IEEE Computer Graphics and Applications, 2:17 25, November 1982. [10] G. 
Farin. Curves and Surfaces for Computer Aided Geometric Design. Aca­demic Press, 1993. [11] L. Farkas. 
Anthropometric Facial Proportions in Medicine. Thomas Books, 1987. [12] L. Farkas. Anthropometry of the 
Head and Face. Raven Press, 1994. [13] A. Gibbons. Algorithmic Graph Theory. Cambridge University Press, 
1985. [14] G. Golub and C. Van Loan. Matrix Computations. Johns Hopkins University Press, 1989. [15] 
C. Gordon. 1988 anthropometric survey of U.S. Army personnel: methods and summary statistics. United 
States Army Natick Research, Development and Engineering Center, 1989. [16] S. Gortler and M. Cohen. 
Hierarchical and variational geometric modeling with wavelets. In 1995 Symposium on Interactive 3D Graphics, 
pages 35 42, April 1995. [17] M. Grosso, R. Quach, and N. Badler. Anthropometry for computer animated 
human .gures. In N. Magnenat-Thalmann and D. Thalmann, editors, State-of­the-art in Computer Animation: 
Proceedings of Computer Animation 89, New York, 1989. Springer-Verlag. [18] M. Halstead, M. Kass, and 
T. DeRose. Ef.cient, fair interpolation using Catmull-Clark surfaces. In Proceedings SIGGRAPH 93, volume 
27, pages 35 44, August 1993. [19] A. Hrdlicka. Practical anthropometry. AMS Press, 1972. [20] J. Kolar 
and E. Salter. Craniofacial Anthropometry: Practical Measurement of the Head and Face for Clinical, Surgical 
and Research Use. Charles C. Thomas Publisher, LTD, 1996. [21] Y. Lee, D. Terzopoulos, and K.Waters. 
Realistic face modeling for animation. In Proceedings SIGGRAPH 95, pages 55 62, 1995. [22] J. P. Lewis. 
Algorithms for solid noise synthesis. Proceedings SIGGRAPH 89, 23(3):263 270, 1989. [23] N. Magnenat-Thalmann, 
H. Minh, M. de Angelis, and D. Thalmann. Design, transformation and animation of human faces. The Visual 
Computer, 5(1/2):32 39, March 1989. [24] H. Moreton and C. S´equin. Functional optimization for fair 
surface design. In Proceedings SIGGRAPH 92, volume 26, pages 167 176, 1992. [25] F. Parke. Parameterized 
models for facial animation. IEEE Computer Graphics and Applications, 2(9):61 68, 1982. [26] F. Parke 
and K. Waters. Computer Facial Animation. A K Peters, 1996. [27] M. Patel and P. Willis. FACES: The facial 
animation construction and editing system. In Eurographics 91, 1991. [28] J. Platt and A. Barr. Constraint 
methods for .exible models. In Proceedings SIGGRAPH 88, volume 22, pages 279 288, 1988. [29] W. Press, 
S. Teukolsky, W. Vetterling, and B. Flannery. Numerical Recipes in C: The Art of Scienti.c Computing. 
Cambridge University Press, 1992. [30] S. Rogers. Personal Identi.cation from Human Remains. Charles 
C. Thomas Publisher, LTD, 1984. [31] D. Terzopoulos and H. Qin. Dynamic nurbs with geometric constrains 
for inter­active sculpting. ACM Transactions on Graphics, 13(2):103 136, 1994. [32] T. Vetter and T. 
Poggio. Linear object classes and image synthesis from a single example image. IEEE Pattern Analysis 
and Machine Intelligence, 19(7):733 742, 1997. [33] W. Welch and A. Witkin. Variational surface modeling. 
In Proceedings SIG-GRAPH 92, volume 26, pages 157 166, 1992. [34] W. Welch and A. Witkin. Free Form shape 
design using triangulated surfaces. In Proceedings SIGGRAPH 94, volume 28, pages 247 256, July 1994. </RefA>
 Males Females Figure 5: Automatically generated face models (3 views of each)  Figure 6: A male a 
minute 
			
