
 An Analytic Performance Edward K. Lee University of California 571 Evans Hall Berkeley, CA 94720 eklee@cs. 
berkeley.edu Abstract As disk arrays become widely used, tools for under­ standing and analyzing their 
performance become in­ creasingly important. In particular, performance mod­ els can be invaluable in 
both configuring and designing disk arrays. Accurate analytic performance models are preferable to other 
types of models because they can be quickly evaluated, are applicable under a wide range of system and 
workload parameters, and can be manipu­lated by a range of mathematical techniques. Unfortu­nately, analytic 
performance models of disk arrays are difficult to formulate due to the presence of queueing and fork-join 
synchronization; a disk array request is broken up into independent disk requests which must all complete 
to satisfy the original request. In this paper, we develop and validate an analytic performance model 
for disk arrays. We derive simple equations for approxi­mating their utilization, response time and throughput. 
We validate the analytic model via simulation, investi­gate the error introduced by each approximation 
used in deriving the analytic model, and examine the validity of some of the conclusions that can be 
drawn from the model. 1 Introduction Disk arrays provide high 1/0 performance by striping data over multiple 
disks. High performance is achieved by servicing multiple 1/0 requests concurrently and by using several 
disks to service a single request in par­allel. Given the increasing importance of disk arrays as high-performance 
secondary storage systems [7, 8, 12, 14,15, 17], tools for understanding their performance become increasingly 
important. In particular, perfor- Permission to copy without fee all or part of this material is granted 
provided that the oopies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and ita date appear, and notice is given that oopying ie by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. 1993 ACM SIGMETRICS-5/93 /CA, USA ~ 1993 ACM O-89791 -581 -X19310005 ]O098...9I 
.50  Model of Disk Arrays Randy H. Katz University of California 571 Evans Hall Berkeley, CA 94720 
randy @cs.berkeley.edu mance models, combined with a thorough understand­ing of an installation s workload, 
will be invaluable in both configuring and designing disk arrays. In general, accurate analytic performance 
models are preferable to other types of models, such as empirical and simulation, because they can be 
quickly evaluated, are applicable under a wide range of system and workload parameters, and can be manipulated 
by a range of mathematical techniques. Even when analytic models are not directly applicable to a particular 
system or workload, they are frequently useful for quickly analyzing general proper­ties of the system, 
stimulating intuition and furthering understanding. Unfortunately, analytic performance models of disk 
arrays are difficult to formulate due to the presence of queueing and fork-join synchronization; a disk 
array re­quest is broken up into independent disk requests, all of which must complete to satisfy the 
disk array re­quest. While systems with only of queueing or fork-join synchronization are frequently 
tractable given certain reasonable approximations, the combination of the two result in systems that 
are very difficult to analyze an­alytically. Exact analytic solutions for the two server fork-join queue 
given Poisson arrivals and independent service times currently exist [1, 4] but the k-server fork­join 
queue remains unsolved. Other related work in the field of disk array performance falls into four primary 
categories: (1) simulation studies [3, 12, 16], (2) ana­lytic models that ignore queueing effects [2,9, 
17], (3) analytic models that ignore fork-join synchronization [8] and (4) restricted queueing models 
that deal with fork­join synchronization using specialized techniques not easily extended to modeling 
disk arrays [5, 13]. Most analytic queueing studies deal with general queueing systems rather than disk 
arrays in particular. In this paper, we develop and validate an analytic performance model for asynchronous 
disk arrays. Our model is different from previous analytic models of disk arrays mentioned above for 
the following reasons. First, we use a closed queueing model with a fixed number of processes whereas 
previous analytic models of disk arrays have used open queueing models with Poisson stripeunit DataStnpc 
arrivals. A closed model more accurately models the synchronous 1/0 behavior of scientific, time-sharing 
and distributed systems. In such systems, processes tends to wait for previous 1/0 requests to complete 
before issuing new 1/0 requests, whereas in transaction based systems, 1/0 requests are issued randomly 
in time regardless of whether the previous 1/0 requests have completed. Sec­ond, to the best of our knowledge, 
we present the first analytic model for disk arrays that handles both the queueing at individual disks 
and the fork-join synchro­nization introduced by data striping. Previous analytic models handling both 
queueing and fork-join synchro­nization cannot easily be applied to disk arrays; these assume service 
times across servers (disks) are indepen­dent whereas in disk arrays, service times are very much dependent. 
We have found the analytic model useful for com­parative studies that focus on the relative performance 
of various disk array configurations. Lee [10] uses the analytic model presented here to derive a formula 
for the optimal size of data striping in disk arrays, pro­viding an important application of the model. 
We are currently using the model to calculate quantita­tive price/performance metrics for disk arrays 
under a range of system and workload parameters. The model is also useful in identifying important factors 
in the per­formance of disk arrays and presents insights that are useful in characterizing the performance 
of real disk ar­rays. The model, of course, is not without limitations. Although the analytic model can 
be used to model both read and write requests to non-redundant disk arrays and read requests to a subclass 
of RAID s (Redundant Arrays of Inexpensive Disks) identified in Section 2, it currently does not model 
parity updates which occur during write requests to a RAID. Another limitation is that the workload model 
is not expressive enough to easily model real workloads. Thus, although the model can be used to accurately 
predict the performance of real disk arrays under many of the synthetic workloads used in this paper, 
its prediction of performance under real workloads may be highly approximate. A final lim­itation is 
that we only model the disk components of a disk array system. Real disk array systems have many other 
components such as strings, 1/0 controllers, 1/0 busses and CPU s that affect the performance of the 
sys­tem. We are currently addressing the above limitations in a work in preparation. In the following 
sections, we first derive an exact expression for the utilization of the model system. Be­cause the exact 
expression contains parameters that are difficult or impossible to compute, we analytically ap­proximate 
the difficult parameters to make the expres­sion more tractable. From the resulting approximate  4314w3m 
 Figure 1: Data Striping in Disk Arrays. Stripe unit is the unit of data interleaving, that is, the 
amount of data that is placed on a disk before data is placed on the next disk. Stripe units typ­ ically 
range from a sector to a track in size (512 bytes to 64 kilobytes). The figure illustrates a disk array 
with five disks with the first ten stripe units labeled. Data stripe is a sequence of logically consecutive 
stripe units. A logical 1/0 request to a disk array corresponds to a data stripe. The figure illustrates 
a data stripe consisting of four stripe units span­ning stripe units three through six. equation for 
utilization, we de~ive equations for response time and throughput. We then validate the analytic model 
via simulation and investigate the error intro­duced by each approximation made in deriving the an­alytic 
model. Next, we empirically verify certain con­clusions that can be drawn from the analytic model and 
present an alternative empirical derivation of the ana­lytic model. Finally, we derive and validate a 
simple extension to the basic analytic model which allows the modeling of variable sized request distributions. 
2 The Modeled System Our primary focus is on modeling non-redundant asynchronous disk arrays. Figure 
1 illustrates the basic disk array of interest and the terms stripe unit and data stripe. For readers 
who are familiar with the RAID taxon­omy, we mention that the analytic model we develop can also be used 
to model reads for RAID level 5 disk arrays using the left-symmetric parity placement [11]. This is because 
the left-symmetric parity placement has the property that it does not disturb the data mapping illustrated 
in Figure 1. 3 The Analytic Model In this section, we derive equations that approximate the read/write 
performance of non-redundant asyn­L processes L requests of size n N queues N diSkS Figure 2: Closed 
Queuiruz Model for Disk Ar­ . rays. The parameters of the above system are as follows: L s Number of 
processes issuing requests. N s Number of disks. n = Request size in disks (n < N). S s Service time 
of a given disk request. chronous disk arrays. Our approach is to derive the expected utilization of 
a given disk in the disk array. Because we are modeling a closed system where each disk plays a symmetric 
role with respect to each other, knowing the expected utilization of a given disk will al­low us to compute 
the entire system s throughput and response time. For the sake of convenience and clarity, we present 
the complete derivation of the analytic model before presenting the empirical validation of the model. 
How­ever, the actual development of the model followed an iterative process consisting of an alternating 
sequence of analytical derivations and empirical validations. While some of the approximations made in 
this section, when separately presented from their empirical validation, may appear arbitrary, the approximations 
and results of the model are justified in Section 4. 3.1 The Model System Consider the closed queueing 
system illustrated by Fig­ ure 2. The system consists of L processes, each of which issues, one at a 
time, an array request of size n stripe units. Each array request is broken up into n disk re­ quests 
and the disk requests are queued round-robin starting from a randomly chosen disk. Each disk ser­vices 
a single disk request at a time in a FIFO manner. When all of the disk requests corresponding to an array 
request are serviced, the issuing process generates an­other array request, repeating the cycle. Note 
that two or more array requests may partially overlap on some of the disks, resulting in complex interactions. 
We some­times refer to array requests simply as requests. In the derivation of the analytic model, we 
will assume that L and n are fixed. We will also assume that the processes do nothing but issue 1/0 requests. 
Later, we will extend the model to allow variable sized requests.  3.2 The Expected Utilization In deriving 
the expected utilization of the model system, the following definitions will prove useful: U = Expected 
utilization of a given disk. R = Response time of a given array request. W = Disk idle (wait) time between 
disk requests. Q s Queue length at a given disk. p. = Probability the queue at a given disk is empty 
when the disk finishes a disk request. p = n/N, probability of a request accessing a given disk. If we 
visualize the activity at a given disk as an al­ternating sequence of busy periods of length S and idle 
periods of length W, the expected utilization of a given disk is, E(S) (1) u = E(S)+ E(W) Idle periods 
of length zero can occur and imply that another disk request is already waiting for service, Q > 0, when 
the current disk request finishes service. Let r-o denote the time between the end of service of a given 
disk request and the issuing of a new array request into the system. Let ri, i E {1, 2, . . .}, denote 
the successive time intervals between successive issues of array requests numbered relative to ro. Let 
M de­ note the number of array requests issued after a given disk finishes a disk request until, but 
excluding, the ar­ ray request that accesses the given disk. Since each array request has probability 
p of accessing a given disk and disk requests are issued one at a time, &#38;f is a mod­ ified geometric 
random variable with E(A4) = I/p 1. Figure 3 illustrates the above terms. By conditioning on the queue 
length at the time a X = alTly reqw$tissued ri. timeimmals dixkrequestfinishes wxt &#38; Rquestmives 
A r-2 r.Jro 11 [2 13 000v *+ 000 \/&#38;v \/ ,. time-> to tl tt t2 t4 t6 I 1 M=2. W=IOtr1+r2 Figure 
3: Time-line of Events at a Given Disk. After the disk request finishes service at time tz,M = 2 array 
requests that do not access the given disk are issued at times t3and t4before an array request that accesses 
the given disk is issued at time t5. The disk remains idle for a time period of W = r. + rl + r2. disk 
request finishes service, we can write, E(W) = P(Q > O) E(W]Q > O)+ P(Q = O) E(WIQ = ()), E(w) = (1 
po)o + POE(Z*O ri), E(w) = po(ll(ro) -1-J!@!l ri)). Substituting into Equation 1 we have, E(S) u== (2) 
E(s) + po(E(~o) + E(2HI T;)) Equation 2 is an exact, though not directly useful, equa­tion for the expected 
utilization of the model system. 3.3 Approximating the Expected Uti­lization In the previous section, 
we formulated an exact equa­tion, Equation 2, for the expected utilization of the model system. Unfortunately, 
the exact equation con­sists of terms which are very difficult if not impossible to compute. In this 
section, we approximate components of Equation 2 to make it analytically tractable. To simplif Equation 
2, the first approximation we &#38;make is l?(~i=l ri) = E(A4)E(Ti) = (l/p l) E(R)/L. From Little s 
Law, we know that the average time be­tween successive issues of array requests is E(R)/L. Note also 
that M is a stopping time, that is, the event that the mth request misses the given disk, M > m, is independent 
of the random variables r~+l, r~+2, . . .. Thus, from Wald s Equation, the above approximation would 
be exact jf ri, i ~ {1, 2, . . .} were independently distributed with a common mean of E(R)/L. For the 
moment, we will take the above approximation as given, but later show via simulation that the above is 
an ex­ tremely good approximation. The second approximation we make is to assume that E(ro) H O. As 
motivation, we present the following observations concerning E(ro): lJ(ro) = O implies that disk requests 
associated with the same array request finish at the same time and thus an array request is issued immedi­ate 
y whenever any disk request finishes.  E(ro) = O when n = 1, that is, when each ar­ray request consists 
of a single disk request, the completion of each disk request corresponds to the completion of the corresponding 
array request and, thus, the process that issued the disk request will immediately issue another array 
request.  E(ro) E O when n = N, that is, when an array request always uses all the disks, disk requests 
as­sociated with the same array request will tend to finish at close to the same time because all of 
the disks will be in very similar states and operate in a lock step fashion since disk service times 
are de­terministic and disk requests across disks will be almost identical.  Hopefully, E(ro) will not 
deviate too far from zero for values of n other than one or N.  The third and final approximation is 
poE(R)/E(S) H 1. This equation is true for M/M/l systems and approximately holds at low to moderate loads 
for M/G/l systems but the primary motivation for the approximation comes from empirical observa­tions. 
Incorporating the three approximations, we can rewrite Equation 2 as, 1 u? (3) l-t+(l/p -1) Note that 
under the approximations we have made, the expected utilization is insensitive to the disk service time 
distribution, S. The expected throughput in bytes per second can be written as, ~ UNB (4) = E(S) where 
B is the size of the stripe unit. Since this is a closed system, the expected response time can be ex­pressed 
as, E(R) = ~, (5) where T/(nl?) is simply the throughput in array re­quests per second. Future references 
to a specific an­alytic model will refer to the above equations and to Equation 3 in particular. To briefly 
motivate the usefulness of the analytic model, consider the following applications of the model. An equation 
for the stripe unit size, B, that maximizes throughput can be computed from Equation 4 by dif­ferentiating 
it with respect to B and solving for local maxima. Another simple application is to solve Equa­tion 5 
with respect to N to get a feel for the number of disks needed to achieve a certain response time for 
a given workload.  4 Empirical Validation In this section, we examine via simulation the accuracy of 
the analytic model and the error introduced by each approximation in the derivation of the analytic model. 
We also empirically examine the validity of the conclu­sions that can be drawn from the model. In particu­lar, 
we will show that utilization is insensitive to the disk service time distribution and that utilization 
can be accurately represented by an equation of the form U = 1/(1 + ~~(p, iV)) where ~(p, IV) represents 
an ar­ bitrary function of p and N. Finally, we will extend the basic analytic model to handle variable 
sized re­quests and validate the result. Our basic approach is to compare the results of the analytic 
model to simula­tion using aggregate statistics which summarize errors and graphs which plot the analytic 
model versus the simulated data points. 4.1 Metrics for Error Analysis When analyzing the errors in an 
analytic model versus simulation over a wide range of inputs, we must use ag­gregate statistics summarizing 
the errors because it is infeasible to compare directly the error resulting from each and every data 
point. The following defines stan­dard statistical terms [6] and metrics that will be used in the rest 
of this paper. Note in particular the defini­tions of the three error metrics R2, max error and 90% error 
which will be used to characterize errors in the analytic model. response The result of a simulation 
run. parameter A simulation variable that can influence the response. factor A parameter that is being 
varied in a simulation study. In most studies, certain simulation param­eters are held constant. factor 
level A possible value for a factor. For example, the factor request size may have factor levels 4 KB, 
8KB, or 16KB. design An experimental design is constructed by spec­ifying the factors, the factor levels 
used at each simulation run and the number of times the simu­lation is repeated with the same factor 
levels (usu­ally using a different seed in the random number generator). design point The factor levels 
for a single simulation run. For example, (number of disks = 8, request type = read, request size = 4 
KB). design set The set of design points used in an exper­imental design. For example, a design set can 
be constructed by taking a cross product of the fol­lowing factor levels: number of disks E {8, 16}, 
request type E {read, write}, request size E {4, 8, 16} KB. The following defines the metrics R2, max 
error and 90% error. Yi The ith simulated response. $i The ith analytically predicted response. e~ y~ 
 y~ (error of the ith input) u Arithmetic mean of yi s. SSE ~ e: (sum of squared errors) SST z(Yi -?)2 
(sum of squares total) R2 (SST -SSE)/SST (coefficient of determination) max error max e% (maximum error) 
90% error The 90th percentile of ei. The coefficient of determination, R2, is a measure of how closely 
the analytic model predicts the simulated response. A simple model predicting that the response is equal 
to the mean] V, for all design points would have R2 = O. A model that perfectly predicts the simulated 
response would have R2 = 1.R2 can be interpreted as the fraction of total variation that is explained 
by a model. Although R2 is a good measure for checking the overall accuracy of a model, it may be highly 
dependent upon the choice of the design set and may vary signif­icantly for certain subsets of the design 
set. That is, an analytic model that is wildly inaccurate for a signif­icant collection of design points 
can still have R2 H 1 if the model is accurate for the other design points. Be­cause R2 can be insensitive 
to large errors in the analytic model, the max error metric is useful as an indication of the worst predictions 
made by the model. The 90% er­ror metric is a compromise between R2 and max error which compensates for 
the extreme sensitivity of maz error to outliers.  4.2 Experime~tal Design E(S) We are interested in 
the following factors to validate our analytic model. diskModel Disk type. N Number of disks in the 
disk array. L Number of processes issuing 1/0 requests. B Size of the stripe unit (block size). P Request 
size as a fraction of the disk array. The design set consists of the complete cross product of the following 
factor levels. Factor Factor Levels diskModel Lightning, Fujitsu, FutureDisk N 2,3,4,8, 16 L 1,2, 4,8,16,32 
B (1, 4, 16, 64)KB P (1,2,..., IVN/N The parameters for the three disk models listed above are described 
in Table 1. Note that the number of fac­tor levels for p depend upon N and are expressed as multiples 
of l/IV. This means, for example, that there are twice as many design points with N = 4 relative to N 
= 2. Thus, although we do not intrinsically value disk arrays with N = 4 more than disk arrays with N 
= 2, the design set implicitly assigns the former twice the importance of the latter. To compensate for 
this ef­fect, we weigh all design points by the factor l/N when calculating statistics. We simulate each 
design point in the design set twice with two different random seeds to quantify the experi­mental error 
which intrinsically cannot be explained by any model. Thus, the total number of simulation runs is 2(3x4x6x(2+3+4+8 
+16)) =4,752. In each simulation run, the disks are rot ationally synchro­nized, requests to the disk 
array are aligned on stripe unit boundaries, and L and p are held constant. 4.3 Validation of the Analytic 
Model In this section, we examine via simulation the accuracy of the analytic model and the error introduced 
by each of the three approximations in the model of Section 3. Recall that the three approximations are 
as follows: 1. E(zfll ri) = (1/P l)JZ(~)/L, 2. E(ro) = o, 3. p&#38; E(R)/E(s) H 1.  Consider the 
following definitions: The variable U represents the analytic model derived in Section 3 by applying 
approximations 1, 2 and 3. The variables U1, 02 and 03 are submodels derived by ap­plying only one of 
approxima~ion: 1, 2 or 3, respectively. By examining the errors in UI, U2 and U3, we can ap­proximately 
study the errors introduced by each of the corresponding approximations. 1 = E(S)+ f?o(E(ro) + (1/P 
 1)~(~)/~) E(S) 02 = E(S) + pO(~fiI ~i)  The table below tabulates the error metrics dis­cussed in Section 
4.1 for the best empirical model, U, U1, 02 and 03. The best empirical model is that model which minimizes 
the sum of squared errors or, equiva­lently, maximizes R2 and is computed by averaging the responses 
of data points with the same design point. The error metrics for the best empirical model are use­ful 
for comparison purposes and give a feel for the mag­nitude of experimental errors that can not be explained 
by any model. The metric 1 R2 is included for eas­ier comparisons of models that have values of R2 very 
close to one. Because we are more interested in rela­tive rather than absolute errors, the error metrics 
are calculated for the logarithm of utilization rather than utilization directly. This means that for 
small errors, less than approximately 20%, the max error and 90% en-or metrics can be interpreted as 
percentage devia­tions. For example, a max error of 0.0430 represents a 4.30 !lo deviation from the predicted 
utilization. Model R2 1 R2 max err 90% err BEST 0.9995 0.0005 0.0430 0.0133 u 0.9814 0.0186 0.1863 0.0987 
01 0.9990 0.0010 0.0834 0.0192 02 0.9888 0.0112 0.1676 0.0742 03 0.9808 0.0192 0.1807 0.0951 The above 
table shows that 0.05 yo of the variation in response is due to experimental errors which can not be 
explained by any model. The maximum experimen­tal error is 4.30 Yo, and 9070 of all experimental errors 
are less than 1.33 Yo. The maximum error for the an­alytic model, U, derived in Section 3 is 18.6370 
with 90 YO of errors less than 9.87% of the predicted utiliza­tion. Finally, approximations 2 and 3 introduce 
most of the experimental errors, while approximation 1, as expected, introduces very few errors. 1 Figure 
4 plots the response predicted by the analytic u= 1++(1/p 1) model U together with the 90 percentile 
intervals as a Lightning Fujitsu FutureDisk bytes per sector 512 512 512 sectors per track 48 88 132 
tracks per cylinder 14 20 20 cylinders per disk 949 1944 2500 revolution time 13.9ms 11.lms 9.lms single 
cylinder seek time 2.Oms 2.Oms 1.8ms average seek time 12.6ms 11.Oms 10.0 ms max stroke seek time 25.Oms 
22.Oms 20.Oms sustained transfer rate 1.8 MB/s 4.1 MB/s 7.4 MB/s Table 1: Disk Model Parameters. Average-seek-time 
is the average time needed to seek between two equally randomly selected cylinders. Note that sustained-transfer-rate 
is a function of bytes-per-sector, sectors-per-track and revolution-time. Lightning is the IBM 0661 3.5 
320 MB SCSI disk drive, Fujitsu is the Fujitsu M2652H/S 5.25 1.8 GB SCSI disk drive and FutureDisk is 
a hypothetical disk of the future created by projecting the parameters of the Fujitsu disk approximately 
three years into the future based on current trends in disk technology. The most dramatic improvements 
are in the bit and track density of the disks rather than in mechanical positioning times. Thus, disks 
in the future will have much higher sustained transfer rates but only marginally better positioning times. 
The seek profile for each disk is computed using the following formula: o ifx=O seekl ime(z) = a~-t-b(z-l)+c 
ifz>O { where x is the seek dist ante in cylinders and a, b and c are chosen the satisfy the single-cylinder-seek-time, 
average­seek-time and max-stroke-seek-time constraints. The square root term in the above formula models 
the constant acceleration/deceleration period of the disk head and the linear term models the period 
after maximum disk head velocity is reached. If cylinders-per-track is greater than approximately 200, 
a, b and c can be approximated using the following formulas: a = ( 10 minSeek + 15 avgSeek 5 mazSeek)/(3 
~=) b = (7 minSeek -15 avgSeek + 8 mazSeek)/(3 numCyl) c! = minSeek where minSeek, avgSeek, maxSeek 
and num Cyl correspond to the disk parameters single-cylinder-seek-time, average­seek-time, max-stroke-seek-time 
and cylinders-per-track, respectively. We have compared the model to the seek profile of the Amdahl 6380A 
published by Thisquen [18] and have found the model to closely approximate the seek profile of the actual 
disk. In practice, we have found the model to be well behaved, although care must be taken to check that 
a and b evaluate to positive numbers. Analytic U with 90 Percentile Intervals 1 0.8 !2 00.6 ..+ 4.) 
a .: r­ -i :0.4 0.2 0 .--. A. A­ U.,z U.4 U.b U.b 1. P Figure4: Analytic Uwith90 Percentile Intervals 
asa FunctionofL andp. Each line andshadedre­gion represents the analytically predicted response and empirically 
determined 90 percentile intervals, respec­tively, for a different value of L. From bottom to top the 
values for L are 1,2,4,8,16 and 32, respectively. function of L and p, the only two factors considered 
im­portant by the analytic model. In the figure, each 90 percentile interval encloses 90 ~o of the weighted 
simu­lated responses for the given values of L and p. We have elected to give percentile intervals rather 
than con­fidence intervals because standard methods for calculat­ing confidence intervals require that 
errors be normally distributed with a constant standard deviation. Certain transformations can be made 
on responses to satisfy the requirement but these transformations are often artifi­cial. Percentile intervals, 
on the other hand, do not re­quire any assumptions in the distribution of errors but do require a larger 
number of data points to calculate. Figure 4 shows that the analytically predicted utiliza­tion approximately 
passes through the 90 percentile in­tervals determined by simulation. As we will see later, the jaggedness 
of the percentile intervals is caused by the fact that the factor N, which is ignored by the ana­lytic 
model, is significant in explaining variations in the response. 4.4 Validation of Model Properties The 
previous section examined the errors in the analytic model, but regardless of the accuracy of the model, 
cer­tain properties of the model may be valid where the model itself is not. This section will investigate 
the model s prediction that the utilization is independent of the disk service time distribution, S, 
or more specif­ically is dependent only on the factors L and p. We will also examine whether, as implied 
by the model, the utilization can be accurately modeled by an equation of the form U = 1/(1+ ~ f(p, N)) 
where f(p, N) represents an arbitrary function of p and N. Recall that .f(p, N) is equal to l/p 1 in 
the analytic model. 4.4.1 Significance of Factors The following table tabulates the error metrics for 
the best empirical models models that maximize R2 when certain factors are excluded. The first entry 
la­beled NONE corresponds to the best empirical model that can be constructed when no factors are excluded 
and is identical to the model identified as BEST in the previous section. If the exclusion of a factor 
results in error metrics that are only slightly different from the error metrics of the NONE entry, this 
provides strong evidence that the factor can be safely ignored by the analytic model, at least over the 
range of factor levels investigated. The last two entries in the table illustrate the effects of excluding 
more than one factor at a time. As before, the metrics are calculated for the logarithm of utilization 
rather than for utilization directly. Deleted Factors R2 1 R2 max err 90% err NONE 0.9995 0.0005 0.0430 
0.0133 diskModel 0.9990 0.0010 0.0570 0.0205 N 0.9936 0.0064 0.1653 0.0525 L 0.4238 0.5762 1.4311 0.4835 
B 0,9986 0.0014 0.0789 0.0252 P 0.4285 0.5715 1.8733 0.5018 diskModel B 0.9983 0.0017 0.0843 0.0269 diskModeI 
B N 0.9926 0.0074 0.1678 0.0577 As predicted by the analytic model, the above table illustrates that 
utilization is insensitive to the disk ser­vice time distribution, S, or more specifically to the two 
principle factors, diskModel and B, that determine S. Excluding both the factors diskModel and B result 
in error metrics max error = 8.43 yo and 90 % error = 2.69 % which compare favorably with the error metrics 
of the best case when no factors are excluded of ma$ em-or = 4.30 YO and 90 % error = 1.33 Yo. Thus, 
we con­clude that utilization is insensitive to the disk service time distribution, S. The insensitivity 
of utilization to the disk service time distribution is hardly surprising given that we have a closed 
queueing system where processes perform noth­ing but 1/0. Consider the following thought experiment. 
If we replaced all the disks with devices twice as fast but the same in other respects, we would expect 
throughput to exactly double but utilization to remain the same. Real systems are more complicated because 
changing disks or stripe unit sizes not only changes the mean of the service time distribution but also 
its shape. How­ever, this simple thought experiment provides a valu­able insight as to why utilization 
is insensitive to the disk service time distribution. It also provides a reason to believe that this 
is a generalizable property that also holds under a wide range of factor levels that we have not investigated 
in this paper. Unlike excluding the factors diskModel and 1?, ex­cluding factor N introduces significant 
errors. The er­rors, however, are not large enough to say that it is never acceptable to ignore N. Whether 
N can be ig­nored depends on the actual use of the model. If one is primarily interested in the effects 
of varying N, it may not be acceptable, but otherwise, it is probably accept­able. The table shows that 
the remaining factors, L and p, are clearly important and cannot be ignored.  4.4.2 Relationships Between 
IV, L and p The previous section identified the factors N, L and p as significant in formulating a model 
for the utiliza­tion of the modeled system. In this section, we em­pirically investigate the relationships 
between these fac­tors, In particular, we examine whether, as implied by the model, the utilization can 
be accurately modeled by an equation of the form U = 1/(1 + ~j(p, N)) where ~(p, N) represents an arbitrary 
function of p and N. We then search for values of ~(p, N) that result in accurate analytic models. Figure 
5 plots log(l/~ 1) versus logz L for the dif­ferent factor levels of N and p where ~ is the geometric 
mean of the utilization over all design points with the same values of N, L and p. We use ~ rather than 
arbitrarily selecting design points with a specific value for diskModel and B to reduce experimental 
error. If u= 1/(1+ ~f(P,N)), a dot of log(l/~ 1) versus logz L should result in straight lines with 
a slope of -1. As is evident from the figure, this is approximately the case. Now that we have verified 
that U H 1/(1 + ~~(P, N)), it remains to determine a good approxima­tion for ~(p, N). Since ~ is a function 
only of p and N and not L, we can theoretically determine j by fixing L to any particular value. In particular, 
if L = 1, the resulting system has no queueing and it is evident that N= 2   !lsIiE ,234, ,,345 N=4 
N=8 !l!El ,234, ,234, ,.3+ L 1DJ2 L  Figure 5: Plots of log(l/~ 1) vs. logz L. Each plot corresponds 
to a different value of N. Within each plot, each line represents a plot of log(l/~ 1) versus logz L 
for a different value of p. From top to bottom the values for p are l/N, 2/N, . . . . and N/N, respectively. 
U H p. Substituting, we have p E 1/(1 -I-~~(p, N)) and solving for f(p, N) we have ~(p, N) = l/p 1. 
Note that this results in the same analytic model, U N 1/( 1 + ~ (l/p 1)) derived in Section 3. The 
reader can look upon the above result as an alternative derivation of the analytic model based on empirical 
techniques. Having rederived the analytical model above, two questions immediately arise: 1 Can we get 
a more accurate model by solving for utilization with L = 2 rather than L = 1? The­oretically, a solution 
to such a model would take into account a greater amount of the interaction between processes and should 
result in a more ac­curate model.  2. How good is the best model of the form U H 1/(1+ +f(P! Aq)? The 
second question is easily answered empirically; we simply calculate the values of $(p, IV) which maximizes 
R2 and examine the errors of the resulting model. The first question is more difficult to answer. Even 
for L = 2, we must take into account both queueing and fork-join synchronization. We approximately model 
the system with L = 2 as a discrete-time discrete-state Markov chain. If we assume that disk service 
times are con­stant, the number of states required to model the system is equal to the number of disks 
in the system. That is, the queue length at each disk is either zero or one, disks with a queue length 
of one are always consecutively lo­cated in the disk array, and the state where every disk has a queue 
can be merged with the state where no disk has a queue. We have formulated and solved such a model for 
arbitrary N. The solution is complex enough and would require sufficient explanation that it is not presented 
here. The model will be presented in a dis­sert ation current] y in preparation. Let UL represent the 
best empirical model of the form U = 1/(1+ ~f(P, N)), let UL1 : 1/(1+ ~(1/P l)), and let OLZ represent 
the approximate solution for utilization derived by assuming L = 2. The table below tabulates the error 
metrics for QL, UL1 and OLZ. Model Rz I R2 maz err 90% err UL 0.9929 0.0071 0.1299 0.0642 fiLI 0.9814 
0.0186 0.1863 0.0987 UL2 0.9814 0.0186 0.2176 0.0920 The error metrics of UL1, the analytic model derived 
in Section 3, compares favorably with the error metrics of UL, the best empirical model of the form U 
H 1/(1 + ~ $(P, N)). Somewhat surprisingly, The maz error for ULZ is larger than that for fiI,I although 
the 90% error is smaller. Although not visible from the table due to roundoff, R2 for OLZ is slightly 
larger than that for ~Ll. We conclude that the additional comp~xities of 0L2 does not, in general, merit 
its use over UL1. 4.5 Modeling Variable Request Sizes In this section, we extend our model to handle 
variable sized workloads. Although we derived Equation 3 as­suming a constant request size, it can be 
easily extended by noting that the parameter p is just the probability that a given request will access 
a given disk. Thus, given a workload which is fl fraction requests of size pl and f2 = 1 fl fraction 
requests of size P2, P = flpl + f2p2. In general, if z is the size of requests as a fraction of the disk 
array and F(z) its corresponding cumulative distribution function. Then, (6) where ~ is the average request 
size as a fraction of the disk array. To validate the above result, consider the design set consisting 
of the following parameter and factor levels: Parameter Parameter Value diskModel Fujitsu N8 B 32 KB 
Factor Factor Levels L 1,2, 4,8,16,32 (2, ....N)/N PI (1 ,..., pI1)lN/NP2 0.20, 0.40,0.60, 0.80 fl Since 
we have shown in Section 4.4.1 that utilization is insensitive to diskModel, N and B, we hold them con­stant. 
In each simulation run, L processes randomly issue requests of size pl, fl fraction of the time, and 
requests of size pa, 1 fl fraction of the time. Each design point in the design set is simulated twice 
with two different random seeds in order to quantify the ex­perimental error. Thus, the total number 
of simulation runs is 2(6 x 28 x 4)) = 1344. In each simulation run, the disks are rotationally synchronized, 
requests to the disk array are aligned on stripe unit boundaries and L is held constant. The following 
are the error metrics from the experi­ment where U s 1/(1+ ~(1/F l)). Model R2 1 R2 maz err 90% err 
BEST 0.9986 0.0014 0.0801 0.0192 u 0.9969 0.0031 0.0934 0.0300 As can be seen from the table, the analytic 
model which only uses the factors L and F compares favorably with the best empirical model which uses 
all of the factors L, P1, P2 and fl. Fig~re 6 plots the response predicted by the analytic model U together 
with the maximum error intervals and individual data points as a function of L and F. As can be seen 
from the figure, the analytically predicted response approximately passes through the simulated data 
points. 5 Summary and Future Work We have derived and validated an analytic performance model for disk 
arrays. We initially modeled disk ar­rays as a closed queueing system consisting of a fixed 1 0.8 c 
o .r­ :0.6 .: 0.2 I 1 0.2 0.4 0.6 0.8 pbar Figure 6: Analytic U with Maximum Error In­tervals and Individual 
Data Points. In the above plot, diskModel = Fujitsu, N = 8 and B = 32 KB. Each line, shaded region and 
set of datapoints corresponds to a different value of L. From bottom to top the values for L are 124816 
and 32, respectively. ???> number, L, of processes continuously issuing requests of a fixed size, p, 
to a disk array consisting of N disks. We then extended the model to handle variable sized requests. 
The resulting model predicts the expected utilization of the model system, U, as approximately where 
P is the average size of requests as a l+; (;/p-1) fraction of the number of disks in the disk array. 
We then directly derived the expected response time and throughput as a function of utilization. We showed 
via simulation that the simulated utilization is gener­ally within +1O %O of the utilization predicted 
by the analytic model. We also examined the error introduced by each approximation made in the derivation 
of the analytic model to better understand the validity of the approximations. Finally, we validated 
two results of the analytic model, namely that utilization is insensitive to the disk service time distribution 
and that utilization can be accurately represented by an equation of the form U = 1/(1 + ~~(p, N)) where 
.f(p, N) represents an arbitrary function of p and N. There are several major areas for future work with 
respect to the analytic model presented here. First, we plan to extend the workload model to handle something 
similar to CPU think time, where the processes, instead of simply issuing 1/0 requests, would alternate 
between computation and 1/0. Second, we plan to extend the model to handle write requests to RAID s. 
Finally, we will apply the analytic model to solve problems in the design and configuration of disk arrays 
such as deter­mining the optimal size for data striping, computing the price/performance ratios for various 
disk array and workload parameters, and quantifying tradeoffs between the performance and reliability 
of disk arrays.  6 Acknowledgements We would like to thank our government and industrial affiliates, 
Array Technologies, DARPA/NASA (NAG2­591), DEC, Hewlett-Packard, IBM, Intel Scientific Com­puters, California 
MICRO, NSF (MIP 8715235), Sea­gate, Storage Tek, Sun Microsystems and Thinking Ma­chines Corporation 
for their support. This material is based in part upon work supported by the National Sci­ence Foundation 
under Infrastructure Grant No. CDA­8722788. References <RefA>[1] Francois Baccelli. Two parallel queues created 
by arrivals with two demands. Technical Report 426, INRIA Rocquencourt France, 1985. [2] Dina Bitton 
and Jim Gray. Disk shadowing. In Proc. Very Large Data Bases, pages 331-338, Au­gust 1988. [3] Peter 
M. Chen and David A. Patterson. Maximiz­ing performance in a striped disk array. In Proc. In­ternational 
Symposium on Computer Architecture, pages 322-331, May 1990. [4] L. Flatto and S. Hahn. Two parallel 
queues created by arrivals with two demands i. SIAM J. Appl. Math,, 44:1041-1053, October 1984. [5] Philip 
Heidelberger and Kishor S. Trivedi. Queue­ing network models for parallel processing with asynchronous 
tasks. IEEE Trans. on Computers, C-31:1099-11O9, November 1982. [6] Raj Jain. The Art of Computer Systems 
Perfor­mance Analysis. John Wiley &#38; Sons, Inc., 1991. [7] R. H. Katz, G. A. Gibson, and D. A. Patter­son. 
Disk system architectures for high perfor­mance computing. In Proc. IEEE, volume 77, pages 1842-1858, 
December 1989. [8] Michelle Y. Kim. Synchronized disk interleaving. IEEE Trans. on Computers, C-35:978-988, 
Novem­ber 1986. [9] Michelle Y. Kim and Asser N. Tantawi. Asyn­chronous disk interleaving. Technical 
Report RC12497, IBM, January 1987. [10] Edward K. Lee and Randy H. Katz. An analytic performance model 
of disk arrays and its applica­tion. Technical Report UCB/CSD 91/660, Univer­sity of California at Berkeley, 
November 1991. [11] Edward K. Lee and Randy H. Katz. Performance consequences of parity placement in 
disk arrays. In Proc. ASPLOS, pages 190-199, April 1991. [12] Miron Livny, S. Khoshafian, and H. Boral. 
Multi­disk management algorithms. In Proc. SIGMET-RIC S, pages 69-77, May 1987. [13] R. Nelson and A. 
N. Tantawi, Approximate analy­sis of fork/join synchronization in parallel queues. IEEE Trans. on Computers, 
37:739-743, June 1988. [14] David A. Patterson, Peter M. Chen, Garth Gibson, and Randy H. Katz. Introduction 
to redundant arrays of inexpensive disks (RAID). In Proc. IEEE C OMPCON, pages 112-117, Spring 1989. 
[15] David A. Patterson, Garth Gibson, and Randy H. Katz. A case for redundant arrays of inexpensive 
disks (RAID). In Proc. ACM SIGMOD, pages 109­116, June 1988. [16] A. L. Narasimha Reddy and Prithviraj 
Baner­jee. An evaluation of multiple-disk 1/0 systems. IEEE Trans. on Computers, 38: 1680 1690, Decem­ber 
1989. [17] K. Salem and H. Garcia-Molina. Disk striping. In Proc. IEEE Data Engineering, pages 336-342, 
February 1986. [18] J. Thisquen. Seek time measurements. Technical report, Amdahl Peripheral Products 
Division, May 1988.  </RefA>
			
