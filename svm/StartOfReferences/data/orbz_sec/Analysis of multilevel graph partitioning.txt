
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. SC 
'95, San Diego, CA &#38;#169; ACM 1995 0-89791-985-8/97/0011 $3.50 Analysis of Multilevel Graph Partitioning 
* GEORGE KARYPIS AND VIPIN KUMAR University of Minnesota, Department of Computer Science Minneapolis, 
MN 55455 {karypis, kumar}@cs.umn.edu Abstract Recently, a number of researchers have investigated a 
class of algorithms that are based on multilevel graph partitioning that have moderate computational 
complexity, and provide excellent graph partitions. However, there exists little theoretical analysis 
that could explain the ability of multilevel algorithms to produce good partitions. In this paper we 
present such an analysis. We show under certain reasonable assumptions that even if no re.nement is used 
in the uncoarsening phase, a good bisection of the coarser graph is worse than a good bisection of the 
.ner graph by at most a small factor. We also show that for planar graphs, the size of a good vertex-separator 
of the coarse graph projected to the .ner graph (without performing re.nement in the uncoarsening phase) 
is higher than the size of a good vertex-separator of the .ner graph by at most a small factor. *This 
work was supported by IST/BMDO through Army Research Of.ce con­tract DA/DAAH04-93-G-0080, and by Army 
High Performance Computing Re­search Center under the auspices of the Department of the Army, Army Re­search 
Laboratory cooperative agreement number DAAH04-95-2-0003/contract number DAAH04-95-C-0008, the content 
of which does not necessarily re­.ect the position or the policy of the government, and no of.cial endorse­ment 
should be inferred. Access to computing facilities were provided by Minnesota Supercomputer Institute, 
Cray Research Inc, and by the Pittsburgh Supercomputing Center. Related papers are available via WWW 
at URL: http://www.cs.umn.edu/users/kumar/papers.html  1 Introduction Graph partitioning is an important 
problem that has extensive applica­tions in many areas, including scienti.c computing, VLSI design, and 
task scheduling. The problem is to partition the vertices of a graph in p roughly equal parts, such that 
the number of edges connecting vertices in different parts is minimized. For example, the solution of 
a sparse system of linear equations Ax = b via iterative methods on a parallel computer gives rise to 
a graph partitioning problem. A key step in each iteration of these methods is the multiplication of 
a sparse matrix and a (dense) vector. Partitioning the graph that cor­responds to matrix A is used to 
signi.cantly reduce the amount of communication [11]. If parallel direct methods are used to solve a 
sparse system of equations, then a graph partitioning algorithm can be used to compute a .ll reducing 
ordering that lead to high degree of concurrency in the factorization phase [11, 4]. The graph partitioning 
problem is NP-complete. However, many algorithms have been developed that .nd reasonably good partitions. 
Spectral methods [17, 7] have been shown to be quite effective for partitioning unstructured problems 
in a variety of applications, but have very high computational complexity. The MSB algorithm pro­duces 
partitions that are as good as those produced by the original spectral bisection, but it is one to two 
orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach 
[1]. Geometric partition methods [5, 15, 16] are quite fast but they often provide worse partitions than 
those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only 
if coordinate information for the graph is available. Recently, a number of researches have investigated 
a class of al­gorithms that have moderate computational complexity, and provide excellent (even better 
than spectral) graph partitions [3, 7, 9]. The basic idea behind these algorithms is very simple. The 
graph G is .rst coarsened down to a few hundred vertices, a bisection of this much smaller graph is computed, 
and then this partition is projected back towards the original graph (.ner graph) by periodically re.ning 
the partition. Since the .ner graph has more degrees of freedom, such re.nements usually decrease the 
edge-cut. These are called multilevel graph partitioning schemes. In particular, in [9, 10] we have developed 
a multilevel graph partitioning scheme that produces high quality partitions in small amount of time. 
Our algorithm pro­duces partitions that are 10% to 60% better than those produced by spectral partitioning 
algorithms [17, 1], and 5% to 30% than those produced by other multilevel algorithms [7]. Furthermore, 
our algo­rithm is 10 to 40 times faster than multilevel spectral bisection (as implemented in the Chaco 
graph partitioning package [6]), and 2 to 6 times faster than the multilevel algorithm of [7]. We also 
used our multilevel graph partitioning scheme to compute .ll reducing order­ings for sparse matrices 
[9]. Surprisingly, our scheme substantially outperforms the multiple minimum degree algorithm [13], which 
is the most commonly used method for computing .ll reducing orderings of a sparse matrix. From the experiments 
presented in [9, 3, 7], it is clear that multilevel graph partitioning algorithms are able to .nd high 
quality partitions for a variety of unstructured graphs. However, there exists little the­oretical analysis 
that could explain the ability of multilevel algorithms to produce good partitions. In this paper we 
present such an analy­sis. We show under certain reasonable assumptions that even if no re.nement is 
used in the uncoarsening phase, a good bisection of the coarser graph is worse than a good bisection 
of the .ner graph by at most a small factor. We also show that the size of a good vertex­separator of 
the coarse graph projected to the .ner graph (without performing re.nement in the uncoarsening phase) 
is higher than the size of a good vertex-separator of the .ner graph by at most a small factor. 2 Multilevel 
Graph Bisection In this section we brie.y describe the various phases of the multilevel algorithm. The 
reader should refer to [9] for further details. Coarsening Phase During the coarsening phase, a sequence 
of smaller graphs Gi = (Vi, Ei ), is constructed from the original graph G0 = (V0, E0) such that |Vi 
| > |Vi+1|. Graph Gi+1 is constructed from Gi by .nding a maximal matching Mi . Ei of Gi and collapsing 
together the vertices that are incident on each edge of the matching. In this process no more than two 
vertices are collapsed together because a matching of a graph is a set of edges, no two of which are 
incident on the same vertex. Vertices that are not incident on any edge of the matching, are simply copied 
over to Gi+1. When vertices v,u . Vi are collapsed to form vertex w . Vi+1,the weight of vertex w is 
set to be equal to the sum of the weights of vertices v and u, while the edges incident on w is set equal 
to the union of the edges incident on v and u minus the edge (v,u). If there is an edge that is incident 
to both on v and u, then the weight of this edge is set equal to the sum of the weights of these edges. 
Thus, during successive coarsening levels, the weight of both vertices and edges increases. Maximal matchings 
can be computed in different ways [9]. The method used to compute the matching greatly affects both the 
quality of the bisection, and the time required during the uncoarseningphase. Here we brie.y describe 
two such matching schemes. The .rst scheme, which we called random matching (RM), com­putes the maximal 
matching by using a randomized algorithm [3, 7]. The RM scheme works as follows. The vertices of the 
graph are visited in random order. If a vertex u has not been matched yet, then an unmatched adjacent 
vertex v is randomly selected and the edge (u,v)is included in the matching. The second scheme, which 
we call heavy-edge matching (HEM), computes a matching Mi , such that the weight of the edges in Mi is 
high. The HEM matching is com­puted using a randomized algorithm similar to the one used for RM. The 
vertices are again visited in random order. However, instead of randomly matching a vertex with one of 
its adjacent unmatched ver­tices, HEM matches it with the unmatched vertex that is connected with the 
heavier edge. As a result, the HEM scheme reduces the sum of the weights of the edges in the coarser 
graph by a larger amount than RM. In [9], we experimentally evaluated both the RM and HEM matching schemes, 
and we found that the HEM scheme produces consistently better results than RM, and the amount of time 
spent in re.nement is less than that of RM. Initial Partitioning Phase The second phase of a multilevel 
al­gorithm is to compute a balanced bisection of the coarsest graph Gk = (Vk,Ek ). An evaluation of different 
algorithms for partitioning the coarser graph can be found in [9]. Uncoarsening Phase During the uncoarsening 
phase, the partition of the coarsest graph Gk is projected back to the original graph by going through 
the graphs Gk-1,Gk-2 ,...,G1. Furthermore, even if the partition of Gi is at a local minima, the partition 
of Gi-1 obtained by this projection may not be at a local minima. Hence, it may still be possible to 
improve the the partition of Gi-1 obtained by the projection by using local re.nement heuristics. For 
this reason, a partition re.nement algorithmisused. Anumberofre.nementalgorithmsareinvestigated in [9], 
that signi.cantly improve the quality of the projected partition. Matrix Name No. of Vertices No. of 
Edges Description 3ELT 4720 13722 2D Finite element mesh 4ELT 15606 45878 2D Finite element mesh BCSSTK31 
35588 572914 3D Stiffness matrix BRACK2 62631 366559 3D Finite element mesh WAVE 156317 1059331 3D Finite 
element mesh WHITAKER3 9800 28989 2D Finite element mesh Table 1: Various matrices used in evaluating 
the multilevel graph partitioning and sparse matrix ordering algorithm. 3 Analysis The central theme 
of the analysis is as follows. If the graph is coarsen perfectly , then the coarsest graph will be an 
exact replica of the .ner (original) graph except that it will be smaller. Hence, an optimal bisec­tion 
of this coarsest (smaller) graph will also be an optimal bisection of the .ner graph. If the graph has 
been coarsened (using a perfect coarsening scheme) enough times, then it becomes small enough that we 
can .nd a near-optimal bisection in a reasonable amount of time. This near-optimal bisection of the coarsest 
graph will also be a good bisection of the original graph. If the coarsening scheme is not good, then 
it is entirely possible that a near-optimal bisection of the coarsest graph is an arbitrarily bad bisection 
of the .ner (original) graph. The matching strategies (RM and HEM) used in our multilevel algorithm do 
not lead to optimal coarsening. Hence, a near-optimal bisection of the coarsest graph obtained using 
RM or HEM, is not guaranteed to be a near-optimal bisection of the .ner graph. The analysis in Section 
3.2 shows that under some reasonable assump­tions, the edge-cut of a near-optimal bisection of the coarser 
graph is larger than the edge-cut of a near-optimal bisection of the .ner graph only by a small constant 
factor. The analysis also motivates why this penalty factor is even smaller when the HEM scheme is used 
(instead of RM). Similarly, if the graph is coarsened perfectly, then a near-optimal vertex separator 
of the coarser graph can be projected to the .ner graph to construct a near-optimal separator of the 
.ner graph. As for the case of the edge-cut, if the coarsening scheme is not good, then the projected 
separator of the coarser graph can lead to an arbitrarily bad separator of the .ner graph. The vertex-separator 
analysis in Section 3.3 shows that under reasonable assumptions, the projection of a near-optimal separator 
of the coarser graph leads to a separator for the .ner graph that is worse than a near-optimal separator 
(for the .ner graph) only by a small constant factor. Both of these analyses show that even if no re.nement 
is performed during the uncoarsening phase, the bisection of the coarsest graph is also a good bisection 
of the original graph, especially if HEM is used for coarsening. These observations are supported by 
experimental results in both cases. 3.1 De.nitions and Assumptions Analyzing the quality of the bisections 
produced by multilevel graph partitioning algorithms is particularly hard, and can only be done if certain 
assumptions are made about the original graphs and the coarsening process. In the rest of this section 
we present these as­sumptions and some notation that will be used throughout the analy­sis. Let G0 =(V0,E0)be 
the original graph, and Gi =(Vi,Ei )be the ith level coarser graph. For each graph Gi ,let W(Mi )be the 
sum of the weights of the edges in the matching used to obtain Gi+1, W(Ei ) be the sum of the weights 
of the edges, .i be the average edge­weight, di be the average degree of a vertex, and Ci be the size 
of the edge-cut (i.e., the weight of the edges crossing parts). To simplify the presentation of the analysis 
we assume that at each successive level of coarsening, the number of vertices reduce by a factor of two1 
, i.e., |Vi |=2|Vi+1|. Consequently, the matching at level i contains |Vi |/2 edges; hence, the weight 
of the matching is equal to W(Mi )=d.i |Vi|/2, where dis a constant that captures the properties of RM 
and HEM. In particular, d=1 for RM (because the matched edges in RM are chosen randomly), and d=1 for 
HEM (because the HEM prefers edges with higher weight). Also, to simplify the analysis we assume that 
the average degree of the successive coarser graphs changes at a constant rate, i.e., di /di+1 =ß. Note 
that if ß<1,the average degree increases, if ß>1 the average degree decreases, and if ß=1 the average 
degree remains the same. In the rest of the analysis we assume that the following are true. Assumption 
1 (Small Separators) There are constants a and . such that each graph Gi has a balanced separator of 
size less than or equal to a|Vi |. . Assumption 2 (Size of the Edge-Cut) The edge-cut of Gi is pro­portional 
to adi .i |Vi |. . That is, Ci is proportional to the size of the balanced separator, the averagedegree 
of the graph, and the average weight of each edge. In the case of graphs arising in .nite element applications, 
the small separator assumption is true. In particular, for planar graphs .=0.5 [12], and for the graphs 
that correspond to 3D .nite element meshes, . = 2/3 [15]. Assumption 2 follows directly from Assumption 
1 if the successive coarser graphs have constant bounded degree2.The edge-cut in Assumption 2 corresponds 
to the bisection in which the separator is the boundary of one of the two parts. 1The analysis will go 
through if we assume that the number of vertices reduces by a constant factor. This assumption appears 
to be valid for well-shaped .nite element meshes, as from our experiments we know that for most coarsening 
levels somewhere between 85% to 95% of the vertices get matched. RM tends to match more vertices than 
HEM, but the difference between them is small (less than 5%) for most coarsening levels. 2Graphs that 
correspond to 2D and 3D .nite element meshes have bounded degree. In the coarsening process due to randomization, 
the degrees remain bounded even for the coarser graphs. Due to the bounded degree, the edge­cut of these 
graphs cannot be smaller asymptotically, because it will lead to an asymptotically smaller vertex separator. 
 3.2 Edge-Cut Analysis The multilevel algorithm can be viewed as an approximation algo­rithm since every 
successively coarse graph becomes a succes­sively rougher approximation of the original graph. Since 
more and more features of the original graph are eliminated in this process, the coarser graphs have 
bisections with larger edge-cut than the original graph. It is natural to ask how bad can the edge-cut 
of the coarser graph get with respect to the edge-cut of the original graph. In par­ticular the following 
theorem is true [8]. Theorem 1 The size of the edge-cut for graph Gi for i = 1 is i-1 dß Ci . 21-. 1 
- Ci-1 . (1)d0 Equation 1 reveals signi.cant information about the quality of edge­cut when it is computed 
at a coarse graph. In particular, for a given graph, the increase in the edge-cut between successive 
coarse graphs decreases as either dor ßincreases. That is, if the weight of the edges in the independent 
set used to coarsen the graph is much higher than the average weight of the edges (d>1), then the penalty 
paid for .nding a partition at the coarse graph is smaller. Sim­ilarly, as the average degree of the 
coarse graph decreases (ß>1), again the increase of the edge-cut at the coarse graph is smaller. In the 
next two sections we see how Equation 1 applies to graphs that correspond to 2D and 3D .nite element 
meshes with triangular and tetrahedron elements, respectively. 3.2.1 2D Finite Element Meshes The 2D 
.nite elements meshes correspond to planar graphs. Fur­thermore, when the elements of the mesh are triangles 
(e.g., when the .nite element mesh is generated using Delaunay triangulation), then the graph that corresponds 
to the interior of the mesh is maxi­mally planar. For the rest of this section we use this correspondence 
and we only concentrate on maximally planar graphs. Planar graphs have been extensively studied and a 
great deal of properties are known about them. In particular, for maximally planar graphs .= 0.5 [12], 
and d0 6. Also, in [12] it was shown that edge contraction also preserves maximal planarity; thus, ß= 
1. From Equation 1, and for RM (i.e., d= 1), we have that C2D-RM . 1.18C2D-RM = 1.18iC0. (2) ii-1 Thus, 
the edge-cut increases only by 18% at each successive coarsening level. For instance, the edge-cut after 
10 coarsening levels is only 5.2 times worse than the edge-cut of the original graph. However, the size 
of G10 is smaller than G0 by a factor of 1024, so it is much quicker to .nd a good partition of G10 than 
of G0. As discussed in Section 3.2, the increase in the edge-cut at successive coarsening levels is smaller 
when HEM is used, because in this case d>1. 3.2.2 3D Finite Element Meshes The graphs that correspond 
to 3D .nite element meshes do not correspond to any extensively studied class of graphs as the 2D .nite 
element graphs did. Nevertheless, for these type of graphs it is known that .= 2/3 [15] and that for 
most .nite element applicationsd0 ranges between 12 and 16 [2]. However, in order to apply Equation 1, 
we need to know the value of ß. Unlike maximally planar graphs, for which the average degree of successive 
coarser graphs remains the same, the average degree of 3D .nite element graphs does not always remain 
the same. In particular, if d0 >12, and RM is used to coarsen the graph, di increases in successive coarser 
graphs. However, if HEM is used to coarsen the graph, then the average degree of the graph actually decreases 
in successive coarsening levels as discussed later. In particular, for 3D .nite element meshes, the following 
theorem holds for the RM matching scheme [8]. Theorem 2 (Average Degree of 3D Graphs) The averagedegreeof 
the interior vertices of the ith level coarser graph Gi, of a graph G0 that corresponds to a 3D .nite 
element mesh with tetrahedron elements is 12 di = 2 di-1 - 7 + . (3)di-1 From Equation 3 we have that 
when d0 = 12, di = 12 for all coarse graphs. However, if d0 <12, di decreases whereas if d0 > 12, di 
increases at each successive coarse graph. Thus, when d0 = 12, ß= 1, and from Equation 1 we have that 
the edge-cut for 3D .nite element graphs when RM is used to coarsen the graph (i.e., d= 1)is C3D-RM . 
1.15C3D-RM = 1.15iC3D-RM . (4) ii-10 Comparing this equation with Equation 2, we see that the increase 
in the edge-cut at successive coarsening levels is smaller for 3D graphs than it is for 2D graphs. As 
it was the case with 2D graphs, the increase in the edge-cut is small, compared to the reduction in the 
graph size. If HEM is used to coarsen the graph, then d>1, and the decrease in quality is even smaller. 
The increase in the average degree of the graph can be controlled if coarsening is done in a certain 
way. In proving Equation 3, we assumed that each edge in the matching is such that the number of triangular 
phases incident on it is equal to the average. This assumption is valid when RM is used to coarsen the 
graph which randomly selects unmatched edges. However, the HEM matching scheme tends to select edges 
that have a large number of triangular phases incident on them. As a result, the average degree di of 
the coarse graphs produced by HEM will be smaller [8]. In fact, our experiments show the average degrees 
of the coarse graphs produced by HEM not only do not increase but they actually decrease. 3.2.3 Experimental 
Results To verify the analysis presented in Sections 3.2.1 and 3.2.2, we instrumented our multilevel 
algorithm to report various statistics dur­ing coarsening. In the rest of this section we present results 
for the following four matrices: 4ELT is a 2D .nite element mesh; BRACK2 and WAVE are 3D .nite element 
meshes. This set of matrices is a representative sample of the matrices shown in Table 1. 4ELT 300  
   HEM RM 2200 270 1980 240 1760 210 1540 180 1320 150 1100 120 880 90 660 60 440 30 220 0 0 0 1 
2 3 4 5 6 7 012345678 012345678910 Coarsening Level Coarsening Level Coarsening Level Figure 1: The increase 
in the edge-cut at successive coarsening levels. Figure 1 shows the edge-cut Ci for successive coarsening 
levels for both the RM and HEM coarsening schemes. The edge-cut at the ith level was obtained by performing 
i coarsening levels to obtain Gi , and then using our multilevel algorithm to .nd a good partition of 
this coarser graph. The plotted value of Ci is the minimum of the edge­cuts produced by the multilevel 
algorithm and SB. From this graph we see that as indicated by our analysis, for all four matrices, the 
edge­cut Ci increases slowly at successive coarsening levels. When RM is used to coarsen the graphs, 
the edge-cut at the last coarsening level is only 1.8, 2.4, 2.9, and 4.2 times worse than C0 for 4ELT, 
BRACK2, andWAVErespectively. Thisincreaseintheedge-cutisactuallylower than the one predicted by the analysis. 
This should not be surprising since Equation 1 is only an upper bound. Also, from Figure 1 we see that 
when HEM is used to coarsen the graph, the edge-cuts at the coarser graphs and their rate of increase 
at successive coarsening levels are smaller than those of the RM coarsening scheme. This is also predicted 
by our analysis since for HEM, d>1. Furthermore, for 3D .nite element meshes, HEM tends to decrease the 
average degree of the graph with successive coarsening levels as shown in  Edge-Cut Figure 2. 4ELT BRACK2 
WAVE Average Degree 8 7 6 5 4 3 2 1 0 14 12 10 8 6 4 2 0 24 21 18 15 12 9 6 3 0 0 1 2 3 4 5 6 7 012345678 
012345678910 Coarsening Level Coarsening Level Coarsening Level Figure 2: The average degrees at successive 
coarsening levels. Figure 2 shows the average degree of the graphs at successive coarsening levels for 
both RM and HEM. For 4ELT, we see that for both coarsening schemes, the average degrees are similar and 
they slowly decrease. This decrease is due to the boundary elements of the mesh. However, for the 3D 
.nite element meshes (BRACK2 and WAVE), the averagedegree of the graphswhen RM is used to coarsen them, 
increases at successive coarsening levels. This is consistent with the analysis presented in Section 
3.2.2, which indicated that the average degree of 3D .nite element meshes increases when RM is used. 
Also, comparing the degrees of BRACK2 and WAVE, we see that the degrees increase at a higher rate if 
d0 is high. This again follows directly from Equation 3. However, the increase in the average degree 
of the graph tappers off after a number of coarsening levels because of the boundary elements (like it 
was for the 2D case). Our analysis in Section 3.2.2 also predicted that if HEM is used to coarsen the 
graph, then the average degree of 3D .nite element meshes will increase at a slower rate than RM. This 
is clearly illus­trated in Figure 2. The average degree of the graph increases for the 1st level coarser 
graph (d1) because HEM and RM are equivalent for the .rst coarsening level (initially all edges have 
weight of one). The average degree of subsequent coarser graphs, not only do not increase but actually 
they decrease quite substantially. The advan­tages of the decreasing average degree can be seen by comparing 
the edge-cut of RM and HEM at the coarsest graph for BRACK2 and WAVE. For instance, at the last coarsening 
level, the HEM edge-cut for WAVE is only 1.8 times higher while the RM edge-cut is 2.9 times higher. 
Finally, Figure 3 shows the average weight of the adjacency list of a vertex for successive coarsening 
levels. Recall that the average weight of the adjacency list at the ith level is equal to di .i and from 
Assumption 2 it is directly related to the edge-cut of the graph. From Figure 3 we see that for all four 
matrices, the weight of the adjacency 4ELT BRACK2 WAVE Weight of Adjacency List 80 70 60 50 40 30 20 
10 0 450 400 350 300 250 200 150 100 50 0 2700 2400 2100 1800 1500 1200 900 600 300 0  0 1 2 3 4 5 
6 7 012345678 012345678910 Coarsening Level Coarsening Level Coarsening Level Figure 3: The average weight 
of the adjacency lists at successive coarsening levels. The weight of the adjacency list at level i is 
di .i . lists when HEM is used to coarsen the graph is smaller than that for RM.  3.3 Vertex Separator 
Analysis In the previous section we showed that the edge-cut of the coarser graph is higher than the 
edge-cut of the original graph G0 by a small factor. Consequently, from Assumption 2, this implies that 
the vertex separator induced by the bisection of the coarser graph is larger than the separator of the 
original graph by a small factor. In this section we analyze the coarsening process by looking at the 
vertex separators. In particular, we will show that the vertex separator obtained in the coarse graph 
is also a small vertex separator in the original graph. This analysis is focused on maximal planar graphs 
that satisfy the assumptions in Section 3. Furthermore, it is assumed that the sepa­rator forms a simple 
path or cycle [14]. This analysis can be extended to the graphs that correspond to 3D .nite element meshes, 
when the separators are simple surfaces. Consider the kth level coarse graph Gk =(Vk, Ek ). From the 
small separator assumption, we know that Gk has a separator Sk that con­ v tains no more than a |Vk |vertices 
(recall that . = 0.5 for planar graphs [12]). Let S0bbe the union of the vertices of Sk projected to 
G0. S0bforms a balanced separator of G0 and its size is v |S0b|=2k |Sk|=a2k|Vk|=a2k|V0|/2k =a( 2)k|V0|. 
However, applying the small separator assumption to the original v graph, the size of the separator of 
G0 is |S0|=a |V0|. In the limiting vv case, when k = O(log |V0|), wehavethat ( 2)k =|V0|,in which v case 
|S0b|=O(|V0|). Thus, S0bcontains O( |V0|) more vertices than a small separator. However, not all the 
vertices in S0bare required to form a separator for G0, and a smaller separator can be constructed from 
S0bby dropping some vertices. Figure 4 illustrates the basic idea behind the processes of vertex dropping. 
In this .gure, the 1st level coarser graph is constructed (c) Coarse Graph (a) Original Graph (b) Random 
Matching (e) Projected Separator (d) Coarse Separator (f) Dropping of Vertices (g) Refined Separator 
 Figure 4: The sequence of one level coarsening, .nding a separator for the coarse graph, projecting 
the separator to the original graph, and re.ning the separator by dropping vertices. using RM, and a 
separator of this coarse graph is computed (Fig­ure 4(d)). Figure 4(e) shows the projected separator 
S0 b that corre­sponds to S1. Note that not all the vertices of S0 b are necessary to form a separator 
for G0. As Figure 4(f) illustrates certain vertices can be dropped. In the rest of this section we compute 
the average number of vertices being dropped in successive uncoarsening levels. Consider the graph G1, 
and let P1 be a simple path or cycle of G1. Let F be the subgraph of G0 induced by the vertices of P1 
projected onto graph G0. The subgraph F contains 2|P1| vertices, and on the average these vertices do 
not form a simple path or cycle. Lemma 1 (Path Projection for Planar Graphs) Let G1 be a one level coarse 
graph obtained from G0 using random perfect coarsening, and let P1 be a simple path of G1, between vertices 
u1 and v1. Let F be the subgraph of G0 that has P1 as its minor, and let u0 and v0 be the vertices of 
F that are mapped onto u1 and v1 respectively. On the average, the shortest path between u0 and v0 in 
F contains less than 1.5|P1| vertices [8]. The path projection lemma is very powerful and can be used 
to compute the size of the projected separator as a function of the sep­arator of the coarser graph. 
Furthermore, as the next lemma shows, it can also be used to show that the sub-optimality of a separator 
at a coarser graph, decreases as this separator is projected to succes­sively .ner graphs. Lemma 2 (Simple 
Separator for Planar Graphs) Let Gk be the k level coarse graph obtained from G0 using random matching. 
There is a separator for G0 whose size is bounded by f0.75k|V0|for some constant f [8]. The simple separator 
lemma is interesting when we consider the case in which k =O(log n). In this case, the separator for 
G0 is bounded by |S0|=f0.75k |V0|=f0.75log |V0||V0|=f|V0|log 0.75|V0|=f|V0|0.59 . Thus, even though the 
separator of Gk contained O(|Vk |) vertices, this same separator when it is projected onto the original 
graph contains only O(|V0|0.59) vertices. Hence, if k is suf.ciently large, a suboptimal separator of 
Gk does not signi.cantly affect the size of the separator of the graph G0. 3.3.1 The Nature of a Good 
Separator The key element in the proof of the path projection lemma is that the edge-weight of the path 
in question was average. This is certainly true for any simple path but is it true for a separator path 
as well? The answer to this question depends on the algorithm used to compute the vertex separator. In 
the multilevel algorithm, the vertex separator is computed as being the path along the boundary of the 
bisection. Since, the bisection is computed so that the number of edges crossing the two parts is minimized, 
it is not unreasonable to assume that an equal or larger amount of edge-weight does not cross the boundary. 
Because of this, the separator path obtained from the partition boundary should have on the average at 
least as much weight as any other path. Our experimental results verify this observation. In fact, for 
all coarsening schemes, if we look at the number of vertices as being projected from a coarse graph to 
the next level .ner graph, the in­crease in the separator size is almost always bounded by 1.5. Hence, 
assuming that the edge-weight of the separator path is no less than that of any other path, the following 
lemma is true. Lemma 3 The separator of G0 obtained by projecting the separator v of Gk is bounded by 
a(1.06)k|V0|[8]. 3.3.2 Experimental Results To verify the correctness of Lemmas 1, and 3 we performed 
exper­iments with three different planar graphs that have triangular faces. As we did throughout the 
analysis in this section, each vertex vi .Vi is treated as a single vertex, irrespective of its weight. 
Furthermore, the separators were computed as the vertices of the .rst part that lay along the boundary 
of the bisection. That is, if V0 is bisected into A and B, then the set Ab. A of vertices that are connected 
to some vertices of B is taken as the separator. 3ELT 4ELT WHITAKER3 Separator Size 150 135 120 105 90 
75 60 45 30 15 0 200 180 160 140 120 100 80 60 40 20 0 110 100 90 80 70 60 50 40 30 20 10 0 1 2 3 
4 5 6 7 8 123456789 123456789 UnCoarsening Level UnCoarsening Level UnCoarsening Level Figure 5: The 
increase in the number of nodes in the separator at successive uncoarsening levels. Figure 5 shows how 
the size of the separator increases at succes­sive coarsening levels. For each matrix, three curves are 
shown. The two of them, labeled RM and HEM, correspond to random matching and heavy-edge matching with 
no re.nement during the uncoarsen­ing phase, while the one labeled HEM-R, corresponds to heavy-edge with 
boundary greedy re.nement [9]. From this graph, we see that at successive uncoarsening levels, the size 
of the separator increases by a factor smaller than 2. For example, when RM is used for 4ELT, going from 
the 7th to the 8th uncoarsening level, the separator in­creases from 92 to 135 vertices an increase by 
a factor of 1.47. Furthermore, comparing RM with HEM, we have that HEM consis­tently produces smaller 
separators, which is not surprising, since HEM .nds bisections with smaller edge-cuts (Section 3.2). 
Also, when boundary re.nement is used (HEM-R), the size of the .nal separator is much smaller, and tends 
to increase at a lower rate. Note that for all the graphs in Figure 5, the size of the separator increases 
much slower than 1.5 for the .rst few coarsening levels. This is because the size of the graphs during 
these last levels does not decrease very fast. For this reason we constructed the graphs shown in Figure 
6. In this .gure, for each graph and matching scheme we plotted the relative increase of the size of 
the separator for successive uncoarsening levels, over the size of the initial separator. Also, for each 
graph and matching scheme we computed the ideal relative v increase so that the a |Vi | bound is maintained 
[8]. Since, RM and HEM lead to coarser graphs that have slightly different number of vertices (i.e., 
the maximal matching computed by RM and HEM are not of the same size), each matching scheme has a different 
ideal 3ELT 4ELT WHITAKER3 12 16  11 14 10 10 9 9 12 8 8 10 7 7 6 6 8 5 5 6 4 4 3 3 4 2 2 2 1 1 0 
0 0 1 2 3 4 5 6 7 8 123456789 123456789 12 12 16 Separator Size Separator Size  14 10 10 9 9 12 8 8 
10 7 7 6 6 8 5 5 6 4 4 3 3 4 2 2 2 1 1 0 0 0 1 2 3 4 5 6 7 8 123456789 123456789 UnCoarsening Level 
UnCoarsening Level UnCoarsening Level 11 Figure 6: The rate of increase of the separator compared to 
the ideal increase. curve. From these graphs we see that, the overall rate of increase in the size of 
the separator is worse than the ideal increase. However, the difference is usually very small. The graph 
for WHITAKER3 is particularly interesting, because both RM and HEM lead to a relatively high increase 
(a factor of two) in the size of the separator over the ideal increase. The reason for that, is that 
the initial separator of WHITAKER3 is actually quite small compared to the size of the graph. In particular, 
the coarsest graph for RM has 88 vertices while the separator has 7, and the coarsest graph for HEM has 
118 vertices while the separator has only 6. Consequently, vertices cannot be dropped at the rate dictated 
by the ideal curve, since it will lead to separators that are contradictory small. BRACK2 WAVE BCSSTK31 
9000 1800  8000 1600 800 7000 1400 700 6000 1200 600 5000 1000 500 4000 800 400 3000 600 300 2000 400200 
100 1000 200 0 0 0 Separator Size Figure 7: The rate of increase of the separator for 3D .nite element 
meshes. Finally, Figure 7 shows how the size of the separator increases at successive uncoarsening levels 
for graphs that correspond to 3D .nite element meshes. As it was the case for planar graphs, the size 
of the separator decreases by a factor smaller than two at each successive uncoarsening level. Also, 
HEM .nds smaller separators at the coarsest graph, and the size of the separator increases at a slower 
rate than RM. Also, in the case of HEM-R, the size of the separator increases very slowly. For 3D graphs, 
the ideal increase of the separator size should be 20.75 1.68 at each successive un­coarsening level. 
From these graphs, we that the rate of increase is usually higher than that by a small factor. For instance, 
in the case of BCSSTK31 and RM, going from the 9th to the 10th uncoarsening level, the separator increased 
from 989 vertices to 1698 vertices, an increase by a factor of 1.72.  References <RefA>[1] Stephen T. Barnard 
and Horst D. Simon. A fast multilevel implementation of recursive spectral bisection for partitioning 
unstructured problems. In Pro­ceedings of the sixth SIAM conference on Parallel Processing for Scienti.c 
Computing, pages 711 718, 1993. [2] Timothy J. Barth. Aspects of unstructured grids and .nite-volume 
solvers for the euler and navier-strokes equations. In AGARD Report 787 on Unstructured Grid Methods 
for Advection Dominated Flows, pages 6.1 6.60, 1992. [3] T. Bui and C. Jones. A heuristic for reducing 
.ll in sparse matrix factorization. In 6th SIAM Conf. Parallel Processing for Scienti.c Computing, pages 
445 452, 1993. [4] A. George and J. W.-H. Liu. Computer Solution of Large Sparse Positive De.nite Systems. 
Prentice-Hall, Englewood Cliffs, NJ, 1981. [5] M. T. Heath and P. Raghavan. A Cartesian nested dissection 
algorithm. Tech­nical Report UIUCDCS-R-92-1772, Department of Computer Science, Uni­versity of Illinois, 
Urbana, IL 61801, 1992. To appear in SIAM Journal on Matrix Analysis and Applications, 1994. [6] Bruce 
Hendrickson and Rober Leland. The chaco user s guide, version 1.0. Technical Report SAND93-2339, Sandia 
National Laboratories, 1993. [7] Bruce Hendrickson and Rober Leland. A multilevel algorithm for partitioning 
graphs. Technical Report SAND93-1301, Sandia National Laboratories, 1993. [8] G. Karypis and V. Kumar. 
Analysis of multilevel graph partition­ing. Technical Report TR 95-037, Department of Computer Science, 
University of Minnesota, 1995. Also available on WWW at URL http://www.cs.umn.edu/users/kumar/papers/mlevel 
analysis.ps. [9] G. Karypis and V. Kumar. A fast and high quality multilevel scheme for partition­ing 
irregular graphs. Technical Report TR 95-035, Department of Computer Science, University of Minnesota, 
1995. Also available on WWW at URL http://www.cs.umn.edu/users/kumar/papers/mlevel serial.ps. A short 
version appears in Intl. Conf. on Parallel Processing 1995. [10] G. Karypis and V. Kumar. METIS: Unstructured 
graph partitioning and sparse matrix ordering system. Technical report, Department of Computer Sci­ence, 
University of Minnesota, 1995. Available on the WWW at URL http://www.cs.umn.edu/users/kumar/metis/metis.html. 
[11] Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. Intro­duction to Parallel Computing: 
Design and Analysis of Algorithms. Ben­jamin/Cummings Publishing Company, Redwood City, CA, 1994. [12] 
R. J. Lipton and R. E. Tarjan. A separator theorem for planar graphs. SIAM Journal on Applied Mathematics, 
36:177 189, 1979. [13] J. W.-H. Liu. Modi.cation of the minimum degree algorithm by multiple elimi­nation. 
ACM Transactions on Mathematical Software, 11:141 153, 1985. [14] G. L. Miller. Finding small simple 
cycle separators for 2-connected planar graphs. Journal of Computer and system Sciences, 32(3):265 279, 
June 1986. [15] Gary L. Miller, Shang-Hua Teng, W. Thurston, and Stephen A. Vavasis. Au­tomatic mesh 
partitioning. In A. George, John R. Gilbert, and J. W.-H. Liu, editors, Sparse Matrix Computations: Graph 
Theory Issues and Algorithms. (An IMA Workshop Volume). Springer-Verlag, New York, NY, 1993. [16] B. 
Nour-Omid, A. Raefsky, and G. Lyzenga. Solving .nite element equations on concurrent computers. In A. 
K. Noor, editor, American Soc. Mech. Eng, pages 291 307, 1986. [17] Alex Pothen, Horst D. Simon, and 
Kang-Pu Liou. Partitioning sparse matrices with eigenvectors of graphs. SIAM Journal of Matrix Analysis 
and Applications, 11(3):430 452, 1990. Bibliographical Sketch of George Karypis George Karypis received 
the B.S. degree in Computer Science from University of Minnesota, Minneapolis, in 1992. College Park, 
in 1982. He is currently pursuing a Ph.D. degree in Computer Science at the University of Minnesota. 
His current research interests include parallel algorithms for scienti.c computing, communi­cation libraries, 
and scalable parallel libraries. He is author of over 10 research articles, and is a coauthor of a text 
book Introduction to Parallel Computing" (Publ. Benjamin Cummings/Addison Wesley, 1994). Recent publication 
can be found at http://www.cs.umn.edu/ karypis. </RefA>Bibliographical Sketch of Vipin Kumar Vipin Kumar received 
the B.E. degree in electronics &#38; communication engineering from University of Roorkee, India, in 
1977; the M.E. degree in electronics engi­neering from Philips International Institute, Eindhoven, Netherlands, 
in 1979; and the Ph.D. degree in computer science from University of Maryland, College Park, in 1982. 
He is currently a Professor of Computer Science at the University of Minnesota. His current research 
interests include scalable parallel computing and arti.cial intelligence. He is author of over 80 research 
articles on the above top­ics, and is a coauthor of a text book Introduction to Parallel Computing" (Publ. 
Benjamin Cummings/Addison Wesley, 1994). Kumar has chaired many workshops and served on the program committee 
of many conferences in parallel processing. He is Vice Chair for Applications Area for the 9th International 
Parallel Processing Symposium. Kumar serves on the editorial boards of IEEE Parallel and Distributed 
Technology, IEEE Transactions of Data and Knowledge Engineering, and the Jour­nal of Parallel and Distributed 
Computing. http://www.cs.umn.edu/ kumar. Copyright &#38;#169; 1995 by the Association for Computing Machinery, 
Inc. (ACM). Permission to make digital or hard copies of part or all of this work for personal or classroom 
use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that new copies bear this notice and the full citation on the first page. Copyrights for 
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. 
To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific 
permission and/or a fee. Request permissions from Publications Dept, ACM Inc., via fax at +1 (212) 869-0481, 
or via email at permissions@acm.org.  
			
