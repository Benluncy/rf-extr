
 Algorithms for Symmetrical Polynomials Emi Lauer University of Kaiserslautern March 1976  Abstract 
 A special representation for symmetrical polynomials is introduced. Algorithms for the ring operations 
and for several ver- sions of Gauss" method to express an arbit- rary symmetrical polynomial by the elemen- 
tary symmetrical functions are given and analyzed. Empirical observations show that the representation 
which is the most eco- nomical in terms of space is not always the most economical in terms o~ time. 
 i. Introduction ^ Symmetrical functions play an important role in algebra and its applications. In 
particular, many proofs in the theory of algebraic numbers refer to them explicitly. Resultants [i] and 
Sturm sequences [2] can be generated as symmetrical functions. In practice, problems often are symmetri- 
cal in some if not all variables and one may ask how the general algorithms of a Computer Algebra system 
can take advan- tage of the additional structure A spe- cial set for symmetrical functions could even 
be helpful if only s out of r vari- ables are symmetrical. In the case of polynomials one can separate 
out the sym- metrical variables, say Xl,...,Xs, from the rest xs+l,...,x r, 2 ~ s < r, and perform 
polynomial operations in Ds[Xs+ 1 ..... Xr] with D s = D[Xl,...,Xs] using symmetrical arithmetic in 
the coefficient domain D s As a first step in this direction we have implemented an algorithm due 
to Gauss (section 2), an efficient algorithm for the generation of the elementary sym- metrical polynomials 
(section 3), and al- gorithms for arithmetical operations (sec- tion 4) where we also study the impact 
of a space saving representation on the com- puting times. Finally (section 6) we give some empirical 
results for different re- alizations of Gauss" algorithm and the arithmetic. 2. The Fundamental Theorem 
and the Gauss-Algorithm The fundamental theorem of symmetri- cal functions is of interest because 
of a constructive proof due to Gauss [i]. His proof is easily understood in terms of a distributive canonical 
polynomial repre- sentation which are actually used in alge- bra systems like ALTRAN [3]. A non-zero 
polynomial in r > o variables is an or- dered sequence of terms, each term consis- ting of a non-zero 
numerical coefficient and a monomial x I nl ...x~ r. The ordering is lexicographically decreasing on 
the expo- nent vectors (nl,...,nr). Fundamental Theorem Let P E Z[Xl,'-',x r] be a symmetrical polynomial. 
Then there exists a polynomial Q E Z[Y 1 ..... yr ] such that P(Xl,...,x r) = Q(ql '''''qr ) where. 
~'i is the. i-th elemen- tary functlon in the r varlables Xl,...,x r Gauss proved that the following 
algo- rithm produces the polynomial Q in fini- tely many steps. Q ÷ GAUSS(P) [The notations are those 
of the Fundamen- tal Theorem.] (i) Construct Ol,...,Or and set Q = O.  (2) while P # O do the following 
  n I ... nr {let a x I x r be the lexicographi- cally first term of P; nl-n 2 n n r Then set Pl=a~l 
...~ r-l-nr ~ , r-i r nl-n 2. .. nr-l-nr n r Q1 =a Yl Yr-i Yr ' p = p -p 1 Q = Q + Q1 } and stop. 
i First, one notes that the exponents nl-n2,...,nr_l-nr, n~ of P1 are all non-negative because the 
symmetrical poly- nomial P contains with the first term  Proceedings of the 1976 ACM Symposium on Symbolic 
and Algebraic Computation 242 nl... a-x I n r x r also the sum list (Go(S) ''''' ~s(S)1" by taking adjacent 
n. ii ...' n. Zr pairs from a list (~s-l) ,... (s-l)%s_l,. If a- Z x I x r where (nil ,. ..,nir ) runs 
the polynomials are represented by lists over all different permutations of (n I, .... nr). We call 
this sum a symmetrical component of P and denote it by S(a;nl, ...,nr). For the lexicographically first 
 term one has therefore n I a n2a ... a n r. Secondly, the polynomial P1 = nl-n2.., n r a ~i Sr has 
the same leading term (and hence component) as P, since x~ I i i e o o e x i xi+ 1 -.-x r is the 
leading term of oi" Therefore, the subtraction P-P1 removes the leading component from P (but may introduce 
new components, which are lexico- graphically later, from Pi). Finally, the algorithm terminates since 
there are only a finite number of components whose lexi- cographically first term is later than the lexicographically 
first term of P.| In fact, a symmetrical polynomial with leading component S(a;n,...,n) has at most 
 A(n,r) = (n~r) symmetrical components Using classical polynomial arithmetic in step 2 one has: Theorem 
1 The computing time of the Gauss- algorithm is dominated by 2 r r 2 (n+1)r+3 .n+r. t r ) 2"L(dp ) 
' where L(dp) is the integer length of the maximum norm d of P. P Empirical computing times of the 
Gauss- algorithm using classical arithmetic are given in Table 3, column Gi, in section 6. 3. Generation 
of the Elementary Symmetrical Functions Let ~:s) be the i-th elementary sym-  metrical function in 
s variables. Then the following recurrence relation holds (s) (s-l)+ (s-l) ~i = ~ ~i-i si ,for i = 
l,...,s  with (o) 1 and ~s s-l) O,for all s~'~ i. G o si(s) is a linear polynomial in x s having 
 coefficients 1 , s in s-I varia-  bles Using a recursive polynomial repre- sentation an algorithm based 
on the recur- rence relation generates inductively the allowing overlapping o~s)" is constructed from 
~s~l) and~ ~ s-l)~ in constant time and space The construction of the list takes c s operations and 
d s list cells for some constants c and d. Since 0 ~ s ~ r we have the Theorem 2. The algorithm to 
generate o~r) ,---, ~r(r) (which altogether contain 2 r terms) requires ~ r 2 time and space ~(r). 
is a polynomial whose exponent vectors 3 contain j ones and (r-j) zeros. So, con- structing all bit 
strings of length r with j ones, j running from O to r, the total number of terms is 2 r. In this case 
a dis- tributive representation would have been inferior The algorithm is simple to im- plement and the 
observed times are very small (see table I). 4. Arithmetic for a Special Representation of Symmetrical 
Polynomials By a consideration of Gauss" proof one sees that a symmetrical polynomial is a sum of symmetrical 
components. Recalling that S(a; nl, .... n ) denotes the sum of all differefit permutations of monomlals 
with coefficient a and exponent vectors (nil,...,nir) this sum consists of max- imally r! terms for 
the case that all ni, nj (i ~ j) are different Obviously, a representation more economical in s~ace would 
be obtained by representing each symmetrical component by its leading term and SUDDressinq all other 
permuted terms. s . (i) (i), Hence , if P = i{ I S~ai;n I ,...,n r )t n1(i)~.... "~ n(i)r , is a symmetrical 
poly- nomial, we de~ine the component representa- tion of P as the list (al, (~i) . n (I)) . as, (n~ 
s) ''" ' r ''" ' ''''' n(S))), where the exponent vectors are lex~ r graphically decreasing. In the 
worst case a symmetrical polynomial of degree n in r variables has in the general representaticn (n+l) 
r terms but only (n~r) symmetrical components Asymptotically the saving ratio goes for fixed r as i/r! 
and for fixed n to 0 in favor of the representa- tion by components. For compatibility reasons we 
need conversion algorithms for the two repre- sentations. If a symmetrical polynomial P is given in recursive 
representation, one obtains the component representation by selecting from all exponent vectors of P 
those which are in decreasing order. This can be done recursively:  ei and L i (a~i)~ i) ~)v(~ ) of 
x r = , ...a )the list of decreasing exponent vectors of Pi together with the corresponding integer 
 coefficients Then if vj (i) ij = (n I ,..., ij ij nr_ I) and n I ~ el, the augmented expo- nliJ 
ij nent vector (el, ,..., nr_ I) belongs to the component representation of P. The recursion base 
is r=l in which case both representations coincide. The conversion from component to recur- sive representation 
is even easier, since the r~cursive representation of the terms -i Dr a x I ... x r can be constructed 
by sim- ple list -processing. In order to ob- tain S(a, n i''''' nr) in recursive repre- sentation 
one has to construct the monomials  a xlni!... Xr nir for all different permu- tations of the exponent 
vector and ads them with usual arithmetic The important question is how the polyno- mial algorithms react 
to the drastic drop in redundant information in the data structure of symmetrical polynomials Obviously 
 things are not as simple as the (computer folklore) statement suggests that the gain in space has 
to be paid by a loss in time and vice versa. The first algorithms we consider are polynomial addition 
and equivalently ne- gation and subtraction. Polynomial addi- tion is essentially a merging of terms,the 
cost being directly proportional to the number of terms of the inputs In the com- ponent representation 
addition is a merging of components represented by leading terms, the cost being reduced by the number 
of dropped terms. Table 2 (a,b) in section 6 compares the addition of symmetrical poly- nomials in the 
component representation and in the general representation. The asymptotic maximum computing times are 
 (n+r) (r+L(d))for the component represen- r r tation as compared with (n+l) L(d) for the recursive 
representation where n is the maximum of the degrees and d the maximum norm of the inputs Next we consider 
the multiplication of symmetrical polynomials in component repre- sentation. In the example 2 2 2 2 
2 2 A = S(3;2,1,0)= 3%x y+x z+xy +xz +yz +y z) B = S(-2;2,O,O)=-2(x2+y2+z 2) we have 32 32 2 2 22 
 C=A::B=-6(x4y+x4z+x y +x z +x yz +x y z+ 23 22 4 22 32 4 +x y +x y z+xy +xy z ÷y z .y z÷ 2 2 23 22 
4 4 2 3. +x yz +x z ÷xy z ÷xz ÷yz +y z )= =S(-6;4,1,O)+S(-6;3,2,O)+S(-12;2,1,1) and the question arises 
whether there is a multiplication algorithm for symmetrical components in order to get the right hand 
side from the left hand side directly We define the notion of the 'star- component by n n 7(1) (r) 
 S~(nl,...,nr) = Z x I ...x r ,where ~eS r S denotes the set of all permutations of r {l,...,r} , the 
symmetric group. Recall that for S(a;nl,...,n r) the summation runs over all different permutations of 
(nl,...,nr) resulting for the case of e- qual ni, nj s(i # j) in fewer terms than S ~. However there 
is a simple relation be- tween S and S e. We define the density P (n i) of n i as the frequency of the 
oc- currence of n. in the final segment i (ni, ni+l,...,n r) of the exponent vector. The repetition 
factor of an exponent vector is defined by rep(n I ..... n r) = 0 (nl)... p (nr). The relation between 
S and S ~ is given by the Lemma a Se(nl,...,nr)= rep(nl,...,nr)- S(a; nl,...,nr). Finally, the modified 
permanent of a r x r matrix (aij) is defined ~y per (aij) ~e~rS*(al,~(1) ..... ar,~(r) (In a "true" permanent 
S*(al,~(1),... ,a r ) is replaced by the product "" ,~(r) r H ) i=I ai,~(i) Theorem 3 ( Loos ) 
 The product of two symmetrical compo- nents is given by S(a;m 1,...,m r ) ~ S(b;n I .... ,n r) = a- 
b per (mi+n j ) rep(m l,...,m r ) rep(n I .... ,n r) For brevity we omit the simple proof. In the 
example above we had  = -~[2SXt4,1,O)+2SX~3,2,0}+2SX~2,1,1)]~''''''~ = = S(-6;4,1,O)+S(-6;3,2,O)+S(-12;2,1,i) 
 The product algorithm for two symmetri- cal polynomials A and B represented by se- quences of symmetric 
components processes in the outer loop each component of A and mul~iplies it in the inner loop with each 
component of B and the results are added. If the modified permanent is expanded recursively with respect 
to the first co- lumn it will usually contain exponent vec- tors which are not in decreasing order. These 
have to be sorted since the com- ponent representation requires decreasing exponent vectors. Likewise 
the list of ex- ponent vectors which is obtained after this sorting is generally not in lexicographi- 
cally decreasing order and must be sorted, too. Finally the coefficents of equal ex- ponent vectors must 
be added. This twofold sorting process and the summing up of equal vectors slows down the product algorithm 
considerably such that the gain in terms is overcompensated. Al- though we could multiply symmetric polynom- 
 ials which could not beheld in memory in the general representation the time com- parisons were in disfavor 
for the component representation in all cases. Table 2 (a,b) of section 6 gives the times for component 
arithmetic. Advantages of the general al- gorithm are that in multiplying terms only single terms are 
produced but not polynom- ials and therefore polynomial addition has not to be done in the inner loop. 
We expect that in our algorithm the inner loop with the comPonent product can be improved. Theorem 
4 Let tA, t B denote the number of compo- nents of A and B respectively. Then the time to multiply A 
and B is dominated by .m+n+r. tAtB ~ r )r~r21°g(r)L(IAI~) "L(IBIi)  where r is the humber of variables, 
m = degr(A) , n = degr(B ) . For the important case of the Gauss-al- gorithm the component product algorithm 
can be designed more satisfactory. The only products of the Gauss-algorithm are prod- ucts of elementary 
symmetrical functions, and for the case of one factor being of this special kind the modified permanent 
according to Theorem 3 can be produced in sorted form, both the exponents in the vec- tors and the vectors 
in the permanent. We recall that ~(~)consists of the sin- gle component S(i;i,~..,i,O .... ,0) with 
j l's and r-j O's after the coefficient. Then the matrix of S(a;nl,...,nr) :: ~j has the special form: 
the first j rows are (nl+l, ..., nr+l) = Ri, the last (r-j) rows are (nl'''''nr) = ~2" An element of 
the modi- fied permanent is a vector consisting of j elements of R 1 and the r-j complementary elements 
of R2; this means that it is just the componentwise sum of (nl,...,n r) and a permutation of Sj = (i,...,i,O,...,O). 
 The complete modified permanent is obtained by doing this for all (~) permutations of S.. If one takes 
these permutations in lex- 3 icographically decreasing order one can prove that: (i) all resulting 
vectors which do not have decreasing exponents appear al- ready as ordered sum vectors of anoth- er earlier 
permutation of S. and there- fore can be left out if one 3 takes in- to account the multiplicity of the 
dropped vectors.  (2) the list of remaining ordered vectors is lexicographically ordered .  The multiplicity 
can be computed in the following way: let (n],. . nr) contain k adjacent equal elemen£s;iet some per- 
mutation of S. contain e ones in this segment. Then 3 there exist exactly (~)_ permutations of Sj which 
permute only this segment and let all other elements fixed. Since ni+ 1 = ... = ni+ k, all these permutations 
give permutations of the same sum vector and hence only one of those (the sorted one) is taken; its multiplic- 
 k ,n r ) con- ity is therefore (e) . If (n I .... tains several such blocks of equal ele- ments, the 
total multiplicity is the prod- uct of the multiplicities of each block. Since only the different permutations 
are considered, the numerical coefficients must be multiplied with a correc~on factor r!/([) = j! (r-j)!, 
but this is exactly the J repetition factor of % and hence cancels. Example: Compute S(-7; 5,5,5,4,3,3) 
:: ~2 The (26 i different permutations of S 2 are: i.) (i,i,O,0,O,O) 9.) (O,i,0,0,0,i) 2.) (i,0,i,O,O,O) 
IO.) (O,O,i,i,O,O) 3.) (i,O,O,i,0,0) ii.) (0,0,i,O,i,O) 4.) (i,O,O,O,i,O) 12.) (0,0,I,0,0,I) 5.) (1,o,o,o,o,i) 
13.) (0,0,0,i,i,0) 6.) (0,1,1,0,0,0) 14.) (0,0,0,I,0,i) 7.) (O,i,O,i,O,O) 15.) (0,0,0,0,i,i) 8.) (O,i,O,O,i,O) 
 The permutations 2,5,6,7,8,9,10,11,12,14 produce sum vectors which are not in de- creasing order . The 
others give :  i.) : (6,6,5,4,3,3) with multiplicity 3 3.) : (6,5,5,5,3,3) " 3 4.) : (6,5,5,4,4,3) " 
6 13.) : (5,5,5,5,4,3) ,L 2 15.) : (5,5,5,4,4,4) " 1 The numerical coefficient of (6,5,5,5,3,3) for 
example is (-7) rep(6,5,5,5,3,3)-3 = -21 . rep(5,5,5,4,3,3) So we finally get: S(-7; 5,5,5,4,3,3) * 
o 2 =  S(-7; 6,6,5,4,3,3) + S (-21; 6,5,5,5,3,3)+ +S(-14;6,5,5,4,4,3) + S (-28; 5,5,5,5,4,3)+ +S(-21;5,5,5,4,4,4). 
 These observations are the base of the fol- lowing algorithm: L ÷ SSCPR(C,j) [Special symmetrical 
component product. C = (c; n l,...,nr) a symmetrical component, L C * ~ ].. (~.) (i) [Initialize] 
 Set N = (n I,.. ,n r) , S = (i,... ,I,O, ...,O) with j l's, and L = ( ).  (2) [Permutation loop] 
 For all different permutations of S perform step 3, 4 and 5 and stop.  (3) [Process single permutation] 
  i + i; m ÷ i; [multiplicity of re- tained component] while i < r do {k ÷ i; [number of adjacent equal 
elements in N] e ÷ si; [number of l's in this seg- ment of S=(Sl,...,Sr) ] while i < r &#38; n i = ni+ 
1 do [process block] {if s i < si+ 1 then process next permutation, if any; k ÷ k + i; e ÷ e + Si+l; 
i + i + i}; m ÷ m * (~); i + i + i}. (4) [Numerical coefficient] d + c * m * rep(N+s)/rep(N). Theorem 
5: The computing time of the Gauss-algo- rithm using SSCPR is dominated by 2 r r n 2 ( ~l)r. n+r.3 
" ( r ) " L(]PI~)" 5. The Bratley-McKay Algorithm In order to obtain empirical compari- sons with existing 
algorithms we imple- mented an algorithm of Bratley and McKay which is published as Algorithm 305 in 
the Collected Algorithms from CACM [5]. This algorithm expresses the symmet- rical component S(i; ~_,..., 
n ) as a sum i r of determinants in the elementary symmet- rical functions The symmetrical component 
 is first expressed in terms of Schur functions which are then evaluated as de- terminants in the elementary 
symmetrical functions. Our implementation is just a translitera- tion of the ALGOL program to ANSI-FORTRAN 
 with the modifications that lists are used instead of arrays, that the elementary symmetrical functions 
are given as symbolic polynomials (not as values of these poly- nomials), and the determinants (which 
have polynomial entries now) are computed by use of the SAC-i algorithm PDET. Unfortunately there 
exists no theoretical computing time analysis of this algorithm. The empirical times are given in table 
3, column BM. 6. Empirical results In the following some observed computing times are presented for 
the generation of the elementary functions, the arithmetic of symmetric polynomials and the Gauss al- 
 gorithm with different arithmetic All times are given in seconds and were ob- tained by using SAC-i 
[4] on the Universi- ty of Kaiserslautern Telefunken TR 440 computer In a forthcoming Diplomarbeit 
by the author, supervised by Professor R. Loos, the omitted proofs, algorithm descrip- tions and programs 
will be given. TABLE i: Generation of the elementary symmetrical functions in r variables. r EGEN 
5 O.O051 iO O.O169 15 0.0354 20 0.0595 (5) [ Join to output] Suffix (d,N+S) to L  Computing time 
~ (~)(r+L(c)), if r is a small single precision number. Random symmetrical polynomials in r varia- bles 
and of degree n in each variable; maximum norm bounded by 28; half dense (50 % of all possible symmetrical 
compo- nents) PSUM, PPROD: usual SAC-i algorithm SPSUM, SPPROD: special algorithms for symmetrical 
polynomials. (a) r n PSUM SPSUM PPROD SPPROD 2 2 0.006 0.004 0.06 O.iO 2 4 0.009 0.005 0.36 0.85 2 
6 O.O19 O.O12 1.67 6.05  2 8 0.030 O.019 4.55 23.0  4 2 0.054 0.010 6.28 5.95  4 4 0.295 0.040 +) 
336.1  4 6 0.905 O.113 4 8 +) 0.264  +) memory overflow (b) r n PSUM SPSUM PPROD SPPROD 2 2 0.006 
0.005 0.06 O.iO  4 2 0.054 0.008 7.18 6.20  6 2 0.458 O.O15 +) 1075.O  3 4 0.052 O.O14  4 4 0.282 
0.037 5 4 +) 0.074  +) memory overflow TABLE 3: Gauss" algorithm with different arithmetic Gi: with 
usual arithmetic G2: with SPSUM and SPPROD G3: with SSCPR BM: with Bratley McKay algorithm~ Random 
polynomials like in TABLE 2, maximum norm < 24 r n G 1 G 2 G 3 BM 2 0.46 0.57 O.12 0.54  4 5.91 4.94 
1.63 18.OO  2 3.18 4.66 0.39 1.93  4 55.30 53.56 5.13 112.O5  2 9.94 42.92 O.71 4.73 4 437.9 707.6 
17.O 728.12  References <RefA>[i] B. van der Waerden, Algebra I, Heidelberg [2] E. Netto, Vorlesungen Ober 
Algebra, Leipzig, 1896, Bd.I [3] W.S. Brown, ALTRAN User's Manual, Bell Laboratories, Murray Hill, 1973 
 [4] G.E. Collins, a list of SAC-~i reports is given in the KWIC-Index in SIGSAM Bulletin of the ACM, 
New York, 8, (1974), 17-44 [5] P. Bratley and J.K.S.McKay,Algorithm 305: Symmetric polynomials,Comm.ACM, 
VOL. iO,(July 1967),450; ll,(April 1968)</RefA> 272.   
			
