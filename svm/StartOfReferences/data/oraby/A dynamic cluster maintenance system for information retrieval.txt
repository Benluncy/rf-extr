
 A DYNAMIC CI,USTER ~AINT.~NANCE SY~I'~M FOR INFORMATION RETRIEVAL Fazli CAN Esen A. OZKARAHAN Dept. 
of System Analysis Dept. of Computer Science Miami University Arizona State University Oxford, Ohio 45056 
Tempe, Arizona 85287 ABSTRACT Partitioning by clustering of very large databases is a necessity to 
reduce the spaze/time complexity of retrieval operations. How-ever, the contemporary and modern retrieval 
environments demand dynamic maintenance of clusters. A new cluster mainte- nance strategy is proposed 
and its similarity/stability characteris-tics, cost analysis, and retrieval behavior in comparison with 
unclustered and completely reclustered database environments have been examined by means of a series 
of experiments. I. INTRODUCTION _ Clustering has diverse applications in science [lJ. In information 
retrieval clustering is related to classification of documents in such a way that similar documents are 
grouped together in parti- tions. Partitioning of very large document data-bases is a necessity to reduce 
the space/time complexity of related search operations. We can also construct a hierarchy of clusters 
and there-fore use it as an index in document searches in addition to using clustering for optimizing 
storage and paging of documents. Because similar docu-ments would be jointly relevant for a given search 
request queries are compared against cluster cen-troids (i.e., cluster representative) at the begin-ning 
of a search process. Clustering is often performed with the use of documents available in a database 
and therefore any set of clusters reflect the semantics of the database as a given point in time. Although 
such an environment would be suitable for static collec- tions with almost no document growth and/or 
retirement, assumption of a dynamic database with new additions to the collection would be more in line 
with contemporary applications. In this paper we, therefore, would like to address cluster maintenance 
which is the most neglected area of clustering, maintenance. After a brief overview of clustering and 
published maintenance schemes we will introduce a new cluster maintenance metho- dology, assess its similarity 
and stability charac- teristics, and finally observe its retrieval behavior, Permission to copy without 
fee all or part of this material is granted pro- vided that the copies are not made or distributed for 
direct commercial ad- vantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Associa- tion for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM 089791-232-2/87/0006/0123--75¢ 
all accompanied with the respective experiments. 2. OVERVIEW OF CLU~IrERING In the vector space model 
of document representation an index vocabulary T that is believed to best describe a document collection 
D is first generated. A document is then represented as a vector ~ assembled from a collection of index 
terms that are present in the document while placing zero entries in the vector for the term positions 
that are not found in the given docu- ment. We will use n and m to represent the number of terms in the 
vocabulary set T and the total number of documents in the database respectively. We can use vector comparison 
schemes, such as the cosine of the angle between two vectors, to show the extent of the similarity between 
two vec- tors which can belong to a document pair or a document and a user query. In clustering we often 
resort to similarity measure which can also be interpreted as a matching function in the case of query 
comparison. In clustering of documents various aooroaches have been proposed [7,1.3,15]. One possible 
way is to prepare a similarity matrix where a given document's similarity with all the others can be 
seen. Starting with such an in_formation and then by applying various similarity thresholds, clusters 
belonging to closely related documents which form a connected graph can be identified. In the other category 
of clustering algorithms, an initia-tor called the seed document is determined for each cluster and the 
remaining documents are assigned to the clusters of the seeds to which they are most similar. The seeds 
can be determined in various ways and all the clustering algorithms can also be classsified on the number 
of iterations they take to complete the clustering and are therefore referred to as the single-pass or 
itera-tive algorithms. The following properties are important in determining_the acceptability of a given 
clustering algorithm [1 l, 15,17J: 123 a) The clusters are stable i.e., they are unlikely to change when 
new documents are added and/or the clusters are not affected by the small errors made in the description 
of docu- ments. b) The composition of clusters is independent of the order in which documents are processed. 
c) The clusters should be well defined i.e., for a given set of data either a single classification or 
a small number of compatible classifications should be produced. d) Document distribution in clusters 
should be as uniform as possible. e) The clustering algorithm should be able to handle document growth 
efficiently i.e., maintenance of clustering should be practical and efficient. f) Clusters produced 
should result in an effective and efficient retrieval environment. In the following we will first briefly 
introduce the cover coefficient concept which is key to our clustering and its maintenance and then 
move to the cluster maintenance issues.  2.1 The Cover Coefficient Concept In clustering using the cover 
coefficient (CC) concept we map. the document description matrix D of size mxn (i.e., documents by index 
terms) into the cover coefficient matrix called the c matrix of size mxm. Each entry c~. of this matrix 
indicates the extent . ~, of coverage of a document, by itself (when i=j) and by the other documents 
(when l_<j_<~z and j#i) where individual entries of the C matrix are defined as follows: n cij = aix 
~ d.ex/~xgik l_<i.~m, l<_j_<w% k=l where ~ and ~ are the reciprocals of the row, and columnk sums, respectively. 
Each cq is a covering coefficient among documents and ~c~ i=l for i=I l_<i_<m. The diagonal entries, 
c~, of the C matrix indicate the extent of self coverage for d~, l<_i_<rn. c~ is therefore called the 
uniqueness or decou-pling coefficient 6~ of o~. For a binary D matrix c~>_c,~ for i~j, however, this 
may not hold for a weighted D matrix. ~ can be unity if d~ is com-pletely unique otherwise, normally 
6i<1, 0<6i<1, meaning that d~ is coupled with one or more of the documents of the database. The sum of 
the off-diagonal entries of a row of C matrix is referred to as the coupling coefficient ~ of 4. %~ indicates 
the total coupling of &#38; with all other documents. By definition ~=~-6,, ~-%~<1. The decoup]ing and 
cou-pling can be expressed for the entire database. or example the average coupling of the database is 
called ~, 0<d_<l, which is given by From these it has been hypothesized and observed that the number 
of clusters, n~, resulting from the entire database is no=~×m with the implication that l_<n~_<min(rr~,n). 
Similar to documents, terms can also be clustered via the C' matrix of size nxn (generated from the D 
matrix) whose entries are m k=l From c'~ the same concepts of decoupling, coupling, and number of clusters 
can be defined for the terms, as c~ provided for the documents. In the clustering of C (or c') a document 
(term) cluster seed power is defined to be able to deter- mine the cluster seeds. The cluster seed power 
of . i=I i=1 corresponding to the binary and weighted versions of the /) matrix, respectively. In forming 
clusters the documents corresponding to the first n~ highest p~ are taken as seeds and some c~#'s of 
all the remaining m-n0 documents are used in assign- ing the documents to the cluster of the seed that 
covers them most. 3. CLUSTER MAINTENANCE 3.1 Overview A close examination of most clustering algo- rithms 
reveals the fact that the majority of the algorithms are not suitable [17] for maintaining clusters in 
a dynamic environment. One reason is that their clustering and maintenance methodolo- gies are merely 
based on heuristics which most of the time make reclustering of the entire database more practical. A 
well known cluster maintenance methodol- ogy is cluster splitting [ 14,15]. In the cluster split- ting 
approach a new document being added to the system is treated as a query and compared with the existing 
clusters. The document is added to the cluster that yields the best match to the "query". Whenever a 
cluster overgrows with addi- tions it is split into two new clusters. In another maintenance strategy 
proposed by 6] first a process called categorization is per- ormed to create an index for the existing 
data- base in the form of category vectors. The docu- ments are compared with these vectors and assigned 
to the "categories" they have resem- blance with. Actually if the similarity of a docu- ment compared 
exceeds a threshold the docu-ment is assigned to each category where the threshold is reached, otherwise 
the document is assigned to the category of most resemblance. The category sets obtained correspond to 
clus-ters. In the maintenance algorithm the categori- zation process is continued and during this phase 
some new category classes may be generated and the old ones changed if necessary. These new and/or modified 
category vectors are then used as queries and compared with the documents. The matching documents arc 
assigned to their respec- tive categories (i.e., clusters). The comments on the two foregoing mainte- 
nance approaches are as follows. ]n the cluster splitting approach the documents in the split clus- ters 
can no longer interact with the rest of the database (i.e., documents in the unsplit clusters). In other 
words a document in a split cluster can-not later join an unsplit cluster. In the categoriza- tion approach 
there is order dependence both before (because/generation of category vectors is order dependent)and 
after maintenance.  3.2 The Need For New Approaches Ifwe assume a static index vocabulary, that is an 
unvarying index even when new documents are added, then we may first think to resort to using inter document 
similarities. We can compute the similarities among the new comers. For me new comers this will yield 
a complexity of O(Tr~). And then we need to compute the similarities among the existing m~ documents 
and the new comers at a complexity O(m,xma), thusyielding an overall complexity of O(~1×m2+m#). The time 
and space requirement of such an approach would be prohi- 124 bitive. We may also be tempted to use 
a cheap clustering algorithm of mlogm complexity to forget about maintenance and just recluster the 
entire database consisting of old and new documents. However, even this approach would be prohibitive 
 especially when considering consecutive mainte- nance. These points imply that we would be better 
off by using an efficient maintenance algorithm instead of reclustering the documents.  3.3 CC-Based 
Clu~ter Maintenance Cluster maintenance starts with an m~ number of existing documents corresponding 
to what we will call "old documents '. According to the CC- based clustering methodology these documents 
 are clustered with the single pass clustering algo- rithm which bases its clustering on seeds. Each 
 seed corresponds to a document selected with [ espect to its seed power computed from the C cover coeffient) 
matrix [2,3,4,5,10,11]. Docu- ments are assigned to the cluster of the seed which covers them maximally. 
That is, if d~ is a nonseed document and sl,s2 ..... s~ are the seed documents, then ~ will be assigned 
to the cluster initiated by the seed whose c~j is the highest where dis Isl,s2 .....s~ I. Any tie among 
c~j is broken by the corresponding cluster seed power p~ value (i.e., take the document of the higher 
p~). n~ denotes the number of clusters. We will now introduce our CC-based dynamic cluster maintenance 
algorithm but first let us introduce the necessary notation. D~i: old document collection S,~i: cluster 
seeds of P,~1 (old seeds) D~e: new (additional) documents to be clustered D~: D~iUD~2 (extended document 
collection) Df docu.rnents corresponding to falsified cluster seeds due to new arrivals  Dr: D~2UDf, 
i.e., documents to be clustered no=:number of clusters in D~ implied by the CC nc~i:nun~ber of seeds 
in D~ concept heR: number of seeds in Dr [R=ID, I)   ~e e ,CC-Based (Cluster) Maintenance Algorithm 
 store old clusters, old seeds, and n~,; a) fori=:l tom do/*m:mz+ms */ compute p~;endfor; b) compute 
n~ tcdce n~ documents with the highest cluster seed power by eliminating identical seeds c) Ds=O for 
i.'=l to n~ do ff old cluster seed-i is not a seed azzymore then Df=PfLJ(o~. ]for all d~.eQ) endif; 
endfor; d) for i:= 1 to n~ do if new cluster seed-i s Q and cluster seed-i ~ S~l then D~=DfU(~- I gj~q) 
 endif; endfor; e) fori:=l toR/*R=IDr[ */ i~nd the cluster seed maximally covemng document-i there is 
more than one seed with this property the eument is assigned to the one with the hzghest cluster seed 
power end.for; end/*the end of maintenance algorithm */ The following provides an informal description 
 of the above algorithm by its items. a) Compute the cluster seed powers of the docu- ments in the extended 
document collection, D~ = D~ i U D~2. b) Determine the clusters seeds of D~. Whenever identical seeds 
are found choose any one and eliminate the rest. c.d) Determine the set of documents to be clustered, 
A-, that is, the documents in the new arrivals, D.,e, and the documents of the falsified clusters, D 
I. e) Assign the documents of Dr to the cluster of the seed that covers these documents maxi- mally. 
 Note that the documents that are not assigned to any cluster might form a separate cluster by themselves 
or placed in a rag-bag cluster. (This did not happen in our experiments.) As can be seen from the foregoing 
the mainte-  nance clustering process is applied only to the new comers and the members of the falsified 
clus- ters (if any). The CC-based maintenance algorithm performs well in generating firm clusters and 
true seeds. Therefore, the size of Dr is expected to be close to D,~2 (i.e., small DS) so that the 
computa- tional load of the maintenance will be low. 3.4 Complexity Analysis of the CC-Based Mainte-nance 
Algorithm We will analyze the algorithm of the previous section in its unique steps. a)The cluster seed 
power of each document is computed and placed into a sorted order. This results in the following complexity: 
O (m xX~ + 2xnxtg +mloOm ) where mxX~+2xn x G corresponds to the complexity of the cluster seer power 
computation, x~ is the average number of terms per document and tg is the average number of documents 
that use a term. With t being the total number of nonzero entries in the D matrix then Xa=t/m and t,=t/n. 
2xnxt, is needed only in the weighted (i.e. non-bins'y) document representation. This ste'p will aIso 
eliminate the identical seeds without incur-ring additional computations [2,4]. fbo)Because the ~i (l_<i~<m) 
values which are needed r n~m are already available the complexity of this step can be ignored. The elimination 
of false clus- ter seed power can also be ignored. c)This step has a complexity of O(n~,~xno,~). d)This 
step has the same complexity as step (d) and can be performed concurrently with it. e)This step's complexity 
is O(n~mx(R-ncR)xX~). Note that there are n~ seeds, only (R--heR ~ documents will be clustered, and for 
computing the entries of the C matrix on the average we need to consider x~ terms in each document. Accordingly, 
the overall complexity of the CC-based maintenance algorithm will be o (3t + rraogrn.)+ 0 (n~,,, ~xn=,)+ 
0 (n~,~ x (g -ncR)XX,~) This complexity analysis shows that if the number of documents corresponding 
to the falsified clusters is small then R will be small (i.e., close to m2) and the complexity of the 
algorithm will be reduced accordingly. 125 Now let us compare the cost of the two choices that we have 
after collection expansion. The fol- lowing can be considered. a) We can reinitiate the single-pass algorithm 
(i.e., reclustering ) for the expanded set of documents. b) We can use the maintenance algorithm. In 
the case of (a) the complexity will be  o (3t +~ogm)+ o(~ x (~--~.)xx~) And in the case of (b) the complexity 
of computa- tions will be O (at + rmogm )+ O (n~ x (R -nca )X X~ ) In both (a) and (b) a weighted D matrix 
is assumed for general interpretation. Also, in (b) O(n~,×n~) part is not included since it is negligi- 
ble compared to the rest given above. With these figures we see that the OOt +rnZogm) complexity is inevitable 
since it is involved in the determination of cluster seeds. However, it should be noticed that this complexity 
is much less than the second part which is O(n~x(m-nc~)xX~) and O(r~..~x(R-ncR)xX~) in (a) and (b) respectively. 
Therefore, the main factor that will lead us to judge the maintenance algo-rithm is the difference between 
these second parts of the complexities, or more specifically (m-~) and (R-ncR) where m--~.~=lNm,I + ID~,I 
-IsI R-ncR=INsl + ]D~,[ -ISnN~l where s is the set containing seed documents. The third terms will be 
ignored since they are small compared to the others. If ]Di] is small compared tO IDml I then it is advisable 
to use the mainte- nance algorithm, assuming that it creates clusters compatible with those of the clustering 
algorithm. We will deal with compatibility later. [Dr I=0 indi- cates that cluster maintenance does not 
incur any extra cost i.e., it only clusters the new comers. In this paper, the proportion of the old 
documents that are reclusteredlP~,I/ID~,I will be referred to as the cost of the maintenance algorithm. 
 Even though the C C-based clustering process is order independent[2,3], maintenance process can preserve 
independence only within the docu- ment set, which will be referred to as Dr, corresponding to the new 
comers and the portion of the old documents that have to be reclustered. This somewhat less desirable 
situation is offset by the cost savings. A maintenance algorithm that would be universally order independent 
and yet .cheap is not known to the authors. 4. EVALUATION OF THE CC-BASED MAINTENANCE ALGORITHM The 
efficiency of a clustering maintenance algorithm is very important because we expect that the cost of 
maintenance would be consider- ably less than that of reclustering. Furthermore, it is also expected 
that the dusters generated by maintenance be compatible with those of reclus- tering. For these reasons 
we will conduct our evaluation from the points of view of stability/similarity, cost, and retrieval perfor- 
mane e. The similarity between the clusters generated for the m~ old docmnents and those clusters resulting 
from maintenance will be used to meas- ure the stability of the maintenance algorithm. Higher stability 
would be an indication of the firmness (or genuineness) of the original clusters generated by the single-pass 
algorithm. In other words, new additions do not cause noticeable changes in the original clustering pattern. 
Another way of measuring this is with the similar- ity between the clusters generated after mainte- nance 
and the clusters resulting front reclustering (i.e., of m=mi+m 2 documents) with the use of the single-pass 
clustering algorithm. In the cost evaluation we look at the percen- tage tNil/m , of the old clusters 
that are reclustered due to addition of r,.~ documents. A low percentage indicates that R (i.e., cardinality 
of DT ) is close to me. And this is what is desirable in cluster maintenance. In the retrieval performance 
we will compare the retrieval results of the single level, sinK]e-pass clustering system obtained before 
and after the maintenance experiments to measure the possible effects of the maintenance algorithm. 4.1 
Experimental Environment 4.1.1 Document Collection and Indexing Policy The evaluation issues discussed 
in the forego- ing are assessed in our experimental environment which is described here. The document 
database is the TODS database which contains titles, abstracts, and keywords of 314 articles from the 
journal called ACM Transactions on Database Sys-tems. This database has been used in our previous pubflications 
and the indexing policy is described in [12J. Accordingly, the index vocabulary is gen- erated with respect 
to a frequency and weight threshold range applied to the stems generated after stop words have been discarded. 
In the experiments both the binary and weighted ver- sions of the document, D, matrix have been gen- 
erated. Table 1 shows the database characteris-tics. The variable t denotes the total term usage (i.e., 
total number of nonzero entries)in the O matrix; X~ and tg are the average depth of index- ing and term 
generality respectively (i.e., Xa=t/m and ta=t/n); Xa~ and t~ are the so-called weighted average depth 
of indexing and term generality respectively. If G corresponds to the total weight corresponding to the 
total term usage, then X~=t=/m and t~=tw/n, n~ indicates the number of clusters implied by the CC concept. 
The experi- ments are carried out using various indexing thresholds. These will be notated as Ps=~,s~. 
For example, D3-40 means that for a term to appear in a document as an index term it must appear in at 
least three and no more than forty documents in the database. Table 1. Staf~t@s oS the-b:~n.~ria: used'in 
the experiments ! (gr~:,f m~) n t X~ 6 X~ toe n~l (2;40) 1060 7448 34. 79 7. 02 53. 02 10. 70 34 (3;40) 
757 6840 31..96 9.04 49.15 13.90 27 (4;20) 532i 4472 20.90 8.41 30.75 12.37 30 4.2 Query Construction 
The query set contained a total of fifty seven queries. Thirty nine of these queries are con- structed 
from five textbooks on databases. If a chapter contained two or more references to a TONS article the 
titles and subtitles of that chapter are used as the query text. The docu- ments corresponding to these 
references are assumed relevant to the query. The query set is almost evenly distributed among the five 
texts 126 th the actual distribution being 3,7,7,10,12). e other set of eighteen queries are taken 
from the experimental environment of [12]. The natural language text of the queries is mapped into a 
query vector. A query vector Q is defined as Q=Q, nT where Q, and T aice, respectively, the stems corresponding 
to the query text and index vocabulary. Table 2 gives the details of the query set. Table g. Characteristics 
of the ~eryj Set Number of queries 57 Number of clistict documents found for the queries 122 Total number 
of relevant documents for lhe queries 299 Avera@e number o[ relevant clocuments for a qu~ryj 5 3 4.3 
Similarity and Stability Analysis of the Algo-rithm In the similarity and stability analysis of the CC-based 
maintenamce algorithm we used the Rand, Corrected Rand, and C~edman-Kruskal metrics [1,9]. The way these 
metrics measure similarity/stability is that when the clusters (par- titions), generated by two different 
algorithms for the same input, are similar to each other the values of the metrics get close to unity, 
or to zero if they are dissimilar. In the experiments for similarity/stability a) The initial document 
set m~ was set to the old document set values of B0,I00,I~0,140,160,180, and zOO documents with clusters 
generated according to the single-pass clustering algo- rithm. b) For each m~ value the set corresponding 
to the difference rn,2=214.-m 1 is interpreted as to belong to the new arrivals and they are clustered 
with the maintenance algorithm. e) The extended set of m~+ ma documents are also reclustered by use of 
the single-pass clus- tering algorithm. d) The clustering patterns obtained by (a), (b), and (c) are 
referred to as the partitions p~, pc, and ps respectively. e) For similarity the partitions pe and pa, 
and for stability the partitions p, and p~ are compared by using the three metrics mentioned in the foregoing. 
 The experiments mentioned above are repeated for different indexing thresholds (i.e., ffr~ and fm~) 
on the D matrix [8]. The index voca-bulary is generated from the old set of m~ docu- ments. In other 
words, the vocabulary was fixed because the addition of me new documents has not affected indexing. The 
proportion of newly needed index terms, as can be noticed in Tables l&#38;3, would have been less than 
3Z. Figure 1 shows the results of the similarity comparison of the cluster- ing of the old document set 
with the maintained clustering using the D,-40 environment. The results of the similarity comparison 
of the maintained clustering with the clusters of the reclustered database are shown in Figures 2 and 
3 for the indexing environments Ds-~0 and /)4-e0, respec- tively. The stability and similarity values 
(in terms of the Rand, Corrected Rand, and Coodman-Krustcal coefficients) obtained during the experiments 
are considerably high. The high stability values obtained (see Figure 1) show that the old docu- ments 
that are clustered again by the mainte-nance algorithm do not change the old clusters. In other words, 
since the single-pass algorithm creates the correct (genuine) clustering pattern in the old collection 
the maintenance algorithm, did not need to change them. The results of the similarity experiments in 
Figures 2 and 3 show that the maintenance algo-rithm yields compatible results with the case when all 
documents are reclustered. The results of the stability and similarity experiments indicate the qualityof 
the maintenance algorithm. Furth-ermore, high similarity/stability values were. .... - .... .----"" LEGEND: 
// RBMO CORRECTED RflND  GODDM~-KRUSKA£ HOTES: 1. 'iHE i'~IKIBtg4~ g..GORII'HI~ IS FOR O_J_~ (9EIDiT~) 
 NO OF I~IJMEnTS(IN OLB O MATRIX) Figure 1. Similarity between the old and maintained clustering 127 
 LEGEND: .... . ...................... -.... -....... -.........   C-~ECTEIIRAND  cooB -KPKC . NOltS: 
I. ~ ~II41BiAHll I;.QIIIlHN IS FOR O_l.te (~Ig~l'l~l)) oJ y u MOOF BIEUMEMTS (IM OLD D MATRIX) Figure 
2. Similarity between the maintained clustering and reclustering  LEGEND: NBMB ~RRECTEDI~'IB ....... 
m ............ o .............. ~m@~ ......... GOODMBM-KRUSKAL HOLE: I. ~ ~IHrDIAHCt tLG~IIt4I ? t~ECmID 
FOt~ ~4,..20(~ICmil~) .6 110 OF BOCUMEPITS (IO OLD D M.qTRIX) Figure 3. Similarity between the maintained 
clustering and reclustering obtained even when r~ was considerably less than reelustered, or in terms 
of the notation used ear- r~a. As expected, when the value of m 2 decreases lier I D.r I/I-O~l. In the 
cost experiments,(or 7~ 1 increases) both the similarity and stability values increase. (IPzl/ ]D~,l) 
xlO0 is plotted against [(r~-~l)/~l]xlO0 (i.e., the percentage of falsified 4.4 Cost Analysis of the 
CC-Based Maintenance documents of nzx are plotted against the percen-Algorithm tage increase in mx while 
fox being kept fixed). In In this section an experimental cost analysis the cost experiments, first, 
one hundred and ten documents are taken as ~x and then the rest of of the algorithm will be presented. 
In the complex- the documents are added ten by ten to r~l. For iLy analysis of the maintenance algorithm 
(see example, if r~2=10, then the percent of the addedSection 3) the cost of the algorithm is defined 
as documents becomes (10/l10)x100=9. the proportion of the old documents that are 128 °/o of rel¢osed 
docun'~nts ,,D _4_20 t R I' 3 , , / l l ,'.~ %4 /D_2_~0 a ~" .*----,"" ~ ....... D_3_L.O //\... _ ........ 
.... 21'4 753 31.91 ? 49. O? 13. 95 27  °/o of new I I I I' I I t~ I I I ~ docurneflts 10 20 30 40 50 
60 70 80 90 4o0 Figure 4. The effect of new documents on the old ones In Figure 4 the percentage of 
falsified docu-ments versus the percentage of new documents (with respect to m~)areplotted. The results 
of the experiments show that for low percentage of new documents the percentage of falsified documents 
is very small. There is only one unexpected high value for D~_40 at me=t0, However, the remainder of 
the results shows very satisfactory performance. Lven with a sizeable number of additional docu-ments 
the amount of falsified documents is not high. For example, for D4-aQ, /)e-4Q, and D~--4Q when me is 
at 90 percent of m, only 40, 23, and 19 per- cent of the m, documents are falsified and reclustered respectively. 
In [13] it has been stated that if the increase in the number of documents is more than fifty percent 
it might be better if all the documents are reclustered. 'Fnis is because such an increase might destroy 
clusters and lead to meaningless clustering patterns. However, such an argument may not be universally 
true and is more depen-dent on a particular maintenance algorithm. For example, the CC-based cluster 
maintenance algo-rithm always yields clusters compatible with those of reclustering as seen in the similarity 
experi- ments of Figures 2 and 3. Furthermore, as can be seen in Figure 4 the amount of computations 
involved in it is considerably less than that of full utilization of the single-pass clustering algorithm. 
These arguments are valid even when m2=2.7×m ~ (Figures ~ and 3) and m2=0.gxml (Figure 4). This shows 
that the CC-based cluster maintenance algorithm can handle considerable number of extensions in a dynamic 
environment. 4.5 Cluster Maintena~:~.ce 15erforrnance in Informa- tion Retrieval Retrieval experiments 
are performed in two modes. The modes are the search of the full D matrix, which is referred to as the 
"full search", and single level cluster search which is referred to as the 6luster based retrieval (CBR). 
The effect of maintenance is observed by comparing the retrieval results of the full search with those 
of CBR made both with maintained clustering and reclustering of all the documents. The conditions of 
the experiment were as follows: a) The old (initial) document set, m~, is taken as 160 documents. 129 
 b) The index vocabulary T is prepared with respect to the document set of (~a) and a D matrix of /)~-~0 
is generated to be used in the experiments. Table 3 shows the database characteristics. A slight reduction 
in the size of n as compared to its size in Table 1 can be noticed in the table. This is due to the reduced 
size of m~. me was increased up to 54 docu- ments (i.e., mJmt=34 %) and that is a reson- ably large increase. 
Table 3, Database charactevisfics ~vith Ds-4o and m,1=160 In the retrieval experiments the entire set 
of 214 database documents and the query collection of fifty seven queries were divided into old and new 
such that the relevance characteristics of docu- ments with respect to queries were preserved. In other 
words, as also stated in [13], r,/ml=r2/m2 where r~ and re are the number of relevant docu- ments in 
the old and new documents respectively. In this way the probability of a given document's relevance to 
any query is not varied with respect to the set of old and new documents. This is aone to maintain the 
neutrality of our experimental environment. Although relevance of documents to ueries has nothing to 
do with the maintenance gorithm, bunching up all the relevant docu-ments in the initial set of ml documents 
would not have left us anything to experiment with! In the experirnents [16] we have used the weighted 
D matrix and the single-pass clustering, the latter being needed for CBR. A centroid entry was computed 
as the total weight of the corresponding term in all the documents of the cluster divided by the size 
of the cluster. The matching function was the coupling function intro- duced earlier whose results are 
compatible with those of the cosine similarity function. The cou-pling function has been introduced [5,12] 
in the C-based clustering and uses the idea of coupling of a query with the documents of the database 
in the same way inter-document couplings are pro- duced. In the first set of experiments, precisions 
corresponding to retrievals using full search, CBR with maintained clustering, and CBR after reelus- 
tering were measured at the recall levels of 0.1,0.2 ..... 1 averaged over fifty seven queries. The results 
are tabulated in Table 4. ..... Table 41Pre ci~ion values at fizecl re call levels Full Search ' CBR-recl~t 
CBR-main.ce RECALL Precision Precision Precision O. 1 O. 4089 o. 3485 0. 345,3 O. 2 0, 3301 o. 2930 " 
o. 3061 O. 3 O. 2604 0.243? o. 2808 O. 4 O. 2324 0.2313 0.2520 O. 5 O. 2275 o. 2209 O. 2489 O. 6 o. 1943 
o. 1859 0. 2,036 0. 7 0.1931 0. t 791 0.1874 0. 8 O. 1827 o. 1682 0.1766 i 0. 9 o. 1720 0.1492 9.1592 
i 1.0 i O. 1659 0.1404 O. 1592 The results in Table 4 show that the precisions of CBR with the maintained 
clustering are compa-tible with those of the CBR after reclustering as well as direct full search. In 
terms of the total search effort in CBR we compare the query vector with the centroid vectors and subsequently 
with the document vectors of the three selected (tar- get) clusters. In full search we compare the query 
vector with all the document vectors of the entire D matrix. The correlation percentage (CP) has been 
defined [5,13] as the ratio between the total comparisons of the former and the latter (i.e., CP=full 
search effort/CBR effort]. ]n Table 5 we present another set of comparisons this time with variable number 
of selectedclusters versus recall, precision, and CP, all between CBR with mainte- nance and CBR after 
reclustering. Table 5. Varhz2ions eff recail, trrecisien, and CP with ~zurnbeT of clusters exarninecl 
No, expanded Recall Clusters Recluster~ng Maint enanc e 1 O. 2782 0.2155 2 O. 3562 0. 2993 3 0. 4094 
0.4076 4 0. 4666 O. 4588 5 0. 4892 0. 4865 6 0. 5340 0.5247 7 0. 5513 0. 5431 8 O. 5729 0. 5936 9 O. 
5886 0. 6035 10 O. 5904 0.6115 Table 5 co~t/ztueg Pre cis,i, an CP Recluster~n~l Maintenance ReclusteTi~ 
Maint e nan e e O. 2860 G 2653 O. 1768 0.1731 0. 2190 0. 2603 0.2194 0.9160 O. 9144 0.2669 O. 2609 0. 
2608 O. 1996 0.2320 0.2988 0. 3036 0.1912 O. 2387 O. 3382 0. 3504 O.1830 0.2198 O. 3895 O. 3932 0.1854 
O. 2053 0.4313 o. 4352 0.1923 0.1818 0.4774 0.4716 O.1858 0.1739 O. 5103 O. 5089 O.1675 0.1705 O.5484 
0.5499 Table 5 shows that as we examine more and more clusters the recall will increase parallel to increase 
in CP. Also, in the table we can see that the recall values for reclustering are slighly better than 
those of maintenance. The opposite is true for precision. In both recall and precision, as well as in 
CP, the maintenance results are compatible with those of reclustering. The average recall for fifty seven 
queries in the ease of full sereh reaches 0.6881. On the other hand we reach a recall of 0.4865 (i.e., 
71% of full search case) with. a CP of 0.35 (i.e., 35Yo of search effort of full search) with just examining 
five clusters, in the case of CBR with maintenance. For more reduction a cluster hierarchy [10] must 
be built instead of the single level cluster search performed here.  5. CONCLUSIONS The value of a 
clustering strategy is reflected not only by its ability to meet various clustering objectives efficiently, 
but also by its ability to han- dle dynamic cluster maintenance efficiently and effectively. To judge 
the effectiveness of a cluster maintenance scheme we can compare its similar- ity and stability with 
respect to the initial set of clusters and clusters resulting from reclustering of the entire collection 
including the new addi-tions. We can also assess the behavior of main- tained clustering in retrieval 
environments. We have introduced a new cluster mainte-nance technique which draws its roots from the 
cover coefficient based clustering methodology introduced previously. To observe the behavior of this 
maintenance scheme we have conducted experiments to compare the similarity/stability of the maintained 
clusters with those of the clusters existing before maintenance and those obtained after complete clustering. 
The results obtained show that similarity/stability of maintained clus-ters was consirably high even 
with the large number of additions to the database. This also led to the observation that because of 
high stability the number of falsified documents due to new additions is relatively small wh_tch in turn 
reduces the cost of maintenance. In the retrieval experiments we compared the recall, precision, and 
search effort performances of the unclustered database with those of the clustered database after maintenance 
and reclus- tering. The recall and precision of cluster based retrieval yields satisfactory effectiveness 
.with small number of clusters examined and total search effort spent. In addition the recall, preci- 
sion, and search effort of maintained clusters are observed to be closely compatible with those of the 
reclustered database. Finally, if we review the proposed maintenance algorithm quantitatively the following 
can be sum- marized: It allows large extensions (e.g., me =0.9) ~TZ. without deterioration (c.f. Figures 
2 &#38;3~ and at a small cost of incremental clustering (c.f. Figure 4). The cost of maintenance is predictable 
before- hand (see step (d) of the algorithm) so that decision as to whether recluster or execute maintenance 
can be assessed at the begin-ning. The concept of thresholding, and the difficulty of supplying a threshold 
do not exist. As can be seen from the algorithm the CC-based maintenance is straightforward and easily 
implementable. 6. REFERENCES <RefA>1. Anderberg, M.R. Cluster Analysis for Applica- tions. New York: Academic 
Press; 1973. 2. Can, F., Ozkarahan, E.A. A CZustering Scheme. Proc. of the ACM SIGIR Conf. Bethesda, 
MD; pp. 115-121: 1983. 3. Can, F., 0zkarahan, E.A. Two Partitioning Type mustering Algorithms. Journal 
of the erican Society for Information Science. Vol.35, No.5, pp.268-276; 1984. 4. Can, F. A New Clustemng 
Scheme for Informa 5 tion Retrieval Systems Incorporating the Sup-port of a Database Machine. Ph.D. disserta-tion, 
Department of Computer Engineering, Middle East Techrdeal University; Ankara, January 1985.  5. Can, 
F., 0zkarahan, E.A. Concepts of the Cover Coefficient-Based Clustering Methodology. Proc. of the ACM 
SIGIR Conf.; Montreal, pp.204-211; 1985. 130 Crouch, D.B., A File Organization and Mainte- nance Procedure 
far Dynamic Document Col-lections. Information Processing and Management. Vol. 11, pp. 11-21; 1975. 7. 
Deogun, J.S., Raghavanl V.V. User-oriented Document Clustering.'A Framework for Learn- ing in Information 
Retr~evaLProc. of the ACM SIGIR Conf.; Pisa, pp.157-163; 1936. 8. Kutluay, S. Validity Analysis of the 
Cover Coefficient Concept on Clustering. Msc Thesis, Dept. of Electricaland Electronic Eng., Middle East 
Technical University; Ankara, 1986. Milligan, G.W., Soon, S.C., Sokol, L.M. The Effect of Cluster Size, 
D~mensionality, and Number of Clusters on Recovery of True Clus- ter Structure. IEEE Transactions on 
Pattern Analysis and Machine Intelligence. Vol.-PAMI-5 No. 1; 1983. 10. 0zkarahan, E.A., Can, F. An Integrated 
Fact/Document Information System for Office Automation, Information Technology: Research and Development. 
Vo. 3, No.3, pp. 142-156; 1984. 11. 0zkarahan, E. Database Machines and Data-base Management. Englewood 
Cliffs, New Jer- sey: Prentice-Hal]; 1986. 12. Ozkarahan, E.A., Can, F. An Automatic and Tunable Document 
Indexing System.Proc. of ACM SIGIR Conf.; Pisa, pp.234-243; 1986.  i3. Salton, G. Dynamic Information 
and Library/Processing. Englewood Cliffs, New Jer- sey: Prentice Hall; 1975. 14. Salton, G., Wong, A. 
Generation and Search of Clustered Files. ACM Transactions on Data-base Systems. Vol.3, No.4, pp.321-346; 
1978. 15. Salton, G., McGill, M.J. Introduction to Modern Information Retrieval. New York: McGraw Hill, 
1983.  16. Ural, M.H. Performance Evaluation of the Cover Coefficient Based Clustering and Clus-ter 
Maintenance Methodology in Information Retrieval. Msc Thesis, Dept. of Electrical and Electronic Eng., 
Middle East Technical Univer- sity; Ankara, 1986. 17. Van Rijsbergen, C.J. Information Retrieval. 2nd 
ed. London: Butterworth Scientific Pub-lishers; 1979.</RefA>   ACKNO~.EDGEMENTS We gratefully acknowledge 
the contributions of M. Sina Kutluay and M. Haluk Ural of the Middle East Technical University in various 
experiments.  
			
