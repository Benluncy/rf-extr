
 Antialiased Ray Tracing by Adaptive Progressive Refinement James Painter and Kenneth Sloan University 
of Washington ABSTRACT We describe an antialiasing system for ray tracing based on adaptive progressive 
refinement. The goals of the system are to produce high quality antialiased images at a modest average 
sample rate, and to refine the image progressively so that the image is available in a usable form early 
and is refined gradually toward the final result. The method proceeds by adaptive stochastic sampling 
of the image plane, evaluation of the samples by ray tracing, and image reconstruction from the samples. 
Adaptive control of the sample generation process is driven by three basic goals: coverage of the image, 
location of features, and confidence in the values at a distinguished "pixel level" of resolution. A 
three-stage process of interpolation, filtering, and resam- pling is used to reconstruct a regular grid 
of display pixels. This reconstruction can be either batch or incremental. CR Categories and Subject 
Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation - Display algorithms Additional Keywords 
and Phrases: Adaptive Sampling, An- tialiasing, Filtering, Progressive Refinement, Ray Tracing. Department 
of Computer Science, FR-35 Seattle WA 98195 U.S.A. This work was supported in part by the National Science 
Foundation under grant numbers DCR - 8505713, CCR - 8612543, and IRI -8081932. Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0281 
$0035 1. Introduction Raster graphics is inherently a sampling process. A render- ing program is given 
a scene description and should produce a "realistic" approximation of it for display. The scene description 
and the physical model of lighting embodied in the rendering program define an image function giving 
a color at each point in a continuous domain representing the screen plane. The rendering program's output 
is a discrete array of pixel values representing colors at points on a discrete regular grid representing 
the screen. Because rendering is a sampling process, it is prone to aliasing artifacts where the frequency 
spectrum of the image function is not band limited before sampling. Ray casting methods of rendering 
have become popular in the last several years. Their benefits include conceptual simplicity and the ability 
to model complex lighting effects such as shadows, transparency, and reflections. One of the major disadvantages 
has been their susceptibility to aliasing artifacts. These methods are prone to aliasing because they 
sample the image function only at discrete points in its domain. Aliasing can be reduced, however, if 
the sampling pattern is generated by a stochastic process which is uncorrelated with the image function. 
These randomly placed samples can be filtered and resampled at the screen resolution for display. Ray 
tracing is a very slow process, particularly when an-tialiasing algorithms are used. Should a mistake 
be made in constructing the model for rendering, hours of cpu time may be lost before the error is realized. 
Typically, low resolution images are created first for previewing and then discarded. A ray tracing algorithm 
which produces a usable image relatively quickly and refines it gradually to the final image would alleviate 
this problem. This paper describes a new method for antialiased ray tracing which proceeds by adaptive 
subdivision of the image plane. 2. Prior Work Several researchers [2], [7] have explored the idea of 
pro- gressive refinement in image generation. The main difference in this work is the rendering method. 
Our method is based on ray tracing rather than z-buffer [2], or radiosity [7] algorithms. Our own earlier 
work [3] relates progressive refinement in image transmission to the rendering problem. Previous researchers 
in the area of antialiased raytracing have been concerned with three subproblems: selection of efficient 
sampling patterns, methods to adaptively control the sample rate, and filters for image reconstruction. 
 ':~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 2.1 Sampling Pattern Selection Stochastic sampling 
methods for image synthesis have been reported in [9], [8], [11], and [15]. The qualities desired in 
a stochastic sampling pattern are that it minimize visible aliasing artifacts, minimize visible noise, 
and be efficiently evaluated. The spectral characteristics of the noise are also important: the human 
visual system is more sensitive to narrow-band noise than broad- band noise and to low frequency noise 
rather than high frequency noise. The noise properties of a sampling pattern can be evaluated by examining 
the Power Spectral Density of the sampling pattern applied to a constant image function. Two families 
of sampling patterns have been examined in the literature: Jittered sampling divides the domain to be 
sampled into a regular lattice of rectangular cells. A sample is distributed uniformly into each lattice 
cell. Jittered sampling ensures that the sampling pattern avoids large gaps. Poisson Disk distributions 
sample over the domain uniformly but with the added constraint that no two samples may be closer than 
a specified minimum distance. Poisson disk sampling ensures that the sampling pattern avoids excessive 
clumping. The Poisson disk distribution has been used as a model for the distribution of photoreceptors 
in primates [191. The relative merits of jittered sampling and Poisson disk sampling have been discussed 
in [11], [8], and [15]. Jittered sampling is favored by Cook because the samples can be produced efficiently. 
Mitchell favors the spectral properties of Poisson disk distributions because they minimize low frequency 
noise introduced in the sampling processes. He gives an algorithm for efficiently approximating a Poisson 
disk distribution at a fixed sample rate. A variant of jittered sampling, hierarchical sampling, has 
been used effectively with a variable sample rate. 2.2 Adaptive Sampling Rate Computer-generated images 
do not exhibit uniform local image variation. Edges between objects are areas of high contrast (or variance), 
while large, uniform objects and backgrounds yield regions which have little local variation. Adaptive 
sampling adjusts the sample rate locally to concentrate samples where they are needed most: at edges 
and other regions of high contrast. This can substantially reduce the number of samples required to achieve 
the desired image accuracy. Adaptive sampling requires an error estimator and a stopping condition. The 
error estimator indicates how closely the sample values represent the local mean of the image function, 
or alter- natively, the local noise level present in the sampled image. The stopping condition is a threshold 
on the error estimator used to determine when enough samples have been taken. Lee, Redner and Uselton 
[13] present an error estimator based on local image variance. Their sampling approach is based on area 
sampling of each pixel, evaluating the output image as an expected value of the input image sampled over 
an area. Under the assumption that the image function has a normal distribution locally (a questionable 
assumption), they develop a confidence interval test which gives the probability that the variance of 
the sample mean is below a specified tolerance. Sampling continues until the desired probability is reached. 
Traditionally, stopping conditions for simulation experiments are based on a confidence interval of the 
mean estimator itself rather than its variance [5]. The error estimator given in [13] does not directly 
specify a desired confidence interval of the mean but instead, of its variance. Since the mean is the 
parameter we are interested in estimating, it would be more appropriate to apply the confidence interval 
analysis to it directly. Dipp6 and Wold [11] propose a different error estimate based on the root mean 
square signal to noise ratio (RMS SNR) of the stochastically sampled and reconstructed image function. 
They show that the RMS SNR is proportional to the square root of the sample rate. The constant of proportionality 
depends on the image function and the reconstruction filter but is independent of sample rate. The RMS 
SNR is approximately the absolute value of the difference between the stochastically sampled and filtered 
function and the perfectly filtered function. This allows an estimate of the rate of change of the RMS 
SNR as a function of the square root of the sample rate to be estimated from the sampled and filtered 
image at two different sample rates. Mitchell [15] suggests that variance is not an appropriate measure 
of perceived image variation, because the human visual system does not exhibit linear response properties 
to rapid changes in intensity. Instead, he proposes that contrast is a better measure. Adaptive sample 
rate control places an additional burden on the sample generation scheme. Since it is not known in advance 
how many samples are to be taken, every prefix of an ordered set of samples should be well distributed 
over the sample area. Algorithms which produce samples in a raster scan order are unsuitable. The hierarchical 
sampling method given in [12] is a suitable method for generating jittered sampling patterns. Dipp6 suggested 
that Poisson Disk samples can be created in a uniform order by coupling the minimum distance constraint 
to the local sample rate. As more samples are needed in a given area, the minimum distance is decreased. 
Mitchell avoids the problem by using a very limited form of adaptation with only two different sample 
rates Mitchell [15] uses a two level technique to accomplish a limited form of sample rate adaptation. 
The image is first sampled at a moderate sampling rate. Areas of high contrast are sampled at a higher 
rate. Contrast is measured over a neighborhood of approximately 8 samples. This avoids the problems of 
previous methods which required many samples per pixel just to determine the image variation over a single 
sampling region. It is liable, however, to completely miss small objects which fall between the samples 
in the initial, rather coarse, sampling.  2.3 Image Reconstruction Once the input image function has 
been sampled at a set of stochastic sample points, it must be filtered prior to resampling for display. 
Filtering accomplishes two purposes. First, the image function should be filtered to limit its high frequency 
content to avoid aliasing when it is resampled for display. Second, the filter can be used to attenuate 
noise introduced in the stochastic sampling process. The properties of a filter depend on its width and 
its shape. Practical filters have a finite width, that is, they are non-zero except on a finite region. 
Commonly used filter shapes include box filters, triangular filters, raised cosine filters and Gaussian 
filters. The choice of filter width and shape depends on the desired attenuation of frequencies above 
Nl/2 (the Nyquist limit), and the tolerance for attenuation of frequencies below Nx/2. In addition, the 
computational costs must be considered. Extremely wide filters are expensive to compute by direct convolution. 
A varying sample rate compounds the problem of applying a filter. The number of samples under the filter 
kernel will vary depending on the local sample rate. If direct convolution is used, areas with more samples 
appear brighter than areas with fewer samples. Dipp6 suggested that the filter should be normalized: 
the sum of the weighted sample values should be divided by the sum of the filter weights. A normalized 
filter improves matters but does not eliminate the problem. Some consideration must be made for the size 
of the region each sample represents. Otherwise, image values in areas of dense sampling will dominate 
nearby' areas which are sparsely sampled. Ideally, we would like to weight each sample point by the volume 
contained under the filter function over the area the sample represents. The hierarchical sampling method 
associates a cell with each sample. This cell provides a natural region for use in weighting the sample. 
Mitchell attacl&#38; the problem with a multi-stage filter. The sampled image function is filtered multiple 
times with filters of wider and wider support, resulting in lower and lower cutoff frequencies. The narrow 
filters in the early stages average densely sampled regions into single samples covering a larger region. 
Subsequent stages average these larger regions into pixel sized samples for display. Mitchell used four 
stages of box filters with three different widths. While a single box filter does not provide adequate 
high frequency attenuation, repeated box filtering does, approaching a Gaussian filter in the limit. 
3. System Description Our method is composed of three stages: sample generation, sample evaluation and 
image reconstruction (resampling). 3.1 Sample Generation The purpose of the sample generator is to choose 
points in the spatial domain of the image where the image function is to be evaluated. Information from 
prior samples is used to decide which areas of the image have the greatest need for additional samples. 
In addition, the sample generator determines when to stop sampling. It should also order the samples 
to allow for progressive refinement of the rendered image. Early methods [ 13], [ 12] treat the sample 
generation problem independently at each pixel. Each pixel is sampled until a stopping condition is meet. 
Samples taken for one pixel are not used for other pixels. One of the major problems with this approach 
is that a fairly high minimum sample rate (typically 8 samples per pixel) is required simply to determine 
that a pixel is uninteresting and need not be sampled further. Later work [15] lowers the average sample 
rate, in part by sharing samples between pixels. This lowers the minimum sample rate required to evaluate 
the stopping condition. [15] uses a very simple, two level stopping condition. The image is first sampled 
at a coarse sample rate. Selected areas are sampled at a finer rate as needed. It is our belief that 
a further reduction in the sample rate will be realized if the sample rate is allowed to vary over a 
wider range of values. Our sample generator is based on hierarchical integration, a sampling method described 
by Kajiya in [12]. Kajiya applied hierarchical integration independently to each pixel. We apply the 
technique to refine the entire image plane. 3.1.1 Data Structures In our implementation, as in [12], 
the sample generator maintains a k-D tree [1] containing all the samples taken. The k-D tree is a binary 
tree which partitions the two dimensional image plane by alternately splitting in x and y. On even levels, 
the domain is split along a line parallel to the x axis. On odd levels, the domain is split along lines 
parallel to the y axis. The leaf nodes in the tree store the raw sample values and positions. An internal 
node of the tree stores an estimate of the mean value of the image function over the region covered by 
that node, an estimate of the variance of this mean estimate (internal variance), and the number of samples 
in the subtree rooted at this node. All nodes also store an external measure of variance. The external 
variance is computed from the mean estimates of the node and all of its neighbors at the same level in 
the tree. 3.1.2 Refinement Rules When a new sample is needed, a path from the root to a leaf is followed 
leading to the region with the greatest need for further refinement. At each (binary) branch in the k-D 
tree, a decision is made as to which subnode to refine. The decision is based on the variance estimates 
(both internal and external) of the node, the area of the node, the number of samples already contained 
in the node and the level of the node in the tree. We distinguish a level of the tree, called the pixel 
level which is the level of the tree corresponding to pixels in the anticipated reconstruction. The goal 
of the refinement process is to produce the best answers at the pixel level. This leads to different 
strategies above and below the pixel level. At coarse levels, above the pixel level, we are driven by 
the progressive refinement goals: Coverage --refine large regions before smaller ones and Feature Location 
--refine "edge" cells before non "edge" cells. A heuristic is required to rank the pixel level nodes 
according to refinement priority. We use the product of external variance and area as a priority measure. 
The area term enforces the coverage goal while the external variance enforces the feature location goal. 
Nodes at the pixel level, or leaves above the pixel level, are assigned a priority by direct computation. 
Internal nodes above the pixel level are assigned a priority value which is the maximum of the two child 
priority values. Thus, a path can be followed from the root to the highest priority pixel by always branching 
toward the subnode with higher priority (ties are broken randomly.) At finer levels, below the pixel 
level, our only goal is to increase our confidence in the mean of the pixel level node above. To do this, 
we use the principles of stratified sampling [13]. If two subnodes have mean estimates of #~ and It2 
and mean estimate variances of crj and ~r2 and are of equal area, the mean of the parent node can be 
estimated as It = (It1 + It2)/2 with variance of the mean estimate given by ~r = (~rl + ~r2)/4. This 
mean estimate is often better and never worse than that given by the mean of all the sample values. If 
we want to improve the mean estimate of the parent node, the best choice is to refine the subnode with 
the highest mean variance. This is the only refinement principle used in hierarchical sampling [12] since 
it only operates below the pixel level. 3.1.3 Stopping Condition The stopping condition is based on 
a confidence interval test. A desired confidence level and confidence interval is selected. For example, 
we require that 99% of the time (or = .01, the confidence level) the mean estimate at each pixel will 
be within 1/255 (the confidence interval) of the correct value. We can take into account the nonlinear 
response characteristics of human visual perception by allowing the confidence interval to vary with 
the mean estimate value. For example, we might specify that small mean estimates require a smaller confidence 
interval than large mean estimates. The confidence interval for a given confidence level can be computed 
from the variance of the mean estimate and the number   ~,...~SIGGRAPH '89, Boston, 31 July-4 August, 
1989 of samples taken, [5]. If the desired confidence level is 1 -c~, the confidence interval is given 
by t~/2a where t~/2 is taken from the student-t distribution with n -1 degress of freedom, n is the number 
of samples contributing to the mean estimate, and a is the variance of the mean estimate. When the sample 
count within a pixel node is small, the mean estimate variance can approximated from the external vari- 
ance. A subtree rooted at a pixel level node is "'closed off" when the confidence interval at the desired 
confidence level becomes at least as small as the desired confidence interval. Once closed off, no more 
samples will be taken within the subtree. An internal node above the pixel level is closed off when both 
of its offspring are closed. The confidence interval test is not the only stopping con-dition. A coverage 
condition is imposed to ensure that small objects are not missed completely. We require that all nodes 
are refined at least to the pixel level to ensure that no objects larger than one pixel are missed. Note 
however that no direct limit on the number of samples within a pixel is required. An upper bound on number 
of samples per pixel can be determined from the confidence interval and confidence level requirements. 
3.2 Sample evaluation The purpose of the sample evaluator is to evaluate the image function at a single 
point in the image plane. In this implementation, the image function is evaluated by a ray tracing algorithm 
[18]. The sample evaluator used here is part of Renaissance, a modelling and rendering system developed 
at the University of Washington [14]. 3.3 Reconstruction The purpose of the reconstruction process is 
to resample the image function on a regular grid for display. This can be considered as a three step 
process: First, an interpolation scheme is used to interpolate color values between the samples generated 
by the sample generator. Next, the resulting image function is convolved with a low-pass filter to reduce 
aliasing and to attenuate high frequency noise introduced in the original sampling process. Finally, 
the filtered image function is point sampled at the center of each pixel of the display. In practice, 
the last two steps are combined so that the filtered image function need only be evaluated at the center 
of each display pixel. 3.3.1 Piecewise Constant Interpolation We first consider a very simple interpolant: 
piecewise con-stant. While the interpolant is not particularly well behaved (it's not continuous) it 
makes the filter convolution computationally efficient. The k-D tree data structure generated during 
sampling pro- vides a basis for our interpolation scheme. The data structure partitions the plane into 
rectangular cells aligned with the coordi- nate axes, each containing exactly one sample point. An obvious 
interpolant, albeit not a continuous one, is to assign the value of the sample to the entire cell in 
which it is contained. This gives a piecewise constant image function defined everywhere in the image 
plane. The piecewise constant form of the interpolated image func- tion can be exploited to simplify 
filtering. Convolution of a filter with a constant function reduces to integration of the filter function. 
i(u, v) * f(u, v) = j j$ z(u , v')f(u -u , v -v') du' dv' = C ~JR f(u -u', v -v') du' dr' where i(u, 
v) is constant with value C over the region R and zero elsewhere. To find the contribution one of the 
sampling cells makes on a display pixel, we need only integrate the filter function over the sample cell 
and multiply it by the value in the cell. The filtered image value at a pixel is evaluated by summing 
the contributions from all the sample cells which overlap the domain of the filter function centered 
at the pixel. I(x,y)=~C(s) ]] f(u -u',v-v')da' dv' (3.1) sES J J Rn~ where 1 is the value to be assigned 
to pixel (x, y), S is the set of sample cells that overlap the filter support, and R is the filter support 
centered at pixel (z, y). For polynomial filters, the integral can be evaluated ana-lytically. When analytic 
integration is intractable, the filter can integrated approximately and stored in a summed area table 
as described in [ 10]. The summed area table stores the pre-integrated filter function. Integrals of 
the filter function over sample ceils can be evaluated by querying the filter summed area table at the 
corners of the sample cell. The idea of storing the filter function in a summed area table has been explored 
in font filtering, [16]. A bivariate filter function f(~, v) is separable if it can be decomposed into 
the product of two univariate filters, fl(u)f2(v). Most filters used in computer graphics are separable. 
A separable filter kernel can be stored more compactly as two 1-D summed area tables rather than one 
2-D summed area table. The space required is O(N) rather than O(N 2) where N is the number of discrete 
intervals used to approximate the filter. The example images shown in the figures were reconstructed 
using a Lanczos windowed sinc filter [4] over a 7x7 pixel filter support. The filter was discretized 
and stored as a 1-D summed area table with 4096 entries. 3.3.2 Higher Degree Interpolants The method 
described above uses a particularly simple interpolant to simplify convolution with the filter function. 
We are currently considering reconstruction methods using higher quality interpolants. First, the sample 
points can be used to triangulate the image plane using a Delaunay triangulation, [17]. A triangle based 
interpolation scheme can be used to interpolate a surface through the sample values. The simplest interpolation 
scheme is piecewise planar: interpolate within each triangle in the plane formed by the three triangle 
vertices. This scheme produces an image function which is C °, but not C ~. C ~ triangle based interpolation 
is also possible [61. Next, the interpolated image function must be convolved with the filter function 
and evaluated at the pixel centers. When the filter function and the image function are both piecewise 
polynomial, this convolution can be performed analytically. When analytic convolution is not tractable, 
a discrete approximation may be used. However, the usual summed area table requires rectangular regions. 
We are currently exploring appropriate data structures for discrete convolution over triangular patches. 
 3.3.3 Progressive Reconstruction One of the the goals of this work is to have the rendered image available 
in a usable form very early in the rendering process and to progress incrementally toward the final result. 
We have seen that the sample generator meets this goal. In this section we consider the impact of the 
progressive refinement goal on reconstruction algorithms. When the time required for reconstruction is 
much smaller than the sample generation and evaluation time, the image can be reconstructed from scratch 
from the available samples each time an update is desired. Hence, a fast batch method may be adequate 
for viewing intermediate results. A slower, higher quality reconstruction method can be used for the 
final image. An alternative is an incremental reconstruction scheme. Each time a new sample is taken, 
the pixels affected by the sample are updated. The reconstruction method described in section 3.3.1 is 
batch oriented. The value of a each pixel is determined only after all the samples which affect it are 
known. With a little effort, the computation can be reordered to allow an incremental algorithm. When 
a sample cell is created, a single term from the sum in equation 3.1 can be evaluated. This term can 
be added to a running sum for the pixel. This must be done for every pixel affected by the sample cells, 
those whose filter supports overlap the sample cell. When a sample cell is subdivided, its contribution 
must be subtracted from the pixels it affects and the contribution of its new subcells added in. The 
reconstruction methods described in section 3.3.2 can also be evaluated incrementally by the use of an 
incremental Delaunay triangulation algorithm. Each time a triangular tile is included or removed, its 
contribution to each pixel affected is evaluated and added or subtracted respectively. 4. Performance 
Two test images are shown in Figures 2 and 3 to illustrate the performance of the system. The tables 
below give performance statistics for the system when evaluating the two test images. The cpu time is 
divided into three categories: sample genera- tion, sample evaluation, and reconstruction. Note that 
sample evalutation time dominates. The cost of evaluating samples via ray tracing is high enough that 
the time spent generating sample points and filtering the samples for reconstruction is relatively unimportant. 
Note that as the resolution increases the average sample rate decreases. This is accounted for by the 
fact that with increasing resolution, the ratio of "edge" pixels to "internal" pixels in general decreases. 
Images involving fractal based textures may not show this behavior. Figures 4 and 5 show the number of 
rays required at each pixel as an intensity image. The intensity image is scaled from full black at 0 
samples per pixel to full white at 20 samples per pixel. Any pixels above 20 samples per pixel are painted 
red. The histograms of the number of samples show that nearly all pixels require fewer than 10 samples 
per pixel. Comparisons with data reported in [13] show a significant reduction in the sample rate required. 
It is difficult to compare our performance figures with [15] since he did not report comparable statistics. 
5. Conclusions We have presented a rendering system which produces high quality antialiased images with 
relatively low average sample densities. A single adaptive sampling mechanism can be used to achieve 
several, sometimes conflicting, goals. This method generalizes hierarchical integration [12]. At coarse 
levels of resolution, we concentrate on producing a low-quality sketch of the final image. The emphasis 
is on detecting objects and features (such as edges.) Subsequent samples are aimed at refining these 
features. Finally, we concentrate on improving the accuracy of averages over "pixel-sized" pieces of 
the image. The quality of images reconstructed from these samples is roughly the same everywhere in the 
image. The amount of work done can be controlled interactively ("that looks good enough") or by a pre-set 
specification of the image quality. A two parameter family of reconstruction algorithms for scattered 
samples has been presented. The methods consist of three phases: interpolation, filtering and resampling. 
The interpolation scheme and reconstruction filter may be selected to choose a particular reconstruction 
method from this family. 6. Acknowledgements Dan O'Donnell provided the lamp model. Gemini Lasswell provided 
the solid texture function for the teapot. Thanks to the UW Grail group for providing a rich supply of 
ideas and a software base to build on. ':L,f~SIGG RAPH '89, Boston, 31 July-4 August, 1989 References 
<RefA>1. Bentley, Jon L. and Friedman, J.J. Data Structures for range searching. ACM Comp. Surv. I1, 4 (1979), 
397---409. 2. Bergman, Larry, Fuchs, Henry, Grant, Eric and Spach, Susan Image Rendering by Adaptive 
Refinement. Computer Graphics 20, 4(Aug., 1986), 29-37, Proceedings of SIGGRAPH '86 (Dallas, Texas, August 
18-22, 1986). 3. Blanford, Ronald P., Painter, James S. and Sloan, Kenneth R. Adaptive Sampling, Transmission, 
and Rendering of Images. SPIE Proceedings 1077 (Jan., 1989), SPIE Conference on Hu- man Vision, Visual 
Processing, and Digital Display. 4. Blinn, James E Return of the Jaggy. IEEE Computer Graph- ics and 
Applications 9, 2 (Mar., 1989), 82-89. 5. Burr, Irving W. Applied Statistical Methods. Academic Press, 
New York, NY, 1974. 6. Cendes, Zoltan J. and Wong, Steven H. C l Quadratic Inter- polation Over Arbitrary 
Point Sets. IEEE Computer Graphics and Applications 7, 11 (Nov., 1987), 8-16. 7. Cohen, Michael E, Chert, 
Shenchang E., Wallace, John R. and Greenberg, Donald E A Progressive Refinement Approach to Fast Radiosity 
Image Generation. Computer Graphics 22, 4 (Aug., 1988), 75-82, Proceedings of SIGGRAPH '88 (Atlanta, 
Georgia, August 1-5, 1988). 8. Cook, Robert L. Stochastic Sampling in Computer Graphics. ACM Transactions 
on Graphics5, I (Jan., 1986), 51-72. 9. Cook, Robert L., Porter, Thomas and Carpenter, Loren Dis-tributed 
Ray Tracing. Computer Graphics 18, 3 (July, 1984), 137-146, Proceedings of SIGGRAPH '84 (Minneapolis, 
Min- nesota, July 23-27, 1984). 10. Crow, Franklin C. Summed-Area Tables for Texture Mapping. Computer 
Graphics 18, 3 (July, 1984), 207-212, Proceedings of SIGGRAPH '84, (Minneapolis, Minnesota, July 23-27, 
1984). 11. Dipp6, Mark A.Z. and Wold, E.H. Antialiasing through Stochastic Sampling. Computer Graphics 
I9, 3 (July, 1985), 69-78, Proceedings of SIGGRAPH '85, (San Francisco, Cali- fornia, July 22-26, 1985). 
 12. Kajiya, James T. The Rendering Equation. Computer Graph- ics20, 4(Aug., 1986), 143-150, Proceedings 
of SIGGRAPH '86, (Dallas, Texas, August 18-22, 1986). 13. Lee, Mark E., Redner, Richard A. and Uselton, 
Samuel E Statistically Optimized Sampling for Distributed Ray Tracing. Computer Graphics 19, 3 (July, 
1985), 61-67, Proceedings of SIGGRAPH '85 (in San Francisco, CA, July 22-26, 1985). 14. Lounsbery, J. 
Michael The Renaissance Modeling System. Dept. of Computer Science, Univ. of Washington, Tech. Rep. #89-01-05, 
Jan., 1989. 15. Mitchell, Don P. Generating Antialiased Images at Low Sam- pling Densities. Computer 
Graphics 21, 4 (July, 1987), 65-69, Proceedings of SIGGRAPH '87 (Anaheim, CA, July 27-31, 1987). 16. 
Naiman, Avi and Fournier, Alain Rectangular Convolution for Fast Filtering of Characters. Computer Graphics21, 
4(July, 1987), 233-242, Proceedings of SIGGRAPH '87, (Anaheim, CA, July 27-31, 1987). 17. Preparata, 
Franco P. and Shamos, Michael I. Computa-tional Geometry: An Introduction. Springer-Verlag, New York- 
Heidelberg-Berlin, 1985. 18. Whitted, Turner J. An Improved Illumination Model for Shaded Display. Communications 
of the ACM 23, 6 (June, 1980), 343-349.  19. Yellott, James I. Jr. Spectral Consequences of Photoreceptor 
Sampling in the Rhesus Retina. Science 221 (July, 1983), 392-385.</RefA> Samples per Pixel Histogram for Lamp 
Image (512x512) 120~ 100 - 80 --Number of 60 - Pixels (x 103) 40 -i 20 - 02 5 t0 15 20 25 Figure 1. 
The k-D subdivision of the image plane. The bold path Samples per Pixel leads to the next node to be 
subdivided. Samples per Pixel Histogram for Teapot Image (512x512) Algorithm Performance: Lamp Image 
 120 Cpu time (seconds) 100 Resolution Generate I Evaluate Reconstruct Rays per Pixel 64 250.5 2900 
286.1 5.002930 80 Number 128 753.9 9800 906.6 3.905520 of Pixels 60 256 2117.9 33900 2883.7 3.012775 
(N 103) 40 512 7075.3 103620 9505.7 1.880589 20 0 --1 5 10 15 20 25 Algorithm Performance: Teapot Image 
 Samples per Pixel Cpu time (seconds) Resolution Generate Evaluate Reconstruct Rays per Pixel 64 125.1 
710 169.2 2.607670 128 456.8 2680 605.6 2.347838 256 1777.9 9594 2276.7 2.139068 512 6466.6 34217 8629.7 
1.970165  
			
