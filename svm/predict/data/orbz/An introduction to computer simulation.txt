
 Proceedings of the 1994 Winter Simulation Conference ed. J. D. Tew, S. Manivannan, D. A. Sadowski, and 
A. F. Seila AN 1NTRODUCTION TO COMPUTER SIMULATION MIchJcl Pidd The Munagcmcnl School Lancaster Unhcrsily 
E3ailrigg Lancaster LA 1 -IYX UK ABSTRACT This paper provides a gentle introduction to the fimdamentals 
of computer simulation. It discusses the difference bet~veen the various approaches in common use and 
highlights the importance of a carefully considered approach to modelling. Its main stress is on discrctc 
event methods ~vithin lvhich it dcscribcs conceptual rnodclling. statistical aspects and the types of 
computer software ~vhich arc a~ailablc. 1 THE WHYS AND WHEREFORES OF COMPUTER-BASED MODELLING Computer 
simulation methods have been in Ltse since the 1950S and are based on the idea that an experimental 
or gaming approach can be a useful support to decision making. The idea is to try out a policy before 
it is implcrnentcd. clearly, there arc sc~cral ways in which this could bc done. The policy could be 
tried in the real world, but in a controlled ~vay so that its effects can be understood and aualysed. 
There are ob~ ious problems u ith this approach, especially in systems ~}hich are dangerous or expensive 
LOopera{e for which experimenting with the real system could turn out disaster. Nevertheless. experimentation 
does have training people. a second option mathematical model of the this is the spcciali~ of ~vould 
bc to de~clop a systcm being studied. and operations research. This to k experimenting with this type 
of direct its place, especially when approach ~vorks tvcll for some ~ pes of application (for example 
in simp]c queuing systems) but not so wcl I in others The basic problcm is that the maths needed to represent 
a complex dynamic systcm may bc impossible to SOIVCor virtually impossible to formulate ~vithout cxccssivc 
approximation. Hcncc. the third option is to simulate the systcm of interest in a computer-based model 
and then carry out cxpcrimcnts on that model to scc \vhat might bc the best policy to adopt in practice. 
in addition. a simulation approach is sometimes used in order to understand how an existing system operates 
or 11OU a proposed system might operate. Wlmt are believed to bc the rules governing the bchaviour of 
the systcm arc captured in a computer-based model and the beha~iour of this model is used to infer how 
the system being modclled might itself operate. 1.1 The essence of computer-based modelling A computer-based 
model is at the heart of any computer simulation and the question which has to be faced is, how can the 
important details of the system to be simulated bc captured within such a model ? A later section of 
this paper will discuss the main features of simulation models. but before considering these features 
it is a good idea to give some brief consideration to the process of modelling. . jk ,J,rJL.[, . dnlx. 
te Figure 1: Computer-based modclling Figure 1 shovs that at the core of this process are one or more 
human beings who are concerned to ensure that their model is appropriate for the purpose for which it 
is intended. To do this it is useful to consider the main features of Figure 1. The t(JtIgIl)lewhich 
they are attempting to ,i,v.}tem model is separate from them and. to use the ideas of Zeiglcr ( 1976. 
1984) pro~ ides a source of data from w hicll a model }vill be constructed. Different people may well 
hold different notions about the operation of this tanglblc systcm and these can bc dcscribcd in 7 concepttiat 
models which arc thcmsclvcs the result of reflection about the tangible systcm. The simulation model, 
which eventually becomes a computer program, stems from the conceptual model and is expected to be much 
simpler than the tangible system. Were it not simpler, then it would be as dit%cull to use for experimentation 
as the tangible system itself. Hence. computer-based modelling is a process of simplification and abstraction 
in which the modeller attempts to isolate those factors believed to be crucial in the operation of the 
system being modelled. This process of abstraction depends on data and information about the tangible 
system and also on the intended purpose of the simulation. 1.2 Modelling complicated dynamic systems 
Given enough time, money, expertise and computer power almost any system can be simulated on a computer, 
but this may not be sensible. Hence the next question to face is, to what type of systems are modern 
computer simulation methods best suited? The following features tend to characterise the systems best 
suited to computer simulation. They are (~ynamic, that is they display distinctive behaviour which is 
known to vary through time. This variation might be due to factors which are not well understood and 
may therefore be amenable to statistical analysis -for example, the apparently random failures of equipment. 
Or they might be due to well understood relationships which can be captured in equations -for example, 
the flight of a missile through a non-turbulent atmosphere.  They are interactive, that is, the system 
is made up of a number of components which interact with one another and this interaction produces the 
distinctive behaviour of the system. For example, the observed behaviour of aircraft under air trafilc 
control will be due to the performance characteristics of the individual aircraft. the intervention of 
the air traftic controllers. the weather and any routing problems duc to political action on the ground. 
This mix of factors }vill be varying all the time and their interaction will produce the observed behaviour 
of the air trat%c.  They are complicated, that is, there are many objects which interact in the system 
of interest, and their individual dynamics need careful consideration and analysis.  1.3 Continuous, 
discrete and mixed approaches It is normal to classify approaches to computer simulation into three groups 
and this will be done here, but it should be noted that these distinctions are ones made by the modeller 
and are not ones which occur in the real vorld being simulated. 1.3.1 Discrete event simulation The Winter 
Simulation Conference is traditionally concerned with Discrete Event .Ymwlalion. This approach is based 
on a number of building blocks as follows. each of which is discussed in more detail in #2 of this paper. 
 Individual ent~tles: the behaviour of the model is composed of the behaviour of individual objects of 
interest which are usually called entities. The simulation program tracks the behaviour of each of these 
entities through simulated time and will bc minutely concerned with their individual logics. The entities 
could be truly individual objects (e.g. machines, people, vehicles) or could be a group of such objects 
(e.g. a crowd, a machine shop, a convoy of vehicles).  Discrete events: each entity s behaviour is modelled 
as a sequence of events, where an event is a point of time at which the entity changes state. For example, 
a customer in a shop may arrive (an event), may wait for a while, their service may begin (an event), 
their service will end (an event) and so on. The task of the modeller is thus to capture the distinctive 
logic of each of these events (e.g. what conditions must hold if a be,gin service e~ei~t is to occur 
?). The flow of simulation time in a discrete event simulation is not smooth, as it moves from the event 
time to event time and these intervals may be irregular.  ,Ytochastzc behaviour: the intervals between 
events is not always predictable, for example the time taken to serve a number of customers in a shop 
will be observed to vary. There may sometimes be obvious and entirely predictable reasons for this (the 
server may speed up as the queue of waiting customers increases) or there may be no obvious reason to 
explain things. In the latter case, the \arying intervals between events has to be modelled stochastically 
by using sampling methods based on probability theory.  1.3.2 Continuous simulation A quite different 
approach to simulation is taken in Continuous Sirnuiation, which is an approach that is popular amongst 
engineers and economists. The main building blocks of this approach areas follows. b Aggregated ~,ariables: 
instead of a concern with individual entities, the main concern is with the aggregated behaviour of populations. 
For example. the changing sales of a product through time. ,Snooth changes in continuous tzme: rather 
than focusing on individual events, the stress is on the gradual changes which happen as time progresses. 
Thus, just as the graph of a variable might be smooth, the aim is to model the smooth changes of the 
variable by developing the suitable continuous equations An Introduction to I)~~2renllal or dtfjw-ence 
equations; the model consists mainly of a set of equations ~vhich define how behaviour varies through 
time, thus these tend to bc differential equations or, in simpler cases such as sj stem dynamics (Forrcstcr, 
1961 and Wolstcnholme. 19(}0), difference equations. Nature does not present itself labclled neatly as 
discrete or continuous. both clcmcnts occur in reality. Modelling, howc~cr, as mentioned in #1.1 above. 
involves approximation. and the modcllcr must dccidc which of these approaches is most useful in achieving 
the desired aim of the simulation? 1.3.3 Mixed discrete/continuous simulation In some cases, both approaches 
are needed and the result is a mixed discrete-con tinuou,s simulation. An example of this might be a 
factory in which there is a cooking process controlled by known physics which is modelled by continuous 
equations. Also in the factory is a packing line from which discrete pallets of products emerge. To model 
the factory might well require a mixed approach.  1.4 The role of software Computer software plays 
an essential role in the development and use of computer simulations and is available to support the 
following aspects. Statuitlcal analysis o~f input data: in a discrete simulation it will probably be 
necessary to model certain aspects by taking samples from probability distributions within the model. 
Thus the modeller needs to consider which distributions are appropriate for the system being considered. 
This requires the modeller to collect data (e.g. the times between failure) and to t~ to fit an appropriate 
distribution, There arc a number of products awilablc to support this task. examples include UniFitII 
(Vincent &#38; Law. 1993) and SIMSTAT 2.0 (Blaisdalc &#38; Haddock, 1993). Rapid modeiimg: the last 
10 years ha~c seen the dcvclopmcnt of J7sual Interactwe ~fodelling ,!$stems ( VIMS) such as Witness (AT 
&#38; T Istcl. latest version), XCELL+ (Conway ct al, 1990) and ProModcl (Harrell &#38; Lca\y, 1993) 
and Stclla/I Think (Richmond &#38; Peterson, 1988). These allow the modcllcr to develop the logic of 
a model on-scrccn using a graphical user intcrfacc and also col~trol the running of the model.  Simulation 
model programming; as #4 makes clear, it is sometimes ncccssaq to write a proper computer program and 
this can bc done using a purpose designed simulation language such as SIMSCRIPT 11.S (CACI, 1987). a 
general purpose language such as c or even on a spreadsheet or database.  Statlstlcal oulpul anol~,si,v; 
It is not always cas> 10 interpret the results of a simulation, especially one  Computer Simulation 
which includes a Iargc number of stochastic clcmcnts and the resulting output many need carcfhl skltistical 
analysis. There arc tools to support this task. some are spccitlcally for simulation modclling (e.g. 
SIMSTAT, Blaisdalc &#38; Haddock. 1993) and others arc more generally available packages such as SPSS 
and SAS.  2 MODELLING IN DISCRETE SIMULATION As this is the winter simulation conference, the rest 
of this paper will concentrate on discrete event simulation. 2.1 Events and their logic A computer program 
which represents a discrete simulation model will have a number of components as follows. The event 
Iogvc: a precise definition of the conditions which govern the state changes of the entities to be included 
in the model.  An executive or control program: which ensures that the entities events occur at the 
right time and in the correct sequence and thus ensures that their aggregate behaviour is a model of 
the system being simulated.  Othe~ components: such as sampling routines. integration algorithms, graphics 
and other features needed for a particular model.  If the modeller is using a WMS or a simulation programming 
Ianguagc, then he or she need only be concerned with the event logic, everything else will be provided 
by the system vendor. If a bespoke program is being written in a general purpose language then all of 
the features will have to be provided.  2.2 Capturing system logic 2.2.1 The principle of parsimony 
Perhaps the best \vay of modclling complicated event logic is to bear in mind the principle of parsimony, 
which is to keep things as simple as possible for as long as possible. This requires an evolutionary 
approach to modclling, starting }~ith a deliberately over-simplified model \vhich is gradually elaborated 
until it is agreed to be valid for the intended purpose. The initially over­simplified model should represent 
the skeletal logic of the system and should not be elaborated until the modcllcr is happy }~ith the validi~ 
of the skeleton.  2.2.2 Using diagrams One way of ensuring a parsimonious approach @ modelling is to 
try to capture the essential system logic within spree type of network diagram. In some cases, such diagrams 
can be drawn on-screen or described textually to a computer program which will itself generate the computer-based 
model from the diagram 10 Pidd (see #4. 1). In this paper, only a simple type of diagram ­the Activity 
Cycle Diagram (ACD) will be presented, though other forms (for example, Petri nets and GPSS flowcharts) 
have been used in discrete simulation. An ACD is an attempt to show how the processes of different entity 
classes interact, at least in a skeletal form. An ACD has just two symbols as shown in Figure 2. ACTIVE 
5TATE II o DEAD 5TATE Figure 2: Activity cycle diagram symbols An active state is one whose time duration 
can be directly determined at the event which marks its start. This might be because the time duration 
is deterministic (the bus will definitely leave in 5 minutes) or because its duration can be sampled 
from some probability distribution (see #3).  A dead state is one whose duration cannot be so determined 
but can only be inferred by knowing how long the active states may last. In most cases, a dead state 
is one in which an entity is waiting for something to happen and thus some writers refer the dead states 
as queues.  These two symbols are used to represent the logic of a system as in the following simple 
example, Consider a theatre booking otllce statled by one or more clerks who have two tasks -answering 
the phone and attending to personal callers at the theatre. As this is a skeletal model, suppose that 
the theatre has a call queuing system with infinite capacity, that there is no limit on the number of 
waiting personal customers and that all waiting callers have customers are ifilnitely patient. Hence 
the diagram of figure 3 can be drawn. The skeletal logic of the system can be clearly understood from 
the activity cycle diagram. For example, a personal service can only begin if two conditions hold -there 
must be an idle clerk and a waiting personal enquirer. Similarly it shows that any clerk may engage in 
two tasks -attending to personal enquirers or answering the phone. It also shows some of the ambiguities. 
For example, what should a clerk do if faced, at the same time, with waiting enquirers and a ringing 
phone? Figure 3: Harassed booking clerks ACD This type of conceptual representation must eventually become 
part of a computer program which might involve some programming or could involve a description of the 
logic being fed as data to a simulator which may be a VIMS (see #4).   3 HANDLING RANDOM AND UNPREDICTABLE 
BEHAVIOUR As was made clear earlier, one aspect of systems which are well suited to discrete event simulation 
is that they may have behaviour which can only be modelled statistically -for example, the time interval 
between arrivals may be observed to vary and the variation may be modelled by fitting a probability distribution 
to that variation. To cope with this variation, discrete simulation models employ sampling procedures. 
 3.1 Basics of random sampling The idea of random sampling is to ensure that a set of samples is produced 
that is representative of the distribution from which they were taken and within which set no pattern 
is evident. This is usually achieved by a two stage sampling process which uses pseudo­random numbers. 
A truly random number stream is a sequence of numbers produced by a device which is believed to be random 
-for example a roulette wheel, which some people find curiously interesting. Truly random numbers streams 
are not used in discrete simulations because most such devices are slow (millions of random numbers may 
be needed) and also they cannot be repeated -an important consideration, as will become clear shortly. 
A pseudo-random number stream is a sequence of numbers which behave exactly as a stream of random numbers 
would be expected to behave but which is produced by a well-understood mathematical process.. Thus, when 
the sequence is examined, there is no pattern in the sequence and all values covered by the range of 
the random numbers occur equally often. In statistical terms, the sequence must be independent and uniformly 
distributed with a dense coverage of the range of values. An Introduction to The two stage process is 
follows. Generate 1 or more pseudo-random numbers.  Convert these into the samples needed by some 
 suitable algorithm. 3.1.1 Top-hat sampling To illustrate the basic idea, consider Top-hat sampling, 
which is an common approach to taking samples from histograms. Figure 4 shows the probability of a clerk 
selling a certain number of tickets during the service of a customer. Figure 5 is the cumulative histogram. 
PrckabMv 05, 04 03 02 01 0 L 123456 0 Number d ticksts Figure 4: Histogram of ticket sales 11Cumutabve 
prcimbihty ,,5 t 08 L[06 06 04 02 0, I 0 -+ .&#38; 12 Numberd tickets Figure 5: Cumulative histogram 
of ticket sales In figure 5, the vertical axis represents the cumulative probability of ticket sales. 
It runs over the (O, 1) interval and can be replaced by a range of pseudo­random numbers which also runs 
over (O, 1). Thus, if the pseudo-random sequence includes a set of numbers (0.38, 0.75, 0.53) then reading 
from the graph of figure 5, these correspond to a set of ticket sales (2, 4, 3). The simple two stage 
process for Top-hat sampling involves, Generate a pseudo-random number.  Look up the corresponding 
value from the  graph or a look-up table.. As well as top-hat sampling, there are many algorithms in 
use for different types of probability distribution. Law &#38;Kclton(1991 ) have more details.  3.2 
The effects of statistical variation Due to its sampling procedures, a discrete simulation may display 
complicated behaviour which needs careful Computer Simulation 11 analysis. For example, there may be 
separate samples taken for the personal enquirer arrival time, the phone call arrival time, the personal 
service duration and the phone conversation duration even in a simple model such as the harassed booking 
clerk. Typical two stage sampling procedures use the pseudo-random numbers for two purposes. The first 
is to ensure that the sequence of samples is pattern-free, the second is to select the set of values 
which are contained in the sequence. These two sources of sampling variation, which will be combined 
as different samples are combined, means that any discrete simulation which stochastic elements needs 
to be regarded as a sampling experiment. In any such experiment, it must be recognised that there is 
a risk of coming to the wrong conclusions. For example, consider figures 6 and 7 which show the (imagined) 
results from two sets of simulations in which policy A is being compared with policy B -the idea being 
to decide which one generates the highest profit. Probability \,/ / \\ Profit + Figure 6: First set of 
experiments Probability t L B /+- \ ,. / / \ /:. / .L . .. Profit --+ Figure 7: Second set of experiments 
 The variation due to the pattern-free sequence is wholly desirable (this is random behavior), that due 
to a badly selected set is wholly undesirable and is due to the fact that the set is of finite (and possibly 
rather small) size. This set effect means that the distribution of the samples may not properly represent 
the distributions from which they came. 12 Pidd In both cases the mean Taluc of the experiments with 
policy B exceeds those with policy A, but ii would be possible to be much more cotildent that this is 
a true inference if the experiments turned out like the first set shown in figure 6. The difference between 
the two sets of experiments is that the output variances are much lower in figure 6 than in figure 7 
and thus the risk of a wrong inference is lower. The output variance is a function of the sampling variation 
w-hich must be controlled.  3.3 Some cautionary advice In any experimental comparison. whether using 
real systems or a simulation, it is important to ensure that the comparison is a fair one. That is, the 
comparisons should be made with the system (real or simulated) operating under similar and typical conditions 
for all policy options. 3.3.1 Run-in periods Suppose that someone wished to simulate the effect of adding 
an extra runway to a civil airport and in particular they wished to discover what extra trtilc, if any, 
this would permit. Part of the experimental control would be to ensure that simulations of the existing 
runway contlguration and the extra runways were conducted in such a way that both options were compared 
under the same starting conditions. There is probably never a time when a large civil airport has no 
activity and thus starting the simulations with no activity would not be representative of real conditions. 
Indeed, there is a risk that this may bias the comparison one way or the other. Two ways of coping with 
this are to use typical starting conditions or to use a run-in period. Of the two, the latter is preferable. 
but why? The risks with using typical starting conditions are twofold. First, we may know what these 
are for the existing system cotilguration but we do not know what they are for the novel alternative. 
Indeed, if we knew this then there would be no need for the simulation. The second reason is that use 
of typical starting conditions may bias the results. For example, in the airport example we might reasonably 
believe that an extra runway will allow extra flights and we may thus ensure that the starting conditions 
for this policy have more activity than those for the current system cotilguration. If we arc interested 
in assessing whether the extra runway will permit extra trtilc then there is a great danger of a self-fulfilling 
prophecy. Hcncc it is better to employ a run-in period. The idea of this is that, if a simulation starts 
with no activity, then it should be allowed to run to some time until it is bclicvcd to have settled 
down into some form of steady state. During this run-in period the output from the simulation is ignored 
and only output generated after that point will be used in the analysis. Of course, there are simulations 
in which no form of steady state is possible (e.g. a missile chasing a jinking target) in which case 
the transient effects are the main focus of interest. In such cases, ruin-in periods should not be used. 
 3.3.2 Variance reduction As was pointed out in #3.2, the accuracy of simulation results is related to 
the observed variation in the sampling processes of the model. Thus it is important to control these 
if at all possible. There are many techniques available to help in this (for a thorough discussion see 
Law &#38; Kelton ( 1992) and Kleijnen &#38; van Groenendal (1992). The simplest approach when comparing 
different policies is to use coFnrnon random numbers, a technique which works by synchronizing sampling 
processes across policy comparisons. To use common random numbers, the analyst must ensure that each 
sampling process has its own controllable pseudo-random number stream. Hence, in the harassed booking 
clerk example introduced earlier, this means that 4 streams will be needed for each simulation run (one 
each for personal arrivals, phone calls, personal service and phone conversations) if there is just one 
clerk and 2+2n if there are n clerks. The technique works by controlling the set of random numbers which 
are used to generate the required samples. If each policy option is compared using the same random numbers 
then the same samples will, as far as is possible, be used for each policy comparison. If each policy 
option is being replicated m times, then the modeller will need to ensure that each of these m replication 
uses common random numbers and thus will need access to m(2+2n) streams in the above example. This need 
for control of the random numbers streams is the main reason why pseudo-random numbers are preferred 
over truly random streams.  4 SOFTWARE SUPPORT FOR DISCRETE SIMULATION 4.1 Types of software A thorough 
review of this is given in Pidd (1992) but a summary here will help to place things in context.  4.1.1 
Coding in a general purpose language Early simulations were written in whatever primitive programming 
languages were available on the simple computers of the day. This approach. like the rest, persists to 
this day and it seems likely that a reasonable proportion of simulations arc written in languages such 
 An Introduction to computer Simulation as C (Crookcs. 1989). C+ t (Joines et al, 1992, Pidd 1993), Pascal 
(Pidd. 1989)and even in FORTRAN and BASIC (Pidd 1988). Using such an approach means that very flexible 
and bespoke software can be created. but the cost is that such program development is very slow and requires 
considerable skills and highly specific knowledge in detailed computer programming.  4.1.2 Using a library 
Rather than starting each program from scratch it has also long been possible to construct some parts 
(occasionally, most parts) of a discrete simulation application out of program building blocks taken 
from a library. This allows quicker program development but still requires detailed programming skills 
-and faith in the library which being used. 4.1.3 Simulation programming languages Many simulations are 
written in special purpose simulation languages such as SIMSCRIPT 11.5 (CACI. 1987) because these ease 
the task of program development by providing language constructs which are designed for discrete simulation. 
Thus these languages usually provide the event scheduling mechanisms which underpin discrete simulations 
and also have a syntax which eases the expression of the logical interaction of the simulation entities. 
However, as with the other two approaches, such software still requires detailed programming skills if 
it is to be used effectively. 4.1.4 Flow diagram systems A different approach to easing model implementation 
is taken in flow diagram systems such as HOCUS (Szymankiewicz et al, 1988)). In these systems. the user 
develops a flow diagram such as an activity cycle diagram, and then uses a defined command set to describe 
the features of the flow diagram to the flow diagram system. This description is. in essence, data to 
a generic simulation model which is suited to a particular domain (e.g. queuing systems). As originally 
developed, these flow diagram ~stems did not permit the user to develop or generate a simulation program 
in any meaningful sense. The main advantage of this approach is that it supports rapid program development. 
The main snag is that, without considerable effort. it is very diflicult to model complex systems. It 
is interesting to note that so-called block-structured languages such as GPSS are, at root, flow diagram 
systems. 4.1.5 Interactive program generators These. for example CAPS/EC SL (Clementson, 1991) and SIGM.4 
(Schruben, 1991), attempt to combine the benefits rapid development from flow diagram systems and the 
flexibility of direct programming. They represent the start of attempts to provide layered software development 
tools for discrete simulation. Their initial use resembles that of a flow diagram but. instead of treating 
the diagram description just as program data, it is used to generate a working program in some target 
language by linked together edited pre­written fragments of program code. This code may then be edited 
so as to allow the modelling of complex systems. Because the user can develop the simulation model at 
different levels, these interactive program generators represent the start of layered program development 
systems. 4.1.6 Visual interactive modelling systems These are flow diagram systems brought up to date, 
in the sense that they make good use of recent developments in general computing. There are many examples 
available on the current market such as Witness (AT&#38;T Istel, latest version), Pro-Model (Harrell 
&#38; Leavy, 1993), SIMFACTORY (CACL latest version). To use them, the modeller must conceptualise the 
system of interest as a network around which elements flow, changing their state at the nodes of the 
network. Icons are placed on-screen and linked together so as to represent the network logic. In some 
systems, there is considerable scope for expressing the event logic at nodes by the use of special designed 
macro-type languages. However, it is not normal for these VIMSS to generate proper program code which 
the user may modi~. though some (for example Witness) have a simplified coding language, and they are 
thus best suited to relatively straightforward network-type applications. 4.2 Choosing software 4.2.1 
Type of application Sornc tools are better suited to certain applications than to others. To use an analogy 
of house-painting. If the walls and windows of a house need to be painted. then. the best way to paint 
the walls is probably to use a large roller or paint-spray. But if these are used on the windows the 
results tend to obscure the view! The discrete simulation equivalents of the paint­sprayers arc the VIMSS 
which provide a rapid way of developing models with attractit c graphics. For relatively straightfonvard 
applications. many of which arc found in factories and back-ofllcc processing, these tools are hard to 
beat. 14 Pidd 1Io~vc\cr. time arc tirncs wtm vcw dclailcd systcmis need to rnodcllcd and lhis \viIl 
require the usc of tools which make it easier to express complex systcm logic wld this tiswdly invol~cs 
programming. Thus for a smaller proportion of discrctc simulations (probably lCSS than 20(%) there is 
no cscapc from the skilled pi-mess of dacloping a computer prograrri. 4.2.2 Required features The next 
issue to face is the detailed demands which will be placed on d~c software. Examples of tbtse issiics 
arc the following. Is graphical display important?  Dots the software need to intcrfacc  MMJ corporates} 
stems (e.g. databases)? Do you need strong statistical support for input and output analysis?  Is .sccurity 
important !  Arc debugging tools required.  What hard~~arc~softwarc platform ~~ill it be run on (e.g. 
LTNTIXor DOSIWindows?) ?  The software vendors need to be asked to specify a system to meet your rcqtlircmcnts. 
 4.3.3 Vendor support and prices Finally, no user can ignore two \cry practical issues. How much ~~ill 
the software cost? -and remember that software prices arc soft. so negotiation is often possible. Also 
ask %vhat support you can reasonably expect from the vendor given the vendor s size and given your physical 
location. REFERENCES <RefA>Blaisdalc. W7.E. and Haddock, J (1993) .Szmtl!ation ana[isis Lining SL\L5 T.4 T 
2.0. Proc 1993 Winter Sim Conf, Los Angeles Cal. AT &#38; T Istcl (latest ~crsion) !J il;ws.s .qxkw; 
}}iamial. AT&#38; T Istcl, Rcdditch Worcs, UK CAC1 (latest version) Si.ifl l-l (.-TORI ii7ti OdliCtluil 
a;?d user s mamial. La Jolla. Cal. CACX (1987) I C ,S1.ilS(7Ul T Ii. 5. [i7tiYX!liC tiOii Uild use/s 
inai7uu/. La Jolla. Cal. Clcmcntson. A.T. (1991) l~le L. C ,SL plus svstem mi7i77ii71. Available from 
A.T. Clcmcntson, The Chestnuts, Princes Road. Windcrrncrc. Cumbria UK Comvay. R., Maxwell. W. L., McClain, 
W.L. and Worona, S.L. (1990) L;wr .v gliidc to .I_( cll: jizto);v mode[lulg systcw, relea.w -i. O (31 
11 echtiw). The Scicnlitic Press, %n Ffancisco. CM. Crookcs, J.G. (1989) ,Simuluiitw ill [ . 11] Pidd, 
M. (cd) ( oi)tpuier ttwdel]ing Jbr di,wrelc simul(i[ion. John Wiley &#38; Sons Lid. Chichesier. Forrcstcr. 
J.S. (196 1) Indusmial @wamics. MIT Press. Cambridge, Mass. Ihmdl. C.Il. and Lcav~. J.J. (1993) i iw.\fodel 
tutond. Proc 1993 Winter Sim Conf, Los Angeles Cal. Joints, J.A.. PoIycll. K.A. and Roberts. S.D. (1992) 
ObjSC1-UYiCiiiCd iiidtii iiig Uild .fiiJlli/diiOJi [ii ( Proc 1992 Winter SiimilatiOn Conference. Arliligton 
VA. KkijiXil. J.P.C. &#38; ian Grocrmdal W. (i992) ,yf;iii;[cyt~{jii .. -+-+ -- - . --- - > John Wiley 
&#38; d ,>lU/I.\Cl~~il~cf.f~~~lll U. Sons Ltd. Chichcstcr La;~. A.?vf. &#38; Kdton, W.D. ( 1991) Siiii;i/,~f;<>ii 
;;id~~i;ig and a;ialjxi.s, (.?iid ~d~ti~ii). McGmw-HilL NCR York Pidd, M (1992) Obj~~~-d~~?tati~i? LWZd 
th?~ .Aask SiHilili7tiOiZ. Proc 1992 Winter Simiilation Conference, Arlington VA. Pidd, M ( 19S9) Silii~ildi~i~ 
ii~ Pascal. h Pidd. M, (cd) ( Oi~l~Lit~F Hiodcllij)$? jb~ discmti? s;i;)iilat loiz. John W ilcj &#38; 
Sons Ltd, Chichcstcr. Pidd. M ( 1988) C ~iiipitt~~ si};iiildio)i ii? ;;iaitag~iii~;zt (2id - ; .-John 
&#38; Sons Ltd, .Wit?i7C2. c keg11 ulf). ) tt ilcy Chichcstcr. Pidd. M {1992) ( oiiipiif~~ .~[)~ii[!atic?i~ 
ii~ mailagzi)ie;tt SCiCi?CC. (3rd Cd;tiOi7). John Wiky &#38; Sons Ltd. Chichtstcr. Richmond. B.,M. and 
Peterson. S (1988 ).3 iisw- s gtizd~ to STWL.4. High performance systems Inc. Lyme. NH. Schrubcn. L (1991) 
S1G21.4: a ,giwphica[ Sii;iiilatioiz s}.~tti}}. The Scientific Press, San Francisco. Cal Szymankiewicz. 
J., McDonald. J. and Turner, K. (1988) Soh.i;;g i3Msii7essprohkm.v by sii)iii![~ti~il. McGraw-Hill, Maidcnhead. 
Vincent, S.G. StiJ?~Oif jbr Winter Sim Wolstcnholmc, tiyf7Ui)llL$ Chichcstcr Zciglcr. B.P. siiniilation. 
and Law, A.M. (1993) [>?itltll: total S~iliii/UtiOi? iilpUt i]iadeling. I?roc 1993 Conf. Los Augclcs 
Cal. E. S. (1990) .Sjxtenz ~;?qiii<i: a .sy~tci~i approac!i. John Wiley &#38; Sons Ltd, (1976) YJ7eoi3> 
i)ioikllin.g OJ U}ld Wiley Intcrscicnce. NTc\vYork. Zciglcr. 13.P. (19S4) Alii[t{jacettd mockl[i);g a;z<i 
fi]isovk ~v ~i~t .~ii)~ii!atlo;~. Ac.adcmic Press. New York.</RefA> AUTHOR B1OGRAPHY MIKE PIDD is a Professor 
of Management Studies in the Management School of Lancaster University in the UK. He is author of [ omputer 
sintuiation in mana,gewcnt science and of C omputer modclling @ ~i~.scrcie s; HIulatIaH (bet h published 
by John Wiley). He teaches. researches and consulfs in discrete simulfition and management science. His 
current interests include research on object oricntat ion and an upcoming book on Modclling.  
			
