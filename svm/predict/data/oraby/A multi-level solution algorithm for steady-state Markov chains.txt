
 A Multi-Level Solution Algorithm for Steady-State Markov Chains Graham Horton * Lehrstuld fiir Rechner:strukturen, 
Universitat Erlangen-Niirnberg Martensstr. 3, 91058 Erlangen, Federal Republic of Germany grahanz@intmd3. 
injormatik. uni-er[angen.de %ott T. Leutenegger t Institute for Computer Applications in Science and 
Engineering Mail Stop 132c, NASA Langley Research Center, Hampton, VA 23681-0001 leut@icase. edu Abstract 
new algorithm -the multigrid method -has met with con­siderable success, achieving, under appropriate 
conditions, A new iterative algorithm, the multi-level algorithm, for substantially improved solution 
speeds compared to tradi­ the numerical solution of steady state Markov chains is tional methods such 
as Gauss-Seidel and SOR. One should presented. The method utilizes a set of recursively coarsened more 
accurately consider multigrid to be a class of methods, representations of the original system to achieve 
accelerated as the basic framework allows a wide variety of choices for convergence. It is motivated 
by multigrid methods, which each of the constituent components. The method to be pre­ are widely used 
for fast solution of partial differential sented in this paper is in many respects related to this class 
equations. Initial results of numerical experiments are of algorithms: the Markov system is recursively 
coarsened reported, showing significant reductions in computation and values obtained from these smaller 
systems are used to time, often an order of magnitnde or more, relative to the achieve faster convergence. 
 Gauss-Seidel and optimal SOR algorithms for a variety of test problems. It is shown how the well-known 
iterative In this paper we present a new solution algorithm, the Mulh-f,evel algorithm, for Markov chains. 
aggregation-disaggregation algorithm of Takahashi can be Our initial interpreted as a special case of 
the new method. experiments indicate the multi-level algorithm does not require the Markov chain to have 
any special structure in1. Introduction order to achieve excellent performance, although if suchMarkov 
systems generated by computer modeling tools structure does exist it may be possible to exploit thatsuch 
as queueing networks, Petri nets, or reliability mc~deling structure to achieve even better results. 
We can offer no proof of convergence, but in all experiments we have run packages may contain hundreds 
of thousands of states. The resulting sparse linear systems of equations have a correspondingly large 
number of unknowns and must, in so far the method always converged. The convergence theory for multigrid 
methods is relatively limited, applyinggeneral, be solved numerically using an iterative scheme. largely 
to equations of elliptic type. However the methodsTypical methods are the Power, Gauss-Seidel, and SOR 
are widely used on all classes of linear and non-linearmethods. All of these methods have the drawback 
that they PDEs. We present experimental results for the Gauss­may require many iterations to reach a 
solution, particularly Seidel, SOR, and Multi-Level algorithms when appliedif the system is large, or 
a if high degree of accuracy is to Markov chains generated from birth-death processes,required. This 
can lead to unacceptably long computation finite population tandem queueing networks, blocking (finitetimes. 
capacity) tandem queueing networks, and a canonicalA similar situation is found when solving partial 
differen­ tial equations, where systems of many hundreds of thousands stochastic Petri-net model. of 
unknowns are not uncommon. Here, however, a relatively For purposes of brevity we will refer to the Gauss-Seidel 
algorithm as the GS algorithm, and the Multi-Level This work was carried out in part while the first 
author was algorithm as the ML algorithm. Note that the phrase multi­a guest at ICAS E, NASA Langley 
Research center. level algorithm is also used to denote a class of methods t Thjs research was supported 
by the National Aeronautics and related to multigrid. These bear a structural resemblance Space Administration 
under NASA contract NASI-194801 while to the scheme presented here in that they make use of the second 
author was III residence at the Institute for Computer coarser subproblems to achieve accelerated solution; 
they Applications in Science and Engineering, NASA Langley Research Center. are, however, otherwise 
unrelated. The remainder of the paper is structured as follows. In the following section, Permission 
to copy without fee all or parl of this material is after some preliminary remarks, the multi-level method 
granted provided that the copies are not made or distributed for is described. [n section 3 we describe 
related work and direct commercial advantage, the ACM copyright notice and the title of the publication 
and Its date appear, and notice is given compare and contrast the multi-level algorithm with existing 
that copying is by permission of the Association of Computing algorithms. In section 4 results of experiments 
are presented Machinery. To copy otherwise, or to republish, requires a fee comparing the performance 
of the method to GS and SOR and/or specific permission. using a variety of test problems. In section 
5 we discuss SIGMETRICS 94-5/94 Santa Clara, CA. USA 0 1994 ACM 0-89791 -659-x19410005 ..$3.5O 191 the 
practical aspects of implementation of the multi-level method and provide a list of possible directions 
for future research. In the final section we summarize the paper 2. IUulti-Level Solution Algorithm 
In this section we present our new ML solution algorithm. We first summarize classical rnultigrid techniques 
in section 2.1. We then review classical M arkov chain aggregation techniques in section 2.2. In section 
2.3 we give a detailed description of our ML algorithm. 2.1 Multigrid Methods Multigrid algorithms are 
a recent development in the field of iterative solvers for large systems of equations [1]. They were 
originally applied to the systems of equations that arise from the discretization of elliptic boundary 
value problems, and it is for these equations that most multigrid theory has been developed. For this 
class of problems multigrid algorithms are among the fastest known solvers, being of optima~ complexity, 
i.e. having computation times that are linear in the size of the input. An introduction to multigrid 
algorithms may be found in [2], [7] or [18]. Multigrid algorithms begin by defining a set of increas­ingly 
coarse representations (grid levels) of the original prob­lem, each of which has only a fraction of the 
number of de­grees of freedom as its predecessor. The algorithm uses a standard iterative procedure such 
as ~,S at each grid level to quickly reduce error components that are high frequency w.r. t. that level 
(smoothing). A smoothing sweep through all grid levels efficiently reduces errors across the entire fre­quency 
spectrum. Multigrid algorithms work most efficiently on regularly structured elliptic problems, whose 
coefficients vary smoothly between neighboring unknowns. In such cases they can achieve an error reduction 
of an order of magnitude per it­eration. Conversely, multigrid algorithms for problems that are non-ellipticj 
unstructured or have rapidly varying co­efficients do not in general perform as well and currently represent 
an active field of research. Markov chains can pos­sess one or more of the above characteristics. The 
branch of multigrid research which attempts to deal with general sparse systems is known as algebraic 
muitigrid, see [12]. Given an appropriate choice of smoother, multigrid algo­rithms can be parallelized 
with a high degree of efficiency, see [9] for a recent survey. This is, of course, an added advan­tage 
in the context of modern supercomputer architectures and networked workstations. The algorithm to be 
presented in section 2.3 may be viewed as a multigrid-like algorithm. However, owing to the absence of 
a grid structure and because of the difference in approach to multigrid schemes, we will refer to the 
algorithm more abstractly as a rnulti-tevei algorithm. Because of the similarities between the algorithms, 
we nevertheless expect that many of the established rnultigrid ideas can be applied to the Markov chain 
solver, and this indeed proves to be the case. 2.2 Aggregation of Markov Chains Consider a steady state 
continuous time Markov chain consisting of n states sl . . . sn. Denote the unknown vector A B . . ./ 
.... . . . . . . . . .. . . .. . . . .>, .; i., .,, &#38; ,;. Figure 1: Aggregation of Markov Chains 
by p, where p, is the probability of being in state s,. We then have to solve the system of equations 
F p=o (1)( with the additional condition ,=n E pi=] (2) :=1 Equation (1) is simply a reformulation of 
the classic continuous time Markov chain equation: ?rQ=o (3) where P is the transpose of the generator 
matrix Q, and p is the transpose of the steady state probability row vector m. Note that we will use 
the symbol Q differently in this paper. Equations (1) and (2) form a sparse linear system which is typically 
solved numerically using the GS or SOR algorithm. These schemes suffer the drawback of needing a large 
number of iterations when n is large or when a high degree of accuracy is required. A coarser representation 
of the Markov chain described by matrix P may be obtained by aggregation. This means creating a new Markov 
chain described by a matrix Q with the vector of state probabilities q, each of whose N states S1 . . 
. SN is derived from a small number of states of the original system. Figure 1 illustrates the situation 
for an eight-state birth/death chain (A), where states are aggregated in pairs to form a four-state coarser 
level system (B), which in turn is pairwise aggregated to form the coarsest level two-state system (C). 
In the following we will use the terms jine leuel and coarse level to refer to Markov chains where the 
latter is obtained by aggregation from the former. The relation sk G S, signifies that the fine level 
state !Sk is mapped by the aggregation operation to the coarse level state S;. The matrix Q of the aggregated 
system may be chosen as follows : ~ Pk ~ Plk Q,j = ~k=~t =Sl;; (4) skcs, This is the classical aggregation 
eguation. Note that the matrix Q is a function not only of the fine level matrix P, but also of the fine 
level solution vector p. 192 This yields the aggregated equations in the unknown q: smaller, and thus 
the computation will be cheaper. We write Qq=() , (5) N qt=l (6) x ,=1 It can then be shown that i.e. 
the solution q of the aggregated system truly represents a coarser version of the solution p of the original 
problem. The probability of being in state q, is the sum of the probabilities of being in any of its 
constituent fine-level states. The idea behind the ML algorithm is to aggregate slowly, typically setting 
N = n/2 or N = n/4, and to proceed recursively to obtain further coarsening, arriving eventually at some 
coarsest system which may consist of only two states. Approximations obtained on coarser systems are 
used to obtain a correction to the fine-level solution vector. One iteration of the ML algorithm will 
proceed in the multigrid manner from the original, finest system down to the coarsest, setting up coarse 
level equations and performing GS smoothing, and then back up to the finest level, computing and applying 
corrections. Note, however, that other orderings of processing the various levels are possible. 2.3 
Description of tile Algorithm We adopt the following abbreviations for vectors a, b, c c Rm: We enter 
the (i+ l)th iteration of the ML algorithm with the current approximation to the solution p( ) obtainedl 
as a result of the (i)th iteration, whereby p(o) denotes the initial guess, and begin by performing one 
or more sweeps of the GS algorithm, obtaining the vector j: j=. (8)  Gs(p( )) We assume throughout 
that application of GS includes a subsequent normalisation step to enforce (2). The vector j will not, 
in general be the solution p of (1), but we may write fi+p$=p , (9) where p$ is the elementwase multzplicataue 
correction neces­sary to ~. Knowledge of p* would immediately enable us to compute the solution p. We 
may write (1) as P(fi*p*)=o . (lo) Since j has been smoothed by application of the GS algorithm, we 
assume that it no longer contains any high frequency error components, and thus that p is smooth. Therefore 
we may compute an approximation to p on a coarsened system, since the dimension of the latter is a coarsened 
version of (1 O) as Q(f*q*)=o , (11) where Q is the matrix of the aggregated system and q* and { represent 
aggregated representations of p* and $, respectively. The coarse system matrix ~ is chosen to be an approxi­mation 
to the the matrix Q from (4), replacing p by $, since p is not available until the algorithm has converged: 
In the case of a converged solution, we will, however, have j = p and therefore the correct coarse matrix 
Q = Q. In order to obtain ~ in (11) we require an operator that maps a fine level vector to the coarser, 
aggregated vector. This operator will be denoted by R (from the multigrid restriction operation), and 
we write (13) We choose summation for R, in accordance with (7): This choice for R has the property 
!7= R(P) , i.e. the exact fine level solution is mapped by R to the @xact coarse level solution. It 
is clear that this property is necessary, since at convergence, both (1) and (5) must be satisfied. We 
proceed by defining (15) thus obtaining the coarse level equations to be solved: Qa=o, N-q,=l (16) x 
,=1 Solving (16) for ~ will therefore enable us to compute q*, the coarse approximation to the correction 
via (15): q* = g/~. We compute the fine-level correction from its coarse approximation using the operator 
1 (interpolation): p* = I(q ) . (17) We choose the following operation for I: (18) The multiplicative 
correction is equivalent to a scaling: a coarse level node value ~, represents the probability of being 
m any state sk c S, and therefore g* represents the scaling factor necessary to achieve this for the 
values pk, sk < S,. ln 193 this respect the ML algorithm differs from multigrid, where an additive correction 
is performed. We then compute the new iterate P( +l) using $AQ = p= ,/j?(jj p*) ~ $*p* . (19) If the 
algorithm converges, we hope that P( + 1) will be a better approximation top than p( ). Meanwhile, however, 
we have p[ + 1) # p, since the correction p* was computed only a-pproximately on a coarse grid, using 
an incorrect matrix Q#Q. By analogy with the SOR scheme, which computes an over-corrected iterate compared 
to the underlying GS algorithm, we may consider using an overcorrection for the ML scheme: P = ~(9*) 
= P: = 9:(u+(l u)q; ) Sk E s, , (20) where we set O ~ u ~ 1. For w < 1 such an operation will overdo 
the correction, since values g: < 1 will be decreased and values of q: > 1 will be enlarged. The parameter 
w thus plays an analogous role to that of the over-relaxation parameter in the SOR scheme. It is to be 
hoped that, as is the case for the SOR scheme, certain choices of w may lead to improved solution efficiency. 
We will consider the utility of over-correction in section 4.2. After the iteration has converged, we 
have p =1~ ,~*=~N 3 where 1 denotes the vector (1, 1, . . . . 1)~, i.e. no further correction takes place. 
We then also have Q = Q and therefore q = q. Note that the question of assigning fine nodes to their 
coarse counterparts is still open. This we will call the coar-senmg strategy or aggregation strategy. 
The aggregation strategy can have a significant effect on the performance of the ML algorithm. In cases 
where we have some knowledge of the structure of the Markov chain, for example when queneing networks 
are to be modelled, then we may utilize this information in the construction of the aggregated system. 
In other cases, mapping strongly coupled fine states to the same aggregated state seems to be an efficient 
strategy. Note that the composite coarse grid correction operator C(ji, l(q )) preserves the relahve 
probubthties of all fine level states mapped to the same coarse level state by aggregation: ~=c(p,~(q 
))+~+=p; ski, sk2E st, l<ISN . pk, The tw~level version of the ML iteration is given by the sequence 
of steps (8), (13), (16), (17), (19). The multi­level algorithm 1s obtained by recursive application 
of the two-level algorithm to obtain a solution to the aggregated equation (16) and is described in algorithmic 
form in Figure 2. We use the subscript 1 to denote level of representation (i= lmax finest level, 1 = 
O coarsest level). The coarse level 1 1 and fine level 1 between which the operators I and R map are 
identified by appropriate indices. Note that, because of procedure mss (1) if (1= O) solve P[@L = O else 
Ft = w (n) h- l = Ll,l(fi) mss(l 1) P7-1 = PL1/fi-l P; = I&#38;l, L(p;_, ) f% = C (fit, Pf) return Figure 
2: Multi-Level Algorithm the recursive nature of the algorithm, the unknowns g , ~ and f are represented 
by the variables pf_l, FL-I and fit-l, respectively. The Multi-Level algorithm is non-linear, owing 
to the use of the coarsened system obtained via (12), although the original problem (1) is linear. It 
seems therefore unlikely that theoretical results can be obtained for estimates of the convergence speed 
of the algorithm for general problems. We allow in general the possibility of applying GS v times at 
each level with v > 1, denoted by GS . We also consider the possibility of a more complex cycle form 
(in particular F-and W-cycles, see the multigrid literature), obtained by multiple recursive calls to 
procedure mss. 3. Related Work Currently most performance tools requiring the solution of Markov chains 
use either the power, GS, or SOR algorithms. In a paper by Stewart and Goyal [16] the various techniques 
are compared and SOR with dynamic tuning of the relaxation parameter emerges as the method of choice. 
Initial results of the ML algorithm show that it generally outperforms optimal SOR, often by on order 
of magnitude or more, without any parameters to tune. Our work is related to a large body of work on 
aggregation­ disaggregation techniques. Most previous work using aggre­ gation makes the assumption that 
the number of aggregate states, N, is much less than the number of states, n, i.e. N < n. In our algorithm 
we generalIy assume N = ~. In addition, much of the related work assumes that the Markov chains being 
solved are generalized birth-death processes [17, 15], or that the Markov chains are nearly completely 
decomposable systems [5, 6] In the latter case the solution is usually an approximation often accompanied 
by bounds on the error. We refer the reader to [13] for descriptions of these special Markov chain structures 
and for a more comprehensive list of references. Our work differs in that it does not require any special 
structure in the Markov chain, and the result is exact, not an approximation. The work that most strongly 
resemble ours is the algorithm of Takahashi [17] and its variants [13]. We subsequently use the terminology 
derived in the previous section. The Takahashi algorithm starts with an initial 194 iterate for the fine 
level chain. The fine level chain of n states is then aggregated into a coarse Markov chain of N states, 
where N << n using equation (12). The coarse chain is then solved (equation (16)), and the correction 
obtained from the coarse chain is applied to the previous iterate in the fine level. A new iterate at 
the fine level is obtained as follows. The fine level states are grouped together into N sets of states 
where the members of each set correspond to each aggregate state in the coarse level. The set of linear 
equations corresponding to each of these sets of states is solved independently of the other fine level 
states by treating the values for the other states as constants. The new iterate at the fine level is 
the result of solving the equations fa,r each set of states. The algorithm iterates between the two levels 
until sufficient accuracy is obtained. We may view the Takahashi algorithm as a special case of ML, obtained 
by the following choices, compared to the ML scheme we prefer: 1. Use of only two levels of representation 
of the slystem, rather than multiply coarsened problems. 2. N << n, as opposed to N = ~ for a small 
c (typically 2 or 4). 3. Use of Block Gauss-Seidel or Block Jacobi on the finer level, as opposed to 
a small number of steps of a pointwise Gauss-Seidel scheme.  Although the fundamental motivation for 
the Takahashi and the ML algorithms is similar: computation of local probability distribution on the 
fine level and achieving global probability redistribution using the coarsened equation, it is our claim 
that 1, 2 and 3 above are not the best choices. Point 1 above leads to a system of equations on the coarse 
level of size N, and point 3 generates N subsystems of size n/N, all of which have to be solved at each 
iteration, which can become prohibitively expensive. Point 2 above implies that each new coarse node 
value has to serve as a correction for a large number of fine states. By contrast, the ML algorithm never 
requires the solution of medium or large equations and provides corrections with a high ratio of coarse 
to fine values. We restate that our motivation for the ML algorithm was not to modify current aggregation-disaggregation 
algo­ rithms, but rather to devise a algorithm similar to multi-grid algorithms which have shown exceptional 
merit in solving el- Iiptic PDEs. We find it helpful to not view our algorithm as a Markov chain aggregation-disaggreg 
ation variant, but instead view it as a multigrid-like scheme. 4. EXpWhIli311hl Results In this section 
we present experimental results to show how our new algorithm compares with GS and SOR. All experiments 
presented assume continuous time M arkov chains. We have also solved discrete time Markov chains with 
similar improvements in performance relative to SOR and GS. In section 4.] we first compare ML to G!3 
and SOR for a variety of test ~roblems using an unsophisticated implementation of the ML algorithm. In 
section 4.2 we demonstrate the potential of improving M L performance via techniques including intelligent 
aggregation, varying the number of smoothing steps at each level and over-correction. 4.1 Generic Multi-Level 
Results In this section we present our generic ML results. By generic we mean that the ML algorithm used 
is the simplest one possible, a V cycle (each iteration goes from the finest level down to the coarsest 
level and back up to the finest level), no overcorrection, only applying one iteration of the smoother 
(GS) at each level, and a simple aggregation strategy. In particular, we assume states of the Markov 
chain are ordered O . . . n 1, and that the aggregation policy is by pairing neighboring states by index: 
s, c S1 ~ 1 = [ ~~ . If a level has an odd number of states then the last state is included in the last 
coarse level state. Unlike SOR, this ML algorithm has no parameters to tune. In all of our experiments 
we give the benefit of the doubt to SOR and assume we can find the optimal relaxation parameter w. We 
find w to the nearest &#38; b by using a binary search between 1.0 and 2.0. This results in over-optimistic 
metrics for the SOR algorithm since in practice u must be found via dynamic tuning, thus resulting in 
additional iterations. By presenting best case results for SOR and worst case results for ML, we strengthen 
our argument that ML may be a more promising solution algorithm than SOR. In all experiments we set the 
initial iterate to the vector (~, . . . . ~)T and the systems are solved with with all methods to an 
accuracy of llPp( )1[2 <10- . The ML algorithm recursively coarsens the set of equations until the coarsest 
sytem has only two states. Possible metrics for comparing the algorithms are the number of iterations, 
the process time, the number of floating point operations (flops), and the geometric mean of the convergence 
rate. The number of flops was computed by inserting a counter into all three programs. The process time 
is obtained from the unix system call times{) and is the CPU time used while executing instructions in 
the user space of the programs. In all cases we have found the process time to be a more conservative 
measure than flops, i.e. the comparison of ML to GS and SOR is less favorable when using process times 
than when using flops. Hence to strengthen our arguments of the utility of the ML algorithm we chose 
process time as our primary metric. Note that the process time also includes time for generation of the 
additional ML data structures, whereas the flops metric would miss this factor. In addition, the flops 
metric does not capture the additional pointer operations needed by ML for accessing elements in the 
coarse levels, We also consider the number of iterations necessary for convergence. In general, ML requires 
far fewer iterations than the other two algorithms, but consumes more time per iteration since each iteration 
requires application of the smoother at each level and the construction of the coarse level matrices 
Q. We first consider a birth-death Markov chain with a birth rate of 1 and a death rate of 2 and a varying 
the number of states. The results are presented in figure 3. The number of iterations increases linearly 
with the nnmber of states for the GS and SOR algorithms, whereas it remains fixed at 21 iterations for 
the ML algorithm. Intuitively, probability 195 mass only moves slowly through the system in the GS and 
SOR algorithms, whereas one iteration of the ML algorithm can move mass from one end of the chain to 
the other via the coarse level problems. The process time of SOR and GS increases quadratically for SOR 
and GS with the number of states, whereas it increases only linearly for ML. Thus M L is an optimal method 
for this particular problem. The GS (SOR) algorithm requires 257 (128) times more processing time than 
ML for a birth-death chain of 10,000 states. The ratios increase with system size. Even for small birth 
death chains, such as 1,000 states, the ML algorithm is more than an order of magnitude faster than GS 
and SOR. One possible reason that the GS and SOR zdgorithms require more time as the number of states 
is increased is that they must move probabihty mass a longer distance in the solution vector. To determine 
whether it is this distance or the overall number of states we conduct the following experiment. We assume 
a birth death chain with each state having two additional exiting transitions beyond the birth and death. 
State s, has a transition to state s,+~ and .. a transition to state s, m. If (i + m) > n 1 then the 
transition is to state n 1. Similarly, if (t m) < 0 then the transition is to state so. We initially 
set the number of states equal to 500 and m equal to 2. We then successively double the number of states 
and the distance m. We define the diameter of a Markov chain to be the maximum distance (or number of 
transitions) between any two states. Hence, in this experiment, regardless of the number of states, the 
diameter is fixed at 250. We assume all transitions in the birth direction proceed at rate 1, and all 
transitions in the death direction are at rate 2. The results from this experiment are presented in figure 
 4. It appears that both the size and diameter of the Markov chain influence convergence speed of GS 
and SOR. The number of iterations for the ML algorithm varies only between 19 and 25. Thus the diameter 
of the chain does not appear to have much effect on the solution speed (measured in iterations) of the 
ML algorithm. We next investigate the sensitivity of the relative perfor­ mance of the algorithms to 
the ratio of birth rate to death rate. We fix the birth rate at 1 and vary the death rate from 0.001 
to 1000. The number of states is equal to 10,000. The results are presented in figure 5. Note that both 
axes are scaled logarithmically. The performance of the GS algorithm is always worse than that of the 
ML algorithm. The SOR algorithm performs better than ML when the death rate is less than the birth rate, 
but one to two orders of magnitude worse when the roles are reversed. In the best case observed (for 
SOR), SOR requires ~ of the Process time of ML. Note that the computation times for GS and SOR could 
be made symmetric by exchanging the birth and death rates or by reordering the states. The ML algorithm 
does not require any such special techniques to achieve good performance, and hence is more resilient 
to changes in transition rates. The excellent performance of SOR when the death rate is less than the 
birth rate is surprising. In fact, it ZS not reahstic. For a ratio of ~ or less SOR converges in less 
than 30 iterations. We were able to achieve this excellent performance by first determining the optimal 
c-o to the nearest ~ ~ h by applying SOR many times with u values chosen in a binary search. In practical 
situations the optimal value of u is not known a priori and the solution will be calculated only once. 
Hence w must be obtained via some dynamic procedure. It is impractical to assume that an SOR algorithm 
including dynamic tuning of co can converge in only 30 iterations. In fact, in a recent paper proposing 
a dynamic method for determining w, [3] , 30 iterations are executed before tuning of w even begins. 
The paper notes that often thousands of iterations were necessary to find the optimal w. Thus, the excellent 
performance of SOR in figure 5 could never be achieved in practice. We next explore Markov chains generated 
from simple queueing models. We first assume a closed system tandem queue model. The queueing system 
is shown in figure 6. We assume a finite population where jobs think for an exponentially distributed 
period of time with rate A (i.e. the jobs visit an infinite server and are served at rate J). Jobs are 
served in queues 1 and 2 at rates ~1 and YZ respectively. The states of the Markov chain are generated 
from an initial state of all jobs in the think state, and then by constructing the chain in a breadth-first 
fashion. States are numbered O through n 1 as they are created in the breadth first search. The aggregation 
policy used in the ML algorithm is to pair adjacent-numbered states. Hence, the performance of the ML 
algorithm is almost certainly sub-optimal, since no intelligent aggregation techniques are being used. 
In all experiments reported we fix the think rate to 1.0. In the first experiment we set p] to 1.0 and 
pz to 2.0 and vary the population from 25 to 250. This results in a range of 351 to 31,626 states in 
the underlying Markov chain. The results of the experiment are p~otted in figure 7. The ML algorithm 
requires far less computation time for the solution than the other algorithms, especially as the population 
increases. We next consider the effect of the relative values of PI and pz on the performance of the 
algorithms. We fix the think rate to 1.0 and the population to 100 (resulting in 5151 states in the underlying 
Markov chain), set pl to 1.0, and vary KZ from 0.001 to 1000. The results are plotted in figure 8 using 
a logarithmic scaling of both axes. The ML policy results in lower computation times than the other algorithms 
across the entire parameter space, and when Ml > uz the solution time is an order of magnitude faster. 
Experiments with larger populations demonstrate a more pronounced difference in the performance of ML 
relative to GS and SOR. We now consider the application of the three al~orithms to the solution of the 
underlying Markov chain of a canonical stochastic Petri net. Figure 10 shows the complexities, measured 
in KFLOPS and plotted logarithmically, of the GS, SOR and ML algorithms applied to the underlying Markov 
chain of the stochastic Petri net of Molloy [1 O], depicted in Figure 9. In this experiment the number 
of tokens ranged from 10 to 60, resulting in Markov chains with 506 to 77531 states. The Markov chains 
for this 196 I I I D \ 2 D \ v 1 2 311 2 3 MFLOPs / 12.7 9.3 8.2 ~ 5.4 5.2 4.9  Table 1: Effect of 
v and aggregation strategy on the ML algorithm. problem were generated using the SPNP (stochastic Petrv 
net package) tool of Ciardo et al [4]. M L is superior to GS for all cases tested, the improvement being 
a factor of approximately 3.3 for the smallest and approximately 42.7 for the largest case considered. 
Against SOR with an optimally chosen w, ML performs slightly worse only for the smallest problem considered. 
A comparison of computation times shows similar, but slightly less good results, owing to an increased 
number of page fanlts caused by M L s greater memory requirements. The aggregation strategy used was 
the simplest possible, using only pairwise aggregation by index. Initial experiments with more a sophisticated 
scheme indicate that further improvements are possible. 4.2 Multi-Level Acceleration Techniques In this 
section we consider a few techniques, some of which are borrowed from the multigrid literature, that 
can be applied to the ML algorithm to further accelerate convergence speed. The over-correction idea 
is directly analogous to over-relaxation in SOR. We first consider how more intelligent aggregation of 
the Markov chain can affect the performance of the ML algorithm. We consider the same tandem queueing 
network in section 4.1, figure 6, except that we assume finite capacity (blocking) queues with a capacity 
of 63. We assume the queues are finite capacity to facilitate the ease of an intelligent aggregation 
technique. Figure 11 shows c)n the left the Markov chain generated by this modified tandem queue. The 
states of the Markov chain may be written as a two-dimensional lattice of size (64) x (64). The transitions 
then form a regular pattern, somewhat analogous to the grid of a discretized PDE, We assume the states 
to be numbered lexicographically from top left to bottom right. The simple aggregation strategy used 
would successively pair states that are adjacent horizontally until no longer possible andl then pairwise 
vertically, as illustrated on the upper right. An alternative strategy more appropriate to the structure 
of the problem is shown on the lower right, where fine level states are grouped into 2 x 2 units. Table 
1 shows the number of floating point operations needed by ML applied to the Markov chain of Figure 11. 
We compare the one-dimensional, pairwise aggregation strategy ( I-D) with the two-dimensional case (2-D). 
We consider from one to three smoothing steps (v = 1, 2, 3). For comparison, GS requires 30.1 MFLOPS 
and optimal SOR requires 14.1 MFLOPS. It can be clearly seen that the two-dimensional aggregation strategy 
is significantly faster than the 1-D method. The former can be also be improved (by about . 33~o) by 
performing additional relaxation steps, whereas the latter algorithm, which is already superior, improves 
to a w 1.0 0.8 0.6 0.4 0.2 0.0 ~~LOF s ~ 5.38 4.67 3.78 3.25 3.07 3.07 Table 2: Effect of overcorrection 
on operation count. lesser extent. In this experiment the best-case ML scheme achieves a speedup of 6.1 
over GS and 2.9 over SOR. Table 2 shows the effect of the overcorrection according to (20) on the operation 
count of the ML scheme applied to the same problem, where u ranges from 1.0 to 0.0. A significant improvement 
is found to be achievable, the optimal value of w giving rise to an improvement of approximately 53~o 
over the unmodified correction. The ML scheme with the optimal overcorrection and adapted aggregation 
strategy thus requires less than 1/1 O (1/5) of the floating point operations of the GS (SOR) algorithm. 
5. Discussion of the alrzorithm and the results Memory requirements. The implementation of the ML algorithm 
requires one additional variable at each state compared to the SOR scheme in order to store the temporary 
values ~. In addition, the overall nnmber of states needed is higher than for SOR because of the additional 
recursively aggregated systems. If the number of states of the original problem is n and this number 
is rednced by a factor of .f = N/n during each aggregation step, then the overall number of states s 
needed by the ML algorithm is bounded by s < n/(1 ~). Thus in the examples considered in section 4 we 
have f = 1/2 and therefore s < 2n. We therefore pay the price of circa three times the memory requirements 
of GS in order to achieve performance improvements of an order of magnitude or more. Implementation effort. 
The ML algorithm is evidently more complex than the SOR scheme, additional coding being required for 
the the treatment of the coarse level equations. The implementations used in section 4 required however, 
only 329 and 576 lines of C for the SOR and the ML algorithms respectively. Thus we consider implementation 
overhead not to be significant. Parallelization. The Multi-Level algorithm will paral­ lelize well, given 
an appropriate choice of smoother. There are difficulties involved with the parallel execution of the 
GS and SOR algorithms, owing to their recursive struc­ t ure. However, it has been shown that the multi-color 
style of GS can allow efficient parallelization without com­ promising convergence speed [9]. Parallelization 
of ML is done by data partitioning within each level. With a multi­ color smoother, all the operations 
of the ML method at a given level can be performed concurrently. Communication will be required between 
processors for the smoothing step and collect/broadcast operations for the convergence test and enforcement 
of (2). Although coarser levels will run less efficiently, as less computation is performed there, the 
coarse granularity of the finer levels, where most computa­ tional work is located, will ensure overall 
good parallel per­ formance. Thus we conclude that the ML algorithm, too, 197 will perform well on a 
multiprocessor system or workstation AclcnowledKements cluster. The authors would like to thank J. Van 
Rosendale, D. Nicol, Cycle types. There are other alternatives to processing P Heidelberger, and G. Ciardo 
for helpful discussions and the levels of aggregation in the downward-upward sweep suggestions for improvements 
and G. Ciardo for permission to use the SPNP tool. used in the present scheme. These can be obtained 
by modifying the number of recursive calls to procedure mss in References Figure 2. Thus coarser levels 
may be visited more than once during one iteration. Such techniques can, in the multigrid <RefA>[1] A. BRANDT: 
Multi-1evel adapttve solutions to boundaTy-va/ue pro b[ems. Math. Comp. 31, pp. 333-390, 1977. context, 
lead to improved efficiencies, as the coarse level [2] W. BRIGGS: A Multigr_id Tutorial. SIAM, Philadelphia, 
PA, equations are then more accurately solved. Experiments 1987. reported in [8] have shown that this 
can also be the case for [3] G. CIAR~O, A. BLAKEMORE, P. CHIMENTO, J. MUPPALA, ML. One may furthermore 
consider dynamic cycling after K. TRIVEDI: Automated generation and analysis oj Markov Brandt [I] or 
adaptive cycling according to R.iide [II]. reward models ustng stochastic reward nets. To appear Choice 
of coarsening strategy. Convergence charac-MEYER AND (Ed. Lznear in C. R. PLEMMONS ) A[gebra, teristics 
may be improved by a judicious cho~ce of aggre-Markov Chains, and Qu.ueing Mode[s, IMA Volumes in gation 
strategy. In particular, Markov chains derived from Mathematics and its Applications, springer-Verlag, 
1993. queueing networks can possess a regular structure which may [4] G. CIARDO, K. TRPJEDI, J. MUPPALA: 
SPNP: stochastic Petrz net package. Proc. of the Third Int. Workshop on Petri be explolted. Experiments 
have shown this to be the case Nets and Performance Models (PNPM89), Kyoto, Japan, pp. for the tandem 
queue example of section 3. Our main pri­142-151 Dee, 1989. IEEE Computer Society Press. ority for future 
work is therefore to develop an aggregation [5] P. COURTOIS: Block Decomposition and Iteration in Stochas­ 
 strategy which obtains appropriate coarse systems at a rea­ tic Matr-ices. Philips Journal of Research 
39, 1984. sonable cost. Finding optimal aggregations is a notoriously [6] P. COURTOIS, P. SEMAL: Computable 
Bounds joT Condi­ complex problem, but we believe that sub-optimal solutions tional Steady State PTobabi[ities 
in La7ge Markov Chains are sufficient for the ML algorithm. ans Queueing Mode[s. IEEE Journal on Selected 
Areas in Communications, SAC-4, No. 6, 1986. 6. Summary and Outlook [7] W. HACKBUSCH: Multi-Grnd Methods 
and Appl~cat~ons, The ML algorithm presented in this paper has been Springer Verlag, Berlin, 1985. shown 
to require significantly less computation time than [8] G. HORTON, S. LEUTENEGGER: A Muhiletiel So[ution 
Algomthm jor Sieady-State Markov Chains. ICASE Report the SOR scheme for a number of test problems. 
The #93-81 NASA CR-191558, NASA Langley Resarch Center, difference between the two algorithms increases 
with the September 1993. number of states of the Markov chain. In addition to [9] 0. MCBRYAN, P. FREDERICKSON, 
J. LINDEN, A. SCHiiLLER, being significantly faster, based on our experience to date K. SOLCHENBACH, 
K. STWBEN, C. THOLE, AND U. TROTTEN­it appears that the ML algorithm is much more resilient to BERG.: 
Multigrid methods on parallel computers a sur-wey variations in transition rates. Another nice property 
of the of recent a!eve[opments. IMPACT of Computing in Science ML algorithm is that excellent performance 
can be obtained and Engineering, 3:1 75, 1991. without the necessity of tuning a parameter, such as 
the [10] M. MOLLOY: PeTfo7mance analysis using stochastic Petri net.. IEEE Trans. Comp. Vol 31 No. 9, 
913-917, Sept. 1982. over-relaxation parameter in SOR. The M L method settles [11] U. RUDE: Multilevel 
It.r-ative quickly into a constant rate of convergence, implying that On the Adapiave Method. Technical 
Report TUM-19216, Computer Science Dept., the computational work increases linearly with the accuracy 
Technische Universitiit Miinchen, 1992. requirements [12] J. RUGE, K. STUBEN: Algebraic Multigrid in 
S. McCotick Examination of a larger sample of cases, including Markov (Ed.): Mu[tigrid Methods, SIAM, 
Philadelphia, 1987. chains from real applications have yet to be made. However, [13] P. SCHWEITZER: 
A Survey of Agg?egationDisaggreg aiion in we feel that the algorithm shows enough promise to justify 
LaTge Markov Chaans. In W. STEWART (Ed.) Numern.al further investigation into ML schemes for solving 
Markov So[ufzon of Mark.. Chains, Marcel Dekker, 1991, ISBN O­ chains. 8247-8405-7. Further work will 
also include the implementation and [14] P. SCHWEITZER: Aggregation Methods for Large Mar-kov testing 
of the techniques mentioned in the previous section. Chains. G. Iazeolla, P. Courtois, A. Hordijk (eds.): 
Math­ ematical Compater Performance and Reliability. Elsevier, In particular, attention will be paid 
to choosing an aggrega­ 1984. tion strategy for general Markov chains, where no a prvori [15] L. P. 
SEELEN: An A lgortthm for Ph/Ph/c Queues, European knowledge of the topology is available. Several of 
these tech- Journal of Operations Research, V 23, pp 118-127, 1986. niques have already proven to provide 
improved efficiency in [16] W. S~mvP,flT, A. GOYAL,: A fat.izin Large DcPcnd M.thods ­ preliminary experiments. 
We hope to be able to report on abi(ity Models. IBM Research Report RC 11485 (#51598) this in the near 
future. 11/4/85. An experimental comparison with the Takahashi algo­ [17] 1 . TAKAHASHI: A Lumping Method 
foT Numerical Calcu­rithm is also pIannecI. lations of Stationary Distr-ibutions oj MaTkov Chains, Re- 
A parallel version of the ML algorithm is also in prepara-search Report No. B-18, Department of Information 
Sci­ences, Tokyo Institute of Technology, Tokyo, Japan, 1975. tion, and we hope to be able to present 
results obtained on [18] P. WESSELING: An introduction to mult~gTid methods, John a MIMD supercomputer 
in the near future. Wiley &#38; Sons Ltd., Chichester, England, 1992. 198 400</RefA>  25000~ 350 22500 SOR 
---­pfL ... .... 30020000 17500 250 15000 200 12500 15010000 7500 100 5000 50 2500 ....... . ..., 
 . ....................................... 0 ++_+._+ . -.-9.- ++.+.. . 4 o 4000 8000 12000 16000 Number 
of States-25000~ 4000 6000 8000 1000G Number of States  Figure 4: Birth Death problem with fixed diameter. 
Computation times. 3000 275o 2500 GS -w SOR -w-­225o /: ML -R-­ 100000 2000 GS* 1750 SOR -=--­10000 
 ML ---­1500 1250 ,,./., ~.. 1000 #1000 750 ,,... ....-- -100 500 :/; ~ A ,.,, ,, 250 //:; - x 
 - = ,,,. 10 MB: %., 0 ---.dc::z.-. ..- .+. ...-.d....., ..,*. f %...... -250 [ J ... ...........w 
,,.s --a ..=,, ........*..=....-.. = o 2000 4000 6000 8000 10000 1 Number of States . ....--* - .-.*-......-. 
--­  1)== I0.1 300 0.001 0.01 0.1 1 10 100 1000 Ratio of (death Rate [ birth Rate) 250 GS -+-- SOR 
-w-1000 ;, 200 100 150 / / ... -* - 100 ...-. ....­10 .,....-= / .,.,x -,..x., / ~... 50 ,....­. 
...=­ / .,.=.­1 W.- 0  0 2000 4000 6000 8000 10000 I.-.*------------------=.-......+* Numbel-of States 
 1 0.1 I 0.001 0.01 0.1 1 10 100 1000 Ratio of (death Rate I birth Rate) Figure 3: Birth-Death chain. 
Top : Number of Iterations; Center : Computation tim~; Bottom : Time Ratio. Figure 5: Birth-Death chain, 
effect of varying rates. Above : Computation time; Below : Time Ratio. u Figure6: Tandem Queueing Network 
4500 4000 3500 GS * SOR -*-­~ ... .... / 3000 / 2500 2000 1500 1000 500 Figure 7: Tandem queue, variation 
of pop. Computation times. 1000 100 10 ~~ 10 100 1000 0.001 0.01 0.1 1 Ratio of mul / mu2, mul set to 
1.0 l/p2 Figure 8: Tandem queue problem, variation of p Computation time. Figure 9: Molloy s Problem 
IIIII 100000 10000 1000 K F 100 k GS O P s 10 ML l 1  0.1 I IIII 2030 40 5060 Population Figure 
10: Results for Molloy s problem (:@::::@ ---0 p,, (.-.-- O-> _ _ -0 E ?. ....... i.oj ,,, ___----@ 
/,;...;, ___; : 0,0 IQ KI .........­ 0, 1,1   ..1 0 III II I II ,! @@---- =-4 ?>=; --@ I-...4 
, !1 I o 0----o Figure 11: Markov state space for tandem blocking queue 200  
			
