
 A Distributed Shared for Ada 83 and Ada Yvon Kermarrec D6partement Informatique T616com Bretagne BP 
832 29285 Brest Cedex France kermarre@iif.enst.fr ABSTRACT This paper presents our experience in developing 
a toolaet for distributed applications in Ada. Ada has been chosen as our programming language because 
it offers software engineer­ing concepts and an interesting tasking model. In this paper wc shall present, 
among other things, a software component which implements a distributed shared virtual memory and which 
thus allows distributed Ada applications to commu­nicate using a single address space. Our approach is 
based on an existing algorithm but we have extended it in order to tackle Ada peculiarities. This software 
component is a key component in our toolaet as it can be used either at the programmer level or at the 
level of the kernel implementor. INTRODUCTION Local area networks and workstations are becoming more 
and more common. Each machine in such a system has its own locaJ memory and each machine may communicate 
with its neighbors using a communication facility (e.g. Ether­net ). There is no shared memory in such 
a distributed sys­tem. Therefore, message-baaed communication is the sole means of exchanging information 
with the other nodes. As mentioned by H. Bal et al. in [2] it may seem to be unnatural to use shared 
data for communication and synchronisation in a distributed system . Nevertheless, if we still want the 
programmer to benefit from a single ad­dress space memory and use the shared memory program­ming paradigm 
[1], we have to design a Dwtributed Shared Viitual Memory (DSVM) by implementing a software layer based 
upon : the local memory of each machhe,  a set of adequate algorithms and protocols which can transmit 
data between machiies and which guarantees memory consistency.  We do not intend to substitute the shared 
memory com­munication scheme for the message-baaed communication model. Our aim is to propose both paradigms 
to the pro­grammers so that they can choose the most adequate model. Permission to copy without fee all 
or part of this material IS granted provided that the copies are not made or distnfuted for direct commercial 
advantage, the ACM copyrfght notice and the title of tie pubficatkm and its date appear, and notice is 
given that copying is by pernd~im of the Association for Computing Machinery. To copy otherwise or republish, 
requwes a fee and/or specific permission.  Virtual Memory 9X Applications Laurent Pautet Dassault Electronique 
55, Quai Marcel Dassault 92214 Saint Cloud -France or D4p. Inf. -T614com Paris 46, Rue Barrault 75013 
Paris -France pautet@inf.enst.tk  In this paper, we show the concepts and the advantages of a DSVM and 
the issues raised in developing such a memory for Ada applications. Then we present our implementation 
and an example which illustrates the power of expression and the simplicity of our components for the 
programmer. Finally, we conclude with research in progress. 2 CONCEPTS AND INTERESTS A shared memory 
offers several benefits. It can be considered as a communication medium in many simple situations. Activities 
may communicate provided they access the same address : one activity sets the value and the others read 
it. Thus, such a com­munication may involve several partners and therefore is broader than the classical 
rendezvous (only two part­ners at a time). Moreover$ process naming is required in Ada rendezvous since 
the sender has to name the receiver and there are restrictions to program accept statements. There are 
no such limitations in shared memory-based communication. The shared memory programming paradigm is well 
known and thus eases software developments. For ex­ample, let us consider the case of the transfer of 
data structures like heaps or trees. In a message-based communication scheme, the data must be flattened 
and then all the values have to be transferred. In shared memory based communication, the transfer of 
a pointer to the data structure is sufficient. Message-based synchronous communication is not very flexible 
and may introduce deadlock situations. In or­der to cope with such a situation, application program­mers 
have to mix deadlock detection and resolution in their code thus making the application more complex 
and harder to design. Shared memory bnacd communication prcacnts inter­esting features for real time 
dwtributed applications [2]. The assignment of a shared variable has an ixn­mediate effect (provided 
the data is on the node) whereas communication through a network induces de­lays. Moreover, a read operation 
of a shared variable may also be immediate provided there are memory copies whereas message-based communication 
requires message passing each time. Shared memory can be used at different levels : ap­plication programmer, 
kernel designer and system de­signer. It can be considered as a general purpose com­munication component. 
 01993 ACM 0-89791-621 -2/93/0009--0242 1.50 Fmrdly, the design of a fault tolerant system will be easier 
with such a memory since vital informaflon may be stored in it. Activity migration (due to a fault and 
not linked to load balancing) will also be smoother by implementing kernel information and process informa­tion 
in the shared memory area. Nevertheless we are aware of the limits and the draw. backs of the shared 
memory communication scheme. The major disadvantage of such a mechanism is ensuring mem­ory consistency 
[11] [15] and its costs. Moreover, express. ~g Synchronisation is not as easy as in the message-based 
paradigm. 3 A DISTRIBUTED ALGORITHM 3.1 VARIOUS ALGORITHMS Dwtributed shared memory has been well studied 
for many years [14], [11]. Many tile algorithms are provided for implementing DSVM. These algorithms 
ensure data consis­tency of a distributed virtual address space. Most of these algorithms behave somehow 
like CPU caches. Therefore, as they are mainly used in diatributcd operating systems, the distributed 
virtual address space is usually partitioned into pagea. Otherwise, these algorithms may be compared 
to each other in terms of communication overheads and cost, data migration and replication, ... The following 
paragraphs highlight how algorithms can be improved to allow more dynamic and more flexible situations 
(See [14] for more details). 1. The most natural akorithm is baaed on a centralised client/server approa&#38; 
A centralised algorithm asso­ciates one or more pages to each server which updates these pages. Write 
and read operations are executed through the server by sending requests and receiving acknowledgements 
or page copies. 2. Another algorithm may be used when the page locality is not adequate. To be more 
precise, the page owner may be overloaded by too many requests especially when it is not the most frequent 
writer. Then, the page should migrate to thisvery frequent client. In this algorithm, when write request 
is received by the page owner, the page is sent to the client which be­comes the new page owner. Read 
operations will still be executed by the page owner. This solution which integrates page migration is 
an answer to preventing write request bottlenecks.  ., o. Read request bottleneck is a similar problem 
that has a more flexible answer as the unicit y of the page copy in read-mode is not required. Therefore, 
page replicas may be delivered by the page owner to several clients as long as the page is not modified. 
Therefore, a copy is sent to the client which may execute as many read operations as needed without sendhig 
requests to the page owner. An invalidation protocol ensures that any write operation invalidates all 
page replicas. 4. The last algorithm provides full memory acccsscs for multiple writers as well as for 
multilple readers. The page server serializes write operations. Updates are propagated to owners of copies 
(in read and write mode). To summarise, the more d~tributed the application is, the more sophisticated 
the algorithm has to be. 243  3.2 IMPROVED DYNAMIC DISTRIBUTED SHARED MEMORY Among these diiFerent strategies, 
we chose to implement the algorithm of multiple readers/single writer replication i.e. the thiid one. 
One of our purposes is to allow migration of objects (ultimately tasks). The abiit y to localine a page 
at execution time is very attractive compared to the centralised algorithm. Therefore, in thii context, 
the first algorithm seems too static. Compared with the second algorithm, the third one im­plies an invalidation 
protocol which is of a very low cost compared to read fault occurrences. On the other hand, the fourth 
algorithm is well suited to small syrkcms accessing pages in read mode as frequently as in write mode, 
but it overloads the network. As it has been highlighted in section 2, the DSVM should be provided to 
help the user to reduce distribution complex­ity. But, a software layer providing a DSVM service cannot 
reach the performance of a normal local memory. Therefore, an application writer has to be aware that 
too many write operations would overload his network. He: has to choose an appropriate strategy of data 
localisation nnd distribution dependiig on whether data are frequently updated by dif­ferent nodes or 
not. Using a shared memory implying a low read/write ratio is unsuitable and we decided to discard the 
fourth algorithm. To be more precise, we chose to implement an improved version of the third algorithm. 
In its original version ([11]), the algorithm allows a copy to be delivered only by the page owner. The 
implemented version allows any owner of a copy (ii read or write mode) to deliver immediately a copy 
in read-mode upon client request. This allows a client to quickly acquire a copy in read-mode without 
contacting the page owner in order to get thM copy. Note that now the in­validation protocol spreads 
requests through a dependency tree. In figure 1, we illustrate the concept of dependency tree. A plain 
arrow from Node A to Node B means that Node B has delivered a copy in read-mode to Node A. At step 1, 
Nodes 1 and 2 own page copies. At step 2, Node 2 requests the page in write-mode. Therefore, copies of 
Nodes 1 and 2 are invalidated and Node 2 gets the page. Dashed arrows from Node 1 and 3 to Node 2 mean 
that Node 2 is the new page owner from Node 1 and 3 point of view. At step 3, Node 3 gets the original 
page in write-mode horn Node 2. Node 1 has no copy in write or read-mode; therefore, the dashed arrow 
between Node 1 and Node 2 is not modiiied. Then, Node 2 asks Node 3 for a page copy in read-mode. At 
step 4, Node 2 delivers a page copy in read-mode to Node 1. When Node 3 invalidates its page, the invalidation 
request will be propagat cd recursively to Node 2, and then to Node 1. The invalidation protocol is described 
in 3.3 Conceptually, th~ improved algorithm is not dlffcrcnt fr9m the initial thkd algorithm and is also 
described in [11]. 3.3 EXTENSIONS FOR EMBEDDED SYSTEMS Let us now depict the algorithm (See [11] for 
more details) : 1 2 C+@ .. 3 S*1 c1Sql2 1? 21 2 s:%% 3 3 Smp4 F~ure 1: Node 2 get% a page and invalidate 
writers. Then, Node S gets the page and node 1 get* a wpg jrom node 2. NOTATIONS A page server is present 
on each node of the system and the servers maintain all together the consistency of the virtual memory. 
When a user activity wants to access a data, it contacts its local server and there are two situations 
: the data is available or the data is not. If the data is unavailable, the server makes a read/write 
page fimlt in order to get the data from the others. For each page, there is a unique real owner (real 
is used here for clarity) : this node is the only one which can access a page in write mode. Being a 
real owner of a page is a privilege which the node might transfer to another node upon request. Several 
nodes may be client owners: they have a copy of the page in read mode but they are not the real owner. 
Let Pag=Tab2e be a table of records (one per page) composed of two fields, the Probable.Owner field and 
the CopySet field. Probable-Owner When a write-fault occurs, a page acqui­sition request is sent to the 
Pri&#38;bkOwner of this page. The ProbableOwner field contains the last node to which the local node 
delivered the page in write mode or for which it forwarded an acquisition request. Note that the Probabl~Owner 
is not usually the real owner as the Probabl~Owner may have already de­livered its page in the meantime. 
By following the se­quence of Probable-Owner, the page acquisition request will reach the find page owner. 
Of course, each succes­sive owner properly maintains ita Probable-Owner field at the value of the last 
node to which it has answered an acquisition request. Copy-Set When a read-ilmlt occurs, a copy scquiskion 
re­quest is sent to the Pwbabl&#38;Owner of thispage, but thistime, a copy is required, not the privilege 
of being the real owner of the page. Therefore, as soon as the *wanderingw request arrivea at a node 
in which a copy can be provided, the local node aends a copy to the client and adds the client to its 
Copy.Set. Thus, the Copg.Set of one node describes a list of clients (client owners of the page) to which 
the node has delivered a copy. Moreover, the owner of the original page is the root of a tree whose leaves 
represent nodes which own a copy of this page and whose branches represent nodea which dao own a copy, 
but have delivered copies of this page as well. INVALIDATION When a red page owner wants to deliver 
a page in write­mode, it provides this page with its Copy-Set. The client invalidates existing page copies 
by sending invalidation re­quests to each node recorded in the received Copg-Set and its own Copy-Set 
(F~ure 1). At invalidation time, each client modify the Probab2~Owner field as this invalidation session 
started tkom the current page owner. 3.4 PA(3E REPLACEMENT The fundamental point not described in [11] 
or in most other algorithms is page replacement. Obviously, if a node ac­quires too many pages in write 
mode (and manages them) without redly using them, it needs to free 10CZJ memory space to load new shared 
pages. In an operating system, unused pagee are typically saved on a dwk. Many strategies are used to 
determine which unused pages should be saved on a disk (like oldest pages first or less used pages first). 
In the context of embedded systems, such a strategy is unsuitable as the system could be diskless. Therefore, 
we have improved and adapted the existing algorithm for our purpose. As a matter of fact, we shall notice 
that in this case the consistency strategy is not independent of the re­placement strategy. We chose 
to flush oldest pages first as this criterion seems simple and standard. We present this extended algorithm 
in the following paragraphs. MEMORY PARTITION On each node, the local memory space dedicated to the shared 
memory facility is divided into two parts as described in figure 2: Page permanent storage r At initialisation 
time, these pages are shared pages and are owned by the local node (red page owner). We call home owner 
of the page the node which is its red owner at initializ­ation time. There is a unique home owner and 
this information cannot be modified whereas the red page ownership can be transfered according to the 
memory needs. At execution time, when another node wanta to get rid of a page, it flushes this page to 
the home owner. Thus, this node must be able to store them in the permanent storage location at any time 
; The per­manent storage is never used to store pages or copies other than the pagee or copies described 
at initialis­ation time. Thus, the permanent storage remains al­ways available for flushing request. 
After storage, the local node is the probable owner as well as the real owner. Page cache storage : Page 
cache storage enables the local node to load pages when it owns a page m write or read-mode or when it 
owns a copy in read-mode. When memory storage w needed, the node may free some of these pages and may 
tlush them to their home owner. No&#38; 1 Isa 1% n um.t ManOry c1 C-he nwmory Figure 2: Node 1 acquirea 
Page 1 jimn node 2. Node acquirea Page 5 ~m node 1. DEADLOCK PROBLEM This new page management raises 
another theoretical prob­lem described in figure 3. This problem is linked to a mod­ification of ~1 and 
Hudak s algorithm as the real page own­ership might be transferee spontaneously if the node wants to 
free its local memory. As we can notice, when node 2 deadcs to flush page 3 to free local memory (After 
flushing, Pdable_Owner or PO = 3), nodes 1 and S ask for page 3 in write mode. As PO = 2 for node 1 and 
3, these nodes send their requests to node 2. Let us assume that the request of node 1 arrives first; 
this request is forwarded to node 3. Now, in node 2, PO = 1. When the request of node 3 ar­rives, this 
request is forwarded to node 1. Therefore, we are in a deadlock situation as the two requests must wait 
for the completion of each other. At time T, node 3 is the only one to know how to solve the problem 
as page S has been flushed him. In order to unlock the situation, node 3 will force the acquiakion of 
page 3 by node 1. The algorithm may now continue as described in 3.2. Thus, we have developed an algorithm 
in order to provide PO=2 PO=2 m=2  i=~-.---,,); -;4.. ­ . -n m=l m=3 ,kEEr---- T Acquire IRca - 
Nede 1 Node 2 Node 3 -. ---Node 1 asks for page 3 in write mode --------Node 2 flushes&#38;c 3 back to 
site 3 Node 3 asks for page 3 in write mode F~ure 3: Deadlock situation due to page replacement stmt­ 
e~ a DSVM in an embedded environment. Dtierent strategies have been chosen to fit Ada peculiarities. 
These different choices have led us to fully define the algorithm from the consistency phase to the page 
replacement phase. (F~ure 4 illustrates the memory structure). 4 ISSUES RAISED USINC3 ADA AS A PROGRAMMING 
LANGUAGE This section presents two distinct levels. The first one is linked to Ada as the implementation 
language of our sys­tem. The second level deals with issues linked to Ada as the 245 Node2 , 0 1 ~ . 
--- LJ W Wri. mode ~ Read mode .- --Permanent cache Flgurc 4: Memory dtructurs language which is used 
to program applications on top of DSVM. 4.1 COMMUNICATION FACILITIES As presented earlier, the design 
of DSVM requires the abfity to communicate by message passing. This facility is not offered in a standard 
Ada environment for a distributed system. We reuse an Ada software component which implements communication 
in various situations [9]. It follows recom­mendations of international working groups (CIJ?O [3] and 
ExTRA [7]). Our implementation is available in the Unix world using several interproceee communication 
tools [13] (Pipes, fles, sockets -d tli) and can be extended to real time environments. 4.2 GRANULARITY 
The page is the unit in a distributed shared virtual mem­ory. Granularity is defined here as the physical 
memory sise which is required to store a page on a given node. In network protocols, the sise of a message 
is not the key factor in eval­uating the cost. The traversal of the protocol layers (thue enforcing the 
reliabfity of the transfer) is not much cheaper for a message of 10 bytes sise than for a message of 
1000 bytes sise. At a first glance, it seems preferable to choose very large page... Nevertheless, onc 
has to realise that ac­cess confllcts depends on the page sise. K. Ii and P. Hudak [11] recommend a sise 
of 1 K-bytes. But one must take into account that the optimal sise is application dependent.  4.3 CONSISTENCY 
AND LIVENESS For efficiency improvements, we have to consider data du­plications in the system. Thw raises 
the issue of consistency among copies of the same data : i.e. the value returned by a read operation 
of variable v must be the value which has been stored at this variable on the more recent write operation. 
 The system must also be fair : i.e. activities must have equal opportunities of accessing a page in 
order to avoid starvation (thus guaranteeing system Iivertess). This prop­erty can also be expressed 
in terms of time : once a node has required a memory page it will receive it. 4.4 PECULIARITIES OF ADA 
AND ADA 9X R. Dewar et al. [4] consider three classes of storage for variables in Ada 83: Local memory 
: accessed only by one task.  Shared memory accessed by multiple tasks in a syn­chronized manner.  
Memory labeled with pragma sha~ accessed by mul­tiple tasks in an asynchronous manner.  The last two 
classes of memory can be implemented in the DSVM. For asynchronous data, declared by pragma shared the 
implementation must guarantee atomic access to them and each access to such data is considered as a synchronies 
tion point. In our DSVM model, several copies of a given data can exist but none of the copies can be 
modfied; only one node has the privilege (which can be transferred) to modify a data and in thii case 
there cannot be any copy of the data. In the case of a read operation, the model fits Ada requirements 
as it guarantees that all the copies are identi­cal. In the case of a write operation, the model is compatible 
with Ada as there will be no other read and write operations. Synchronous data will be handled as asynchronous 
data. This model is a little bit too rigorous aa the programmer is supposed to take care of data synchronisation. 
Therefore it might have been possible to delay invalidations up to an ordinary synchronisation point. 
Ada 9X has taken into account the limits of Ada 83 and has also removed the ambiguity of pragma Shared 
[4] [8]. Ada 9X proposes two new pragmas : volatile and atomic. Therefore we now have four classes of 
storage for a variable inAda 9X : local memory,  synchronous variables,  atomic variables (atomic 
~ the ncw name of pragma shared),  volatile variables.  So let us consider volatile variables since 
atomic variables match the previous situation (pragma shared). The pragma volatile Lv3cater. that the 
read and write operations must go directly to the memories. Thii pragma can be used to program the shared 
circular buffer [5]. As stated in the Ada 9X documents, it is impossible to keep local copies of the 
variable. We claim that DSVM cart be used to store volatile data. Let us consider the shared circular 
buffer. By declaring the data buffer as volatile, we are guaranteed to maintain the consistency of the 
data when accessing ends of the buffer (the producer and the consumer access the memory directly). For 
thw, the DSVM must be designed to handle large objects like arrays (we present thw issue later). 4.5 
THE STRONG TYPE MODEL A memory is an ordered set of words and each of them is a string of bits. Our DSVM 
is a memory and is designed to store programmer s data which are typed since declared in art Ada program. 
But here we have a gap since types are only used by the compiler and the programmer levels and wc still 
need to fit Ada requirements. Therefore implementing a DSVM in Ada raises the issue of type controls. 
For the moment, we do not check Ada types. This point is illustrated by the use of the address attribute 
as param­eters of DSVM primitives. One way to deal with this sit­uation is to integrate the notion of 
dutributed variables at compilation time. This solution will also solve the problem of accessing distributed 
variables with names instead of ad­dresses.  4.6 CONTROL In message passing communication, communication 
and synchronization are often closely related (e.g. the Ada ren­dezvous). ThB is no more the case with 
shared memory communication ; thii can imply polling and thus a waste of time. As mentioned earlier, 
our implementation maintains mem­ory consistency. Nevertheless, the Ada programmer must still consider 
race conditions and nondeterrninacy. 5 SPECIFICATION AND IMPLEMENTATION As one can imagine, the design 
of a DSVM presents several difficulties. Our developments are even more complex since we want the DSVM 
to be used at three distinct levels : Inside the kernel : the kernel solves &#38;ult accesses and manages 
1/0 requests itself. It schedules tasks which are waiting for unavailable pages itself.  Outside the 
kernel : the page server is art internal pro­cess of the Ada run-time. It is an internal service of­fered 
to the run-time.  User level : the service is offered at user level. The user is granted a DSVM service. 
An Ada package provides these memory primitives.  In the following sections, we indicate the Ada specification 
of our DSVM software component. Then we preoent extensions we have produced so that DSVM cart be used 
at the appli­cation level and solve complex problems. Finally, we present implcmerttation details and 
the technical problems we faced during the design of these Ada software components. 5.1 ADA SPECIFICATIONS 
As mentioned before, DSVM has to offer basic memory op erations. Peek and Poke primitives access the 
shared mem­ ory; Copy primitives allow the programmer to transfer data between the local memory and the 
shared memory or be­ tween shared memory areas. Therefore we have the following Ada specification for 
our software component. with System; package Shared-Memory is type Shared-Address is private; type Shared-Count 
is private; type Shsred.Word is private; Shared-Storage-Error : exception; Data : Data-T); procedure 
Pree ( Sh.Addr : in Shared-Address; Sl%e : in Shared.Count ~ procedure Allot ( Sh-Addr : out Shared. 
Addrq Si*e : in Shsred.Coumt} procedure Poke ( Where : in Shared-Address; Value : in Share&#38;Word); 
procedure Poke ( Where : in System.Address; Value : in Sh.ared-wed); procedure Peek ( Where : in Sharad-Address; 
Value : out Shared-Word} procedure Peek ( Where : in System.Address; Value : out Sharad-Word~ procadure 
Copy ( Source : in SharedAdd~ Destination : in Shared-Addrass; Count : in Shared-Count); procedure Copy 
( Source : in Shared-Addreoq Destination : in System.Addreq Count : in Shared-Count} procedure Copy 
( Source : in System.Addrass; Dmtination : in SharedAddress; Count : in Shared-Count} procedure Copy 
( Source : in System. Addreq Destination : in System.Address; Count : in Shared.Count); procedure 1nit3hsred-Memory; 
procedure Stop-5hsredJ4emory;  end SharadJ4emow DSVM is prone to thraahirw. To explain thii situation, 
let us consid&#38; the simplest o~eration &#38; the memory : s&#38; incrementing of art integer value 
(e.g. var :=var + 1). In the worst case, this operation generates two page huh and several invalidations 
of existing copies. If many nodee do the same operation, no real work cart be done on a node since pages 
have to be transferred or invalidated contirm­ously. As another example, let us consider the initialisation 
of an array. If we do not have high level primitives, then we have to perform irtitidisation of each 
component of the array, and this may produce aeverd page faults. Whereas, it is possible to perform the 
initidiaation of the whole ar­ray, provided there is a dedicated primitive. Therefore, syn­chronisation 
operations and memory management must be specially tuned [12]. We are developing complex primitives which 
require aev­erd read/write operationa on a given page. As mentioned earlier, the problem in developing 
such a component in Ada relies on typecontrol. One way to ded with such a situa­tion is to use generiaty. 
Nevertheless, we cannot consider all possible operations and we have to sdcct the most adequate ptiltivea. 
Here is a simple Ada software component, which offers three primitives : the first one performs an atomic 
operation (generic pa­rameter) on data stored in the DSVM. Thm operation cart be used to increment the 
value stored at the given address.  the second operation is quite simiiar to the first. ThE operation 
can return a partial result, for example.  the third one can be used to copy one memory block to another. 
The count Darameter indlcatee how many memory words are concerned by such a transfer.  package SharedJiemoryJUanagement 
is generic type Data-T is private; with procedure Locrd.Operation( Addr : System. Addre=; 247 procedure 
DSVM-Operation (Shared-Addr : Shared-Address; Data : Data-T); generic type Data-T is private; with procedure 
LocaLOperation (Addr : System. Address; Data : out Data-T~ procedure DSVM.Operation (Shared-Addr : SharedAddwq 
Data : out Data-T} generic with procedure Local-Operation( Addrk : System. Addre~, Addr-Out : System.Address; 
count : Iuteger); procedure DSVM-Operation (Shared-AddrJn : SharedAddrss~ Shared.Addr-Out : Shared-Address; 
count : Integer~ end Shared-Memory JWanagement; This package (i.e. Shared-Memory-Management) has a wide 
range of applications. One has also to note that the first one (i.e. Shared-Memory) can be obtained from 
an instantiation of Shared-MemoryJlanagement.  5.2 LARGE OBJECTS As mentioned before, the DSVM unit 
is the page, but for software engineering purposes, another Ada package manip­ulating objects should 
offer genericity, modularity, inform­tion hiding and strong typing to provide the nice features of Ada. 
Developing such a package could be easy as long as the developer takes care with tricky problems. Let 
us assume that two nodes want to initialize art array allocated onto two DSVM pages. Let us assume that 
node 1 starts to Wltirdize each element of the first part of the array to 1 and then releases the page. 
The modified page is at the same time acquired by node 2 as well as the second page. Node 2 initialises 
the full array to 2. Then, node 1 completes its job by initidising the second part of the array to 1. 
Therefore, the array is inconsistent. Of course, node 1 should get page 1 and. 2 at the same time. But, 
once again, this raises other problems. Let us assume that node 1 wants page 1 and then page 2. On the 
other hand, node 2 wants page 2 and then page 1. If neither of them releases its pages, there will be 
a deadlock. Node 1 gets page 1 and node 2 gets page 2. A strategy which consists in acquiring pages in 
a predefine order could solve the problem. But, this shows how careful the user should be when developing 
Ku application. Let us assume, now, that we manage a double linked list of abstract data. The insertion 
operation rteeds to modify the previous object as well ea the next one. When the unit is the page, such 
an operation executed in a distributed en­vironment may lead us to an incorrect situation even if the 
object is on one page. Let us assume that node 1 modi­fies the next object whiie node 2 modifies the 
previous one. Then, the double linked list is corrupt. For thisreason, well designed Ada packages manipulating 
shared objects should be designed to prevent the user from such an error. We have proposed solutions 
for the mentioned problems. Our DSVM components implement solutions to the latter. Nevertheless, we still 
have to validate our algorithms.  5.3 AUTOMATA Automata are our basic tools for the design of our software 
components : An automaton can be used to program efficient eolu­ tion to complex problems. An automaton 
moves from one state to another trig­ gered by transitions. It can modelise the behavior 6f a server. 
The different events of a DSVM automaton are mainly re­ quests : ~ rmte server Read A server asks f 
or rc ad access to the page ACqUW= A server answers an e+cqumtion request. COPY A server answers a copy 
request. Th e server asks the local server to lnvah. date copia and to propagate the invali&#38;tion 
request. InvalidateAck The server receives acknowledgement of in­validation requests &#38;am other servers 
of its Copy-Set and can itself propagate the invali­dation acknowledgement; -- Save Th e 10Cal server 
w told to save a page in its own p armanent memory space to unload the memory encumbrance of another 
server. We may provide the diferent states encountered by the page server as an automaton : Acquwing 
Th e server re w~tmg for a page m write-mode. Acquumg/O wn Same ss Acquwmg except that the server gets 
its page and invalidates the ditkrent copies of other servers, coPYW Th e server IS wrutmg for a copy 
III read-mode. dating Th e server IS weutmg for mvab datlon acknowledgments. Invalid Th e server has 
no rights over th e page. Write The server has Its page m wrnte-mode. < Read/own Th e server has Its 
page not m wrste-mode but I I in reed-mode. --I I Th e server has a copy m reed-mode. Iv cmurmrf/Save-. 
I Same as Acaumnx excemt the tthe maae has been flushed-by &#38;other-server and it k to wait for its 
request to be forwarded (3.4) Oopyrng/Save Same as Acquiring/Save for a Copy request. The automaton 
table in fi ure S d ~ribed the difFerent actions to be taken (ii br ~ets) and the resulting state. The 
dilFerent actions may be detined as follows : Is Is uepend I Th = request Is queued ad w~ be answered 
1 I later. tore I Th e rccelv ad page is Sto red m one of the two I memory stora---( 3.4) Invalide te 
Th valid atlon request IS propagated to the Co~y~Set. If the Copy. Set is empty end the previous state 
is not Acqu.irktg, the resulting state is Invalid. Release The page is sent to the client. Deliver A 
copy is unt to the client. Forward The request is forwarded end Probable-Owner is updated. Propagate 
If every acknowledgment has been received, the resulting state is Invalid except when the state wee previously 
Acquiring(/Own).  5.4 TECHNICAL PROBLEMS We want our DSVM component to share a memory between Sun workstations 
connected to each other by a network like Ethernet. Thanks to our communication component De­vices, most 
of the usual problems raised by the interaction .. x   %7 1 %71x Ix K %%%!IR52.I I n v-v I F~ure 5: 
Automata table between the Ada run-time and the network were solved [41. But, we now describe the remaining 
difficulties we faced dur­ mg implementation. REPRESENTATION CLAUSES Devices wee designed to work on 
WFerent machine types. It uses severed protocols like streams (Tli) and tcp (Socket). It has been ported 
on dMerent Ada compilers and target machines. Therefore, the DSVM component may provide a communication 
means using different networks transpar­ently from the user s point of view. It offers a common ad­dress 
space through various networks. We want also our DSVM component to be portable from the Ada technology 
point of view. Therefore, the same prob­lems of data representation remain present. In the case of o 
DVSM sharing pages, the problem is solved by forcing datl~ representation at DSVM level. But, as soon 
as we want to share objects, it is the developer s r~sponaibiity to ensure data clause representations 
of shared objects. Ada, which is a strong typed language, requires a typed data reception. This problem 
increases with complex types since a type de­scriptor is added to the real data. TERMINATION As our DSVM 
is a shared Ada package, we would like to evel­uate the termination of our components. But, as in Ada, 
it is not possible to detect a local termination before the effective termination, once again, it is 
the user s responsibility to ac­tivate the termination ,of the DSVM component. Of course, such a solution 
is inadequate, but automatic termination de­tection would need much more run-time information than h 
possible nowadays. Finally, when the DSVM is used at ker­nel level, such a problem is solved as we may 
have direct access to thw information. Thus, a global termination elgo­rithm may be activated to stop 
the kernels properly as well as the DSVMS. 6 EXAMPLES 6.1 MUTUAL EXCLUSION As an example, we programmed 
a mutual exclusion ** rithm written by D~katra [6]. We are aware that this dg~ rithm is not optimal and 
presents aeverd drawbacks as ihr as fault tolerance is concerned. Nevertheless, we sdected it because 
of its simplicity. In the algorithm, we have aeverd nodes and each of them has a distinct identity (MyJd). 
These nodes are connected by a logical ring. There is art array of flags which stores one data per node. 
Each node can access ita associated value (My.Value) and the value of its ndghbour (Neigh­bottr-Vdue). 
Thus, we need a distributed shared memory to store these flags. One node will get the mutual exclusion 
privilege as soon as the following condition is evaluated to true. (A&#38;Zd = O and Jfg-Value = Neighbouw-Value) 
or (d@Id /= O and J@ Value /= Neighbourg-Value) This algorithm is not symmetrical since the node whose 
identity is O baa a special function. One major drawback of this algorithm is that mutual exclusion is 
transferred from one node to ita successor on the logical ring. Therefore, one node can receive the right 
to enter mutual exclusion even if it doea not need it. We have not taken care of the initialisation of 
flags since our DSVM component irtitidisee the shared memory to O. The following program is executed 
on aeverd Sun worksta­tions. One has to note that in the application code there is no reference to the 
topology (e.g. the names of the machines, the underlying communication protocol,...) since there is a 
configuration file. This guarantees portability of the appli­cation on various networks and eases software 
developments. proeadure MutJ3xcDUkstra74 is MyJd, NbJbdes : Integer32; Object-SharcLAddren : Shared-Addreu 
:= l% My-Value, Naighbour-Value : Iateger3~ ~eg= I.t.Io i. new lkxtJo.IntegerJo (Integer32~ Io&#38;ShareLMemO~ 
MonoJIkxtJo.Put ( Nodu : J Int-fo.Get (NbJfodes} -number of nodes in the network MonoJIkxtJo.Put (mid 
: } IntJo.Get (MyJd~ -each node must get a diitinct id loop -mutual exclusion prelude loop if My-Id = 
O then Copy (Object-Shared.Addreu + (NbXodea -1) * 4, Neighbour.Value ADDRESS, 4X Copy (Object3hared.Addrau, 
My-Value ADDRESS, 4); eke Copy (Ob@t.Shared-Addrms + (MyJd -1) * 4, Neighbinw-Value ADDRESS, 4} Copy 
(Object-Shared.Addreme + MyJd 4, My-Value ADDRESS, 4~ and ifi exit when (MyJd = O and My-Value = Neighbour.Vrdue) 
or (MyJd /= O and My-value /= Neighhour-Value); delay 0.1; end loop, -in mutual exclusion Mono.lkxtJo.Put-Ltne 
( In mutual exclusion ~ delay O.~ 249 if My-Id = O then My-Value := My-Value + 1; Copy (My-Value ADDRESS, 
Ob@t.SharedAddrer.a, 4); exit when My-Val = 5, else Copy (Neighbour-Value ADDRESS, Object.SharedAddress 
+ MyJd * 4, 4); exit when Neighbour-Value = 5; end ifi delay 0.1; end 100W Stop.Shared-Memory; nd MutJ3xcDUkctra_7~ 
 6.2 DISTRIBUTED ALLOCATOR Another example is a distributed allocator. The DW tributedJIeap procedure 
is duplicated on each node of the distributed system. Nodee use their own allocator and ask for an amount 
of distributed memory. The shared address 16#0000# is reserved to localize the flee block section. This 
address stands for a shared distributed variable. This vari­able points to the free block section shared 
by each allocator. In the Allot procedure, the reader may notice how the W quest-Page/Ileleaae-Page sequence 
provides a critical region to secure concurrent access to the shared address 16#0000#. Nodee try to allocate 
aa many blocks as possible and link them together to create their own list. procedure Allot (Sh.Addr 
: out SharedAddress; size : in Shared.Count) is RSke : Shared-Count := SlzeR.ound (Size); Addr : System.Address; 
Head : Shrared-Addrers; begin Reque8t.Page (O, Write, Addrb Shenr&#38;Memory.Copy (Addr, Head ADDRESS,, 
4); if H:&#38;~= O then := 4; end i~ if Max-ShJdemXk -Head >= lt.%se then Sh.Addr := Her@ Head :. Head 
+ RSh.q Shared-Memory.Copy (Head ADDRESS, Addr, Ralea9al%ge (0); else ReleaseYage (0} raiae Shared.Storage=rroq 
 end i~ end Allot; procedure Distributed-Heap is Head, Add&#38;, Addrl : Shared.Addresq Pattern : array 
(0..7) of Iuteger8 := (others => 1); begin Init.Shared-hfemory; AUOC (Head, 12~ AddrO := He*, loop bOgift 
Copy Pattern (O~Addreu, AddrO, 8~ Allot [ Addrl, 12} Copy (Addrl ADDRESS, AddrO + 8, 4); A&#38;tIQ := 
Addrl; exception when Shared-StorageError =:> Copy (Head ADDRESS, AddrO + S, 4); exit; en&#38; and 
loop, TextJo.Put (Shared-Addrers IMAGE (Head)); AddrO := He*, loop Addrl := AddrO + ~ Copy (Addrl$ AddtQ 
ADDRESS, 4~ TkxtJo.Put ( => k SharedAddress IMAGE (AddrO)~ exit when AddrO = Head end loop; REFERENCES 
Stop.Shsred-Memory; end Dist ributedJIea~ <RefA>[1] G. Andrews and F. Schneider. Concepts and notations for 
concurrent programming. ACM computing surveys, 15(1):3-44, 1983. Figure 6 illustrates the artioning 
of the distributed shared heap. In thw examp YS, each node creates a list of [2] H. Bal, J. Steiner, 
and A. Tanenbaum. Programming element wluch have the following structure : languages for distributed 
computing systems. ACM type Dummy is computing aurveye, 21(3):260-322$ septembe 1989. record Fkldl, 
Fleld2: Integer3~ -Here, the structure owner [3] CIFO working group. Asynchronous co-operation mech-Next 
: Shared~ddresq anisms (with reference memory model). Catalog of In. end record; terface Featurea and 
Options for Ada run time environ. An element has a twelve octets sise. The first two fields ment, july 
1991. Realease 3.0. are set to the node value and the last one refers to the next [4] R. Dewar, S. Flynn, 
E. Schonberg, and N. Schuhnan. element. Therefore, we may notice that Node 1 has a linked Dutributed 
Ada of shared memory multiprocessors. In list of two elements which are respectively stored at address 
Proceeding of the Didributed Ada aympoaium, pages16#0004# and 16#OOlC#. 228-241, Southampton, UK, December 
1989. British Computer Society and Ada UK. [5] R.B.K. Dewar. Shared variables and Ada 9X issues. Special 
report SEI-90-SR, january 1990. [6] E.W. D~katra. Self-stabiising systems in spite of dis­tributed controL 
Communication of ACM, 17(11):643­644, November 1974. [7] ExTRA working group. Proposed draft standard 
for real-time Ada extensions, december 1991. specific In­put/Output chapter, release 1.0, veraion 1.0. 
m Nodcl m Nodc2 m N06c3 [8] S. Flynn Hummel. SMARTS: shared-memory multipro­cemor Ada run time supervisor. 
PhD thesis, ComputerFigure 6: Distributed shared heap Science Department$ New York University, 1990. 
[9] Y. Kermarrec and L. Pautet. Ada communication com­ponents for distributed and rerd time applications. 
In CONCLUSIONS Proceedings of the TRI ADA 92 conference, Orlando, Florida, November 1992. ACM ZigAda. 
 In this paper, we have presented our implementation of a dis­tributed shared virtual memory for Ada 
applications. Such [10] Y. Kermarrec and L. Pautet. Ada reusable software a software component eases 
software developments as the components for education in distributed systems and shared memory paradigm 
is made available on a distributed In of 7th confer­ applications. Pmceeding8 the SEI architecture. Nevertheless, 
this model has to be considered ence on Software Engineem ng Educatiotq San Antonio, as a complement 
to message-based communication. soft- Texas, January 1994. ACM IEEE SEI CMU, LNCS ware designers can 
choose the best suitable communication Springer Verlag (to be published). model for their applications. 
[11] K. L1 and P. Hudak. Memory coherence in shared vir­ tual memory systems. ACM tmnaactions on computerThis 
software component is also part of a more general systems, 7(4):321-359, november 1989. toolset which 
is being designed by our research team. This toolset addresses features like distributed communication 
[12] B. Nitsberg and V. Lo. Dmtributed shared memory: a and diitributcd control. This toolset is also 
being designed survey of issues and algorithms. Computer, pages 52­so that students can make experiments 
in dwtributed system 60, august 1991. programming [10]. [13] W. Richard Stevens. Uniz network progmmming. 
Pren­ tice Hall Software series, 1990. With an Ada software component which implements a dis­ [14] M. 
Stumm and S. Zhou. Algorithms implementing dis­tributed shared virtual memory, we have started new re­tributed 
shared memory. IEEE Computer, pages 54-63,search activities : May 1990. Investigating the design of 
a distributed kernel for Ada [15] S. Zhou, M. Stumm, K. Li, and D. Wortman. Het­ applications. This 
should present no dMiculties thanks to our software components. We could also extend thii erogeneous 
distributed shared memory. IEEE 2hansac­tiotu on parallel and distributed u@ems, 3(5):540-554, research 
by taking into account fisult tolerance. september 1992.</RefA> Implementing an associative memory to offer 
a Lmda- Iike approach for communication. Thu is to offer the programmer another communication mechanism. 
 Yvon Kermarrec got a PhD degree in computer sci­ence from IRISA at Rennes University in 1988. The ti-Developing 
our toolset of software components for d~ tle of Km dissertation is An approach for d~tributed sys­ tributed 
applications. The idea is to build a dw tem simulation : software components in Ada . He joined tributed 
application tiom basic components. the Ada-Ed group at New York University as a visMng re-Implementing 
a RPC (remote procedure call) mech­ searcher. He worked with Ed Schonberg and Robert Dewar anism and 
thus investigating communication between on the NYU Ada Compiler. In 1990, he joined the faculty Ada 
9X d~tributed applications. at Ecole Nationale Sup6rieure des T614communications in 250  Paris as assistant 
professor. He has just arrived at Ecole Na­tionale Sup6rieure des T614communications in Brest, France. 
He teaches Ada, software engineering and dwtributed algo­rithms. His research interests are : distributed 
systems, Ada and programming languages. Laurent Pautet received the Dlp16me d Ing6nieur from the Ecole 
Nationale Sup6rieure des T616communications (ENST), Paris, Prance in 1989. He is currently pursuing a 
PhD degree in computer science at the ENST in Paris. He joined Daasault Electronique, Paris, France as 
a research en­gineer in Dec. 1990. His research interests include Ada run­time systems, dwtributed and 
parallel systems and hard real­time systems. His PhD degree deals with Ada distributed real time kernels. 
 
			
