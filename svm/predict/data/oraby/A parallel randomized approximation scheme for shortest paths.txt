
 A parallel randomized approximation scheme for shortest paths Philip N. Klein* Brown University Abstract 
We give a randomized parallel algorithm for approx­imate shortest path computation in an undirected weight 
ed graph. The algorithm is based on a tech­nique used by Unman and Yannakakis in a parallel algorithm 
for breadth-first search. It has application, e.g., in approximate solution of multi commodit y flow 
 problems with unit capacities. We also show how to adapt the algorithm to perform better for planar 
graphs. 1 Introduction One of the most fundamental and ubiquitous prob­lems in combinatorial optimization 
is finding shortest paths rooted at one node in a weighted graph. Aside from being important in its own 
right, the problem arises in algorithms for many other problems, espe­cially those related to flow. In 
view of the importance of the single-source shortest paths problem, it is unfortunate that all known 
parallel algorithms for this problem are hope­lessly inefficient on sparse graphs. Indeed, the only approach 
known that achieves significant parallel speed-up involves solving all-pairs shortest paths. When the 
number of processors available is linear in the size of the input graph, this rather brute-force ap­proach 
yields essentially no speed-up over sequential computation of the shortest path. *Research supported 
by NSF grant CCR-901 2357 and an NSF PYI award, together with PYI matching funds from Thinking Machines 
Corporation and Xerox Corporation. Ad­ditional support provided by ONR and DARPA contract NOO014-83-K-0146 
and ARPA Order No. 6320, Amendment 1. t support was provided in part by an National Science Foun­dation 
Presidential Young Investigator Award CCR 9047466 with matching funds from IBM, by NSF research grant 
CCR 9007851, by Army Research Office grant DAAL03 91 G O035, and by the Office of Naval Research and 
the Defense Advanced Research Projects Agency under contract NOO014 83 K 0146 and ARPA order 6320, Amendment 
1. Permission to copy without fee all or part of this material is granted provided that the copies are 
not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the 
publication and its date appear, and notice ia given that copying is by permiaaion of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee andlor specific permission. 
24th ANNUAL ACM STOC -51921VICTORIA, B. C., CANADA 01992 ACM 0-88791-51 2-71921000410750 . ..S1 .50 S. 
Sairamt Brown University This inability to make efficient use of parallelism in computing shortest paths 
is of both theoretical and practical significance. A fast and efficient parallel algorithm for this problem 
remains a major goal for many researchers in parallel graph algorithms. In this paper, we describe a 
parallel approxima­tion algorithm for computing single-source shortest paths. The algorithm achieves 
significant speed-up even when only a linear number of processors are available, when the degree of accuracy 
required is moderate. In the bounds below, we assume the concurrent-write P-RAM as our model of parallel 
computation. Moreover, we assume c is no more than a constant. Theorem 1.1 There is a randomized parallel 
algo­rithm that uses (e log n)/e-2 processors and time O(@-2 log n log* n) on an undirected graph with 
e edges and n nodes, to approximate shortest path dis­tances to within a factor of 1+ c. The algorithm 
is based on a parallel breadth-first search algorithm due to Unman and Yannakakis [23]. They show that 
a breadth-first search tree can be constructed in ~(fi) time using a linear number of processors. Their 
algorithm is limited, however, in that it can­not handle weights on nodes or edges. Thus our con­tribution 
is to extend their algorithm so that it can do so, although at a slight loss in speed and accu­racy. 
The key technique is the randomized rounding technique of Raghavan and Thompson [18]. For graphs with 
small separators planar graphs, for example the basic bound of Theorem 1.1 can be improved. For graphs 
with O(@)-size separators, if the separators can be found quickly and efficiently in parallel, the time 
bound of Theorem 1.1 can be reduced from roughly nl/2 to roughly nli3. Theorem 1.2 For undirected planar 
graphs, there is a randomized parallel shortest-path approximation al­gorithm that uses (n log n)/c-2 
processors and time 0(nl/36-2 log n log* n). Like that of Unman and Yannakakis, our algorithm can be 
modified to find A single-source single-sink approximate shortest paths within the same resource bounds, 
Theorem 1.3 There is a randomized parallel algo­rithm that uses (e log n)/c-2 processors and time O(@-2 
log n log* n) on an undirected graph with e edges and n nodes, to find @ single-source single­sink approximate 
shortest paths. The paths are within a 1 + c factor of being shortest. In fact, within the available 
resources one can af­ford to find minimum path-sizes for e log2 n different source-sink pairs, as long 
as the number of distinct sources is O(W). We show in the next subsection how the algorithm of Theorem 
1.3 could be especially useful in speeding up concurrent flow computation using parallel processing. 
Unman and Yannakakis show that their approach can be used to obtain even faster parallel algorithms, 
albeit at a cost: the total work done is greater. The same is true for the shortest path approximation 
al­ gorithm. Theorem 1.4 There is a randomized parallel shortest-path approximation algorithm that uses 
(enl 26 log n)/c-2 processors and ttme 0(n6c-2 log n log n), provided e ~ n2-3 . 1.1 Application to concurrent 
flow computation One application for which our algorithm is particu­larly well-suited is in approximating 
concurrent flow with uniform capacities. Concurrent flow [21] is an optimization version of multicommodity 
flow. A spe­cial case of concurrent flow, in which all capacities are the same, is the computational 
bottleneck in im­plementing two important approximation algorithms, one by Leighton and Rao [13] for 
finding sparsest cuts in a graph, and one by Raghavan and Thompson [18] for finding a VLSI routing that 
minimizes channel width. Klein, Plotkin, Stein, and Tardos [12] have given a fast approximation algorithm 
for concurrent flow with uniform capacities. The algorithm consists of a sequence of iterations, each 
essentially a shortest path computation. Consider implementing this al­gorithm on a parallel machine. 
A straightforward implement ation of Dijkstra s shortest paths in paral­lel would require O(n log n) 
time using e/n log n pro­cessors. Thus using this implementation, one could achieve a speed-up of about 
O(e/n) over the sequen­tial algorithm. For sparse graphs, then, the speed-up is small. Using the algorithm 
of Theorem 1.1, on the other hand, one can compute shortest paths in 0(&#38;-2 log n log* n) time using 
e log n/6-2 proces­sors. Thus one can achieve a speed-up of Q(e/fi) in solving concurrent flow to within 
a constant fac­tor, and consequently in implementing the aforemen­tioned approximation algorithms. This 
speed-up is Q(w) even in the case of sparse graphs. Admittedly, the time-processor product to achieve 
this speed-up is larger by a factor of about &#38;. How can we make better use of processors? We use 
the fact (Theorem 1.3) that the shortest path algorithm can actually find O(W) single-source single-sink 
shortest paths within the same bounds. The randomized algorithm of [12] involves a se­quence of iterations. 
In each iteration, a commodity is randomly selected and the shortest path is found from the commodity 
s source to its sink. If the short­est path is sufficiently short, flow is rerouted. Other­wise, nothing 
is done. Recent experiments [11] with a version of the al­gorithm indicate that the path is sufficiently 
short only about 8% of the time (on average). Thus most of the algorithm s time is spent computing shortest 
paths that are not sufficiently short. By using the algorithm of Theorem 1.3, one can try O(@) paths 
at a time, and have a much greater chance of find­ing a sufficiently short path in each iteration. The 
resulting speed-up should in turn be much greater. Plotkin, Shmoys, and Tardos have developed a very 
general framework for approximation algorithms, one that encompasses the concurrent flow approxima­tion 
algorithm and much else. One of the conse­quences of their work is an approximation algorithm for rein-cost 
multicommodity flow. The algorithm finds a nearly feasible multicommodity flow whose cost is nearly minimum. 
For constant E, the ran­domized algorithm they give runs in expected time O(ke log rn(e + n log n) log 
k), where k is the num­ber of commodities. The algorithm consist of a se­quence of calls t o a shortest-path 
subroutine. It turns out that an approximate-shortest path subroutine is sufficient for their algorithm. 
Using our shortest­path approximation algorithm, therefore, one ob­tains a parallel approximation algorithm 
for min­cost multicommodit y flow that runs in expected time 0(lcen112 log3 n log* n) using e log n processors. 
  2 Background and overview A word about terminology in order to forestall confu­sion. Unless otherwise 
stated, when we speak of the length of a path, we mean the sum of the weights of its edges (rather than 
the number of its edges). Simi­ larly, distance is measured according to edge-weights. The size of a 
path, on the other hand, shall signify the number of nodes in the path, and the minimum path-size is 
the shortest distance measured in number of nodes traversed. Unless otherwise stated, n and e denote, 
respec­tively the number of nodes and the number of edges in the input graph. 2.1 Parallel breadth-first 
search The fastest known parallel algorithm for breadth-first search involves repeatedly squaring a matrix, 
where the elementwise operations are in the rein-plus semir­ing, In fact, this algorithm can compute 
shortest paths. The technique is well-known; see [1, 2] for more details. The problem with this algorithm 
is that it requires a great many processors; to achieve O(log n) time requires about n3 processors. The 
pro­cessor bound has been improved somewhat [5] in the case of breadth-first search. The most elementary 
parallel search technique is parallel breadth-first search, in which the nodes are visited level by level 
as the search progresses. Level O consists of the starting node s, level 1 consists of the neighbors 
ofs, level 2 consists of the neighbors of the neighbors ofs (or, rather, those not belonging to previous 
levels), and so forth. Togo from, say, level i to level i+ 1, the processors divide up the edges with 
endpoints among the level i nodes; for each such edge, if the other endpoint has not yet been traversed, 
it is assigned to level i + 1. Suppose e~ is the number of such edges; then this computation takes time 
O(ei/p + log* n) using p pro­cessors. (The log* p term accounts for the time for load-balancing, using 
the technique of [8].) Hence the time required to traverse k levels is O(e/p+ k log* n). The problem 
with this approach is that the time required grows linearly with the number of levels tra­versed. To 
keep the time small, we must resort to limited search, in which we limit the number of lev­els traversed. 
We will use the adjective k-limited to signify that only paths consisting of ~ k nodes are under consideration. 
Thus a k-limited shortest path from s to t is a path that is no longer than any path containing < k nodes. 
(We mean to allow the k-limited shortest path to consist of more than k nodes.) Thus, for example, in 
an n-node graph, an n-limited shortest path is in fact a true shortest path, because every path contains 
~ n nodes, whereaa an n/2-limited shortest path may not be a true shortest path.  2.2 Unman and Yannakakis 
s algo­rit hm The basic version of Unman and Yannakakis s par­allel algorithm for breadth-first search 
is based on @-limited search. We review a simplified version. We are given a graph and a source s from 
which to find a breadth-first search tree. First, O(filog n) randomly chosen nodes, along with the source, 
are designated as distinguished. From each of the dis­tinguished nodes x in parallel, p processors conduct 
a /E-limited search, identifying the minimum path­size from x to each node within path-size +. By choosing 
p = e/&#38;, we can carry out all of these searches in O(@) time using p~ log n = e log n pro­cessors, 
Second, an auxiliary graph is formed on the set of distinguished nodes, where the length of an edge from 
u to v is defined to be the mininum path-size from u to v found during the limited search. All-pairs 
shortest paths are computed for the auxiliary graph. This takes total work 0((@)3 log n), and can easily 
be done in O(@) time using e log n processors. In particular, we have the length of the shortest path 
in the auxiliary graph from the source s to each of the distinguished nodes. Third, the minimum path-size 
from the source s to a node v is computed by taking the minimum, over all distinguished nodes x, of the 
auxiliary-graph shortest path length from s to z plus the minimum path-size from z to v found in Z S 
limited search. One can show that, with high probability y, this method yields the minimum path-size 
for all the nodes v. The proof is essentially as follows. Fix in advance one minimum-size path Pv froms 
to v, for every node v. Now consider the randomly selected distinguished nodes. With high probability, 
each subpath of P. of size fi cent ains a distinguished node. Thus the path P. is broken up into subpaths 
starting and ending with distinguished nodes (except for the last subpath, which ends on v), such that 
each subpath has size at most X. These subpaths are traversed in the limited search. Hence the minimum 
path-size from s to the last distinguished node of Pv is correctly computed in the all-pairs computation, 
and the minimum path­size from s to v is correctly computed in the last step of the algorithm.  Given 
A source-sink pairs, one can use essentially the same algorithm to find corresponding minimum path-sizes. 
Let the set of distinguished nodes include the W sources in addition to the randomly selected nodes. 
The first and second steps are otherwise the same. In the third step, for each of the given source­sink 
pairs (s, t) in parallel, one computes the mini­mum path-size froms to t, as follows. The path-size is 
the minimum, over all distinguished nodes x, of the auxiliary-graph shortest path length from s to z 
plus the minimum-path size from x to tfound in x s limited search. Computing that minimum for a sin­gle 
source-sink pair takes O(@) work, so the total work for the third step is only O(n). Indeed, within the 
available resources one can afford to find mini­mum path-sizes for e log n different source-sink pairs, 
as long as the number of distinct sources is O(W). Unman and Yannakakis s approach does not di­rectly 
work with weighted graphs because there is no apparent way to find even the /ii-limited shortest paths 
within the available resource bounds. Our con­tribution is a method that approximates these short­est 
paths. We provide a procedure that will find @limited approximate e shortest paths in O(@-2 log n) time 
using e/(@-2, processors. The estimated lengths are within a factor of 1 + c of correct. Note that this 
procedure is sufficient to make Unm­an and Yannakakis s procedure work for weighted graphs; the second 
and third steps don t depend on the weights being one. The resulting algorithm, though slower by a factor 
of O(c-2 log n), performs only a factor of O(log n) more work. 2.3 Weighted parallel breadth-first search 
 There is an obvious approach to extending paral­lel breadth-first search to handle positive integral 
weights. Weight ed parallel breadth-first search is just like ordinary parallel breadth-first search, 
except that for each active edge, if the edge s weight is one, its head is assigned to the next level, 
and if the edge s weight is more than one, its weight is decreased by one. Thus level i consists of those 
nodes at distance i from the source. Assuming the graph is undirected, we can also allow zero weights; 
in a preprocessing step, the processors contract all zero-weight edges. This step does not change shortest-path 
lengths. Weighted parallel breadth-first search has the same disadvantage as ordinary parallel breadth-first 
search, only more so. The time required grows linearly with the distance traversed. This is especially 
a problem when the weights are large. To alleviate this dis­advantage, the obvious fix is to uniformly 
shrink all weights. This in itself is not enough; the search cru­cially depends on the weights being 
integral. Thus the subtlety is in rounding the shrunken weights to integers without substantially changing 
the length of the shortest path.  2.4 Our randomized approach to ap­proximating shortest paths There 
is a well-established technique for rounding weights without changing sums of weights too much; the randomized 
rounding technique of Raghavan and Thompson, originally proposed for VLSI routing. The idea is that a 
nonintegral value is rounded up or down, with the decision being made randomly; the relative probabilities 
reflect how close the value is to the next higher and next lower integer. This is the technique w; use 
in our weighted lim-ited search pro­cedure. In Sections 3 and 4, we outline a procedure, FULLSEARCH(G, 
s, k, p, E) for finding approximate k­limited shortest paths from source s in the graph G. Here e is 
a positive number strictly less than one, and the estimated path lengths are no more than 1 + c times 
the actual length and no less than 1 E times the actual length. In this case, we say the estimates are 
accurate to within a relative error of ~, or, more briefly, to within c. The procedure uses p processors 
and takes time O((IE(G)I + k6-2) logn) P When we call this procedure with k = @ and p = lE(G)[/@-2, 
it takes time O(#Ec-2 log n). By using the procedure in Unman and Yannakakis s al­gorithm, we prove Theorems 
1.1 and 1.3.  3 The procedure SEARCH In this sec­tion, we give a procedure SEARCH(G, s, d, k, p, c) 
to perform a k-limited search in a graph G starting at source node s, using p processors. It determines 
the k-limited approximate shortest path distances from s of those nodes whose distance is at least d 
and at most 2d. We show that estimated path length will with high probability be accurate to within a 
relative error of c. By calling SEARCH(G, s, d, k, p, c) in parallel with d= 1,2,4,..., one can find 
the k-limited approxi­mate shortest path dist antes of all nodes. We show in the next section how to 
accomplish this with only an O(log n) factor increase in the number of proces­sors. Using p processors, 
the procedure SEARCH(G, s, d, k, p, e) takes time (1) where IE(G) I is the number of edges and n is 
the number of nodes. The first step of the procedure is to define the scale factor ~ by ?r= @(k log n/#d) 
(2) Assign randomly rounded scaled edge-lengths ~(e) = round(~l(e)) where round(z) is a procedure that 
randomly rounds z to a nearby integer, according to the following rule: [xl with probability z lzJ ound(z) 
= [cJ otherwise { Contract every edge whose assigned length ~(e) is zero. Since the graph is undirected, 
this does not affect shortest path lengths. (This is essentially the only place where we use the fact 
that the graph is undirected. We also use it in the procedure FULLSEARCH, when we contract edges whose 
lengths are small.) Then compute shortest paths subject to the new lengths ~. Note that ~ is integral, 
so we can use weighted par­allel breadth-first search. Moreover, since we are only interested in path 
lengths that are at most 2dJ and under scaling such lengths become O(rd) with high probability, the number 
of stages of search needed is only O(zd), which is O(k log nc-2) by choice of ~. Hence the time required 
is as claimed in (l). The estimated distances can be obtained by unsealing the scaled distances, namely 
by dividing distances by T. Theorem 3.1 With high probability, estimated path length is accurate to within 
a relative error of e. Proofi We want to show that TI(P) = &#38;P rl(uv) is well-estimated, for each 
path P under considera­tion. Write eEP eEP and let b denote the first sum on the right-hand side. We 
use versions of Chernoff s bound due to Ragha­van [19]: if 1! is the sum of independent Bernoulli tri­als, 
and p is the expected value of ~, then for 6 less than twice the base of the natural log, minus one, 
Pr[!l < (1 d)p] < exp( ti2p/2) (3) and Pr[IU > (1+ c$)p] > exp( 62p/4) (4) For each edge e, let Ze = 
round(~t(v)) Lm.t(v)j. Let V = ~eEP z.. Then the expected value of V is b. Moreover, the estimated path 
length is ?(P) = 7rl(P) + Y! b 754 The estimated path length differs by too much if and only if [1(P) 
-7rqP)l > Url(P) which holds if and only if We use the Chernoff bounds to show that this event is unlikely. 
Pr[lV bl > eml(P)] s 2 exp( (arl(P)/b) 2b/4) = exp( fl(k logn ~)) < exp( $l(k log n)) Thus the probability 
that path P s estimated length differs by an error exceeding c is at most exp( fl(k log n)), which is 
at most I/nzk for an ap­propriate choice of ~. We must ensure that none of the paths with at most k nodes 
have inaccurately es­timated lengths. There are at most nk such paths. The probability that any one has 
an inaccurate es­timated length is at most the sum of the individual probabilities l/n2k, which is at 
most l/n~. Thus with probability at least 1 l/nk, the lengths of all such paths are sufficiently accurate. 
0 4 The procedure FULLSEARCH The procedure SEARCH (G, s, d, k, p, c) only accu­rately estimates the 
k-limited distances of nodes when those distances are between d and 2d. To esti­mate the distances of 
all nodes, we must call SEARCH in parallel with different values of d. We next show how to do this while 
only paying an O(log n) factor in the number of processors. The key is to use the fact that we re only 
trying for an estimate of the shortest path lengths to discard some edges for some computations. Namely, 
if a path cent ains an edge of weight w, then in computing its length, we can essentially treat as zero 
all weights less than, say, cw/2n, because the sum of all such weights in the path can be no more than 
an c/2 fraction of the total weight in the path. We use this idea in a procedure FULLSEARCH(G, s, k, 
p, c), which calls SEARCH many times in parallel. The procedure FULLSEARCH first scans all the edges, 
and places them in categories according to their weights. For a weight w, let R(w) denote the range (cw/4n, 
w]. Let wmin be the smallest nonzero weight. The category E. consists of those edges with weights in 
the range R(2°wmin ), the category El consists of those edges with weights in the range R(21~min), and 
so on. Note that each edge lies in only logz 2nc-I different categories. We assume c-1 is no more than 
n114 log n (else shortest paths are exactly computable by a sequential algorithm in the time alloted), 
so each edge lies in at most clog n cat­egories, where c is a small constant. Second, FULL SEARCH assigns 
processors to the categories in proportion to the number of edges in each. For each i for which Ei is 
nonempty, let lEi[ (1/clogn) = IE(G)I be the number of processors assigned to the category R(2 ~min). 
Because each edge is in at most clog n categories, the total number of processors assigned is at most 
the number p available. Third, FULLSEARCH creates a graph for each cat­egory, containing the edges in 
that category. Con­struct the graph Gi from G by contracting all edges with weight at most (~/4n)2i~min 
and removing all edges with weight greater than 2i~min. If the graph is disconnected, only the component 
that contains the source s is constructed. We describe the contraction process in greater detail later. 
Finally, FULLSEARCH calls SEARCH(Gi, s, di, k, pi, c/2) for each i for which Ei is nonempty, where di 
= ~ (2i ~min ). These searches take place in parallel; the time for each is ~([Ei[ + kc-2 log n log*) 
Pi which, by choice of pi, is ~~ IE(G)I10gn+ k~-2 logn ]og*) P Call number i estimates the distances 
in the graph Gi that are between di and 2di to within error t/2. The low-weight edges omitted from Gi 
could have added at most distance n(~/4n)2di = (~/2)di, so the relevant distances in Gi are accurate 
to within error c/2, compared to the distances in the original graph G. Hence the estimated distances 
are accurate to within a relative error of ~, compared to the original graph distances. 4.1 The contraction 
process Constructing the graphs Gi from G is not entirely trivial. The difficult step is carrying out 
the contrac­tions. Contracting a set of edges in a single graph consists principally of a connected-components 
tal­culation on the edges to be contracted, which can be done quickly and efficiently using, e.g., the 
algorithm of Shiloach and Vishkin [22]. However, we need to form many different graphs by contracting 
different sets of edges. Let Ai consist of the edges that must be contracted in Gi but not in Gi 1 (namely, 
the edges with weights in the range (e2i -l~~i./4n, ~2i~~i./4n].) Then the Ai s are disjoint, and the 
set of edges to be contracted in Gi is Alu A2u... uA~ (5) We need to compute the connected components 
of (5) for every i. We use parallel prefix computation. Suppose Ai,, Aiz,... jAi, are the nonempty sets, 
in increasing order of sub­script. Using a parallel prefix computation, one can compute the connected 
components of Ail, . . . . Ai j for every j ~ s. The number of stages is O(logs), which is logarithmic 
in the number of edges. Each stage consists of some connected components calcu­lations on disjoint sets 
of edges. Thus the entire com­putation can be done in parallel in O(IE(G)] log2 n/p) time using p processors, 
as long as p < IE(G)I.  5 Faster (but less processor­efficient ) algorithms Unman and Yannakakis point 
out that for a con­stant 6> 0, one can finds a breadth-first search tree in 0(n6) time using O(en 1-2$) 
processors, provided e > n2-36. Their algorithm can be adapted to use our limited search procedure FULL 
SEARCH. We omit details in this extended abstract. 6 Applications to Planar Graphs The Unman Yanakakis 
algorithm gives us a way of doing breadth first search in an n-node planar graph G in about &#38; time 
using n processors; however, their algorithm relies only on the fact that planar graphs are sparse and 
takes no advantage of the pla­narity of G. In this section we present a three phase approach which takes 
advantage of the fact that pla­nar graphs have O(@) separators. Our algorithm is based on an idea by 
Fredrickson [3] and uses n log n/c-2 processors and time 0(n113c-2 log n) to compute approximate single-source 
shortest paths in G. We use the approximate shortest path algorithm of Theorem 1.1 as a subroutine. Our 
algorithms can be extended to other classes of graphs which have small separators that can be computed 
quickly in par­ allel. Theobvious separator-based approach is to divide G into two roughly equal pieces 
G1 and Gz, using an O(X) separator; recursively solve the problem in each piece using the separator nodes 
aa sources and sinks and combine the two solutions to solve the problem for G. It is easy to see that 
a any naive method of combining the solutions of the two sub­problems would lead to 0(n15) total work, 
thus de­feating our purpose. Unfortunately there seems to be no way to take advantage of the planarity 
of G to combine the subproblems in a more efficient man­ner. Instead we present a three phase approach; 
In the first phase we recursively divide the graph into t3(n113) pieces each of size 0(n213), such that 
none of the pieces cent ains more than 0(nli3) boundary nodes (where a boundary node refers to s or a 
node which is in a separator at some point in the recur­sive subdivision); we then solve the all-pairs 
shortest path problem between boundary nodes in each piece. In the second phase we create a skeletal 
graph S, which is composed of the boundary nodes from each piece and edges among them denoting the shortest 
path distance in each of the @(nlJ3) pieces. We then use our algorithm of Theorem 1.1 to get the shortest 
paths from the source s to all the nodes in S. In the final phase we calculate the shortest paths from 
s to the remaining nodes in each piece. 6.1 Preliminaries Definition 6.1 Given a graph G = (V, E) with 
n nodes we call a set X C V an f(n) separator that ti­splits G if 1X1 < f(n) and the nodes in V X can 
be partitioned into sets {Al ,.. .Ak} such that there are no edges between any two sets Ai and Aj and 
for all Ai we have [Ail < c%. Lipton and Tarjan [14] proved that any planar graph with n nodes has a 
&#38; separator that 2/3­splits. This result and other extensions to it have paved the way to divide 
and conquer solutions for many problems in planar graphs. A parallel algo­rithm for finding a cycle separator 
for biconnected graphs was given by Miller [15] which uses n proces­sors if the breadth-first search 
tree of the graph is al­ready known. Gazit and Miller [4] later gave an algo­rithm which does not require 
a precomputed breadth­first search tree. Their algorithm uses nl+ proces­sors to find an O(fi) cycle 
separator. Randomized parallel algorithms to find small separators for more general undirected graphs 
are given in [17]. Recently Shannon and Wan [20] have given the first linear pro­cessor deterministic 
algorithm to find O(@) separa­tors in planar graphs. 6.2 Shortest Paths in Planar Undi­rected Graphs 
Let G = (V, E) be a planar undirected graph with weights on its edges. To compute the single-source shortest 
paths from a source s, we first divide G using one of the parallel separator algorithms into pieces such 
that none of the pieces have too many boundary nodes. To ascertain that we use the following lemma from 
[3]. Lemma 6.1 For any r c N, an n-node planar graph can be divided into ~(n/r) regions with no more 
than r nodes each, and O(n/fi) boundary nodes in to­tal, such that none of the regions contain more than 
O(V) boundary nodes. The strategy for planar graphs is now clear; Given an undirected planar graph G 
= (V, E), to get the single-source shortest paths from a given source node s we proceed aa follows: 1.Divide 
G into ~(nli3) regions RI, Rz, . . . Rk, such that each region has O(n213) nodes and O(nlf3) boundary 
nodes. This can be done in parallel in O(nli3) time with n processors by us­ing the separator algorithm 
by Gazit and Miller [4]. 2. Let Gi be the graph induced by the nodes in the region Ri. For each Gi in 
parallel, use the short­est path algorithm to compute for every pair of boundary nodes, an e approximation 
of the shortest path distance among paths that lie en­tirely within Gi. 3. Create a new skeletal graph 
S which consists of boundary nodes from each Gi, and edges uv such that both u and v are in some piece 
Gi; l(uv) is then equal to the shortest distance between u and vin Gi. 4. Use the shortest path algorithm 
on S to compute c-approximate single-source shortest paths from s to all the other nodes in S. 5. For 
each region Ri create a new graph Hi, that consists of the graph G; with a new node s;, and edges from 
Si to every boundary node of Ri; i(sib) for these new edges is equal to the shortest distance from s 
to the boundary node b in the skeletal graph S.  6. For each lf~ in parallel, use the shortest path 
algorithm to compute c-approximate shortest paths from si to all the other nodes in Ili We now claim 
that we have approximate single-source shortest paths froms. Theorem 6.1 The algorithm given shove approxi­mates 
the single-source shortest paths from s to every other node of G. Moreover, it performs the compu­tation 
in time 0(n1j3c-2 logn) and uses n log n/e-2 processors. Proof Sketch To prove that the algorithm is 
correct we note that the shortest path from s to any other node tcan be broken into a number of subpaths, 
each of which is contained in one of the regions. At the end of first phase every subpath that is between 
two boundary nodes is replaced by an edge of appropri­ate length between the corresponding nodes in S. 
At the end of second phase we therefore know the ap­proximate shortest paths from s to all the boundary 
nodes in G. The shortest path from s to a node t which is in the interior of one of the regions is a 
com­bination of two subpaths, one from s to a boundary node b of Ri, and the other from b to t which 
lies completely within Ri. It is clear that all such paths are computed approximately in the final phase, 
by performing a shortest path computation on Hi. To prove that the algorithm works within the stated 
processor and time bounds we note that since each of the @(nl/3) pieces has only O(n2J3) nodes; we can 
solve all the @(n113) subproblems simultaneously in time O(n1j3 log n) by allocating n2i3 processors 
to each Gi. Since each Gi has only O(n113) boundary nodes it contributes only O(n2i3) edges to the skele­tal 
graph S, and thus S has only O(n) edges and O(n213) nodes. We can therefore do the approximate single-source 
shortest path computation on S in time O(nl/3 log n) using n processors. The final phase is similar to 
the first one; we therefore get our stated processor and time bounds. 0  6.3 Comments Recently Miller 
Teng and Vavasis [17] have proposed a class of graphs called k-overlap graphs. Special classes of k-overlap 
graphs include planar graphs, k­nearest neighbor graphs, and many other graphs as­sociated with finite 
element methods. They prove a a separator bound of O(nfd-l)id) for k-overlap graphs embedded in d dimensions. 
Miller [16] has shown that given weights on the nodes of a k-overlap graph G, an O(n(d I)ld) separator 
that splits G into roughly equal weight pieces can be found in polylog time us­ing n processors. Essentially 
overlap graphs on a set of points cl, ..., Cn in dimension d are generated by considering d-dimensional 
balls Bi of radius ri cen­tered at ci. There is an edge between the nodes ci and cj if their corresponding 
neighborhoods Bi and Bj intersect. The class of k-overlap graphs are over­lap graphs with the added restriction 
that any neigh­borhood Bi contains at most k points. Our approach can be extended to the class of k-overlap 
graphs to get efficient parallel approximation algorithms for single­source shortest path computations. 
In particular for the case d = 2 we get the following theorem Theorem 6.2 There is a randomized parallel 
al­gorithm that uses e log n/c-2 processors and time O(@-2 log n) on a k-overl~p graph for dimension 
2 with h nodes and e edges, to approximate the single­sourca shortest path distances to within a factor 
of 1+6.  7 Conclusion Unfortunately, except for planar graphs, our algo­rithm seems only to work for 
undirected graphs, since otherwise it is not clear how to get rid of zero-weight edges. It is an open 
question whether there exists an algorithm with similar performance for shortest paths in undirected 
graphs. In this paper, we have given one answer to one of the open problems posed by Unman and Yannakakis: 
Does any of this material generalize to the general shortest-path problem, where arcs initially have 
ar­bitrary weight? A more satisfactory answer would be an exact algorithm with comparable performance. 
An even more ambitious goal, articulated by Unman and Yannakakis, is a fast algorithm that worked for 
an arbitrary closed semiring (see [1]). That remains the most tantalizing open problem. Acknowledgements 
Thanks to David Shmoys, Matt Pappas, and Serge Plotkin. References <RefA>[1]A. Aho, J. E. Hopcroft, and J. 
D. Unman, The Design and Analysis of Computer Algorithms, Addison-Wesley, Reading, Mass. (1974). [2] 
D. Eppstein and Z. Galil, Parallel algorith­mic techniques for Combinatorial Computa­tion, preprint, 
Columbia University (1988). [3] G. N. Fredrickson, Shortest path problems in [13] planar graphs, Proceedings, 
2dth Symposium on Foundations of Computer Science (1983). [4] H. Gazit and G. L. Miller, A Parallel Algo­rithm 
for finding a Separator in Planar Graphs,) Proceedings, 28th Symposium on Foundations of [14]Computer 
Science(1987) pp. 238-248 [5] H. Gazit and G. L. Miller, An improved parallel algorithm that computes 
the BFS numbering of a directed graph, Information Processing Iet­ [15] ters 28 (1988), pp. 61-65. [6] 
H. Gazit and G. Miller, A parallel algorithm for finding a separator in planar graphs, Proceed­ings, 
28th Symposium on Foundations of Com­ [16] \puter Science (1987) pp. 238-248. [17] [7] H. Gazit and 
G.L. Miller A Deterministic Par­allel Algorithm for Finding a Separator in Planar Graphs, manuscript. 
 TO-[18] [8] Joseph Gil, Yossi Matias, and U. Vishkin, wards a theory of nearly constant time parallel 
algorithms, Proceedings, 32nd Symposium on on Foundations of Computer Science (1991), pp. 698-710. [19] 
 [9] M.-Y. Kao and P. Klein, Towards overcoming the transitive-closure bottleneck: efficient paral~ [20] 
lel algorithms for planar digraphs, Proceedings, .22nd ACM Symposium on Theory of Computing (1990), pp~181-192. 
[21] [10] P. Klein, A parallel randomized approximation scheme for shortest paths, Brown University 
Technical Report CS-91-56 (1991). [22] [11] P. Klein and S. Kang, Approximating concur­rent flow with 
uniform demands and capaci­ties: an implementation, submitted to First DI-MA CS Int&#38;national Algorithm 
Implementation [23] Challenge. [12] P. Klein, S, Plotkin, C. Stein, and E. Tardos, Faster approximation 
algorithms for the unit capacity concurrent flow problem with applica­tions to routing and finding sparse 
cuts, sub­mit ted to Journal of the ACM. An earlier ver­sion appeared aa Leighton-Rao might be practi­cal: 
fast er approximation algorithms for concur­rent flow with uniform capacities , Proceedings, 22nd ACM 
Symposium on Theory of Computing (1990), pp. 310-321. 758 F. T. Leighton and S. Rae, An approximate max-flow 
rein-cut theorem for uniform multi­commodity flow problems with application to approximation algorithms 
, Proceedings, 29th Symposium on Foundations of Computer Science (1988), pp. 422-431. R. Lipton and R. 
Tarjan. A separator theo­rem for planar graphs. SLIM Journal on AL gebraic and Discrete Methods, 36(2):177-189, 
April 1979, G. L. Miller, Finding Small Simple Cycle Sep­arators for 2-Connected Planar Graphs, Jour­nal 
of Computer and System Sciences (1986) pp. 265-279 G. L. Miller, personal communication (1991). G. L. 
Miller, S. Teng and S. A. Vavasis A Uni­fied Geometric Approah to Graph Separators, Proceedings, 3 2nd 
ACM Symposium on Theory of Computing, 1991 P. Raghavan and C.D. Thompson, Provably good routing in graphs: 
regular arrays , pro­ceedings, 17th ACM Symposium on Theory of Computing (1985), pp. 79-87. P. Raghavan, 
Lecture Notes on Randomized Al­gorith~s, preprint (1989). G.E. Shannon and F. Wan, Subdividing Planar 
Graphs in Parallel, Technical Report, Depart­ment of Computer Science Indiana University, Bloomington 
(1991) F. Shahrokhi and D. W. Matula. The maximum  concurrent flow problem, Journal of the ACM, 37 
(1990), pp. 318-334. Y. Shiloach and U. Vishkin. An O(log n) parallel connectivity algorithm. Journal 
of Algorithms, 3:57-67, 1982. J. D. Unman and M. Yannakakis, High-probability parallel transitive closure 
algorithms, SIAM J. Comput. 20 (1991 ),pp. 100-125. </RefA>
			
