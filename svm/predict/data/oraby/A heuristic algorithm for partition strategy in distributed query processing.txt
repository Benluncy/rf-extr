
 A Heuristic Algorithm for Partition Strategy in Distributed Query Processing * Chengwen Liu and Hao 
Chen School of Computer Science, Telecommunications and Information Systems DePaul University, Chicago, 
Illinois 60604 Key Words: distributed query processing, partition and replicate, multi-database. Abstract 
This paper describes an improvement on a Par-tition and Replicate Strategy (PRS) for distributed query 
processing in a multi-database environment in which relations are unfragmented and replicated. For a 
given set of relations to be partitioned, determining the optimal copies of the relations to be partitioned 
is NP-hard. A heuristic algorithm is proposed. Our ex-perimental results show that the heuristic algorithm 
is very effective and efficient. Introduction Relation partitioning has been used as a strategy for data 
allocation [5, 10~, or dynamic query process- ing [2, 6, 7, 12] to achieve a high degree of parallelism 
among processing units and to improve response time. In [2], one of the relations referenced by a query 
is par- titioned into equal-sized fragments, each fragment is sent to a computer processor, and all other 
relations are replicated in all computer processors. Since differ- ent computer processors may have different 
processing speeds and/or different access methods for accessing required data, equal-sized fragments 
may not balance the load of computer processors. This is considered in [12] to partition a relation into 
unequal-sized frag- ments for load balancing. However, since only one relation is partitioned, the gain 
due to this partition may not be significant when the number of relations referenced by a query is large. 
It is desirable to parti- tion more relations into fragments to improve response time. In this paper, 
we provide a sketch of a new par- tition strategy and an efficient and effective heuristic algorithm 
for choosing the copies of the relations to be partitioned. The rest of this paper is organized as follows. 
In section 2, we briefly describe the PRS strategy and an * Research supported in part by Trilogy Technologies, 
Inc.  "Permission to make digital/hard copy of all or part of this material without fee is granted provided 
that copies are not made or distributed for profit or commercial advantage, the ACM copyright/server 
notice, the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery, Inc.(ACM). To copy otherwise, to republish, to post on servers 
or to redistribute to lists, requires prior specific permission and/or a fee." &#38;#169; 1996 ACM 0-89791-820-7 
96 0002 3.50 approach to improve PRS. In section 3, we present a heuristic algorithm. In section 4, we 
provide per- formance evaluation of the heuristic algorithm. We conclude the paper in section 5. 2 PRS 
and Improvement The Partition and Replicate Strategy (PRS) algo- rithm proposed in [12} partitions one 
of the referenced relations into a number of fragments and distributes the fragments to a number of sites 
so that the query can be processed in parallel at these sites. We first use an example to illustrate 
how the PRS algorithm works and how a new partition strategy can improve response time. Example 1 Let 
a query reference two relations R1 and R2 which are unfragmented and distributed be-tween two sites 1 
and 2 as shown in Table 1. Assume that both sites have the same processing speed. Relation Total Tuples 
Site 1 Site 2 R1 12000 R1 R2 10000 R2 Table 1: Data Distribution for Example 1 If PRS algorithm is used, 
R1 will be partitioned into two equal-sized fragments Fll and F12. Fragment F12 is sent to site 2 and 
relation R2 is sent to site 1. Then two joins, Fn N R2 and Fn N R2, will be processed in parallel at 
the two different sites. The union of the results of the two joins forms the result of R1 ~ R2. If we 
further assume that the join attribute has in- teger domain and has uniform distribution, then we can 
partition R1 in such a way that Fll contains all the tuples whose join attribute values are odd numbers 
and F12 contains all the tuples whose join attributes are even numbers. Similarly, R2 can also be parti- 
tioned into two fragments, F21 and F22. Obviously, the following conditions hold: FllNF22= 0 F12 NF21----O 
Thus, R1 M R2 can be processed by sending F12 to site 2 and F21 to site 1, and then process two joins, 
Fn N F21 and F12 t~ F22, at the two sites in parallel. The final result of RI' 1>4 R 2 is the union 
of the results of the two joins. Compared with the PRS strategy, the join cost at each site is less since 
only one frag-ment of R2, instead of the whole relation, is involved i~ the join. Furthermore, communication 
cost is also reduced because only F21 instead of R2 needs to be transferred from site 2 to site 1. Clearly, 
the trade off is that the partition of Rl may be slower since the join attribute needs to be checked 
to decide to which fragment a tuple belongs. [n addition, partitioning R2 also takes time. However, this 
is not a problem because it is performed at site 2 while R1 is being partitioned at site 1. The time 
needed to compare the join attribute values also might not be a problem since in most present day systems, 
a data transfer involving secondary storage usually takes as long as, or longer than searching the block 
for desired data in the main memory [8]. Ifwe implement the partitioning in such a way that comparing 
the join attribute values of one block overlaps with the transfer of another block from disk to main 
memory, then the partition cost will be approximately the same as in the previous strategy. Example 1 
shows that both R1 and R2 are parti-tioned into two fragments based on whether the value of the join 
attribute is odd or even. In general, a hash- ing function can be applied to the join attribute to decide 
to which fragment a tuple should belong [1, 9]. Definition 1 A relation Ri is hash partitioned on at- 
tribute A into d disjoint fragments {Fij}, 1 < j < d, if (1) R~ = U~_<j<dF~j, (2) Fij N Fik = 0 for 
j 5 ~ k, and  (3) vT ~ F~ h(T.d)= ~, where h 0 is a hash function and cj is a constant for a given j. 
Suppose that RRQ = {R1, R2, ..., Rn} is the set of relations referenced by a query Q and none of them 
is fragmented. A subset PR of these relations will be chosen to be hash partitioned on their join attributes. 
Each relation contained in PR is partitioned into d disjoint fraglnents, for some integer d, by applying 
the same hash function to one of its join attributes. Then the fragments will be assigned to a set of 
d sites, called processing sites, in such a way that the frag- ments having the same hash address are 
assigned to the same site. The other relations, W R -- RRQ -PR, are replicated at each of the d sites. 
At each process- ing site, a subquery, which is the same as the query Q but referencing the fragments 
of the relations in PR and all the other relations in W R, is executed. The answer to the query Q is 
the union of the results to the subqueries at the d sites. Assume that the set of relations PR to be 
parti- tioned is given and some relations in PR have dupli- cate copies at different sites for the purpose 
of higher reliability and higher availability. Then, for each rela- tion in PR, we need to determine 
which copy should be used so that the best response time can be obtained. It can be proven that this 
problem is NP-Hard [11]. In the next section, we propose a very efficient and effective heuristic algorithm 
to find a reasonable copy for each of the relations to be partitioned. 3 A Heuristic Algorithm In order 
to simplify the problem, we consider the partition delay (time needed to do partitioning) rather than 
response time of the query. Since each site may have different processing speed, we define the normal- 
ized partition load (NPL) for site j as the total size of the relations to be partitioned at site j divided 
by the processing speed of the site. Now the problem becomes to balance the partition load. Unfortunately, 
even for this reduced problem, there is no polynomial algorithm. As a result, the following greedy method 
is used. We first sort the re- lations to be partitioned into descending order of their sizes, i.e., 
R1 :> R2 _ ... _> Rp. Then for each relation in the list, we arrange the copies of the relation in in- 
creasing order of normalized partition load. The first copy will be chosen and the NPL of the corresponding 
site is updated. For a given set of relations PR = {R1, R2, ..., R,.} to be partitioned, we use vector 
CS = (CSI, CS2, ..., CS,.) to represent the distribution of the copies of the relations and vector SP 
---- (SP1, SP2, ..., SPIn) to rep- resent the processing speeds of the sites. Specifically, CSi is the 
set of sites that contain a copy of relation Ri and SPj is the processing speed of site j. We also use 
IRil to denote the size of Ri. The following four steps are processed to determine the copies of the 
relations to be partitioned. Step 1: For each site that contains a copy of the re- lation(s) in PR, we 
initialize its NPL to 0. Step 2: For any relation Ri E PR, if Ri has only one copy, this copy of R~ will 
be chosen to be partitioned. Thus, the value, which is the size of Ri divided by the processing speed 
of the site that contains this copy, is added to the NPL of the corresponding site. Step 3: The remaining 
relations to be partitioned are sorted in descending order of their sizes and stored in a list L. Relations 
having the same sizes are further ordered in ascending order of the num- ber of copies. Step 4: For every 
relation Rj (from first to last) in the above list, we first compute the estimated NPL' of every site 
in CSj, where NPL' of a site is the sum of its NPL and the size of Rj divided by its processing speed, 
i.e., for site k E CSj, N PL k = N PLk + IRjl/SPk. Secondly, the copy of Rj that situates at the site 
havingminimum NPL among the sites in CSj will be chosen to be partitioned and the NPL of the site is 
updated to its NPL. Assume the number of copies of a relation at a single site is either 0 (not exist 
at this site) or 1 (there is a copy at the site). Then the copies of the relations to be partitioned 
can be represented as 197 vector CP = (S1, S2,...,Sr), 1 < Si <_. m, where Si (1 < i < r) is the site 
containing the copy of Ri in PR to be partitioned and m is the total nmnber of sites. Let MAXNPL be the 
maximum NPL among the sites that participate in partition processing. After performing the above steps, 
both CP and MAXNPL can be obtained. Example 2 Let the relations to be partitioned are Ra, R2, Ra, R4 
and Rs, whose sizes are 6000, 2000, 4000, 1000 and 7000 tuples, respectively. These re-lations are distributed 
among four sites as shown in Table 2. Assume the processing speeds of sites 1, 2, 3 and 4 are 900, 100, 
700 and 400, respectively. R ~tuples Site 1 Site 2 Site 3 Site 4 R1 6000 R1 RL Rt R~ 2000 R2 R 3 4000 
R 3 R3 R3 R3 Ra 1000 R4 R4 R5 7000 R5 R5 Speed 900 100 700 400 Table 2: Data Distributed for Example 
2 In the example, PR = {R1, R2, R3, R4, Rs}, CS = (CS~, CS2, CS3, CS4, CS5), where CS1 = {1,2,3}, CS2 
= {3}, CS3 = {1,2,3,4}, 6S4 = {2,3} and CS5 = {1,2}, and SP = (900, 100, 700,400). First, we initialize 
NPL of every referenced site to 0. That is NPLi=O for l <i<4. Next, since R2 has only one copy and CS2 
= {3}, the copy at site 3 is chosen to be partitioned. Thus, NPL3 is updated to 2000 / 700 = 2.86. Third, 
the remaining relations, RI, R3, R4 and Rs, are stored into a list L by descending order of their size. 
That is L: R5 (7000), R1 (6000), R3 (4000), R4 (1000). Now, we process each relation, from first to 
last, in the list L. For R5 which is the first relation in L, CS5 = (1,2}, we get NPL ] 1 = 7000/900 
= 7.78, NPL t 2 = 7000/100 -=- 70. Since NPL t a is less than NPL2, ! the copy at site 1 is chosen to 
be partitioned and NPL1 is updated to 7.78. t t For R1, similarly, we get NPL 1 = 14.45, NPL 2 = I 60.0 
and NPL a ---- 11.43. Thus, the copy at site 3 is chosen to be partitioned and NPL3 is updated to 11.43. 
 For R3, we get NPL' 1 = 12.22, NPL' 2 -= 40.0, NPL 3 t = 17.14 and NPL 4 t = 10.0. So the copy at site 
4 is chosen to be partitioned and N PL4 is updated to 10.0. For R4, we get NPL t 2 = 10.0, and NPL t 
3 = 18.57. Thus, the copy at site 2 is chosen to be partitioned and NPL2 is updated to 10.0. Now, the 
copies of the relations to be partitioned is CP = (3, 3, 4, 2, 1) and the maximum NPL, Algorithm SH: 
Size Heuristic Algorithm Input: PR = {R1, R2, ..., Rr}, CS (CSI, CS2, ..., CS,-), and SP = (SPa, SP2, 
..., SPIn). Output: CP = ($1,$2, ..., St) and MAXNPL. Initializes NPL of every referenced site to 0; 
FOR i = 1 TO r ( If (CSi only contains one copy of Ri) { p +- CSi; Si +-- p; N PLp ~ N PLp + IRd/SPp; 
PR ~-- PR -Ri; }} Sort the remaining relations in PR into a list L in descending order of their sizes 
and ascending order of the number of copies. For every relation Rj in L, from first to last { For every 
site p in CSj NPLp t *--- gPLp + IRj]/SPp; i J get site /¢ such that N PLk6cs ~ = minp~esj (N PLp); 
NPLk *--- NPLk; t Sj +"- k; } CP~ (S~, $2, ..., 5',.); MAXNPL +-maxkecp(NPLk); Figure 1: SH Algorithm 
MAXNPL, among these four sites is 11.4 which incurs at site 3. The SH algorithm to determine the copies 
of the given relations to be partitioned is given in Figure 1. The algorithm does not guarantee the optimal 
solu- tion, but it is very efficient and effective as will be shown in the next section. 4 Performance 
of the Algorithm In order to study the performance of the SH algo- rithm and compare to the optimal solution 
in which all different combinations of the copies of the relations are considered for choosing the one 
with the minimum partition delay, we define the following two perfor-mance matrices: (1) Success rate: 
the success rate of SH algorithm is defined as (N/T) 100%, where T is the total number of test cases 
and N is the number of test cases in which SH algorithm coincides with the optimal solution.  (2) Performance 
deterioration: the performance de- terioration of SH algorithm is defined as ((Yd --Yo)/Yo) * 100%, where 
Yd and Yo are the partition delay obtained by applying the SH algorithm and the optimal solution, respectively. 
The following experiments are conducted. The dimension of the initial data distribution for each experiment 
is n * m, where n, which changes from 2 to 10, is the number of relations, and m, which changes from 
2 to 10, is the number of sites. The range of the sizes of the relations is from 1K to 10K tuples. These 
sizes are relatively small com-pared to the sizes of nowaday databases. However, most queries have some 
types of restrictions that re-duce the number of tuples for the join operation. In the experiment, the 
relative speed of the sites are rep- resented by numbers from 1000 to 10000. For each combination of 
n (the number of relations to be partitioned) and m (the number of sites), we ar- bitrarily generated 
400 initial data distributions. Re-sults of SH algorithm and the optimal algorithm are both collected 
and the success rates and the average performance deteriorations are shown in Table 3 and Table 4, respectively. 
The success rate of SH algo-rithm depends on the number of join relations and the number of sites having 
copies of join relations. From Table 3, one can easily notice that when the number of sites is fixed, 
the success rate of SH algorithm de- creases as the number of relations increases (columns of Table 3). 
This is not surprising since the number of different combinations of copies of relations to be partitioned 
increases as the number of relations in-creases and then the probability that SH algorithm chooses the 
one yielding the minimum partition de-lay decreases. However, in most cases, SH algorithm generates the 
same results as the optimal solution. m n 2 4 6 8 10 A 2 100.0 95.0 98.5 99.0 99.0 98.3 3 100.0 96.5 
95.0 96.5 93.0 96.2' 4 96.5 90.0 85.0 91.0 91.0 90.7"" 5 84.5 86.5 71.0 77.5 90.5 82.0 6 86.0 77.5 67.5 
75.0 81.5 77.5 7 82.5 69.5 69.5 79.0 91.5 78.4 8 85.0 62.0 64.5 67.5 80.5 71.9 9 74.0 58.5 60.5 57.8 
51.5 60.5" 10 79.5 54.5 52.0 49.2 43.2 55.7- A 87.6 76.7 73.7 76.9 80.2 Table 3: Success Rate of SH 
Algorithm When the number of relations is fixed, increasing the number of sites involves two cases: 
1) the num-ber of copies does not increase and the distribution of copies becomes sparse, and 2) the 
number of copies increases and the copies are distributed among more sites. In the first case, the number 
of combinations of copies does not increase as the number of sites in- m ° L5 0% 0, I 0, I 0.8 0,4 
.... 3 ~3,0 0.4 0.~ 1.4 L~ i ,8'" 0.8 1.4 i.I 1.0 4 0.2 1.0 0.8 1.2 5 0,8 4.2 [.8 2.3  6 0.8 3.0 3.5 
2.T 4.2 2,9 6.~ 4,S 4,3 3.7 7 0.8 2.2 3,8 2.5 4,6 3.0 2.9 1.4 1,0 2.5 8 0",3 2.1 4.4 4.3 4.9 3.2 4.6 
3.6 3,3 3.4 9 o,9 2,2 4.0 4.a 4.3 4,2 4,8 4.7 5.0 3,9  I0 0:'4 1,5 5.2 6.4 7.4 6.5 6.1 6.3 6,9 5.2 A 
0.4 1.9 3.0 3.1 3.~ 3,4 4.0 3.2 2.9 Table 4: Performance deterioration of SH Algorithm creases. As a 
consequence, the chances that SH al- gorithm chooses the optimal strategy remain approxi- mately the 
same. In the second case, the success rate of SH algorithm slightly decreases since the number of combinations 
of copies increases. Thus, combining the above two cases, the success rate of SH algorithm depends on 
the number of copies rather than the num- ber of sites. As a result, the performance of SH algo- rithm 
does not increase or decrease monotonically as the number of sites increases (rows of Table 3). Comparing 
with the optimal solution, the average performance deterioration of SH algorithm is below 7.5% as shown 
in Table 4. This indicates that even in the cases where SH algorithm does not choose the op- timal copies 
of the set of relations to be partitioned, the cost of partitioning the copies chosen by SH al- gorithm 
is very close to the cost of partitioning the optimal copies. In SH algorithm, the relations to be partitioned 
are sorted into descending order of their sizes. However, the number of copies of relations is also an 
important factor relative to the performance. We change Step 3) in SH algorithm such that the relations 
to be parti- tioned are sorted into descending order of the number of copies rather than the sizes, and 
call it CH (Copy Heuristic) algorithm. We repeated the experiments by using CH algorithm. Our experiments 
show the gen- eral performances of SH and CH are similar but the cases that yields minimum partition 
delay are comple- mentary. As a result, combining the two algorithms yields better performance than each 
individual algo- rithm does. Thus we run algorithms SH and CH in turn for a certain case, the one having 
better perfor- mance is chosen. The experimental results are shown in Table 5. In order to give the readers 
a feeling of the running times of SH algorithm and the optimal algorithm, the CPU times of both algorithms 
are collected in our ex- periments. When the number of relations and/or sites increases, the CPU time 
for SH algorithm increases as a linear function Of n * m while that for the optimal algorithm increases 
exponentially. For example, when both the nulnber of relations and .the number of sites increase from 
4 to 8, the CPU time for SH algorithm increases from 49 tts to 180 tts while that for the opti- mal algorithm 
increases from 1.27ms to 67.9 seconds. When both the number of relations and the number of sites are 
10, the CPU time for the optimal algorithm is about 3 hours while that for SH algorithm is only a given 
query, the alternative sets of relations that can .m n 2 4 6 8 10 A 2 100.0 99.5 100.0 100.0 100.0 99.7 
3 100.0 98.5 98.0 100.0 98.5 98.3 4 96.5 95.5 93.0 97.0 95.0 95.3 5 84.5 91.0 82.0 89.5 92.5 86.9 6 
86.0 85.0 75.5 83.0 86.5 84.4 7 82.5 79.5 75.5 85.5 96.5 84.8 8 85.0 70.5 70.5 72.5 83.0 76.4 9 74.0 
66.0 66.0 60.2 56.5 64.0 l0 79.5 60.0 57.0 50.8 45.2 58.9 A 87.6 82.8 79.7 82.1 83.8  Table 5: Success 
rate of Combining SH and CH 0.3ms. In Table 6, we show the ratio of To to Td, where To is the CPU time 
of the optimal algorithm and Td is the CPU time of SH algorithm. Clearly, the ratio increases very quickly 
as the number of relations and the number of sites increase. This further indicates that SH algorithm 
is very useful. m n 2 4 6 8 10 2 6.25 8.33 10.4 14.4 19.3 4 7.61 25.9 74.6 192 390 6 10.5 217 1540 
7056 20125 8 25.9 2657 53473 377278 1786270 10 111 32222 1469460 13264300 35264700  Table 6: Ratio 
of CPU Running Time (To / Td) 5 Conclusion We propose an improvement on the well-studied PRS algorithm 
[12, 3, 4]. Since replicas of relations are allowed and determining the optimal copies of the relations 
to be partitioned is NP-hard, a heuristic al- gorithm is proposed. Simulation experiments are conducted 
to evaluate the performance of our algorithm. We show that our heuristic algorithm is very efficient 
and effective. In general, not all of the relations referenced by a query can be partitioned. For example, 
let a query be Q = {R~.A, R2.B [ R1.A -~ R2.A A R2.B = R3.B}, then not all of the three relations can 
be partitioned since the first join predicate (R1.A =-R2.A) requires R2 be partitioned on attribute A 
and the second join predicate (R2.B = Ru.B) requires R2 be partitioned on attribute B. Clearly there 
is a conflict between these requirements. However, we can choose to parti- tion R1 and R 2 on attribute 
A and replicate R3 at the processing sites. Yet another alternative is to partition R2 and R3 on attribute 
B and replicate R1 at the pro- cessing sites. We will provide a method to identify, for be partitioned. 
An algorithm is needed to determine which of the alternative sets allows minimum response time. References 
<RefA>[1] DeWitt, D. and Gerber, R.: Multiprocessor hash- based join algorithms. Proceedings of the 11th In- 
ternational Conference on Very Large Data Bases (VLDB), pp. 151-164, Stockhohn, Aug. 1985. [2] Epstein, 
R., Stonebraker, M. and Wong, E.: Dis-tributed query processing in relational databases sys- tem. Proceedings 
i978 ACM SIGMOD Conference, Austin, TX, May 1978. [3] Liu, C. and Yu, C.: Validation and Performance 
EvMuation of the Partition and Replicate Algorithm. Proceedings of the 12th IEEE International Confer-ence 
on Distributed Computing Systems, pp. 400-407, Yokohama, Japan, June 1992. [4] Liu, C. and Yu, C.: Performance 
Issues in Distributed Query Processing. IEEE Transactions on Parallel and Distributed Systems, Vol. 4, 
No. 8, pp. 889-905, Aug. 1993. [5] Sacca, D. and Wiederhold, G.: Database partitioning in a cluster of 
processors. ACM TODS, Vol. 10, No. 1, pp. 29-56, Mar. 1985. [6] Sacco, Giovanni Maria: Fragmentation: 
A technique for efficient query processing. ACM TODS, Vol. 11, No. 2, pp. 113-133, June 1986. [7] Shasha, 
Dennis and Wang, Tsong-Li: Optimizing Equijoin Queries In Distributed Databases Where Re- lations Are 
Hash Partitioned. ACM Transactions on Database System, Vol. 16, No. 2, pp. 279-308, June 1991. [8] Ullman, 
J. D.: Principles of Database Systems. Com-puter Science Press, Inc., Rockville, MD, 2 edition, 1982. 
[9] Valduriez, P. and Gardarin, G.: Join and semijoin algorithms for a multiprocessor database machine. 
ACM TODS, Vol. 9, No. 1, pp. 133-161, Mar. 1984. [10] Wong, E. and Katz, R. H.: Distributing a database 
for parallelism. In Proceedings 1983 ACM SIGMOD Conference, pp. 23-29, San Jose, CA, May 1983. [11] Yu, 
C. T., Chang, C. and Chang, Y.: Two surpris- ing results in processing simple queries in distributed 
databases. Proceedings 6th IEEE International Com- puter Software and Application Conference, pp. 377- 
384, Chicago, IL, Nov. 1982. [12] Yu, C. T., Guh, K. C., Brill, D. and Chen, A. L. P.: Partition strategy 
for distributed query processing in fast local networks. IEEE Transactions on Software Engineering, Vol. 
15, No. 6, pp. 780-793, June 1989.</RefA>  
			
