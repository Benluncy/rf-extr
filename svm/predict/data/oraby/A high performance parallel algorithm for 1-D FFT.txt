
 A High Performance Parallel Algorithm for 1-D FFT R.C. Agarwal, F.G. Gustavson, and M. Zubair IBM T.J. 
Watson Research Center, Yorktown Hts., NY 10598 Abstract In this paper we propose a parallel high performance 
FFT algorithm based on a multi-dimensional formula­ tion. We use this to solve a commonly encountered 
FFT based kernel on a distributed memory parallel machine, the IBM scalable parallel system, SP1, The 
kernel requires a forward FFT computation of an input sequence, multiplication of the transformed data 
by a coefficient array, and jinally an inverse FFT compu­ tation of the resultant data. We show that 
the multi­ dimensional formulation helps in reducing the commu­ nication costs and also improves the 
single node per­formance by effectively utilizing the memory system of the node. We implemented this 
kernel on the IBM SP1 and observed a performance of 1.25 GFL OPS on a 6J-node machine. Introduction Computation 
of Fourier transforms arises in many scientific and engineering applications like digital fil­ tering, 
calculation of auto and cross correlation, so­lution of partial differential equations etc. The fast 
Fourier transform algorithm (FFT) computes the transform of a length-n sequence of complex numbers in 
O(n log n) time. Parallel FFT algorithms have been well studied, see for example [4-8, 10-17, 19-21]. 
In this paper, we propose a parallel high perfor­mance FFT algorithm based on a multi-dimensional formulation. 
We use this to solve a commonly encoun­tered FFT based kernel on a distributed memory par­allel machine, 
the IBM scalable parallel system, SP1. The kernel requires a forward FFT computation on an input sequence, 
multiplication of the transformed data by a coefficient array, and finally an inverse FFT com­putation 
on the resultant data. This kernel arises in many real applications such as digital signal process­ing, 
and the solution of partial differential equations. A similar kernel is being considered as one of the 
par­allel benchmarks in the PARKBENCH suite [19]. Our proposed parallel implementation of this ker­nel 
is based on the mixed radix discrete Fourier trans­form algorithm of Agarwal and Cooley [1, 2] for vector 
machines. In their approach, a one-dimensional FFT computation is formulated as a multi-dimensional FFT 
computation. This formulation allows one to work with a full vector length and to also use a simple data 
addressing scheme which uses small strides. This multi-dimensional formulation is quite powerful; it 
has been exploited to get high performance on memory hi­erarchy based machines by Agarwal [3], and also 
in­dependently by Bailey [6]. The multi-dimensional for­mulation was also used by Averbuch, Gabber, Gordis­sky, 
and Medan [4] to develop a parallel implementa­tion on a shared memory parallel machine. Data movements 
between various phases of a com­putation often determine the overall performance of the computation on 
a distributed memory parallel ma­chine. Considering the complete application where the kernel would be 
used, it is desirable to have the output data distribution for the kernel to be identical to the input 
data distribution. One way to implement the kernel is to use a parallel FFT routine which works on an 
input data distributed in a specified manner and generates the output data which is distributed in the 
same manner. On most commercially available parallel machines, the cost of such a FFT routine is dominated 
by the cost of moving data between proces­sors. These data movements are typically imposed by (i) the 
structure of the FFT computation, and (ii) the rearrangement of the output data to according to the original 
data distribution. Using our approach, we show how to completely eliminate the cost due to (ii). In our 
approach we exploit the fact that the inter­mediate data distribution for the kernel can take any form. 
A second major advantage of the multi-dimensional formulation is to provide an efficient mechanism for 
blocking the data for cache of a single node of the parallel machine. This is particularly important 
for parallei machines like the IBM SP1 where each node has memory heirarchy. The size of the FFT computa­ 
1063-9535/94 $4.00 @ 1994 IEEE tion on each node is determined by the number of di­mensions in the multi-dimensional 
formulation. Thus given the kernel size and the cache size, one can de­termine what dimension formulation 
should be used so aa to fit the resulting individual FFT computation in cache. We have implemented the 
FFT based kernel on the SP1. The SP1 is a scalable parallel system containing up to 64 RISC/6000 nodes 
connected through a high speed switch. Each node can be configured with up to 256 MB memory and up to 
2 GB of disk. We observed a performance of 1.25 GFLOPS on a 64-node machine where the initial and final 
data distribution identical. Our experiments on the IBM SP1 show that as the size of the kernel grows 
it pays to move to a higher dimensional formulation. 2 SP1 The IBM SP1 is a scalable parallel system 
contain­ing up to 64 RISC/6000 Model 370 nodes. Each node can be configured with up to 256 MB memory 
and up to 2 GB disk. The nodes on SP 1 are intercon­nected through a switch. The communication band­width 
available at a node is about 8 MB/second. One important characteristic of the communication net­work 
of SP1 is that the bandwidth available at a node does not degrade with increasing number of nodes or 
in the presence of other messages on the network. As a result, a global transpose operation which involves 
an all-to-all communication scales well on the SP 1. However, the scaling is not good if the message 
size is small. For small messages, all-to-all communication requires fine grain synchronization (of the 
order of 1 mil sec for an 8KB message) across all processors. If during this period an aix daemon appears 
on ofie of the processors, it will delay all the processors (Note that on each node of SP1 we have a 
full AIX operat­ing system. ) A single node of SP1 is a Model 370 RS/6000. It has a four-way set-associative, 
32 K-byte cache with a cache line size of 64 bytes. The RS/6000 Model 370 TLB has 128 entries in a two-way 
set associative table. Therefore, at any time, up to 128 virtual pages can be translated. If the translation 
information for a virtual page is not in the TLB, a TLB miss occurs and it can take up to 40 cycles to 
bring it in the TLB. Therefore, in addition to cache misses, it is imperative to block the problem to 
minimize TLB misses. Supers calar Features Some of the salient features which enable RS/6000 to give 
very good floating point performance are summa­rized below. When data and instructions remain in cache 
and TLB, the RS/6000 is capable of executing four instructions per machine cycle: a branch, a con­dition 
code logic instruction, a fixed point instruc­tion, and a floating point instruction. The float­ing point 
instruction can be a compound multi­ply/add instruction.  All arithmetic is done between registers. 
There are 32 fixed point and 32 floating point registers.  The floating point multiply/add instruction 
(FMA), a compound instruction, is executed in a two stage pipeline. The delay in each stage is one cycle. 
After the first cycle, a second FMA instruction may start provided that it does not need data from the 
output of the first FMA in­struction.  A floating point load instruction is done by the fixed point 
instruction unit (FXU), and can be done concurrently with a floating point arithmetic instruction which 
does not use the value being loaded.  3 Multidimensional Formulation To understand our approach, we 
first describe the basic multi-dimensional formulation given in [1, 2] for computing DFT on vector machines. 
This foundation is then extended to implement the FFT based kernel on parallel machines. 3.1 Basic multi-dimensional 
formulation of Agarwal and Cooley Consider the following DFT computation. j =0 where WN = e-2 TilN. Let 
N E ~1~2~3...~r Consider the following mapping of z and y onto a r-dimensional data space. k=kI+kzN2+ 
k3N2NI+. ..+~r(~l-l x . ..Nl) 4 ParalleI Algorithm Based on the Multi-dimensional Formulation j=jr+jr-l~r 
+...+ j2(~3~T )+jl(~2X(~r )... ~r). We can now express z and y as r-dimensional array The parallel algorithm 
to implement the FFT ker­in FORTRAN notation: nel is based on the multi-dimensional formulation. The 
kernel has three phases: (i) Forward phase, (ii) y(k) = y(kl, . . .,kr) Multiplication phase, and (iii) 
Inverse phase. In the first phase we perform a forward FFT computation on the one-dimensional data. The 
transformed data a!(j) = Z(jr, . . ..jl)=izo(jl . . ..l~r) is multiplied by a coefficient array in the 
multiplica­where Z. is a permutation of x in which the r-tion phase. The inverse phase involves inverse 
FFT dimensional indices have been reversed. computation. The basic outline of the algorithm for the forward 
The twiddle factor W# can be expressed as: phase is given below. The inverse phase is similar to the 
forward phase. A one dimensional array is viewed . . . ~:(k, +k,N, +... k, N,-N,). N,) WJk = ~~,ki~jz(kl+k~Nl) 
as a multi-dimensional array. The initial distribution NI N2 of the data is assumed to be along one 
of the dimen- The DFT is computed by first summing over jl, sions. In the first stage, we compute FFT 
along one then on j2, and so on. The complete computation of the local dimensions (i.e., a dimension 
other than consisting of r steps can be described as follows. the one across which data has been distributed). 
This Step 1: FFT computation is accompanied with a local trans­N1-l pose (data re-arrangment) and twiddle 
factor multipli­cation (for the next dimension). Next we do a collec­ xl(j2, ...,jrj~l) = ~ ~O(jl, . 
. ..jr)WJ.k . jlcO  tive communication between the processors so as to re­distribute the data along 
the dimension for which we Step 2 just completed the FFT. Finally, one after the other, N, 1 for the 
rest of the dimensions we complete the FFT computation and the twiddle factor multiplication. x2(j3, 
. . . . jr, h, k2) = ~ z1(j2, ..., jr, kl)W$,k&#38;, Wg k2. j~=O We now discuss details of our algorithm. 
Here, we will only give details of the three-and four­dimensional formulations. The algorithm for a gen­eral 
number of dimensions can be easily derived from these two formulations. We will also give details of 
the two-dimensional formulation which is slightly different from the general formulation. Before giving 
details of the algorithm, we describe the notations used and the initial data distribution. 4.1 Initial 
data distribution and nota­t ions one­putation. dimensional array c(iV) can be viewed as an r­dimensional 
array z(N., . . . . IVz, lVl) (in FORTRAN To summarize, at lth step, we do the following com-As discussed 
in Section 3-1, the original Multiply the ~-dimensional array with the twid­notation). The initial array 
ZO(7V1, N2, . . . . IVr ) is an dle factor array which depends on the previously indez-reverseu! permutation 
of the original array. On transformed 1 1 dimensions. a p-processor distributed memory machine, the 
array Z. is distributed along the last dimension (Nr ). ThisDo length IVz FFT computation along the Zth 
di­ is equivalent to mapping the first IV/p values of themension. X. array to the first processor and 
so on, We are M+ 0 Store the computed array with a left cyclic shift suming that N, is divisible by p. 
To indicate that the on the indices. data is distributed along dimension r, we introduce the notation 
N, = NT/P and the corresponding in­dex is called ~. indicating that the data along index jr is distributed 
across all p processors. The first fir values of index jr are mapped to the first processor and so on. 
Th~ distributed array is represented as io(Nl, N2, ..., N.). This is also the dimensionality of the array 
declaration at every processor. At proces­sor m, the local index ~. (m) corresponds to the global A index 
j? = mN~+~r(m),m = 0, 1, . . .,p l. Through­out the paper, we will use the zero-based indexing. The completion 
of the forward FFT along ith di­mension is indicated by replacing Ni by K, in the distributed array representation. 
For example, af­ter completion of the FFT al~ng the first dimen­sion the array ~o(N1, N2, . . . . N,) 
is represented as &#38;( Kl, N2, . . ..ivT). Similarly we will indicate the completion of the inverse 
FFT by replacing Ka by Ni. For illustrating the global transpose operation we will find it convenient 
to decompose N, (K, ) into t~o dimensions fit (ii) and Pi, where fit = Na/P, (K, = Kt/P,). Here, Pi is 
the number of processors in the machine. Although P, is same as P, we are using the subscript i to denote 
that this index belongs to dimension i. 4.2 Algorithm We describe the algorithm by a ~eries of transforma­tions 
on the array 20(N1, N2, , . . . N.). There are three phases of the algorithm: (i) foward FFT computation, 
(ii) multiplication by the coefficient array, and (iii) in­verse FFT computation. The various transformations 
(or operations) on the array for a typical forward or inverse FFT computation phase are: FFT: Fast Fourier 
Transform computation along one of the dimensions. FFT and rearrangement : FFT computation along one 
of the dimensions with data rearrangement. Twiddle and transpose: Multiplication by twiddle fac­tor array 
along with the local data rearrangement. Global transpose OT All to all communication : In this operation, 
an array of size L is redistributed across all P processors. The array at each node is partitioned in 
P chunks of size L/P, and every processor sends its i-th chunk to processor i. Every processor receives 
a chunk from j-th processor (j = O, 1, . . . . P 1)which is stored in the receiving array of size L, 
starting at location j(L/P). Coefficient multiplication: Multiplication by the coef­ficient array. Notice 
that we have combined some of the operations with data movements. This is in order to effectively utilize 
the memory bandwidth. 3-Dimensional Formulation The initial data array at each We illustrate the algorithm 
by after each transformation. Initial distribution: 20(N1, N2, Operation Forward phase FFT Twiddle and 
transpose Global transpose FFT and rearrangement Twiddle and transpose FFT lklultiplication phase Coefficient 
multiplication Inverse phase FFT Twiddle and transpose Global transpose FFT and rearrangement Twiddle 
and transpose FFT 4-Dimensional Formulation The initial data array at each We illustrate the algorithm 
by after each transformation. Initial distribution: ;O (Nl, N2, Operation Forward phase FFT Twiddle and 
transpose Global transpose FFT and rearrangement node is represented by, showing the data array N3) Data 
array after the operation &#38;l(KI,~z,l$3) 22(N2, ~3, ~1) = 22(N2, N3, :1, PI) f3(N2, fi31 Kl, P3) i4(K2, 
I?l, fi3, P3) = &#38;4(K2, I?l, N3) 25(N3, K2, $) &#38;( K3, K2, Kl) ;T(K3, K2, ~1) fis(N3, Kz, kl) ilg(K2, 
El, N3) = ~g(K2, Kl, ~:, P3) &#38;(K2, l?l, N3, Pl) 211 (Nz, fis, I?l, Pl) s ~ll(Nz,i?3,Kl) 212(K1, N2, 
13) 513(N1, N2, N3) node is represented by, showing the data array N3, fi4) Data array aft er the operation 
&#38;( Kl, Nz, Ns, &#38;) i2(~2, N3, fi4, xl) = ~2(~2, N3, fi4, ~1, ~1) $3(N2, N3, ~4, ~1, P4) &#38;4(Kz, 
IV3, Kl, lV4, P4) = ~4(~2, ~3, ~1, ~4) Twiddle and transpose 25(N3, K2, J?l, N4) FFT &#38;(~3, ~2, i?l, 
iV4) Twiddle and transpose i7(N4, K3, K2, Ill) FFT &#38;(K4, K3, K2, iJ Multiplication phase Coefficient 
multiplication 29(K4, A-3, K2, Ill) Inverse phase   FFT &#38;I(~4,~3,~2,i@ Twiddle and transpose &#38;1(K3, 
K2, ~1, N4) E ih1(K3, K2, I?I, Ii4, P4) Global transpose ~12(~3, ~2, :1, fi4, ~1) FFT and rearrangement 
&#38;3(~3, Kz, ~4, il, Pl) = &#38;3(N3, K2, fi4, Kl) Twiddle and transpose ;14(Kz, N3, fi4, Kl) FFT &#38;@z,Ns,@) 
Twiddle and transpose fi16(Kl,Nz,Ns,NA) FFT &#38;T(Nl,Nz,Ns,tiA)  The algorithm outlined for the 3-and 
4-dimensional cases can be ea.silty extended to higher dimensions. In general for the r-dimensional case 
we will have: (i) 2(T 1) FFT computation operations, (ii) two FFT and rearrangement operations, (iii) 
two Global trans­pose operations, (iv) 2(T 1) 1 widdle and transpose operations, and (v) a coefficient 
multiplication oper­ation. 2-Dimensional Formulation This formulation is slightly different from the 
higher or general formulation. Here, the FFT and rearrange­ment operation which follows the global transpose 
op­eration haa to be split up in two separate operations: (i) rearrangement, and (ii) FFT . The rest 
of the struc­ture remains identical to the higher dimensional for­ ,. mulation. Starting with the initial 
data 20(N1, iV2), the various steps of the algorithm are shown below. Initial distribution 20(N1, N2) 
Operation Data array after the operation ForwaTd phase FFT ~l(K1, fi2) Twiddle and transpose 22(~2, Kl) 
E i2(N2, ~1, F 1) Global transpose ~3(lVZ, Ill, Pz) Rearrangement ~4(fiz, <z, kl) ~ ~4(N2, Kl) FFT i?5(Kz, 
kl) Multiplication phase Coefficient multiplication Inverse phase FFT Twiddle and transpose Global transpose 
Rearrangement FFT 4.3 Cache Considerations In general, for a given N, it is possible to have more than 
one multi-dimensional formulation. For example, given N = 1024, it is possible to have a 2-d formula­tion 
with N = N1 x N2 = 32 x 32, or a 3-d formulation with N= N1x N2x N3= 16x16 x4. For agiven N, the best 
formulation is determined by the cache size on a single node. The cache size in turn deter­mines what 
size FFT computation gives the best per­formance. On SP 1, a length-512 FFT gives the best performance. 
Thus, a length-21s FFT can be most efficiently computed on SP1 using a 2-d formulation. For this formulation, 
N = N1 x N2 = 512 x 512. On the other hand a 3-d formulation is best for length­227 FFT computation. 
For this formulation, N = N1xN2xN3=512x512x512. The value ofNfor which, we should switch to a higher 
dimensional for­mulation is determined by the performance behavior of the uniprocessor FFT and the overheads 
associated with a higher dimensional formulation. 5 Experimental Results We implemented our parallel 
algorithm on the IBM SP1 for the two-and three-dimensional caaes. The higher dimensional cases were not 
necessary for IBM SP 1. This is because of the limitation of the size of the problem which can be solved 
on a 64-node SP 1. The maximum size problem which we can solve on a 64-node SP 1 (in memory) is 22s. 
This is because each node of our SP1 had a memory of 128 M bytes. For this value of N, a three-dimensional 
formulation is sufficient to give optimal performance. On a single node we use FFT routines of the Engi­neering 
and Scientific Subroutine Library (ESSL) [9]. It should be mentioned that all our coding is done us­ing 
standard FORTRAN and the IBM AIX Parallel Environment [11]. We summarize our results in Ta­bles 1-4. 
Tables 1 and 2 give results for the parallel algorithm based on a 2-d formulation and Tables 3 and 4 
give results for the algorithm based on a 3-d formulation. The first column of a table indicates the 
number of nodes. We obtained results starting with 8 nodes and going up to 64 nodes. We used the IBM 
SP 1 at Yorktown. The second column gives the problem size. In the third column we give the sizes of 
different di­mensions in the multi-dimensional formulation. The fourth column of Tables 1 and 3 gives 
T, the total execution time in seconds. The last two columns of Tables 1 and 3 give T. and TC, the time 
spent on com­puting and communication respectively. For Tables 2 and 4 the third column gives &#38;fU, 
the communication requirement in Million Bytes at each node; the fourth column gives Be = Mv /TC, the 
effective bandwidth in MB/second observed on a node; the fifth column gives M,, the message size in Kilo 
Bytes involved in the all­to-all communication; and the last column gives the overall performance in 
MFLOP/Seconds. The float­ing point operation count for the FFT computation is based on the formula 5N 
log N. Note that the in­put sequence consists of COMPLEX* 16 floating point numbers. The total floating 
point operations count for the kernel is taken to be 10N log N. These results clearly indicate that for 
larger problem sizes the 3-d formulation is superior to the 2-d formulation. 6 Conclusion In this paper 
we have proposed a multi-dimensional high performance parallel FFT algorithm which is an extension of 
the approach of Agarwal and Coo­ley [1, 2]. This new algorithm was used to compute a commonly encountered 
FFT based kernel on the BM SP1. We showed that the multi-dimensional formu­lation helps in reducing the 
inter-processor commu­nication and also provides an efficient mechanism for blocking for cache of a single 
node of a parallel ma­chine. We implemented the kernel on the IBM SP 1, and observed a performance of 
1.25 GFLOP/Seconds on a 64-node system. The performance results demon­strate that the proposed algorithm 
has low communi­cation cost and utilizes cache effectively. References <RefA>[1] R. C. Agarvval, An Efficient 
Formulation of the Mixed-Radix FFT Algorithm, ln­ternational Conference on Computers, Sys­ tems and Signal 
Processing, Bangalore, In­ dia, Dec. 1984, pp.769-772. [2] R.C. Agarwal and J.W. Cooley, Vectorized Mixed 
Radix Discrete Fourier Transform Al­gorithms, Proceedings of the IEEE, VO1.75, No.9, September 1987, 
pp.1283-1292. [3] R. C. Agarwal, A Vector and Parallel Implementation of the FFT Algorithm on the IBM 
3090, Aspects of Computation on Asynchronous Parallel Processors, Edited by Margaret Wright, North-Holland, 
1989, pp.45-54. [4] A. Averbuch, E. Gabber, B. Gordissky and Y. Medan, A Parallel FFT on a MIMD Ma­chine, 
 Parallel Computing, vol. 15, 1990, pp. 61-74. [5] D.H. Bailey, A High-Performance Fast Fourier Transform 
Algorithm for the CRAY­2 , The Journal of Supercomputing, vol. 1, 1987, pp.43-60. [6] D.H. Bailey, FFTs 
in External or Hierar­chical Memory , The Journal of Supercom­puting, VO1.4, 1990, pp,23-35. [7] David 
A. Carlson, Ultrahigh-Performance FFTs for the Cray-2 and Cray Y-MP Su­percomputers, Journal of Supercomputing, 
VO1.6, 1992, pp. 107-116. [8] R.M. Chamberlain, Gray Codes, Fast Fourier Transforms and Hypercubes, Par­allel 
Computing 6 (1988), pp.225-233. [9] ESSL, Guide and Reference, Order number SC23-0526-00, IBM Corp., 
1992. [10] R.W. Hockney and C.R. Jesshope, Parallel Computers} Adam Higler, 1981. [11] IBM AIX Parallel 
Environment, Parallel Programming Subroutine Reference, Re­lease 2.0, Order number SH26-7228-01, IBM 
Corp., 1994. [12] L.H. Jamieson,P.T. Mueller, and H.J. Siegel, FFT Algorithm for SIMD Parallel Process­ing 
Systems, m Journal of Pavallel and Dis­tributed Computing, VO1.3, 1986, pp.48-71. [13] S.L. Johnson, 
C.T. Ho, M. Jacquemin and Table 1. Performance of FFT based kernel using 2-d for- A. Ruttenburg, Computing 
Fast Fourier mulation on SP1. Transform on Boolean Cubes and Related P N N1XN2 T T. T= Networks, In SPIE 
Advanced Algorithms Sec. Sec. Sec. and Architectures for Signal Processing II, 8 224 212 x 212 28.3 14.8 
13.5 21s x 212 vol 826, 1987, pp. 223-231 16 226 29.9 15.3 14.6 32 226 21s x 213 32.5 16.7 15.8 214 
x 213 [14] S. L. Johnsson, R.L. Krawitz, D. MacDon-64 227 34.7 19.0 15.7 ald and R. Frye, A Radix 2 
FFT on the Connection Machine, proceedings of Super­computing 89, November 1989, pp. 809-819. Table 2. 
Communication and over all performance for the 2-d case (refer to results in Table l.). [15] S. L. Johnsson. 
M. Jacquemin and C.T. Ho, High Radix FFT on Boolean Cube Net- PIN IM. IB, M, MFLOP works, Technical 
Report NA89-7, Thinking I MB \ MB/s I KB I /See. Machines Corporation, 1989. 8 I 22 117 I 8.67 4194 142 
16 225 126 8.63 2097 281 [16] S.L. Johnsson and R.L. Krawitz, Commu-32 226 130 8.23 1049 537 nication 
Efficient Multiprocessor FFT, Di-64 227 132 8.41 524 1044 vision of Applied Sciences Report TR-25-91, 
Harvard University, 1991. [17] S.L. Johnsson and R.L. Krawitz, Cooley- Table 3. Performance of FFT based 
kernel using 3-d for- Tukey FFT on the Connection Machine, mulation on SP 1. Parallel Computing, vol. 
18, 1992, pp. 1201- P N NIX N2XN3 T T. T= 1221. Sec. Sec. Sec. 8 22 28X28X28 27.0 13.2 13.8 [18] R.A. 
Kamin III and G.B. Adams III, Fast 16 226 29X28X28 27.9 13.2 14.7 Fourier Transform Algorithm Design 
and 32 226 29X29X28 28.2 13.0 15.2 Tradeoffs on the CM-2, in Proceedings of 64 227 29x29x29 28.9 13.3 
15.6 the Conference on Scientific Applications on The Connection Machine, September 1988, pp.134-160. 
Table 4. Communication and over all performance for the [19] Public International Benchmarks For Par­ 
3-d case (refer to results in Table 3.). allel Computers, PARKBENCH Committee: },l~l~vlB= 1~, I MFLOP 
\ [20] Report 1, Assembled by Roger Hockney, No­vember 1993 (Available from Netlib). P.N. Swarztrauber, 
Multiprocessor FFTs, Parallel Computing 5(1987), pp.197-210. 8-1-=2 16 22 32 226 64 227 T_rMB MB/s KB 
117 8.49 4194 126 8.57 2097 130 8.55 1049 132 8.46 524 /See. 149 301 619 1254 [21] P.N. Swarztrauber, 
R.A. Sweet, W.L. Briggs, V.E. Henson and J. Otto, Bluestein s FFT for Arbitrary N on the Hy­percube, 
Parallel Computing, vol 17, 1991, pp. 607-617. [22] C. Tong and P.N. Swarztrauber, Ordered Fast Fourier 
Transform on a Massively Par­allel Hypercube Multiprocessor, Journal of Parallel and Distributed Computing, 
vol 12, 1991, pp. 50-59.</RefA>  
			
