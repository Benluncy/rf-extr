
 A Meta-Model for Usable Secure Requirements Engineering Shamal FailyIvan Fléchais Oxford University 
Computing Laboratory Oxford University Computing Laboratory Wolfson Building Wolfson Building Oxford 
OX1 3QD, UKOxford OX1 3QD, UK shamal.faily@comlab.ox.ac.uk ivan..echais@comlab.ox.ac.uk ABSTRACT There 
is a growing recognition of the need for secure soft­ware engineering approaches addressing both technical 
and human factors. Existing approaches to secure software engi­neering focus on the need for technical 
security to the detri­ment of usability. This paper presents the IRIS (Integrating Requirements and Information 
Security) meta-model, a con­ceptual model for usable secure requirements engineering. We describe a practical 
application of the meta-model through a case study in the Critical Infrastructure domain. 1. INTRODUCTION 
Human factors are still not su.ciently addressed in the process of engineering secure software systems, 
and this is not a new problem. Auguste Kercko.s wrote in 1883 that systems should be easy to use and 
require neither mental strain nor the observance of many rules [1]. Over 35 years ago, Saltzer &#38; 
Schroeder [2] penned the principle of Psy­chological Acceptability, stating that the human interface 
should be designed such that users routinely and automat­ically apply protection mechanisms correctly. 
More recent work in HCISec (Human Computer Interaction in Security) [3, 4] describes how unusable controls 
may introduce vulner­abilities if circumvented or used incorrectly. In spite of this, while it is accepted 
wisdom that security concerns should be treated as early as possible (preferably when eliciting and specifying 
requirements), usability concerns remain largely ignored. Considering human factors during secure systems 
engi­neering requires additional attitudes and techniques. As­sumptions which may seem reasonable from 
a security stand­point may be unwarranted from a usability standpoint. For example, when considering 
how to approach usability design for security in the Critical Infrastructure (e.g. power, water and gas 
utilities, etc.), Anderson et al. [5] argue that we should think about designing security that Homer 
[Simp­son] can use safely. While from a security standpoint this highlights the importance of security 
in the face of incompe- Permission to make digital or hard copies of all or part of this work for personal 
or classroom use is granted without fee provided that copies are not made or distributed for pro.t or 
commercial advantage and that copies bear this notice and the full citation on the .rst page. To copy 
otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission 
and/or a fee. SESS 10, May 2 2010, Cape Town, South Africa Copyright 2010 ACM 978-1-60558-965-7/10/05 
...$10.00. tence, it is counterproductive from a usability perspective. It is important to ground usability 
decisions in information gathered about real people, potentially including them in the design process; 
comparing these stakeholders to Homer marginalises them and undermines their contribution. These caricatures 
may also introduce unwarranted biases into the speci.cation and design process. As well as designing 
for the people who will use them, se­cure systems also need to be designed for the environments they 
will be used in. Even though environmental changes may undermine the security in system designs, approaches 
for specifying requirements remain grounded in the assump­tion of a single environment representing the 
real world [6]. Unfortunately, the real world is complex: a system may be situated in di.erent countries, 
or be used by people with di.erent cultural backgrounds and di.erent perceptions of security and its 
importance. Environments within which a system will run are often the least understood aspect of a proposed 
design, and tools and techniques for reasoning about these lack maturity [7]. Approaches to specifying 
requirements for systems which are usable and secure need to align concepts from within Usability Engineering 
and Security with those used to elicit and specify requirements. Encapsulating these concepts and their 
associations within a conceptual model is a .rst step towards developing Requirements Engineering processes 
for usable security, and tool-support for managing such a pro­cess. This paper presents the IRIS (Integrating 
Require­ments and Information Security) meta-model, a conceptual model for Usable Secure Requirements 
Engineering. This work builds upon practical work in usability design and recent research on meta-models 
for Security Requirements Engineering to help structure and manage usability, secu­rity, and requirements 
engineering in di.erent contexts. In section 2, we describe the related work our meta-model is founded 
upon. In section 3, we present the meta-model and its component parts, which we validate in section 4 
using a Critical Infrastructure case study. In section 5, we brie.y describe how the meta-model supports 
inter-related qualita­tive and quantitative analysis of risks and tasks.  2. BACKGROUND 2.1 Security 
Requirements Engineering Meta-Models Existing meta-models for Security Requirements Engineer­ing [8, 
9, 10] do not explicitly consider usability needs. It is, therefore, important to determine the associations 
relat­ing Security Requirements Engineering concepts with those used in Usability Engineering. We cannot, 
however, devise any rational conceptual model without thinking about the techniques used to elicit and 
re.ne data into the requisite concepts. A number of such techniques have been proven useful in Usability 
Engineering as well as Security Require­ments Engineering. Task analysis is a core technique for understanding 
the impact of work performance on human agents [11]. Tasks can be modelled using scenarios, which are 
arguably the most common representation shared by Us­ability and Requirements Engineering for eliciting 
empirical data. Scenarios have been used extensively to help elicit and model requirements [12], and 
have also been used to describe how a system may be attacked or misused [13]. Closely allied to tasks 
are the goals a human agent wishes to achieve by carrying out speci.c tasks. Goal Oriented Re­quirements 
Engineering techniques are useful for validating the completeness of requirements [14] and modelling 
stake­holder rationale [15], as well as building threat trees [16] and modelling vulnerabilities and 
their e.ect [17]. Mayer s work on the Information System Security Risk Management (ISSRM) modelling 
language [10] examines all the stages of Information Systems development. This has included work on aligning 
ISSRM concepts with techniques such as scenario-based support for risk analysis [18], and goal-modelling 
approaches [19]. This work has also attempted to integrate existing e.orts on meta-modelling for risk 
anal­ysis. On .rst inspection, this helps capture contextual in­formation such as scenarios, and how 
stakeholder beliefs and goals contribute to speci.cation and design decisions implicitly supporting the 
capture of usability as well as risk and requirements data. Closer inspection, however, in­dicates that 
certain concepts are missing and others need re-evaluating.  2.2 Contexts of Use For systems to be situated 
in their environments, they need to be designed with their contexts of use in mind; these are the users, 
tasks, equipment, and social and physical en­vironments where a system is used [20]. While the notion 
of Context of Use is key within Usability Engineering, it is largely unused in Requirements Engineering. 
For example, Ali et al. [21] considered how the notion of context can be used to integrate goal, Problem 
Frame, and feature models, but this work is limited to using a textual context descrip­tion to guide 
analysis decisions. Attempts have been made by the HCI (Human Computer Interaction) community to integrate 
data about context of use into the larger design process [22]. This work found that di.erent models are 
better at representing di.erent aspects of context of use than others, and that contexts of use should 
be modelled as entities in their own right. 2.3 Concept Alignment Challenges A key issue in aligning 
Security Requirements Engineer­ing with Usability Engineering is understanding how a given concept may 
have a di.erent importance or meaning de­pending on whether a usability, security or requirements perspective 
is taken. For example, we may agree that a goal represents a statement of intent; but intent with respect 
to what and whom? Does a goal represent the intentions of somebody using the system, somebody designing 
the sys­tem, or someone with the task of turning a goal into work­ing software? Di.erent levels of emphasis 
may be placed on these potentially ambiguous terms. A security engineer may be happy to assume that a 
user operates a control, a requirements engineer may want to know more about the roles ful.lled by that 
user, but a usability engineer needs to understand the human characteristics of the user, his or her 
behaviour, and the context within which the system is used. A further area that needs clari.cation is 
the relationship between people and their values, and goals. Contemporary thinking in HCI [23] argues 
that while human values remain core to usability, our changing relationship with technology means determining 
what these might be is harder than ever. The interaction between people and the system works on many 
di.erent levels, each of which provides di.erent oppor­tunities for interaction. These opportunities 
are, however, deeply contextual and based not only on the person, but the physical or social environment 
surrounding the interac­tion. While goal-oriented approaches are useful for reasoning about system requirements, 
they capture little contextual information, and cast people as abstract actors and roles. We would argue 
that this is a good state of a.airs: goals are a useful vehicle for re.ning and specifying requirements, 
but we do not believe they are the right tool for capturing empirical usability data. Hinds [24] suggests 
that we should consider empirical data as clues to the true nature of requirements; these require­ments 
exist in the problem domain independently of stake­holders. This position implies that concepts relating 
to the elicitation of empirical data should be disjoint from those used to specify goals and requirements. 
However, stakehold­ers still need to understand the rationale behind requirement speci.cation decisions, 
which necessitates traceability from empirical usability data to goals and requirements. There­fore, 
we need to devise a conceptual model which describes how usability artifacts relate to requirements artifacts. 
  3. IRIS META-MODEL The IRIS meta-model is a conceptual model for usable secure requirements engineering. 
This meta-model extends existing work in Security Requirements Engineering in two ways. First, concepts 
are included which allow the usability of tasks, and the usability impact of security design decisions 
to be modelled. Second, the meta-model explicitly de.nes concepts and associations which allow a context 
of use to be modelled. Two guiding principles were followed when devising the IRIS meta-model. First, 
where possible, we extend related meta-models in Security Requirements Engineering so as to reuse existing 
concepts. Second, we apply as much parsi­mony as possible when declaring model concepts; in some cases, 
this involves simplifying relationships to make the conceptual associations clearer. For example, in 
the risk meta-model (section 3.3), we de.ne a risk as a combination of a single threat and vulnerability. 
This di.ers from the ISSRM concept of risk, which combines a single cause with one or more impacts, where 
a cause is associated with a sin­gle threat and one or more vulnerabilities. As section 3.3 will illustrate, 
supplemental concepts are used to capture the knowledge lost by removing these concepts. For clarity, 
we have sub-divided the meta-model into .ve views. Four of these Task, Goal, Risk, and Responsibility 
correspond to di.erent perspectives of a secure system s context of use. The .fth centres on the axial 
concept of En­ Figure 1: Task Meta-Model  1..* * Persona 11 1 4  vironment. By introducing the environment 
as a conceptual type, and allowing other concepts to be associated with it, we can develop complete models 
of a context of use. Cross-cutting each of these views is the concept of As­set, which represents artifacts 
which must be safeguarded by the system being speci.ed; these may also represent com­ponents forming 
part of the system. Because stakeholders value certain properties of an asset over others, we asso­ciate 
one or more security attributes to each asset; these at­tributes re.ect the security properties that 
stakeholders wish to preserve in the system being speci.ed; these attributes are Con.dentiality, Integrity, 
Availability, and Accountabil­ity. Each attribute is assigned a value of Low, Medium, or High, and each 
type of value should be agreed before being used. Closely associated with Asset is the additional cross­cutting 
concept of Task, which represents work being carried out within a context of use. Subsequent sections 
will illus­trate how information about tasks can be used to measure the usability impact of security 
design decisions. 3.1 Task Meta-Model The Task Meta-Model, illustrated in .gure 1, captures el­ements 
describing how people carry out work in the system being speci.ed. Rather than a description of a system 
oper­ative like user and administrator, IRIS characterises people using personas. A persona is a descriptive 
model of how in­dicative users behave, think, what they wish to accomplish, and why [25]. Personas sensitise 
participants to the con­text of use and, through the interplay between personas and their tasks, help 
identify assets, threats, and vulnerabilities which would otherwise be missed. Personas are developed 
from rich empirical data about stakeholders and their con­texts; this means few assumptions need to be 
made about how people ful.l di.erent roles, thereby reducing the risk of ambiguity about operatives being 
introduced into the anal­ysis process. As well as an informal objective the persona wants to meet, a 
task is composed of a textual scenario describing how the persona carries out some work associated with 
the sys­tem being speci.ed. Each task aggregates one or more per­sonas and, for each associated persona, 
usability attributes are speci.ed. These attributes are de.ned from the per­spective of the persona, 
and describe how well the work in the task meets implicit usability goals of e.ciency (how ef­.cient 
does the persona .nd the task), e.ectiveness (how ef­fective is the task at meeting its objective), and 
satisfaction (how happy does the persona feel about the task). These attributes are elicited by assigning 
categorical values relat­ing to task duration, task frequency, task demand, and the task s support for 
the persona s intentions. When describing tasks, it may become apparent that certain assets use or con­strain 
tasks. To re.ect this, the meta-model allows assets to be associated with tasks, enabling traceability 
between tasks and models where these assets are present. Figure 2: Goal Meta-Model Asset Domain Property 
* **  * * * Requirement * * *  ***  * * * * *  3.2 Goal Meta-Model Many concepts in the Goal Meta-Model, 
illustrated in .g­ure 2, are based on the KAOS (Knowledge Acquisition in au­tOmated Speci.cation) method 
[26]. KAOS was chosen over alternative goal-oriented notations for two reasons. First, unlike i* [15] 
derived approaches, KAOS de.nes goals as prescriptive descriptions of system intent. Because goal and 
requirement analysis is already carried out in the context of personas and tasks, we use goals as a vehicle 
for re.ning requirements, rather than understanding the intent of ac­tors. Second, as Van Lamsweerde 
reports [14], the KAOS modelling notation is compliant with UML and, by exten­sion, compatible with modelling 
notations commonly found in industry. In IRIS, we de.ne a goal as a prescriptive statement of in­tent 
that the system should satisfy through the co-operation of its agents [14]. This de.nition of a goal 
appeals to the objectivity of the speci.cation being developed as opposed to the subjectivity of analysis 
which informs usability at­tributes (section 3.1) and security attributes (section 3.3). In KAOS, requirements 
are re.ned goals under the respon­sibility of a single agent. We choose to make the distinction between 
goal and requirement explicit by treating the latter as an independent concept. This has a number of 
bene.ts. First, requirements may arise during analysis independent of any goal re.nement or discussion 
about tasks. Second, although not recommended, requirements and risk analysis can be divorced from goal 
modelling; this may be useful if neither analysts nor developers have any knowledge of goal­oriented 
techniques. Domain properties are descriptive statements about the problem world [14]. In IRIS, we use 
these to capture as­sumptions satis.ed by the system, or requirements which must hold to achieve requirements, 
but are outside of the scope of the system being speci.ed. Speci.cations derived from IRIS are based 
on a .xed scope, but goal modelling may lead to the elicitation of important out-of-scope require­ments. 
If these requirements are not speci.ed elsewhere, as­suming these requirements must hold by de.ning them 
as domain properties is useful for ensuring they are not forgot­ten. Assets or environments may be associated 
with zero or more requirements. When associated with assets, the re­quirements reference or constrain 
an asset; this is typically the case when a security requirement acts as a constraint. This is similar 
to the approach taken by the Problem Frames approach where requirements reference certain phenomena in 
problem diagrams [27]; this reference indicates that a re­quirement references or constrains the related 
domain in the context being modelled. In certain cases, however, require­ Figure 3: Risk Meta-Model 
 * 1..4 Security 0..4 Attribute ments may be elicited which do not relate to assets. These may be requirements 
re.ned from a goal, non-functional requirements which a.ect the system in general, or a re­quirement 
implying functionality which does not yet exist. In such cases, associating a requirement with the environ­ment 
stimulating its elicitation may be useful if the require­ment needs to be categorised for some reason, 
e.g. a re­quirement speci.cation is generated and requirements need to be grouped based on the environments 
they relate to. By de.ning these associations as aggregations, we indicate that tool-support implementing 
this meta-model should not remove these requirements if the associated asset or envi­ronment is removed; 
these requirements may be associated with otherassetsorenvironments. In addition to being re.ned to sub-goals, 
requirements, and operationalised as tasks, goals in KAOS may con.ict with obstacles; obstacles are conditions 
representing unde­sired behaviour and prevent an associated goal from being achieved [28]. By re.ning 
obstacles, candidate threats and vulnerabilities may be de.ned. This approach is similar, but not identical 
to, Van Lamsweerde s concept of anti-goals [29]. While anti-goals arise exclusively from malicious intent, 
obstacles may arise from accidental error as well.  3.3 Risk Meta-Model The Risk Meta-Model, illustrated 
in .gure 3, models the elements contributing to the de.nition of risks; it also incor­porates concepts 
for responding and mitigating these risks. A single risk aggregates a single threat and vulnerabil­ity. 
This re.ects a threat exploiting a vulnerability; threats target assets and vulnerabilities expose their 
weaknesses. Threats arise from the motives and capabilities de.ned for the attackers behind them. Many 
of these possible motives and capabilities are known from the many reports in the literature and media. 
The attackers behind a threat target assets with respect to the properties they want to exploit. When 
a threat is de.ned, security attributes are associated with it depending on the assets the attacker wants 
to ex­ploit and how much they want to exploit them by. For each de.ned risk, a Misuse Case must also 
be speci.ed; these are used to describe risk impact. While the traditional view of Misuse Cases is that 
they threaten Use Cases, this view contests the idea that threats target assets, and not just con­texts 
of use in general. By narrating a risk s impact using Figure 4: Responsibility Meta-Model a scenario, 
Misuse Cases not only place the risk in a hu­man context, it also sanity checks the analysis contributing 
to the de.nition of a risk, justifying its threat and vulner­ability, the related likelihood and severity 
values, and the security attributes for these assets. Risks may be treated in di.erent ways. Risks can 
be ac­cepted if we are prepared to accept the consequence of its impact, transferred if the responsibility 
for dealing with it is out of scope, or mitigated if treating the risk has a bear­ing on the system speci.cation. 
Strategies for mitigating a risk may be preventing or avoiding it, detecting it, or react­ing to it. 
Choosing to mitigate a response is synonymous to intentionally specifying that the system shall manage 
the risk as part of its design. Consequently, we can associate goals with mitigating responses. As section 
3.2 indicates, these goals can be analysed and re.ned to requirements mit­igating this goal. Countermeasures 
can then be de.ned to meet these requirements, and, should we choose to incorpo­rate them in the speci.cation, 
assets can be associated with these countermeasures. If countermeasures target threats, and these countermeasures 
are considered e.ective at re­ducing the value of the security attributes an attacker might hold about 
the threatened assets, these can also be de.ned at the countermeasure level.  3.4 Responsibility Meta-Model 
Roles are a pervasive concept within IRIS. Attackers and personas are associated with one or more roles. 
Roles may also become responsible for risk responses transferred to them, or countermeasures they are 
required to maintain. These responsibility relationships are captured by the Re­sponsibility Meta-Model, 
illustrated in .gure 4. IRIS distinguishes between representations of human per­sonas &#38; attackers 
and roles for two reasons. First, by al­locating responsibilities to roles, we can identify personas 
that may become overloaded with roles, or roles which may be dispersed among several personas; these 
cases can lead to security responsibilities becoming neglected. Second, at­tackers and personas may share 
certain roles, allowing us to consider the evolution of a lawful stakeholder to an inside attacker. Because 
countermeasures are assigned to roles, roles are associated with personas, and personas participate in 
tasks, the meta-model facilitates exploring the usability impact of countermeasure design decisions. 
This is possible if a coun­termeasure assigned to a role within a given context of use is Figure 5: 
Environment Meta-Model Obstacle shared by a persona participating in one or more tasks in the same context 
of use. Where this occurs, usability attributes may be associated with the persona-task pairing to indicate 
how much the countermeasure helps or hinders the persona in the associated task. This is described in 
more detail in [30]. Although goals de.ne how the intent of a system is re.ned to a requirements speci.cation, 
it is also important to un­derstand how these goals laterally relate to other concepts; this knowledge 
is captured using dependency relationships. Ternaryassociationsdescribehowonerole(thedepender), relates 
on another (the dependee), for a task, goal, or asset (the dependum). The dependency relationships in 
IRIS are based on the dependency links used by i* [15]; Van Lam­sweerde [14] describes how these relationships 
can also be used in KAOS to supplement agent responsibility modelling.  3.5 Environment Meta-Model Many 
concepts speci.ed in the IRIS Meta-Model are sit­uated within one or more environments as illustrated 
in .g­ure 5. Together, these concepts represent a Context of Use. Some of these concepts are de.ned explicitly 
within an en­vironment; an asset may have di.erent security attributes based on the prevailing environment, 
and some goals may exist in one environment and not in another. Other concepts are implicitly situated 
within an environment by virtue of their dependencies. For example, a risk may only be de.ned if the 
contributing threat and vulnerability exist in the same environments. Some concepts are not situated 
within an environment. A system is speci.ed with a single set of requirements ir­respective of the environments 
the system must operate in. Similarly, we don t assume a role ful.lled by a human agent will vary by 
environment. While the role may not vary, the perceptions of the human ful.lling it can; this explains 
why a persona exists within an environment, but a role does not.  4. CASE STUDY Water and sewage treatment 
is controlled by a substantial amount of control software. This software runs on many dif­ferent devices 
and locations across a wide geographic area. As part of their responsibility for maintaining the water 
net­work, instrument technicians often make software modi.ca­tions to telemetry outstations, PLCs (Programmable 
Logic Controllers), and SCADA (Supervisory Control and Data Acquisition) workstations. Without a central 
strategy for controlling such software, water treatment integrity may be compromised if software is lost, 
or incorrect software is ac­cidentally, or deliberately, installed on critical instrumenta­tion. However, 
because maintaining the water network can be physically and mentally demanding, any new technology needs 
to be situated for the contexts within which these technicians work. We validated the IRIS Meta-Model 
by using it to support the speci.cation of requirements for a central repository for control software; 
this repository will be used to support in­strument technicians at a UK water company. After holding 
an initial scoping workshop, empirical data was collected by interviewing various stakeholders, and ob­serving 
real instrument technicians. After analysing this empirical data, the behavioural characteristics of 
potential users were identi.ed based on the work they need to use the software repository for. Several 
participatory workshops were then used to elicit the di.erent elements of the meta­model; participants 
included instrument technicians, soft­ware engineers, IT support sta., and information security o.cers. 
The elicited data was captured by a software tool building upon this meta-model. After analysing the 
empirical data, two di.erent environ­ments were elicited. The .rst of these, Planned, encapsu­lated a 
repository context of use during working hours when infrastructure modi.cations are scheduled in advance. 
The second environment, Unplanned, encapsulated a repository context of use when the infrastructure is 
modi.ed due to an out-of-hours emergency. For reasons of brevity, this section focuses only on the Planned 
environment. Because the page limit forbids a detailed report of the design process used, fur­ther details 
of this case study will be elaborated in a future publication. 4.1 Task Analysis Based on the empirical 
data, three personas were elicited. Barry represented an instrument technician who modi.es software as 
part of this day-to-day work. Alan represented a commissioning engineer responsible for developing initial 
releases of PLC software. Eric represented an engineer work­ing in a 2nd line support capacity. Of these 
representations, Barry was the primary persona the repository needed to be designed for. Several tasks 
in the case study involved Barry making in­frastructure changes to plant equipment; this work led to 
control software modi.cations and, consequently, interac­tion with the software repository. Although 
conceptually very similar, tasks were distinct enough for some to be less usable than others. For example, 
from Barry s perspective, outstation modi.cations are easier, quicker, involve fewer .le changes, and 
considered less operationally critical than changes to PLCs. Knowledge about these di.erences was not 
initially known by many workshop participants. Con­sequently, authoring the scenario for this task, and 
de.ning the associated assets led to discussion on the usability im­pact of some design decisions.  
4.2 Goal and Requirement Elicitation The scope of the case study was limited to con.guration management 
of control software, but the tasks assumed cer­tain software tools were installed on laptops used by 
instru­ment technicians. To ensure this interface requirement was not lost, this was captured as a domain 
property. Require­ments were also speci.ed which were not directly associated with an asset. For example, 
a requirement was speci.ed and associated with the Planned environment; this indicated that software 
tools to interface with plant hardware an out­of-scope asset needed to be installed as a pre-requisite 
for repository access. One of the goals the repository needed to support was the download of particular 
items of control software; this re.ned to a sub-goal stating that an instrument technician needs to be 
authorised to download software for a given geographic area. Participants chose to obstruct this goal 
by stipulating that a user can download software he is not authorised for. Re.ning this obstacle led 
to the identi.cation of a number of vulnerabilities; these included the sharing of login creden­tials, 
and unwarranted access to a technician s laptop. Some goals were re.ned on a top-down basis. However, 
many were re.ned by de.ning the tasks, followed by the goals and requirements which have to be speci.ed 
before personas can carry them out securely and without undue hindrance. 4.3 Risk Analysis Before the 
assets were de.ned, values of Low, Medium, and High were associated with No a.ect on performance, quality, 
or pollution, Part failure does not a.ect quality of site or .ow,and Critical to the business or the 
quality of the site respectively. Assets were elicited from task analysis, goal modelling, and general 
discussion. Assets for di.erent types of software were associated with security attributes based on their 
criticality; some software assets were associ­ated with low integrity, availability, and accountability 
at­tributes, while others were de.ned as being high. Attackers were de.ned based on participants concerns. 
For example, the fear of malicious insiders led to the de.ni­tion of a disgruntled instrument technician 
attacker. Based on their domain knowledge, several motives and capabilities were associated with this 
inside attacker. When the PLC software asset was originally de.ned, par­ticipants indicated that the 
security attributes they wished to preserve for this asset were integrity and availability. Later in 
the analysis, a risk was de.ned which explored how an inside attacker might plant a logic bomb in this 
software to compromise the water treatment process. In addition to tampering with the software, the attacker 
was keen on cov­ering his tracks, thereby introducing an accountability at­tribute to the related threat. 
When a risk incorporating this threat was de.ned, together with its associated Misuse Case, the importance 
of PLC software accountability was noted, and an accountability attribute was retrospectively added to 
it. This risk was treated with a detective mitigation re­sponse, such that occurrences of this risk would 
be detected after the event and, based on this, an associated goal was de.ned. Following goal-re.nement, 
requirements for peer­reviewing PLC software changes were elicited. Based on these requirements, a software 
component linking the work­system to the repository was de.ned as a countermeasure; this ensured that 
the instrument technician making these change would not be assigned as a peer reviewer. A new asset was 
de.ned based on this countermeasure, and an ac­countability security attribute associated with it. 4.4 
Responsibility Modelling Because personas perform tasks, and certain roles took re­sponsibility for implementing 
countermeasures, several role­responsibility associations were present. Based on the restricted scope 
of the system being speci­.ed, the roles in this study were limited to Instrument Tech­nicians and Engineers 
providing 2nd-line support. Depen­dency relationships were modelled where an Engineer de­pends on an 
Instrument Technician for the di.erent software modi.cation tasks. Engineers are responsible for perform­ing 
the task of auditing software changes, but this is not possible until an Instrument Technician completes 
the work requiring audit. The countermeasure de.ned in section 4.3 not only miti­gated the logic bomb 
threat, it helped improve the usability of the software modi.cation task to Barry. This improve­ment 
arose because submitting a software modi.cation to the repository also led to data being automatically 
updated in the work scheduling system, thereby reducing the demand of Barry s software modi.cation task. 
  5. CONCLUSION There is a need for support when specifying systems which need to be secure and situated 
for their many contexts of use. Risk analysis supports the speci.cation of such systems, but this analysis 
needs to be better informed by human factors, and better integrated into the requirements engineering 
pro­cess. To meet this need, we have presented a meta-model for usable secure requirements engineering. 
We have built upon existing conceptual risk-based Security Requirements Engineering meta-models by introducing 
concepts which fa­cilitate the modelling of a system s di.erent contexts of use. We have also validated 
this contribution by applying it to a case study, which demonstrates how our work can be used to tackle 
contemporary security problems of national and international interest. Although the results of risk mitigation 
in section 4 had a positive outcome to the security and usability of the system, assets arising from 
countermeasures may introduce new vul­nerabilities, become open to new or existing threats, or com­plicate 
other tasks. In related work [30], we have devised an approach for qualitatively and quantitatively analysing 
the results of risk and task analysis. By leveraging the concep­tual relationships in the IRIS Meta-Model, 
together with values assigned to tasks, assets, threats, vulnerabilities, and countermeasures, we can 
infer qualitative categories for risk, and quantitative scores for risks and tasks; these can be used 
to support visualisation of on-going security and usability analysis, especially as models become more 
developed.  6. ACKNOWLEDGEMENTS The research described in this paper was funded by EP-SRC CASE Studentship 
R07437/CN001. We are very grate­ful to Qinetiq Ltd for their sponsorship of this work. We are also grateful 
to the Oxford University Computing Labora­tory Security Reading Group and the anonymous reviewers for 
their insightful comments when reviewing this work.  7. REFERENCES <RefA>[1] A Kerckho.s, La cryptographie 
militaire , Journal des Sciences Militaires, pp. 5 38, 1883. [2] J.H. Saltzer and M.D. Schroeder, The 
protection of information in computer systems , Proceedings of the IEEE, vol. 63, no. 9, pp. 1278 1308, 
Sept. 1975. [3] A Adams and MA Sasse, Users are not the enemy , Communications of the ACM, vol. 42, pp. 
41 46, 1999. [4] Alma Whitten and J. D. Tygar, Why Johnny can t encrypt: a usability evaluation of PGP 
5.0 , in SSYM 99: Proceedings of the 8th conference on USENIX Security Symposium, Berkeley, CA, USA, 
1999, pp. 14 14, USENIX Association. [5] Ross Anderson and Shailendra Fuloria, Security economics and 
critical national infrastructure , in Eight Workshop on the Economics of Information Security (WEIS 
2009), 2009. [6] Pamela Zave and Michael Jackson, Four dark corners of requirements engineering , ACM 
Trans. Softw. Eng. Methodol., vol. 6, no. 1, pp. 1 30, 1997. [7] Betty H. C. Cheng and Joanne M. Atlee, 
Research directions in requirements engineering , in FOSE 07: 2007 Future of Software Engineering, Washington, 
DC, USA, 2007, pp. 285 303, IEEE Computer Society. [8] D. Firesmith, Specifying reusable security requirements 
, Journal of Object Technology,vol.3, no. 1, pp. 61 75, 2004. [9] Daniel Mellado, Eduardo Fern´andez-Medina, 
and Mario Piattini, A common criteria based security requirements engineering process for the development 
of secure information systems , Computer Standards &#38; Interfaces, vol. 29, no. 2, pp. 244 253, 2007. 
[10] Nicolas Mayer, Model-based Management of Information System Security Risk, PhD thesis, University 
of Namur, 2009. [11] D. Diaper, Understanding Task Analysis for Human-Computer Interaction , in The Handbook 
of Task Analysis for Human-Computer Interaction,Dan Diaper and Neville A. Stanton, Eds., pp. 5 47. Lawrence 
Erlbaum Associates, 2004. [12] Ian. F. Alexander and Neil Maiden, Eds., Scenarios, Stories, Use Cases: 
Through the Systems Development Life-Cycle, John Wiley &#38; Sons Ltd, 2004. [13] Ian Alexander, Negative 
scenarios and misuse cases , in Scenarios, Stories, Use Cases: Through the Systems Development Life-Cycle, 
Ian. F. Alexander and Neil Maiden, Eds. John Wiley &#38; Sons Ltd, 2004. [14] A. van Lamsweerde, Requirements 
engineering: from system goals to UML models to software speci.cations, John Wiley, Hoboken, NJ, 2009. 
[15] Eric Yu, Modeling Strategic Relationships for Process Reengineering, PhD thesis, University of Toronto, 
1995. [16] Axel van Lamsweerde, Elaborating security requirements by construction of intentional anti-models 
, in ICSE 04: Proceedings of the 26th International Conference on Software Engineering, Washington, DC, 
USA, 2004, pp. 148 157, IEEE Computer Society. [17] Golnaz Elahi, Eric Yu, and Nicola Zannone, A vulnerability-centric 
requirements engineering framework: analyzing security attacks, countermeasures, and requirements based 
on vulnerabilities , Requirements Engineering, vol. 15, no. 1, pp. 41 62, 2010. [18] R. Matulevi.cius,N.Mayer,andP. 
Heymans, Alignment of misuse cases with security risk management , Availability, Reliability and Security, 
2008. ARES 08. Third International Conference on, pp. 1397 1404, March 2008. [19] Raimundas Matulevi.cius, 
Nicolas Mayer, Haralambos Mouratidis, Eric Dubois, Patrick Heymans, and Nicolas Genon, Adapting Secure 
Tropos for Security Risk Management in the Early Phases of Information Systems Development , in CAiSE 
08: Proceedings of the 20th international conference on Advanced Information Systems Engineering, Berlin, 
Heidelberg, 2008, pp. 541 555, Springer-Verlag. [20] ISO/IEC 13407: Human-Centered Design Processes for 
Interactive Systems, ISO/IEC, 1999. [21] Raian Ali, Yijun Yu, Ruzanna Chitchyan, Armstrong Nhlabatsi, 
and Paolo Giorgini, Towards a Uni.ed Framework for Contextual Variability in Requirements , 3rd International 
Workshop on Software Product Management (IWSPM09), Atlanta, USA, 2009. [22] Gilbert Cockton, Grounded 
design: Integrating models and evaluation , Interactinginthelarge: Developing a framework for integrating 
models in HCI, ACM CHI 99 Workshop, 1999. [23] Abigail Sellen, Yvonne Rogers, Richard Harper, and Tom 
Rodden, Re.ecting human values in the digital age , Commun. ACM, vol. 52, no. 3, pp. 58 66, 2009. [24] 
Chris Hinds, The case against a positivist philosophy of requirements engineering , Requirements Engineering, 
vol. 13, no. 4, pp. 315 328, 2008. [25] Alan Cooper, Robert Reimann, and David Cronin, About Face 3: 
The Essentials of Interaction Design, Wiley, 2007. [26] Anne Dardenne, Axel van Lamsweerde, and Stephen 
Fickas, Goal-directed requirements acquisition , Science of Computer Programming, vol. 20, no. 1-2, pp. 
3 50, 1993. [27] M. A Jackson, Problem frames : analysing and structuring software development problems, 
Addison-Wesley/ACM Press, Harlow, England, 2001. [28] A. van Lamsweerde and E. Letier, Handling obstacles 
in goal-oriented requirements engineering , Software Engineering, IEEE Transactions on, vol. 26, no. 
10, pp. 978 1005, 2000. [29] Axel van Lamsweerde, Elaborating security requirements by construction of 
intentional anti-models , in ICSE 04: Proceedings of the 26th International Conference on Software Engineering, 
Washington, DC, USA, 2004, pp. 148 157, IEEE Computer Society. [30] Shamal Faily and Ivan Fl´echais, 
Analysing and Visualising Security and Usability in IRIS , in Availability, Reliability and Security, 
2010. ARES 10. Fifth International Conference on, 2010.</RefA>  
			
