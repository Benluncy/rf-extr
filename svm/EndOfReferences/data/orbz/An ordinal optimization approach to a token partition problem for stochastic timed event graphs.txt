
 Proceedings of the 1994 Winter Simulation Conference ed. J. D. Tew, S. Manivannan, D. A. Sadowski, and 
A. F. Seila AN ORDINAL OPTIMIZATION APPROACH TO A TOKEN PARTITION PROBLEM FOR STOCHASTIC TIMED EVENT 
GRAPHS Xiaolan Xie INRIA Technop61e Metz 2000,57070 Metz, FRANCE ABSTRACT The paper addresses the 
optimal partition of tokens in stochastic timed event graphs. The transition firing times are random 
variables with geneml distribution. The problem consists in choosing an initial marking among a large 
set of candidate initial markings such that a criterion function (linear or nonlinear) of the initial 
marking and the average cycle time is minimized. We propose a simulation-based ordinal optimization algorithm 
for solving this problem. The algorithm simultaneously simulates a set of event graphs, each has a candidate 
initial marking as its initial marking. The most important feature of this approach is the capability 
of identifying with very short simulation run the candidate initial mar~ings which can hardly be optimal 
solutions. Significant computation time saving is realized by stopping the simulation of the related 
nets at appropriate time. 1. INTRODUCTION Optimization in discrete solution space becomes more and more 
important for discrete event dynamic systems. There are numerous potential applications such as production 
capacity and buffer capacity dimensioning in manufacturing systems. The only general enough tool for 
evaluating such systems is the simulation. Due to the lack of viable optimization approaches, empirical 
and sometime blind solution search approaches are used. The purpose of this paper is to propose an ordinal 
optimization approach to a token partition problem for stochastic timed event graphs. In such a system, 
the average cycle time (I/throughput rate) is function of the token partition. The problem consists in 
choosing one among a set of candidate initial markings in order to minimize a criterion which is a (linear 
or non-linear) function of the initial marking and the average cycle time. A new ordinal optimization 
approach is proposed. This approach simultaneously simulates different candidate initial markings. Distributions 
of their average cycle times are estimated along the simulation and arc used to evaluate the probability 
for a candidate initial marking to be optimal. The candidate initial markings whose probability to be 
optimal are low are discarded at appropriate points of the simulation. This approach is applied to the 
kanban distribution determination for a four-machines serial systems. Optimal solutions are obtained 
in all test examples which contain 36 candidate initial markings. Closely related to this work are works 
on the marking optimization problems for deterministic event graphs (Laftit, Proth, Xie 1992) and stochastic 
timed event graphs (Proth, Sauer, Wardi, and Xie 1993). The marking optimization problem consists in 
finding an initial marking such that a given cycle time is obtained while a linear p-invariant criterion 
is minimized. This problem can be considered as a special case of the new token partition problem. This 
paper is organized as follows. Section 2 contains notations about the stochastic timed event graphs and 
some preliminary results. Section 3 defines the new token partition problem and proposes a parallel simulation 
algorithm. Based on this algorithm, Section 4 proposes an ordinal optimization approach. Section 5 applies 
the ordinal optimization approach to the optimal kanban distribution determination of a four-machines 
serial systems. Section 6 is a conclusion. 2. STOCHASTIC TIMED EVENT GRAPHS Let N = (P, T, F) be the 
strongly connected event graph considered. P is the set of places, T is the set of transitions, and F 
g (!P x T) u (T x P) is the set of directed arcs connecting places to transitions and transitions to 
places. We denote by M the initial marking of N. We assume that no transition can be fired by more than 
one token at any time. This implies that there is a self loop place with one token related to each transition, 
i.e. (t, t) e T and %f((t,t)) = 1, V t e T where (t, s) indicates the place connecting transition t to 
transition s. As a result, the set of places P can be written as T= P u Pt where Pt denotes the set of 
self loop places and P the other places. Furthermore, since !lf((t,t)) = 1, V t = T, only the marking 
of the places belonging to P will be considered. Since N is an event graph, each place has exactly one 
input transition and one output transition. Without loss 581 of generality, we assume that there exists 
at most one place between any two transitions. The following notations will be used : in(t): set of transitions 
which immediately precede transition t, i.e. in(t)= ~t) (t, s): place connecting transition t tos M: 
initial marking of the places in P Xt(k) : time required for the k-th firing oft St(k): starting time 
of the k-th firing oft Dt(k): termination time of the k-th firing of t By convention, Xt(k) = O, V ks 
O and St(k)= O, V k s O. As shown in Chretienne (1983), St(k) can be determined by the following recursive 
equations: St(k) = ~~lt) {DT(k -M((t,t)))] (1) with Dt(k) = St(k) + Xt(k), Vt e T,Vk 20 We assume that 
{Xt(k)};=l for all t e T are mutually independent sequences of i.i.d, integrable r.v.s. It was proven 
by Baccelli (1992) that ~im St(n) _ ~im E[St(n)] = Z(M) a s . . (2) n+= n n-+. n for all transition 
t where rc(M) is the average cycle time of the event graph. Since any stochastic timed event graph is 
completely characterized by its net structure, its initial marking and the firing time sequences, it 
can be denoted by the triplet SPN = (N, M, {Xt(k)]). Let us consider now the simulation of a stochastic 
timed event graph. Thanks to the ergodicity relation (2), we can use the evolution equation (1) to simulate 
a stochastic timed event graph instead of the classical discrete event simulation technique. This approach 
turns out to be more efficient than the discrete simulation technique. ALGORITHM Al (Simulation of an 
event graph) 1. Choose a simulation cycle K. 2. Compute a sequence of transitions ($1, .... rJITI) 
 firablc from the initial marking M in which each transition appears exactly once. 3.SetSt(k) :=O,for 
allt=Tandfor atlkSO. 4. Fork=l toKdo 4.1. Generate the r.v.s Xt(k) for all t c T 4.2. For t = 01 to ~lTl, 
compute St(k) using equation (1) 5. z(MO) = SCl(K)/K The existence of the sequence (o 1, .... ~lTl) 
was proved by Commoner, Holt, Even, and Pnueli (1971). Since (01, .... OITl) is firable from M, the k-th 
firing of any transition t = ~i is independent of the k-th firings of the transitions ~i+ 1, .... OITI. 
This guarantees the computability of St(k) at step %2. 3. PROBLEM SETTING AND A PARALLEL SIMULATION APPROACH 
 The token partition problem consists in choosing an initial marking among a set of candidate initial 
markings in order to minimize a criterion function of the average cycle time and the initial marking. 
More precisely, ;$Q{F(M, z(M))] (3) where Q = [MI, M2, .... Mn ] is a set of n candidate initial markings 
and F(M,rc(M)) is the criterion function. Let us consider the motivations of this token partition problem. 
When designing a system, a very popular approach consists in first elaborate a set of alternative solutions 
under some technical and economical considerations, then quantify the performance of these solutions 
and finally choose the one with the best performance. Our token partition problem applies to the resources 
dimensioning of a manufacturing system. In the stochastic timed event graph model of such a system, a 
potential solution can be represented by the initial marking. The set of the alternative solutions corresponds 
to the set Q. The value l/n(M) can be considered as the throughput value of the related system or productivity 
rate when manufacturing is concerned. The tokens appeared in the net usually model the resources employed. 
The criterion function F(M,n(M)) quantifies the balance between the total cost of the resources employed 
and the average cycle time obtained. The optimal token partition allows to achieve a good balance between 
two contradictory factors. For problem (3), the lack of closed-form solutions of the average cycle time 
leaves the simulation the only acceptable tool. A natural approach consists in repeating algorithm A 
1 for each element of the candidate solution set Q to obtain an estimate of its average cycle time and 
then choosing the one which minimizes the criterion function. The major drawback of this approach is 
clearly the computation burden as the set of candidate initial markings is usually large. To reduce the 
computational burden, we first propose a parallel simulation algorithm A2 which takes advantage of the 
structure of the event graphs. In this algorithm, SPNi denotes the stochastic timed event graph (N, Mi, 
(Xt(k) 1). Sl,t(k) is the starting time of the k-th firing of transition t of SPNi. n(Mi) is its average 
cycle time, Algorithm A2 (Parallel simulation of n event graphs) 1. Choose a simulation cycle K.  2. 
For each net SPNi, compute a sequence of transitions (~i,l, .... ~i ,ITI) firable from the initial marking 
Mi in which each transition appears exactly once. 3. Set Si,t(k) := O, for all t 6 T, k S 0 and lsiSn. 
 4. Fork=l toKdo  4.1. Generate the r.v.s Xt(k) for all t ~ T 4.2. For i = 1 to n and for t = ~i, 1 
to ~i,lTl, compute Si,t(k) using equation (1)  5. Fori=l tondo  5.1. Compute n(Mi) = Si,t*(K)/K where 
t* is a given transition 5.2. Compute F(Mi, n(Mi)) 6. Determine the optimal solution M*.  As it can 
be remarked, the different SPNS share the same random variable generation in the parallel simulation 
approach while each SPN needs its own random variable generation in the traditional approach. Clearly, 
this advantage disappears if each SPN uses the same pre-generated firing times in traditional approach. 
However, we show in the next section that the computational burden can be significantly reduced by combining 
this parallel simulation algorithm and an ordinal optimization approach. 4. AN ORDINAL OPTIMIZATION APPROACH 
 4.1. Introduction to Ordinal Optimization Let us come back to the algorithm A2. The major drawback of 
algorithm A2 is an implicit self-imposed requirement of accurate enough estimation of the criterion value 
for all candidate initial markings. As a result, long simulation run (i.e. large K) is necessary for 
the convergence of criterion value estimates. The ordinal optimization approaches, first proposed by 
Ho Sreenivas, and Vakili (1992), reduce the computation burden by appropriately relaxing this requirement. 
The primary concern of the ordinal optimization is the rankings of the candidate solutions instead of 
their exact criterion vatues. Numerous simulations conducted by different authors for a wide range of 
problems have shown that the candidate solution rankings stabilize hefore the convergence of the criterion 
value estimates. Ordinal optimization approaches generally simulate simultaneously different candidate 
solutions using common random variable generation. It has been shown by Deng, Ho, and Hu (1992) that 
the resulted correlations between the criterion value estimation errors can only help and increase the 
chance of identifying good solutions very early in the simulation. Approach 583 To significantly reduce 
the simulation time, ordinal optimization approaches typically relax the goal of simulation to the isolation 
of a set of good candidate solutions. The observations of numerous simulation experiments indicate that 
it is possible to determine whether a candidate solution is good or bad very early in the simulation 
with high probability. Typical relaxing goal of existing ordinal optimization approaches is to identify 
a small subset of candidate solutions containing at least one top-r solution with high probability. Estimates 
of this probability has been proposed by Chen (1993) for a class of discrete event systems. Another principle 
of ordinal optimization approaches is the use of different simulation length for different candidate 
solutions. The idea is to discard solutions which can hardly be optimal ones whenever we are confident 
enough. Figure 1 is a typical simulation time distribution when using an ordinal optimization approach. 
simulation ordinal approaches. . I good ,,  I fair I traditional approaches I I pcmr ~  l time 
I + Figure 1: Simulation Length Profile (from Ho and Cassandra (1993)) The main question regarding the 
ordinal approaches is how to determine that a subset of candidate solutions can hardly be optimal ones 
with high probability at a given point of the simulation. This confidence probability problem has been 
addressed by Chen (1993) for a class of discrete event systems. This approach does not apply to our case 
as it cannot handle criteria which are non-linear functions of performance measures.  4.2. Proposed 
Ordinal Optimization Approach 4.2.1. Average Cycle Time Estimation The starting point of our ordinal 
optimization approach is the estimation of the average cycle time at different point of the simulation. 
The approach of Chen (1993) is used and is summarized in the following. We tirst define the following 
quantities: Yi(j) = (Si,t*(j.L) -Si,t*((j-l).L))/L (4) and assume that Yi(j) for j 21 are independent 
samples from a common random variables Yi. This is a wcll­known batched means technique in simulation 
to obtain roughly independent observations (see Mitrani 1982). At any point k = J.L of the simulation, 
the following sample estimate can be derived: Si,t*(J. L) Yi j y ()= (5) J.L j=l From the ergodicity 
property (2), it converges to the exact average cycle time with probability 1, i.e. J E[Yi] = lim ~~Yi(j) 
= ~(Mi), as. (6)J+-J j=l However, at any point of the simulation, the sample estimate is only an approximation 
of the exact average cycle time. The Bayesian approach is used to characterize the exact average cycle 
time ~(Mi). This approach treats as a random variable n(Mi) and derives its posterior distribution based 
the sample path {Yi(l), .... Yi(J)]. A Let ml(J) bea random variable whose distribution is the posterior 
distribution of n(Mi) conditioned on the samples {Yi(l), .... Yi(J)) . Assume that the distribution of 
fii (0) is N(O, V2) for some very large v which implies that there is no prior knowledge about the average 
cycle time. Furthermore, we assume that the distribution of Yi is N(n(Mi), ~i2). It can be easily shown 
that the distribution of fii (J) is also a normal distribution with: ,. E[fii(J)] = ~$Yi(j), Var[fii 
(J)] = $ (7) ,=1 The last obstacle is that the variance ~i2 is unknown. We replace it by its sample 
estimate: 2 -&#38; ,J Yi(J)-~~Yi (J) X[ (8) J=l ,=1 1 4.2.2 Proposed Ordinal Optimization Approach Let 
us first consider a trivial example of 7 candidate solutions. Assume that their criterion value estimates 
follow normal distributions at any point of the simulation. Table 1 contains the mean and the standard 
deviations obtained at a given point of the simulation. Table 1. A Trivial Example No. 1 2 3 4 5 6 7 
E[Fi] 1 2 2.1 2.2 3 4 5 Cri 0.1 0.2 0.2 0.2 2 2 1 The top-3 solutions are candidates 1, 2 and 3. However, 
the probability that candidate 2 or 3 provides better criterion value candidate 1, i.e. F2 < F1 or F3 
< F1, is very small while the probability that F5 < FI or F6 < F1, is not insignificant. As a result, 
we can discard candidates 2, 3, and 7 at this point and further simulate candidates 1, 5 and 6. This 
is what differs our approach and the existing ordinal optimization approaches which always keep all the 
top-r candidates. Instead, the central idea of our approach is to determine a subset of candidate solutions 
which outperforms all other candidate solutions with high enough probability. The ordinal optimization 
algorithm for the token partition problem can be summarized as follows. Algorithm A3 (Ordinal optimization) 
1. Choose a simulation cycle K. 2. For each net SPNi, cOmpute (Oi, 1, . . . . ai,lTl). 3. Set Si,t(k) 
:= O, for all t ~ T, k <0 and l<i<n. 4. Set Q= (Ml, .... Mn). p*= 1.  4. Fork=l toKdo 4.1. Generate 
the r.v.s Xt(k) for all t c T 4.2. For Mi = Q and for t = ~i,l to ~i,lTl, compute Si,t(k) using equation 
(1)  4.3. If k = J . L, update the posterior distribution of ii(J) for all Mi E Q by using (7) and 
(8)  4.4. If IQI> randJ=J .L1 andJ2Jo, select a subset of candidate initiat markings G such that p(G) 
> PO where p(G) is the probability that an optimal solution in G is also optimal in Q. 4.5.IfG#Q,setQ 
=Gandsetp* =p* .p(G) 5.For all Mi = Qdo 5.1. Compute ~(Mi) = Si,t*(K)/K where t* is a given transition 
5.2. Compute F(Mi, n(Mi)) 6. Determine the optimal solution M*.  An Ordinal Optimization Approach 
!585 In this algorithm, at step 4.3, the posterior distribution of the average cycle time is updated 
according to the method presented in section 4.2.1. L is the batch size of the raw data to be grouped 
together. At some regular intervals (i.e. L1 * L), we determine a subset of candidate initial markings 
G such that initial markings in G outperform initial markings in Q -G with probability greater than PO, 
i.e. p(G) 2 PO. Candidate initial markings in Q -G which correspond to not good enough solutions are 
discarded at step 4.4. The integer r is the number of candidate initial markings that can be simulated 
until K. Jo is the number of samples necessary for the variance estimates (8) to be accurate enough. 
p* is the confidence probability for the candidate initial marking M* to be the real optimal. The main 
question regarding this algorithm is the determination of the subset G and p(G). A Monte Carlo method 
is used to solve this problem. For this purpose, a sequence of m samples {Zi,l for l<l<m ] of the random 
variable is generated for each candidate Mi c Q. We then determine p(Mi), the number of times that Mi 
is optimal over all candidates in Q, i.e. F(Mi, Zi,l) = Min{F(Ma,Za,l) for all Ma E Q). We then add the 
candidate initial markings Mi to G in decreasing order of p(Mi) until p(G)= (l/m) ~Mi= ~ p(Mi) 2 Po. 
The computation burden for the generation of {Zi,l for l<l<m ) can be reduced by generating at the initialization 
phase a sequence of samples { zi,l for l<l<m ] of a r.v. with distribution N(O, 1). The sequence {Zi,l 
for l<l<m ] can then be obtained as follows: Zi,l = E[fii(J)] + zi,l.~- (9) 5. OPTIMAL KANBAN DISTRIBUTION 
This section applies the proposed ordinal optimization approach to the optimal kanban distribution determination 
for a four-machines serial system. Its Petri net model (see Xie (1993) for more detail) is given in Figure 
2. Fig. 2: A 4-machine Seriat System The work in process is controlled by kanbans. The manufacturing 
process is decomposed into stages and we assume that each stage corresponds to one operation (or one 
machine). Each stage is assigned a given number of kanbans. A kanban is attached to each part within 
a stage and the kanban is detached from the part when it leaves the stage. Let Kj >0 be the number of 
kanbans assigned to the stage j. We assume that the transportation times between stages are small enough 
and can be neglected. To illustrate the functioning, let us consider the second stage modeled by the 
elementary circuit (p2, t3, p7, t4, p8, t5, p2). place p2 contains as many tokens as free kanbans, the 
place p7 contains as many tokens as kanbans attached to parts waiting to be serviced (including the one 
being serviced) in stage j. Place p8 contains as many tokens as completed parts waiting to be moved to 
the next stage. Transition t4 represents the operation performed in stage 2. It is a timed and recycled 
transition which means that at most one firing can be initiated at any time. The completed parts will 
be transfered to the next stage 3 if free kanbans are available in stage 3, i.e. place p3 contains tokens. 
The transfer of these parts are represented by transition t5. Firings of transition t5 remove tokens 
in places p8 and add them to place p2 which detaches the kanbans attached to the completed parts. The 
kanbans detached from the completed parts become free kanbans. If there are completed parts waiting in 
stage 1, transition t3 fires which attaches one free kanban to each of these parts and moves them to 
stage 2. The total numbers of tokens in the four elementary circuits are invariant under the transition 
firings and are equal to K1, K2, K3 and K4 respectively. The criterion to be minimized is as follows: 
F(M, ~(M)) = ~M(pi) + ~.(C -~(M))+ (lo) i=l Let us consider the set of candidate initial markings to 
be taken into account. For this serial kanban system, Property 4 of Xie (1993) implies that the average 
cycle time depends on the number of kanbans associated to each elementary circuit, i.e. K1, K2, K3 and 
K4 but it does not depend on the exact token distribution. Since ZiM(pi) = K1+K2+K3+K4, we only need 
to consider the set of initial markings ~~ satisfying M(pi) = O, for 5 <i <12. Furthermore, it has been 
proved by Tayur (1992) that for a 4-stage serial system with a given number of kanbans, the average cycle 
time is minimized when K1 = K4 = 1. As a result, we can further limit ourselves to the set of candidate 
initial markings M satisfying M(pI) = M(p4) = 1and M(pi) =O,for 5<i<12.Inthe following, wc consider the 
following 36 initial markings which contain at most 11 tokens: Moo: 1111 OOOOOOOO, M(31:1211OOOOOOOO, 
Mo2:I121OOOOOOOO, M(33:I311OOOOOOOO, M04 :122100000000, Mo5:1131OOOOOOOO, M06:1411OOOOOOOO, Mo7:1321OOOOOOOO, 
Mo8:1231OOOOOOOO, Mo9:1141OOOOOOOO, M10:1511OOOOOOOO, M11:I421OOOOOOOO, M12:1331OOOO()()O(), M13:1241OC)(IC)OOOO, 
M14:1151OOOOOOOO, M15:161100000000, MI6:1521OOOOOOOO, M17:1431OOOOOOOO, M18:I341OOOOOOOO, M19:I251OOOOOOOO, 
M20:l 16100000000, M21:1711O()()()O()OO, M22:162100000000, M23 :153100000000, M24:1441000t)OC)C)tJ, M25:1351OI)OC)OOOO, 
M26:1261O()()O()()()(), M27:1171OOOOO()()(), M28:I811OOOOOOOO, M29:172100000000, M30:163100000000, M31:154100000000, 
M32:1451OOOOOOO(), M33:136100000000, M34:1271OOOOOOOO, M35:I181OOOOOOOO. The corttrol parameters needed 
in the algorithm A3 are as follows :K=20000,L = 100,r=5,JO=9,L1= 5andPO= 0.98. In the remainder of this 
section, we reported numerical results for four different cases. Casel. The firing time distributions 
are as follows. Xt2= 10, Xt4 is exponentially distributed with mean equal to lo,Xt6i suniformlyd istributedon[5, 
15] and Xt8 is a two stage Erlang distributed r.v. with mean equa1t08. C= 10.5 andcx =20. The exact criterion 
values are obtained by algorithm A2 by simulating all candidate solutions until K = 20000. The criterion 
values of these candidate initial markings are given in the following in non-increasing order of the 
criterion value: (30 20.82) (31 21.76) (23 22.59) (29 23.23) (22 24.22) (24 24.91) (32 25.09) (17 25.80) 
(16 26.07) (11 29.32) (18 30.44) (25 30.73) (12 31.26) (33 31.45) (7 34.90) (28 38.98) (21 39.21) (1540.01) 
(lo 41.57) (13 41.60) (19 42.13) (8 42.21) (26 42.97) (34 43.92) (6 44.66) (4 46.08) (3 50.88) (1 63.48) 
(5 71.09) (9 71.34) (14 72.14) (20 73.11) (2 73.97) (27 74.1 1) (35 75.11) (O 95.16) where the first 
number in any couple indicates the candidate marking and the second one indicates the criterion value. 
Let us report the result of the ordinal optimization algorithm A3. At iteration k = 600 and 1=5, the 
following criterion values are obtained: (30 15.96)* (31 16.39)* (23 17.56)* (29 19.28)* (32 19.51) (24 
19.51)* (22 19.98) (17 20.64)* (16 21.21)* (18 24.27) (25 24.52) (11 24.83) (12 25.23)* (33 25.30)* (7 
29.66)* (13 34.78) (19 35.32) (8 35.78) (26 36.27) (34 37.27) (4 40.51) (28 40.84) (21 40.91) (15 41.05) 
(10 41.64) (6 44.76) (3 49.60)* (1 60.51)* (5 65.99)* (9 66.77)* (14 67.77)* (2 68.51) (20 68.77) (27 
69.77)* (35 70.77)* (O 93.71)*. Surprisingly, a large number of candidate markings (see marked candidate 
markings) are ranked correctly although the criterion values are far from stable. The same observation 
is made for other cases. This confirms observations made by other authors. The criterion values obtained 
at iteration k = 1100 and 1=11 are as follows: (30 17.98) (31 18.99) (23 20.05) (29 21 .52) (32 22.22) 
(24 22.33) (22 22.53) (17 23.46 ) (16 24.28) (25 27.31) (18 27.48) (11 27.77 ) (33 27.83) (12 28.44) 
(7 32.61) (13 37.49) (19 37.84) (26 38.45) (8 38.56) (34 39.45) (28 41.52) (21 41.59) (15 42.13) (10 
42.97) (4 43.05) (6 45.85) (3 50.89) (1 62.01 ) (5 66.23) (9 66.73) (14 67.54) (20 68.54) (27 69.54) 
(2 69.65) (35 70.54) (o 94.00). The probabilities for candidate markings to be optimal are as follows 
: (30, 0.382), (31, 0.231), (23, O.145), (29, 0.062), (32, 0.058), (24, 0.036), (22, 0.047), (17, 0.023), 
(16, 0.015), (11, 0.001), and O for the other candidate markings. At this point of the simulation, the 
candidate markings (16 11 0 1 2 3 4 56789101213141518192021 25262728 3334 35) are rejected. The confidence 
probability p* = 0.984. At iteration k = 1600 and 1=16, the criterion values become (30 18.59) (31 19.01) 
(23 20.32) (32 22.08) (24 22.15) (29 22,20) (22 23.10) (17 23.49). The probabilities for candidate markings 
to be optimal are as follows : (30, 0.392), (31, 0.296), (23, O.145), (32, 0.053), (24, 0.036), (29, 
0.040), (22, 0.020), (17, 0.018). At this point of the simulation, the candidate marking 17 is rejected. 
The confidence probability p* = 0.966288. Candidate marking 22 is rejected at iteration k = 2100, candidate 
marking 29 is rejected at iteration 2600. The 5 remainder candidate markings are simulated until k =20000. 
The correct optimal candidate initial marking M30 is obtained with confidence probability p* = 0.946091. 
Case 2. The firing times distributions are the same as in the first case. C = 11.5 and a = 50. For this 
case, the exact criterion values are as follows: (16 9.00) (17 9.00) (22 10.00) (23 10.00) (24 10.00) 
(29 11.00) (30 11.00) (31 11.00) (32 11.00) (11 11.30) (25 11.84) (33 12.12) (18 12.61) (12 16.14) (7 
26.75) (28 30.96) (21 33.02) (15 36.52) (19 41.82) (10 41.92) (13 42.01) (26 42.42) (34 43.30) (8 45.02) 
(6 51.14) (4 56.19) (3 68.21) (1 101.21) (9 117.85) (14 118.34) (5 118.73) (20 119.27) (27 120.26) (35 
121.26) (2 127.42) (O 181.90). Let us report the result of the ordinal optimization algorithm A3. The 
criterion values obtained at iteration k = 1100 and 1=11 areas follows: (11 8.00) (16 9.00) (17 9.00) 
(18 9.00) (12 9.11) (22 10.00) (23 10.00) (24 10.00) (25 10.00) (29 11.00) (30 11.00) (31 11.00) (32 
11.00) (33 11.00) (7 21.03) (19 31.10) (26 31.13) (13 31.72) (34 32.13) (8 35.90) (28 37.30) (21 38.97) 
(15 41.83) (10 45.42) (4 48.64) (6 54.12) (3 68.22) (1 97.53) (9 106.33) (5 106.57) (14 106.86) (20 107.86) 
(27 108.86) (35 109.86) (2 116.62) (O 178.99). The probabilities for candidate markings to be optimal 
are as follows : (11, 0.464), (16, 0.201), (17, 0.014), (18, 0.002), (12, 0.245), (7, 0.073), and O for 
the other candidate markings. At this point of the simulation, the candidate markings (17 1813 0 1 2 
3 45689101415192021222324 25262728 29 30 31 32 33 34 35) are rejected. The confidence probability p*= 
0.983. Let us notice that the candidate markings 17 and 18 ranked No. 3 and No. 4 are rejected as they 
can hardly outperform the set of retained candidate markings while the candidate marking 7 ranked No. 
15 is kept. The 4 remainder candidate markings (11, 12, 16, 7) are simulated until k =20000. The correct 
optimal candidate initial marking Ml 6 is obtained with confidence probability p* = 0.983. Case 3, The 
firing time distributions are as follows. Xt2 = 10, Xt4 is a three-stages Erlang distributed r.v. with 
mean equal to 9, Xtb is uniformly distributed on [5, 15] and &#38;8 is a two stage Erlang distributed 
r.v. with mean equal to 8. C = 10.5 and IX= 20. For this case, the exact criterion values are the following 
ones: (12 8.00) (17 9.00) (18 9.00) (23 10.00) (24 10.00) (25 10.00) (19 10.40) (16 10.54) (13 10.57) 
(11 10.66) (26 10.76) (22 10.91) (30 11.00) (31 11.00) (32 11.00) (33 11.00) (34 11.48) (29 11.58) (8 
11.83) (7 11.90) (4 16.32) (9 30.31) (6 30.46) (5 30.56) (14 30.86) (3 30.99) (lo 30.99) (20 31 .74) 
(15 31.85) (27 32.74) (21 32.84) (35 33.74) (28 33.83) (2 34.31) (1 35.19) (o 57.01). Algorithm A3 proceeds 
as follows. The criterion values obtained at iteration at k = 1100 and 1= 11 are as follows: (12 8.00) 
(13 8.56) (17 9.00) (18 9.00) Approach 587 (19 9.00) (11 9.78) (23 10.00) (24 10.00) (25 10.00) (26 10.00) 
(8 10.17) (16 10.38) (7 10.62) (30 11.00) (31 11.00) (32 11.00) (33 11.00) (34 11.00) (22 11.04) (29 
11.86) (4 14.85) (9 26.68) (14 26.84) (5 27.59) (20 27.66) (27 28.65) (35 29.65) (6 31.58) (3 31.93) 
(10 32.34) (2 32.66) (15 33.08) (21 33.87) (28 34.69) (1 35.83) (O 56.36). The probabilities for candidate 
markings to be optimal are as follows : (12, 0.882), (13, 0.030), (17, 0.000), (18, 0.001), (11, 0.010), 
(8, 0.054), (7, 0.023), and O for the others. At this point of the simulation, the candidate markings 
(11 18 0 1 2 3 4 5 6 91014 1516171920212223242526272829 303132 3334 35) are rejected. The confidence 
probability p* = 0.989. The 4 remainder candidate markings (12, 13,8,7) are simulated until k =20000. 
The correct optimal candidate initial marking M 12 is obtained with confidence probability p* = 0.989. 
Case 4. The firing time distributions are as follows. Xt2 is uniformly distributed on [0, 18], Xt4 is 
a three­stages Erlang distributed r.v. with mean equal to 9, Xt6 is uniformly distributed on [5, 15] 
and Xt8 is a two stage Erlang distributed r.v. with mean equal to 8. C = 10.5 and cx= 20. In this case, 
the exact criterion values ar~ (17 9.00) (18 9.00) (12 9.37) (23 10.00) (24 10.00) (25 10.00) (30 11.00) 
(31 11.00) (32 11.00) (33 11.00) (22 11.29) (16 11.29) (29 11.85) (11 12.22) (26 12.54) (19 12.61) (34 
12.91) (13 13.41) (7 14.77) (8 15.57) (4 21.20) (6 32.12) (10 32.15) (15 32.82) (21 33.73) (3 33.85) 
(28 34.70) (9 37.87) (14 38.17) (5 38.75) (20 38.94) (27 39.86) (1 40.64) (35 40.84) (2 43.81) (O 67.05). 
Let us report the result of the ordinal optimization algorithm A3. The results obtained at iteration 
k = 1100 and 1=11 are given in the following: (17 9,00) (18 9.00) (23 10.00) (24 10.00) (25 10.00) (12 
10.36) (26 10.41) (30 11.00) (31 11.00) (32 11.00) (33 11.00) (34 11.00) (19 11.05) (13 12.54) (16 13.49) 
(22 13.80) (11 14.07) (29 14.56) (8 15.57) (7 16.25) (4 21.80) (6 35.81) (10 36.16) (14 36.24) (9 36.60) 
(20 36.66) (15 37.00) (27 37.23) (3 37.59) (21 37.75) (35 38.22) (5 38.28) (28 38.58) (1 44.00) (2 44.79) 
(O 69.59). The probabilities for a candidate marking to be optimal is as follows: (17, 0.418), (18, 0.270), 
(23, 0.006), (24, 0.002), (25, 0.001), (12, 0.240)> (19, 0.020), (13, 0.030), (11, 0.010), ( 8, 0.003), 
and O for the others. At this point of the simulation, the candidate markings (238242501234 5679101415 
 1620 21 22 26 2 728 29 30 31 32 33 34 35) are rejected. The confidence probability p* = 0.988. The candidate 
markings 13 and 19 are rejected at iteration k = 1600. The 4 remainder candidate markings (17, 18, 12, 
11) are simulated until k =20000. The correct optimal marking Ml 7 is obtained with confidence probability 
p* = 0.988. 6. CONCLUSION In this paper, we have proposed an ordinal optimization approach to a token 
partition problem for stochastic timed event graphs. This approach simultaneously simulates all candidate 
initial markings. The distributions of the average cycle times are characterized along with the simulation. 
The distributions are used to calculate the probability for a candidate initial marking to be optimal. 
Candidate initial markings whose probabilities to be optimal are low are rejected along the simulation. 
Numerical results show the power of this approach in identifying good solutions. We believe that this 
approach is generat enough and can be extended to general discrete event systems such as general Petri 
nets. Several problems remain open. First, the definition of the candidate solutions is crucial due to 
the combinatorial feature of such problems. Theoretical results such as ergodicity, monotonicity and 
deadlock freeness are needed to restrict the number of candidate solutions. Another open problem is the 
confidence interval of the cycle time distribution estimates. REFERENCES <RefA>Baccelli, F. 1992. Ergodic Theory 
of Stochastic Petri Networks. Annals of Probability 20:375-396. Chen, C.-H. 1993. Confidence Level Quantification 
and Optimal Computing Budget Allocation for Discrete Event System Simulations. Submitted to IEEE Trans. 
on Automatic Control. Deng, M., Y.C. Ho, and J.Q. Hu. 1992. Effect of Correlated Estimation Errors in 
Ordinal Optimization. In Proc. of the 1992 Winter Simulation Conference. Chretienne, P. 1983. La rt%eaux 
de Petri temporis6s. University Paris VI, Paris, France, Th6se d Etat. Commoner, F., A. Holt, S. Even, 
and A. Pnueli. 1971. Marked Directed Graphs. J. Computer and System Science, 5:511-523. Ho, Y. C., and 
C.G. Cassandra. 1993. Parallel Computation in the Design and Stochastic Optimization of Discrete Event 
Systems. In Proc. of 32nd IEEE Conf on Decision and Control, San Antonio, Texas. Ho, Y.C., R.S. Sreenivas, 
and P. Vakili. 1992. Ordinal Optimization of DEDS. Journal of Discrete Event Dynamic Systems 2:61-88. 
Laftit, S., J.M. Proth, and X.L. Xie. 1992, Optimization of Invariant Criteria for Event Graphs. IEEE 
Trans. on Automatic Control 37:547 -555. Mitrani, I. 1982. Simulation techniques for discrete event systems. 
Cambridge University Press. Proth, J.M., N. Sauer, Y. Wardi, and X.L. Xie. 1993. Marking Optimization 
of Stochastic Timed Event Graphs using IPA. Research Report No. 1863, INRIA, France. Tayur, S.R. 1992. 
Properties of Serial Kanban Systems , Queueing Systems 12:297-318. Xie, X.L. 1993. On the Impact of Randomness 
in Production Lines Controlled by Kanbans. In Proc. of the 2nd European Control CO;lference, 158-163, 
Groningen, The Netherlands.</RefA> AUTHOR BIOGRAPHY XIAO-LAN XIE is a research officer at the Institut National 
de Recherche en Informatique et en Automatique (INRIA). His research interests include modelling, performance 
evaluation, real-time control and design of manufacturing systems.  
			
