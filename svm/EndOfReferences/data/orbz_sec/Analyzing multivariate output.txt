
 Proceedings of the 1995 Winter Simulation Conference ed. C. Alexopoulos, K. Kang, W. R. Lilegdon, and 
D. Goldsman ANALYZING MULTIVARIATE OUTPUT John M. Charnes School of Business University of Kansas Lawrence, 
Kansas 66045-2003 ABSTRACT This paper gives an overview of multivariate sta­ tistical techniques that 
can be useful for analyzing discrete-event simulation output, and describes some of the latest directions 
in research on multivariate output analysis. A general discussion is given of con­structing joint confidence 
regions on the mean vec­tor of multivariate output from independent replica­tions of terminating models. 
The multivariate batch means method of simultaneous estimation of means from one long run of steady-state 
simulation models is described. References are also given for autoregres­sive, spectral analysis and 
regenerative methods of in­ference, as well as variance-reduction and sequential techniques. INTRODUCTION 
There has been considerable activity recently by re­searchers on the problem of simultaneously making 
statistical inferences on more than one output mea­sure of interest in simulation modeling (Seila 1982, 
1983, 1984, 1990; Chen and Seila 1987; Chen and Chen 1988; Chen and Cheng 1989; Chen 1991; Munoz 1991; 
Yang and Nelson 1988, 1992; Charnes 1990, 1991; Charnes and Kelton 1988, 1993; Raatikainen 1993; Gallagher, 
Bauer and Maybeck 1994). The in­tent of this paper is to describe some of the latest directions of research 
in this area. It will attempt to highlight some of the important multivariate statisti­cal techniques 
that may be found useful in analyzing simulation output. The methods presented here will be of most interest 
to those analysts wishing to extract more informa­tion from their simulation models. Novice analysts 
looking for basic information on simulation output analysis should consult simulation textbooks, such 
as Bratley, Fox and Schrage (1987) or Law and Kelton (1991), or one of the tutorial papers published 
in pre­ vious Proceedings of the Winter Simulation Confer­ence and the references therein. This paper 
is an update of Charnes (1991). The next section discusses multivariate output from simulation models 
and contrasts multivariate analysis to univariate. Section 3 discusses terminat­ing simulation models. 
Section 4 discusses steady­state models. Section 5 concludes the paper and gives references to more advanced 
techniques of multivari­ate output analysis. 2 MULTIVARIATE OUTPUT Most simulation models produce outputs 
on more than one measure of interest, and these outputs are usually cross-correlated as well as being 
autocorre­lated. If cross correlation of the output measures is important to the simulation analyst, 
a mult ivari­ate technique should be used with the output data generated by the simulation model. Two 
examples illustrate the usefulness of considering multivariate output from simulation models. Example 
1: Bank Lobby Layout. A bank man­ager is considering changing the present configuration (Layout 1) of 
the teller windows in the lobby from one in which both private and corporate customers are served by 
any of the available tellers, to one in which certain tellers serve only private customers, and cer­tain 
tellers serve only corporate customers (Layout 2). The two different layouts are illustrated schematically 
in Figure 1. Corporate customers are represented by the crosses ( x ) and private customers are represented 
by the open circles (o). The bank manager is willing to change the lobby layout if it decreases the time 
spent waiting in the bank by corporate customers, even if it means the time spent waiting by private 
customers increases by a small amount. To help make the decision, the manager wants to know the correla­tion 
between the average times spent waiting by both types of customers, because she feels that private cus­ 
201 Charnes Layout 1 0 x Xxxooxox: or o Servers x D Layout 2 xl___l xXxx : x Servers x 1 I r 1 0 0 
+00: Servers o 1 1 Figure 1: Two Bank Lobby Layouts tomers may be more tolerant of slightly longer 
delays if they observe corporate customers experiencing long delays when they do. Example 2 Tandem Queueing 
System. Two states of a simple tandem queueing system are shown in Figure 2. The customers, depicted 
as open circles (o), arrive to the system and wait on line, if necessary, to be served individually by 
Server 1. The customers then proceed to Server 2, and wait on line there, if necessary, to be served 
individually by Server 2, af­ter which they depart from the system. Server 1 has a mean service rate 
PI = 1 customer per unit time, while Server 2 has a mean service rate of pz = 10 customers per unit time. 
If only the total number in system is observed, the two states appear to be identical; in both State 
1 and State 2, there are six customers in the system. However, the difference be­tween the two states 
is quite noticeable to an arriv­ing customer who occupies the last spot on line in Server 1 s queue. 
In State 1, which has only two cus­tomers at Server 1 (the slower server), the customer is likely to 
get through the system much more quickly than in State 2, which has four customers at Server 1. Thus 
by looking only at univariate output data (such as total number in system), rather than multivariate 
(such as the 2-dimensional vector of number of cus­tomers at each server), a simulation analyst might 
miss important information about the system that could be useful for making decisions. For example, if 
this simple system represented some portion of a factory, and the factory configuration were such that 
the queues at Server 1 and Server 2 State 1  OOEEzl OOOOE State 2 1II ( Server 1 Server 2 +0000 -00 
pl=l ,U2=1O I1I I Figure 2: Tandem Queueing System were able to share plant-floor space, the plant 
man­ager may well be interested in the correlation between the numbers in queue. Frequent occurrences 
of the numbers in queue being large simultaneously (indi­cated by a large positive correlation) could 
require the allocation of more floor space to the servers queues. By using multivariate statistical methods 
with the data obtained from valid simulation models, deci­sion makers can extract more information from 
which to make inferences on the processes being modeled. Constructing multivariate confidence regions 
on the mean vector of the data-generating process is one way to summarize information about each of the 
univari­ate processes composing the multivariate process, as well as the correlations among processes. 
The next two sections describe techniques for constructing con­fidence regions that could be applied 
to the two ex­amples given above. 3 TERMINATING MODELS There are two different types of discrete-event 
simu­lation models that call for different basic approaches to experimental design as well as to constructing 
con­fidence regions on, the mean. In the terminating sim­ ulation case, where the system being modeled 
has specific start-up and shut-down times (e.g., the bank described in Example 1, which opens at 9 A.M. 
and closes at 3 P.M.), the simulation analyst can make in­dependent replications of the model, each represent­ing 
one complete succession from start up to shut down. If the simulation analyst calculates point estimates 
of the parameters of interest from each replication (such as the averages of the time spent in the bank 
by Analyzing Multi the private and the corporate customers), the result will be a sequence of independent 
and identically dis­tributed (iid) random vectors that can be analyzed using classical multivariate statistical 
methods. By viewing the output as vectors and using multivari­ate methods, rather than analyzing the 
components of the vectors separately with univariate statistical methods, the analyst can get an estimate 
of the cor­ relations among the vector components that can pro­ vide useful information to the decision 
maker about the process being modeled. 3.1 Joint Confidence Regions One multivariate technique that 
can be applied is the construction of a joint confidence region on the mean vector. The procedure is 
based on Hotelling s T2 distribution, and is the generalization to higher di­mensions of the univariate 
t-distribution confidence­interval procedure for a single mean. The validity of the procedure rests upon 
the assumption of mul­tivariate normality of the data. See an introductory multivariate statistics text 
such as Anderson (1984), Johnson and Wichern (1988), or Morrison (1976) for a fuller discussion of this 
procedure. Consider a simulation model that is replicated R times, and that has D measures of interest. 
The ob­servations are denoted by X( ) = ( x~r), . . . . x:) ) ( denotes matrix transposition), where 
X$) is the value of the dth measure of interest on the r-th repli­cation. The measure of interest might 
be the average cycle time of a specific product, time-average number in a selected queue, or some other 
point estimator cal­culable from each replication. The analyst wishes to construct a confidence region 
on the true mean vector of the parameters Z = E [x( )] = (pl, . . . . ~D) . To form the confidence region, 
first find ~ = ~ ~s=l x( ) = (~~nl X\ )/R, . . . . ~~=1 X~)/R)L The vector of point estimators ~ is 
an unbiased estimator of the mean vector ~. An unbiased es­timate of the variance-covariance matrix of 
~ is S = (1/(R 1)) ~~=l(X( l ~)(X[rJ ~) , and a 100(1 a)Yo confidence region for the true mean vector 
of the parameters of interest is given by the set of all vectors @ such that (~ @) S l(% El) < (D(R 
l) Fa,~,R-D)/(R(R D)) where Fa;D,R-D is the upper (100a)th percentile of the F distribution with D and 
R D degrees of freedom. With two parameters of interest, the confidence re­gion can be plotted as an 
ellipse in two-dimensional space. For three parameters, the region is a three­dimensional ellipsoid. 
For more than three param­eters, the region cannot be plotted; however, it is a straightforward calculation 
to check whether any variate Output given vector will be in the confidence region, so that one can easily 
check for combinations of parameters that are undesirable (such as short corporate cus­tomer delays and 
long private customer delays). The shape and orientation in parameter space of the ellipsoid depends 
upon the magnitudes and al­gebraic signs of the off-diagonal terms of the matrix S. Because it is the 
relative magnitude of the off­diagonal elements that is important, it is informa­tive to compute the 
correlation matrix, C, for the mean vector. The correlation matrix is calculated as Cij = S%J -, where 
Sij is the (i, j)th element of / S. The element C;j of C gives the correlation between point estimator 
i and point estimator j and thus will be such that 1 < Cij <1. Note that the validity of this procedure 
rests upon the assumption of multivariate normality and inde­pendence of the vector observations taken 
from each replication. Obtaining independent vector observa­tions from replications in simulation modeling 
is not usually a problem, and averaging over each replica­tion will tend to make the point estimates 
normally distributed. However, the analyst should be aware that the validity of this procedure rests 
upon these two assumptions. 3.2 Simultaneous Confidence Intervals Because joint confidence regions can 
be difficult to interpret, the analyst might want to construct indi­vidual confidence intervals on the 
mean of each com­ponent process in the output vector. Two methods for doing so are Scheff6 and Bonferroni 
intervals. 3.2.1 Scheff6 Intervals Scheff6 confidence intervals (also known as Roy-Bose intervals) are 
the shadows of the ellipsoidal confidence region on the coordinate axes. Using the elements of the matrix 
S given above, the Sch%&#38; intervals are given by Z, + <(D(R -l)F@;~,~_~sii)/(R(R -D)) fori= l,..., 
D, where Ei is the ith element of the vector X. These intervals define a rectangular region that cir­cumscribes 
the ellipsoid given above. Regardless of the dependence structure of the individual estima­tors, the 
overall level of confidence that the Scheff6 intervals cover their respective means will thus be greater 
than or equal to (1 a) when the assump­tions above hold for the ellipsoidal region. The Scheff6 intervals 
are easier to interpret than the ellipsoidal region because they yield a range for each component of 
the output vector. However, be­cause they utilize all the information contained in the variance-covariance 
matrix, S, they require more computation than do the confidence intervals result­ing from univariate 
procedures.  3.2.2 Bonferroni Intervals A naive approach to analyzing simulation output is to use univariate 
procedures on each output measure without being aware of the limitations of doing so. One must be careful 
in constructing more than one confidence interval from simulation output with the usual univariate procedures 
because the overall level of confidence that all intervals with the same nomi­nal confidence level will 
cover their respective means is less than the nominal confidence level of each in­terval. The exact amount 
less is usually difficult to determine and is affected by the dependence structure of the univariate 
estimators; however, the Bonferroni Inequality yields a simple method of setting the in­dividual confidence 
levels for a group of univariate procedures in order to obtain a lower bound on the overall level of 
confidence in the set of inferences. Let Pr(Ci true) = 1 ai for i = 1, ....D where C i denotes a confidence 
statement about the mean value of the ith component of the output vector. The Bonferroni Inequality holds 
that Pr(all C i true) > I (al+az +.. . + ~D ). This result is often used as follows. If each one of D 
confidence intervals is con­structed at the 1 a/D level, then the overall level of confidence is at 
least 1 a that all D parameters lie in the D-dimensional box defined by these confidence intervals. 
If the vector ~ and the matrix S have been calcu­lated as described above, individual Bonferroni Inter­vals 
can be constructed on each component mean as follows: Zi + ta/~D,&#38;-~&#38;j% for i = 1, ...D where 
t~/zD,R_l is the upper (100a/( 2D))th percentile of the tdistribution with (R 1) degrees of freedom. 
An advantage of using Bonferroni Intervals rather than Scheff6 is their ease of construction. Many com­mercial 
simulation software packages provide one or more methods of obtaining confidence intervals us­ing standard 
univariate procedures. If so, Bonferroni Intervals can be constructed by using one of the avail­able 
methods with an appropriate choice of the con­fidence coefficient. The disadvantage is that for large 
D the intervals may be very wide, and thus not very precise. Further, the same caveats in regard to the 
independence and normality assumptions given pre­viously for joint confidence regions apply here. The 
actual lower bound on the coverage probability for the Bonferroni method depends upon the true cover­age 
probabilities of the individual confidence inter­vals. If the univariate confidence intervals do not 
obtain their nominal coverage individually, then the Charnes II -1 -i -d.8 -d.6 -d.4-O .2 b 0!2 0:4 
0:6 0:8 i 81 Figure 3: Comparison of Confidence Regions Bonferroni Inequality will not ensure that the 
bound on the nominal coverage given by the inequality will obtain. Figure 3 illustrates the three confidence 
regions de­scribed above. The Scheff6 and Bonferroni regions are labeled and the ellipse labeled E represents 
an el­lipsoidal region obtained as described in Section 3.1. Similar comparisons have been given by Miller 
(1981) and Chen (1991). The three 90% confidence regions depicted were constructed from the variance-covariance 
matrix S = for R = 22. Without 10SS of general­(l}, : ) ity, the sample mean vector was taken to be X 
= O. The plot shows the typical pattern in that the Scheff6 region is larger than the Bonferroni region. 
It also shows that portions of the ellipsoidal confidence re­gion are not covered by the Bonferroni Intervals. 
4 STEADY-STATE MODELS In a steady-state simulation, the system being mod­eled has no specific start-up 
or shut-down times. An example is the simulation of a factory that op­erates t went y-four hours a day, 
seven days a week. In cases like this, the simulation analyst is most of­ten interested in estimating 
steady-state parameters of the model. That is, the analyst assumes that if the model is in operation 
long enough, it will reach a state of statistical equilibrium, in which the means, cross covariances, 
and autocovariances (defined below) of the output process will be invariant to the passage of simulated 
time. As in the univariate case, if the initial conditions for the simulation are not representative 
of steady-state, the simulation must be allowed to warm up by run­ Analyzing Multi ning for a suitable 
length of time to mitigate any bias induced by the non-representative initial conditions. Schruben (1981) 
and Gallagher, Bauer, and Maybeck (1994) give multivariate methods for deciding when the simulation appears 
to have reached steady state. Once the initial transient observations have been identified, they are 
usually discarded and the remain­ing observations are analyzed. However, as in the univariate case, the 
autocorrelation problem makes it more difficult to analyze these data than the serially independent data 
obtained from terminating models. This section deals with analyzing multivariate output obtained from 
steady-state models. 4.1 Autocorrelation Function Assume that the initial transient observations gener­ated 
by a simulation model have been discarded. In general, if a simulation model produces the station­ary 
sequence of D-dimensional vector observations {x~, xz,... ,X~}, where Xt = (X1t, X2t, . . ., X~i) and 
E[X~] = ~ = (PI, P2, . . . . PD) , the output vec­tors will not be iid. The dependence among the ele­ments 
and across time is characterized by the autoco­ variance function, I (h) = E [(X~ ~)(X~+h ~) ], which 
is a function of only the lag, h, for a stationary sequence. For univariate processes, the autocovari­ance 
function is a scalar function of h but for mul­tivariate processes, I (h) is a matrix. The autoco­variance 
of the ith component of the vector output sequence is given by the corresponding diagonal el­ement in 
I (h), which is denoted yii (h). The cross covariances are given by the off-diagonal terms in the autocovariance 
function, yij (h) (i # j). In practice, if the observations are simultaneous (all elements of the observation 
vector are taken at the same point in simulated time), and equally spaced in simulated time, it may be 
informative to compute the sample autocorrelation function, R(h), which is a nor­malized version of the 
sample autocovariance func­tion, G(h), calculated from the simulation output. The sample autocovariance 
function is found from the data as G(h) = ~~~~(Xt ~)(Xt+h ~) /(T h) forh =0,1,2 , . . . . T 1. For 
large h, the estimates will be calculated from only a few observations, and thus may be poor; however, 
much insight can be gained from calculating these matrices for small lags (e.g., h = 0,1,2, 3). Then 
the sample autocorrelation function is computed from the elements of the auto­covariance function as 
rtj (h) = gij (h)/ ~~ . Because these are correlations, it will be true that 1 < ?-Zj(h) <1 Vi, j,h. 
The sample autocorrelation function may reveal important information about the dependence struc­ variate 
Output ture of the processes being modeled. For example, a model of a factory with ten work centers on 
which a 10-dimensional vector of numbers at each work center is observed at equally spaced time periods 
will yield a (10 x 10) autocorrelation matrix for each lag, h, that will indicate how much a work center 
downline may be affected by backups at previous work centers. High values of rij (0) for instance, will 
tell the analyst that the relative (to the mean) number at work center j will follow closely the relative 
number at work center i. High values of rij (h) will indicate that high (low) numbers at work center 
i will tend to be followed by high (low) numbers at work center j, but not until a lag of h time units 
later. The matrix autocorrelation function may be worthwhile calculating for only this reason it gives 
the analyst more information about the characteristics of the operation. 4.2 Multivariate Batch Means 
Consider a stationary process that produces a se­quence {Xt }:= ~ of D-dimensional vector-valued ob­servations. 
The analyst wishes to estimate the mean vector ~ = E(Xt ) with a joint confidence region. The multivariate 
batch means (MBM) method calls for di­viding the sequence of output vectors into 1? batches of M (vector) 
observations each (where T > BM) and computing the batch-mean vectors as yb = ~~=1 (b-l) M+m/~ for b 
= 1,..., B. The B vec­tors of batch means are then treated as if they are uncorrelated observations from 
a multivariate nor­mal distribution, and standard multivariate statisti­cal techniques are used to form 
a confidence region on the mean vector, ji, just as for terminating mod­els. Let S = ~~=l(Y~ ~)(yb 
~) /(B 1) de­note the sample variance-covariance matrix for the batch mean vectors, where the point 
estimator of ~ is the D-dimensional vector ~ = ~~=1 Yi /m. An approximate 100( 1 cr)~o confidence region 
for ~ is then given by the set of all vectors El such that (~ O) S- (~ O) < (D(B l)F.,~,~-~ )/( B(B 
D)). Chen and Seila (1987) proposed the use of the mul­tivariate batch means method at a previous Winter 
Simulation Conference. An important step in forming the MBM confidence region is the determination of 
the number of vector observations per batch, M (equivalently, the number of batches, B). One method of 
making this determi­nation is to assume that the batch-means process can be sufficiently approximated 
by the VAR(l) (first­order, vector-autoregressive) model yb = @Yb-1 + C6 for b=l, . . .. B.where @is 
aDx Dmatrixof au­toregression coefficients and the ~b are D x 1 inde­pendent and identically distributed 
vectors of random 206 Charnes errors drawn from the multivariate normal distribu­ tion. Then M is chosen 
such that the null hypothesis of no first-order serial correlation, Ho: @ = O, is not ~ejected. Anderson 
(1978) suggests HO: @ = O can be tested with one of the criteria given in Anderson (1984) for testing 
the general linear hypothesis. Charnes (1990) compared these criteria, which include the Lawley-Hotelling 
trace criterion, the Bartlett-Nanda-Pillai criterion, and three slightly different forms of the Wilks 
likelihood-ratio criterion. Because the batch sizes are chosen upon not rejecting Ho, the criteria were 
compared on their power to detect departures from Ho. The conclusion from the comparison was that there 
is little difference in the power of each of these statistics. However, Rae s (1951 ) approxima­tion 
to the Wilks likelihood-ratio procedure can be recommended because (i) it has a degrees-of-freedom correction, 
which makes it appropriate for a small number of batches containing a large number of vec­tors, and (ii) 
the critical value for the hypothesis test comes from the F distribution rather than tabulated values 
in Anderson (1984), which makes it possible to calculate the critical value with a computer al­gorithm, 
thus making it amenable to inclusion in a software package that automates simulation output analysis. 
Rae s approximation to Wilks s procedure uses R = [(kS r)/D2] [(1 Ulf )/U1/s]where the scalar U = IS(O) 
S(l) S*(0) -l S(l) [/lS(O)l, the DxD ma­ trix S*(0) = ~~=-~l(yb ~)(Y~ ~) , the D x D matrix S(0) = 
~~=2(Y~ ~)(Y~ ~) , the D x D matrix S(l) = ~f?=2(Y~ K)(Y~.1 Y) , and the ~(D4 _ 4)/(2@ _ 5), . = 
Dz/2 1, and scalars s = k= B 1/2. R has approximately the F distribu­tion with D2 and ks r degrees 
of freedom (Anderson 1984). A procedure for selecting the number and size of the batches is to begin 
with some maximum num­ber of batches, B -Bma, (D), compute the sequence of batch means, {Yb}~=~, and 
test HO with R. If Ho is rejected, decrease B, compute the new sequence {Yb}~nl, and test Ho again with 
R. Continue until either Ho is not rejected, or until a prespecified min­imum number of batches, Bm,n 
(D), is reached. If Ho is not rejected, compute the region given above. If the minimum number of batches 
is reached, run the simulation for a longer amount of time, and repeat this procedure. Schmeiser (1982) 
provides guidelines for choosing the minimum and maximum number of batches for the univariate batch means 
method (D = 1),but an open topic for further research is the best choice of the minimum and maximum number 
of batches for multivariate analysis. Yang and Nelson (1992) give some guidelines for choosing Bm,n (D) 
for D < 5; however, little else has been published to date on this topic. 4.3 Simultaneous Confidence 
Intervals As in the terminating simulation case, an analyst will probably want to construct individual 
confidence in­tervals on the true mean of each component process. One way to accomplish this is to use 
the univariate batch means method with each component process taken individually (see Schmeiser 1982), 
while being mindful of the Bonferroni Inequality when choosing the percentile of the t distribution used 
to construct each interval. An alternative is to use the elements of S from the MBM method to compute 
Ed A tal(2Dj,B-1 m forcl=l , . . . . D. Note that by using this alternate method, the analyst is forcing 
the batch sizes to be the same for each component process. This is not nec­essarily true when the univariate 
batch means tech­nique is applied to each process individually. How­ever, by calculating the matrix S 
from the MBM method, the analyst can also get an estimate of the correlation among the estimators of 
the means. This will not be true, in general, for any univariate method applied individually to the component 
processes. 4.4 Advanced Techniques More proposed state advanced for asimulation multivariate nalyzing 
data models. techniques generated have by st been eady­ 4.4.1 Autoregressive Models Charnes and Kelton 
(1993) use a vector autoregres­sive (VAR) model to obtain confidence regions on the mean vector, ~. This 
approach differs from the MBM method in that the VAR method uses the information contained in the autocorrelation 
of the output, while the MBM method attempts to eliminate the autocor­relation by batching. The empirical 
evidence shows that VAR compares favorably with MBM and other methods. 4.4.2 Spectral Analysis Kabaila 
and Nelson (1985) give a frequency domain time-series technique that was used to make infer­ences on 
the earth s mean atmospheric response to external forcing. The method uses an estimate of the spectral 
density function at frequency zero for con­structing a confidence region on ~. Charnes and Kel­Analyzing 
Mrdtivariate ton (1993) compare this method empirically to MBM and VAR. 4.4.3 Standardized Time Series 
Munoz (1991) extends the method of standardized time series, initially proposed to estimate a single 
steady-state mean, to the case where simultaneous inferences on the components of ji are desired.  
 4.4.4 Regenerative Method The regenerative method is a way to analyze steady­state data in a manner 
similar to that used in ana­lyzing terminating data. The idea is to identify nat­urally occurring cycles 
in the output processes from which point estimates of the parameters of interest can be calculated. Seila 
(1990) and Chen and Cheng (1989) discuss estimation in regenerative simulations. 4.4.5 Variance Reduction 
Techniques Yang and Nelson (1988, 1992) discuss the extension of a univariate variance-reduction technique, 
the use of control variates, to the multivariate case. Yang and Nelson s (1992) work can be used to gain 
insight as to the minimum number of batches to specify in the MBM method. 4.4.6 Sequential Methods Raatikainen 
(1993) gives a sequential procedure for controlling the length of a simulation run so as to ob­tain confidence 
intervals on the components of ~ that are a pre-specified width or smaller. This method is based on the 
Bonferroni Inequality and does not use the information contained in the off-diagonal ele­ments of S. 
5 CONCLUSION Multivariate methods must be used if the analyst is interested in learning about the correlation 
structure of the output processes of simulation models. Even if a joint confidence region won t be constructed, 
it can be informative to calculate the correlation matrix, C, to gain some insight into the behavior 
of the model. Constructing an ellipsoidal confidence region is a multivariate method that takes into 
account the cross covariance among output processes, while simultane­ous confidence intervals based on 
the Bonferroni In­equality do not. However, ellipsoidal confidence re­gions are harder to interpret, 
especially for D > 4, when they can t be plotted. On the other hand, for Output higher D, the Bonferroni 
confidence intervals can be very large, and thus not very precise. Research is continuing in developing 
and refining techniques for analyzing multivariate simulation out­ put. Perhaps these methods will one 
day be included as part of the standard output routines in the com­ monly used simulation soft ware packages. 
REFERENCES <RefA>Anderson, T. W. 1978. Repeated measurements on autoregressive processes, Journal of The American 
Statistical Association, 73:371-378. Anderson, T.W. 1984. An Introduction to Multwarz­ate Statistical 
Analysw, Second Edition. New York: John Wiley. Bratley, P., B. L. Fox, and L. E. Schrage. 1987. A Guade 
to Simulation, Second Edition. New York: Springer-Verlag. Charnes, J .M. 1990. Power comparisons for 
the mul­tivariate batch-means method, In Proceedings of the 1990 Winter Simulation Conference, eds. O. 
Balci, R.P. Sadowski, R.E. Nance, 281 287. Insti­tute of Electrical and Electronics Engineers, New Orleans, 
Lousiana. Charnes, J .M. 1991. Multivariate simulation output analysis, In Proceedings of the 1991 Want 
er Simula­tion Conference, eds. B. L. Nelson, W. D. Kelton, G. M. Clark, 187 193. Institute of Electrical 
and Electronics Engineers, Phoenix, Arizona. Charnes, J.M. and W.D. Kelton. 1988. A compar­ison of confidence 
region estimators for multivari­ate simulation output, In Proceedings of the 1988 Winter Simulation Conferencel 
eds. M. Abrams, P. Haigh, J .C. Comfort, 458 465. Institute of Electri­ cal and Electronics Engineers, 
San Diego, Califor­ nia. Charnes, J. M. and Kelton, W. D. 1993. Multivari­ate autoregressive techniques 
for constructing con­fidence regions on the mean vector, Management Science, 39: 1112-1129. Chen, D.R. 
and Chen, W.P. 1988. Multivariate infer­ence in stationary simulation using batch means, In Proceedings 
of the 1989 Wtnter Stmulatzon Confer­ence, E.A. MacNair, K.J. Musselman, and P. Hei­delberger, Eds. Institute 
of Electrical and Elec­tronics Engineers, Piscat away, NJ, 524-533. Chen , D.R. and Cheng, W.J. 1989. 
Multivariate sta­tistical analysis for regenerative simulation, Jour­nal of Management Science, 6: 43 
56. Chen, D.R. 1991. The relationship between multi­ variate correlation and coverage rat e, presentation 
at TIMS XXX SOBRAPO XXIII Joint Interna­tional Meeting. 208 Charnes Chen, D .R. and A.F. Seila. 1987. 
Multivariate infer­ence in stationary simulation using batch means, In Proceedings of the 1987 Winter 
Simulation Con­ference, eds. A. Thesen, H. Grant, W.D. Kelton, 302 304. Institute of Electrical and Electronics 
En­gineers, Atlanta, Georgia. Gallagher, M. A., Bauer, K. W., and Maybeck, P. S. 1994. Initial data truncation 
for multivariate out­put of discrete-event simulations using the Kalman filter. In Annals of Operations 
Research, ed. O. Balci, 53:419. Johnson, R.A. and D.W. Wichern 1988. Applied Mul­tivariat e Statistical 
Analysis, Second Edition. En­glewood Cliffs, New Jersey: Prentice Hall. Kabaila, P. and G. Nelson. 1985. 
On confidence re­gions for the mean of a multivariate time series, Communications in Statistics Theory 
and Meth­ods, 14: 735 753. Law, A.M. and W.D. Kelton. 1991. Szmuiation Mod­elling and Analysis, Second 
Edition. New York: McGraw-Hill. Miller, R. G. Jr. 1981. Simultaneous Statistical Infer­ence, Second Edition. 
New York: Springer-Verlag. Morrison, D.F. 1976. Multivariate Statistical Meth­ ods, New York: McGraw-Hill. 
Munoz, D. F. 1991. Cancellation methods in the anal­ysis of simulation output (confidence intervals). 
Ph.D. thesis, Department of Operations Research, Stanford University. Raatikainen, K. E. E. 1993. A sequential 
procedure for simultaneous estimation of several means, ACM Transactions on Modeling and Computer Simula­tion, 
3: 108-133. Rae, C.R. 1951. An asymptotic expansion of the dis­tribution of Wilk s criterion. Bulletin 
of the Inter­national Statistical Institute, 33: 177 180. Schmeiser, B. 1982. Batch size effects in the 
analy­sis of simulation output. Operations Research, 30: 556-568. Schruben, L. W. 1981. Control of initialization 
bias in multivariate simulation response. Communications of the A CM, 24: 246 252. Seila, A. F. 1982. 
Multivariate estimation in regen­erative simulation, Operations Research Letters, 1: 153-156. Seila, 
A. F. 19X3. Multivariate estimation in simu­ lation, Proceedings of the 1983 Winter Simulation Conference, 
693 696. Institute of Electrical and Electronics Engineers. Seila, A. F. 1984. Multivariate simulation 
output analysis, Amerzcan Journal of Mathematical and Management Sciences, 4: 313 334, Seila, A.F. 1990. 
Multivariate Estimation of Condi­tional Performance Measures in Regenerative Sim­ ulation. American Journal 
of Mathematical and Management Scaences 10: 17-50. Yang, W.-N. and B.L. Nelson. 1988. Multivariate es­timation 
and variance reduction in terminating and steady-state simulation, In Proceedings of the 1988 Wtnter 
Simulation Conference, eds. M. Abrams, P. Haigh, J .C. Comfort, 466 472. Institute of Electri­cal and 
Electronics Engineers, San Diego, Califor­nia. Yang, W.-N. and B.L. Nelson. 1992. Multivari­ate batch 
means and control variates, Management Science, 38: 1415-1431.</RefA> AUTHOR BIOGRAPHY JOHN M. CHARNES is Associate 
Professor in the management science group of the School of Busi­ness at the University of Kansas in Lawrence. 
His re­search interests are in multivariate simulation output analysis and using simulation for process 
improve­ment. He is the current newsletter editor for the IN-FORMS College on Simulation. 
			
