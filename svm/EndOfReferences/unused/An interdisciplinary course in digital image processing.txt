
 An Interdisciplinary Course in Digital Image Processing~ Dr. Michael Magee Dr. Sue Englert Computer 
Science Department Electrical Engineering Department University of Wyoming University of Wyoming Laramie, 
Wyoming 82071-3682 Laramie, Wyoming 82071-3295 e-mail: magee @outlaw. uwyo.edu e-mail: sue @ outlaw. 
uwyo.edu (307) 766-5289 (307) 766-6137 f This work was partially supported by NSF grant ILI-8952218. 
Abstract This paper documents the development and first offering of an interdisclipinary undergraduate 
course in Digital image Processing at the University of Wyoming. The course itself was designed to serve 
majors from a wide range of academic disclipines, although in its initial offering, it was attended mainly 
by students majoring in Computer Science and Electrical Engineering. National Permission to copy without 
fee all or part of this material is granted provided that the copiee are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication end its date appear, 
and notice is givan that copying ia by permission of the Aeeocietion for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. Q 1992 ACM 0-89791 -468 -61921000210197 
...$ 1.50 Science Foundation funding for equipment for the course was used to to purchase a high speed 
image processing system and six state-of-the-art graphics workstations with software that supported basic 
and intermediate level image processing operations. Students in the course were required to perform a 
standard set of image processing sequences such as histogramming and histogram equalization, edge detection 
and evaluation, image smoothing, region growing, Fourier filtering, and image warping. Each student, 
in consultation with the instructor, then pursued a specific topic in image processing which invcdved 
either combining several image processing operations to produce a desired result or developing special 
code to implement image processing algorithms that were discussed in the text but not included in the 
provided software. The nature of the course and its impact on education at the University of Wyoming 
is discussed in the paper that follows. Introduction Historically, there have been two primary academic 
units that taught courses related to digital image processing at the University of Wyoming. These were 
the Departments of Computer Science (in the College of Arts and Science) and Electrical Engineering (in 
the College of Engineering). A topics course in image processing was offered by Electrical Engineering 
on a somewhat irregular basis, with the emphasis being on classical signal processing techniques in both 
continuous and discrete domains. The Computer Science Department, on the other hand, offered a graduate 
level computer vision course in which the fundamental goal was to explore the arhficial intelligence 
related aspects of automated vision systems. The intended emphasis of this latter course was image interpretation 
and motion understanding. Due to the nature of the course, however, it was necessary to spend a significant 
amount of time early in the semester discussing topics that should have been reserved for a prerequisite 
course in image processing in order to be able to provide a foundation for discussing higher level topics 
relating to image understanding. For example, in order to constuct a graph structure representative of 
an image object, it is necessary to apply primitive (digital image processing) operators to an image. 
Discussion of these low-level operators consumed a considerable amount of time at the ex~nse of higher 
level image understanding algorithms. In recent years it was also becoming apparent that there was increasing 
interest in image processing from disciplines other than Computer Science and Electrical Engineering. 
Faculty from many diverse academic units such as the School of Pharmacy, the Physics / Astronomy Department, 
the Animal Science Department, the Civil Engineering Department and the Anthropology Department had expressed 
interest in having students that could assist them with image processing related work. With this background 
in mind, the directors of this project set out to establish an undergraduate interdisciplinary course 
in Digital Image Processing that would have two principal objectives. First, it would provide a broad 
classroom and laboratory exposure to most of the topics in digital image processing. Second, the image 
processing assignments were designed to illustmte the utility of image processing in a wide variety of 
interdisciplinary problem domains to avoid provincial thinking by the students. Overall Course Structure 
The course as implemented was structured to have three main graded components which were (1) laboratory 
assignments, (2) an independent project and (3) written examinations. The first two of these components 
required direct interaction with NSF ILI funded laboratory hardware and software. Work in the laboratory 
was emphasized to provide hands-on reinforcement of the concepts discussed in the classroom and in the 
text (IXgitul Image Processing, by Wayne Niblack). Laboratory assignments were designed to include both 
clinical (idealized textbook) examples as well as pathological cases in order to show students the limitations 
inherent in many of the algorithms inherent in the text. Where feasible, assignments incorporated real-world 
images that would benefit from enhancement by one or more of the discussed algorithms. For example, one 
assignment involved enhancing the contrast of recently discovered sunken ships in the depths of the Atlantic 
Ocean. The Instructional Laboratory The laboratory that made possible the teaching of the digital image 
processing course consisted of six Silicon Graphics Inc. (SGI) Personal Irises (4D/20) with an Image 
Technology Inc. Series 150 (ITI -150) Image Processing System. This hardware configuration was integrated 
with image processing software supplied by G.W. Harmaway and Associates (Boulder, Colorado). The image 
processing software packages included Hardware WHIP (for fast real-time image processing on the ITI -150) 
as well as Virtual WHIP for image processing on the CPU s of the Personal IRIS workstations. This combination 
of virtual and hardware image processing capabilities proved to be extremely useful since students could 
develop many of their image processing algorithms on any of the workstations (using Virtual WHIP) and 
transport them to the real-time system (using Hardware WHIP) with minimal difficulty. Image Processing 
Lab Assignments The required laboratory assignments themselves consisted of the following: 1. Image histogramming 
and image enhancement using histogram equalization. 2. Image gradient operations to detect edges (intensity 
changes). 3. Gaussian filtering to smoothe out random noise in an image. 4. Region growing to find 
image areas of similar intensities. 5. Fourier transformations to selective y remove noise or enhance 
certain features. 6. Image warping operations in which the two-dimensional geometries of images were 
altered. 7. Image subtraction to determine which features vary from frame to frame.  Each of the above 
assignments was augmented with in-class discussion of the goals of the assignment and a handout that 
explained the software logistics of how to perform the specific processing. Generally, two Unix shell 
scripts were provided with each assignment. These showed how to accomplish the processing using Virtual 
WHIP as well as Hardware WHIP. For purposes of illustrating the handling of a laboratory assignment, 
the image histogramming assignment (#1 above) is examined in the next sections. In Class Discussion 
of Lab Assignments The main textbook provided the foundation for the theory associated with each laboratory 
assignment. For the case of the histogram operations in the first assignment, in-class discussion followed 
along the lines of how to construct a histogram from image data and how images can be characterized based 
on the image histograms derived. For this particular assignment as well as others, readings and discussions 
were augmented by more detailed mathematical analyses such as those given by Pavlidis (Algorithms for 
Graphics and Image Processing). After the theory of a particular class of algorithms was discussed, the 
emphasis shifted to the appropriateness of their application. Since transforming an image histogram is 
typically done to alter image contrast, it is particularly easy to provide examples with which most students 
are familiar in order to illustrate the utility of contrast enhancement. Such examples include the enhancement 
of images taken of the Titanic following its discovery in the North Atlantic Ocean as well as the images 
of the outer planets taken by Voyager spacecraft. The speafic data with which students dealt for this 
assignment were low contrast images from a 19th century sailing vessel that had been sunk (in somewhat 
murky waters) off the coast of South Carolina and a much higher contrast image of a black horse on a 
light background. Performing the Laboratory Assignments Each laboratory assignment stated the purpose 
of the assignment, the methodologies to be employed, the results to be turned in, and specifics relating 
to which software (image processing) primitives to use. To make the shell scripts more transparent to 
the students, printed commentary augmented execution of image processing primitives. For example, Table 
1 illustrates the actual shell script for invoking the hardware WHIP commands for performing histogram 
equalization. Where appropriate, the script file itself causes descriptive text to appear on the workstation 
or in the image processing window itself. The purpose of the script file is clarified (lines 1 and 2). 
Frame buffer (image memory) O is selected and the original image is viewed (lines 3 and 4). A message 
is printed on the terminal stating that an image histogram is being constructed (line 5) after which 
the histogram is computed and graphed (lines 6-9) and the image is displayed using an equalized histogram 
(lines 10-12). Appropriate labels for each relevant image are then placed on the display screen (lines 
13-20). In class, the nature of each image processing primitive in the script file is discussed. If students 
desire to explore various options of individual operators, there are online manual descriptors associated 
with most of the image processing primitives embedded in WHIP that can be invoked by using the Unix u 
command. This feature is particularly useful when one needs to know the capabilities or arguments of 
a particular operator. 1. # Purpose Produce a histogram equalized :lmage. 2. # Example invocation: h_histogram 
xxx.pic 3. source locate 0 4. view $1.pic 5. echo Histogram equalizing image in frame buffer O [al]. 
 6. cpfb al ah 7. hist > temp.hist 8. source locate bl 9. graph < temp.hist 10. histeq < temp.hist 
> temp.gam 11. source locate ah 12. gamma temp.gam 13. source locate 0 14. p_label The Original Image 
 15. soarce locate 1 16. p_label The Histogram E.quatized Image 17. echo Now displaying the histogram 
equalized image in frame buffer 1 (ah). 18. echo The original image is in frame buffer O (al). 19. 
echo The raw histogram is in frame buffer 2 (bI). 20. echo  Table 1: Shell Script h_histogram Learning 
from Experimentation The primary objective of each laboratory assignment is to increase the students 
understanding of the motivations for using various image processing operations. This is especially important 
when one considers combining several operations in order to achieve a desired result. Hence, each assignment 
typically involves applying an image processing operation to several images with different characteristics, 
For the case of histogram equalization, students should recognize that visual detail will be enhanced 
if the original image has a relatively well distributed histogram and will lose detail if there are, 
for example, two strong peaks. The following list outlines each of the assignments with a brief description 
of the educational goals to be achieved. 1. Histogram construction and equalization This assignment involved 
taking a raw image and computing its histogram. This was followed by equalization of the histogram and 
construction of a gamma table that could be used to stretch the image contrast. The results of applying 
histogram equalization to images of high and low contrast were to be discussed. 2. Edge detection For 
this assignment students were to investigate and characterize the effects of applying Roberts and Sobel 
edge operators to two images, one with sharp edges and one with diffuse edges. The results to be reported 
included discussing what happens relative to the width of the edges and the intensities of the edges 
generated as the size of the operators varied. 3. Gaussian Filtering The third laboratory assignment 
involved examining the effects of applying several Gaussian filters to a digitized image with high frequency 
noise. Gaussian kernels of varying widths and standard deviations were convolved with this image and 
the effects on the output image were noted. In particular, students were to note which filter produced 
an enhanced image in which most detail was preserved as well as which filter tended to blur the image 
more and to explain why these effects occured. 4. Region Growing The fourth laboratory assignment was 
the only one which involved non-command-level programming. Students were to develop a C program that 
could recursively grow regions using an 8-connected  algorithm (see Computer Graphics by Hearn and Baker). 
A set of seed pixels was interactively input (via mouse) that specified the location of a starting (x,y) 
coordinate. From that point, each of the 8 neighbors was examined to determine whether it was within 
a tolerated intensity range. If so, it was added to the region and filled with a color consistent with 
the seed pixel. Otherwise the search continued recursively. The specific data with which the students 
dealt was an image of a printed circuit board. The region growing illustrated how the metallic traces 
on the board could be followed for inspection purposes. 5. Fourier Transformations For the fifth laboratory 
assignment, students were to apply Fourier transforms to one image that was provided for everyone in 
addition to images that they selected in order to enhance some feature or remove some undesirable characteristic. 
The standard image had high frequency noise which could be removed by blocking out (band stopping) the 
high frequencies in the frequency domain. High pass filtering preserved this noise in addition to enhancing 
edges. The basic flow of control was to (1) convert a spatial domain image to frequency domain image, 
(2) selectively edit the frequency domain, and (3) convert the editted frequency domain image back to 
a spatial domain image for display. This three step procedure had the advantage of illustrating the full 
(forward/inverse) cycle of Fourier transformations by showing the image as it appeared in both spatial 
and frequency domains, and facilitated discussions of the equivalence between convolution in the spatial 
domain with multiplication in the frequency domain (and vice versa). 6. Image warping The image warping 
assignment had two primary goals which were to illustrate registration between two images and to show 
how polynomial mappings from one image space to another are defined. The interactive mouse was used to 
select control points between two images (call them A and B). A polynomial warping function between the 
two images then mapped image A into a subregion of image B. Experimentation with control points and the 
order of the warping polynomial gave insight on how to deform images based on knowledge about sensor 
motion or based on the geometry of observed objects. 7. Image subtraction Real time pipelined image 
operations were demonstrated with image subtraction in which a static reference image was continuous 
y subtracted from incoming digitized video. The resulting displayed image showed Ii ght areas only where 
the image  200 changed relative to the stored reference image. Hence, if the camera were pointed out 
the window toward the street below, pedestrians and moving automobiles would show up as white regions 
on a static black background. The particular value of this laboratory experiment was to facilitate specialized 
pipelined image processing architectures such as the ITI -150, that can continuous y perform simple 
operations such as subtraction or convolution on incoming or stored data. Independent Projects The laboratory 
equipment was also used to support independent projects for the Digital Image Processing Course. While 
a detailed discussion of each of these would require more space than is currently available suffice it 
to say that each student pursued a topic that was of particular interest to him, within the context of 
his major. The better projects included studies relating to the extractions of circles and lines using 
Hough transforms, Butterworth and exponential filtering of images, animation, and adaptive filtering 
and enhancement of chest X-rays. Other Instructional Uses of the Image Processing Laboratory Aside from 
the Digital Image Processing Course, the laboratory has been used for several other instructional endeavors 
as well. The Silicon Graphics workstations were incorporated into the undergraduate Computer Graphics 
Course during the off-semester for Digital Image Processing. The Personal Irises were of particular value 
in this course due to their true color (24 bit) display capability as well as their ability to render 
real time three-dimension scenes. Numerous assignments that emphasized dynamic wireframe and solid models 
were given. In previous offerings of the course, it was impractical to attempt such dynamic renderings 
(on PCs) due to their slow computational and rendering speed and due to their limited (16 color) capability. 
In addition, students in astronomy who were sponsored by the National Science Foundation s Research Experiences 
for Undergraduates (REU) program worked on the Personal Irises under the supervision of Dr. Earl Spillar. 
The IRAF image processing package was installed on 3 of the machines, and 6 of the 8 REU students anat 
yzed astronomical data obtained at Lowell observatory, Lick observatory, and the University of Wyoming 
Infrared Observatory in the optical and infrared bands. The students were advised by 6 astronomy faculty 
in the department. The workstations were especially important to the success of the REU program during 
the summer of 1991, since the Physics/Astronomy department does not have sufficient computer resources 
to hamile so many students working intensely at image processing. It is anticipated by Dr. Spillar that 
that severat student papers will result. Suggested Revisions When considered in its entirety, the basic 
structure of the Digital Image Processing Course is an appropriate one worthy of continuation. However, 
it is intended to enhance the course in two ways during its next offering. The first of these is to attempt 
to recruit more students from additional disciplines. Although notices advertising the new Digital Image 
Processing Course were posted around campus, the course attracted students only from Computer Science 
and Electrical Engineering. A more concerted effort needs to be made in related courses (e.g. courses 
involving image data acquisition and anal ysis such as astronomy, geology and geography). The second 
improvement involves requiring knowledge of the C programming language as a prerequisite. In its initial 
offering, the course required only knowledge of a structured programming language (e. g. Pascal), the 
assumption being that enough knowledge of C could be learned in a relativel y short time in order to 
solve problems like the recursive region growing assignment. Due to the complexity of the image processing 
subroutines, particular y those involving pointers and pointer arrays, however, this proved to be an 
overly optimistic assumption. Since C is now becoming the programming language of choice for several 
majors, requiring it as a prerequisite should now be feasible and this was in fact suggested by the students 
who took the course initially. Conclusions The use of Unix based workstations in concert with specialized 
image processing hardware is a solid laboratory foundation upon which to teach digital image processing. 
Use of a virtual image processing packd~ge (utilizing workstation CPUS) is a cost effective way in which 
to develop image processing algorithms that can be ported to the specialized image processing hardware. 
Experiments performed in the laboratory reinforce the theoretical knowledge gained from the textbook 
or )from in-class discussion with the visual feedback enthusiastically received by the students. 
			
