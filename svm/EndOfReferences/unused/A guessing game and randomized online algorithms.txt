
 A Guessing Game and Randomized Online Algorithms Steven S. Seiden Department of Computer Science 298 
Coates Hall Louisiana State University Baton Rouge, LA 70803 sseiden @ acm.org ABSTRACT We present the 
first general framework for proving lower bounds for randomized online algorithms using the von Neu- 
mann/Yao principle. This framework encompasses and ex- plains many existent lower bound results, and 
allows us to prove several new ones. The foremost of the new results is a lower bound of 1.58197 for 
the online TCP acknowl-edgment problem of Dooly, Goldman and Scott [11]. Oth- er new results include: 
a lower bound of 1.34880 for ran- domized online two-machine flow shop scheduling, a lower bound of 1.15775 
for randomized online total completion time scheduling on parallel machines and a lower bound of 1.06532 
for scheduling with machine cost. Out method pro- vides a sort of 'Master theorem' for proving randomized 
low- er bounds. 1. INTRODUCTION The yon Neumann/Yao principle [26; 27] is an important tool in the study 
of randomized algorithms. This principle asserts that, given some problem, if one shows a distribu- tion 
over problem instances such that all deterministic algo- rithms incur an expected cost of at least x 
then x is a lower bound on the cost incurred by the best possible randomized algorithm. In practice this 
approach seems to easier than the alternative: devising an adversarial strategy against the set of all 
randomized algorithms. This principle was first applied within the context of com- petitive analysis 
of online algorithms by Borodin, Linial and Saks [8]. Since that time it has repeatedly shown its use- 
fulness in this area. However, despite the fact that many proofs via the von Neumann/Yao principle share 
a common structure, beyond this principle there are no general tools to aid researchers. In this paper, 
it is our goal to try to rectify *Part of this work was done while the author was a post- doc at the 
Max-Planck-Institut for Computer Science. This work was partially supported by the EU ESPRIT LTR Project 
N. 20244 (ALCOM-IT), WP 3.2 Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without flee provided that copies are not made or distributed for 
profit or commercial advamage and that copies bear this notice and the full citation on the first page. 
To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific 
permission and/or a fee. STOC 2000 Portland Oregon USA Copyright ACM 2000 1-58113-184-4/00/5...$5.00 
this situation by providing a general framework which elu- cidates many existing results, and allows 
us to prove several new ones. One of the main difficulties in using the von Neumann/Yao principle to 
prove lower bounds is that one has to find the right distribution. In the past, this has been a process 
shrouded in mystery, as few researchers have bothered to explain how they found a distribution after 
the fact. We pro- vide a sort of 'Master theorem', which reduces the problem of finding the right distribution 
to that of simply checking a number of cases and plugging parameters into the correct general solution 
form. Another problem is as follows: When there exists a mapping from the set of all deterministic algorithms 
for a given set of inputs to the set of integers or to ~k, the von Neumann/Yao principle is easily applied. 
However, when the set of all de- terministic algorithms for a given set of inputs has a more complicated 
structure, application often seems intractable. For instance, if the algorithm is given multiple inputs, 
the decision of the algorithm for the ith input might depend on inputs 1,... , i - 1. The set of all 
deterministic algorithms is then a set of functions, and proving something about such a set might be 
difficult. However, in our framework we over- come this problem for certain types of online problems, 
and thereby show several new lower bounds. The only previous general research along these lines that 
we are aware of is that of Borodin and E1-Yaniv [6; 7]. They note that it is possible to use the von 
Neumann/Yao prin- ciple incorrectly when proving lower bounds on the com-petitive ratio. Thus, they have 
formalized the use of this principle with respect to competitive analysis. Many online problems have 
as a sub-problem what we call the rent/buy problem. Typically one has to decide whether to stay in one's 
current state, and incur a certain amount of cost per time unit (rent), or pay some fixed cost to move 
to another state (buy). The classic example is the well-known ski-rental problem [17], where the rent/buy 
decision is the entire problem. Other examples include: In the TCP acknowledgment problem, one has to 
de- cide how long to wait before sending an acknowledg- ment for a received packet [11]. Waiting incurs 
a cost. However, it can also be beneficial, as multiple packets can potentially be acknowledged together. 
 In scheduling problems, one often has to decide at what point in time to start an available job [20; 
24; 25]. Waiting is often beneficial, as more information  about the problem is learned as time passes. 
However, it is also wasteful, as available machines are idle. In the page replication problem, one has 
to decide whether to send individual requested data items, or the entire page, to the location of a request 
[1; 14]. If enough requests occur at a location, sending the entire page is fruitful. * In the scheduling 
problem of Imreh and Noga [16], one must decide when to buy new machines. Buying machines is expensive, 
but with more machines, more work can be accomplished per time unit. If one looks at the randomized lower 
bounds which have been proven for such problems, a pattern begins to emerge. All the proofs share a common 
structure. In fact, what we show is that all of these problems (and potentially many more) are reducible 
to a single general problem. By study- ing the general problem we obtain lower bound results for many 
specific problems, and a better overall understanding of online computation. Our presentation is organized 
as follows: In Section 2, we present definitions and background material necessary for what will follow. 
In Section 3, we define a guessing game, which is easy to understand, but complex enough to encom- pass 
a wide range of online problems. We explain how to calculate a lower bound on the competitive ratio for 
this game In Section 4, we explain how one finds the best distri- bution for a given game: The distribution 
which yields the highest lower bound. In Section 5, we make some remark- s about the generality of our 
framework. In Section 6, we give a simple example, while in Section 7, we prove a new result using the 
full generality of our framework: We show that no randomized online algorithm for TCP acknowledg- ment 
is c-competitive if e < ~ ~ 1.58197. This problem is closely related to the ski rental problem. Therefore, 
at first one might think that such a lower bound would be eas- ily forthcoming. However there are a number 
of important differences between the two problems which require one to use several new ideas. In Section 
8, we list a number of oth- er results which follow almost as corollaries to our general method, several 
of which are new. Finally, in Section 9, we present conclusions. 2. DEFINITIONS AND PRELIMINARIES Competitive 
analysis is a type of worst case analysis where the performance of an online algorithm is compared to 
that of the optimal offline algorithm. This approach to analyz- ing online problems was initiated by 
Sleator and Tarjan, who used it to analyze the list update problem [23]. The term competitive analysis 
originated in [18]. For a given input se- quence a, let costA(a) be the cost incurred by an algorithm 
,4 on a. Let cost(a) be the cost of the optimal solution for a. An algorithm .4 is c-competitive if costA(a) 
_< c" cost(a), for all job sequences a. (For certain problems, an addition- al additive constant is 
allowed. We do not consider such problems here.) If the algorithm is randomized then we use E[costA(a)] 
instead of costA(a) in the above definition. The competitive ratio of .4 is the infimum of the set of 
values c for which .4 is c-competitive. The competitive ratio of a problem is the infimum of the competitive 
ratio of .4 over all online algorithms -4. Since competitive analysis is a type of worst case analysis, 
we imagine that the input a is produced by a malicious adversary. This adversary's goal is to make the 
algorithm perform as badly as possible. For the purposes of analyzing randomized algorithms, there are 
several types of adversaries [3]. We use an oblivious adversary; an adversary that never learns the random 
choices of the algorithm. Our concern in this paper shall be to prove lower bounds on the competitive 
ratio of problems. The variant of von Neumann/Yao we use here is as follows: Suppose for some problem 
we have a distribution 79 over inputs and a positive constant c such that E[costA(a)] > c. E[cost(a)] 
 for all deterministic online algorithms .4 and E[cost(a)] ¢ 0. Then c is a lower bound on the competitive 
ratio of the prob- lem. Since we are always using this principle, from this point forward when we say 
algorithm, we mean deterministic al- gorithm, and when we say adversary, we mean an adversary who draws 
inputs from some fixed distribution. We shall make use of Lambert's W function. Wk(z) is the kth solution 
to the equation z = Wk(z)e w~(z).  3. THE GAME We consider a game which is fairly simple, but general 
e- nough to provide lower bounds for a large number of online problems. The game is as follows: There 
are two players, the algorithm and the adversary. The game consists of a number of rounds. To start the 
game, the algorithm is asked to pick a real number Xl C [0, 1]. The adversary then either chooses to 
say stop, in which which case the game is over, or picks a number Yl E [0, 1]. If Xl > yl the algorithm 
wins, otherwise it loses. If the adversary did not say stop, the game continues in the same fashion, 
up to a maximum of n rounds. I.e. the adversary must say stop in the nth round, if he has not already. 
The adversary is however restricted in the following way: he must in advance choose a probability distribution 
7) and act according to this distribution. Further, he must reveal this distribution to the algorithm. 
More formally, in the ith round: The adversary stops with probability qi. If the adversary does not stop, 
the number yl is picked according to the probability density function pi(z). For this to be a valid distribution 
we require that 1 ql + fo pi(z)dz = 1. In the nth round we fix q,~ = 1. The cost to the algorithm for 
the ith round may depend on the outcome of previous rounds. We adopt the following notation: an outcome 
string is some sequence ~ E ~n = U~=o{W,~} 3. We indicate the. empty string by e. The jth position in 
the string indicates whether the algorithm wins or loses the jth round. Now suppose we are in the ith 
round and the outcomes so far are given by ft. If the adversary says stop, the algorithm pays ~¢ + fi~¢ 
 xi. If xi > yi then the algorithm pays 7¢ + 5¢ yi. Finally, if xl < yi then the algorithm pays X¢ + 
¢~ " xi + we yi. The total cost to the algorithm is the sum of the costs incurred in each round. To 
ensure that costs are always positive, we require that a¢ + min{0,/3¢} _> 0, "7~ + min{0, ~} _> 0, X~ 
+ min{0,¢¢,w~,¢~ +w~} > 0, (1) for all ~ E n. The formal description of a game G consists of n along 
with a~,fl¢,7¢,6~,X~,¢~,w~ for ~ E ~. Define A¢ to be the expected cost to the algorithm for the remainder 
of the game, given ¢ is the outcome so far. We calculate this using the following recurrence A~ = q~(~ 
+ ~x~) + p~(~)(.~ + ~z + A~)d~ + pi(z)(x~ + ¢~xi + w~z + Ace)dz, i where i = [gl+ 1. In the above sum, 
the first term accounts for the cost if the adversary stops, the second term accounts for the cost if 
the algorithm wins and the third determines the cost if the algorithm loses. The algorithm's total expect- 
ed cost is just A~. We wish to lower bound the cost to an algorithm for game ~. Unfortunately, it is 
difficult to use A to do this direct- ly. The problem is that in general xi can be a function of the 
previously revealed part of the game. I.e. in general xi = fi(yt,... ,yi-1) for some set of functions 
fl,... ,f~. We want to show a lower bound on the cost for all such sets of functions. However, working 
with such an algorithm de- scription would seem to be intractable. Fortunately, there is a simple way 
to overcome this problem. We lower bound the algorithm's expected cost by B~ where B~ = min {qi(a~ + 
t3~u) + /: pi(z)(% + 5~z + B~,)dz O<u<l + p~(z)(x~ + ¢~u + w~z + B~)az , and again i = I~1+ 1. It is 
easy to see that this provides the desired lower bound, as at each round the algorithm can do no better 
than to minimize its expected cost for the remainder of the game. We now consider the adversary's cost. 
Suppose there are k _< n rounds. The adversary pays % + 5~ yl for each round i < k where g = w i-~. 
I.e. if the algorithm wins it incurs the same cost as the adversary. In the kth round, the adversary 
pays min{a~, c~ +~}, the same as the minimum cost to the algorithm. The expected cost to the adversary 
is calculated via the recurrence Oi = qi min{c~, c~ + ~} + pi(z)(% + ~z + O~+~)dz, (2) where ~ = w i-1. 
The competitive ratio for game ~ is c(~) = sup~ inf.a A~/Oo. But as previously explained we have c(~) 
_> sup~ B~/Oo. Therefore, it is only a question of finding the best distribu- tion 7).  4. THE BEST 
DISTRIBUTION In this section, we find the distribution which maximizes the competitive ratio. Although 
the technique we use is certain- ly understood by certain researchers, it would seem that it has never 
been formalized, and therefore is understood by only this small group. Part of our contribution is to 
take the mystery out of finding the right distribution. We find our distribution in a bottom up fashion. 
I.e. we derive the distribution for the last round first, and then the distribution for the second to 
last round from that, etc. Suppose we have already picked qi+l, pi+l,  , q~- 1, P~- 1. Then we wish 
to pick qi and pi to maximize: min {qi(a~ + ~u) + /?pi(z)(% + 5~z + B~)dz 0<u~l + p~(z)(x~ +¢~u+~z+B~)az 
. This assumes that we have chosen one particular g and wish to maximize the algorithm's cost for that 
g. A heuristic that usually yields good results is to pick q so that the algorithm has won all the previous 
rounds, i.e. g = w i-1. Since we have fixed the distributions qi+l, pi+l,  , qn-'l, pn-1, B~w and B¢e 
are constants. From this point forward, since we are considering only a fixed round with fixed previous 
out- comes, we drop subscripts. The problem we need to solve is equivalent to that of finding p and q 
to maximize min ¢(u), O<u<l ¢(~) ----q(a + flu) + p(z)(r + 5z)dz fo ~ + p(z)(X + Cu + wz)dz. where F 
= ff~ + S~h and X = X¢ + Bet. In general, the form of our solution depends on the values a, fl, F, 5, 
X, ¢ and w, as will be explained in the paragraphs to follow. Define P(x) -= fop(z)dz. Except for in 
degenerate cases, the distribution which maximizes c = mine ¢(u) satisfies ¢(u) = e for all u E [0,1]. 
We call this the principle of equality. Since ¢(u) is constant with respect to u, we have oJ~9(U)/OU 
j ~-0 for all j > 1. We find that 0¢(u) -f~q+¢(1-q)+Xp(u)+0up(u)-¢P(u), Ou 02¢(u) -(0 -¢)p(u) + Ap'(u) 
+ Oup'(u), Ou 2 where A = F-X, 0 = 5-¢-w. For ¢ # 0, we findp by solving the differential equation (0 
-¢)p(u) + Xp'(u) + Oup' (u) = 0. For ¢ = 0, we solve ~q + Ap(u) + Oup(u) = O. The form of the solution 
depends on whether the constant coefficients are zero or not. The boundary conditions used axe q + P(1) 
= 1 and ¢(0) = ¢(1). We list the most common solutions in Table 1. Note that when using these distributions 
with specific parameters, one should verify that the distribution is valid. I.e. all values should be 
finite and we must have q >__ 0 and p(z) >_ 0 for all z [0, 1]. As example, we give the derivation for 
Case 4. In this case, the desired function p satisfies Ap' (u) -- Cp(u) ---- 0. This differential equation 
has solutions of the form p(z) = eCZ/~v, I II Conditions 1 ¢= o,),# o,o #o ¢ = o,),# o,o = o A ¢ #o,;~#o,o 
#o ¢# o,;~#o,o=o ¢ ¢ +/~(e-¢/~ - 1) ¢#o,),=o,o #o ¢ ¢-~ ¢ # o,),¢ o,o ¢ o, A = --O,w : 0 where v is 
some real constant. f~ p(z)dz = 1 and find ¢(1 - v = A(e¢/x To find q, we proceed as follows: ¢(0) Table 
1: The distributions To find v we solve q + q) _ 1)' = x(1 -q) + c~q + ~ ~p(z)az = ¢(1) = F(1 -q) + 
(a + fl)q + 6 zp(z)dz 1) = r(1 -q) + (a +/3)q + 6(1 -q) 1 ¢ e ¢/x -1 " which implies ¢e¢/~ q = /3- (/3- 
¢)e¢/~' Back substituting and simplifying, we get the solution in Table 1. In certain degenerate cases, 
constant ¢ is impossible, in which case we usually want to pick y E {0, 1}. As these cases usually do 
not arise in practice, we omit them here. 5. REMARKS ON THE GAME The reader may wonder why we do not 
consider more general games. For instance, one might draw the numbers x~ and yi from some interval other 
than [0, 1]. However, this case is easily accommodated within our framework--we can map any interval 
onto [0, 1] by changing cost functions. In general, it is also possible to consider non-linear cost functions, 
or functions where the cost during a particular round may depend on the values of the variables at previous 
rounds. We do not consider such cases here, as such compli- cations do not seem to be required. We have 
tried to make p(z) ~q A+Oz q~(A + Oz) ¢/0-1 (~ + o)¢/o q~ Ae¢(1-z)/)~ q/3z¢/0-1 ¢(1 -z)~/°-2 min~ ¢(u) 
aq + X(1 -q) -w(/3q + )~(1 - q)) 5-w aq + ½(2X + w)(1 - q) otq q- X(1 -- q) -- w(flq + A(1 -- q)) 5--to 
aq .q- X(1 --q) --w(flq .q- A(1 --q)) 5-w aq Jr X(1 --q) --~wq X our framework as simple as possible, 
but as complicated as necessary. In fact, for some problems, it is sufficient to consider a spe- cial 
subtype of game which we call simple. In a simple game, n=2 anda~ =al =fl~ =/~t =0. A simple game is 
en- tirely specified by a,,/3¢, %, 6,, X~, ¢~ and w~. Therefore, we shall drop the e subscript for simple 
games. It is also possible to consider a discrete version of our game, where the guessed numbers are 
integral. We shall consider this in the full-version. Finally, we note that it is sometimes useful to 
have an unfair game. This means that the cost functions for the algorithm and the adversary differ. This 
can be to the favor of the algo- rithm, or to that of the adversary. Unfairness is often useful in abstracting 
away messy details [2; 22; 5; 14; 12]. More precisely, we mean that the adversary's cost is calculated 
using a~,fl~, %, 6~, X~, ¢~ and w~; whereas the algorithm's cost is calculated using ~', fl', 7'~, 6'¢, 
X'¢, ¢~ and w'~. 6. A SIMPLE EXAMPLE We consider an example from the machine scheduling litera- ture 
which is easily understood and which can be formulated as a simple game. From this formulation we get 
immediately an alternative proof of the previously shown result. The problem is as follows: There are 
two machines and a set of jobs. Each job has a release time rj and a processing time pj. The algorithm 
must assign each job to both a machine and a start time, such that no two jobs are running at the same 
time on a given machine, and no job starts before its release time. For job j let sj be the start time 
in the algorithm's schedule. Define the completion time for job j to be cj = sj +pj. The makespan is 
maxycj. The algorithm's goal is to minimize the makespan. In the online version of this problem jobs 
are unknown before their release times. This problem is studied in [10; 24; 20; 25]. The best random- 
ized lower bound is due to Noga and Seiden [20]; we show that their result is easily obtained using our 
framework. THEOREM 7.1. 1 The competitive ratio of TCP acknowl- edgment is at least THEOREM 6.1 (NOGA 
&#38; SEIDEN [20]). The competitive ratio of 2[rjlCma× is at least e 1 --> 1.58197. 1-> 1.21207. e-1 
2W-1 (-e -3/2) PROOF. Let v < 1 be a real constant. At time 0, we give the algorithm two jobs with processing 
time 1. Now we either stop, in which case no further jobs arrive, or give the algorithm a job of processing 
time 2 -y at time y < v. If the algorithm starts the second size 1 job at time x, and no further jobs 
arrive, it pays 1 + x. If the job of size 2 -y arrives at time y < x, the algorithm can create a schedule 
with makespan 2. On the other hand, if the job of size 2 - y arrives at time y > x, the algorithm pays 
at least 3 - y. This is a simple game with a=l, /3=v, 7=2, 5=0, X=3, ¢=0, ~d -~---V. From Case 1 in Table 
1 and (2) we get 1 vq q --i-in(i-v)' p(z) --1-vz' 1-v 1  B~ = 2 + Oo = 2 + ln(1 --v) --1' ln(1 --v) 
--1' Since the adversary picks v, the competitive ratio is at least v 1+ max 0<~<1 1 - 21n(1 -v)' which 
yields the desired bound. []   7. A NOT-SO-SIMPLE EXAMPLE In this section we prove a new result that 
requires the full generality of our framework. We consider the online TCP acknowledgment problem, in- 
troduced by Dooley, Goldman and Scott [11]. In this prob- lem, a number of packets are received. Each 
packet j has receipt time rj and weight wj. (In the original formulation, all packets have equal weight. 
However, a packet of weight x has the same effect as x packets of weight 1. Weights make the proof a 
bit cleaner, but are not necessary.) J is the set of all packets. The latency of S C J at time t is L(S,t) 
= E(t rj)wj. jes - All packets must be acknowledged at some time after their receipt. A single acknowledgment 
acknowledges all packet- s received since the last acknowledgment. The cost of an acknowledgment is 1. 
We would like to acknowledge all packets quickly, using as few acknowledgements as possi-ble. A schedule 
7r is a positive integer k along with a par- tition J1,... ,Jk of J and real numbers al,... ,ak. The 
acknowledgment time of j 6 Ji is ai. Therefore we must have a~ >_ maxjej~ rj. The cost of a schedule 
is k cost(% J) = k + E L(J,, ai). i=1 Note that the cost function is used in [11] is a special case 
of the one we use here. The optimal offline cost for J is cost(J) = inf~ cost(r, J). This value can be 
calculated using a simple dynamic programming algorithm [11]. We show that: 596 PROOF. The input consists 
of up to n packets. The weight of the ith packet is v i, where v > 1 is a real constant. Sup-pose the 
ith packet has arrived. Now we either stop, in which case no other packets arrive, or packet i + 1 arrives 
after an amount of time yi/v i passes. The online algorithm picks a number xi and sends an acknowledgment 
after time x~/v i passes if it does not receive packet i ÷ 1 first. With-out loss of generality, xi < 
1 since if no packet arrives by that time, the algorithm knows that no further packets will be forthcoming. 
The algorithm's xi, and the adversary's yi, correspond to the values xi and yi in the game, respectively. 
The cost to an algorithm during the ith round depends on the number of packets outstanding. This is equal 
to the number of preceding rounds where the algorithm has not acknowledged, i.e. the algorithm wins. 
For an outcome string q we define g(q) to number of trailing w's in ~. I.e. g(g) = i iffg 6 E*~w ~Uw 
~. Then we define our game as follows: g(~) a¢ = 1, fie = Ev-i, 7¢ = 0, 5¢ = J3~, i=0 X~ = 1, ¢~ = fie, 
w~ = 0. The adversary's strategy is to send a single acknowledgment for all packets at the very end. 
We calculate the adversary's cost using (2). We are unfair in calculating the algorithm's cost. For the 
algorithm we use l I I l a~ = 1, ~ = 1, -y~ = 0, 5~ = 1, X~! = 1, ¢'~ = 1, w~! = 0. Clearly this is 
a lower bound; essentially we charge the algo- rithm only for the latency of the current packet. Since 
these values depend only on ];I, we reindex using the integers in the obvious way. The result is that 
B~ = DIe I where Di-1 = min ~qi(~ + fllu) + pi(z)(')'i + 5iz + Di)dz 0<u<l [ /o + ~lpi(z)(~i + ¢iu + 
¢diz + Di)dz}." From Case 4 in Table 1 we get the following distribution: 1 1 (1-1 qi=-, pi(z)=--Di=l+ 
7) D~+1' D,~-I =1. e e z ' In the remainder of the proof, we show that Do e lim lim ---- n-~oo v-~oo 
O0 e - 1 Define p = 1 - 1/e. It is easily seen that 1 -p~ Do = 1-p Using our distribution and (2) we 
find 2 - e - v i -vTM + ev TM Oi = e(v--1)v i + pOi+l' 0~-1 =1. 1Noga [19] has an independent proof. 
Define O~ = lim~-~¢~Oi. Note that O~ = lira ( 2-e-vi-v~+l +evi+l ) + p 2 --e --v i --v i+l -~ ev TM = 
lira + p lim 0i+1 ~ e(v -1)v i v-+oo = p+pOi*+I, and therefore O~ = p~-i + (p _ p~)/(1 -p). To complete 
the proof, we note that the competitive ratio is at least 1 -p'~ e lim lim Do= lira Do= lim + ~-:--1---=--" 
'~¢~ "-~¢~ ~00 n-~ O-~ '~ p 2p ~ e - 1 []  8. OTHER RESULTS We list here several other results which 
can be obtained by our method. Details on these results appear in Appendix A. The first is a new result 
for the problem of scheduling on one machine with delivery times, which is studied in [15; 21; 24; 25]. 
The following result can be proved using a simple game THEOREM 8.1 (STOUGIE~ VESTJENS [24; 25]). The 
com-petitive ratio of l lrj, qj I Lmax is at least 1 1 + Wl(-~) > 1.30201. By using a non-simple game 
we get a better result: THEOREM 8.2. The competitive ratio of the scheduling prob- lem l lrj, qjlLmax 
is at least 1.3~9~3. This implies that the same bound holds for minimizing the makespan in 2-machine 
flow shops: COROLLARY 8.1. The competitive ratio of the scheduling problem F21rj]Cmax is at least 1.3~9~3. 
The problem of scheduling with machine cost is introduced in [16]. We show the first randomized lower 
bound for the list variant of this problem: THEOREM 8.3. The competitive ratio of the list variant of 
scheduling with machine cost is at least 1 1 + ~ > 1.06532. The problem of scheduling parallel machines 
to minimize the total completion time is studied in [24; 25; 9]. A randomized lower bound for the single 
machine case is known: THEOREM 8.4 (STOUGIE ~Z VESTJENS [24; 25]). The com-petitive ratio of llrjl~C 
j is at least e --> 1 58197. e-1 This result is easily proven in our framework. As far as we know, no 
general randomized lower bound was previously known. We obtain the following result: THEOREM 8.5. The 
competitive ratio of PIrj[ECj is at least V --V 3 1 + max > 1.15775. 0<.<1 2v 2 + (3- In 16)v + ln16- 
1 The remaining results have all been proven elsewhere. Their proofs all involve only a simple game. 
Note that some of these results were originally proven without use of the von Neumann/Yao principle THEOREM 
8.6 (KARLINet al. [17]). The competitive ra- tio of the ski rental problem is at least e --> 1.58197. 
e-1 THEOREM 8.7 (ALBERS &#38; KOGA [1]). The competitive ratio of page replication in any network is 
at least e > 1.58197. e-1 THEOREM 8.8 (FLEISCHER ~5 SEIDEN [14]). The com- petitive ratio of v-unfair 
page replication in any network is at least el/v e 1Iv --1" THEOREM 8.9 (STOUGIE VESTJENS [24; 25]). 
The com- petitive ratio of Plrj, qjlLmax is at least > 1.26567. 2 + 2W1(-~) 3e THEOREM 8.10 (FLEISCHER[13]). 
The competitive ra- tio of the Bahncard problem with price reduction factor v is at least e e--l+v 9. 
CONCLUSIONS We have presented a general framework for proving lower bounds on the competitive ratio of 
randomized online algo- rithms. We consider this work to be just a first step in this direction. Interesting 
questions yet to be answered include: 1. What other new results can be proven within our frame- work? 
 2. The principle of equality seems to yield the best dis- tribution for "natural" problems. What are 
the exact conditions under which it is guaranteed to give the optimal distribution? 3. Can we develop 
frameworks to handle other problem areas?  10. ACKNOWLEDGEMENT The author would like to thank Gerhard 
Woeginger for sug- gesting this line of research. Further, he wants to thank Esteban Feuerstein for pointing 
out [11]. 11. REFERENCES [1] S. Albers and H. Koga. New on-line algorithms for the page replication problem. 
Journal of Algorithms, 27(1):75-96, Apr 1998. [2] Y. Bartal, A. Blum, C. Butch, and A. Tomkins. A polylog(n)-competitive 
algorithm for metrical task sys- tems. In Proceedings of the 29th ACM Symposium on Theory of Computing, 
pages 711-719, 1997. [3] S. Ben-David, A. Borodin, R. Karp, G. Tardos, and A. Wigderson. On the power 
of randomization in on- line algorithms. Algorithmiea, 11(1):2-14, Jan 1994.  [4] D. L. Black and D. 
D. Sleator. Competitive algorithms for replication and migration problems. Technical Re- port CMU-CS-89-201, 
Department of Computer Sci-ence, Carnegie-Mellon University, 1989. [5] A. Blum, C. Butch, and A. Kalal. 
Finely-competitive paging. In Proceedings of the 4Oth IEEE Symposium on Foundations of Computer Science, 
pages 450-457, 1999. [6] A. Borodin and R. E1-Yaniv. On randomization in on- line computation. In IEEE 
Conference on Computa-tional Complexity, pages 226-238, 1997. [7] A. Borodin and R. E1-Yaniv. On randomization 
in online computation. Information and Computation, 150(2):244-267, May 1999. [8] A. Borodin, N. Linial, 
and M. Saks. An optimal on-line algorithm for metrical task systems. Journal of the ACM, 39(4):745-763, 
Oct 1992. [9] C. Chekuri, R. Motwani, B. Natarajan, and C. Stein. Approximation techniques for average 
completion time scheduling. In Proceedings of the 8th ACM-SIAM Sym- posium on Discrete Algorithms, pages 
609-618, 1997. [10] B. Chen and A. Vestjens. Scheduling on identical ma-chines: How good is LPT in an 
online setting? Opera-tions Research Letters, 21(4):165-169, Nov 1997. [11] D. R. Dooly, S. A. Goldman, 
and S. D. Scott. TCP dy- namic acknowledgment delay: Theory and practice. In Proceedings of the 30th 
A CM Symposium on the Theory of Computing, pages 389-398, May 1998. [12] A. Fiat and M. Mendel. Better 
algorithms for unfair metrical task systems and applications. In Proceedings of the 32nd Annual ACM Symposium 
on Theory of Computing, May 2000. (This proceedings). [13] R. Fleischer. On the Bahncard problem. In 
Proceedings of the 4th Annual International Conference on Comput- ing and Combinatorics, pages 65-74, 
1998. Final ver-sion to appear in Theoretical Computer Science. [14] R. Fleischer and S. S. Seiden. Page 
replication--Variations on a theme. Manuscript, 1999. [15] H. Hoogeveen and A. Vestjens. Optimal on-line 
algo- rithms for single-machine scheduling. In Proceedings of the 5th International Conference on Integer 
Program- ming and Combinatorial Optimization, pages 404-414, 1996. [16] C. Imreh and J. Noga. Scheduling 
with machine cost. In Randomization, Approximation, and Combinatorial Optimization -Algorithms and Techniques, 
pages 168- 176, 1999. [17] A. Karlin, M. Manasse, L. McGeoch, and S. Owick- i. Competitive randomized 
algorithms for nonuniform problems. Algorithmiea, 11(6):542-571, Jun 1994. [18] A. Karlin, M. Manasse, 
L. Rudolph, and D. Sleator. Competitive snoopy caching. Algorithmiea, 3(1):79-119, 1988. [19] 3. Noga. 
Unpublished manuscript, 3un 1999. [20] J. Noga and S. S. Seiden. Scheduling two machines with release 
times. In Proceedings of the 7th Conference on Integer Programming and Combinatorial Optimization, pages 
391-399, Jun 1999. [21] S. S. Seiden. Randomized online scheduling with de- livery times. Journal of 
Combinatorial Optimization, 3(4):399-416, Dec 1999. [22] S. S. Seiden. Unfair problems and randomized 
algo-rithms for metrical task systems. Information and Com- putation, 148(2):219-240, Feb 1999. [23] 
D. Sleator and R. Tarjan. Amortized efficiency of list update and paging rules. Communications of the 
A CM, 28(2):202-208, Feb 1985. [24] L. Stougie and A. P. A. Vestjens. Randomized on-line scheduling: 
How low can't you go? Manuscript, 1997. [25] A. P. A. Vestjens. On-line Machine Scheduling. PhD thesis, 
Eindhoven University of Technology, The Netherlands, 1997. [26] J. Von Neumann and O. Morgenstern. Theory 
of games and economic behavior. Princeton University Press, 1st edition, 1944. [27] A. C. Yao. Probabilistic 
computations: Toward a uni- fied measure of complexity. In Proceedings of the 18th IEEE Symposium on 
Foundations of Computer Science, pages 222-227, 1977. APPENDIX A. PROOFS OF THEOREMS STATED IN SECTION 
8 In this appendix, we give details about the results listed in Section 8. We provide a short description 
of each problem; we do not attempt to motivate or explain all details. Readers unfamiliar with a given 
problem are referred to the original paper(s). A.1 The ski rental problem [17] Consider the following 
situation: You are going skiing some undetermined number of times. You must decide whether to rent skis, 
or to buy them. Renting skis costs one dollar. Buying skis costs m >> 1 dollars. We consider a continuous 
version of this problem, where the cost of buying skis is 1, and you are given the freedom of buying 
at any time x E [0, c~]. You ski continuously from time 0 to time y, and pay continuously. However, you 
do not know when you will stop until time y is reached. PROOF OF THEOREM 8.6. We pick y from [0, 1]U{2}. 
An algorithm for this problem is easily characterized: Every algorithm is specified by a number x E [0, 
1], which gives the time at which the algorithm will buy. (Given the possible inputs, an algorithm that 
does not buy at or before time 1 can only pay more). The adversary's solution is to rent if y_< landbuyat 
time0ify=2. We encode this as a simple game in a straight-forward fash- ion. Stopping means that y = 
2. We have a=l, ~---1, 7----0, 6=1, X=I, ¢=1, w=0. From Case 4 in Table 1 and (2) we get 1 1 1 q=-, p(z)=--B~ 
=1, O0=1--. e e z ' e So the desired lower bound is proven. []    A.2 Scheduling with delivery times 
[15; 21; 24; 25] In this problem, there are m identical parallel machines. Jobs arrive, and must run 
one at a time without interrup- tion. Each job j has release time rj, a processing time pj, and a delivery 
time qj. After a job is completed, it must be delivered (for instance, to a customer). We assume that 
the delivery is performed by some independent agent who can deliver an infinite number of jobs simultaneously. 
I.e. once a job is completed, it is no longer the concern of the scheduler, and another job may start 
immediately. Let sj be the start time of job j in a fixed schedule. The goal is to create a schedule 
which minimizes the time that the last job is delivered, i.e. minimize maxj{sj +pj + qj}. We consider 
separately the single machine case and the mul- tiple machine case. PROOF OF THEOREM 8.2. The adversary 
gives the algo- rithm two types of jobs. A type 1 job has processing time 1 and delivery time 0, while 
a type 2 job has processing time 0 and delivery time 1. At time 0 a type 1 job arrives. All further jobs 
are type 2. Between 0 and n -1 type 2 jobs are given. The arrival of the ith job corresponds directly 
to the ith round of the game. Stopping corresponds to the fact that no further jobs arrive. The (i + 
1)st job, if it exists, arrives an amount of time yl E (0, vi] after the ith job. After the arrival of 
the ith job, the algorithm picks xi E (0, vii and starts the type 1 job after an amount of time xi has 
passed, given that the (i + 1)st job has not arrived. Once the algo- rithm has started the type I job, 
we calculate a lower bound on its cost based purely on whether further jobs arrive. I.e. once the type 
1 job is started, the game is effectively over. In the ith round, if we stop, the algorithm pays 1 + 
xi for this round, plus the cost for previous rounds. If xi > yl, then this round contributes yl to the 
makespan. If xi < y~, then the algorithm's makespan is at least 2 + xi, plus the cost for previous rounds. 
We model this with a non-simple game. We define a~,i = 1, ~w~ = Vi+l, 7wl = O, 6wl = vi-l-1, Xwl = 2, 
¢~i = vi+l, w~i = O, for 0 _< i < n. All other coefficients are 0. This being the case, we have B~ = 
0 for ~ ¢ w*. We define Di = Bw~. Using Case 4 in Table 1 we find 1 vi qi --p~ (z) = e v~/(2-D~)' (2 
--Di)eZVJ(2-D~) ' 1 Di-1 = 2 eVl/(2_Di) , Dn-1 -= 1.  From (2) we get 0i-1 =2-Di+Oi+ 1-Di+Oi+vi 0~-1 
=1. evil(2--Di) For n = 2 we get a bound of e vl 1 max --> 1.30201. vl 2eVl-vl-1 I+W(-1) This is exactly 
the bound of Stougie and Vestjens [24; 25]. For n -- 3 we get e~2 (2eVle~2 - 1) max (vl,v2) e ~2 (2e 
v1~2 -1) - vie v2 -v2 (e ~1e'2 -1) 2eV2 = max > 1.34239. .2 2e ~2 + 2 W(-11(2e~+'2/2)) -v2 In general, 
we are not able to get a closed form solution for v2,.  , vn-1. This makes the calculation of the bound 
tedious for larger n. We are able to calculate values for n up to 6, which gives the stated lower bound. 
These results are included in Table 2. All values were calculated using Mathematica. [] PROOF OF THEOREM 
8.9. Let v E [0, 1] be a real con-stant. At time 0, m jobs with processing time 1 and delivery time 0 
arrive. If we stop, no further jobs arrive. If we do not stop, m jobs of size y and delivery time 1 arrive 
at time y E [0, v]. The algorithm picks a time x E [0, v] at which it starts the last of the initial 
jobs, given that the size y jobs have not arrived yet. If we stop, the algorithm pays 1 +x. If y < x 
then the algorithm can run the m size y jobs, followed by the initial jobs, and it pays l+2y. Ify > x 
then the algorithm pays at least 2 -b y -+- x. This is a simple game with a=l, /~=v, ~,=1, 5=2v, X=2, 
¢=v, w=v From Case 4 in Table 1 and (2) we get v 2+v 2+2v  ! p(Z)=ev=, B,=3--- Oo=3--- q = e v ' --e 
v ' e" Since the adversary chooses v the competitive ratio is at least v 1 + max 0<v<l 3e v -- 2v -- 
2' which gives the stated result. [] A.3 Scheduling with machine cost [16] In this problem, we are 
presented jobs, one by one. Each job has a fixed processing time pj. Each job has to be as- signed to 
a machine, and must run uninterrupted once s- tarted. The machines are identical, but their number is 
not fixed. Instead the algorithm must buy machines, each at a cost of one. The load of a machine is the 
sum of the pro- cessing times of the jobs assigned to it. The makespan is the maximum machine load. The 
cost to an algorithm is the makespan plus the cost for machines purchased. n 2 3 4 5 6 Vl 0.76804 0.67490 
0.64579 0.64108 0.64080 V2 0.43094 0.43307 0.43228 0.43219 V3 0.25310 0.25247 0.25221 V4 0.13791 0.13650 
V5 0.071238 Lower bound 1.30201 1.34239 1.34880 1.34941 1.34943 Table 2: Summary of lower bounds for 
l[rj, qj iL.... PROOF OF THEOREM 8.3. We give the algorithm only job- s of size e ~< 1. The total processing 
time of all jobs will be y E [1, 2] U {3}. The algorithm must immediately buy one machine. Let x be the 
amount of processing that has arrived when it buys a second machine. Without loss of generality we have 
x E {0} U [1,2]: if algorithm buys in (0, 1) it does not do worse by buying at the start; if the algorithm 
has not bought a second machine and the total processing arrived so far is 2, the cost to the algorithm 
is the same whether it buys or not. If y < x the algorithm pays at least 1 -b y. If y > x the algorithm 
pays at least 2 -b x. The adversary buys one machine immediately if y < 3, and two machines immediately 
if y -- 3. If x E [1, 2], this is an unfair simple game with a={, /3=0, 7=2, 6=1, X=3, ¢=1, w=0, for 
the adversary and a' = 3, fl' = 1, 7' = 2, 6' = 1, X' = 3, ¢' ----1, w' = 0, for the algorithm. From 
Case 4 in Table 1 and (2) we get 1 1 1 q = -, p(z) ----B~ = 3, 0o--3-2--e" e e z ' So in this case the 
desired lower bound is shown. A simple calculation shows that it also holds if x = 0. []  A.4 Total 
completion time scheduling [9; 24; 25] We wish to schedule jobs with fixed processing times on m identical 
machines. The processing time of job j is pj. Further, each job has a release time rj, before which the 
job is unknown to the scheduler. The goal is to minimize the sum of completion times over all jobs. PROOF 
OF THEOREM 8.4. We consider the following in- puts: At time 0, a job with processing time 1 arrives. 
Now we either stop, or k jobs with processing time 0 arrive at some time y E [0, 1]. The algorithm waits 
until time x and starts the first job. Note that any algorithm which chooses x > 1 is worse than the 
one that chooses x ----1. If the processing time 0 jobs arrive before time x, the algorithm can run them 
immediately followed by the first job. In this case the algorithm's cost is 1 q- (k -b 1)y. If the processing 
time 0 jobs arrive after time x, the algorithm pays at least (k q- 1)(1 -b x). In the case that only 
the first job is given, the algorithm pays 1 -b x. This is a simple game with a --1, fl --1, V = 1, 6 
= k+l, X = k+l, ¢ = k-bl, w = 0. From Case 4 in Table 1 and (2) we get k -Jr I e (1-z)(l'bl/k) q = e 
l+l/k--kk' p(z) = k ' (k ÷ 1)e 1+1/k (k q- 1)(e 1+1/k -1) B~ -O0 ---- e l+l/k "~- k ' e k'~l/k + k Therefore, 
the competitive ratio is at least 1 1+ el-I-l/k __ 1 ' which approaches the desired bounds as k grows. 
[] For parallel machines, proving lower bounds would seem to be harder, as is the case for deterministic 
bounds [25]. How- ever, we do obtain the following result: PROOF OF THEOREM 8.5. We prove a lower bound 
for minimizing the average completion time online, which is e- quivalent. We use two types of jobs. Type 
1 jobs have duration 1. Type 2 jobs have processing requirement (1 -y)/i, where is a positive integer. 
At time 0, the algorithm is given m type 1 jobs. Now we either stop, in which case no further jobs arrive, 
or m£ type 2 jobs arrive at time y E [0, ½]. Let k < m be a positive integer and v = k/m. Let x be the 
minimum time at which at least k type 1 jobs have been started. Clearly, the algorithm should start all 
the type 1 jobs at or before time 1 ~, given that no type 2 jobs arrive by that time. We consider the 
cost to the algorithm as ~ -4 c~. For what follows, we refer the reader to Figure 1. If the adversary 
stops, then the average completion time for the first k machines is at least 1, while for the remaining 
machines the average completion time is at least 1 ÷ x. The overall average is vl + (1 - v)(1 + x) = 
1 + (1 - v)x. If y _< x then the algorithm can run all the type 2 jobs before the type 1 jobs. As g --+ 
oo, the average completion time approaches (1 q- y)/2. If y > x then the algorithm has started at least 
k type 1 jobs before time y. Therefore, at least k machines are busy until at least time 1 running these 
jobs. On the other m -k machines, the algorithm can immediately start running type 2 jobs. The earliest 
time that all type 2 jobs can be completed is 1 q- v(1 -y). The average completion time, as £ -4 co, 
approaches 1-by 2+v(1-y) v2 'b v b l v2 ÷ v -1 (1-v)-V-+ v 2 -2 2 ~" (a) (b) (c) 2+~(i -y) l+x 1T 1 
 i m Y lll 0 t Y rn--k Figure 1: The best possible schedules when: This is a rumple game with l--v 
I a = 1, 2 ' ~ = 2' 1 V2+v+l 5 = ~, X 2 , ¢ = 0, v2+v-1 0,,1 ~ -. 4 Prom Case 1 in Table 1 and (2) we 
get q = K1 + ~) v 2 + v-vln4 +ln4' 2q(1 -v) Kz)  v(1 + v)(2 - z)' v 3 - 2v 2 + (ln16-4)v-ln16 + 1 B~ 
= 2v 2 + (2 -in 16)v + In 16 2v 2 + (3 -In16)v + ln16- 1 O0 2v 2 + (2 -In 16)v + In 16 which yields the 
desired result. [] A.5 Page replication [1; 4; 14] In the online page replication problem, one must 
decide which nodes of a given network should have a copy of a fixed database (or page). Initially only 
one node has this page. The page can be replicated to any other node, but only at high cost. To serve 
a single request it is better to send only the requested data through the network. Formally, if we send 
a single data item from s to t we pay the distance between s and t in the network. Replicating the page 
from s to t we pay d times the distance. In the the unfair version of this problem [14], the algorithm 
pays vd times the distance, while the adversary pays d times. PROOF OF THEOREM 8.8. We prove the lower 
bound us-ing the network consisting of a single edge (s, t) of length 1. The node s initially has the 
page. Node t is requested yd times with y E [0, 1] U {1 +v}. The algorithm replicates to t after xd requests. 
Without loss of generality x _< 1. If y < x the algorithm pays yd. If y > x the algorithm pays vd + xd. 
The adversary replicates only if y = 1 + v. This is an unfair simple game with a=l, fl=l, 0,=0, 5=1, 
X=I, ¢=1, w=0, 1 + v(l --y) i Y 0 J%, m--k (a) No type 2 jobs are given, (b) y < x, (c) y > x. for 
the adversary and a' = V, /3' = 1, 7' = O, 5' = 1, X' = v, ¢' = 1, w' = O, for the algorithm. We find 
1 1 v q--el/v , p(z) --vez/, , B~ = v, Oo = v el~,, which gives the desired result. [] Note that Theorem 
8.8 implies Theorem 8.7.  A.6 The Bahneard problem [13] In this problem, one makes a purchase each day. 
However, the amount that one spends on purchases on a given day is unknown in advance. (It could be 0.) 
It is possible to buy a discount card at a price of d, which entitles one to a discount factor of v for 
some fixed number of days. The question is when to buy a card. PROOF OF THEOREM 8.10. For the lower bound, 
we con- sider only the case where a card is valid forever. The pur- chase amount will be 1 for the first 
y days and 0 afterwards. Define w = 1/(1-v). We pick y E [0, w]U{2w}. Since 1 + w + vw = 2w, we assume 
that the algorithm buys by day dw. This can be formulated as a game with a = (v+l)w, ~ = 1, ~' = O, 5 
= w, X = 1, g, = 1, w = vw, from which the desired result follows. []   
			
