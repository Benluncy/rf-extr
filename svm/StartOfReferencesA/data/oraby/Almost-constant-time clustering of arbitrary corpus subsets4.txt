
 Almost-Constant-Time Clustering of Arbitrary Corpus Subsets Craig Silverstein Jan O. Pedersen Stanford 
University Verity Inc. Gates Hall, Stanford, CA 94305 894 Ross Dr., Sunnyvale, CA 94089 csilvers~cs. 
stanf ord. edu jpederse@verity. com Abstract Methods exist for comtant-time clustering of corpus subsets 
selected via Scatter/Gather browsing [3]. In thii paper we expand on those techniqum, giving an algorithm 
for alrnost­constant-time clustering of arbitrary corpus subsets. This algorithm is never slower than 
clustering the document set from scratch, and for medium-sised and large sets it is sig­nificantly faster. 
ThE algorithm ia USSM for clustering ar­bitrary subsets of large corpora obtained, for instance, by 
a boolean search quickly enough to be useful in an interactive setting.  Introduction Document clustering 
haa emerged as an important tool for preaentiug and navigating document coUections. Since no explicit 
input is required from the user aaide from a specifi­cation of the initial document coUection, cluster-baaed 
meth­ods address the vocabula~ problem: the difficulty of express­ing a vague information need as a formal 
query. For exam­ple, the Scatter/Gather browsing paradigm clusters docu­ments into topic-coherent groupa 
and presents descriptive textual summariea to the user [2]. Informed by the sum­maries, the user may 
select clusters, thereby forming a re­iined aubcoktion, for iterative examination. The procms ends when 
the user identifks one or more documents that may be used as input to relevance feedback. The clustering 
and reclustering is done on the fly, so that different top­ics are seen depending on the subcoktion clustered. 
This is preferable to navigating with respect to a static, giobal, topic hierarchy since the induced 
topics are specfic to the document set under instigation [6]. However, since typi­cal clustering algorithms 
are at least linear in the number of objects to be clustered (see e.g. [7]), the computational cost of 
these operationa may be too great for interactive use if the document set is large. The computational 
coat of on-thdly, or on-lirvq docu­ment chartering may be greatly reduced by preprocessing the document 
collection. The general approach is to pre­compute, off-line, a global clwter hierumh~, a tree struc­ture 
whose Ieavss are documents and whose internal nodee Pennissiorrto makedigitafhd cqicc of all orpartof 
thismaicridfor pctaonalor Classramrlk3ai$--f@~ti&#38;jtitiqia Werlottnadcorltigffiwtipfnw mmmcrcialadwttagq 
ate cQpy­ rigbtnotice,thetitleof thepublicntimanditsdatesppsar,andnoticeis 8iVCIIW ~gbt k bypfmksha 
oftk ACM,k. Tocopyotherwise, to republih to poston serversor to redistributeto lists,rcquirmspecific 
-=ioa artdkvf~ S!GIR 97 Philadelphia PA, USA %@@ 1997 ACM O-89791-836-3/97/7.. $3.So correspond to aggregate 
of similar documents. The clus­ter hierarchy ia then used to accelerate on-line clustering. For example, 
Cutting, Karger, and Psdersen [3] develop a comtant-time Scatter/Gather step, assuming that one atarts 
with document subseta corresponding to nodes in a precom­puted hierarchy. Suppose one wsnta to cluster 
an entire collection into five groups. One could start at the root of a precomputed hierarchy and expand 
that node by replacing it with its chil­dren. These nodes could in turn be examined and the Iargeat one 
expanded. The proc-could be iterated until the total number of nodes is equal to some predefine constant, 
say 50. These nodes corrsaportd to either groups of documents or, for leaf nodea, individual documents. 
In either case, the node can be repreasnted as a vector, namely the centroid of document vectors associated 
with the node. One could then apply a linear-time clustering algorithm to these 50 vectors to produce 
a partition into five groups. Thii partition would be returned as the result of the operation. Since 
we would only cluster 50 objects, the clustering would take constant time regardless of the size of the 
collection. 1 See Figure 1 for an example cluster hierarchy. R repre­sents the entire corpus dhided into 
4 cluetem a, b, c, and d which are pressnted to the user. Suppose the user se­lects a and b and desires 
a recluatering into four clusters. We expand clusters a and b to obtain 8 clusters, al, OZ, as, ad, b], 
~, 4, ad b4. We then run a linear-time cluster­ing algorithm to cluster these 8 pseud~documents into 
4 new clusters. The algorithm might output al, az Ua4 U bl, as U b2U b4, &#38;. These would be the 4 
clusters prssented to the user for the next interactive step. Note that clusters displayed to the user 
are always the union of nodes in the cluster hierarchy. The constant M (50 above) determines bow far 
down into the hierarchy we descend; the further we descend, the more complicated the unions become, and 
the leas obvious the precomputed clusters are in the M cluster set . Though the pr~, as described, starts 
at the root of the precomputed hierarchy, it could just as easily start at an arbitrary node. Similarly, 
it could atart with a set of nodes rather than a single node. This is the case, for mram­ple, if one 
selects one or more clusters, computed as above, for further expansion. Hence if one begins a Scatter/Gather 
process using this method, it can also apply to each sub sequent iteration. By modifjing the expansion 
constant M the user can trade off clustering tiie and the customization 1Actually, for thia to be formatly 
true the objects clustered must haw constant length. This is achieved by truncating centroids to a prcdefined 
size. rid b   l--f  Figure 1: An example cluster hierarchy. of the remits to the input set, while 
keeping all calculations constant time. Note that one could avoid the final clustering in each Scatter/Gather 
iteration by, instead of expanding to 50 nodes and then clustering back down to 5, merely expanding to 
5 nodes and atopping. However, this would be equivalent to navigating a static, global, topic hierarchy. 
The extra expansion and clustering aclieves a greater degree of cus­tomization to the input. This is 
especially desirable when the input set corresponds to more than one internal node of the precomputed 
hierarchy. Thii constant-time clustering technique is constrained to document colkctions that correspond 
to sets of nodes in the precomputed hierarchy, as arise when one performs Scat­ter/Gather on an entire 
collection. However, Scatter/Gather browsing is most useful as a tool for viewing search results, which 
are arbitrary corpus subsets [1]. Indeed, experiments indicate that searching followed by the preeentation 
of CIW ters and selection of the moat relevant one improves preci­sion with respect to a baseliie presentation 
of ranked docu­ments [6]. The constant-time Scatter/Gather method does not directly appl~ arbitrary corpus 
subsets cannot be triv­ially mapped to nodee in a precomputed hierarchy and hence cannot be eaeily expanded. 
One solution, presented in this paper, is to find a resaon­able embedding of an arbitrary subcollection 
into an exist­ing cluster hierarchy, run the constant-time clustering rdgo­rithm, and recover the relevant 
documents from the output clusters. We present atechnique for doing so that is linear in theory but 
since the time is dominated by the constant­time clustering in practice effectively constant-time. Section 
2 presents the algorithm. Section 3 describes experimental results indicating that the near-constant-time 
method doea not significantly degrade precision while Sec­tion 4 shows that it is in fact considerably 
faster than direct clustering methods. Methodology We begin with the with a precomputed cluster hierarchy, 
H, covering a document cmpus C of size N, and an arb:trary set of documents S G C. Each node in H includes 
several documents, and we denote the documents included in a node n by D(n). The cluster hierarchy is 
a tree of cluster nodes with fan-out k and root r such that D(r) = C and, for any node n, the union of 
the k children of n includes the same documents as n itself. The cluster hierarchy is computed off-line, 
typically in IV log N time by recursively applying a linear-time partitioning algorithm (see, for example, 
[3]). The goal is to cluster (partition) S into p groups. Note that this algorithm wiU be similar in 
kind to an algorithm that takes S and clusters it born scratch. It is not expected that the algorithm 
will give better results than such a direct clustering algorithm however, we expect it will give comparable 
results at a ~eat advantage in speed. The technique employed is similar to that d-ibed above for Scatter/Gather. 
We find a small number, M, of nodes in the cluster hierarchy that are good in some way, and we cluster 
them using a linear-time clustering algorithm. Aa long se the number of nodes we select is bounded, the 
chM­tering takea constant time. Because the number of nodes in the cluster hierarchy may be large O(log 
IV) is reasonable , we cannot afford to look at all the nodes to fmd good ones. hated we fan out from 
the top of the cluster hierarchy. We start with the root node of H and immediately replsce it with its 
children. We examine the k nodea in our current node set and pick the worst one. We remove that worst 
node and replace it with its k ch~ldren. We repeat the procees on the 2k -1 nodes now under consideration. 
As we describe later, as an optimization, we do not always include all k children, but rather pick a 
subsetof the children. When we have collected M nodea, we stop the algorithm. We cluster the M result 
nodes into p clusters, treating each node as a single entity. The p clusters include documents not in 
S, which we wish to remove. To do so we introduce a function 1s that gives, for each node n in the cluster 
hierarchy, the aubeet of S that is included in n: Is(n) = S n D(n). We also need a function IH, which, 
given a document, R+ turns the nodes in H that contain the document. Note that ~H does not depend on 
S and can be computed as H is constructed. It is possible to calculate 1S in O(ISI log IV) time. We implement 
IS using a table indexed by nodes. To construct the table, we take each documed d E S, and add d to the 
table entry for each node in ZH(d). After this is done, the table entry for node n will contain all the 
documents in n that are also in S. We get the required time bound by noting that H has constant fan-out, 
so l~H(d)l E f3(log ~) for all d. See Table 1 for a more formal description of the rdg­rithm. It remains 
to define /, the function that picks children, and g, the function that determines bad nodes of H. Algorithm 
SELECTNODES Input: S, a set of documents. H, a cluster hierarchy, with its associated node membership 
function lX. J.M, the maximum number of nodes we collect. A child function ~ and a goodness function 
g. Output: P, aset of clusters. 1. cO~t~d 1s. (1s(72)ss n D(7J).) 2. T-{r}, the root of H. 3. repeat 
 (a) w + g(S, T). (g returns the worst el~ ment of T according to some metric.) (b) T -T -{w}+ f(w). 
(f(w) returns some of the children of w in H.)   until ]Tl > M. 4. Cluster T using a linear time clustering 
algo­rithm. We obtain P, a partition of T into d$ joint seta. 5. Replace each node n in P by Is(n). 
 6, return P. Table 1: The clustering algorithm for an arbitrary data set. 2.1 Pickingchildren When 
replacii a node with its children, we can clearly avoid empty children, that ia, children that do not 
contain any documents in S. Singleton children, that contain only one document horn S, may alaobe dealt 
with specially. There ia no need to include the entire node when we only care about one document in it: 
We might as well just take out the doc­ument and treat it as its own node. This is equivalent to replacing 
the child node by an appropriate leaf descendent. In general, we can replacenodes containing less than 
c do­umente by c single-document nodea. This strategy should improve the quality of the resulting clustering 
because it r­ducea the average size of chosen hierarchynodes while not adversely affecting the recall. 
There is a question as to whether the single-document nod-created in this way should count toward the 
limit of ITI. At first, it seems obvious that they should. However, these singl-document nodes are anomalies, 
chosen not b­cause the goodness function g preferred them but rather because they qualiikd for a special 
expansion exemption. If many nodes are created through this loophole, it may limit the abiity of g to 
replace bad nodea by their children, which may impact the quality of the result clustering. To forestall 
thii eventuality, we lmep the @@.&#38;cum ent nodes created by the expansion exemption in aeet E whichisseparate 
from T. We still stop when ITI= M, but insteadof then clnater­ing T, we cluster TU E. Note that since 
IEl s CM ~ O(l), the performance guarantee of the algorithm ia not affected. With this adjustment, the 
algorithm is as shown in Ta­ble 2. 2.2 The RATIOteet All that remains is to deihe the goodness test used 
to select nodes for expansion. The moat obvious teatisprecision: A Algorithm SELECTNODESW TH CUTOFF Input: 
S, a set of documents. H, a chwter hier­ archy, with its associated node membership function ~Jf. M, 
the maximum number of nodes we cokct. A child function f and a goodnmE function g. c, a cutoff value. 
Output: P, a setof clusters. 1. construct Is. 2. T+ {r}. 3. E~O.  4. repeat (a) w + g(S, T ). (b) 
if IIs(w)I ~ c, E-E U Is(w), else T-T {w} +f(w).  until[Tl> M. 5. Cluster T U E using a linear time 
clustering al­gorithm. We obtain P, a partition of T U E into disjoint aeta. 6. Replace each node n 
in P by Is(rL). 7. return P.  Table 2: The clustering algorithm for an arbitrary data set with cutoff 
values added. Lf a node includes few documents in S, we add those documents to a separate set E instead 
of spending time expanding the node, node is good if most of the documents it contains are in S. This 
gives the following ratio test definition of goodness: G.(n) = lIs(n)l/p2(n)l. g(S, T) returna that 
node in T with the lowest goodness. The ratio test favora nodes with small intersection with S, which 
probably have children with no intersection; hence this goodness teat will result in extensive pr@ng, 
improving the results. On the other hand, large nodes with fairly good ratios will stay intact in T, 
even though they include many documents not in S. 2.3 The ROOTIMTIO teet If one large node has a large 
intemection with S, the RA-TIO teat will tend to preserve it. This can be a problem fbr clustering, since 
the clustering algorithm will treat all the documents in the node as a single entity, leading to poten­tially 
lopsided cluster sizes. We can encour~ the expansion of such large nodes by re-expressing the FtATIOgoodnessdef­idion 
M tbllows: G..(n) = im/lD(n)l. In this case, having a lot of docurnentsin Sienotaguarantee of a good 
ratiq it ia more advantageous to have a smaller value of lD(n)l. This helps ensure that the output nodes 
will all have approximately an equal number of documents from S. 2.4 ~he INFORMATION test Another approach 
for testing goodnees ia to use art infor­mation theoretic measure. A node is a good candidate for replacement 
by ita chMren if its children encode more in­formation about S than the node itself. This implies that 
the matchea in the parent are unevenly distributed among the children, allowing us to prune the bed children 
end keep the good ones. Let {ru } be the children of n. We define the information inanodeto be ll~(n)l 
,W2 ~lIs(n)l . ~(n) = -p(n)l () Then the appropriate goodness measure is g(S, T) will return that node 
in T with the bigheet informa­tion gain. This hee the advantage of picking nodee that will benefit the 
moat from being replaced by their children. On the down aide, it will ignore large nodes with few matches 
if these matchea are distributed everdy among the children. 3 Results To evaluate the feat clustering 
methods with respect to the baseline performance of direct cludering, we used tbe method­ology proposed 
in [6]. That ia, we ran one Scatter/Gather step and measured the prectilon, at three cutoff valuea, of 
the best cluster the ~ with the highest density of rele­ \ vant documents). We used the TREC4 ud hoc 
evaluation corpus, consisting of 567,522documents end 49 queries with relevance aaaaenmnte [5]. The corpus 
wea preprocessed by the Xerox PARC TsxtDatabaae engine [4],including the con­struction of a cluster hierarchy 
with fan-out 5 and 201,772 internal nodes. We used a linear-time partitioning alg~ rithm called fmctionation 
es the baseline direct clustering method [3]. For the feat clustering methods we expanded until we hd 
coUected 20 nodes (M = 20), and then used fractionation to cluster back to five groupa. We used a cut­off 
of c = 6 to replace nodee with few documents in S with their appropriate leaf deecendents. For each query 
we collected the ISI (for ISI = 250 and ISI = 500) TREG4 documents ranked moat similar by the Text-Database 
similarity search algorithm.3 We then clustered theee IS] documents in four ways: with fractionation, 
feat clustering with the RATIO teat(Gr), fast clustering with the ROOT RATIO teat(Gm), and fast clustering 
with the INFOR-MATION teat (GI ). Since experiments suggest that 50-100 2Thm prer.idon numbem pr~ume 
the user pick the optimal CIUM ter and hence are an upper bound. If this praxumption is not valid, the 
quality of the Scatter/Gather results ax a whole may ouffer, but wc do not expect that one clustering 
technique would suffer propor­tionally more than another. We use a simple cosine ranking xcheme with 
tf, idf waights, In particular the similarity of document d to query 9 is computed ax ~ d(w)q(ru) ( )=m 
where d(w)=w, q(w)=@ log(N/n(w)), ~=(w) is the frequency of w in = xnd n(w) k the number of documents 
in which w occure. TOPIC: 202 Taxt: Status of nuclmr proliferation traatios -­ violation-and monitoring. 
Sunba r*lOvant: 283 Clrwt*r distribution: cltwtar #-rOl SIZO danaity o: 56 1s0 o. 30s66666 1: 0 8 0.0 
2: 0 23 0.0 3: 0 21 0.0 4: 0 1s 0.0 Clnstar distribution (root-ratio) : clust .s S-sol sizQ daruity o: 
66 1S8 0.2926632 1: 0 62 0.0 Cltwtor distribution 3 (r~tic.): cluxtar 8-ral sixo density o: 6S 2s0 0.23913044 
1: 0 20.0 2: 0 60.0 3: 0 100.0 4: 0 20.0 Cluster distribution 4 (info): clum.or #-rsl sizs dwmity o: 
65 191 0.2S76SS12 1: 0 69 0.0 Precision .t sot cutoffs: clust*r r-ratio ratio info 6 does: 0.3 0.6 0.8 
0.6 10 docn: 0.7 0.6 0.6 0.6 20 dorm: 0.6 0.46 0.46 0.46 Figure 2: Output from a comparison run for Topic 
202 fkom the TREC4 collection. Each clustering technique groups ISI = 250 documents into five cluste~ 
the one with the largest density (not always the one with the moat relevant documents) wea examined. 
documents per cluster is optimal for browsing [6], we c1* tered the ISI documents into five clusters. 
In each cluster, we preserved tbe document order of the original ranking. Hence documents within each 
cluster are ranked by similarity to the query. Each TREC4 query is associated with a list of judged relevant 
documents, For each clustering scheme, we picked the cluster with the largest ratio of relevant documents 
to total documents. We then computed precision at three doc­ument cutoffi within this beet cluster: at 
five, ten and twenty documents. This gave us three precision numbers for each technique. We used precision 
at document cutofi rather than uninterpolated precision or average precision at 11 recall points since 
Scatter/Gather is intended as a tool for gathering positive exemplars and hence should be judged more 
on precision that recall. An example run for a TREC4 query is shown in F@re 2. l bble 3 preeents the 
remdte for ISI = 250 and Table 4 for ISI = 500. Although the fast clustering techniques appear to offer 
lower average precision than the baseline linear CIUS tering method, the decrease is rather negligible. 
In fact, for any given pair of methods at any given cutoff a aired t-test indicates no statistically 
significant difference./ Hence, we 4A more global ANOVA analysis is not appropriate since the rc­oults 
at various cutoffs are highly dependent, xn it is not the cane that each cell of the table reprcecnta 
a fresh experiment. conclude that the fast methods are roughly competitive with the baseline dhct method 
in terms of retrieval performance. 4 lime We also empirically examined whether the fast clustering techniques 
are indeed faster than direct clustering of S. This is a particular concern when N is large and ISI is 
small, since the log N factor in IS[ log N may be comparable to the implied constant in the 0(1S1) fractionation 
clustering technique. In Figure 3 we graph average time versus ISI for the baseline linear method and 
the four fast methods. Note that the fast methods are indeed eeaentially constant time (averaging 7 seconds 
per query), while the linear method is everywhere slower than any fast methods Figure 4 displays timing 
data for M = 200. For ISI < 500, the fast clustering algorithm reducee to the direct CIW tering algorithm. 
Recall that the fast clustering algorithm gains its speed advantage by clustering only M hierarchy nodes 
(for some constant M) instead of all ISI documents. When {Sl S M, however, the feat clustering algorithm 
b­havee exactly like the direct clustering algorithm. Tbua, we see the fast clustering algorithm running 
exactly as fast as the regular clustering algorithm for small S. At ISI = 500 the near constant-time 
behavior of the fast methods become apparent. Though we only show ISI up to 1000 on this ~aph, experiments 
with ISI as large as 15000 confirm that the running time increasee only very alowly with ISI there is 
usually less than one second difference in the running times for ISI = 500 and ISI = 15000. This is consistent 
with our claim of almost-constant running time: The time contribution of the O(ISI log n) step is dwarfed, 
in practice, by the contribution of the O(1) clustering step. 5 conclusion Ahrmat-constant-time clustering 
is a fast and reasonable al­ternative to direct clustering of arbitrary document sets. While these fast 
clusterin~ techniques did not perform as well as direct clustering on the TREC4 queries, the per­formance 
10SSwas not atatiatkally significant while the time savings mmreoften quite large. As the size of the 
document set increases,fast clust@ng becomes increasingly appealing. Of the various fast clustering techniques 
we examined RATIO, ROOT RATIO, and INFORMATION all ptXfOKIWd equally weU in terms of both quality and 
execution time. We nonethelese recommend ROOT RATIO asan alternative to di­rect clustering when cluataing 
arbitrary document subsets, both because it is easier to calculate than INFORMATION, and it usually fultNls 
ita design goal of having a smaller largest cluster than RATIO. Our experiments evaluate the clustering 
tecbniquea after only a single round of Scatter/Gather, while in reality a user would probably iterate 
through several rounda, particularly if S is large. This is a potential problem: repetition could exacerbate 
any d~erence in quality between clustering al­gorithms. Though we do not detect a statistical difference 
between the quality of linear-time and fast clustering tech­niquesafteroneibation, suchaClifferemxmaywellbecome 
apparent after many iterations. However, since the fast clus­tering methods revert to direct clustering 
for [Sl <M, if M is reasonably large, say 200, we can expect that the user The linear method appears 
slightly sublinear in practice. This mv be due to caching behavior. will be employing direct clustering 
after one or two Scat­ter/Gather steps. Acknowledgements We would like to thank Xerox PARC for supporting 
this work, and three anonymous reviewera for their helpful com­ments. References <RefA>[1] Manette B. Lazear 
Adrienne J. Kleiboemer and Jan O. Pederaen. Tailoring a retieval system for naive users. In Fifth Annual 
Symposium on Document Anal@.s and Information Retrieval April 1996. [2] D. R. Cutting, D. R. Karger, 
J. O. Pedereen, and J. W. lhkey. Scatter/gather: A cluster-based approach to browsing large document 
collections. In Prvc. 15th An­nual hit 1 ACM SIGIR Conference on RBD in IR, June 1992. Also available 
as Xerox PARC technical report SSL-92-02. [3] Douglass R. Cutting, David R. Karger, and Jan O. Ped­eraen. 
Comtant interaction-time Scatter/Gather brows ing of very large document collections. In Z+ocedings of 
the 16th Annual Intematwnal ACM/SIGIR Conference, pagee 126-135, Pittsburgh, PA, 1993. [4] Douglasa R. 
Cutting, Jan O. Pederaen, and Per-Kriatian Halvoraen. An object-oriented architecture for text re­trieval. 
In Conference Pnxsedings of RIAO 91, InteU5 gent Tszt and Image Handling, Bamelona, SpaiW pages 285-298, 
April 1991. Aleo available as Xerox PARC tech­nical report SSL90-83. [5] Donna Herman, editor. The Fourth 
T&#38; REtrieval Con­ference. National Institute of Standards and Technology Special Publication 500-236, 
1996. [6] Marti A. Hearst and Jan O. Pederaen. Rmxamh@ the cluster hypothesis Scatter/gather on retrieval 
results. In Pmt. 19th Annual Int 1 ACM SIGIR Conference on R&#38;D in IR, August 1996. [7] Anil K. Jain 
and Richard C. Dubes. Algorithms for Clus­tering Data. Pretice Hall, Engelwood Cliffs, N.J. 07632, 1988. </RefA>
cutoff linear root-ratio ratio info sim search cutoff linear root-ratio ratio info sim search 5 .42 38 
37 37 33 5 -lo% -11% -1170 2170   10 .39 :32 :32 :31 :30 -lWO -lWO -20% -24% 20 .32 .27 .27 .27 .25 
; -15% -15% 18% -23% ,  Table 3: Average precision, at three cutoff values, of a linear-time clustering 
method and four faat clustering methods, for ISI = 250. The first table shows the actual precision, while 
the second shows the (percentage) relative decrease in performance of each method from the baseline linear-time 
method. The final column (labeled sire search ) presents the performance of simple ranking without sekcting 
the best cluster. cutoff linear roo~ratio ratio info sim search cutoff h near root-ratio ratio info 
sim search 5 .41 37 37 39 33 5 -11% 11% -5% -20% 10 .38 :31 :31 :33 :30 10 -18% 17% -12% -21% 20 
.33 .27 .27 .28 .26 20 -18% -19% -Iwo -23%  J Table 4: Average precision, at three cutoff values, 
of a linear-time clustering method and four fast clustering methods, for [S{ = 500. The first table shows 
the actual precision, while the second shows the (percentage) relative decrease in performance of each 
method from the baseline linear-time method. The final column (labeled sire search ) presents the performance 
of simple ranking without selecting the best cluster. 35 30 25 20 E 15 10 ,, , ,, !3 -1oo 200 300 400 
EOo 600 700 em 900 1000 1s1 Figure 3: Average time venausIS[ for the baseline linear method and the 
four ccmatantAme methods for M = 20. 65 35 30 linear rod faib ---­ infcnd%% :::: 25 ...............................------------------------------------­- 
-.-. . ... _--__ ---­ --. --. . . ..... 15 10 5 I 200 300400500600700 Soosoolmo 1s1 Figwre 4: Average 
time versus ISI for the baseline linear method and the four constant-time methods for M= 200.  
			
