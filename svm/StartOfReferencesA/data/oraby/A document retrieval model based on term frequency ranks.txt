
 A Document Retrieval Model Based on Term Frequency Ranks IJsbrand Jan Aalbersberg * Philips Laboratories, 
Briarcliff Manor, NY, USA Abstract This paper introduces a new full-text document retrieval model that 
is based on comparing oc­ currence frequent y rank numbers of terms in queries and documents. More precisely, 
to compute the similarity between a query and a document, this new model first ranks the terms in the 
query and in the document on decreasing occurrence frequency. Next, for each term, it computes a local 
similarity between the query and the document, by calculating a weighted difference between the term 
s rank number in the query and its rank number in the document. Finally, it collects all those local 
similarities and unifies them into one global similarity between the query and the document. In this 
paper we also demonstrate that the effectiveness of this new full-text document retrieval model is comparable 
with that of the standard vector-space retrieval model. Introduction Most of the advanced full-text document 
retrieval models associate term weights or term probabilities with the terms in queries and documents. 
of those models, the most generally accepted are the vector­ space and the probabilistic retrieval models 
(see, e.g., [14] and [9]). Common to both (and to other) retrieval models is the use of term occurrence 
frequencies to calculate the term weights or the initial term probabilities (see, e.g., [10]). Already 
in 1949 CI.K. Zipf formalized a relation between the occurrence frequency of a term in a text (or a set 
of texts) and its rank number, when all terms in the text (or texts) are ranked according to decreasing 
occurrence frequency (see [17]). This so-called rank-frequency law of Zip~ expresses that, for a given 
text (or set of texts), the product of such an occurrence frequency and such a rank number is approximately 
constant. Since then, occurrence frequency rank numbers have been the topic of research in a number of 
theo­retical studies (see, e.g., [4] and [5]). However, in information retrieval (and, more specifically, 
in full-text document retrieval) its application has mainly been in computing the text-size reduction 
achieved by text compression or in estimating storage requirements for term lists and dictionaries (see, 
e.g., [3]). one of the few exceptions to the above is the proposal of D. Blair to use the rank-frequency 
law of Zipf to measure the effectiveness of full-text document retrieval models (see [2]). Blair suggests 
that Zipf s law can be used to compare the language of a document indexer with that of a document inquirer: 
The closer the rank-frequency distribution of indexer and inquirer usage is to the Zipfian distribution, 
the better the evidence that inquirers and indexers are using search terms in substantially the same 
way (page 193). And, according to Blair, the latter is favorable for the effectiveness of a full-text 
document retrieval model. Another exception is the suggestion of IJ ,J. Aalbersberg to apply the rank-frequency 
law of Zipf in posting compression and term-weight approximation (see [1]). By storing postings on decreasing 
term occurrence frequency (but without storing the term frequencies themselves) a reduction of the index 
size by 25% to 50% can be achieved. Using this compression technique in combination with the vector-space 
retrieval model, Aalbersberg demonstrates that term occurrence frequencies can easily be approximated 
from occurrence frequency rank numbers, resulting in a retrieval effectiveness that is almost equal to 
that of standard vector-space retrieval (without the compression technique). In this paper we continue 
the research started in [1], by searching for a full-text document retrieval model that better corresponds 
with the compression technique introduced there. In other words, instead of the vector-space retrieval 
model that translates occurrence frequency rank numbers back into term occurrence frequencies, we try 
to identify a full-text document retrieval model that directly uses those rank numbers themselves. of 
course, the required retrieval model should provide a retrieval effectiveness that is at least as good 
as the one obtained using the vector-space retrieval. *On temporary leave from Philips Researvh Laboratories, 
Eindhoven, The Netherlands. The paper is organized as follows. Firstly, Section 2 recalls the vector-space 
retrieval model (Section 2.1) and a method to evaluate the effectiveness of full-text document retrieval 
models (Section 2.2). Secondly, Section 3 reviews the rank-frequency law of Zipf (Section 3.1) and its 
applicability to approximate term weights (Section 3.2). In Section 4, the main section of the paper, 
we introduce, investigate, and evaluate a new rank-based full-text document retrieval model: Section 
4.1 presents an introduction, Section 4.2 overviews the theory, Section 4.3 provides some variations 
on the theory, and Section 4.4 investigates its retrieval effectiveness. Finally, the paper concludes 
with a brief discussion on the results in Section 5. 2 Full-Text Document Retrieval 2.1 Vector-Space 
Full-Text Retrieval In term-weighted full-text document retrieval (see, e.g., [13]), a term weight becomes 
associated with each term that occurs in a (document or query) text. A term weight w of a term s in a 
text t indicates the descriptive value ofs for t: O for no value and 1 for a maximal value. Term weights 
are used to compute the ted similarity between documents and queries. A query will be answered by listing 
documents in decreasing text similarity to it, and thus listing the most relevant documents first. The 
computation of term weights and text similarities can be done along various lines (see, e.g., [14]). 
The vector-space retrieval model represents the term weights of the terms in a text as a vector, and 
it does term-weight vector calculations to compute text similarities. The model basically calculates 
term weights in one of the following ways (for slightly different calculations, see, e.g., [1]). For 
a text t and a term s in t,let frq(s, t) be the occurrence frequency ofs in t.Then the simple term weight 
ofs in t is frq(s, t) S.wght(s, t) = (1) &#38;rG,(frq(r, t))2 and the modified term wezght of s in t 
is log ~ . frq(s, t) m_wght(s, t) = (2)  X&#38;t(log # ofw(r, t))z Here IV is the total number of documents 
and n. is the number of documents that contain the term z. Note that log IV/na is the so-called inverse 
document frequency of z (see, e.g., [15]). In the vector-space retrieval model a text similarity between 
a query q and a document d, denoted by sim(q, d), is calculated as the inner product of the query term-weight 
vector and the document term­weight vector: sim(q, d) = ~ wght(s, q) . wght(s, d) (3) sEq (clearly, wghi(s, 
z) should actually be replaced by the term weight in discussion). Since the query term­ weight vector 
and the document term-weight vector are length normalized, the text similarities always are between O 
and 1: 0 for no similarity and 1 for a maximal similarity. 2.2 Effectiveness of Full-Text Retrieval Evaluation 
of full-text document retrieval models is based on relevance ranking and it measures recall and precision 
for test collections (see, e.g., [14]). Relevance ranking means that the result of a query is an ordered 
list of relevant documents, recall is the fraction of the relevant documents (stored in the document 
base) that are retrieved upon a query, and precision is the fraction of the retrieved documents that 
are relevant. Clearly, a full-text document retrieval model that computes text similarities provides 
relevance ranking. Furthermore, the effectiveness of such a retrieval model can be indicated by average 
recall and precision: the higher they are the more effect ive the retrieval model is. The test collections 
used are the collections CACM, CISI, CRAN, and MEDLARS (see, e.g., [14] and [16]). For every test collection 
and for every query in it we first compute the associated result list. Next we compute for every query 
the precision values at those points whenever the recall value equals or exceeds zs~., soy., and Ts~o 
for the first time. We then take the mean of these precision Yalues per query and finally we take the 
mean and the median per test collection. For the vector-space retrieval model that uses Formula 1 and/or 
2 (and Formula 3) we reported the average precision figures in Table 1. Here, the row header FZ Fy denotes 
the retrieval model in which the query term weights and the document term weights are calculated using 
Formula z and y, respectively. In these evaluations we used a slightly adapted version of the stop word 
list as presented in [6] (see also [7]). Furthermore, we also used a slightly adapted version of the 
Lovins stemming algorithm as outlined in [12] (see also [8]). Finally, apart from words we also indexed 
numbers. d I CACM CISI CRAN MEDL I average #l F1 I mean 21.07 14.96 35.37 46.72 29.53 F1 F1 median 13.58 
12.74 28.44 45.11 24.97 F1 F2 mean 30.34 19.31 38.01 50.91 34.64 F1 F2 median 23.09 14.20 33.75 47.26 
29.58 F2 F1 mean 31.05 23.30 39.80 52.76 36.73 F2 F1 median 24.31 17.04 36.09 49.24 31.67 F2 F2 mean 
35.88 24.10 39.01 53.44 38.11 F2 F2 median 30.09 18.48 32.73 51.75 33.26 Table 1. Average Precision Figures 
 3 Rank-Frequency Law of Zipf 3.1 Theory The different components of linguistic text do not at all occur 
at random (see, e.g., [11]). Already in 1949 George Kingsley Zipf established a relation between the 
occurrence frequency of a term in a text (or a set of texts) and its rank number, when all terms in the 
text (or texts) are ranked according to decreasing occurrence frequency (see [17]). Informally speaking, 
Zipf noticed that the product of such an occurrence frequency and such a rank number is approximately 
constant. More formally, this mnk-frequency law of Zip~is as follows. For a text tand a terms in t, let 
~rq(s, t) be the occurrence frequency of s in t. Let t be a text containing n > 1 different terms S1, 
. . .,s~ and, without loss of generality, assume that these terms are ranked such that ~rq(sl, t) ~ . 
. . ~ ~T~(sn, t) holds. Then the rank-frequency law of Zipf c~aims that there exists a constant .zp$(t), 
such that, for every 1< i < n, i . jrg(si, t) N .zpf(t), i.e., the product of the rank number i of Si 
and the occurrence frequency frq(sj, t) of Si is approximately constant. The Zipf constant zpj(t) depends 
on the text t: when the size oft increases, the occurrence frequency of the most frequent term as well 
as the number of different terms increase Zipf s law says that they increase evenly and thus zpf(t)increases. 
 3.2 Application It was observed in [1] that the rank-frequency law of Zipf can be applied to compress 
postings and to approximate term weights in those full-text document retrieval models that compute term 
weights out of term occurrence frequencies. For the vector-space retrieval model this approximation technique 
was illustrated as follows. First, for a text t and aterm sin t,the approximated occurrence frequency 
of s in t was defined as afrq(s, t) = zpf(t)/rnk(s, t), where zpf(t) is the Zipf constant of t and mk(s, 
t)is the rank number of s when all terms in t are sorted on decreasing occurrence frequency. Next, the 
approximate ed simple term weight ofs in t was defined as l/~_ as.wght(s, t) = (4) ret (l/rnk(r, t)J 
Z.Et(m) = ~ d-) and the approximated modified term weight ofs in twas defined as log :. J* log ~/1/_ 
am.wght(s, t) = (5) ~rEt(lOg # ~-) = JX(l% :)2M(W) with again N the number of documents and nc the number 
of documents that contain the term Z. Formula 4 and 5 were obtained out of Formula 1 and 2, respectively, 
by substituting <-for frq(s, t). The reason for not just substituting frq(s, t) by afrq(s, t) and thus 
for the presence of the additional square root was the empirical observation that without the square 
root the term weights were approximated too high for the high-frequent terms and too low for the low-frequent 
terms. Evaluation of the effectiveness of the thus obtained full-text document retrieval model results 
in the precision figures depicted in Table 2. From a comparison with the exact term-weight calculation 
F2/F2, it is found that the retrieval effectiveness with the Zip f-based term-weight approximation technique 
F5/F5 shows a deterioration of at most 6%. However, using Formula 4 or 5 to approximate only the term 
weights of the terms in the documents, while still using Formula 2 to calculate the term weights of the 
terms in the queries, the resulting precision figures conclude that the setback in retrieval effectiveness 
now decrermes to slightly more than l%. d I CACM CISI CRAN MEDL I average i4 F4 I mean 16.79 15.10 28.22 
42.72 25.71 F4 F4 median 8.63 10.98 19.17 44.39 20.79 F5 F5 I mean 3173 23.73 37.47 50.88 35.95 F5 F5 
median 26.80 17.07 32,79 51.90 32.14 F2 F4 mean 31.06 23.21 38.90 53.21 36.60 F2 F4 median 22.05 16.41 
33.84 50.05 30.59 F2 F5 mean 33.62 24.03 38.75 54.39 37.70 F2 F5 median 27.38 17.47 33.85 52.46 32.79 
Table 2. Average Precision Figures 4 A Rank-Based Retrieval Model 4.1 Introduction In the standard vector-space 
retrieval model a text is represented by a term-weight vector (see Section 2.1). For each term in a text 
such a term-weight vector provides a term weight, calculated out of the occurrence frequency of the term 
in the text. The text similarity between a query text and a document text is then computed by applying 
a vector operation on the query term-weight vector and the document term-weight vector. In other words, 
the vector-space retrieval model computes the text similarity sz m(q, d) between a query q and a document 
d as follows. 1. Calculate the occurrence frequency vectors frq(q) of q and frq(d) of d. 2. Out of frq(q) 
and jrq(d), calculate the term-weight vectors wght(q) of q and wght(d) of d. 3. Out of zught(q) and 
wght(d), calculate the text similarity sim(q, d).  The resulting value usually lies between O (for no 
similarity at all) and 1 (for maximal similarity). It can be learned from [1] that the occurrence frequency 
rank orders of terms in texts can be very useful for posting compression. It was also demonstrated there 
that these occurrence frequency rank orders can be easily combined with (vector-space) full-text document 
retrieval (see Section 3.2). In fact, it was shown that each term weight in a (vector-space) term-weight 
vector can be calculated out of its rank number in the frequency-based rank order, instead of out of 
the occurrence frequency itself. Thus, this alternative (vector-space) full-text document retrieval model 
computes the text similarity sz m (q, d) between a query text q and a document text d as follows. 1. 
Calculate the occurrence-frequency vectors frq(q) of q and frq(d) of d. 2. Out of frq(q) and frq(d), 
calculate the rank-number vectors mzk(q) of q and ink(d) of d. 3. Out of rnk(q) and mdc(d), calculate 
the term-weight vectors wghi(q) of q and wght(d) of d. 4. Out of wght(q) and wght(d), calculate the 
text similarity sim(q, d).  Again, the resulting value usually lies between O (no similarity) and 1 
(maximal similarity). However, when using occurrence frequency rank orders in the posting compression 
technique described in [1], the question arises whether we can get rid of the intermediate calculation 
of the term-weight vectors. In other words, is there a way to calculate the text similarity between a 
query text q and a document text d directly out of their occurrence frequency rank orders? It turns out 
that there indeed is such a method, which can be schematically described as follows. 1. Calculate the 
occurrence frequencies of all terms in q and d. 2. Sort the terms in q and d on decreasing occurrence 
frequency, obtaining the rank-based term sequences rbts(q) and rhts(d). 3. Replace in rbts(q) and r%ts(d) 
each term by a unique symbol, obtaining the rank-based image strings rbis(q) and rbis(d). 4. Use a weighted 
string-comparison function, to compute the rank-based similarity between rbis(q) and rbzs(d). 5. Set 
the rank-based text similarity rbsim(q, d) between q and d to the rank-based string similarity just computed. 
 The range of the resulting value depends on the weighted string-comparison function used. In the next 
section we illustrate the algorithm sketched above with a string-comparison function that results a value 
between O (no similarity) and 1 (maximal similarity). 4.2 Theory In this section we formalize a full-text 
document retrieval model that is based on the rank order of term occurrence frequencies. Given a query 
text q, the model calculates the rank-based text similarity rbsim(qj d) for a document text d. This rank-based 
text similarity ranges between O and 1, reflecting a low query-document similarity between q and d when 
rbsim(q, d) is near O and a high similarity when rbsirn(q, d) is near 1. In the sequel we use the following 
terminology and notations. Let T be the set of all nonempty finite texts, let S be the set of all (relevant) 
terms occurring in at least one of the texts in T, and let < be a linear ordering on S. Let X be a set 
of symbols such that there exists a bijection from S into .X, and let j be such a bijection. Let R be 
the set of all nonempty finite strings over X that consist of different symbols only (i.e., each string 
in R has no two or more occurrences of the same symbol). For a string p in R, let [Pl denote the length 
of p (i.e., the number of symbols in p) and let O(P) denote the set of symbols occurring in p (note that, 
by definition, the length of p equals the size of o(p)). For a string p in R and an 1< i < \pl, let p[i] 
denote the i-th symbol in p. Let t be a text in T and let, for n > 1, Sl, ....sn e S be the terms in 
t such that .fr@l, t) > ,,. > jrg(sn, t) and such that, for all 1 < i,j < n, frq(si, t) = frq(sj, t) 
=+ Si -+ Sj holds. Then the term sequence (s1, . . . . sn) is called the simple rank-based term sequence 
of t,denoted by s-rbts(t). Furthermore, the simple rank-based zmage string oft, denoted by s.rbis(t), 
is the string f (s1 ) . . . f (.% ) over X. Note that the linear ordering < guarantees that the simple 
rank-based term sequence and the simple rank-based image string of t are both unique. Furthermore, note 
that, by definition, the simple rank-based image string of t is an element of R. Example 4.1. Let tlbe 
the document text Where is the cat? The cat is in the tree. Can the cat sleep there? Yes, it can sleep 
on the branches of the tree, let tzbe the document text Where is the dog? The dog and the cat are in 
the house. Where is the house? The house is next to the tree, and let q be the query text What about 
the cat and the tree? Let S = {tree, cat, sleep, branch, dog, house} be the set of relevant terms in 
tl, tz, and q, and let + be the linear ordering on S such that tree < cat + sleep + branch + dog < house. 
Let E = {t, c,s, 6, d, h} and let f be the bijection from S into X such that f(tree) = t, f(cat) = c, 
f(sieep) = s, f(branch) = b, f(dog) = d, and f(house) = h, Then, if we remove the stop words (i.e., the 
terms not in S) from tl,tz,and q, we obtain s.rbts(tl) = (cat, tree, sleep, branch), s-rbis(tl) = ctsb, 
s-rbts(tz) = (house, dog, tree, cat), s.rbis(t2) = hdtc, s-rbts(q) = (tree, cat), and s.-rbis(q) = tc. 
1 Now the full-text document retrieval question of what is the document d in D C. T that matches the 
query q in T the best? leads to the question what is a string-comparison function on s-rbis(q) and s-rbis(d) 
such that it nears O if and only if q and d have a low similarity and such that it nears 1 if and only 
if q and d have a high similarity? We now provide such a string-comparison function comp on strings in 
R, which, whenever applied to s.rbis(q) and s-rbis(d), equals O if q and d have no terms in common, grows 
from O to 1 when q and d get more terms in common and in a more similar ordering on occurrence frequency, 
and equals 1 if q and d have the same terms in the same ordering on occurrence frequency. The string-comparison 
function comp is based on the following assumptions, observations, and their corollaries: 1, for any 
text t,high-frequent terms in treflect more-descriptive terms for t than low-frequent terms in t (assumption), 
2. for any text t,early terms in the simple rank-based term sequence s-rbts(t ) are higher frequent terms 
in tthan late terms in s-rbts(t) (observation), and thus 3. for any text t,early symbols in the simple 
rank-based image string s-rbis(t) correspond to more­descriptive terms for tthan late symbols in s.rbis(t) 
(corollary); 4. for any query text q and document text d, a term s is equally descriptive for q as for 
d if and only ifs occurs at the same position in s-rbts(q) as in s-rbts(d) (assumption), and thus 5. 
for any query text q and document text d, a term s is equally descriptive for q as for d if and only 
if the symbol f(s) occurs at the same position in s.rbzs(q) as in s-rbis(d) (corollary).  The string-comparison 
function comp has as starting point that if two strings pl in R and p2 in R are identical, then the string 
comparison comp(pl, p2) between pl and p2 should be 1, its maximal value. From that the string-comparison 
function penalizes deviations from equality, using the following two penalty elements. l/fi: a symbol 
a occurs in pl at position i and in pz at position j (i.e., PI [i] = p2[j]), This causes a high penalty 
whenever pl = s-rbis(q) ~ pz = s-r$is(d), and a is positioned late in pl or in P2 (i.e., the term associated 
with u is not very descriptive for g or for d, see the corollary 3 above). (i -~) : a symbol a occurs 
in pl at position i and in pz at position j (i.e., p, [i] = pz[j]). This causes a high penalty whenever 
pl = s.rbis(q), p2 = s-rbis(d), and u is positioned very different in pl than in p2 (i.e., the descriptiveness 
of the term associated with a is very different for q than that for d, see the corollary 5 above). The 
functionality of these penalty elements is illustrated as follows. Example 4.2. Let tl, t2,q, S, <, X, 
and ~ be as in Example 4.1. Then the penalty elements for comparison of cat in the query q with cat in 
the documents tland t2consist of l/~ = fi/2 and (2 1)2 = 1 in comparing q with tl,and  l/~ = fi/4 
and (2 4)2 = 4 in comparing q with t2.  Thus, since cat is ranked higher in s.rbts(t 1) than in s_rbts(t2) 
(i.e., it is more descriptive for tl than for t2),the associated (first) penalty element is higher for 
t1than for tz.Furthermore, since the ranking of cat in s.rbts(q) is more similar to its ranking in s-rbts(tl 
) than to its ranking in s-dds(t z) (i.e., its descriptiveness is more similar to that in t~than to that 
in t2),the associated (second) penalty element is lower for t 1 than for tz. 0 Combining the penalty 
elements described above, the string-comparison function comp (pl, p2) between two strings pl and p2 
in R is defined as follows. Let the position function pos :Xx {p~, p~}+{l,...,l +21p~l+21p21} be such 
that, for a c Z and p c {pi, p2}, { ifp[j] =a for 1 <j < ~pl, and pos(a, p) = 3 l+21p~l+21pzl ifp[j] 
+o for all 1 <j < Ipl. Then: comp(pl, p2) = 1 ~(pl, P2)//3(P1, P2), (6) where (Pos(c, Pl) -Pos(~, P2))2 
4P1, P2) = x (7) /pos(c, pl) . pos(a, pz) uE#(P1)LJq$(P2) and (1+ 21p,l + 21p21)2 m, P2)= x {pos(a, 
pl) oPos(a, p2)ue+(pl)n~(pa) (1+ 21p,l + 21p21 -pos(a,p,))z + x /(1 + 21p,l + 21p21) ~pos(a, p,) oe@(pl)-#J(p2) 
+x (1+ 21p,] + 21p21 -pos(a, p2)) (8) /(1 + 2]p,l + 21p21) ~pos(a, pz) uE@(P2)-@(Pi) Here, CZ(pl, p2) 
aggregates all penalty elements mentioned before and ,B(pl, p2) is a normalization component, guaranteeing 
that the string-comparison function always lies between O and 1. Example 4.3. Let tl,t2,q, S, +, x, and 
~ be as in Example 4.1. Let p = s_rbis(q) = tc, pl = s-rbz s(tl) = ctsb, and pz = smbis(tz) = hdtc. Then 
Ipl = 2, Ipl I = 4, and lp2 I = 4. Furthermore, reflecting the contributions of t, c, s, and b, respectively, 
a(p, Pl) = 12/sqrt(2) + 12/sqrt(2) + 102/sqrt(39) + 92/sqrt(52) = 28.66, P(P, PI) = 132/W-W+ 132/WW + 
lo2/WW9) + 92/@(W = 266.25, and thus comp (p, p2) = 0.89. Similarly, reflecting the contributions oft, 
c, h, and d, respectively, ~(p, p2) = 22/sqrt(3) + 22/sqrt(8) + 122/sqrt(13) + 112/sqrt(26) = 67.39 P(P, 
P2) = 132/s@(3)+ 132/s@(s)+ lz2/s@(13) + 112/sw@G) = ZZO.99) and thus comp(p, pz) = 0.70. 1 Apart from 
normalizing onto a value between O and 1, ,B(pl, pz) also ensures that the string-comparison function 
between pl and p2 equals O if and only if pl and p2 have no common symbols and that it equals 1 if and 
only if pl and pz are identical. All of this is shown as follows. Claim 4.1. 0< comp(p~, pz) ~ 1. Proof. 
Since a(pl, pz) z O and ~(pl, pz) >0, it follows from Formula 6 that O < Comp(pl, p2) s 1 if and only 
if a(pl, pz) < /?(pl, p2). Partitioning the set #(pl ) U @(pz) into the three disjoint subsets @(Pi) 
n 40z), C#(PI) +(m), and ~(m) 4(PI), Formula 7 and 8 above imply that @I, PZ) < WI, P2) if and only 
if (pos(u, p,) -Ws(a, P2))2 < ~ (1+ 21p,l + 21p2[)2 x l/POs(o, Pl) POs(o~P2) ~~#(P1)n#(fl,) i Podu, 
PI) Pos(a, /22) ae~t~l)n+(~a) The latter holds, because, by definition of pos, for all u G 4(pI) n 4(Pz), 
POS(U,P1) < IPI I and Pos(u, P2) < lp21, and thus also (Po$(~!Pl) -POS(U, P2))2 s (1 + Wll + 21P21)2 
Consequently, a(pl, fq) < ~(pl, pz). 0 Claim 4.2. Comp(pl, PZ) = O if and only if d(pI) fl 4(Pz) = 0. 
Proof. Since ,f3(p1, pz) >0, it follows from Formula 6 that cornp(pl, pz) = O if and only if a(pl, LJ2) 
= P(P1, P2). Partitioning the set 4(A) u 4(P2) into the three disjoint subsets 4(P1) n c+5(P2), 4J(P1) 
 4(P2), and 4J(PZ) #(pi), Formula 7 and 8 above imply that a(pl, p2) = ,f3(pI, pz) if and only if (pos(u, 
p,) -Pos(a, P2))2 = ~ (1+21 P11+21P21)2 x /pos(u, Pl) Pfqa, P2) /pos(u, pl) . pos(u, /22) 0~@(p1)n#(p2) 
ffeo(pl)no(pa) However, by definition of pos, for all a c #(pi) n o(gq), POS(O,P1) < IPI [ and POS(O,P2) 
< IP21, and thus (Pos(~, Pl) -Pos(~, P2))2 < (1 + 21P11 + 21P21)2. Consequently, cx(pI, pz) = ~(pl, pz) 
if and only if #(pi) n +(Pz) =0. 0 Claim 4.3. Comp(pl, p2) = 1 if and only if pl = p2. Proof. Since ~(pl, 
p2) >0, it follows from Formula 6 that Comp(pl, p2) = 1 if and only if a(pl, p2) = O. Hence, it follows 
from Formula 7 that Comp(pl, p2) = 1 if and only if pos(a, /71)= pos(u, p2) for all a c @(pl ) U g!J(p2), 
which clearly is equivalent with pl = p2. 0 Another property of the string-comparison function comp(pl, 
P2) between P1 and P2 is that, for any symbol u c @(pl ) U I$(p2), the penalty element (pos(~, pl ) 
pos (m, p2))2 is always smaller whenever a occurs in both pl and p2 than in only one of them. This can 
be deduced from the following claim and its proof. Claim 4.4. For a G I#I(pl) n #(p2), 1. (POS(U!P1) 
 Pd~,P2))2 < (Pod~)Pl) (1+ 21P11+ W21))2 and 2. (pos(c7, pl) pos(a, p2))2 < ((1+ 21pl[ + 2[p21) pos(a, 
p2))2. Proof. By definition of pos, pos(cr, pl) <1 + 21p1 I + 21p21, and thus the first part of the claim 
holds if lPoq~, pl) -Pos(~, p2)[ <1 + Wl[ + 21P21 -pos(~, pl)l which, again by definition of pos, holds 
when pos(a, PI) < pos(a, P2). Moreover, if POS(CT,P1) > POS(U,P2) ~ then the first part of the claim 
holds if 2pos(a, pl) <1 + 21P11 + 21P21 +Pos(~>P2)1 which again holds by definition of pos. The second 
part of the claim is proven similarly. 0 A final property of the string-comparison function is that it 
is symmetric. Claim 4.5. comp(pl, pz) = comp(p2, Pi). Proof. Since (Poqa, Pl)-Pos(a, P2))2 = (Pos(u, 
p2) -pm (a, /21))2 and since product, addition, union, and intersection are commutative, this directly 
follows from Formula 6 through 8 above. 1 After the definition of the string-comparison function comp, 
we finally can define the simple rank-based text similarity between a query text q and a document text 
d, denoted by s.rbsim(q, d), as follows: s-rbsim(q, d) = comp(s-rbis(q), s.rbis(d)). (9) Note that the 
simple rank-based text similarity is, however only slightly, dependent on the linear ordering < on the 
set of terms S. Furthermore, it follows from Claim 4.1 that O < s-rbsim(q, d) s 1, from Claim 4.2 that 
s.rbsim(q, d) = O if and only if q and d have no terms in common, and from Claim 4.3 that s-rbsim(q, 
d) = 1 if and only if q and d have exactly the same terms in exactly the same ordering on occurrence 
frequency. Finally, it follows from Claim 4.4 that s_rbsim(q, d) increases from O to 1 when q and d are 
getting more terms in common. Example 4.4. Let tl, tz, q, S, +, X, and f be as in Example 4.1. Then s-rbsim(q, 
tl) = 0.89 and s.rbsim(q, t2) = 0.70, which shows that t1is more relevant to q than tz is. 0 As we have 
seen in the literature (see, e.g, [14]) as well as in Section 2.2 and 3.2, the use of inverse document 
frequencies highly improves the effectiveness of full-text document retrieval models. Incorporating inverse 
document frequencies in the retrieval model described above can be done as follows. Lettbea text in Tand 
let, forn~l, sl, ..., Sn 65 be the terms in tsuch that frq(sl) t) .log A1/nl ~ . . . ~ frg(sn, t) . loglV/nn 
and such that, for all 1< i,j < n, frq(si, t) .log N/n~ = ~rq(sj, t) . log N/nj ~ s; + sj holds. As before, 
N is the number of documents stored and ni is the number of these documents that contain the term Si 
(1 < i < n). Then the term sequence (sl, . . . . Sn) is called the modtjied mnk­ based term sequence 
oft, denoted by m.rbts(t). Furthermore, the string j(sl ) . . . ~(sn ) .mcr Z is called the modtfied 
rank-based image string of t, denoted by m-rbis(t). Finally, the modified rank-based text simdarity between 
a query q and a document d in D Q T, denoted by m-rbszm (q, d), is: m.rbszm(q, d) = comp(m-rbis(q), m.rbis(d)). 
(lo) Also the modified rank-based text similarity is slightly dependent on the linear ordering < on the 
set of terms S. Furthermore, again by Claim 4.1 through 4.4, 0 < m .rbsim(q, d) < 1, m-rbsim(q, d) = 
O if and only if q and d have no terms in common, m-rbsim (q, d) = 1 if and only if q and d have the 
same terms in the same ordering (on product of inverse document frequency and occurrence frequency), 
and s-rbsim(q, d) increases when q and d are getting more descriptive terms in common. 4.3 Variations 
It is easily understood that the simple and modified rank-based text similarities as defined in Section 
4.2 above are only two examples out of a potential multitude of different ways in which the rank order 
of term occurrence frequencies can be used in full-text document retrieval. And of course, it is impractical 
to report and investigate many of the other possible ways to define rank-based text similarities in one 
and the same paper. Nevertheless, we would like to make some remarks and present some variations on the 
full-text document retrieval model introduced. As shown in Claim 4.5, the string-comparison function 
and thus also the simple and modified rank­based text similarities all are symmetric. However, one could 
argue that a query and a document are two completely different objects, and thus that it is not logical 
that the rank-based text similarities between a query and a document should be symmetrical. For instance, 
one could argue that a(pl, pz) and @(pi, pz) should be defined as (w(a, Pl) -Pos(~, P2))2a(pl, pz) = 
~ (11) /pos(o, p~) . pos(u, p2,) YE4(P1) and (l+21p,l+21p21)2 P(P1 !P2) = x /P@(~> Pl) Pos(~, P2) oc~(~l)no(~a) 
(1 +21p,l + 21p2\ -pos(a, p,))z +2 (12) <(1 + WJll +21P21) W(C,P1) UC O(P1)-4J(172) or (1+ 21p,l + 21p21 
-pos(a, p,))z ml!P2) = ~ (13) /pos(cT, p~) . pos(a, p~) uE@(P1) instead of as defined in Formula 7 and 
8. Next to the fact that these approaches indeed yield non­symmetric rank-based text similarities, computationally 
they have the advantage that for all the symbols that are in pz but not in pl no calculation has to be 
made. And when pz is the rank-based image of a large document while pl is the rank-based image of only 
a small query, this makes quite a difference. Furthermore, although the string-comparison functions as 
defined by Formula 6 and Formula 11 through 13 satisfy Claim 4.1, 4.2, and 4.4, they do not satisfy Claim 
4.3. In other words, for these newly defined functions it does not hold that the string comparison between 
pl and pz equals 1 if and only if PI equals p2. This is caused by the facts that pl could be a prefix 
of p2 and that symbols in pz but not in pl are not taken into account in Formula 11 through 13. However, 
this flaw can be repaired by also incorporating the length of pl and p2 into the definition of a(pl, 
p2) and ~(pl, pz), for instance as follows: (pos(u, p,) -pos(u , p2))2 ~(pl, P2) = +x (14) <(IPII + 1) 
(IP21 + 1) ~e$(pl) JPos(~, Pl) Po5(~)P2) (IPII -IP21)2 P CACM CISI CRAN MEDL average + mean 35.63 22.25 
39.92 55.24 38.26 F7 F8 median 27.53 17.54 36.62 55.09 34.20 Fll F12 mean 37.77 22.82 38.77 54.27 38.41 
Fll F12 median 34.02 16.47 35.54 56.72 35.69 Fll F13 mean 36.61 23.10 38.03 53.53 37.82 Fll F13 median 
31.14 17.05 33.96 55.29 34.63 F14 F15 mean 37.91 22.88 38.95 54.33 38.52 F14 F15 median 33.42 16.46 36.11 
56.78 35.69 F14 F16 mean 36.95 23.08 38.28 53.70 38.00 F14 F16 median 31.19 16.90 33.88 57,04 34.75 Table 
3. Average Precision Figures and (IPII -IP21)2 P(P1 !P2) = +x AIPII+ 1) (IP21 + 1) (1 +21p,l +21p21)2 
 /Pc ~(~, Pl) ws(~, P2)ce+(pl)n~(pz) (1+ 21p,l + 21p2[ -pos(a,p,)) (15)+x /(1 + 21p,l + 21p21) . pos(u, 
p,) uG#(P1) tJ(P2) or (IPII -IP21)2 P(P1 !P2) = +x l/(lPll+ 1) (IP21 + ~) (1 -1-21p,l + 21p21 -pos(a, 
p,))z (16) Jpos(a, p~) ~pos(a, pl) YE+(P1) And indeed, along the same lines of proof, it is not difficult 
to see that the string-comparison functions as defined by Formula 6 and Formula 14 through 16 satisfy 
all of Claim 4.1 through 4.4. 4.4 Evaluation We now evaluate the effectiveness of the full-text document 
retrieval model described in Section 4.2 and 4.3 above. Again (see also Section 3.2) the evaluation method 
is the one recalled in Section 2.2. Thus, applying Formula 6 through 16 above, for each query in each 
of the test collections CACM, CISI, CRAN, and MEDL, we made ten retrieval runs and computed the associated 
precision figures. The resulting average precision figures related to the modified rank-based text similarities 
(Formula 10) are presented in Table 3. The average precision figures related to the simple rank-based 
text similarities (Formula 9) are much lower (average mean is between 27 and 28 and average median is 
between 22 and 23) and therefore they are not shown here. In Table 3, Fx in the column headed by a or 
,6 denotes the retrieval model in which the modified rank-based text similarities are calculated using 
Formula z for cY(pI, p2) or 8(P1, p2), respectively. From these (and the omitted) precision figures it 
follows that the use of inverse document frequencies (using Formula 10 instead of Formula 9) considerably 
improves the effectiveness of the rank-based full-text document retrieval model, In relation with what 
is known from the literature, this is not at all surprising (see, e.g., [14]). However, it is more interesting 
to compare these precision figures with the ones previously presented in Table 1 and 2. In comparison 
with the precision figures resulting from the standard vector­space retrieval model (Formula 1 through 
3) it is found that, on the average, the effectiveness of the modified rank-based retrieval model does 
not show a deterioration. Moreover, in comparison with the best-performing vector-space retrieval model 
F2/F2, a slight increase in effectiveness can even be noticed (from a precision mean of 38.11 to one 
of at most 38.52 for F14/F15). Finally, looking at the precision figures of the Zipf-based retrieval 
model described in Section 3.2 (Formula 3 through 5), the effectiveness of the modified rank-based retrieval 
increases as well (from a precision mean of 37.70 for F2/F4 to one of 38.52 for F14/F15). Note however 
that, because of the direct dependency on inverse document frequencies, the retrieval model based on 
modified rank-based text similarities can only be used in static retrieval environments. Although simple 
rank-based text similarities do not suffer from this problem, the retrieval model based on simple rank-based 
text similarities performs much worse than the best-performing vector-space or Zipf-based retrieval model 
that is suited for dynamic environments (F2/Fl and F2/F4, respectively).   5 Discussion In this paper 
we have proposed a new full-text document retrieval model that is based on the direct comparison of occurrence 
frequency rank numbers of the terms in queries and documents. We also showed that for this new retrieval 
model there was no loss in retrieval effectiveness when compared with the standard vector-space retrieval 
model. In a narrow context, this result can be nicely applied in combination with the compression technique 
presented in [1], our initial motivation for the research presented. However, in a broader context, we 
have also demonstrated that exact occurrence-frequency information does not always seem to be crucial 
in the process of full-text document retrieval. In this paper we did not concentrate on the computational 
complexity of the new full-text document retrieval model. However, for those variants that do not require 
a calculation for those terms in a document that are not in the query, we do expect that the computational 
complexity is comparable with that of, e.g., the vector-space retrieval model. Finally, this paper did 
not yet provide a conclusive investigation into all variations on the use of term occurrence frequency 
rank orders in full-text document retrieval. There might be other models based on occurrence frequency 
rank numbers that are much more effective, and which thus keep up with the increase in effectiveness 
caused by add-ens on the standard vector-space retrieval model. For inst ante, quite some more variations 
can be made on the string-comparison function. Nevertheless, despite of this inconclusiveness, this paper 
illustrated the usefulness of looking beyond term occurrence frequencies, for instance by concentrating 
on term occurrence frequency rank numbers.  References <RefA>1, H .J. Aalbersberg, Posting Compression in 
Dynamic Retrieval Environments, Proc. 14th Interna­tional Conference on Research and Development in Information 
Retrieval SIGIR 91, Chicago, IL (October 1991), 72-81. 2. D.C. Blair, Language and Representation in 
lnforrnatz on Retrieval, Elsevier, Amsterdam, The Netherlands (1990). 3. A.D. Booth, A Law of Occurrence 
for Words of Low Frequency, Information and Control 10 (1967), 386-393. 4. B.C. Brookes, Ranking Techniques 
and the Empirical Log Law, Information Processing and Man­agement 20 (1984), 37-46. 5. L. Egghe, On 
the Classification of the Classical Bibliometric Laws, Journal of Document atz on 44 (1988), 53-62. 
6. C. Fox, A Stop List for General Text, SIGIR Forum 24, No. 1-2 (1989/1990), 19-35. 7. C. Fox, Lexical 
Analysis and Stoplists, in Information Retrieval: Data Structures and Algorithms, W.B. Frakes and R. 
Baeza-Yates (eds.), Prentice-Hall, Englewood Cliffs, NJ (1992), 102-130. 8. W.B. Frakes, Stemming Algorithms, 
in Information Retrieval: Data Structures and Algorithms, W.B. Frakes and R. Baeza-Yates (edsi), Prentice-Hall, 
Englewood Cliffs, NJ (1992), 131-160. 9. N. Fuhr, Probabilistic Models in Information Retrieval, The 
Computer Journai 35 (1992), 243-255. 10. D. Harman, Ranking Algorithms, in Information Retrieval: Data 
Structures and Algorithms, W.B. Frakes and R. Baeza-Yates (eds.), Prentice-Hall, Englewood Cliffs, NJ 
(1992), 363-392. 11. H. Kucera and W.N. Francis, Computational Analysis of Present-day American English, 
Brown University Press, Providence, RI (1967). 12. J .B. Lovins, Development of a Stemming Algorithm, 
Mechanical Translation and Computational Linguistics 11 (1968), 22-31.  13, G. Salton, Automatic Text 
Processing: The !lkansformatzon, Analysis, and Retrtevai of Information by Computer, Addison-Wesley, 
Reading, MA (1989). 14. G. Salton and C. Buckley, Term-Weighting Approaches in Automatic Text Retrieval, 
Information Processing and Management 24 (1988), 513-523.  15. K. Sparck Jones, A Statistical Interpretation 
of Term Specificity and its Application in Retrieval, Journal of Documentation 28 (1972), 11-21. 16. 
Virginia Disc One, CD-ROM from Virginia Polytechnic Institute and State University, Blacksburg, VA (1990). 
 17. G.K. Zipf, Human Behavior and the Principle of Least Effort, Addison-Wesley, Reading, MA (1949). </RefA>
  
			
