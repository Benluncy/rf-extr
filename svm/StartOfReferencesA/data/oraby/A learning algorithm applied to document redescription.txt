
 A LEARNING ALGORITHM APPLIED TO DOCUMENT REDESCRIPTION Michael D. Gordon Computer and Information Systems 
Graduate School of Business Administration The University of Michigan Ann Arbor, MI 48109-1234 1. Introduction 
Relevance feedback in document retrieval usually involves an Inquirer revising a query to obtain better 
retrieval effective-ness [Rocehlo] and [Salton]. The revised query is adjusted to correspond to the descriptions 
of known documents which the inquirer has found relevant. Several problems exist wlth such methods, however, 
and will be described in this paper. Lass frequently, the descriptions of documents, themselves, have 
been altered on the basis of inquirer feedback. The advan- tages that arise from allowing a document 
description to change over tlme wlll be discussed. The heart of thls paper will then be devoted to discussing 
how an algorlthm used in artificial Inte111gence can be used to help redescrlbe documents. A simula- 
tion of a document retrleval system subject to such redescription was conducted, and the results of the 
simulation are descrlbed. 2. query Modification Oonument retrieval is known to be a trial and error process 
CSwanson]. As a result, it IS understandable that attempts have been made to build feedback Into the 
process to improve retrieval effectiveness. Document retrieval involves each of the follow-Ing: inquirers 
identifying their information need with machine processable queries; the subject contents of documents 
being represented and stored in a bibliographic database; and a match- ing function which the retrieval 
system has been programmed to use to select documents in response to a given query. It would be possible, 
then, to try to modify the workings of a document retrieval system in various ways (each in an attempt 
to improve the effectiveness of the system): by reformulating the inquirer's query; by changing the descriptions 
of the docu-ments stored in the database; by adjusting the matching func-tion; Or even by making several 
of these changes at once. Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169;1985 ACM0-89791-159-8/85/006/0179 $00.75 Salton and Rocchlo have studied 
automatic query reformulation (or relevance feedback) and have been able to improve retrieval effectiveness 
in controlled, experimental retrieval environments [$alton] [Roechlo]. In essence, the various techniques 
they offer for query reformulation take the descriptions of documents known to satisfy ~h* (flq~ltrsrta 
hand aRd auE~,metl,,atty bu|ld Ptdw queries out of them. Oddy puts the query adjustment back in the searchers' 
hands (although, strictly, s searcher is not making a query). In hie system, the user learns more about 
the structure of the document database and, hopefully, becomes more able to indicate precisely what kinds 
of documents he or she ls looking for [Oddy]. A problem with such query reformulation systems is that 
documents may be poorly or inconsistently described. There ls known variability in the way trained Indexers 
describe the same documents [Zunde and Dexter], so there is really no reason to be optimistic that a 
given document IS described as well as possi-ble. (Similarly, automatic indexing carries no guarantees 
that the statistical occurrences of tokens in text can be used to adequately describe that document.) 
Worse, documents which satisfy the need of a given Inquirer may be described quite differently. Any attempt 
then to altar a query to be more like the description of one of these relevant documents may bring about 
worse matching relative to another. Thus, relevance feed-back can succeed to the degree that there are 
clearly Identifia-ble, "tight" document clusters [Salton and McGill]. 3. Document,Redeserlption In contrast 
to redesorlblng queries, the descriptions of documents( themselves, may be redescribed. Simplistically, 
if a r~trieval system were devot-d to one induirer~ dne,Jm-nt d~q~rtp- (lens could be changed in response 
to his or her relevance as- sessments. The relevant document which the system has predict- ed is only 
marginally relevant to the inquirer's query would be redescrlbed, if discovered, to increase the llkelihood 
of Its being furnished the next time the inquirer makes a similar query. (Exact matching retrieval 
functions can modify documents somewhat slmilarly.) In multl-user retrleval systems, the same sort 
of redeecrip- (ion iS possible, Instead of modifying a document's description to match better the appropriate 
query (or queries) of a single inquirer, a document may be redescribed to match better the "relevant 
queries" of any inquirer who finds that document satisfies his or her information need. Then, the next 
time any Of these inquirers searches for that document with its modified description, chances are he 
or she should flnd it with less effort (fewer searches) or wlth a higher prediction of probabil- Istlc 
relevance by the retrieval system. To the extent that other inquirers make similar queries, they, too, 
will find the system predicting relevance more effectively. A question which naturally arises is: why 
Is it better to redescrlbe the descriptions of documents than the queries put forth to retrieve them? 
In part, the question is wrong. To the extent possible, the two types of modifications should be used 
together since they are not incompatible. In fact, It is the communication back and forth between inquirer 
and retrieval system that should be stressed as a principle of document re-trieval [Gordon], [Oddy]. 
From another vantage, though, document redescrlption can be regarded as more natural and more effective 
than query reformula-tion. Document retrieval systems which ultimatel 7 hope to pro-vide a natural language 
interface can make use of document redes-criptlon so that a document's descriptions and the queries made 
to retrieve it become more alike. Documents become described similarly to the way they are naturally 
looked for instead of queries being reformulated to match document descriptions which may be rather arbitrarily 
constructed. Additionally, as we have seen, the inaccuracy of a document description and the dissimilar 
descrlptlons of documents which are relevant to the same query may militate against effective query reformulation. 
In redescrl- blng documents, the "inaccuracies" or "dissimilarities" that must be accounted for arise 
solely from the way people naturally use language (and issue queries to express their information needs). 
These variations in linguistic style are built Into the problem of document retrieval. The better able 
we are In ~ccommodetlng this variation, the better our systems will be. In other words, querying (uSing 
language) is (nearly) a natural phenomenon, but document descriptions are the artifacts o£ indexing. 
Both are attempts to "name" the same thing. So it seems senstcal to try to modify the "artificial" name 
(index) to resemble the natural. R previous attempt at adjusting term weights Is reported by Brsuen [Brauen]. 
Despite Its promise, this approach performed worse when it received feedback information concerning both 
successful and unsuccessful searches than when it only received the former. Also, "control" queries, 
which should not necessari-ly have been more easily retrieved after document modification, exhibited 
even better recall-preclslon performance as a result of adjusting term weights than dld the "test" queries 
toward which document redescrlption was directed. ~. Genetic A16orlthm An adaptive algorithm, which has 
application In many fields, can be used to improve the description of document descriptions [Holland 
1975]. This adaptive algorithm (or "genetic algorithm," since it is based on a genetic metaphor) is currently 
being used to artificial intelligence research to help promote learning [Holland 1983]. As I have pointed 
out, retrieval systems can learn about the the relevance relationships between user queries and documents. 
Thus, the genetic algorithm can be seen as an effective too1 for document redescrlption. The lenetlc 
algorithm operates essentially a8 follow=l Repeat 1) Measure the performance (worth) of each competing 
object in a (fixed-size) set. 2) Replace the set of objects: First, throw away the current set of objects. 
Then build new objects out of old object parts, using more parts of the objects with higher worth. Each 
of these new objects will likely be different than all objects in the previously discarded set. gntil 
some criterion is attained. 1 The algorithm attempts to mimic genetics, promoting a popu-lation built 
up of parts ("genes") of its fittest members. As In genetics, succeeding generations introduce variety 
(new "ob-Jects", i.e. people, who resemble their forebears but are not identical to them). A simplifying, 
non-biological example may provide a better feeling for the algorithm. Suppose the perform-anne (worth) 
of a car can be measured as a function of its speed and the comfort it provides Its driver. Then the 
a Porsche may have great worth (because it's fast) while a Rolls Royce may have great worth (because 
of its comfort). The genetic algorithm might "build" a new car (Porsehe Royce) out the parts of both 
oars, trying to attain speed and comfort at once. In genetics, a gene carried by the fittest members 
of the population will proliferate from one generation to the next (assuming these flt members have disproportionately 
more offaprinna thafl thmtr iaaa fit eeun~ePpaP~s). I. tltl~ way, ~tlo. needing generations tend to 
be fitter than their parents. The genetic algorithm operates by determining the fittest members in a 
given generation, ensuring that they are disproportionately represented the next generation, and introducing 
variety in the population to try to "build" offspring fitter than their par-ents. Further, the algorithm 
selects not only good "genes" but good "gene combinations." That is, even If many traits ("genes") of 
an object interact in complex ways, the genetic algorithm works to flnd these viable combinations. 1See 
appendix A for a more detailed discussion of the algo-rithm. This appendix is best read following section 
6. 5. Adapti, ve Document, Redescrtption Document description may be cast as a problem of "building" 
adequate representations of documents, The "genes" of a docu-ment's description are the terms used to 
describe it (or, alter-natively, the weights of those terms, as the case may be). What genetic adaptation 
can do, then, is to ~bulld" fitter and fitter document descriptions in succeeding generations. The more 
the system learns about the requests used to retrieve a given docu- ment, the better it will become subsequently 
in furnishing that d0cu~nt to srelevah~ s quQrte$. 6. Simulation of Adaptive Document Description A 
document retrieval simulation was conducted to determine the effectiveness of using the genetic algorithm 
to redesorlbe documents. Eighteen documents had their subject descriptions altered. The way one document 
was redesortbed was unaffected by the redeserlptlon of any other document, What follows is a brief description 
of the redescrlptlon of on_.~ of these eighteen docu° mests~ First, since the genetic algorithm conducts 
a "competition w among competing objects in some system, a .given document was Initially described by 
approximately seventeen undergraduates who had ~ust read it. Each of these students chose from a closed 
llst Of subject phrases those phrases he Or she felt "definitely" (or almost definitely) described that 
document. Thus, one stu-dent might have described a document as being about the four subject phrases: 
office automation, improving productivity, office of the future, personal work stations. Another student 
may have described the document with some Of these terms, too, or any of the (approximately thirty) terms 
provided to choose from. In this way, the document was described separately (and Independently) by approximately 
seventeen individuals. (The simulation experiment converted these descriptions into seventeen binary 
strings--or vectors--for use by the genetic algorithm.) The action of the simulation was to take a set 
of queries, knowinQ in advance that the given document was relevant to each of them, and determine how 
good each of the competing document descriptions was at matching this query set. This determination made, 
the genetic algorithm would intervene, replacing the given set of seventeen descriptions of the document 
with seventeen new ones. The adequacy Of each description In this new set was measured relative to the 
same set of seventeen original queries, and again the set of desariptions was replaced by a new set of 
seventeen document descriptions created by the genetic algorithm. Each round of evaluation-replacement 
constituted one generation, and the simulation was run for forty generations. (See Figure 1.) At the 
end of the fortieth generation, the effectiveness of the prevaillng set of descriptions was compared 
to that of the origi- nal set of descriptions. An explanation of the method of com-puting the effectiveness 
of a document description (or set of descriptions) wlth respect to the fixed set of of "relevant querles 
~ followS. ~o document description can be perfect (in the sense that it filters exactly those queries 
to which it is relevant from the others) because of the variance among inquirers looking for the same 
(or similar) documents. But, the better the overlap (agree-ment) between a document's subject description 
and a "relevant queryp" the better we might feel the description is. Similarly, we may measure how well 
a given description of a document over-laps each of a set of "relevant queries" to tell how well it does 
at matching this set as a whole. (The term "relevant query" is Simply shorthand for me query to which 
a given document iS known to be relevent." WRelevant query set" is similarly defined.) Accordingly, a 
Jacesrd's score was used in evaluating a document description relative to a query. Considering X to be 
the set of subject phrases used in a query and Y to be the let of phrases used In a (single) description 
of a document relevant to that query, Jaceard(Z,~) = #(X Intersect Y) / I(X union Y), # being the cardlnality 
of the set. Relative to a given query, two competing descriptions of the same relevant document can be 
compared by Jaccard's scores: the higher the Jaocard's score the better the description. Similarly, relative 
to a set of "rele-vant queries, ~ the adequacy of a document description may be Judged by determining 
its average Jaocard'a score with re~pect to that ant. In fact, the genetic algorithm operated in exactly 
this way: determine which descriptions in the current set have the highest average Jacoard's scores relative 
to the (fixed) set of relevant queries, and create new descriptions the next genera-tion out of the parts 
of those descriptions exhibiting the hi'gh- eat average Jaccard's matching scores this generation. (See 
Figure 2.) The same technique Of making Jaccard's score comparisons was used to determine the effectiveness 
of adaptation. That is, each "generation" is characterized by the seventeen descriptions it uses to describe 
 given document. And, for each generation, there is an "overall w average Jaccafd's matching score relating 
the set of "relevant queries" (fixed from generation to genera-tion) to the current set of descriptions. 
The higher this "over-a11" average matching score during a given generation, the more similar the prevailing 
set of document descriptions is to the set of relevant queries. (See again Figure 2.) Thus, the goal 
of adaptation was, first of all, to produce superior "overall" average matching in generation 40 (at 
the end of the simulation) than In generation 1 (with the original set of descriptions). Indeed, for 
each of the eighteen documents redescrlbed, there was an improvement in "overall" average matching from 
generation I to ~0 (averaging 24g improvement in Jaccard's score; see Figure 3). Since each of the 
eighteen documents showed better "overall" average matching after adaptation, the description of any 
given document had thus been changed so that it would now be easier to retrieve, .on average, by any 
one of the queries to which it was relevant. (Easier, because It matched better these queries.) Additionally, 
a control used in this phase of the simulation revealed that redeseribtng documents with a genetic algorithm 
could be achieved without an accompanying degradation in fallout, That is, after adaptation, a given 
document would be more easily retrieved by a "relevant query," but not simply by any query. This control, 
like the simulation, considered each document individually. For any donument, the following question 
was answered: Will a set of queries that the document ta not relevant to--even though the document's 
description bears considerable resemblance to these queries--be more likely to retrieve that document 
after the genetic algorithm redeseribes the document? That As: will redeserlbing a document to Improve 
its retrievability by "relevant queries" be offset by its improved retrievability also by "non-relevant 
queries?" The same questionnaire used by undergraduates to Supply initial document descriptions contained 
enough information to create a set of "non-relevant queries." Simply, all subject phrases that the reader 
of the document said were "somewhat" (or a little less) about the document were taken to represent a 
query to which the document was not relevant. For instance, in saying a given document was "somewhat" 
about "artificial intelligence," "medicine," and "expert systems," the contention was that, if the describer 
were asking for donuments concerning those terms, that document would not be considered relevant. By 
having (approximately) seventeen people make such evaluations about a given document, seventeen "non-relevant 
queries" were obtained for each document. The question that needed answering, therefore, was: what happens 
to "overall" matching between thls document and its non- relevant queries after the document is redeocrlbed 
to match better its "relevant queries?" In evaluating this question separately for each of the eighteen 
documents to which it applied, the answer became: as documents are redescribed, there usually ~s some 
(undesired) increase In "overall" average Jsecard's score relative to non-relevant queries, too. However, 
and Importantly, the redescriptton strongly favored the relevant queries. Specifically, there was nearly 
five times the improvement in Jsecard~s score matching for "relevant queries" than for "non-relevant 
queries" as the result of adaptation. Just as important, for seventeen of the eighteen documents, the 
"desired increase in matching" (between relevant querles and redescrlbed documents) exceeded the "undesired 
increase" (between non-relevant queries and redescribed documents. (See Table I.) In terms of real life 
retrieval, this suggests that deciding which documents are likely to be relevant to a given query is 
an easier task because there is a wider gap between the Jaeeard's scores calculated for relevant and 
non-relevant documents, Zn a seconds and more ambitious, phase of the simulation, the attempt was made 
to alter a document's description so that the document would be more retrievable by relevant queries 
but less retrievable by non-relevant queries. Documents were initially given multiple descriptions just 
as they were in the first phase of the simulation: by taking, for each of approximately seventeen undergraduates, 
those subject phrases the student thought "definitely" (or almost definitely) described the donument's 
subject content. The goal of the adaptation was to alter this set of descriptions so that their "overall" 
average matching score relative to relevant queries would rise but their "overall" average matching score 
relative to "non-relevant que-ries" would fall. (The procedure for obtaining both relevant and non-relevant 
queries has been explained.) That Is, try to redescribe documents an that they are more likely to be 
retrieved when they should be and less likely when not. (See Figure 4.) In this spirit, forty generations 
of document redescrtption took place (independently for each of eighteen documents, each document having 
Its own initial descriptions and relevant and non-relevant query sets). At the end of forty generations 
of adaptation, each generation attempting to build new descriptions out of the beat parts of previously 
evaluated descriptions, two determinations were made: One, did the final set of descriptions associated 
with a document match better the relevant queries than the de- scriptions originally assigned to the 
document? Two, did the (same) final set of descriptions show less resemblance (match worse) the non-relevant 
queries than the original descriptions? The results of simulating the redeacrtptton oE eighteen documents 
indicated that both of these effects were achieved. For each of the eighteen donuments, redescription 
improved the "overall" average matching score relative to the relevant queries (by an averbge of 19.095). 
Additionally, the same redeseription brought about leas resemblance between document descriptions and 
non-relevant queries in fifteen cases out of eighteen (producing an average worsening in resemblance 
of 24.815 across all documents). (See Figure 5 and Table 2.) In sum, then, the genetic algorithm was 
used to build new descriptions of documents that come closer to doing their Job: distinguishing the inquiries 
of those who are interested in a document from those who are not. T. Summary The basic argument advanced 
in this paper has been that redeserihing the subject content of documents in light of inquirers' relevance 
assessments ought to be conducted. The genetic algorithm, a probabllistlc algorithm having application 
to learning and artificial intelligence, has been shown to be effective in governing redescription. Document 
redescriptlon governed by adaptation has shown to be Successful in both of these ways: by making document 
descriptions match better "relevant queries"; and by making document descriptions match less well "non-relevant 
queries" at the same time. In real world retrieval, the same ~nquirers do not reappear again and again, 
always making identical queries (as the simula-tlon suggests they do). But, past inquiring behavior is 
the best evidence we have for predicting future inquiring behavior. Further, the genetic algorithm would 
be sensitive to changes In the nature of the "Pelevant queries" issued for some document. Inquirers who 
attempt to name those subjects about which they are ln~eregtad L~ reteievLn8 documents ape making many 
tins distinctions. In fact, the questionnaire data obtained in th£s research showed thstm all documents 
and all terms considered, over nlne times in ten, at least one respondent felt a given subject term applied 
to a document while other respondents felt it did not, or vice versa. In a "descriptively rich" retrieval 
environment like that in this study, there may be twenty or more plausible descriptions wlth which a 
document can be described and, consequently, which an inquirer may choose in searching for the document. 
With so much variation in the terms inquirers employ, the document redescrtptton problem is quite difficult, 
and Is best handled by a powerful algorithm (such as the genetic algorithm used in thla study). In fact, 
s deterministic algorithm which simply built document descriptions term by term according to the consensus 
of rerevant queries attained Jaccard°s matching scores which the genetic algorithm was able to improve 
upon by 255. Further, genetic adaptation makes no assumptions about statistical term independence, instead 
seeking the best combinations of subject terms and building descriptions from them. In all, the document 
description process ought to be regarded as dynamic, instead of being done once and never again. In this 
way, we can improve the odds that the "right inquirers" will find the "right documents," and the wrong 
inquirers will have fewer irrelevant documents to look through. The genetic |l~rL~h~ h~g pe~veh ~0 b~ 
a Suoe~g8~l eideserlptiofl teehfllque in the present simulation. <desc_x11> <desc_x21> ... <desc_x_H1> 
(deg~_x 12) <d~se_x 22~ ... <d~8o x_H2> <desoxlH> <deacx2N> ... <descxHN> ======= Adaptation =====> Generation 
I Generation 2 Generation UO Desorlp set Oeacrlp set Desorlp set Thls figure shows the set of descriptions 
that describes document-x at various stages of the simulation. In each generation, document x is represented 
by a set of ~ descriptions. Each description Is ~ set of subject terms. Descx Ij Is the j-th description 
of document-x In 8eneratlon-t. Adapt~tTon occurs and the set of descriptions in one generation is replaced 
by the set of descriptions in the next. N averaged approximately 17, all documents considered. Figure 
l--Evolution of document descriptions Avg Hatching relev_xql ... relev_xqM Score ............................................... 
desc_xgl J(gt,ql) ... J(gl,qH) 1/H Z J(gl,ql) desc x_aN 3(gN,ql ) .. J(gN,qH) I/H ~ J(gN,qi) N descriptions 
Overall average, Gg = of document-x I In generatlon-g ..... I: E J(gk,ql) k l 14a N Each of dooument-x,s 
H relevant queries is matched against esch of the document descriptions In force in generation-g. The 
Jsccsrd's match between relevant query relev x ql and document description deso z gJ is indicated by 
J(gJ,q~)~ Row averages give "average ~s~chlng scores" for each document description. G , the grand averagej 
gives the "overall average matching score s for the document descriptions in force In the current generation, 
g° A set of descriptions of document-x which produces an overall averge satchln 8 score greater than 
Gg relative to the same relevant queries is an improvement on the gencration-g set of descriptions. Figure 
2--Hatching or descriptions and relevant queries 49 48 47 / / / 46 45 m 44 42 41 40 39 i i i i i i I 
i 1 6 11 " 16 21 26 31 ~ 40 Generation Figure 3--Jacoard's score improvement--all documents combi~sd 
 Avg Recall relev_x_ql ... relev_x_qM Matching Score Change in overall ................................................ 
average matching score desc_xgl J(gl,ql) ... J(gl,qM) I/M Z J(gl,ql) from generation 1 to 1 generation 
40 Document relevant queries Non-relevant queries Doe 1 10.05 4.14 desc_x_gN J(gN,ql) . ,. J(gN,qM) 
l/M Z J(gN,ql) Doe 12 7.61 1.81 Doe 17 10.83 -5.10 N descriptions Grand average, Gg, = Doc 18 13.11 8.51 
Of document-x 1 Doe 19 8.79 4.75 in generatton-g ..... ~ £ J(gk,qi) Doc 21 9.11 0.96 M m N k i Doc 22 
10.38 0.08 lllllIIllIllllalllllllllllllallllllallllllllllllllllIlllIllllll Doe 23 8.01 -8.18 Avg Fallout 
Doe 25 10.81 -3.29 non-tel s ql ... non-rel_x qH Hatching Score Doe 27 8.06 6.87 ................................................ 
 Doe 28 8.51 11.43 desc s gl J(gl,ql) .,. J(gl,qR) 11H ~ J(gl,qi) Doe 30 9.79 3.05 i Doc 32 11.12 2.94 
Doe 33 7.56 5.ql Doe 34 9.11 3.48 Doe 35 10.69 1.91 Doe 36 9.17 1.69 desc x KN J(gH,ql) ... J(gH,qM) 
1/M ~ J(gN,qt) Doe 7 5.62 -5.82 1 Avg. ~ 9.35 1.92 B descriptions Grand average, G~, = 3.D. : 1.62 4.89 
of document-x 1 in generatton-g ..... Z ~ J(gk,qt) N m H k i ~a~4 @wpru~o4 tn tin|tit ~r Jmn,aPd*a ,.,.~,'0w 
IOn. Each document description is matched with each relevant query and also with each non-relevant query. 
For each document The pair o£ table entries in a row (like 10.05 and 4.1~ in description, a matching 
score is calculated with respect to the row 1) indicate the intentional and inadvertent improvement, 
relevant query set (row averages above the starred line), respectively. That Is, after Document-1 was 
redescrlbed for ~0 and also an average matching score Is calculated with generations, the overall average 
matching score relative to its respect to the non-relevant query set (row averages below the relevant 
queries was intentionally elevated by 10.05 Jaccard starred line), points; similarly, the same redescrtptlon 
inadvertently increased document-l's overall average matching score 4.14 points relative Note that, above 
the dotted line, J(gt,qj) indicates the to its non-relevant queries. Jaccard match between description 
descx gt and relevant query rcl-x-qj, whereas below the line it indicates the Jaccard match Table 1--Increase 
in overall average matching for between the same description and non-relevant query non-relevant queries 
versus relevant queries non-relxqj. The goal of adaptation was to elevate GE but reduce G~. Figure q--Hatching 
of descriptions with relevant and non-relevant queries 19 48 47 __- f ~ " ~ /-/-- m ~ 4s m 16 m ~ 
44 2 : o  46 flout 18 ~ 43 o ./ ~ 42 o 41 1140 10 39 I i I I I I 6 11 16 211 26 ~I-" 36 40 Generation 
Figure 5--Recall-[allout ImprOvement-all documents combined Recall curve shows improving similarity betueen 
document descriptions and the fixed set o£ relevant queries; £allout curves SHOWS that there is s simultaneous 
reduction In similarity between the same document descriptions and the non-relevant querle~. RECALL FALLOUT 
Oen 1 Gen40 %Chng Oen I GenqO %Chng  ............................... , ....................... Doe I 
36.03 42.86 18.96 20.07 14.47 -27.90 Doe 12 44.45 50.59 13.81 17.83 7.69 -56.87 Don 17 42.19 52.53 24.51 
17.12 11.05 -35.36 Doe 18 39.36 50.58 28.51 21.08 25.87 +22.72 DOe 19 41.12 47.33 15.10 18.83 17.58 -6.64 
Doe 21 43.Ol 52.45 21.95 18.00 16.04 -10.89 0oo 22 33.45 ~o.og 19.85 18.11 13.87 -23.~1 Doe 23 31.81 
39.98 25.68 12.92 4.28 -66.87 Doe 25 54.21 64.43 18.85 13.72 8.33 -39.29 Doe 27 37.92 46.65 23.02 17.65 
13.25 -24.93 Doe 28 28.06 30.23 7.73 19.34 14.52 -24.92 Doe 30 48.15 57.72 19.88 16.88 18.~5 +9.30 Doe 
32 47.36 57.09 20.54 16.69 16.81 +0.72 Dec 33 39.95 4~.29 10.86 20.29 13.75 -32.23 Doe 34 36.80 q3.95 
19.43 18.25 16.16 -11.45 Doc 35 39.83 47.64 19.61 17.88 13.03 -27.13 Doe 36 31.23 37.99 21.65 14.75 8.53 
-42.17 Doe 7 36.66 41.68 13.69 16.35 8.31 -~9.17 Average; 39.53 47.12 19.09 17.54 13."4 -24.81 This 
table indlcatea the initial (pre-adaptatlon) level of association between a document and its relevant 
queries and Its non-relevant queries, as well as final (post-adaptation) levels of the same meaauree. 
For don 1, for example, we see that document redeaoription caused the average Jaocard'a match between 
relevant queries and document descriptions to rise from a Janeard's score of 36.03 (before adaptation) 
to a Jaeoard's score of 42.86 (18.965 improvement). The same document redeaeriptton resulted in the average 
match between doe l'a non-relevant queries and document deaoriptions dropping from a Jaecard's score 
of 20.07 to a Jaeeard'a score of 1~.47 (a 27.~05 improvement). Table 2--Recall-fallout improvement Appendix 
A The genetic (adaptive) algorithm operates on a set of objects, each of which is performing a similar 
task. The algorithm replaces this set of objects with another set, then another, and so on. The replacement, 
described below, attempts to produce new sets of objects in eanh succeeding "generation" which, on a 
whole, are more fit (perform the designated task better). The genetlo algorithm repeats the two-step 
process already outlined: Repeat I) Meanure the performance (worth) of each competing object in a (fixed-size) 
set. 2) Replace the set of objects: First, throw away the current set of objects. Then, build new objects 
out of old object parts, using more parts of the objects with higher worth. Each of these new objects 
will likely be different than all objects in the previously discarded act. Until some criterion is attained. 
 Figure 2, in the text, helps explain the details of the algorithm as used in this study. Each of the 
8eneration-g descriptions of doeument-a shown ta really a binary document vector. For example, we might 
have: T 1 T 2 T 3 T 4 T k desex_g1 = < 1 1 I 0 0 ) desc-x-gN = < 0 1 1 0 0 > where each of T~, through 
T~ is a subject term (actually, phrase) that is either 6eing employed in describing a document (1) or 
ia not (0). Both of the steps in the algorlthm above are now more  completely explained. 1) Measure 
performance of oompetin6 obJenta The Average Matching Score for each description is indicated in the 
right most column of Figure 2. This measures how well each competing description "performs" (matches, 
on average, the M relevant queries for thin document). We call this a deaerip-tion*a ~fitmmml". 2) Replacement 
of the set of objects a) Relative Fitness: Calculate, for each description, deaex gi, Relative Fitness 
(descx gi) (1 <= i ~=-N). Relative-Fltneaa{desc ~ ~l) = Av8 Matching Score (desc x_gi)/F, where N F 
= (l/N) a Z Avg Matching Score (dese x gm) m= 1 b) Reproduction : Create Relative Fitness (deac_a gm) 
copies of deac_x_gm (1 <= m <= N) Treat fractional relative fltneanes stochastically. Discard generation 
g descriptions.  a) ~pall_SVer i gandomly partition thla newly created act of ~1 descriptions into floor 
(N/2) paira (plus a single remaining description if N is odd). For each pair, J, pick a random cross-over 
point, pj, 1 <= pj <= k -I (k the length of the vector). Form the generation g + I set Of document descriptions 
as follows (set initially empty): Add to set: initial (dace-pair Jl ) final (dese-pair j2) initial (desc-patr 
J2 ) ++ final (dese-palr jl ) where deae-pair J~ and dace-pair J~ are the pair of document descriptions 
in tMe j-th pair; Initial (deae-palr Jt ) = first p~ positions in vector dave-pair Jt (t = 1,2) ~ final 
(dame-pair at) : last (k -p4) positions in vector deac-palr J~ (t = 1,2) J + = string eoncatenaCion For 
odd n, remove a randomly chosen description from the set Just generated. Pair it with the as yet unpaired 
description. Apply cross over to this additional pair and place this newly created pair into act. For 
Instance, if a copy of dean x 91 and a copy of Deaex gN are chosen to be paired, and pj ta ~n~omly selected 
to be 3T ~e ave Before crossover After crossover TI 72 T3 74 . T k TI T2 T3 TU T k < I 1 1 0 1 < 1 
1 1 0 . . 0 > <0 1 1 0 . 0 > < 0 1 1 0 1> P j= 3  The now sot of dooument-x deaorlptlons would repLace 
those in Figure 2, and the entire adaptive process would be repeated Note: Figure 4 presents a slightly 
more complicated situation, differing in its calculation of relative fitness. There, the fitness of 
any description depends on both its "recall" fitness (similarity to relevant queries) and its "fallout" 
fitness (dissimilarity to no_n-relevant queries) That is, in Figure 4, the fitness of a document description, 
say deaoxgi, would be equal to: (I) Avg Recall Matching Score (dace x gi) + wt (Og -[Avg Fallout Matching 
Sc~r~ (deacxgl) -Gg]) Three observations pertain to this formula. I) The first addend, Average Reeall 
Matching Score (dese xgi), reflects the description's similarity to relevant queries 2) The second addend 
reflects the description's dissimilarity to non-relevant queries. The term the G~-[Avg Fallout Matching 
Score (descx gi) -G~] is exactly the same magnitude above G' as Avg Fallout--M~tehlng Score (dese-x-gl) 
is below it This q "inversion" is necessary so that descriptions good at matching relevant queries and 
descriptions good at not matching non- relevant queries both eontribute in an "above average" fashion 
to the overall fitness the description. (That in, descriptions which are quite dissimilar to non-relevant 
queries should contribute "fallout fitness n values greater than G'q" ) The relative fitness of deaex_gl 
was calculated to be: N fitness (deae_xgi)/(1/~ C fitness (descx_gJ)) J=l 3) The weight, wt, in expression 
(1) was employed to balance the differing effects of a description's Avg 8ecall Matching Score (recall 
fitness) and "inverted" Avg Fallout Matching Score (fallout fitness) on its overall relative fitness. 
Some experimentation indicated a weight of 0,50 was appropriate to cause G 9 to rise and G~ to fall the 
same in succeeding generations. REFERENCES <RefA>Krauen, To L. ~Doeument vector modification," Chapter 2U in 
Salton Gordon, Michael "Adapting document retrieval subject descriptions to relevant uoer inquiries," 
Working Paper Me. 383 Division of Research Graduate $chool of Business Administration The University 
of Michigan Ann Arbor, Michigan, 1983 Holland, John Adaptation in Natural and Artificial Systems University 
Of Michigan Press, Ann Arbor, Michigan, 1975 Holland, John * "Escaping brittleness," Proceedings of 
the International Machine Learning'Workshop Monticello, ILL, May 1983 Oddy, R. N. Information retrieval 
through man-machine dialogue," Journal of Documentation, ~, 1977 Roechlo, J. J.~ Jr. "Relevance feedback 
in information retrieval," Chapter lq in 5alton  Salton, G., "aelevence feedback and the Optimization 
of retrieval effeetiveneee" in The SMART Retrieval System--Experiments in Automatic Document Englewood 
Cliffs, N.J., 1971, Chapter 15 Salton, G., and McGtll, Michael Introduction to Modern Information Retrte.val, 
McGraw-Hill Book Co., New York, 1983 Swanson, Don "Information retrieval as a trtel-end-error "process," 
in Key papers in Information Science," edited by BeZver C. Grlffith, Xnowledge InduatrF publications, 
Inc., White Plains, New York, 1980 Zunde, Pranaa, and Dexter, Margaretj "Indexing consistency and quality," 
American Documentation, July, 1969</RefA>   
			
