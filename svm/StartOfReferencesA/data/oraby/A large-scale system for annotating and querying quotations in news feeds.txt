
 A Large-Scale System for Annotating and Querying Quotations in News Feeds Jisheng Liang Navdeep Dhillon 
Krzysztof Koperski Evri Inc. Evri Inc. Evri Inc. Seattle, WA, United States Seattle, WA, United States 
Seattle, WA, United States jisheng@evri.com deep@evri.com kris@evri.com ABSTRACT In this paper, we describe 
a system that automatically ex­tracts quotations from news feeds, and allows e.cient re­trieval of the 
semantically annotated quotes. APIs for real­timequerying of over10millionquotesextractedfromrecent news 
feeds are publicly available. In addition, each day we add around 60 thousand new quotes extracted from 
around 50 thousand newsarticlesorblogs. Weapply computational linguistic techniques such as coreference 
resolution, entity recognition and disambiguation to improve both precision and recall of thequotedetection. 
Wesupportfaceted search on both speakers and entities mentioned in the quotes. 1. INTRODUCTION We demonstrate 
a faceted search system for querying se­mantically annotated quotations, and show its advantage over 
thebag-of-keyword approach. We use naturallanguage processing techniques to extract quotations from text 
(i.e. news articles, blogs, etc.), including identifying the speaker and the quote, as well as the context 
of the quote being made. We apply entity recognition to identify named en­tities and concepts mentioned 
in the quotations. We store each extractedquotation,together withits associatedprop­erties,in aninvertedindexthat 
enables e.cient and .exible retrieval. The system supports search for quotes in many di.erent ways, in 
the form of What did <speaker> say about <subject>? where <speaker> and <subject> arespeci.edby users. 
The <speaker> parameter could be speci.ed as a speci.c entity (e.g. Obama), a facet (a type or category 
of entities, e.g. politician, basketball player), or anyone. And <subject> canbe speci.ed as combination 
ofkeywords, entities, and/or facets. For example, What did Obama say about global warming?  What are 
people saying about Obama?  Whatarepeople saying aboutObama andglobal warm­ing?  What are [actors] 
or [movie directors] saying about Oscars?  WhatdidObama say about any[basketballplayers] or [basketball 
teams], given he likes to play basketball?  Copyright is held by the author/owner(s). WWW2010, April 
26-30, 2010, Raleigh, North Carolina. .  Here,thetermfacet referstosome aspect of anentitydis­coverable 
from an ontology or taxonomy of entities. Facets typically are more .nely granular characteristics of 
entities, often times used to categorize entities. For example, par­ticular entities may belong to di.erent 
categories such as football players, movies, cities, companies, websites, etc. In this paper, we use 
square brackets to indicate facets (e.g. [Football Player],[Website]). The facets could be organized 
into a hierarchical taxon­omy, based on relations such as is-a, member-of, etc. There­fore, a facet can 
be represented as a taxonomic path, e.g. [Person/Sports/Athlete/Football Player]. At search time, we 
have the .exibility to support query on a facet (e.g. [Football Player]), or any of its parent nodes 
in the tax­onomic path (e.g. [Athlete]), or any subpath (e.g. [Per­son/Sports]). We have built a large 
entity repository, in which the entities are associated with types and facets, as well as many other 
properties. 1.1 Related Work Google sInQuotes1 feature allows usersto searchforquotes made by a small 
selected set of politicians. Users can type in any keywords in the search box, and quotes containing 
the keywords would be returned. They do not allow search on the speaker itself other than from the selected 
set. Daylife returns recent quotes made by a given speaker (e.g. quotes by President Obama2 ). However, 
they do not allow users to search for quotes on a particular subject. Pouliquenet. al.[7]present asystemcalledNewsExplorer3 
. The system identi.es quotations from live news feeds, to­gether with the person who made the quotation 
and the persons mentioned in the quotation. For each person in thesystem sdatabase,the mostrecentquotationsfromand 
abouttheperson arelisted onthisperson sdedicatedinfor­mation page. Onthequote extractionpart, theprior 
approaches extract quotations based on regular expression pattern matching. They do not apply linguistic 
and semantic analysis like we do(e.g. coreferenceresolution,entity disambiguation,etc.), in order to 
reliably identify the speaker, as well as entities and concepts being mentioned in the quotations. On 
the search of quotations, the prior approaches use traditional keyword search. They do not support semantic 
search of entities and facets as we do. 1 http://labs.google.com/inquotes 2 http://www.daylife.com/topic/Barack_Obama/quotes 
3 http://press.jrc.it/NewsExplorer/    2. DEMONSTRATION 2.1 UI examples Examples of the quotes we 
retrieve from live news feeds can be found at http://www.evri.com. User can type in a query in the search 
box, select any one of the returned entities, and land on an entity pro.le page. If the entity is a person 
type, we show retrieved quotes about the person, followed by quotes made by the person. For example, 
on the pro.le page of President Obama, we display the recent quotes about Barack Obama, as well as recent 
quotes made by him(See Figure 1). Figure 1: Quotes by President Obama If the entity is not a person, 
we show quotes about the entity, e.g. quotes aboutiPhone(SeeFigure2). Figure 2: Quotes about iPhone 
Inoursystem,atthetimeofwriting, wehaveatotal of1.6 million entities4 , with about 0.67 million as person 
names5 . Besides the person type, the other major types are organi­zation, location, product, event, 
concept, substance, and or­ganism. The entities are further categorized into more than 500 facets. In 
addition, we have an automated process in 4 for latest numbers, refer to API call: http://api.evri. com/v1/entities 
5 http://api.evri.com/v1/entities?type=person place that detects trendy entities/concepts, and bring 
them intooursystemonanhourlybasis. Wesurfacelatestquotes made by or about each of those entities. To 
handle anything that is not yet included as an entity in our system, we also provide quotes about any 
keywords orphrases(e.g. semanticsearch , WWW2010 ). 2.2 Public APIs Our portal only demonstrates a subset 
of the available quotation search capability. We expose the full capability via a set of public APIs 
(see documentation at http:// www.evri.com/developer/rest#API-GetQuotations). Be­low are a number of 
examples of the API usage. The re­trieved quotes can be returned as either XML or JSON for­ 6 mat. 
quotesbyaperson, http://api.evri.com/v1/quotes? speaker=/person/barack-obama-0x16f69  quotes about a 
particular entity, e.g. iPhone http:// api.evri.com/v1/quotes/about?entityURI=/product/ iphone-0x4d735 
 quotes by any entities of certain facet, e.g. quotes made by basketball players, http://api.evri.com/ 
v1/quotes?speaker=facet/basketball_player  quotes about any entities of certain facet, e.g. quotes about 
college football teams, http://api.evri.com/ v1/quotes/about?facet=college_football_team  quotes aboutanykeyword 
orphrase, http://api.evri. com/v1/quotes/about?phrase=hoyas  quotes made by a person about any entities 
of a par­ticular facet, e.g. quotes made by David Letterman, a talk show host, about any politicians, 
http://api. evri.com/v1/quotes/about?facet=politician&#38;speaker= /person/david-letterman-0x1b480  
quotes madeby any entitiesof aparticularfacetabout something, e.g. quotes made by any football play­ers 
about the Super Bowl, http://api.evri.com/v1/ quotes/about?phrase=super%20bowl&#38;speaker=facet/ football_player 
  3. SYSTEM OVERVIEW The quotation extraction and search system has three components: Quotation extraction 
and attribution from text docu­ments;  Indexing of the extracted quotations and attributions in an inverted 
index;  E.cientand .exiblesearch of theindexedquotations.  This system is built on top of our existing 
infrastructure forindexing of syntactic and semantic annotation of text[4, 5, 6]. We extended the framework 
to support indexing and querying of quotations. This is also related to our work on entity recognition 
and disambiguation[3]. By identifying entitiesintext, andlink­ing them to the corresponding entries in 
our entity reposi­tory, we are able to support retrieval of quotes by or about entities, as well as by 
certain types or facets of the entities. 6 http://www.json.org/ 3.1 Quotation Extraction and Attribution 
We achieve highly accurate extraction of quotations by applying linguistic analysis such as sentenceparsing, 
named entity recognition and disambiguation, and coreference res­olution. 3.1.1 Linguistic and Semantic 
Analysis For each text document, the processing includes the fol­lowing steps: Sentence splitting Split 
the document into paragraphs, and paragraphs into sentences. Parsing For each sentence, apply linguistic 
parsing to as­sign part-of-speech tags (e.g. nouns, verbs), perform lexicalanalysis(e.g. detectingphrases),anddetermine 
grammatical roles(e.g. subjects, verbs, objects). Entity recognition Applynamed entity recognition toiden­tify 
entities and concepts appearing in the text. Coreference resolution Link multiple mentions ofthe same 
entity across the whole document, including resolving pronoun coreference(e.g. he , him , she ), aliases 
and abbreviations (e.g. Bill Gates referred to as Gates , General Mills as GM , Alaska Airlines as Alaska 
), and de.nite-noun anaphora (e.g. the president , the coach ). The coreference resolution step is very 
important to determining quotation attri­butions, because very often the speaker s full name is notprovidedfor 
agivenquote. Instead, the writer typ­ically usespronouns( he said ),partial names( said Gates ), orde.nitenouns( 
thepresident said ). Sim­ilarly, in quotations, entities are often mentioned as aliases or pronoun anaphora. 
Applying coreference resolutionwouldhelpidentify such mentions,that oth­erwise would be missed by keyword 
matching tech­niques. Below is an example of coreferencce resolution. As the result, the quote is attributed 
to President Obama. I sensed a bit of frustration during Presi­dent Obama s State of the Union address 
last month whenhesaid, Thelongerit[the health-care overhaul] was debated, the more skeptical people became. 
Facet tagging To each entity, we assign its type and facet categories. For example, we tag entity Michael 
Jack­son withtype person andfacet[musician]. Disambiguation Apply entity disambiguation such that each 
mention of an entity is linked to an entry in our repository of entities. As the result, di.erent men­tions 
of an entity are all marked with a unique iden­ti.er. During search, we support search of entities by 
their unique identi.ers, instead of using ambigu­ous keywords. For example, we are able to distin­guish 
between Will Smith the actor and Will Smith the American football player who plays for the New Orleans 
Saints. 3.1.2 Quotation Detection The above stepmarks up each sentence with syntactic and semantic annotations, 
which are then leveraged for extract­ ing quotations. 1. For each verb detected in a sentence, we check 
if the verb belongs to a pre-determined list of verbs that can be potentially used to indicate a quotation 
(e.g. acknowledge, add, argue, caution, say, suggest, urge, etc.); 2. Checktheoccurrencesandpositionsofquotation 
marks in the sentence, as well as it surrounding sentences -a long quote could span more than one sentence. 
 3. Determinequotationcandidatesbased oncombination oftheabovetwofactors,i.e. ifthereisaquotationverb 
and there are quotation marks nearby, we have higher con.dence there is a quotation contained in this 
piece of text.   3.1.3 Attribution and Collapsing We collapse eachdetectedquotationinto atriple of(speaker, 
verb, quote): Speaker: the main subject of the verb, as well as its mod­i.er, such as title and a.liation 
of the speaker (e.g. given said Microsoft chairman Bill Gates ... , we rec­ognize Bill Gates as the speaker, 
with Microsoft and chairman as the modi.ers) Verb: quotation verb. In addition, we store the preposi­tional 
modi.ers of the verb. The modi.ers usually provide context of the quote being made (e.g. given said Bill 
Gates in the Microsoft shareholder meeting in Seattle , the modi.ers are in Seattle and in the Microsoft 
shareholder meeting ) Quote: actualquote withinthebeginning and endingquo­tation marks. Note that a quote 
could span multiple sentences. We searchfor startingand endingquotation marks from the neighboring sentences, 
and determine the proper quote boundaries. Then, we store all the segments of the same quote here. In 
addition, we associate each triple with metadata tags fromthedocumentitself,i.e. URL,title,author,publication 
date, etc.  3.2 Indexing Each extracted quotation and attribution is stored as a triplein ourinvertedindex 
structure of subject-action-object triples (See Figure 3). For the underlying information re­trieval 
capability, we use atypicalVectorSpaceModel(VSM) based system, i.e. Apache Lucene7 . By indexing syntactic 
and semantic annotations of textdata using such akeyword search engine, we are able to provide a highly 
scalable, fast semantic seach capability[6]. In Lucene s index, each docu­ment contains one or more named 
.elds. Each .eld corre­sponds to a piece of data that is either queried against or retrieved from the 
index during search[2]. In our case, each triple is treated as a document, while the elements of the 
triple are represented as .elds. Subject .eld: store the speaker entity name, the en­tity s ID, and 
the entity s facets.  Subject-modi.er .eld: store modi.ers of the speaker  Action .eld: store the verb 
  7 http://lucene.apache.org Action-modi.er .eld: store context modi.ers of the quotation, with entities 
marked up.  Object .eld: store the actual quote, marked up with the entities recognized in the quote. 
 Duringprocessingofdocuments, weindex the subject-action­object relations extracted from all the sentences, 
not just from quotes. The quotation triples are distinguished from othertriplesby a .agisQuotation. During 
search, onlyquo­tation triples will be retrieved when the isQuotation .ag is set in the query. Figure 
3: Subject-action-object triples For entitiesidenti.edbothwithin and outside ofthequote, we index not 
only the entity names, but also their unique identi.ers and assigned categories (i.e. facets). Therefore, 
during search, we support search for quotes by or about en­tities by their names, as well as by their 
IDs or categories (i.e. .nd quotes made by any college football coach, or .nd quotes about any hybrid 
cars). Thesubject-modi.er .eldwould support searchforquotes made by speakers of certain properties, e.g. 
Did anyone from Microsoft say anything about iPhone? Similarly, the action-modi.er .eld supports searching 
for quotes within a particular context, e.g. What did Obama say about global warming during his trip 
to China? . Example 1: Nash said, I would love to meet him, obviously, and to play hoops with the President 
would be kind of fun. This quote is made by Steve Nash, an NBA basketball player, about President Obama. 
We are able to link Nash to his full name appearing earlier in the text. Through coreference resolution, 
we recognize him and the presi­dent refertoPresidentObama. Weassignfacet[basketball player] to Steve 
Nash. Therefore, when user queries about any comments madeby anybasketballplayers(orany sports athletes) 
regarding President Obama, this quote would be returned as one of the results. Speaker .eld Entity name 
= Steve Nash Entity ID = 0x49c26 Facet =[Basketballplayer] Action Verb = said, isQuotation Quote Keywords: 
love, meet, Barack Obama, obviously, play, hoops, president, fun Entity 1: Name = Barack Obama ID = 0x49c26 
Facets = [Politician],[Countryleader] Example 2: They might think they ve got a pretty good jump shot 
or a pretty good .ow, but our kids can t all aspiretobe LeBronor LilWayne, Obama said. We recognize 
LeBron as LeBron James, the NBA bas­ketball player, and Lil Wayne as a musician. The pro­noun they islinked 
to children intheprevioussentence. When users search for Obama s quotes regarding any bas­ketball player 
or musician, this quote would be returned. Speaker Entity Name = Barack Obama Entity ID = 0x16f69 Facets 
= [Politician],[CountryLeader] Action Verb = said, isQuotation Quotation Keywords: children, think, get, 
pretty, good, jumpshot, .ow,kids,aspire, LeBronJames, LilWayne Entity 1: Entity Name = LeBron James Entity 
ID = 0x49c85 Facet =[Basketballplayer] Entity 2: Name = Lil Wayne ID = 0x15393 Facet =[Musician] 3.3 
Search This section describes the retrieval of the indexed quotes and presentation of the results. 3.3.1 
Query Thissystemallowsuserstosearchforquotationsin many di.erentways,by specifyingquotesby certain speakers 
and/or about certain topics, as well as the categories (facets) of speakersand topics. Theparameter<speaker> 
canbe spec­i.ed as: an entity, by its unique identi.er or simply its name  a facet, e.g. [football 
player]  or unspeci.ed, i.e. quotes by any person Furthermore, the speaker .eld can be constrained 
by some modi.ers, e.g. What did any [Football player] from the University of Notre Dame say? where Notre 
Dame is the modi.er. The <about> parameter can be speci.ed as: an entity, by its unique identi.er or 
name  an entity facet, e.g. [movies],[hybridcars]  any keywords  or unspeci.ed, i.e. quotes about 
anything We also support Boolean combinations (i.e. AND, OR) of multiple topics. For example: Speaker=Obama;Quote=ChinaAND 
global warm­ing Speaker = PeytonManning;Quote = [footballteam] OR[football coach]  Speaker = [actor];Quote 
=OscarsAND any[movie]  Thetargeted entity does nothavetobeinthequote. For example,thequotefromBillGates: 
Oh myGod,Microsoft didn t aim high enough. was about iPhone. We support search of such quotes by allowing 
the target entity as either within the quote boundary or as a context modi.er. Speaker =BillGates;(Quote 
=iPhone)OR(Modi.er = iPhone)  3.3.2 Result Presentation For a given query, the result returned is a 
ranked list of quotation objects, each containing the following informa­tion: actual quote; the starting 
and ending positions of the quote are marked;  quote attribution -speaker name and its modi.ers;  context 
-surrounding text outside the quote;  document metadata, i.e. URL, document title, publi­cation date, 
publisher name, the top entities we iden­ti.ed in the document text, etc.  Sometimes, the quote is very 
long such that we need to extract a snippet of a speci.ed length that best matches thequery request. 
Duringprocessing andindexing, wehave identi.ed the entities in each sentence, as well as their po­sitions 
within the sentence. Given a query request on a particular subject(speci.ed asentity orkeyword),wedeter­mine 
the snippet that has most occurrences of the subject entity/keyword. 3.3.3 Result Aggregation and Ranking 
Sometimes, what wassaidby aspeakercouldbequotedin multipledi.erent articles. Whenretrievingquotes,weapply 
an aggregation process to detect duplicate quotes by com­puting the similarity distance between each 
pair of quotes. The quotes are then ranked by a combination of the fol­lowing factors: 1. Matching score 
between query and indexed quotes; 2. Publication date. We prefer quotes with fresher date; 3. Number 
of duplicates. Usually, interesting or signi.­cant quotes are repeated more often; 4. Credibility of 
thesource,i.e. articlesfrom majornews­papers have higher credibility than less known blogs.  Users can 
choose to sort the results by their default rank or purely by date.   4. CONCLUSIONS AND FUTURE WORK 
We demonstrated adapting the standard IR technologies (i.e. keyword queries matched against bag-of-words 
docu­ment representation) to semantically tagged natural text. By indexing the annotated quotations, 
we enable users to search for quotes made by a particular person or a category of speakers. Userscanalso 
searchforquotesabout anentity or a category of entities. Wehave madeAPIspubliclyavailableforquerying 
over10 million quotes extracted from news feeds of recent months. In addition, eachdaywe add around60thousand 
newquotes extracted from around 50 thousand news articles or blogs. Based on our test on a set of 150,000 
randomly sampled en­tities, the uncached query execution time has an average of 109 milliseconds with 
median at 54 milliseconds. Note that the queries are executed against an index that contains not only 
quotes, but all relationships extracted from every arti­cle text. The indexed document size is close 
to half billion. Asfuture work, we willinvestigate the relevance re-ranking of the retrieve quotes, aiming 
for surfacing more timely and authoritativequotes about agiventopic, as well asthe nov­elty and diversity 
of the results. In addition, during index­ing, we could identify the most important and interesting quote 
to highlight for each article -automatically selecting the so called pull quotes. Finally, we will explore 
applying sentiment analysis8 or opinion mining [1] to the extracted quotations. 5. ACKNOWLEDGMENTS The 
authors wouldlike to thankAndySkaletforhisinitial implementation ofthepublicAPIs, andJonathanReichhold 
for his valuable suggestion on improving quote search per­formance. 6. REFERENCES <RefA>[1] A. Balahur, R. 
Steinberger, E. van der Goot, B. Pouliquen, and M. Kabadjov. Opinion mining on newspaper quotations. 
In 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, 
2009. [2] O. Gospodneti and E. Hatcher. Lucene in Action. Manning Publications, 2004. [3] J. Liang, 
K. Koperski, N. Dhillon, C. Tusk, and S. Bhatti. NLP-based Entity Recognition and Disambiguation. US 
Patent Application 20090144609, 2009. [4] J. Liang, K. Koperski, T. Nguyen, and G. Marchisio. Extracting 
statistical data frames from text. ACM SIGKDD Explorations, 7(1):67 75, June 2005. [5] G. Marchisio, 
N. Dhillon, C. Tusk, K. Koperski, J. Liang, T. Nguyen, D. White, and L. Pochman. A case study in natural 
language based web search. In Natural Language Processing and Text Mining. Springer-Verlag, 2006. [6] 
G. Marchisio, K. Koperski, J. Liang, T. Nguyen, C. Tusk, N. Dhillon, L. Pochman, and M. Brown. Method 
and System for Extending Keyword Searching to Syntactically and Semantically Annotated Data. US Patent 
7,526,425, 2009. [7] B. Pouliquen, R. Steinberger, and C. Best. Automatic detection of quotations in 
multilingual news. In Proceedings of the International Conference Recent Advances in Natural Language 
Processing, RANLP 2007, 2007. 8 http://www.evri.com/developer/rest# API-GetSentimentInformation</RefA>  
			
