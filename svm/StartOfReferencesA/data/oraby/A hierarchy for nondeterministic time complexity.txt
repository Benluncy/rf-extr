
 A HIERARCHY FOR NONDETERMINISTIC TIME COMPLEXITY Stephen A. Cook University of Toronto Toronto, Canada 
 The purpose of this paper is to Restricted Turing Machines The argument prove the following result: 
 to follow is delicate enough that it is necessary to give an explicit definition Theorem 1 For any 
real numbers r I, r2, of the peculiar variation of Turing 1 ~ r I < r 2 , there is a set A of strings 
machine we will use. A restricted Turing machine is a nondeterministic Turing which has nondeterministic 
time complexity r 2 mach~ with two read/write tapes. One n but not nondeterministic time of these 
serves as both an input tape and r 1 work tape, and one as just a work tape. complexi~ n . e computing 
devices are non-Each tape alphabet consists of the three deterministic multitape Turing machines. symbols 
{B, I, 2} , where B is for blank. The input string is restricted Recently Ibarra [i] has proved to 
the alphabet {I, 2} . a similar result for nondeterministic tape complexities. His proof is based The 
machine operates under the on a lemma similar to the "Translational control of a program, which is a 
finite Lemma" stated below, together with sequence of instructions. Each instruc- Savitch's result [2] 
stating that a set tion is of one of the following types: of strings with nondeterministic L(n) - I) 
Print ~ i , where ~ ~ {i, 2, B} tape complexity has deterministic and i is 1 or 2 (referring to a tape). 
(L(n)) 2 tape complexity. Unfor-2) Shift di, where de{L,R} and iE{l,2}. tunately there is no known analog 
to 3) Goto Z if i ~ , where £ is a Savitch's theorem for time complexity positive integer, i e {i, 2} 
, and (except simulation results giving expo-E {B, I, 2} . nential time bounds), so our theorem 2 4) 
Copy x , where x is a string below is necessary to serve as a sub- on (i, 2} stitute. The main work in 
the present The first two instruction types cause the paper is in the proof of theorem 2. tape heads 
to print or shift left or right in the usual fashion. Instruction Notation Let LN(T(n)) be the class 
 type 3) causes control to be transferred of sets of nondeterministic time com-to the instruction with 
label £ , pro- plexity T(n). vided tape head i is scanning symbol o. (Normally control is transferred 
to the For the purpose of the following next instruction.) We will place the lemma, a function f(n) 
is real time restriction that no single label £ can countable iff there is some d~rmi~fstic appear 
in more than two Goto instructions. multitape Turing machine which for all n, The fourth instruction 
type will be used with an input string of length n will in the definition of g(x) in the proof halt 
within f(n) steps with a string of theorem 2. See also the explanation of length f(n) on its output 
tape. before lemma 2. The effect of copy x is for the first head to write the string Translational 
Lemma Let Tl(n) z n, x Space to the left of the square it currently scans; where Space is a certain 
 T2(n ) ~ n, f(n) ~ n be nondecreasing four digit code. Thus if just before functions on the positive 
integers such execution of Copy x head 1 is scanning that f(n) is real-time countable. If the left end 
of a string y , then after LN(Ti(n)) = LN(T2(n)) , then LN(Ti(f(n)) execution head 1 will scan the left 
end of x Space y. = LN(Tz(f(n)) ) Programs for restricted Turing machines will be coded as strings on 
 Proof Sketch Suppose A E LN(T2(f(n))) , {i, 2} To this end we assume a distinct but A ~ LN(Wl(f(n))) 
four digit string on {i, 2} has been assigned to each of the following iI Let c be a symbol not occurring 
symbols: Print, Shift, Goto, Cod Space, in any of the strings of A , and let Label, i, 2, B, L, R. We 
let Print be A' = {xc£11xcZ l = f(Ixl) and x e A} the 4-digit code for Print, ~l-~ be the (Here Ixl 
is the length of x ). 4-digit code for Shift, etc. Each instruc-Then A' s LN(T2(n) ) , but tion (except 
Copy x) receives a code con- sisting of the concatenation of two or A' # LN(Ti(n)) three of these 4-digit 
string~._ Thus Print ~ i is coded Pr~ ~ i and The Translational Lemma appeared Goto £ if i ~ is coded 
Goto £ i a in different forms in [I] and [3]. where [ is dl~2 .... dk ' and dl...d k is the dyadic 
encading for the integer ~. To label an instruction I with the integer ~ , we r~de the code for I with 
the string Label £ . Since restricted Turing machines are nondeterministic, two instructions in a program 
can have the same label. However, we will not allow more than two instructions to have the same label. 
 ___The instruction Copy__x is coded o~ rxf Space x , where Ixl is the code for the length of x ; and 
~ has length about 4 log 2 Ixl Notice that the string x itself is not coded, but presented "straight". 
The reason for including ~ is so that a machine try- ing to copy the string x will know when x ends 
and the next instruction begins. The code for a program consists of the concatenation of the codes for 
its instructions(suitably labelled). It is easy to check that the program can be unambiguously recovered 
from its code. Notation M R denotes the restricted X Turing machine with code x . A machine M R accepts 
a non- X empty input string y on {i, 2} iff there is a computation in which initially y appears on 
tape 1 (surrounded by B's) with the input head scanning the left- most symbol of y and tape 2 is blank, 
 and the computation eventually halts in an accepting state. (The first instruc- tion of the program 
is the first instruc- tion executed in the computation). If T(n) is a function on the positive in- 
 tegers and A is a set of strings on {i, 2} we say M R accepts A with ' X run time bound T(n) iff 
for each string y on {177--, if y ~ A then M R accepts y in some computation with X at most T(Iyl) 
steps, and if y ~ A then M R does not accept y . Note: x For the purpose of timing, the instruc- tion 
Copy x requires Ix] steps for exe- cution. The following lemma is a conse- quence of the methods of 
Hennie and Stearns [4]. We note that there is no constant "speed-up" for restricted Tur- ing machines 
because of the limited tape alphabet. Lemma 1 If a set A of strings over is accepted within time T(n) 
by some nondeterministic multitape Tur- ing machine, then A is accepted in time [cr(n) log T(n)] on a 
restricted Turing machine, for some constant c . Notation L~(T(n)) is the class of sets accepted within 
time T(n) on a restricted Turing machine. -188- Theorem 2 For all integer constants Co, k ~ 1 there 
is a set A of strings over {i, 2} such that A s L N(n 3k) but R A ~ LN(c0nk ) Corollary For all integer 
constants k _> 1 L N(n k) ~ L N(n 6k) Proof Let A be as in theorem 2, ~--the k of theorem 2 equal to 
twice the present k and c O = 2. Thus A c LN(n 6k) " nIf A e LN(nk) , then by lemma 1 A E L~([cnklog 
n]). But then R 2k A e LN(2n ) , since a restricted Turing machine can be programmed to recognize short 
strings fast using "table look-up". This contradicts theorem 2. Proof of theorem 1 We use the above 
 corollary and the Translational Lemma, with the technique of Ibarra [i]. Let r I, r 2 be as in theorem 
i, and let a,b,c,d be positive integers such that a c 1 -< r I -< ~< ~-< r 2 Suppose the theorem 
is false for rl,r 2 , so that LN([na/b]) = LN([nC/d]) By the translational lemm~, for each k ~ 1 , 
setting f(n) = n , (*) LN([nka/b]) = LN([nkC/d]) By letting k take on successive integer values between 
bd(ad) and 6bd(ad) in- clusive, and noting ad < bc , we form a chain of equalities from (*) which 
shows 2 (n6bC (ad) LN(n(ad) ) = L N ) Since ad < bc , this violates the corollary. Proof of theorem 
2 For the lemma below, the pair (x,y) will be coded by x Space y , which is a string on {i, 2}. We 
note that if we assume the string x codes a restricted Turing machine, then the beginning of the string 
y can be uniquely determined in the string x Space y. Lemma 2 Let k be a positive integer. er~sT a "universal" 
nondeterministic multitape Turing machine M which always 3k halts within time n and for all strings 
x and y on {I, 2} and all positive constants c , if lyl k -M~ either fails > clx I and to accept y 
or accepts y within time cly[ 2k , then M accepts the coded pair (x,y) iff M R accepts y . X Proof 
It will be convenient to assume t input tape M has two read/ a~the of write heads, which initially 
scan the left-most symbol of the input x Space y. It is clear from the main result in [5] that this will 
not increase the comput- ing power over that of a multitap~ Machines with one head per tape. One of these 
two heads operates on the input string in conjunction with several work tapes to form a "clock" which 
shuts M off in 3k exactly n steps no matter what else happens (here n is the length of the input). 
The second head initially copies x onto the "x-tape" in com- pressed form, and then moves to the beginning 
of y . Thereafter this head simulates the input head of M R , using a second "channel" of M so a~ not 
to destroy the input string x ~pace y. The machine M proceeds to simulate M R step by step by referring 
 X to the compressed form of x . It is clear that this can be done with a "simulation factor" of about 
Ixl , so that t steps of M R are simulated in X about Ixl.t + 4 steps (the 4 accounts for the time 
to read Sp~). Hence if lY[ e cIxl and M R accepts y within" X clyl 2k steps, then M will complete the 
simulation within T steps, where T~ lx[cIyI 2k +4 ~ ([ylk/c).clyl 2k +4 - < lyl 3k +4 < n 3k where 
n = Ixl + 4 + lyl Thus the simulation will be completed by the time M halts. Now suppose theorem 2 
is false. We then have constants c O , k so (1) LN(n3k ) ~ L~(c0nk ) . Thus there is a restricted Turing 
machine M R with code w 0 which has w 0 k run time at most COn and accepts the same set of coded pairs 
(x,y) as the machine M of lemma 2. We will use w 0 to define a function w = f(x,d) whose value w codes 
a vastly speeded up version of M R . To this end we first x define the following functions, which map 
strings on {I, 2} into strings on {1, 2} : A) g(x) = Copy ~T~pace x w 0 . Thus if x codes a machine 
M R and X w = g(x) then M R on input y will ' W first change the input to x Space y and then proceed 
to simulate the univer- sal machine M R as if the latter had w 0 as input the coded pair (x,y) But M 
R on (x,y) does a rapid simulation w 0 of M R on input y for suitable x,y . X In sum M R g(x) simulates 
MRx at a more rapid rate, for suitable x and y . B) hl(X) = WlX' , where x' is a modification of x 
, and w I is the code for a restricted program W 1 which on an input of the form y21 k causes the 
trailing string 21 k to be erased, so that the result is yB k+l with the in- put head again scanning 
the left-most symbol of y (and tape 2 blank). If x codes a program X , then x' codes a modified version 
X' of X in which the labels have been changed to be dis- tinct from those in W 1 , but as small as 
possible. The program W 1 is arranged so that in WiX' , control will be trans- ferred to the first 
instruction in X' after W 1 is executed. C) h2(x) = w2x' where w 2 codes a program W 2 which transforms 
an in- put y into the string y21 k , where k = I~1 z -1 if lyl > i and ~ = ; 1~$ lyl = 1 . Other conven- 
tions for W 2 and x' are as in B) above. D) f(x,d) is a function of two arguments: a string x and a 
positive integer d It is defined recursively as follows: f(x,1) g(x) = f(x,d+l) = g(h2(f(hl(X),d)) 
) . The reason for including the unusual instruction Copy x is so that Lemma 3 below will hold. If g(x) 
were defined to be a code with the same effect as its present value but using convention-al instruction 
types instead of Copy x , then the length of g(x) would be several times the length of x . Thus the length 
of f(x,d) would be exponential in d . This would make the time necessary for its evaluation too great. 
Lemma 3 There are constants K 1 , K 2 such that for all d ~ 1 and all strings x of length at least 2 
, (2) [f(x,d) I ~ IxI + Kld log Ix] + K2d2 Proof First we. note that there are con- stants C I , C 
2 , C 3 such that if Ixl e 2 , then  (3) Ig(x)I ~ Ixl + c I log Ixl (4) Ihl(X)] ~ Ix] + c 2 log Ixl 
 (s) Ih2(x) I ~ Ixl + c 3 log Ix[  The first inequality is immediate from the definition of g(x) , and 
the second two follow from the definitions of hl(X ) and h2(x ) by recalling that in our definition 
of restricted Turing machine a given lable ~ can ap- pear at most four times anywhere in a given program, 
so that x' cannot be much longer than x . Next wenote that given any positive constant D there is a 
con- stant D 1 so for all Ixl ~ 2  (6) log(Ixl + D log Ixl) log Ixl * D 1 If we set gl(x) = g(h2(x)) 
, then from (3), (5), and (6) there is a constant C so  (7) Igl(xJl ~ lxl + c log Ixl Also, from the 
recursive defini- tion of f(x,d) we have (8) f(x,d+l) = gl(f(hl(X),d)) We now prove the inequality (2) 
in lemma 3 by induction on d . For d=l , (2) follows from the definition of f(x,l) and (3). For the induc- 
tion step, we have by (7) and (8) (9) I f(x,d+l) I = I f(hl(X),d)l + C log lf(hl(X),d)] By (4) and 
(6) and the induction hypothesis (2) we have for some con- stant D 1 (10) If(hl(X),d)] Ixl + Cz21oglxl 
+ Kld(log Ixl + m 1) + Kzd We estimate log ]f(hl(X),d)l by using (i0) and the inequality log (al+a2+a3+ 
 a4) ~ log (ala2a3a4) g log a I + log a 2 log a 3 + log a 4 , valid at least for the constants a i 
~ 2 Using this estimate we have by (9) and (i0), for sufficiently large K 1 , K 2  (11) If(x,d+l)l 
~ [xl + Kl(d+l) log Ix I + K2(d+l)2 This completes the induction step and the proof of lemma 3. Lemma 
4 The c O , k be as in inclu- sion (i). Then for all sufficiently large constants c (independent of 
x,d) and all positive integers d and all sufficiently long program codes x , if R M x has a run tlme 
at most clyl k2d on an input string y , where Iyl c]f(x,d)| , then R i) Mf(x,d) has a run time on 
input y of at most 4 c01YI k , and R ii) Mf(x,d) accepts y iff MRx accepts y . Proof According to 
the definition of w 0 (given before the definition of g(x)) the machine M R on an input w 0 string 
z pa~y has run time at most c0(Iz I + 4 + lyl) k Hence the machine M R g(z) has, on input y , run 
time at most Izl + c o (Izl + 4 + lyl) k Now by the assumption in lemma 4, IYl c If(x,d) I , and since 
by definition of f, f(x,d) = g(z) for some z with Izl ~ If(x,d) l ~ lyl, we conclude R Mf(x,d) has 
run time at most 4c 0 lyl k , for IYl z 4. This proves i). We prove ii) by induction on d . For d = 
1 , f(x,d) = g(x), so ii) follows from lemma 2 and the definitions of w 0 and g(x) For the induction 
step, we assume M R has a run time at most clyI kZd+l x and IYl ~ clf(x,d+l)I . We recall f(x,d+l) 
= g(h2(f(hl(X),d))) Table indicates input strings and run times for machines M R for various z rele- 
 z rant to this equation, assuming that M~(x,d+l) has input y . (See Table 1 on next page) The run 
time bound for line 1 from the assumptions for lemma 4. For line 2, the run time for M R with input 
 hl(X) y21 ~ is the sum of the run time of M R with input y21~ (namely d0IYl 2 w 1 for some constant 
d O ) and the run time for M R with input y (namely x cly]k2d+l). For line 3, the run time bound follows 
from part i) of lemma 4. The hypotheses for the lemma can be verified with c of the lemma taken as c+d 
0 R Since the input to Mf(hl(X),d) has length lyl 2 , we need to verify that ~ has a run time at 
most  H 1(x)  Program code z Input string for M R Run time bound for given input Z X Y c]ylk2d+l 
hl(X) y21 ~, z=lyl 2 -lyl- 1 (c+do) ]yl k2d+l , some const, d o f(hl (x) ,d) y zl~, e=lyl z -lyl- 1 4c 
0 ryl 2k h 2 (f(h l(x) ,d)) Y (4c 0 + d I) lY 2k , some const, d I g(h2 (f(hl (x) ,d))) Y 4% lyl k TABLE 
I: For each line, M R z accepts the indicated input iff MR X accepts y . (c+d0)([y[2)k2d (which follows 
from line 2 of the Table), and lyl z -> (c+d 0)[f(hl(x),d) [ (which follows for large [Yl from our assumption 
IY[ -> clf(x,d+l)[). We also note that since the hypotheses of lemma 4 are satisfied, we can apply the 
induction hypothesis to conclude MfR(hl_(x),83 accepts y21 £ iff M R h l(x) accepts y21 ~  For line 
4, we note that the run time for M R with input y is hz(z) bounded by the sum of the run time of M R 
 w2 with input y (namely dlIY 12 for some constant dl) and the run time for M R Z with input y21 ~, 
~=lyI2-1yI-I (in this case, the bound is given in line 3). We can now verify that if w = f(x,d+l) = g(h2(f(hl(X),d)) 
) , then M R accepts y iff M R accepts y . W X It is clear from the above argument and from the definitions 
of hi(x ) and h2(x) that for each of the first four lines of Table I, the machine M R z R accepts 
the indicated input iff M x accepts y . Now if we take x in lemma 2 to be h2(f(hl(X),d)) and c and 
y of lemma 2 to have their present values, then by line 4, the hypotheses of lemma 2 are satisfied, provided 
 c _> 4c 0 + d I . Hence by lemma 2, and the definitions of w 0 and the function g , we conclude M R 
 h 2(f(h l(x),d)) accepts y iff M R accepts y . Hence M R W X  accepts y iff M R accepts y . This 
W completes the proof of lemma 4. Lemma 5 The function f(x,d) can be computed by some restricted Turing 
machine (with input (x,d) suitably encoded) within time KdSlxI 2 , for some constant K . Proof The 
function f(x,d) is computed using a recursive subroutine based on its recursive defining equations. The 
number of calls to the subroutine is d The bound for the length of first argu- ment is the bound given 
by lemma 3 for If(x,d) l ; say K3d2Ix I It is not hard to see that the time spent at each level of the 
recursion can be bounded by a constant times the square of the length of the first argument; or K4d41xl 
2 Since there are d levels to the recursion, the lemma follows. Lemma 6 There is a constant K 0 such 
 that for all integers m ~ i and all program codes x , if M R has run time X  m bound n n , then there 
is a restricted Turing machine M R which correctly simu- w fates M R for all sufficiently long in- 
 X puts y ("sufficiently long" depends on m and x) and has run time at most K01Yl 2k Proof M R is 
designed so that on input first computes d according to the equation d =. [m log IYl] , and then computes 
x I = f(x,d) , and finally simulates M R on input y . For this x I  value of d it is easy to check 
that the hypotheses to lemma 4 are satisfied where we fix a value of c large enough for lemma 4 to hold, 
and provided [y[ is sufficiently large. That is,  lyllY] m c lyl k2d and, by lemma 3, lyl ~ c IfCx,d) 
l Thus M R has run time at most 4c0[YI k x 1 The simulation can be carried  out within time 4c0[y[2k 
, provided [Yl is, say, z [xl 2 . The time required to compute d and w = f(x,d) is, by lemma 5, small 
compared to this (for large [y[). Lerama 6 follows. A contradiction can be obtained from lemma 6 by 
diagonalization. We note that a restricted Turing machine with run time at most K01Y[ 2k can be simulated 
for long y be a deterministic restricted Turing machine with run time 2k at most n n Hence there is 
a deterministic restricted Turing machine 2k+l with run time at most n n which for every restricted 
Turing machine with run time at most K01Y[ 2k gives a different output for arbitrarily long inputs. 
Hence lemma 4 cannot possibly be true, so our assumption that Theorem 2 is false is untenable. 5. A. 
R. Meyer, A. L. Rosenberg, and P. C. Fischer. Multi-tape simulation of multi-head Tufa machines," I~E'Conference 
Record of 1967 Eighth Annual Symposium on Switching and Automata Theory, 117-27. References  <RefA>i. Oscar 
Ibarra. A Note concerning nondetermini~t~c tag complexities. Submitted to the J.A.C.M. 2. Walter Savitch. 
Relationships between nondeterministic and deterministic ~s~ complexitles. J. Computer and em Sciences 
4, pp 177-92 (1970). 3. S. Ruby and P. C. Fischer. Translational methods in ~omputational comp~i~. 
1965 IEEE Conference Record on Switching, Circuit Theory, and Logical Design -Sixth Annual Symposium, 
pp. 173-78.  4. F. C. Hennie and R. E. Stearns. Two-tape simulation of multi-tape Turing machines. J.~.C.M. 
13, </RefA>  
			
