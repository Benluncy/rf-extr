
 An Adversarial Model for Distributed Dynamic Load Balancing S. Mu thukrishnan* Rajmohan Rajaraman+ 
Abstract 1 Introduction We study the problem of balancing the load on pro- cessors of an arbitrary network. 
If jobs arrive or depart during the process of load balancing, we have the dynamic load balancing problem; 
other-wise, we have the static load balancing problem. While static load balancing on arbitrary and spe-cial 
networks has been well studied, very little is known about dynamic load balancing. The diffi-culty lies 
in modeling the arrivals and departures of jobs in a clean manner. In this paper, we initiate the study 
of dynamic load balancing by modeling job traffic using an ad-versary. Our main result is that a simple, 
local control distributed load balancing algorithm main-tains the load of the network within a stable 
level against this powerful adversary. Our results hold for different models of traffic patterns and 
proces-sor communication. ?nformation Sciences Center, Bell Labs. Email: muthuQresearch.bell-labs.com. 
DIMACS Center, Rutgers University, Piscataway, NJ 08854-8818. Email: rrajadimacs .rutgers .edu. DI-MACS 
is an NSF Science and Technology Center, funded un-der contract STC-91-19999 and partially supported 
by the New Jersey Commission on Science and Technology. Part of this work was done when the author was 
at the University of Texas at Austin, with support from the National Science Foundation under Grant No. 
CCR-9504145. Pemkion to make digital or herd copies of all or pert ofthis work for personal or classroom 
use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or 
a fee. SPAA 98 Puctto Vallarta Mexico Copyright ACM 1998 Q-89791-989-Q/981 6...$5.00 An important problem 
in a distributed system is to balance the total workload among the various pro-cessors of the underlying 
system. Such load bal-ancing problems arise in a number of parallel and distributed applications including 
job scheduling in operating systems (e.g., see [29]), packet routing (e.g., see [23]), parallel finite 
element methods (e.g., see [lo]); other applications can be found in [27]. Load balancing problems can 
be classified into two categories: static and dynamic. In static load balancing, the total workload is 
available at the start of the computation, and no new load is added to the system. The main objec-tive 
is to distribute the total load amongst the pro-cessors before initiating the computation such that the 
assignment of tasks to processors is balanced. Parallel computations such as large-scale partial diferential 
equations and finite element methods rely on static load balancing. In these applica-tions, the given 
computation can be divided into a large number of small computational tasks that are distributed among 
the processors (for example, see [lo, 291). A no th er important application of static load balancing 
arises in certain packet rout-ing problems, where the initial distribution of pack- ets may be irregular. 
Routing is performed by first redistributing the packets among the processors in a balanced manner, and 
then invoking standard routing techniques such as permutation routing or L-L-routing [23]. Much of the 
extensive literature that is, the total workload may vary with time . on distributed load balancing in 
fact study static load balancing. In dynamic load balancing, the load is dynamic, Dynamic load balancing 
is required in a wide variety of applications, including operating sys- tems [ll, 191, combinatorial 
optimization prob- lems [18], and adaptive mesh partitioning [15, 291. The results and techniques of 
static load balanc- ing are applicable for certain problems in which the computation can be divided into 
alternating phases of balancing and processing. For most ap- plications, however, it is desired to have 
a contin- uous process that manages the distribution of load among nodes. For example, while scheduling 
jobs in a distributed network, the particular sequence of job arrivals is not available in advance, and 
hence, the assignment of jobs to processors has to be per- formed on-line. Similarly, in many parallel 
mesh computations, the mesh regions are continuously refined, or coarsened, thereby modifying the num-ber 
of mesh points (and hence the load) in differ-ent mesh regions (for a more elaborate description, see 
[29]). Due to the potentially arbitrary nature of the on-line load arrival and departure process, dy-namic 
load balancing is substantially more chal-lenging than the static version. In order to make the study 
of dynamic load balancing somewhat tractable, most of the previous work has assumed either a particular 
statistical model of load vari-ation or a specific network topology (for example, see [20, 281). In this 
paper, we initiate an adwersar-ial study of dynamic load balancing for arbitrary network topologies. 
Our Results. We model a distributed system by an arbitrary network (graph) in which the nodes represent 
the processors and the edges rep- resent the communication links. We assume that the load consists of 
independent tokens that may be processed anywhere. We adopt the standard multi-port, unit capacity model 
of communica-tion [3, 13, 21, 241, whereby each node can send or receive at most one token along each 
of its inci- While we have used the terms static and dynamic as a property of the load, some papers in 
the load balancing literature use the term as a property of the algorithm. These papers, (e.g., [28]) 
define a static load balancing algorithm (resp., dynamic load balancing algorithm) to be an algorithm 
in which the decisions of transferring load does not depend (resp., may depend) on the current system 
state. dent links. An important issue arises in this formulation: how do we best model the load variation 
process? In our model, the arrival and departure of load is controlled by an adversary that determines 
the lo-cations and the number of tokens that are added or deleted at any time. Our framework for the 
adver-sary is motivated by previous work on adversarial models for packet routing [5, 91. In such an 
envi-ronment, a natural objective is to maintain a low imbalance in the load distribution at all times. 
We characterize this objective by the requirement that the maximum imbalance in load be bounded at all 
times. We refer to an algorithm that satisfies the preceding objective as a stable algorithm. Clearly, 
some restrictions need to be placed on the adversary to disallow scenarios in which an un- bounded amount 
of imbalance may be trivially cre-ated by adding, for example, a large number of tokens at a single node. 
Therefore, given any sub-set S of nodes, we place an upper bound on the amount of imbalance that an adversary 
can create within S; the particular upper bound depends on the expansion of set 5 . See Section 2 for 
a formal deflnition of our adversary; as we argue there, this adversary is more powerful than alternate, 
natu- ral formulations of an adversary. We think of this clean formulation of a powerful adversary as 
one of our contributions here. Our main technical contribution is a proof that a simple local control 
algorithm is stable under our adversarial model. Each step of the algorithm is simply the following (here, 
d is the degree of the underlying graph): For each edge (u, v), if u has at least 2d + 1 tokens more 
than V, then u sends a token to V. We refer to this algorithm as the local balancing algorithm. To prove 
the stability of the local balancing algorithm, we define an ap-propriate potential function and argue 
that if the potential at the start of a step is above a certain threshold then the increase in the potential 
due to the adversary (namely, adding and removing to-kens), denoted A, is no larger than the decrease 
in the potential, say B, obtained by running one step of the local balancing algorithm. Our anal-ysis 
relies on partitioning the nodes of the graph into groups based on the tokens they have, and then identifying 
the strategy for the adversary to change the token distribution amongst the groups so as to minimize 
B -A. Our results also extend to other models that take into consideration bursty traffic or a single-port 
mode of communication. Related Work. Static load balancing has been studied extensively for the arbitrary 
network model [3, 13, 21, 241. Here the question is how quickly can the imbalance be reduced to a small 
quantity. The local algorithm we described above was proposed in this context [3], and it is known to 
take asymptotically optimal number of steps to balance the load [13]. Our model and our results on stability 
for arbi-trary networks are in the same spirit as previous work on adversarial models for a different 
prob-lem, namely packet routing [5, 91. Also related is the work of Awerbuch, Kutten, and Peleg who introduce 
a novel extension of competitive anal-ysis for dynamic job scheduling in arbitrary net-works [6]. They 
develop a distributed algorithm whose competitive ratio is polylogarithmic in the size of the network. 
Their results are not appli-cable in our model, however, because their model places no bound on the amount 
of information or load that can be sent along any edge at any time. In addition, their work involves 
certain non-local operations that are inefficient in our model. (See [4, 12, 251 for more work on this 
problem.) Another result that considers the unbounded ca-pacity model is the important work of Awerbuch 
and Leighton [8, 71 on multi-commodity flows. The unbounded versus unit capacity assumption on the model 
of communication makes for a big difference in the flavor of the problems. For instance, cut ca-pacity 
provides an upper bound on the number of tokens (amount of flow) that any algorithm may remove from a 
vertex set (in any given step) in the unit capacity case, while this does not apply in the unbounded 
edge capacity case. Another difference between [8, 71 and our work is that in their work, only a fixed 
number of tokens may be injected at a fixed set of nodes (sources) in each step; in con-trast, the bulk 
of our difficulty in analysis comes from coping with a clever adversary that may dis-tribute tokens amongst 
any subset of nodes in each step.. A common theme that our work shares with [7,8] and a growing body 
of work including [3, 13, 141 is that a number of basic network problems admit efficient solutions in 
the form of local control algo-rithms. Several practical systems employ the local balancing algorithm 
to balance load. See [22] for an excellent survey and [l, 21 for a bibliography of such systems. 2 Our 
Model We represent the network by a graph G = (V, E), where V is the set of nodes and E is the set of 
bidirectional links. The network load is mod-eled by tokens, each of which may be processed at any node 
of the network. In order to balance the load distribution, tokens may be communicated among different 
nodes. We adopt the standard synchronous multi-port model for this communi-cation [3, 13, 21, 241: in 
each step, each node can send or receive at most one token along each of its incident links. In order 
to study the dynamic aspect of load bal-ancing, we introduce an adversarial model. In this model, tokens 
are created and/or destroyed at the various nodes in each step, and an adversary de-cides the number 
and location of these tokens. The goal of the balancing algorithm is to keep the im-balance as small 
as possible at all time. Before formally defining the adversary, we need some additional notation. Let 
IU~(V) denote the number of tokens at node v at the start of step t. For any subset S of V, let wt(S) 
denote the total number of tokens in S at the start of step t. Let the average number of tokens (wt(V)/IVI) 
at the start of step t be denoted by at. We define the imbulunce of G at the start of step t to be max{]Wt(v) 
-atI : v E V}. The Adversary. We divide each step into two phases. In the fbst phase, one step of the 
balanc-ing algorithm is executed. In the second phase of each step, an adversary inserts and deletes 
tokens from the network. Let e(S) denote the number of edges coming out of a set S of nodes. Let dt( 
S) denote the net increase in the number of tokens at nodes in set S in the second phase of step t. (Note 
that d,(S) may be negative.) An adversary with rate r, where 0 < r < 1, can insert and delete any number 
of tokens on any subset of nodes subject to the following constraint for every subset S of nodes: I&#38;(S) 
- (at+1 -at)lSlI I r - 4s) (1) Under this adversarial model, we seek stable bal-ancing algorithms, which 
are formally defined as follows. We say that an algorithm A is stable for rate r if there exists a A 
independent oft such that for all t 2 0, the imbalance of G with respect to A at the start of step t 
is at most A. In this paper, we restrict our attention to a study of stability and do not attempt to 
optimize the associated value of A. 3 The Power of the Adversary As formulated in Section 2, the rate 
of the adver-sary is required to be at most 1. This upper bound on the rate is necessary since a straightforward 
ar- gument based on edge-cuts shows that there is no stable load balancing algorithm for r > 1. In Sec-tion 
4, we show that the local balancing algorithm is stable for all T < 1, thus settling this problem for 
all values of r but r = 1. The particular formulation of the adversary is largely motivated by the need 
for a model un-der which strong performance guarantees for dy-namic load balancing can be proved. To 
illustrate this, consider replacing Equation 1 by the follow-ing more uniform constraint where a is the 
edge eqmnsion of the network: l&#38;(S) -(at+1 -~)lSll I r - CY * ISI (2) Again for r > 1, there can 
be no stable load bal-ancing algorithm because there exists a set S* such that e(S*) = oIS*I and the 
adversary would choose to add all the tokens to that set each step and en-sure that > crJS*J tokens must 
leave S* in each step. The adversary under Equation 1 is stronger than an adversary under Equation 2, 
however, since the upper bound on dt(S) in Equation 1 is dependent on the expansion of the particular 
set S rather than the expansion of the smallest expanding subset of G. Formally put, since e(S) 2 cr(S(, 
it follows that Equation 1 implies Equation 2. Another feature of Equation 1 is that the upper bound 
is placed on the increase in imbalance rather than the actual number of tokens that are added to or deleted 
from any set S. Consequently, there is no absolute upper (resp., lower) bound on the number of tokens 
that can be added (resp., deleted) by the adversary in any step. We finally note that since the deletion 
of tokens is controlled by the adver-sary, the model allows for realistic heterogeneous scenarios in 
which the load may consist of different kinds of jobs and the processors may have different processing 
speeds. 4 Stability of the local balancing algo- rithm Recall the local balancing algorithm. In step 
t of the edge balancing algorithm, each node u exe-cutes the following operation: for each edge (u, v), 
if Wt(u) -Wt(v) 2 2d-f 1, then u sends a token to v. This section is devoted to the proof of the following 
theorem. Theorem 1 For any E > 0, the local balancing algorithm is stable for rate 1 -E. To prove the 
stability of the local balancing algo-rithm, we take the standard approach. We define a quadratic potential 
function and argue that if the potential at the start of a step is above a cer- tain threshold then the 
increase in the potential due to the adversary (namely, adding and remov-ing tokens as per Equation l), 
is no larger than the decrease in the potential, obtained by running one step of the local balancing 
algorithm. We remark that in previous analyses of the local balancing al-gorithm [3, 13, 141, the expansion 
of the network was the only characteristic of the topology that was used. Therefore, the lower bounds 
that these anal-yses derive for the potential drop during a single step of the local balancing algorithm 
are limited by the least-expanding subset of the network. As a result, these lower bounds are too weak 
to establish stability against an adversary that has the freedom to overload any subset of nodes in the 
network. We now describe the potential function used in our analysis. At the start of step t, for each 
node v, we assign a potential $t(v) of ( ~lt(v) -~t)~. We de- fine the height h ( ) v f a node start 
t o v at the of step t to be (Wt(v) -at). Let +Bt denote the sum of the potentials of all of the nodes. 
Let Vt+ (resp., Vt-) denote the set of nodes with nonnegative (resp., negative) heights at the start 
of step t. Let %pt (resp., Cp,) denote the sum of the potentials of all of the nodes in Vt+ (resp., V,-). 
We note that 9t equals +,,+ t %c. Let W:(V) denote the number of tokens at v at the start of the adversarial 
phase of step t. Let &#38;(v) denote (w:(v) -Q)~. We prove the stability of the local balancing algo-rithm 
by placing time-independent upper bounds on both !$t and $,. The key step in our analysis is the following 
lemma. Lemma 4.1 If there exists a node with height at least 5n2d2/(2&#38;) at the start of step t, then 
+z+1 is at most $)tf. If there exists a node with height at most -5n2d2/(2c) at the start of step t, 
then apt+1 is at most at, Proof: We only prove the first claim of the lemma. The proof of the second 
claim is symm et- ric. It is useful to extend the notion of height to to-kens as well. For this purpose, 
we assign, for every node v, a unique rank from [l, wt(v)] to each token at v. Let the height of a token 
be its rank minus at. We note that for any node v with nonnegative height, &#38;(v) is the sum, over 
all the tokens z with positive height h(z), of the term 2h(z) -1. Assume that there exists a node with 
height at least 5n2d2/(2&#38;) at the start of step t. We divide Vt+ into distinct sets in the following 
way. For any i in N, if L&#38;j<;Sj is not equal to Vt+, then let S; denote the-minimal nonempty set 
of nodes such that for all u in S; and v in Vt+ \ Uo<j<;Sj, w(v) -UJ~(U) is at least 4d. Let Ic be the 
maximumvalue of i for which S; is defined. Since 5n2d2/(2c) > 4nd, k is positive. Let S>; denote Uj>;Sj. 
Let h; and 1; denote ma&#38;esi(wt(u) -at) and mi~esi(~t(u) -at), respectively. We first study the balancing 
phase. Consider a token z transferred from a node u in S; to a node 2) not in Si. Since a token never 
gains height, the edge (u,v) belongs to the cut (Szi, V \ S>i). In fact, (u,v) belongs to the cut (S>j,V 
\ S>j) for each j 5 i such that v is not in S,, (For ex-ample, if v is not in Vt+ = S>c, then (u,v) belongs 
to (Syj, V \ Szj) for all j < i.) A lower bound on the drop in the potential of the nodes in Vt+ as a 
result of the transfer of the token 2 is obtained by C(u,v)E(~>j,~\~>j)(ej-hj-l-2d). 'JJhus,formyi > 
0, the potential drop due to the cut (S>i, V \ S>i) -is at least 2e(S>i)(C; -hi-1 -2d). During the balancing 
phase, in addition to the potential drop, there may be a positive contribu-tion to the potential of the 
nodes with nonnegative heights by nodes from V \ V,f which gain tokens and achieve nonnegative height. 
Since each node gains at most d tokens, this positive contribution to the potential is at most nd2. Thus, 
we have the total potential drop in the balancing phase to be at least: -nd2 + C 2e(S~i)(C; -hi-1 -2d). 
(3) i>O Let us now consider the adversarial phase in which the potential may increase due to the tokens 
added by the adversary. The potential of any node v in V,+ at the start of step t + 1 is (Wt+r(v) - %+1> 
= ((4(u) -at) t (h(u) -(at+1 -at))) . Thus, the potential at the start of step t + 1 due to nodes in 
Vt+ is at most: c c d(u) + (dt(4 -(at+1 -4 i UESj t 2(4(4 -a&#38;&#38;(u) -(at+1 - a)) 5 (C(K(Si) t 
E 2hi(dt(u) -(%+I -at)))) i UESi + nd2. In addition to nodes in Vt+ that remain in Vt$l, there may be 
nodes that do not belong to Vt+ but belong to Vt$l. By Equation 1, the potential of any such node is 
at most d2. Thus, the total increase in potential in the adversarial phase is at most: 2nd2 + C 2hi(dt(Si) 
-(at+1 -at)lSil). (4) i It follows from Lemma 4.2 below that the right hand side of Equation 4 is maximized 
if the adver-sary adds as many tokens to SI, as the constraint in Equation 1 allows, then adds as many 
tokens to Sk-r as the constraint allows, and continues in this manner to add tokens to 5 i in the order 
of decreas- ing i. Lemma 4.2 thus implies that an upper bound on the increase in potential is obtained 
by making the following substitution in Equation 4 for all i in [k + 11: d,(S) -(at+1 -at)l%l = (I-&#38;)(4&#38;i) 
-e(G)). (5) Let (2 ) be defmed as follows: xz is PO and x;* is By Equations 3,4, and 5, we obtain that 
the net decrease in potential is at least: -3nd2 - c 2hi(l -E)(e(&#38;) -e(S>i)) i>O + c 2e(SLi)(b -k-1 
-2d) i>o ZZ -3nd2 -2h,-,(l - .z)e(SzO) + c 2e(&#38;)(&#38; -(1 -e)hi -&#38;hi-l -2d) i>O = -3nd2 -2h0(1 
-c)e(S>o) - c 2e(S>i)(hi -li) i>o + c 2e(S>i)(E(h -h-1) -2d) i>o 2 -3nd2 -4n2d2 + c 2e(S2i)(e(hi -hi-l) 
-2d) i>O 2 -3nd2 -4n2d2 + 2~(hk - 4nd) -2nd2 = -(4n2d2 + 5nd2 + 8end) + 2ehk L -5n2d2 + 2Ehk, for n sufficiently 
large. (In the first and second inequalities, we rearrange the summands. For the third inequality we 
note that: (i) h; -!; is at most 4nd for all d, and (ii) the total number of edges in the network is 
at most nd/2. For the fourth inequality, we note that: (i) e(S2;) is at least one for all i, (ii) e(S) 
is at most nd/2 for all S, and (iii) ho is at most 4nd.) Since there exists a node with height at least 
5n2d2/(2&#38;), hk is at least 5n2d2/(2&#38;). Hence, the net decrease in potential is nonnegative. n 
In the following lemma, we use the notation (CC) to denote a sequence 20, ~1,. . . , of reals. Lemma 
4.2 Let (cx) be a sequence of k nonin-creasing nonnegative reals. Let (,O) be a sequence of k nondecreasing 
reals. Then, an optimal solution to the linear program P: maximize c a;xi iE[k] subject to c x; 2 p;,for 
all j in [l, k), iEM is obtained when x0 is PO and 2; is p; --/I;-1 for all i in [l, k). Proof: Given 
any solution (y) to P and any i in [k], we say that i is good if Co<j<i yj equals ,&#38;. pi -pi-i for 
all i in [l, k). We note that (x*) is the unique solution that has k good indices. Given an optimal solution 
(z) to P that has fewer than k good indices, we construct a new optimal solution (2) that has more good 
indices than (z). This construction suffices to establish the lemma. Let ! be the largest index that 
is not good; thus, 1 is the largest index such that CoCjCL ,ri is less than pl. If C is k -1, then we 
set Z; ?o-zi for all j in [k -11 and zi-r to Pk.-i -CoCjCrc-r zj. We note that (2) is a feasible solution 
co P. Also, (2) is an optimal solution since ,2$-r > Zk-1 and ok-1 is nonnegative. Moreover, the number 
of good indices of (2) is one more than that of (z). If ! is less than k -1, then we set ,zi to ,rj for 
all j in [k] \ {!,! + 1). Let 6 denote the term &#38;, -We set Z: to y + 6 and zi+r to zl+r -6. c O<j<l 
zi* It follows that (2) is a feasible solution to P. Also, (2) is an optimal solution since: O!jZi = 
(ai -al+l)fi+ C aizi c Oji<k O<i<k where the last inequality holds since cyl > al+r. An index i in [k] 
\ {!} is good for solution (z) if and only if i is good for solution (z ). Moreover, e is a good index 
for (z ). Therefore, the number of good indices of (2) is one more than that of (2). This completes the 
proof of the desired claim. n Proof of Theorem 1: We now show that for all t, +t and @; are both at most 
n(5n2d2/(2c) + d)2. Let, if possible, t be the first step such that @)t+ is greater than n(5n2d2/(2e) 
+ d)2. Therefore, there exists at least one node v such that h,(v) is at least (5n2d2/(2&#38;) + d). 
Since the height of a node increases by at most d in the balancing phase and by at most d in the adversarial 
phase, we obtain that ht(v) _< ht-l(v)+2d for all v. Therefore, for all v in V, ht.-l(v) is at least 
5n2d2/(2c). This implies that by Lemma 4.1, a:-, is at least ipt, which contradicts our choice oft. A 
symmetric argument establishes that !Jt is at most n(5n2d2/(2e) + d)2. Hence, the imbalance at the start 
of any step t is at most Jn(5n2d2/(2E) + 2d)2, which is at most 3n5i2d2/c for n sufficiently large. 
This establishes the stability of the local balancing algorithm. n 5 Extensions We now present two variants 
of the adversarial model for which our results can be extended. In both cases, proving appropriate versions 
of Lemma 4.2 is the crux. Bursty Load. We can modify the model of Sec- tion 2 to account for bursty changes 
in the load. Instead of limiting the adversary by the constraint of Equation 1, we allow the adversary 
to add and delete token arbitrarily, subject to the constraint that for some fixed integer 20, the following 
inequal-ity is satisfied for all t and S: c I&#38;(S) -(at/+1 -at~>lSIl 5 T. w . e(s). (6) t--w<v<t In 
other words, while the ratio (dtt(S) -(up+1 -%wII/~e(s) need not be at most T for any given step t , 
the average of the ratio for any window of w steps must be at most T. Our definition for the bursty load 
pattern is based on the definitions of bursty packet traffic in [5, 261. Our analysis in Section 4 can 
be modified to show that the local balancing algoritbm is stable under bursty adver-saries as well. Single-port 
Communication. The model of Section 2 assumes multi-port communication; i.e., in each step each node 
can send and/or receive at most one token along each of its incident edges. A more suitable communication 
model for certain applications is the single-port model. In the single-port model, each node can send 
and/or receive a token along at most one of its incident edges. Since communication is typically assumed 
to be in hand- shaking mode, this implies that at any step, to-kens may only move along a set of edges 
that form a graph matching. The u&#38;port model has been studied in [lo, 14, 13, 16, 171. We define 
an adver-sarial model for the single-port model in much the same way as for the multi-port model except 
that Equation 1 is replaced by the following inequality. b&#38;(S) -(at+1 -at)lSlI < r -m(s), (7) where 
m(S) is the size of the maximum matching between the sets S and V\S. A variant of the local balancing 
algorithm for the single-port model was studied in [14]. Each step of this algorithm consists of two 
phases. In the first phase the nodes compute a random matching. In the second phase, for each node u, 
if edge (u, V) is chosen in the matching and w(u) > W(V) + 1, then u sends a token to V. In [14], it 
is shown that the probability that an edge appears in the random matching of any step is at least 1/(8d). 
Using this property of the random matching, we can modify the analysis in Section 4 and prove that if 
T < l/8, then the expected global imbalance at any given step is bounded. On the other hand, it trivially 
follows that if T > 1, then no load balancing algorithm is stable in this model. 6 Future Work We have 
established the stability of the local bal-ancing algorithm for any rate less than 1 and for any arbitrary 
network. We conjecture that the al-gorithm is stable for rate 1 too. However, a dif-ferent proof technique 
may be needed to establish such a result (if it holds). It is noteworthy that current stability proofs 
for packet routing [5, 91 in the adversarial model also apply for rates less than 1 only. We have been 
able to prove the stability of the edge balancing algorithm for the ring topol-ogy when T = 1. We would 
also like to improve the bound on the maximum imbalance by a more careful analysis of the algorithm. 
References <RefA>[I] The collection of computer science bibliogra-phies: Bibliography on load balancing. At 
URL http://liinwww.ira.uka.de/bibliography/Parallel/ Load.Balance.l.html. [2] References to online documents 
about pro-cess migration, checkpointing and load balanc-ing. At URL http:// wwwbode.informatik.tu-muenchen.de/ 
petri/pbeamrefs.html. [3] W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. Approximate load balancing on 
dynamic and asyn- chronous networks. In Proceedings of the 25th An-nual ACM Symposium on Theory of Computing, 
pages 632-641, May 1993. [4] N. Alon, G. Kalai, M. Ricklin, and L. Stockmeyer. Lower bounds on the competitive 
ratio for mobile user tracking and distributed job scheduling. The-oretical Computer Science, 130:175-201, 
1994. [5] M. Andrews, B. Awerbuch, A. FernAndez, J. Klein- berg, T. Leighton, and Z. Liu. Universal stability 
results for greedy contention-resolution protocols. In Proceeding8 of the 37th Annual IEEE Sympo- sium 
on Foundations of Computer Science, pages 380-389, October 1996. [6] B. Awerbuch, S. Kutten, and D. 
Peleg. Compet-itive distributed job scheduling. In Proceedings of the 24th Annual ACM Symposium on Theory 
of Computing, pages 571-580, May 1992. [7] B. Awerbuch and F. T. Leighton. Improved ap-proximation algorithms 
for the multi-commodity flow problem and local competitive routing in dy- namic networks. In Proceedings 
of the 26th Annual ACM Symposium on Theory of Computing, pages 487-496, May 1994. [8] B. Awerbuch and 
T. Leighton. A simple local-control approximation algorithm for multi-commodity flow. In Proceedings 
of the 34th An-nual IEEE Symposium on Foundations of Com-puter Science, pages 459-468, October 1993. 
[9] A. Borodin, J. Kleinberg, P. Raghavan, M. Sudan, and D. P. Williamson. Adversarial queueing the-ory. 
In Proceedings of the 28th Annual ACM Sym-posium on Theory of Computing, pages 376-385, May 1996. [lo] 
G. Cybenko. Dynamic load balancing for dis-tributed memory multiprocessors. Journal of Par-allel and 
Distributed Computing, 2:279-301, 1989. [ll] D. Eager, D. Lazowska, and J. Zahorjan. Adap-tive load sharing 
in homogeneous distributed sys-tems. IEEE Transactions on Software Engineering, 12:662-675, 1986. [12] 
P. Fizzano, D. Karger, C. Stein, and J. Wein. Job scheduling in rings. In Proceedings of the 6th An-nual 
ACM Symposium on Parallel Algorithms and Architectures, pages 210-219, June 1994. Journal version to 
appear in Journal of Parallel and Dis-tributed Computing. [13] B. Ghosh, F. T. Leighton, B. M. Maggs, 
S. Muthukrishnan, C. G. Plaxton, R. Rajaraman, A. W. Richa, R. E. Tarjan, and D. Zuckerman. Tight analyses 
of two local load balancing algo-rithms. In Proceedings of the 27th Annual ACM Symposium on Theory of 
Computing, pages 548- 558, May 1995. Journal version to appear in SIAM Journal on computing. [14] B. 
Ghosh and S. Muthukrishnan. Dynamic load balancing in parallel and distributed networks by random matchings. 
In Proceedings of the 6th An-nual ACM Symposium on Parallel Algorithms and Architectures, pages 226-235, 
June 1994. [15] A. Heirich and S. Taylor. A parabolic theory of load balance. Technical Report Caltech-CS-TR-93-22, 
Caltech Scalable Concurrent Computation Lab, March 1993. [16] J. Hong, M. Chen, and X. Tan. Dynamic cyclic 
load balancing on hypercubes. In Proceedings of the 4th Conference on Hypercubes, Concurrent Computers 
and Applications, pages 595-598, 1989. [17] S. H. Hosseini, B. Litow, M. Malkawi, J. McPher- son, and 
K. Vairavan. Analysis of a graph coloring based distributed load balancing algorithm. JOUT-nal of Parallel 
and Distributed Computing, 10:160-166, 1990. [18] E. L. Lawler and D. E. Wood. Branch and bound methods: 
a survey. Operations Research, 14:699-719, 1966. [19] F. C. H. Lin and R. M. Keller. The gradient model 
load balancing method. IEEE Transactions on Software Engineering, 13:32-38, 1986. [20] M. Livny and M. 
Melman. Load balancing in homogeneous broadcast distributed systems. ACM Performance Evaluation Review, 
11(1):47- 55, 1982. [21] F. Meyer auf der Heide, B. Oesterdiekhoff, and R. Wanka. Strongly adaptive 
token distribution. Algorithmica, 15:413-427, 1996. [22] M. Nuttall. Survey of systems providing process 
or object migration. Technical Report DoC94/10, Imperial College, London, 1994. [23] D. Peleg and E. 
Upfal. The generalized packet routing problem. Theoretical Computer Science, 53:281-293, 1987. [24] D. 
Peleg and E. Upfal. The token distribution problem. SIAM Journal on Computing, 18:229-243, 1989. [25] 
C. Phillips, C. Stein, and J. Wein. Task scheduling in networks. In Proceedings of the 5th Scandina-vian 
Workshop on Algorithm Theory, 1994. Jour-nal version to appear in SIAM Journal on Discrete Mathematics. 
[26] Y. Rabani and E. Tardos. Distributed packet switching in arbitrary networks. In Proceeding8 of the 
28th Annual ACM Symposium on the Theory of Computing, pages 366-375, May 1996. [27] B. Shirazi, A. Hurzon, 
and K. Kavi. Scheduling and Load Balancing in Parallel and Distributed Sys-tems. IEEE Computer Society 
Press, 1995. [28] A. N. Tantawi and D. Towsley. Optimal static load balancing in distributed computer 
systems. JOUT-nal of the ACM, 32:445-465, 1985. [29] R. D. Williams. Performance of dynamic load balancing 
algorithms for unstructured mesh cal-culations. Concurrency: Practice and Experience, 3:457-481,</RefA> 1991. 
  
			
