
 An Interprocess Communication Facllity for the Model A Multi-microcomputer System Ramkumar V. Chary 
 Robert C. gammill Computer Science Department North Dakota State University Fargo, North Dakota 58105 
ABSTRACT An interprocess communication (IPC) facility for a shared memory multi- microcomputer system 
Is described. Inter- process communication is performed by exchanging messages through dual-ported mail-box 
memories. The facility uses fun- damental abstractions called 'sockets'. The goals and motivations for 
'sockets', their abstract and implementation views and software interfaces to the interpro- cess communication 
facility are described. The hardware design of a 'fair' dual-port memory controller, which will improve 
the performance of the message-passing scheme, Is also described. INTRODUCTION With the advent of advanced 
yet economical microprocessors, multi-microprocessor sys- tems have become a very viable alternative 
to large, centralized uniprocessor sys- tems. This has made multi-microprocessors a very actively researched 
area. The Cm* [Swan et.al., 77] developed at the Carnegie-Mellon University was one of the pioneering 
research projects in distrlbuted/multi-mlcroprocessor systems which resulted in the development of 
two different operating systems, the StarOS [Jones et.al., 79] and Medusa [Ousterhout 81]. More recent 
systems include the u* system [Marsan et.al.,79; Civera et.al.,82J developed in Italy and the iAPX 432 
system [Cox et.al., 83] developed at Intel. These systems reflect two dif- ferent approaches to the design 
of multi-microprocessor systems. In the first approach reflected by u*, a multi-microprocessor system 
is realized by col- lecting a group of commercially available Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169; 1983 ACM 0-89791-123-7/83/012/0024 
$00.75 microcomputer systems (for example in the form of single board computers). The second approach 
involves developing a multl-microprocessor, 'top-down' The iAPX 432 was the first system to be specifically 
designed for multi-processor configurations, with hardware/firmware aids for interprocess communication, 
pro- cessor dispatching etc. This paper describes the hardware and software Issues of an interprocess 
commun- ication mechanism that Is designed for use in the Model A [Gammlll 83], a heterogene- ous multi-microcomputer 
system that is currently being designed at NDSU. The interprocess communication mechanism uses basic 
structures termed 'sockets'. They have been so named due to their similarity to telephone connections 
as well as to differentiate them from the ,port, mechan- ism used in the iAPX 432 and the 'pipe' mechanism 
used in StarOS and Medusa. The concept of 'sockets' has been used before in Computer networks such as 
ARPANET. But since the Model A is a multiprocessor while the ARPANET is a network, the imple- mentations 
of sockets on these two systems are quite different. In this implementa- tion of the interprocess communication 
mechanism, we have attempted to utilize the basic hardware configuration as much as possible. We have 
also tried to provide a large degree of flexibility to the software hierarchy that wouId be struc- tured 
around it. After s brief descrip- tion of the architectural framework, we describe the prlncipal goals 
and motiva- tions behind our IPC scheme, and then describe the design of a dual-port memory controller 
which makes the IPC mechanism more efficient. We then describe the 'socket' abstraction and the mechanisms 
used to realize it. Descriptions of the interfaces to these facilities, examples of their use, and current 
Implementations complete this paper. ARCHITECTURAL FRAMEWORK The major philosophy behind the Model A 
system was to try to coalesce a group of independent microcomputer systems into a cooperative multi-microcomputer 
system. We have tried to gather existing systems and 24 build yet another level below them, which would 
allow them to functlon with each other's help and yet retain their rights (and abilities) to function 
Independently, if necessary. Although different configurations exist for connecting multiple processors, 
we chose a global shared bus which sup- ports a memory hierarchy [Gammill 83]. A two-processor configuration 
of the Model A system ls shown in figure I. The architecture of the Model A sys- tem is based upon the 
use of two buses, one private to each processor (the PBUS) and the other, a global bus shared by all 
 the processors in the system (the GBUS). Access to the private memory (PMEM) is restricted to the local 
processor. The mail-box memory (MBMEM), is accessible to both the local processor as well as to any remote 
processor, via the global bus (GBUS). The global memory (GMEM) ts accessible to all the processors in 
the system. Although this system is best suited for processors wlth 24-blt address spaces, It does not 
prevent the use of slmpler processors (If some memory-mapping hardware ls added). SPECIFIC GOALS FOR 
INTERPROCESS COMMUNICA- TION In this sectlon, we describe our principal goals for interprocess communication. 
The motivations behind each and the reasoning that led from these goals to the approach followed In thls 
implementation are also discussed. G OALBUS OBS Figure 1. A two-processor Model A configuration The 
major design goals for the Model A IPC mechanism were economy, efficiency, sImpilclty, fIexlbtIity (with 
reference to the software iayers that It can support) and reasonable reliability. We needed a simple 
solution that was at once economical and efficient. A flexi- ble interface with higher level software 
layers was considered important since thls mechanism is to support various, perhaps diverse, software 
systems. Although relia- bility Is a very Important requirement, we gave it a lower priority since this 
system is meant to be used in a principally congenial envlronment. Further, too much concern on reliability 
at this level tends to degrade normal performance and also makes the system much more complex. Higher 
level protocols can, of course, enforce any desired measure of rellablltty. When two processes communicate, 
their demands on the IPC mechanism depends on the amount of information to be exchanged between them. 
At one extreme, the IPC scheme must provide an efficient means for transferring very short messages (I 
or 2 bytes long) between two tasks. Such mes- sages may be used when a process wants to signal the occurence 
of an event to another process. Thus, they are typically used for synchronization between tasks. In the 
rest of this paper, we refer to such messages as 'sync' messages. On the other hand, the system should 
also support the transfer of iarger amounts of data (typically whole files) efficiently. Transfers of 
'sync' messages do not Jus- tify the overhead involved in establishing a higher level protocol for message 
transfer. With longer messages however, some overhead in setting up such a proto- col is Justified, if 
from then on, the rest of the transfer is to be particularly efficient. One of our primary concerns 
In this design was to establish as much indepen- dence as possible between thls low-level mechanism and 
the software layers above it. The actual contents of any message and its interpretation must be of no 
con- cern to the software at thls layer. Higher-ieveI software iayers could estab- llsh any sophisticated 
protocol by using this low-level interface to establish Inl- tlal contacts and exchange basic Informa- 
tlon. Mutually suspicious users could use this basic Informatlon to authenticate each other's identities. 
They can then move on to a mutually arranged, higher- level communication protocol which could completely 
bypass this lower layer. The major ways of improving perfor- mance in s system such as Model A, where 
contention for non-local resources (including data) could be a serious bottleneck, are: (I) Reduce 
the cost of communication by making the duration of the critical sections shorter. 25 (2) Reduce frequency 
of global (remote) access by permitting each process to maintain more non-critical informa- tion that 
could be occasional interest to the remote task. (3) Increase concurrency in the communi-cation mechanism 
by allowing as many simultaneous updates and data transfers as possible. For the IPC mechanism, we 
decided to use a communication scheme that uses mes- sages which are exchanged via the mail-box memories 
(MBMEMs). The sending task writes messages into the mail-box memory of the processor on which the receiving 
task exists. By using this scheme, only the write of a message-transfer sequence has to use the global 
bus. The corresponding read can be performed locally, without any access to the global bus, GBUS. This 
significantly reduces the need to access the global bus, which in turn improves the performance of the 
sys- tem. This scheme assures that no processor can be prevented from making progress on its own (local) 
work, as a result of congestion on the GBUS. Further, conges- tion on the bus can affect the transmis- 
sion but not the reception of inter- processor messages. Another approach, where the sending task passes 
protected pointers to the receiving task and allows it to read the data, results in much more global 
communication in this system and hence is not used. IPC HARDWARE DECISIONS In any global shared bus 
system, the demands on the bus ere enormous. The per-formance of such a system depends pri-marily on 
the following factors: (1) The number of processors on the bus. (2) Extent to which the bus is used 
(in terms of the number of accesses per unit time) (3) The time for which the bus is actu-ally held, 
and (4) Bus arbitration overhead.  Given a certain number of processors and a certain bus-access rate, 
the overall performance of the system can be improved by reducing the 'bus hold' time and the 'bus arbitration' 
time. We limit our dis-cussion in this paper to design issues aimed at reducing the 'bus-hold' times. 
In an attempt to minimize the time for which any processor can hold on to the shared bus, we designed 
a dual-port memory controller which considerably reduces 'bus-hold' times to values dependent on the 
mail-box memory access times rather than the processor cycle times as is Usu-ally the case. A good incentive 
for proceeding in this direction is the avai-lability of economical RAMs with low access times (of the 
order of 50-i00 ns). This also makes the bus-hold times uniform even if the system involves both advanced, 
faster CPUs as well as older, slower pro- cessors. THE DUAL-PORT MEMORY CONTROLLER The memory controller 
is an application of the Dekker's algorithm [Shaw 74], ini- tially proposed for synchronzzation between 
two processes contending for a shared resource. We extended this concept to synchronize resource sharing 
(which in this case is the mail-box memory, MBMEM) between two processors. Figure 2 shows a block diagram 
of the controller. With respect to the diagram, the logic of this dual-port controller can be explained 
as follows: (i) If A contends for the memory and B does not, A gets the right to access the memory. 
 (2) If both A and B contend simuItane- ousiy, either one of them gets to access the memory.  (3) If 
A gets to use the memory, when A's request (read/write) has been served, the right to access the memory 
next is transferred to B.  (4) If A requires the memory while B holds the right to access it, yet B 
does not need the memory, A is given the right to access the memory.  A salient feature of this scheme 
is that as soon as A's request is satisfied, the data is latched (only required in the case of a read) 
at the corresponding processor's data buffer. The address buffers of that processor's interface are 
also tri-stated. Thus the global bus is PBUS of Processor A v I ers Data ~A Mai Me ddr. ~ Control 
" Ace GLOBAL BUS (GBUS) Figure 2. Block diagram of the duel-port controller 26 released as soon as 
the memory access is performed. Apart from enhancing bus util- ity, this also improves the reliability 
of the system since no processor can hold the buffer for longer than the time required for a memory 
includes the arbitration memory controller). access time of (which the SOCKETS- AN ABSTRACTION Communication 
between various tasks exist- ing on the Model A system is accomplished by passing messages through sockets. 
By using sockets, the communication scheme provides a 'virtual circuit' interface to the tasks using 
it. Sockets are data structures that are part of the Model A IPC mechanism. They are abstractions which 
allow a task to communicate with other tasks in the sys-tem. Sockets are assigned and maintained on a 
per-processor basis. This function is performed by protected code that resides in each processor. This 
code exists as a package with well defined interfaces and is invoked by any process intending to communicate 
with other tasks in the system. In order that a task can send a mes-sage to another task in the system, 
two sockets are needed, one each at the 'send-ing' and 'receiving' ends. The socket that is associated 
with the sending task is called the 'sending' socket and is resident in the sending processor. The socket 
that is associated with the receiving task is called a 'receiving' socket and resides in the receiving 
pro-cessor. Thus, Just as each one-way transfer on a telephone requires a ,mlcrophone-speaker' pair, 
a one-way mes-sage transfer between any two tasks requires a 'sending socket-receiving socket' pair. 
Each 'sending socket-receiving socket' pair is said to provide a 'link' between two activities. All information 
regarding that llnk is distri- buted between these two sockets. Between them, the sockets also provide 
a mechan-Ism for queueing messages. The need for such a mechanism arises in either of two situations. 
A receiver may wish to recelve a message when none is available. In the other case, a sender tries to 
communicate with a receiver which is not ready to receive. In the Model A system, 'sockets' are unidirectional 
in nature, much llke the 'port' mechanism used in the 432 or the 'pipes' used in Medusa. Further, since 
the implementations of the sending and receiv- ing sockets differ slightly, their roles cannot be 
interchanged. IPC MECHANISM- IMPLEMENTATION USING SOCK- ET__~S Each processor has a table of sending 
sockets called the Message Sending Table (MST) and a table of receiving sockets called the Message Receiving 
Table (MRT). A task refers to its 'link' with some other task in the system by means of a socket number 
in the MST or MRT at its end of the link. The IPC mechanism uses this number as an Index to a 'socket' 
in the sending (receiving) table that Is resident on that processor. Thus, sending and receiving sockets 
provide a level of abstraction with respect to the exact identities of the tasks on the other side of 
the link. This is partlcularly deslr-able in situations where the communication is of the requestor-server 
type. Once any llnk has been establlshed, all further communication need refer only to socket numbers. 
It should be noted that socket numbers are local to each processor. Thus the same socket number on different 
pro- cessors will normally refer to completely different links. The basic structure of the IPC scheme 
is as shown in figure 3. Tasks 1A and IB are two tasks In the system which need to communicate with 
each other. They can do so by utiIizing the set of commands that Is provided as an Inter- face to thls 
IPC facillty. In figure 3, the IPC mechanism is enciosed within the dotted lines. These commands, In 
turn, invoke 'protected' functions within the IPC mechanism. The mechanism within the dotted llnes is 
fully transparent to the tasks using it. The IPC mechanism can be dlvlded into two loglcal sub-sectlons. 
The first part is responsible for establishing and remov- ing links. Thls 'Link Control' part func- tions 
Just as a telephone operator wouid st a local exchange. Each processor also has a task caIled the Link 
Handler,LH. The major function of the Link Handier is @ expect_li~ \ ..... -f, .... W ..... -3 ---~-.... 
"- ...... -t connect/ seDd~\Processor A recev\ Processor B P I I MBMEM of Proc. All -J ..... 7Q-..... 
 Figure 3. Basic structure of the Inter- process Communication scheme 27 to establish and remove links. 
The Link Handler is in turn made up of two logical sub-tasks; the Link Handler/Sender, which handles 
all outward-bound 'link-control' requests and the Link Handler/Recelver, which handles all In-coming 
'link- control' requests. Certain sockets (sock- ets numbered '0', for example) in the HST and HRT on 
each processor are reserved for use by the locally resident Link Handler. Once a link has been established 
between any two tasks in the system, the second part of the IPC mechanism can be used for the efficient 
transfer of mes- sages between them. For this reason, the second part is referred to as the 'Data- transfer' 
section. At the time of its creation, every t~sk in the system is assigned a receiving socket. This 
socket is primarily used to convey Link Control information to that task. Whenever s new llnk is created 
to that task, the Link Handler leaves infor- mation regarding the freshly created link at this socket. 
Whenever a task is free to participate in a link, it waits for a message to arrive at this 'receiving' 
socket from the local Link Handler. This situation is similar to the one in the IAPX 4~2 where an Idle 
'server' waits for s 'requestor' to arrive at a particular port. Since thls socket normally contains 
information concerning 'links' created to more than one task, these are called 'Pub- lic' sockets. This 
dlfferentlates them from other receiving sockets that are used for transferring 'data'. These sock- ets 
are 'Private' since they usually con- tain information regarding a 'llnk' between Just two communicating 
tasks. Initially, when task IA wishes to establish a connnectlon with task 1B, it has to send a request 
to its local Link Handler. Thls is done by invoking an IPC command which converts this request to a message 
and appends it to the local Link Handler's sending socket. In this case, task 1A is defined to be in 
the 'initiate' mode of a message transfer while task 1B is defined to be in the 'answer' mode. The initial 
request should also include the identification (logical name) of the 'resource' that is required. The 
destina- tion processor is identified by its logl- cal name. The initial request can also contain short 
messages (limited to 4 bytes) which may be used by higher level software layers. This request results 
in the creation of a local 'sending' socket on MSTA. The link Handler then sends a message to its peer 
on the destination (remote) processor, requesting it to create a recefvlng socket on its side, whlch 
would complete e 'llnk' to the indl- cated resource. The remote Link Handler uses the log- ical resource 
name that it has been pro- vided to Identify the local task to which a 'llnk' needs to be established. 
Usu-ally, the 'remote' Link Handler (LHB) completes a link to the task, if possible. This is done by 
creating a 'receiving' socket that is associated with the 'answering' task, lB. The creation of a 'receiving' 
socket includes the allocation of buffer space that is necessary for the queueing mechanism. Since a 
'sending' socket exists for task 1A on processor A and a 'receiving' socket has now been created for 
task IB on processor B, the 'link' between 1A end 1B is complete. The 'remote' Link Handler then sends 
an ack-nowledgement (positive or negative) to the other Link Handler. Also embedded in this acknowledgement 
is the information neces- sary to perform the rest of the transfer efficiently. The remote Link Handler 
also leaves a message in the Public socket of the 'ansewring' task, IB. Certain information regarding 
the freshly created llnk, such as its ,llnk-number', is included in this message. The responsibility 
of reading this message rests completely with the receiving task. In the case of 'sync' messages, nei-ther 
sending or receiving sockets are explicitly created, in order to restrict the overhead to a minimum. 
Instead, the public socket of the task that is waiting for the arrival of this 'sync' message Is used 
by the Link Handlers to convey this information. SOFTWARE INTERFACE Now that we have described what 
supports the sockets and their basic uses, we next describe the software interface that they make available. 
This software interface ls written in the form of a package. The entire mechanism ts presently implemented 
in the 'C' language and is being studied in a Unix environent on a PDP 11/45. The basic interface consists 
of 7 'socket-manipulation' instructions. Both 'uncon-ditional' and 'conditional' SEND and RECEIVE operations 
are provided. The unconditional operations employ implicit blocking of the associated task, i? the operation 
cannot complete. The condi-tional operations never block. Instead, a boolean value which indicates success 
or failure is returned to the calling pro-cess. The 'connect' command is used by a task wishing to establish 
a 'llnk' to some other task in the system. The format of the command is skt= connect ( destination-logical 
name o~ res- ource to which a 'llnk' is to be established qualifier - indicates if connection reqd. Is 
of type 'syno' or ,regular' traffic -an apriort estimate of the expected traffic other lnfo -Any other 
info. needed 2B for high ivl. protocols processor - logical name of the destination processor (to 
be specified by the higher level protocol) );  skt- A valid sending socket number if link can be established. 
Else, a NO_LINK is returned. The unconditional 'send' operator is used to send a message through an 
existing 'link' to a receiving task. This command must be preceded by a 'connect' command. If the message 
queue (at the receiving socket) of that link is full, then the sending process is blocked until s mes- 
sage slot is available. The format of the 'send' command is: send ( send skt- e socket number on the 
local MST returned by a previous 'connect' cell message -the actual message to be sent ); The conditional 
send is similar to the unconditional send. The difference is that the sending task is not blocked even 
if all the buffers associated with that llnk are full. The format of the 'conditional-send' command is: 
 result = csend ( send_skt, msg); result- It equals DONE if the csend completes. If a msg. buffer is 
not available at the rem-ote end, NOT DONE is returned. The receiver which expects a linkestablishment 
from some task in the system, invokes the 'expect_llnk' commend which has the format: rec_skt = expect_ilnk( 
 send_spec- name of resource/task from which a message is expected (need not be specified). order -indicates 
order in which msgs. are received from the public socket. Usually, this is FIFO. mesg type- specifies 
if message expected is 'sync' or regular data. other_msg- In case of 'sync' comm- unication, other_mesg 
holds the 'sync'info. Else it is used for messages meant for higher level protocols. );  rec skt- In 
case of a regular llnk, the socket number of the local receiving socket created for this (unidirectional) 
link Is returned. If the receiving task is expecting a link initiation by e particular task, it is 
blocked in the absence of any waiting messsages from that task. If e FIFO ser-vice has been indicated, 
the task is blocked on e 'queue-empty' condition. The receiving task can conditionally or unconditionally 
receive messages from a receiving socket whose number was returned by a preceding invocation of the 'expect_llnk, 
command. The format of the unconditional receive command is: receive ( rec skt - Local receiving socket 
number mesg - Actual message that has been received from the sending task on the other side of this 
link. );  The conditional receive is of the form result = creceive (rec_skt, mesg); The conditional 
receive does not block on a queue-empty situation. When the call returns, 'result' contains a boolean 
value which indicates success or failure. Finally, 'graceful' termination of the link is performed by 
using disconnect ( local skt -sending socket at the local end. ); A SCENARIO Let 1A be a task running 
on processor A, which needs the services of a 'PRINTER' task which it knows is resident on proces-sor 
8. The various steps involved in establishing a link between these two tasks is briefly discussed here, 
with reference to figure 4. By our earlier definition, IA is in the 'initiate, mode of a message transfer 
while IB is in the 'answer' mode. Inl- tially, IA performs a connect("PRINTER",resource,other,-B,,). 
 This results in IA being blocked. Then, a sending socket 'm' is created in processor A's message sending 
table. Next, a message is sent to LHA, the Link Handler that is resident in processor A. LHA passes this 
message over to LHB, the link handler in processor B. Here the "PRINTER" task is identified to be task 
lB. LHB now creates a receiving socket 'n' in processor B's MRT, if possible. This includes creating 
necessary buffer 29 PROCESSOR A PROCESSOR B HST A HRT A [ST B MRT B Link control -------r----~mesg, 
 messages from IA to IB  Figure A. Example of an interprocess transaction space for the message queue. 
This infor- mation is sent back to LHA. This results in IA being unblocked. Finally, if every thing had 
gone smoothly, 'connect' returns the socket number 'm' to IA. From then on, IA can perform send( m, 
message)  which will result in the messages being sent to IB. Meanwhile, LHB also leaves a message 
about the creation of a new link to IB in IB's public socket 'i'. When IB performs an expect link(ANYONE, 
FIFO, message),  it receives the socket number 'n'. From then on, IB performs receive(n, message) 
 to receive messages from IA. When the transfer is completed, IA performs e disconnect(m),  which results 
in the deallocation of socket 'm' on MSTA. When IB has received all the messages that were sent by 
IA, the final 'receive' command returns an 'End of Link' (EOL) character to IB. The socket 'n' on 
MRTB is then deallocated. At this point, the 'link' between IA and IB has been completely removed. 
 CONCLUSIONS We have examined the motivations for, and the design of an interprocess communica- tion 
facility for a heterogeneous multi- microcomputer system. By using the 'socket' abstraction, we have 
provided a communication mechanism which meets our major goals of simplicity, economy and f)exibility. 
We have realized that by selecting a suitable inter-connection architecture and developing a communica- 
tion mechanlsm that fully utillzes this architecture, practical means for coupling heterogeneous microcomputers 
can be provided. Simulation studies being con-ducted on an implementation of this IPC scheme should 
provide us with more objec-tive evidence with which we can evaluate our design. REFERENCES <RefA>CIVERA, P., 
CONTE, G., DEL CORSO, 0., GRE-GORETTI, F. AND PASERO, E. The U* Pro-Ject: An Experience with a Multlmicropro-cessor 
System. IEEE Micro 2,2 (May 1982), }8-PO. COX, G.W., CORWIN, W.M., LAI, K.K. AND POLLACK, F.3. Interprocess 
Communication and Processor Dispatching on the Intel 452. ACM Trans. Computer. Syst. I,i (Feb. 1983), 
45-66. GAMMILL, R.C. The Model A Multi-Microcomputer System. Personal Communi-talon, June, 1983. JONES, 
A.K., CHANSLER, R.3., DURHAM, I., SCHWANS, K. AND VEGDAHL, S.R. StarOS, A Multiprocessor Operating System 
for the Support of Task Forces. Proc. Seventh Symposium on Operating Systems Principles, ACM, 1979, 117-127. 
MARSAN, M.A., CONTE, G., CORSO, 0.0., AND GREGORETTI, F. Architecture, Communica-tion Procedures and 
Performance Evaluation of the u* Multimicroprocessor System. Proc. of First Intl. Conference on Dlstri- 
buted Computer Systems, IEEE, New York, 1979. 106-115. MARSAN, M.A., CONTE, Ge, CORSO, O.O. AND GREGORETTi, 
F. A study on processor/memory interconnectton in mutlm-tcroprocesso~ systems. ALTA FREQUENZA 50,3 (Apr. 
1981), 122-130. MARSAN, M.A., BALBO, G., CONTE, G, AND GREGORETTI, F. Modeling Bus Contention and Memory 
Interfernce in a Multlprocessor System. IEEE TC }2,1 (Jan. 1983), 60-71. OUSTERHOUT, J.K. Medusa: A Distributed 
Operating System. UMI Research Press, Ann Arbor, 1981. PLUMMER, W.W. Asynchronous Arbiters. IEEE TC 21,1 
(Jan. 1972), 37-42. SHAW, A.C. The Logical Design of Operat-ing Systems. Prentice-Hall Inc., Englewood 
Cliffs, 1974. SWAN, R.J., FULLER, S.H. AND SIEWlOREK, O.P. Cm* A Modular, Multi-microprocessor, Proc. 
NCC, v.46, 1977. 657-644, WEITZMAN, C. Distributed Micro/Minicomputer Systems. Prentice- Hall, Inc., 
Englewood Cliffs, 1980. WULF, W.A., LEVIN, R. AND HARBISON, S.P. 30 HYDRA/C.mmp: An Experimental Computer 
System. McGraw-Hill, New York, 
			</RefA>
