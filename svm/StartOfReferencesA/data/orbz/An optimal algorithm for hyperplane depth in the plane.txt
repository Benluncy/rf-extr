
 An Optimal Algorithm for Hyperplane Depth in the Plane Stefan Langerman* Abstract Given a set of n 
hyperplanes hi .... , hn E R d the hy-perplane depth of a point P E R d is the minimum num- ber of hyperplanes 
that a ray from P can meet. The hyperplane depth of the arrangement is the maximal depth of points P 
not in any h~. We give an optimal O(nlogn) deterministic algorithm to compute the hy- perplane depth 
of an arrangement in dimension d = 2. 1 Introduction and Summary Given a set S --{hl,...,hn} of n real 
numbers, the depth of x E R is defined to be (1.1) d(x) = min(]{h~ _ x}[, ]{hi ~ x}[), and may be thought 
of as the "size" of the smallest halfline containing x. A median is a point of maximal depth ([(n + 1)/2]) 
and may be found in O(n) time. There are many situations -for example in Statistics -where multivariate 
generalizations of ranks and order statistics are useful, and several proposals for depth in R a have 
been made [2], [71. In one of the most familiar ones [14], we are given a set S = {P1,-.-,Pn} of n points 
in R d. The depth, or Tukey depth of x E R d is defined as the minimal number of points of S that must 
be in a closed halfspace containing x. A median is a point of maximal depth. When d = 1 this notion agrees 
with the depth in (1.1). It is a well known consequence of Helly's Theorem (e.g.,[6]) that a Tukey median 
always has depth at least [n/(d + 1)]. Matou~ek [10] has described an algorithm for d = 2 that finds 
a median in time O(n(logn)5). Cole, Sharir and Yap also gave an O(n(logn) 5) algorithm [5], which was 
further improved by Cole [3] to O(n(logn)3). ~puter Science. Rutgers University tComputer Science. Rutgers 
University William Steiger t Recently, Rousseeuw and Hubert [11] proposed an interesting, new notion 
of depth for R d. Given aset S = {hi,..., hn} ofn hyperplanes in R d, they defined the hyperplane depth 
of a point x E R d to be (1.2) 5(x) = min (r(x,u)), u:llull=l where r(x,u) is the number of hi E S that 
meet the ray {x + tu, t > 0} through x in direction u. A median is a point of maximal depth. When d = 
1, (1.2) agrees with the usual definition of depth in (1.1). Hyperplane depth was motivated by prob-lems 
in robust regression. Using a familiar point/hyperplane duality transformation, the hi dualize to n data 
points in R d and x, to a hy-perplane meant to fit the data. The "regression depth" of x in is the minimum 
number of data points x meets in a rotation-to-vertical; this cor-responds exactly to the hyperplane 
depth of x in the original problem. Hyperplane depth has attracted much recent interest. On the combinatorial 
side it was just shown [1] that like the Tukey median, the hyper-plane median must have depth at least 
fn/(d + 1)]; the lower bound is sharp, attained when the hi are duals of n points on the moment curve 
in R d. Other interesting combinatorial questions remain open. On the computational side. a main question 
is to determine the complexity of selection -comput-ing points of given depth, or of maximal depth. We 
use the unit cost RAM model. The hyperplanes in S partition R d into a complex of O(n d) convex cells, 
called the arrangement of S, and written A(S). It is clear that every point in a cell has the same depth. 
The depth of the arrangement, 5(A(S)) is the depth of the deepest cell. The task therefore is to com-pute 
8(A(S)), and a witness point of that depth, or to find a cell of given depth k _< d(A(S)). Rousseeuw 
and Hubert point out that for any x, (~(x) can be computed in O(n d-1 log n), and since there are O(n 
d) vertices in A(S), selection has cost O(n 2d-1 logn). For d = 2 they mention an O(n 3) algorithm [12]. 
In Amenta et. al. [1] it was observed that A(S) can be constructed in O(n d) and then, using breadth-first-search 
on the graph of adjacent cells, the depth of every cell is obtained in the same O(n d) time. This is 
the analogue of using sorting to find the ordinary median. For the case d = 2, vanKreveld et.al. [91 
re-cently described a beautiful O(n(log n) 2) algorithm for hyperplane depth in R 2. This shows that 
it is not necessary to find the depth of every cell in or- der to find the deepest one and is analogous 
to the fact that sorting is not optimal for the usual median. The algorithm is controlled by a binary 
search based on being able to select the k th ver-tex -ordered by x-coordinate -in a set of consec- utive, 
unsearched candidate vertices. This may be done in O(nlogn) (see e.g., [4]). The vertical line through 
the selected vertex is then analyzed for sid-edness. The sidedness test for a line f determines one of 
the two half planes delimited by g that in-tersects a maximum depth cell, and has complexity O(n log 
n). Since there are O(log (])) binary search steps, the algorithm has complexity O(n log 2 n). In the 
present paper we prove the following. THEOREM 1.1. Given a set S of n lines in the plane, the hyperplane 
depth of the arrangement, 5(A(S)), and a witness point tL with that depth can be obtained in O(n log 
n) time and O(n) space. The proof is via an algorithm, shown to have the asserted complexity. The lower 
bound is via a connected components argument showing that ft(nlogn) steps are needed by an algebraic 
decision tree that can decide if the depth of a given point is greater than k, a given integer. An easy 
consequence is that in the same time bounds, given k <_ 6(A(S)), a point of depth k can be found. It 
is interesting that our algorithm combines parametric search and prune-and-search to improve the result 
in [9], much like the way that the linear- time algorithm for the usual median improves on sorting. ~V~ 
are searching for a point # in a cell C of maximal depth. In fact, we will determine for each line in 
S its above/below relationship with/~. Each step of the algorithm solves the parametric problem of finding 
that above/below relationship for a constant frac-tion a < 1 of the m (initially n) remaining lines. 
These lines are then pruned out and the search con- tinues with the remaining lines. We are able to do 
the pruning step in O(m logn +n). Since there are at most n(1-a)J unpruned candidates after the jth Step, 
and at most log n steps in all, the complexity is at most cnlogn + E b(1 - a)Jnlogn = O(nlogn). j=0 2 
Tools In this section, we will describe some tools that will be used in the main algorithm. In particular, 
we will talk about the sidedness test for a line, and insideness test for a convex closed curve. In order 
to simplify the discussion, we define ~(x, u) to be the number of lines of S crossed by the ray {x + 
tu, t > 0} (the difference with r being that we are not counting lines passing through x). We also define 
5(x) = minu:llull=l(~(x ,u)). Note that if x is inside a cell, 5(x) = 5(x), and so, since we are looking 
for a cell of maximum depth, we can use instead of 5 without changing the result. Given a point x, we 
say that u is a witness direction if 7=(x, u) = 5(x). We will need the following: LEMMA 2.1. (WEDGE LEMMA 
[9]) Let x be a point and u and v be directions of rays from x. Then no cell of of A(S) intersecting 
the wedge (cone) formed by u and v at z has depth greater than max(.~(z, u), fix, v)). Given a point 
z, we will call the wedge at x the set of all directions that can be formed by positive linear combinations 
of witness directions at x. By the Wedge Lemma, no cell that intersects the wedge at x can have depth 
greater than ~(x). Note also that if the wedge at x contains all directions, then z is of maximum depth. 
Otherwise, the wedge at x forms an angle less than 7c. Here are a few more facts worth noticing: If x 
is on a segment separating two adjacent cells and x + and x- are points in the adjacent cells, then (~(x) 
= min(5(x+), 5(x-)). On any path in the plane, points x ~ y that have no line of S separating them are 
in the same cell, and have the same wedges. On any path in the plane (not touching any vertex of the 
arrangement), any 2 consecutive wedges intersect. Using the Wedge Lemma, VanKreveld et.al. [9] described 
a sidedness test for a line t~. In time O(nlogn) it computes k = max(5(x),x E e) and gives a side (Left 
or Right) of g which does not contain a point of depth > k. We now describe a new way to test sidedness 
based on the following insideness test. Suppose we are given a convex polygon 79 whose boundary does 
not contain a vertex of A(S), and such that no vertex of P is on a line of the arrangement. Let k denote 
the depth of the deepest point on the boundary of 79. We want to determine which of the inside or the 
outside of the convex polygon cannot contain a cell of depth greater than k. Note that if k = 5(A(S)) 
is the depth of the arrangement, any answer would be correct. LEMMA 2.2. Given a convez polygon 7' with 
s sides and a subset U = {ft,...,fm} C S of the lines of S that meet the interior of 7 9, then the insideness 
test for 79 can be performed in  log(n) + s). We will continuously move a point x around the boundary 
of 79, starting at the leftmost vertex. and keeping track of the wedge at x. Note that the wedge only 
changes when x crosses a line of U. In [9], a data stru.cture is presented to maintain the wedge at x 
as x moves along a path. Its cost is O(log(n)) per line crossing. At the same cost it gives max(5(x)) 
for the points traversed, so k. the greatest depth of points on P, is computed in the traversal of 79. 
The number of wedges is 4m since each line crosses the boundary of the polygon twice, and there are two 
wedges per line crossing, one when x moves onto a new line, and another when it passes that line. Let 
x0,..., Z4rn-l, X4m --~-Z0 be 4m points on the path that mark the wedge change events. Observe the movement 
of the leftmost ray Ai of the wedge at xi along the path, and let -Tr <_ ~i <__ n, i = 0,...,4rn -1 be 
the angle between Ai and Ai+l. Note that since any two consecutive wedges intersect, we can move the 
ray to its next position while always staying inside a wedge, and any point swept by the ray cannot have 
depth greater than k. "4. CLAIM 2.1. If the outside of the.polygon contains a point of depth greater 
than k. then 4rn--1 ~=0 i=0 Pro@ If p is a point outside of the polygon of depth greater than k, then 
that point is not swept by the ray, by the wedge lemma. Let 0 < c~ < 2~ be the angle A0x0p, and let -~r 
<_ w/i < rr be the angle between the two directions zip and Xi+lp. By induction, for any r. we have c~ 
- 2:r + '.~,'i < ~i < a + ~i i=0 i=0 i=0 because the last movement of the ray cannot sweep and so p. 
Since p is outside the polygon, and Z4m = X0, we have 4m-I e~=0 i=0  4rn--1 -2rr___a-2~r< ~ ~i<a_<2~- 
i=0 But v'4rn-1 z-,i=0 ~i must be a multiple of 27r since )~4rn : /~0, SO it must be 0. CLAIM 2.2. If 
the inside of the polygon contains a point of depth greater than k, then 4m-I i#o i=O Proof. Same as 
for the previous claim, but now, since p is inside the polygon, we have 4rn-- 1. ~ = 27r i=0 and so, 
4rn--1 0 <_ a- 2rr +27r < Z ~i < a +27r i=0 Thus the sum cannot be 0. [] Proof of Lemma 2.2. We can 
precompute the ordering of all 2m line crossings, walk around the polygon and compute k and Z~i in O(rn 
log(n)+ s) time. If the sum is 0, then the inside does not contain a point of depth greater than k. Otherwise, 
the outside does not contain a point of depth greater than k, and this proves the lemma. [] COROLLARY 
2.1. Suppose we have a convex poly- gon P with s sides, a subset U = {ft,.--,grn} C_ S of the lines of 
S that meet the interior of 79, and a line ~. If 79 contains a cell C of maximal depth, then the sidedness 
test for e can be performed in O(m log(n)+ Pro@ If e does not meet P, the sidedness test is trivial. 
Otherwise let :P+ denote the part of 7 ) ";above" g, together with the segment on ~ that meets 7 ~. The 
insideness test for P+ resolves the sidedness of e. Note that if the polygon is chosen to be big enough 
to contain all the vertices of the arrangement, this test performs the usual sidedness test from [9]. 
3 Pruning At every step of the algorithm, the lines are di-vided into two sets: the set P contains all 
the pruned lines, and U contains the unpruned lines. Write m = IUI and A(U) for the arrangement of unpruned 
lines. For every line in P, we know if it is above or below some cell of maximal depth, and we maintain 
the intersection of these halfspaces as a convex polygon P which contains a cell of max- imal depth. 
At the beginning of the algorithm, P is empty, and P is some polygon large enough to contain all the 
vertices in the arrangement (such a polygon can be constructed in O(nlogn) time). Consider some point 
# in P of maximal depth, and let v be the vertical line passing through it. We want to solve the parametric 
problem of determining for a constant fraction of the lines in U, whether those lines cross v above or 
below/~. First, we compute the center'point line ~ for U. This line is the dual of a (usual) centerpoint 
for the points dual to the lines in U. It has the property that it is below the m/3 level of A(U) and 
above the 2m/3 level. Jadhav and Mukhopadhyay [8] give a linear time algorithm to compute g. Next, perform 
the sidedness test for that line g, restricted to the polygon P, in O(m log(n) + n) time. Assume without 
loss of generality that tz is below g. In O(m) time, compute the intersection of all lines in U with 
g, and select 9 of those intersection points, say Pl .... ,Pg, each adjacent pair separated by <_ rn/9 
of the intersections on e. We can do this in O(m) using the fast selection algorithm. Perform the sidedness 
test (restricted to P) for the vertical lines at each of those 9 points, in O(m log(n) + n) time. This 
will either find a point of maximal depth, or determine a strip between adjacent lines that contains 
the maximal depth point #. Let x = a and x = b denote the left and right verticals of that strip, a < 
b. By construction g has at most m/9 intersections in [a, b] with lifies in U. In addition there are 
at least m/3 lines in U that meet x = a or x = b, or both. above the level m/3. If these lines meet ~ 
outside [a, b] they cross v above p and can be pruned. It follows that at least nz/3 -m/9 = 2m/9 lines 
of U can be pruned, since they have been determined to be above/~. In order to prune a line, we remove 
it from U and add it to P. We then update the polygon P in O(log(n)) per line using an incremental convex 
hull algorithm. The overall pruning cost is therefore O(mlog(n) + n). When the number of unpruned lines 
falls below some predefined constant, we can perform the sidedness test to all remaining lines in O(n 
log n) time, and that completes the description of the algorithm. A simpler algorithm would replace the 
centerpoint-line construction that used Jadhav and Mukhopadhyay's algorithm by a random choice of a line 
from U. With positive constant probabil-ity, the intersection of that line with v, the vertical line 
through #, will have n/3 intersections above and below it. The resulting randomized algorithm would have 
the same O(n log n) running time for its expected cost. The Lower Bound Let C denote the circumference 
of the unit circle in R 2 and let T denote an algebraic decision tree that can decide whether ~(A(S)) 
>_ [m/2J for a set S of m lines in R 2. We restrict attention to lines that are tangent to C and we will 
even hold most of the lines fixed. Such inputs can be encoded by the arguments (q~l,--., ~m) RTM of 
the tangency points. We will show that the subset Y C R TM of restricted inputs where T returns YES has 
fl(m logm) path connected components. Consider the point 0 = (01,..., 0m) where i (4.3) 0i -4n + 3 2~r' 
i = 1,...,4n + 3. This describes m = 4n + 3 equally spaced points on C, no two diametric. In fact the 
diameter containing 0i is a halving line -both its open semicircles contain 2n + 1 of the other 0j. A 
diameter containing none of the 0z is a non:halving diameter and has one open half circle of C with 2n 
+ 1 points and the other with 2n + 2 points. The vector in (4.3) will be used to encode the set of lines 
S = {gl,---,~m}, where g~ is tangent to C at the point with argument 6i. The maximum depth cell in A(S) 
is the regular convex m-don 7' that inscribes C and has tangency points at the 0i. For any x in P every 
directional depth will be either 2n+ 1 or 2n+2, depending on whether or not the direction is orthogonal 
to a halving diameter, or if it is orthogonal to a non-halving diameter and points to the larger half 
circle. Therefore 6(A(S)) = 2n + 1 = Lm/2J. Ok Ok+l The set of inputs to T that we consider are in I, 
where z = (zl,...,zm) I if all zi e [0, 2zr] and zj = Oj, j =_ 1, 2, 3 mod 4}. Let rr and p be two different 
permutations of the integers 4, 8, ..., 4n, and define the input 6~ I by (01,82, 03, 0~.~,..., 84,-,-1,0~-,,, 
04n+~, 84,+2, 64,~+3) and input 0p E I by (81,02, 83, 0p,,..., 84,-1,0p,, 64,+,, 04,+2, 84,+3); the permutations 
7r and p point to every fourth entry. Both 0~ and t~p are in YNI, as they describe the m lines in S in 
different order. We argue that they are in different components. We hold the 0j fixed for all j = 1,2,3mod 
4, and move each /~,r, continuously on C to the corresponding 6p~, i = 1,..., n. This describes a continuous 
path in I from 0~ to 6p, and every point z E I on the path describes m --4n+3 lines tangent to C, with 
3n + 3 of the lines fixed. Since rr 7~ p, some 04j must ~:cross" (i.e., reverse its radial ordering) 
a neighbor, 045-1 or 04j+i (see figure). Write k = 4j+2n+ linod(m+l); Ok and 0k+l are the neighbors of 
the diameter through 04j. If 045 crosses a neighbor, it first will cross the diameter through Ok or the 
diameter through 0k+l. When this occurs that diameter will have 2n points on one side and 2n + 2 on the 
other, and the m lines that are described by this input z E I will have 6(A(S)) = 2n. Since we have a 
point on a path from 0~ to Op that is not in Y n I, 0r~ and 0p must be in different components of Y N 
I. This accounts for at least n! different components and since m = 4n + 3, we get a lower bound of f~(mlogm) 
on the depth of T. The above argument also establishes an fl(rnlogrn) lower bound for computing the hyper- 
plane depth of a point x. It would be interesting to know if the same lower bound applies to seemingly 
easier questions. One is the problem of reporting a point x, guaranteed to be in a maximum depth cell 
of A(S). Another is the problem of reporting the above/below relation of each line with respect to an 
unknown point x which is in a maximum depth cell. References <RefA>[1] N. Amenta. M. Bern, D. Eppstein, and 
S.-H. Teng. Regression depth and Center Points. Discrete and Comp. Geom. (to appear). [2] B. Chazelle. 
Geometric Order statistics. Proc ,4CM Geometry, 1988. [3] R. Cole. Slowing Down Sorting Networks to Obtain 
Faster Sorting Algorithms. J. ACM 34(1), 200-208. (1987). [4] R. Cole, J. Salowe. W. Steiger. and E. 
Szemer~di. An Optimal Time Algorithm for Slope Selection. SIAM J. Comp. 18, 792-810 (i989). [5] R. Cole. 
M. Sharir, and K. Yap. On k-Hulls and Related Problems. Siam J. Comput. 16(1),61-77, (1987). [61 H. Edelsbrunner. 
Algorithms in Combinatorial Geometry. Springer-Verlag, Berlin. 1987. [7] J. Gill, W. Steiger, and A. 
Wigderson. Geometric Medians, Discrete Math. 108, 37-51. (1992), [8] S..ladhav and A. Mukhopadhyay. Computing 
a Centerpoint of a Finite Planar Set of Points in Linear Time. Discrete and Comp. Geom. 12, 291- 312. 
(1994). [9] M. van Kreveld, J. Mitchell, P. Rousseeuw, M. Sharir, J. Snoeyink, and B. Speckmann. Effi-cient 
Algorithms for Maximum Regression Depth. Discrete and Comp. Geom. (to appear). [101 J. Matou~ek. Computing 
the Center of a Planar Point Set. Discrete and Computational Geometry: Papers from the DIMACS Special 
Year Amer. Math. Soc., J.E. Goodman, R. Pollack, W. Steiger, Eds, (1992), 221-230. [11] P. Rousseeuw 
and M. Hubert. Depth in an Arangement of Hyperplanes. Discrete and Comp. Geom. (1999) [12] P. Rousseeuw 
and M. Hubert. Regression Depth. J. Amer. Statist. Assoc.(to appear in June 1999). [13] W. Steiger and 
R. Wenger. Hyperplane Depth and Nested Simplices (extended abstract) 10 Lh Canadian Conference on Computational 
Geome-try, McGill University, Montreal (i998). [14] John Tukey. "Mathematics and the Picturing of Data". 
International Conf. of Mathematicians, Vancouver, 1971.   </RefA>
			
