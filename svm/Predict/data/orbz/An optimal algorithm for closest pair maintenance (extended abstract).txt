
 An optimal algorithm for closest pair maintenance (Extended abstract) Sergei N. Bespamyatnikh Department 
of Mathematics and Mechanics, Ural State University, 51 Lenin St., Ekaterinburg 620083, Russia. e-mail: 
bsn@ubd. e-burg. SU. Abstract Given a set S of n points in i&#38;dimensional space, and an Lt metric, 
the dynamic clos­est pair problem is defined as follows: find a closest pair of S after each update of 
S (the insertion or the deletion of a point ). For fixed dimension k and fixed metric Lt, we give a data 
structure of size O(n) that maintains a closest pair of S in O(log n) time per inser­tion and deletion. 
The running time of algo­rithm is optimal up to constant factor because Q(log n) is lower bound, in algebraic 
decision­ tree model of computation, on the time com­ plexity of any algorithm that maintains the closest 
pair (for k = 1).  Introduction The dynamic closest pair problem is one of the very well-studied proximity 
problem in Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
of Computing Machinery.To copy otherwise, or to republish, requires a fee and/or specific permission. 
1ltti Computational Geometry, Vancouver, B.C. Canada @ 1995 ACM ()-89791 -724-3/95/0006.. +$3.50 computational 
geometry [8, 13, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28]. We are given a set S of n points in k-dimensional 
space, k >1, and a distance metric Lt, 1< t< co. The point set is modified by insertions and dele­tions 
of points. Each point p is given as a k-tuple of real numbers (pl,. . . . p~). The closest pair of S 
is a pair (p, q) of dis­tinct points p, q c S such that the distance between p and q is minimal. The 
dynamic closest a closest s. pair problem pair (any) is of defined S after as follows: find each update 
of We a ssume that the dimension k and the distance metric Lt are fixed. We use d(p, q) to denote the 
distance between p and q. A survey can be found in Schwarz s Ph. D. Thesis [21]. For the static closest 
pair problem and dimension k = 2, Shames and Hoey [20] gave an algorithm with running time of O(n log 
n). Shortly after that, Bent­ley and Shames [6] obtained this result for general dimension k z 2. In 
the on-line clos­est pair problem only insertions are allowed. For this problem Smid [25] obtained a 
data structure of size O(n) that supports inser­ tions in Cl(logk-l n) amortized time. Schwarz, Smid 
and Snoeyink [23] presented a data structure of size O(n) that maintains the clos­ est pair in O(log 
n) amortized time per inser­tion. Several algorithms are obtained for the dy­namic closest pair problem 
[15, 16, 19, 21, 26, 27, 28]. In [16, 19, 26] the problem is solved with O(filog n) update time using 
O(n) space. In [15] Kapoor and Smid gave data structures of size S(n) that maintain the clos­est pair 
in U(n) amortized time per update, where for k z 3, S(n) = Cl(n) and U(n) = o(log~-1 nlog log n); for 
k = 2, S(n) = O(nlog n/(log log n)~) and U(n) = O(log nlog logn); for k = 2, S(n) = O(n) and U(n) = 0(log2 
n/(log log n)~) (m is an arbitrary non-negative integer constant). In [8] the author obtained an algorithm 
with O(logk+l n log log n) update time and O(n logk-2 n) space. Callahan and Kosaraju [10] developed 
a tree-maintenance technique to solve a general class of dynamic algorithms. This technique can be used 
to maintain the closest pair in 0(log2 n) time and O(n) space. We give a linear size data structure that 
maintains the closest pair in O(log n) time per update. The algorithm is deterministic and the update 
time is worst-case. The algo­rithm fits in the algebraic computation tree model. In the algebraic computation 
tree model, there is a lower bound of fl(n log n) on the time complexity of any algorithm that solves 
the static closest pair problem for di­mension k = 1 [4, 17, 18]. So the running time of our algorithm 
is optimal up to a con­stant factor. Our algorithm is based on the follow­ing idea. We use a hierarchical 
subdivision of space into boxes. Several proximity al­gorithms build hierarchical subdivisions of space 
[30, 12, 11, 25, 22, 21, 3, 10]. These subdivisions differ by the shape of boxes, the overlap allowance, 
the manner of box split­ting, the number of points in a box stored at a leaf. Our algorithm maintains 
almost cu­bical boxes. The boxes are split by almost middle cutting. Any smallest boxe contains exact 
ly one of the given points. For each point we store some neighbor points. The closest pair is one of 
these pairs. To main­tain efficiently these pairs we apply the dy­namic tree of Sleator and Tarj an [24]. 
To insert a point we implement the point loca­tion. The point location also uses the dy­namic tree. The 
idea to use dynamic trees for point location in hierarchical subdivisions is due to Cohen and Tamassia 
[12] and Chi­ang, Preparata and Tamassia [11]. Schwarz [21] applied the dynamic trees for the on-line 
closest pair problem and obtained an algo­rithm with worst-case O(log n) time per in­sertion and O(n) 
space. Our hierarchical sub­division is similar to the box decomposition of [2] and the jair split tree 
of [10]. Arya et al. [3] presented a dynamic algorithm for approx­imate nearest neighbor queries. The 
tree they maintain is closely related to the quadtree of [7] and, as a result, their algorithm requires 
non-algebraic bit operations. In Section 2 we describe a hierarchical subdivision. In Section 3 we show 
how to maintain the hierarchical subdivision (with­out point location). Section 4 explains how to maintain 
a neighbor information of points and the closest pair. In Section 5 we show how to emplement the search 
on the dynamic tree. Finally, in Section 6 we give some con­cluding remarks. 2 The hierarchical subdi­vision 
The essential component of the data struc­ture is a hierarchical subdivision of space into boxes. We 
define a box to be the product [al, al ) x . . . x [ak, a~ ) of k semiclosed inter­vals. The boxes of 
the subdivision are almost cubical. We shall call such boxes as c-boxes. Definition 2.1 Let B be a box 
with sides sl, . . ..s~. The box B is said to be a c-box if, for any i,j G {1,..., k}, s~/sj C [1/3,3]. 
The boxes are split by almost middle cut­ting. Definition 2.2 Let [a, a ) be an interval in R. Divide 
the interval into 3 intervals of equal length. We shall call the interval [%, w] as middle interval of 
[a, a ). Definition 2.3 Let 1? = [al, al ) x . . . x [ak, ak ) be a box and Ci G (a,, a, ) be a real 
number for some z. The cut of B by the hy­perplane z, = c, into the boxes Bfl{o [z~ < c~} and B n {x 
[x; 2 Ci} is almost middle cut of B if Ci belongs to middle interval of [a~, ai ), i.e. 2a, +a a,+2a 
c, e [*, - #l. Definition 2.4 Let A and B be k­dimensional boxes. The box A is said to be a s-sub-/Joz 
of B if there exists a sequence of boxes Bo, 131, l?; ,.. . . B/, B; such that B = Bo, A = B/ and the 
boxes B;, B: are obtained by almost middle cut of the box Bi_l for i=l, . . ..l. The notion of s-sub-box 
is important and we give another definition. Definition 2.5 Let [a, a ) and [b, b ) be in­tervals in 
R. Let [a, a ) is the sub-interval of [b, b ), i.e. b < a s a ~ b . The interval [a, a ) is called s-sub-interval 
of the interval [b, b ) if one of the following conditions holds 1. [a, a ) = [b, b ), or 2. a= band 
Ia a[ s ~] b b[, or 3. a = b and /a al < ~lb bl, or  4. Ia bl s ~lb bl and Ia al s ~la bl, or 5. 
/b al s ~lb bl and la al < ~lb al.  Definition 2.6 Let A = [al, al ) x . . . x [a~, a~ ) and B = [bl, 
bl ) x ... x [bk, bk ) be k-dimensional boxes. The box A is said to be a s-sub-box of B if, for i = 1,....k, 
[az,a, ) is s-sub-interval of [b;, hi ). We leave the proof of the equivalence of definitions 2.4 and 
2.6 to the reader. The definition 2.4 implies the following Lemma. Lemma 2.7 (Transitivity of s-sub-box 
re­lation) Let A, B, and C be k-dimensional boxes, Ij A is s-sub-box of B and B is s-sub­ box of C, then 
A is s-sub-box of C. The hierarchical subdivision is represented by the binary tree T. With each node 
v of the tree T, we store a box B(v) and a shrunken box SB(V). The boxes satisfy the following conditions. 
1. For any node v, the boxes B(v) and SB(V) are c-boxes. 2. For any node v, the box Sl?(v) is a s­sub-box 
of B(v). 3. For any node v, SB(V) nS = B(v) nS.  4. If w has two children u and v, then boxes B(u) 
and B(v) are the results of an almost middle cut of the box SB(W). 5. If v is a leaf, then IS (7 SB(v)/ 
= 1 and B(v) = SB(V). For a point p c S corresponding to the leaf v, let B(p) denotes the box B(v). 
 Let parent(v), Zsorz(v), and T-son(v) denote parent, left son, and right son of the node w of 2 . Two 
nodes with the same parent are siblings. 3 The maintenance of the subdivision In this Section we shall 
show how to maintain the tree T under insertions and deletions of points. The deletion is simpler than 
insertion and we consider the deletion first. Let p be a point to be deleted. Let us w be a leaf corresponding 
p, i.e. p c B(w), v be the parent of w and u # w be the sibling of v. We consider 2 cases. 1) u is a 
leaf (see Fig. 1 a)). Then set SB(V) = B(v) and delete the leaves u and w. 2) u is an internal node (see 
Fig. 1 b)). Then delete the node w, set B(u) = B(v), and collaps the edge (u, v), i.e. set parent(u) 
= parent(v), delete the node v, and rename the node u as v. insertion v u deletion / L a) L i insertion 
v v wu deletion ~ A b) Figure 1: Updating the dynamic tree. a) The inserted point p belongs to l?(v). 
The deleted point p belongs to B(u) where u is a son of v. b) The inserted point p belongs to l?(v) \ 
SB(V). The deleted point p belongs to l?(w). Now consider the insertion. Let p be a point to be inserted. 
The insertion algorithm has two steps. At first we find the smallest box contained the point p. Then 
we update a finite set of nodes and boxes of the tree 2 . The first step uses the point location algo­rithm 
which is described in Section 5. After point location there are 3 cases. 1. The point p does not belong 
to B(v.oot), where vrOOt is the root of T. 2. The point p belongs to the box l?(v), where v is a leaf 
(see Fig. 1 a)). 3. The point p belongs to the set B(v) \ S~(v) for some node v (see Fig. 1 b)).  The 
cases 1 and 2 can be handled similar the case 3. Consider the case 3. We want to construct the box D 
and the almost middle cut of D into the boxes D1 and D2 that satisfy the following conditions 1) the 
box D is a s-sub-box of B(v), 2) the box S13(v) is a s-sub-box of Dl, and 3) the point p ~ Dz. After 
finding ~ we remove the edges from v to children v and v , create two nodes u and w below v, add edges 
joining u and v , v , and set S13(u) = Sl?(v), l?(u) = Dl, Sl?(v) = D, B(w) = DJ (see Fig. 1 b)). Denote 
S13(v) = [al, bl) x . . . x [a~,bk). The algorithm uses a box D and repeatedly shrinks the box D until 
the almost middle cut of D is found. Initially D = l?(v). De­note D = [all, el) X . . . x [dk, ek). After 
each iteration of the algorithm 1) the box D is a c-box and s-sub-box of B(v), 2) the box SB(V) is a 
s-sub-box of D, and 3) the box D contains the point p. The algorithm has O(k) iterations because after 
each iteration the number of coordinates a;, bi coincided with endpoints of [di, e;) is increased, i.e. 
~$=1 I{a,, bi} n {d,,et}l is in­creased. We omit details but describe the ba­sic procedure. procedure 
middle-cut(D) (* almost middle cut of the box D = [dl, el) x ... x [dk, ek) *) 1) Find i such that e, 
 di is maximal. In Step 2 we shall choose const ~ [di, ei) to par­tition D by the hyperplane ~, = const. 
2) If a, or b, lies on middle interval of [d,, e;), then const = ai or const = b,, re­spectively. Otherwise 
the interval [a,, bi] does not intersect the middle interval of [d,, e,). Without loss of generality 
bi < 2d*~e1. Choose const = rnax( 2dt~eI, 2bi dz). 3) Partition the box D by the hyperplane xi = const. 
If this hyperplane partition the box SB(V) and the point p, the cut of D into the boxes Dn{z, ~i < const} 
and Dn{x, z, z const } is almost middle cut which satisfies above conditions (1), (2), and (3). In this 
case we stop the iterations. Otherwise one of these boxes contains both the box SB(V) and the point p. 
Choose this box as D. 4) End of procedure. Theorem 3.1 Let the dimension k is Jized and the point location 
takes COST time. The hierarchical subdivision can be maintained in O(1) + COST time per insertion and 
O(1) time per deletion. 4 The maintenance of the closest pair To maintain the closest pair we shall 
store the set E of some pairs of points of S. Definition 4.1 A point p E S is a near­est neighbor of 
q if, for any r G S \ {q}, ~(P, q) < d(q, r). For points p, q c S, we call the pair (p, q) a neighbor 
pair if p is the near­est neighbor of q and vice versa. The set E contains the neighbor pairs. It is 
clear that the closest pair of S is a neighbor pair of S and the closest pair belongs to E. Let a heap 
H stores the distances of the pairs of E. The heap item is the pair of the points. The key of the item 
(p, q) is the Lt­distance d(p, q). The pair of points with min­imal key is a closest pair of S. With 
each point p ~ S, we store a list EP = {q I (P, !7) ~ E}. with each Point q in EP} we store a pointer 
to the item (p, q) of the heap H. The set E satisfies the following property. Invariant. For any distinct 
points a, b ~ S, if the pair (a, b) does not belong to the set E then there exists a node v such that 
1. l?(a) (1 l?(v) = 0, and 2. d(l?(v)) s 2d(B(a)), and 3. dti~(a, l?(v)) s 3cl(l?(v)), and 4. d~..(a, 
l?(v)) < d(a, b).  Lemma 4.2 Let the invariant holds for the set E. Then the set E contains the neighbor 
pairs of S. Let Nk be a constant independent of n. (N~ depends on the dimension k and the metric L,. 
One can prove that N~ ~ (27k + l)k.) Theorem 4.3 Let the invariant holds for the set E. IJ for apoint 
p ~ S, the set EP contains at least Nh+l pairs, then there exists the point q ~ EP such that the invariant 
holds for E\ {(P, q)} Theorem 4.3 ensures the existence of a set E such that, for any p s S, the cardinality 
of EP is at most 0(1). Theorem 4.3 follows from Theorem 4.4 which is useful in the insertion algorithm. 
To find a set EP, for an inserted point p, we use a search on the dynamic tree. We need to limit the 
number of nodes that are used in search at the same time. Let V = {v~,..., ?.)N} be a set of these nodes. 
We as­sociate the set Si = B(v, ) \ UBi~,jgB(~,) ~(vj) with every node vi E V. Theorem 4.4 Let p be a 
point of S, V = {VI,..., vN} be a set of nodes of T, and E be a set of some point pairs. Let E satisfies 
the conditions of the invariant and Epn S, # (1for i= l,.. ., Nh. If N > Nk, there exists i such that 
the invariant holds for E \ {(p, q) I q 6 EP fl Si}. (Choosing of i does not depend on layout of the 
points of EP in the associated sets). The cost of finding i is O(kN~). The insertion of the point p causes 
inser­tions of some pairs into E and deletions of some pairs from E. Let us look at the updates of boxes. 
Note that the boxes, corresponding to the nodes, are only insert and, in the case fl(vrOOt), are enlarge. 
Hence to provide that the invariant holds for E we need not to insert a pairs that are not incident to 
inserted point. Using the dynamic tree we find at most Nh pairs that are adjacent to p. Add these pairs 
into E. Now in fact the invariant holds for E. However, for some points, the number of in­cidented pairs 
may exceed Nk. These points are adj scent to p and can be determined when we add a pairs into E. For 
these points, we remove some pairs from E using Theorem 4.4. Now we consider the deletion of the point 
p. The deletion causes insertions of some pairs into E and deletions of some pairs from E. Delete the 
pairs adjacent top, i.e. {(p, q) Iq~ s>(A fl) ~ ~} Note that alvf aYs twoboxes size invariant if, for 
each edge e to one of its are deleted. These boxes are the results of an almost middle cut of the box 
S.l?(parent(w)) where the node w corresponds to p. We consider the deletion of the box II(v). Let the 
pair (a, b) was deleted by conditions of the invariant for node v. Then d(.B(a)) > d(B(v))/2 and d~in(a, 
B(v)) s 3d(13(v)). One can show that the number of such points is at most 0(1). The argument is similar 
to the proof of Theorem 4.4. Let A(v) denote this set, i.e. A(v) = {a E S I d(B(a)) > d(B(v))/2 and dtin(a, 
l?(v)) s 3d(Il(v))}.  To find a set A(v) we use a search on the dynamic tree. As in finding of 13P we 
bound the number of nodes that are used in search at the same time. For each a c A(v), we find the set 
Ea. This gives the set E such that the invariant holds for E. 5 Dynamic tree In this Section we shall 
describe the dynamic tree. Using the dynamic tree, we shall im­plement the point location and the search 
for the sets EP and A(v). A dynamic tree A(T) based on the binary tree T has the same nodes and the same 
edges as T. The dynamic tree is a partition of edges into two kinds, solid and dashed, with prop­erty 
that each node has at most one child linked to it by a solid edge. Thus the solid edges define a collection 
of solid path that par­tition the vertices. (A vertex with no incident solid edge is a one-vertex solid 
path). The head of the path is its bottommost node; the tail is its topmost node. For a node v of T, 
let size(v) be the number of nodes in the subtree of T rooted at v. Let (v, w) bean edge of T from v 
to its parent w. The edge is heavy if size(v) > size(w)/2 and light otherwise. A node v of A(T) fulfills 
the children, e is solid if it is heavy and light if it is dashed. We say that the size invariant holds 
for the dynamic tree A(T) if it holds for each node of T. A solid path is represented by a path tree. 
We use globally biased binary trees [5] to im­plement path trees. A biased binary tree stores an ordered 
sequence of weighted items in its leaves. The weight of a node v of T (and corresponding leaf of biased 
binary tree) is defined as size(v), if no solid edge enters v weight(v) = szze(v) size(w), if the solid 
edge (w, v) I enters v The weight of an internal node of biased bi­nary tree is inductively defined 
as the sum of the weight of its children. Each node v of biased binary tree has an in­teger rank denoted 
rank(v) that satisfies the following properties: (i) If v is a leaf, rank(v) = [log weight(v)]. If v 
is an internal node, rank(v) ~ 1+ [log weight(v)]. (ii) If node w has parent v, rank(w) < rank(v), with 
the inequality strict if w is ex­ternal. If w has grandparent u, rank(w) < rank(u).  Each internal node 
w of biased binary tree contains four pointers [24]: blefi(v) and bright(v), which point to the left 
and right child of v, and bhead(v) and btail(v), which point to the head and tail of the subpath cor­responding 
to v (the leftmost and rightmost external descendants of v). For a topmost point v of a solid path P, 
there is the pointer pt.rooi(v) to the root of the path tree for P. Lemma 5.1 ([24]) If v is a leaf of 
a biased binary tree with root u, the depth of v is at most 2(rank(u) rank(v)) ~ 2 log(weighi(u)/weight( 
v)) + 4. The updates of T can be performed using the following operations [5] on rooted trees. Zink(v, 
w): If v is the root of one tree and w is a node in another tree, combine the trees containing v and 
w by adding an edge joining v and w. cut(v, w): If there is an edge joining v and w, delete it, thereby 
breaking the tree con­t aining v and w into two trees, one cent aining v and one cent aining w. The time 
bound of these operations is O(log n). This gives the following result. Lemma 5.3 The dynamic tree can 
be maintained under insertions and deletions of points in O(log n) time per update. In the rest of this 
Section we discuss the search algorithms. We have to implement the point location and the search for 
the sets llP and A(v). Our point location algorithm is similar to the algorithm of Schwarz [21]. function 
pointlocation(p) v := root(l ) while v is an internal node of T do (* Note that p c B(v) and v is the 
topmost node of some path P *) u := pi-root(v) (* u is the root of the path tree for P *) while u is 
an internal node of the path tree do if p G B(btazl(blejt(u))) then U := bright(u) else u := tdeft(u) 
fi od (*u is the bottommost node of the path P such that p G B(u) *) V:=U if the edge (v, rson(v)) is 
dashed and p G B(rson(v)) then v := rson(v) else if the edge (v, Zson(v)) is dashed and p E B(lson(v)) 
then ?J := ken(v) else return v fi fi od  return v end (* of the function *) It is clear that the point 
location algorithm is correct. Let us analyze the running time of the algorithm. Let ~1, . . . . FI be 
the solid paths that are searched during the algorithm. Letul,. ... ul be the roots of path trees and 
VI, ..., vl be the bottommost nodes on path trees that are searched. Note that vi is the parent of Ui+l 
in T for z = 1,...,1 1. The number I of paths is at most log n by the size invariant. The depth of v, 
in the path tree for Pi is at most 2(rank(ui) rank(vi)) by Lemma 5.1. For z = 1,...,l, Ta72k(v~)>)> 
~ank(ui+l ) by definition of rank. The total running time of the point location algorithm is O(log n 
+ Zf=, 2(rank(ui) rank(vi))) = O(log n + rank(u~) rank(q)) = O(log n). Now we shall describe the searching 
for the sets EP and A(v). We consider this prob­lem as the point location problem for at most O(1) points 
(lV~ points for EP). In fact we can build the search tree such that 1. the external nodes corresponds 
the points S, and 2. the path from the root of the search tree to an external node v corresponds to 
the nodes of the path trees that are searched during the point location for the point corre­sponding 
to v.  The search for the sets EP and A(v) ap­plies the breadth-first search on the search tree. node-set 
denotes a set of nodes that is stored in the breadth-first search. We use the pointer depth(v) that is 
a depth of the node v in search tree. For simplicity we extend the pointers btail to the external nodes 
of any path trees. (It is not necessary to store these pointers). Using Theorem 4.4., the procedure . 
refzneo finds at most Nk nodes among the nodes {btail(v) I v ~ node_set} and removes another nodes from 
node.set. function searcho (* the search for EP or A(v) *) v := pt_root(root(T)) node-set := {v} depth(v) 
:= O while there is a node v in node-set such that l%ail(v) is an internal node of T do v is a node in 
node-set with minimal depth such that Mail(v) is an internal node of T if v is an internal node of some 
path tree then node-set := node-setu {Meft(v),h right(u)} depth(tdeft(v)) := depth(v) + 1 depth(twight(v)) 
:= depth(v)+ 1 else (* v is an external node of some path tree *) u := btail(v) (* u is the corresponding 
node of vin T *) if the edge (u, rson(u)) is dashed then w := pt-root(rson(u)) node-set := node-set U 
{w} depth(w) := depth(v) + 1 .4 fi if the edge (u, /son(u)) is dashed then w := pt-root(lson(u)) node-set 
:= node-set U {w} depth(w) := depth(v) + 1 fi fi node-set := node-set \ {v} if ]node-set I > Nk then 
refine({btail(v) I v c node_set}) (* by Theorem 4.4 for EP and analogous result for A(v) *) fi od return 
the points corresponding the nodes btaii(v) for v c node_set end (* of the function *) Finally, we formulate 
the main result. Theorem 5.4 There is a data structure of size O(n) that maintains the closest pair of 
S in O(log n) time per update. 6 Conclusion We have presented an algorithm for main­taining the closest 
pair in O(log n) time per update, using O(n) space. The running time of the algorithm is optimal up to 
a constant factor in the algebraic decision-tree model of computation. The algorithm can be adapted (by 
changing some constants, includ­ing N~) for another metric such that d(p, q) = O(d~ (p, q)). In fact 
algorithm may give the list of the closest pairs (if any) in the time proportional to its number. The 
algorithm maintains a set E of point pairs that contains the neighbor pairs. Unfortunately our hierarchical 
subdivision does not allow efficiently maintain the set of the neighbor pairs, It would be interesting 
to solve the problem of the neighbor pairs main­tenance with O(log n) update time and O(n) space. Acknowledgment. 
The author thanks Emo Welzl for comments and pointing out to the paper of Arya et al. [3] and the paper 
of Callahan and Kosaraju [10]. (Unfortunately, when I was writing this paper I did not know about these 
results. )  References <RefA>[1]S. Arya and D. M. Mount. Approximate Nearest-Neighbor Queries in Fixed Di­mensions. 
Proceedings 4th Annual Sym­posium on Discrete Algorithms, 1993, pp. 271-280. [2] S. Arya, D. M. Mount, 
N. S. Netanyahu, R. Silverman, and A. Wu. An Opti­mal Algorithm for Approximate Nearest-Neighbor Searching. 
Proceedings 5th Annual Symposium on Discrete Algo­rithms, 1994, pp. 573 582. [3] S. Arya, D. M. Mount, 
N. S. Netanyahu, R. Silverman, and A. Wu. An Opti­ mal Algorithm for Approximate Nearest- Neighbor Searching. 
(revised version), 1994. [4] M. Ben-Or. Lower Bounds for Algebraic Computation Trees. Proc. 15th Annual 
ACM Symp. Theory Comput., 1983, pp. 80-86. [5] S. W. Bent, D. D. Sleator and R.E. Tar­jan Biased Search 
Trees. SIAM Journal of Computing, 1985, 14, pp. 545-568 [6] J. L. Bentley and M. I. Shames, Divide­and-Conquer 
in Multidimensional Space. Proc. 8th Annual ACM Symp. Theory of Computing, 1976, pp. 220-230. [7] M. 
Bern, D. Eppstein, and S.-H. Teng. Parallel Construction of Quadtrees and Quality Triangulations. Algorithms 
and Data Structures, Third Workshop, WADS 93, Lecture Notes in Computer Science 709, Springer-Verlag, 
1993, pp. 188-199. [8] S. N. Bespamyatnikh. The Region Ap­proach for Some Dynamic Closest-Point Problems. 
Proc. 6th Canadian Conf. Comput. Geom., 1994. [9] P. B. Callahan and S. R. Kosaraju. A Decomposition 
of Multi-Dimensional Point-Sets with Ap­plications to k-Nearest-Neighbors and n-Body Potential Fields. 
Proceedings 24th Annual AMC Symposium on the Theory of Computing, 1992, pp. 546 556. [10]P. B. Callahan 
and S. R. Kosaraju. Algo­rithms for Dynamic Closest Pair and n-Body Potential Fields. Proc. 6th Annual 
ACM-SIAM Symposium on Discrete Al­gorithms, 1995. [11]Y.-J, Chiang, F. T, Preparata, and R. Tamassia. 
A Unified Approach to Dy­namic Point LocationJ Ray Shooting, and Shortest Paths in Planar Maps. Proc. 
4th ACM-SIAM Symp. on Discrete Algorithms, 1993, pp. 44-53. [12] R. F. Cohen and R. Tamassia. Combine 
and Conquer: a General Technique for Dynamic Algorithms. Proc. First Europ. Symp. on Algorithms, Lecture 
Notes in Computer Science. Springer-Verlag, 1993. [13] M. J. Golin, R. Raman, C. Schwarz, and M. Smid. 
Randomized Data Structures for the Dynamic Closest-Pair Problem. Proc. 4th Annual ACM-SIAM Symp. on Discrete 
Algorithms, 1993, pp. 301-310. [14] M. J. Golin, R. Raman, C. Schwarz, and M. Smid. Simple Randomized 
Algorithms for Closest Pair Problems. Proc. 5th Canadian Conf. Comput. Geom., 1993, pp. 246-251. [15] 
S. Kapoor and M. Smid. New Techniques for Exact and Approximate Dynamic Closest-Point Problems. Proc. 
10th An­nual ACM Symp. Comput. Geom., 1994, pp. 165-174. [16] H.-P. Lenhof and M. Smid. Enumerating 
the k Closest Pair Optimally. Proc. 33rd Ann. IEEE Symp. Found. Comput. Sci., 1992, pp. 380-386. [17] 
F. P. Preparata and M. I. Shames. Com­putational Geometry: An Introduction. Springer-Verlag, New York 
Berlin Hei­delberg Tokyo, 1985. [18] F. P. Preparata and M. I. Shames. Comp­utational Geometry: An Introduction. 
Springer-Verlag, New York Berlin Hei­delberg Tokyo, second edition, 1988. [19] J. S. Salowe. Shallow 
Interdistance Se­lection and Interdistance Enumeration. International Journal of Computational Geometry 
&#38; Applications, 2, 1992, pp. 49-59. [20] M. I. Shames and D. Hoey. Closest-Point Problem. Proc. 16th 
Annual IEEE Symp. Found. Comput. Sci., 1975, pp. 151-162. [21] C. Schwarz. Data Structures and Al­gorithms 
for the Dynamic Closest Pair Problem. Ph.D. Thesis, Universitat des Saarbrucken, 1993. [22] c. Schwarz 
and M. Smid. An O(n log n log log n) Algorithm for the On-Line Closest Pair Problem. Proc. 3th ACM-SIAM 
Symp. Discrete Algorithms, 1992, pp. 280-285. [23] C. Schwarz, M. Smid, and J. Snoeyink. An Optimal Algorithm 
for the On-Line Closest-Pair Problem. Proc. 8th Annual ACM Symp. Comput. Geom., 1992, pp. 330-336. [24] 
D. D. Sleator and R. E. Tarjan. A Data Structure for Dynamic Trees. Journal of Computer and System Sciences, 
26, 1983. [25] M. Smid. Dynamic Rectangular Point Locationj with an Application to the Closest Pair Problem. 
Technical Re­port MPI-I-91-101, Max-Plank-Institut furInformatik, Saarbrucken, Germany, 1991 [26] M. 
Smid. Maintaining the Minimaz Dis­tance of a Point Set in Less Than Linear Time. Algorithms Rev., 2, 
1991, pp. 33­ 44. [27] M. Smid. Maintaining the Minimal Dis­tance of a Point Set in Polylogarithmic Time. 
Discrete &#38; Computational Geom­ etry, 7, 1992, pp. 415 431. [28] K. L. Supowit. New Techniques for 
Some Dynamic Closest-Point and Farthest-Point Problems. Proc. l-st Annual ACM-SIAM Symposium on Discrete 
Al­ gorithms, 1990, pp. 84-90. [29] P. M. Vaidya. An Optimal Algo­rithm for All-Nearest-Neighbors Prob-Jem. 
Proceedings 27th Annual Sympo­sium Found. Comp. Se., 1986, pp. 117 122. [30] P. M. Vaidya. An O(n log 
n) Algorithm for All-Nearest-Neighbors Problem. Dis­crete Comput. Geom., 1989, pp. 101 115 </RefA>
			
