
 An Interruptible Algorithm for Perfect Sampling via Markov Chains James Allen Fill* Johns Hopkins University 
Baltimore, MD 21218 Abstract For a large class of examples arising in statistical ph~ics known as attnxtiue 
spin @ems (e.g., the Ising model), one seeks to sample from a probability distribution T on an enormously 
large state space, but elementary sampling is ruled out by the infeaaibility of calculating an appropriate 
normalizing constant. The same difficulty arises in computer science problems where one seeks to sample 
randomly from a large finite distributive lattice whose precise size cannot be ascertained in any reasonable 
amount of time. The Markov chain Monte Carlo (MCMC) approximate sampling approach to such a problem is 
to construct and run for a long time a Markov chain with long-run distri­bution r. But determining how 
long is long enough to get a good approximation can be both analytically and empiri­cally difncult. Recently, 
Jim Propp and David Wilson have devised an ingenious and efficient algorithm to use the same Markov chains 
to produce per$xt(i.e., exact) samples from T. How­ever, the nmning time of their algorithm is an unbounded 
random wuiable whoee order of magnitude is typically un­known a priori and which is not independent of 
the state sampled, so a naive user with limited patience who aborts a long run of the algorithm will 
introduce bias. We present a new algorithm which (1) again uses the same Markov chains to produce perfect 
samples from n, but is baaed on a different idea (namely, acceptance/rejection sampling); and (2) eliminates 
user-impatience bias. Like the PropP-Wilson algorithm, the new algorithm applies to a general class of 
suitably monotone chains, and also (with modification) to anti-monotone chains. When the chain is reversible, 
naive implementation of the algorithm uaw fewer transitions but more epaoe than Propp-Wilson. When fine­tuned 
and applied with the aid of a typical peeudorandom number generator to an attractive spin system on n 
sits Waearch supported by NSF grants DMS-93-11367 and DMS­9626756. Mailing addIees James Allen Fti, The 
Johns Hop kins Univemity, Department of Mathematical Sciences, Whita­head Hall, 34th and Charles Stm%s, 
Baltimore, MD 2121S-26S2. Email addr~ jirn6110jhu.edu. using a random site updating Gibbs sampler whose 
mix­ing time T is polynomial in n, the algorithm runs in time of the same order (bound) as Propp-WMm 
[expectation O(T log n)] and uaee only logarithmically more space [expec­tation O(n log n), VS. O(n) 
fir Propp-Whn]. If truly ran­dom bits are used instead, then the time and space bounda for a fine-tuned 
implementation of the new algorithm are no worse than those for Propp-Wilson. The full paper is available 
on the author s web PEW% at the Um http: //WU .mts. jhu. edul-f ill/  10vewiew In this extended abstract 
we will present an efficient new algorithm for perfect (i.e., exact) distributional sampling that comblnee 
the ideas of rejection sampling and Markov chain Monte Carlo (MCMC). In Section 2 we describe a large 
class of examples (namely, attractive spin systems) arising in statistical physics and computer science 
where el­ementary perfect sampling from a distribution of interest is desirable but infeasible due to 
the virtual incmmputability of a normalizing constant. The usefulness of MCMC for such problems is explained 
in Section 3, and background mate­rial on monotonicity is discussed in Section 4. In Section 5 we briefly 
review a stationary sampling scheme for mono­tone chains recently developed by Propp and Wilson that 
is baaed on backward coupling, and we point out a subtle bias introduced by naive use of their algorithm. 
~n Sec­tion 6 of the full paper we ameas the extent of this bias and analyze the scheme s time and apace 
requirements.] In Section 6 we preeent, and in Section 7 we analyze, a new algorithm based on rejection 
sampling which eliminates the blaa. [As discussed in Section 9 of the full paper, this algo­rithm is 
closely connected with the construction of a certain minimal strong stationary time [1] [2] [12] [17].] 
A suitable modification of either algorithm allows for the treatment of the anti-monotone chains described 
in [22]; see [!2-4]for a pioneering application of the Propp-WUson algorithm in this direction. (In paesing, 
and in connection with [u], we note that the spatial statistics community has fallen on the idea of pertit 
simulation with avid enthusiasm see also [21] and [25].) For reversible chains, the new algorithm is 
faster, in the precise sense that a bound on the expected number of tran­sitions is of smaller order 
of magnitude than the correspond­ing bound for the backward coupling algorithm. However, the new algorithm 
s memory space requirement turns out to be too large for practical application to attractive spin system 
problem, in Section 8 we fine-tune the algorithm for these problems to make it competitive in time and 
space requirements with the backward coupling algorithm. In Section 9 we give a detailed comparison of 
the Propp- Wilson algorithm and our new one. A reader familiar with the Propp-Wilson algorithm and its 
applications and unin­terested in theoretical detaila might wish to proceed directly to Sections 6.2, 
8.1, and the summary 9.2. Notation: A standard mertaure of discrepancy between two probability distributions 
p and p on a finite state S is the totul vutition (or just variation) distance, a worst-case absolute 
error 11P-P 11:= ~: 1P(A) -P (M Given a Markov chain P on S with long-run dktribution r, we write (1.1) 
d(t):=~1~ 11P (X, .) -P (y, .)11 and (1.2) ~1 := min{t >0: ~(t) ~ e l}. The mixing time parameter T1 
is called the variation thnd­old. Analysis of the new algorithm will involve separation [3] [12] and 
ita corresponding threshold: (1.3)  P( ) =xw+p%)l (1.4) T~ 1):= rnin{t>0: aep(t) < e l}. 2 A caaa fa 
MCMC: attractive spin syatams The class of exampleJT known as athuctive spin sgdems (cf. [26]) nicely 
illustrates the usefulness of finite-state MCMC methods. This is a class of statistical ph~ics models 
which includes the Zsing model of ferromagnetisrn and is easily ex­tended to include the more general 
Potts model. See [29], whose terminology we follow, for a superbly written (and more detailed) d~usaion 
of these models and their central importance in the study of st atistical mechanics, with point­ers to 
the vast literature. The same models are also used in image pro~ing for noise reduction [8] [5] [20] 
[29]. Other frequently-studied attractive spin s@erns are the voter mod­el (e.g., [3] (Chapter 14)) and 
contact ptucess (e.g., [26]). Before proceeding to definitiona, we note a connection with problems in 
computer science. Propp and Wkm [29] have shown how the uniform distribution on the finite dis­tributive 
lattice of order ideals (equivalently, of antichaina) of a given partially ordered set can be viewed 
as an attrac­tive measure n on a certain spin system. Thus methods we shall describe in Sections 5, 6, 
and 8 for perfect sampting from attractive apin systems will also apply for example to generating random 
independent sets in a bipartite graph or random pert&#38;t matchings in a graph, since it is explained 
in [29] how such structure can be viewed as distributive latticea. To begin the description of an attractive 
spin system, comider a finite set V of vertices, regarded ss w tes. A con­jigumtwn x = (z*; u < V) amigns 
to each site u a @n G, either +1 ( up ) or -1 ( down ). Partially order the set S of configurations by 
declaring that x ~ y exactly when Zw~ yv for every v e V. Equivalently, we pmtially order the configurations 
by set inclusion, whereby a configuration is identified with the subset of sites where its spin is posi­tive. 
Write (x, Z t a) for the configuration whose spin at v is u and whose spins at other sites sgree with 
thcee for x. Now let r be a probability distribution on S and let x E S with r(x) > 0. Conaider updating 
x at a specified site v according to r conditionally given the spins at every w# V. That is, consider 
resetting (if necessary) the SPin at v to be +1 with probability (2.1) P (X, (X;z -+1)) := T(x, zv -+1)/[7r(x; 
z. + +1)+ 7r(Yqz + l)] aud 1 with the complementary probability P. (x, (x, z. + l)). Notice that these 
transition probabilities do not de­pend on z.. If P.(x, (x; ZV t +1)) is an increasing func­tion of x 
(in the partial order), we say that m is attmc­tzve.A famous example is the Ising model on a finite graph 
G= (V, E), as discussed in the full paper. Here T(X) is defined to be proportional to exp(O ~{v,w}=~ 
z.z.) with O~ O. A simple calculation for this model shows that P. (x, (Jqz. + +1)) =  F+MP(-2 ( l:)hence 
~ ~ attrutiw In applications, G is usually a rectangular or toroidal grid with n := IVI = 64 x 64 or 
128 x 128, for example. If 0 # O, it is plainly infeasible to calculate the normalizing constant or to 
sample in an elementary fashion from n. In such situationa one may resort to Mat-km chain Monte Carlo 
(MCMC), ss described in the next section. 3 Markov chainMonteCarlo In the general setting of a probability 
distribution m on a set S, the MCMC approach is to devise an ergodic (i.e., irre­ducible, aperiodic, 
and pcaitive recurrent) Markov chain X with state space S and stationary distribution n. To ob­tain a 
single observation with approximate distribution n, one starts X in some conveniently generated distribution 
To (for example, unit msss at a convenient state X0 . S), runs it for a long time t (we shall have more 
to say about this presently), and uses X: as the observation. Tkeating Xt as if it were exactly distributed 
according to ~, one can continue running the chain to obtain a dependent sample from r, or be somewhat 
wasteful and repeatedly restart the process to obtain an i.i.d. sample. For a dkxxsaion of such method­ological 
issues in MCMC, see Chapter 11, Section 4.3 in [3] and the references cited therein. We shall find it 
sufficiently interesting and challenging here to consider the problem of generating a sample of size 
one. The Metropolis algorithm (e.g., [3] (Chapters 11 and 12) or [13]) gives a quite general method for 
constructing such chains. In the setting of an attractive spin system, how­ever, we consider au alternative, 
namely, the Gibbs sarnpkr or heat-bath aZgtithm. Recall the definition (2.1) of the transition matrix 
(t m.) P. for updating of site v and note that it doea not require calculating the normalizing constant. 
Let P := n-l ~ ~cv Pw; that is, the chain P picks a ran­ dom site and updatea it. (This mndom site updating 
scheme has been chosen for detinitenesa. The common alternative P = P., . . . Pvm known as @ematic site 
updating, where 01,. .. , un is an arbitrary but fixed ordering of the sites, will be discussed in Section 
9.1.) It is easy to see that P is er­godic (on S = {-1,+1} , if r(x) > 0 for all x; see also Remark 6.1). 
This class of chains will serve as a running example throughout. fifinition 3.1 A Gibbs sampler with 
random site updating on an attractive spin system will be called an RS U chain. Given an ergodic Markov 
t.m. P, the distribution rt = noPt of the chain at time t will approach x in the long run. The key question, 
of course, is How long is the long run? Many heuristic diagncetic techniques have been devised to address 
this question for Markov chains, but the methods can encounter serious pitfalls [3], including metastability. 
Another approach is to analytically bound rates of conver­gence to stationarity. A tremendous amount 
of work has taken place along these lines in the last 15 ye-see [14] [3] [31] [11] for discussion and 
myriad references. But deriving such bounda is sometimes, aa described in [29], an arduous undertaking. 
A case in point is the Ising model. There are several MCMC algorithms for approximate sampling from n. 
With various restrictions on the underlying graph and the temper­ature, there are also accompanying rapid 
mixing bounds­bounds which imply that r~ is close to T when t is only poly­nomially large in IVI, which 
is the logarithm of the size of the state space. (See [13] [29] [31] for references.) However, the degrea 
and coefficierits involved in these bounds are typically so huge ss to make the bounds ineffective for 
real­sized problems. There are, furthermore, many attractive spin systems (e.g., random independent sets 
in a bipartite graph) for which there are no known bounds suilicient even to imply rapid mixing. An ideal 
remedy to MOMC difficulties would be a self­verifying algorithm that produces a perjectfy stationary 
ob­servation in time on the order of some measure ~ of the mixing time of the chain without using any 
explicit prior information about r. At first thought, it may come as a surprise that a self-verifying 
algorithm exists for a class of chains that includes all RSU chains. We present such an algorithm in 
Section 6. 4 Monotonicity Rapid stationary sampling for Markov chains with enor­mous state spaces, e.g., 
the stochastic Ising model on a 64 x 64 grid, demands some prior information about the t.m. P. Indeed, 
it is argued in [27] and in Chapter 9 of [3] that any pure simulation algorithm (i.e., P is unknown to 
the algorithm) for a generic irreducible IV-state chain cannot terminate without sampling a transition 
from every state, so that the running time is at least of order N. However, effi­cient simulation is 
possible when, as is true for MU chains, the chain is assumed monotone. Here is the definition. LMinition 
4.1 Let P be a t.m. on a partially ordered state space (S, <). We say that P is monotone if P preserves 
the partial order, i.e., if P(x,.) s P(y,.) stochaatically when­everx < y. Aa background, recall the 
following definitions [32] [23]. Call a subset I of a partially ordered set (pceet) S an onier ideal 
or down-set ifwhenever xEI andy<x,wehave Y E 1. The set of all order ideala is denoted J(S). Given two 
probability measures p and v on S, one says that p < v stochasticdy if P(1) z v(I) for all 1 . J(S). 
The product of monotone transition matrices is monotone. Monotonicity of P is guaranteed when one can 
couple transitiona using a monotone transition rule. Definition 4.2 A monotone tmnsition rule for at.m. 
P on a partially ordered state space (S, S) is a measurable func­tion ~ : S x U 4 S, together with a 
random variable U taking values in an arbitrary probability apace U, such that (1) ~(x, u) < ~(y, u) 
for all u . U whenever x < y and (2) P(~(x, U) = .) = P(x,.) for all x.  When a monotone transition 
rule exists, one can simul­tamcmsly generate transitions horn various states in such a way as to maintain 
ordering relations for each realization. Observe that each site update matrix Pw for an attractive spin 
system possemea a monotone transition ruhq indeed, the coupling can be simply redlzed by letting U be 
uniformly distributed on U = [0,1] and using (4.1) ~V(X, U) = (xxv+ -1) or (xzv + +1) according aa u< 
or > Pa(x, (x; zV t l)). The RSU chain also has a monotone transition rule Let U = {l,...,n} x [0, 1]; 
U = (Ul, U2), where U1 and U2 are inde­pendent random variables uniformly distributed on {1,..., n} and 
[0, 1], respectively; and (4.2) f(x, al,U2) = f wl (x, U2). Remark 4.3 For definiteness and simplicity, 
we shall assume that each RSU-chain transition generated using (4.2) is ex­ecuted in time of constant 
order. This seems reasonable in the case of the stochastic Ising model on a toroidal grid, for example, 
since the computation of (2.2) involves a sum of four spin values, regardless of n or v or x. Moreover, 
we shall adopt the assumption equally for all algorithms con­sidered in this papeq thus comparisons between 
algorithms will be fair even if the assumption is violated. Finally, we ~hall usually assume f?r simplicity 
that there exist elements Oand~in Ssuchthat O<z<iforallzcq this condition is also met for attractive 
spin sytema. @fhition 4.4 When a monotone transition rule and 6 and 1 exist for a given chain P, we shall 
say that the monotone case obtains. Remark 4.5 One might conjecture that a monotone transi­tion rule 
exists whenever P is monotine. Although this is true when the state apace S is linearly ordered, joint 
work with Motoya Machida [16] has shown this to be tldse for general poaets. So the monotone case entails 
a somewhat stronger condition than monotonicity of P. 5 A backward cxwplingalgorithmforthamonotonacaaa 
Propp and Whn [29] have devised a backward coupling, or coupZing @m the put, algorithm (call it PW) for 
eilicient exact sampling in the monotone case. Their algorithm is simple to describe. For t = 1,2,4,8,.. 
., start t~o copies (say, X and Y) of the chain at time -t,one in Oand the other in i. Run the two chains 
until time O, coupling the transitions by means of a monotone transition rule ~. If % = Yo = Z (say), 
we say that the trajectories of X and Y have cauleaced and return the value Z. (Note that Z is not necedsa* 
the state of firat coalescence.) Otherwise, restart the procedure with the next value oft. The time and 
space requirements of this algorithm are discussed in [29] and in Section 6.2 of the full paper. For 
Algorithm PW to work properly, it is essential, when the transitions from a given times to times+ 1 are 
generated by means of ~(x, U,), that the same value U. be used in every iteration of the &#38;loop. If 
we assume that the algorithm terminates with probability one (as is true, e.g., in the attractive spin 
system case), then it is not hard to show that Z -rr ezuctly. For this reason, Propp and Wilson describe 
their algorithm as one for exsct sampling from r, However, as Propp and Wllaon ([29], Section 2.1) point 
out, the running time of the algorithm and Z are not inde­pendent. Thus occurrences of catastrophic system 
failures (more likely for long runs than for short), or early termina­tions of long runs by an impatient 
user, will taint the sample with systematic bi~ observations that tend to take a long time to generate 
are underrepresented. ~n connection with user impatience, notice that if no output haa been gener­ated 
by the end of a given iteration, the user knows that, due to time-doubling, the waiting time to termination 
(ss measured by number of transitiona) will be greater than the total time expired to that point.] Remark 
5.1 We do not wish to overstate the importance of this bias, so several comments are in order here. (a) 
If suitable precautions are taken, a system crash need not Iesd to termination of a run. As a simple 
example of this, suppcse that Algorithm PW is implemented using a seeded pmmdorandom number generator 
for an RSU chain, as discussed at the end of Section 6.2 in the full paper. Pro­vided that the initial 
seed is written to disk before a run commences, the run can be started over after rebooting. Alternatively, 
one might wish to save partial results as the run progresses. (b) There would be little sense in stopping 
a run of Al­gorithm PW and beginning a new one, provided the imple­mentation allows for pausing a run 
and resetting the time­doubling scheme. After all, for fixed s ~ O, the conditional probability of coal-me 
fkom time (t +s) to time Ogiven the simulation over the time interval [ t, O] is minimized (over all 
choices of t and all possible simulation results) when t= O.  (c) In light of (b), a somewhat more realistic 
scenario is that of a user who, for a predetermined length of time t, re­peatedly runs the algorithm 
to collect observationa from n, and then quits, perhaps before and perhaps after the run in progress 
at the planned quitting time is completed, ob­taining the results Z1, Zz,. ... ZN(:) . Suppose that these 
observations will be used to estimate a functional Eg(Z) of m (where Z N rr) by the sample meang := ~(t)- 
~~~) g(zi). Curiously, when a run in progress is completed if sn only if no other observations have been 
collected, it can be shown that the resulting estimator ij is unbiased. On the other hand, if the observation 
in progress is always collected, then (due to length-biased sampling) the sample will be biased in favor 
OJ observations that t eke a long time to generate (in contrast to the bias against such okeervations 
caused by aborting long runs). In either case, it is important to realize that the wnditionai distribution 
of a fixed-duration sample given its size is not that of an i.i.d. sample. Instead, a user would be advised 
to use training runs to estimate the distr­ibution of running time, and then sample a fixed number of 
observations rather than for a Iixed computation time. For more on such use of training runs, see Section 
6,1 in the full paper. (d) We have adopted a rather harsh standard of bisa here and do not mean to single 
out the Propp-Wilson algo­ rithm for criticism. Indeed, consider the standard slgorithm for simulating 
a biased coin flip by a sequence of unbiased flips. To be more specific, suppose that independent random 
bits bl, b,... are generated sequentially until it is deter­mined whether or not the uniform random number 
.bl b ... (in binary notation) belongs to the interval [0, 1/3]. Given that a decision is reached after 
at most 2k (respectively, 2k + 1) bits have been generated, the probability of an af%­ mative decision 
is ~ [resp., ~1 l ,2k~1_l) < *]. So, for an ( impatient user, th~ algorithm is biased towards a negative 
decision. In light of our comments, perhaps bias should be read throughout es potential for carelessly 
inappropriate use. (e) See also the cautionary note in the lest paragraph of Section 6.3. A simplistic 
model of user-impatience bias is analymd in Section 6.1 of the full paper. Remark 5.1 indicates that 
the model provides a loose upper bound on the sort of blsa incurred in practice. In Sections 6 and 8 
we shall present alternative aJgo­rith.ms which handle RSU chains (among others) and elimi­nate the user-impatience 
bias. In passing, we offer some general remarks about per­fect simulation in general and backward coupling 
in partic­ular. See Chapter 4 in [3] and [24] for general discweion of perfect simulation and references 
to uses of backward cou­pling predating Algorithm PW. With a mmewhat differ­ent formulation, backward 
coupling has also been developed and employed effectively by Fees [18] and by Borovkov and F= [9] [10]. 
For infinite state space extensions and applica­tions of Algorithm PW, see [28]. For a variant of backward 
coupling using regeneration times, see [19]. 6 A new algorithm baaed on rejection sampling 6.1 &#38;lC&#38;OUnd 
To set the stage for the new algorithm, we review mme background material. Let S be a finite pact, and 
consider probability measures p and v on S. It is well known (e.g., Theorem 1 in [23]; see also [33]) 
that p S v (stochasti­cally) is equivalent to the existence of au upward kernel K such that v = pK, i.e., 
of a Markov t.m. K on S such that (1) for all x 6 S, the measure K(x,.) is supported on {y6S:Y> x}, md(2)for 
dly ES, weha~ v(y)= ZXES P(x) K(xtY) -l rec~l the definition P(x, Y) = m(y)P(y, x)/T(x) of the tirne-rwsrsd 
of a Markov t.m. P with stationary distribution n. For example, it is evident from (2.1) that each P 
is reversible with respect to n (i.e., P = P ); hence so is the RSU chain P = n-l xv Pw. The algorithm 
we shall present does not require reversibil­ity of P. Remark 6.1 For simplicity, we have supposed that 
the t.m. P of interest is ergodic, so that r(x) > 0 for all x E S. Whenj as discussed in Section 2, S 
is the Boolean algebra of all subeets of a fixdte poset V and P is the RSU chain with long-run distribution 
~ that is uniform over the collec­tion J(V) of order ideala of V, the aaeumption of ergodicity is violated 
but can be restored by a suitable restriction of attention to S = .7(V). We omit the details. We-aaa~e 
that ~ is monotone on S and that S pos­sesses O and 1, but we do not require that a monotone tran­sition 
rule exist for P. For each x G S, let pX := P(x, .). Monot.onicity of P is equivalent to the assumption 
that when x ~ y there exists an upward kernel KXY s KX,Y (.,.) such that py = pxKx,Y. We assume that 
the user can simulate transitions from the measure KX,Y (x ,.) whenever x ~ y and P(X, X ) >0. Suppose, 
fo~ example, that a monotone trmeition rule ~ does existfor P, i.e., that the monotone case obtains for 
P in the sense of Definition 4.4. It is then easy to check that one can use (6.1) Kx,y(X ,Y ) := P(j(y, 
u) = y If(x, u) = x ), y Gs (when x s y and P(x, x ) > O) for the upward kernels. In particular, if 
one can generate a random variable ~ (say) whose distribution is the conditional distribution of U given 
~(x, U) = x , then one can simulate an observation Y from KX,Y(X ,.) by setting Y = ~(y, ~). Exampie 
6.2 When we specialize to RSU chains, a straight­forward calculation establiahee the validity of the 
follow­ing simple method for generating Y (as in the preceding ~sgraph) when x # x (so that x and x disagree 
at a uruque site u). If ZV= 1 and x = (xzv ~ +1), then set Y = (y; y. -+1) (deterrninistically). If xv 
= +1 and X = (X; zw + l), then set Y to (y;~ - 1) with probability P.(y, (y; y. t l))/P. (x, (x; XV- 
l)) and to (y; ~ t +1) with the complementary probability. A method for generating Y in the more problematic 
case x = x is discussed in Section 10.1 of the full paper. 6.2 Tha algorithmintheganaralmonotoneaatting 
Let P bean ergodic t.m. with monotone time-reversal ~ on a pceet S poeeesaing a unique minimum (respectively, 
maximum) element b (resp., ~). Let KX,Y be upward kernels for ~, ~ discumed in Section 6.1. The proposed 
new algo­rithm to output a stationary observation runs as follows. In­dependently for t = 1,2,4,8, . 
. . . perform the following rOU­tinq stop when output is iirat obtained. For the lirat phase of the-routine, 
run the P-chain X for t steps starting iiom state O, recording the trajectory (XO, XI,. ... X~). Suppcw 
that Xt = Z. For the second phase, regard (Xt, Xt.l,. . . ,XO) .. ssatrajectmy (Xo, Xl,..., Xt) from 
the time-reversed chain X. Then, in synchrony with the evolution of X, build a second trajectory ~, which 
starts at state ~ and evolves according to the following one-step rule. Corresponding to each obaeNed 
transition, say from x to x , of X, let T choose the transition from its present state y as y with probability 
KX,Y(X , y ), y E S. (Notice that this construction gives X. ~ ~. for O< s ~ t.) If ~t = d, output z 
otherwise, erase all informa~lon and go on to the next value oft. Remark 6.3 The new algorithm beam superficial 
resemblance to techniques of Bessg and Clifford [6] [7] in a different set­ting, but we are unawm-e of 
any useful connections. 6.3 Proofof catYactnesa Why does the algorithm presented in Section 6.2 work? 
The bade reason is that each iteration of the twwphaee rou­tine is an implementation of rejection sampling 
(cf., e.g., Chapter 10, Section 2.2 of [30]). We use an observation from Pt (6,.) to simulate one from 
n. In order to effect this, one produces an upper bound c on the ratio n(z)/Pt (6, z) (subject to Pt(b,z) 
> O), generatee z according to P (b, .), and (conditionally) sccepta z as an observation from ~ with 
probability C-lT(Z)/P:(b, z). The unconditional probability of acceptance is then 1/c. Now (6.2) 7r(z)/Pt(b, 
z) = 7r(o)/F (z, 6), so the monotonicit y of P implies that we may choose c = @)/~t(i, @ and thus accept 
Z with probability The first phase of the routine samples from P*(6, .), and so the question in designing 
the algorithm becomes how to en­gineer a coin-ilip with probability ~t (~, ~)/~:(z) @ of heada. But, 
conditionally given that X starts at ~ and enda at z, thereverse trajectory X = (XO,..,, Xt) = (Xt,..., 
Xo) haa the distnbu~ion of a ~-trajectory conditioned to start at z and end at O. Moreover, the second 
phaae is designed pre­cisely so that the probability of acceptance is the desired P (i, o)/P (z, @: Lemma 
6.4 P(i, d) P(*t=61xo =z, xt=o, io= i)= ­P:(z, 6) -of. -Consid~r a modified sit-wtion where the trajectory 
X=(XIJ,..., Xt) is again a P-trajectory, but no longer conditioned to start at z nor to end at &#38; 
We can again build a second (coupled) trajectory ~ starting at state ~ and evolving as in the second 
phaae of the algorithm if X moves from x to x , then y moves from y to ~ with ~robability KX,Y(X , y 
). As before, we will have X. < Y, for O < s < t; in particular, Vt = h entails ~ = 6. Moreover-, in 
t~s rnod@d setting it is eaay to verify that X. and Y = (Yo,..., Yt) are independent and that ~ is (marginaUy)a 
Markov chain with t.m. ~. Thus, returning to the setting of the algorithm, we have P(%dlxo =z, xt=b, 
% o=i) P(xt=o, Yt +&#38;z, vo=i) . P(xt=iqxo=z, *o=q P(Yt=dlxo=z, Yo=i) ~t(i,~) . = ~ Pt(z, (i) as desired. 
. The unconditional probability of acceptance is Ft(i,0) P (O, i)  (6.3) c 1 ~=- 7r(l) which (by ergodicity) 
converges to 1 as t + 00. It follows that the ccmdtional probability that the algorithm termi­nates at 
the ith iteration given failure to do so previously converges to 1 as i becomes large. A fortiori, the 
algorithm terminates with probability one. The claim of unbiaaednas with respect to user impa­tience 
followa easily from the very nature of rejection sam­pling together with the fact that all information 
is erased after each iteration. However, we warn that for this claim to be valid, user impatience must 
be expressed in terms of number of transitions generated, not real computation time. Otherwise, care 
must be taken to program each tran­sition to take the same (worst-case) amount of time. Wil­son [35] 
points out that this will caww a crippling slowdown for chains with highly vwiable computation time for 
transi­tion see Section 4.2 of [29] for such an example. 7 Performance of the new algorithm From the 
description of the new algorithm presented in Section 6.2 it is clear that one can analyae both the time 
and space requirements by studying the distribution of F, defined to be the number of forward P-transitions 
generated. The algorithm will be fine-tuned for RSU chains in Section 8, and in Section 9 we wmpare the 
performance of the new algorithm with that of Algorithm PW, both generally and alao specifically for 
RSU chains. The following theorem briefly summarizes the perfor­mance of our algorithm and is proved 
in Section 8 of the full paper. Theorem 7.1 LetF &#38;note the (mndom) number of P­ tmnsitti genemted 
by the algtithm in Sectwn 6.2. Then EF = O(Tf)), where T~l) is Ube mizing time pamtneter given by (1.4). 
8 A firn+tuned algorithm for RSU chains 8.1 An algmithmrequiringleasmemaryAlgwithmRSUS As explained in 
Section 7 (see cap. Theorem 7.1), the algorithm of Section 6.2, which stores the entire forward (1)trajectory, 
runs in time of the order of the mixing time T1 of P andspaceoforder~(l)u whereuiathememoryrequired 
to store a single state. In the csse of R.SU chains, u = n and so the space requirement is of order #) 
n. We cannot hope to reduce the order of the running time. However, our algorithm s space requirement 
is typically much larger than the corresponding bound O(T1 (log n)z + n) derived for PW in the full paper. 
Thus we seek to modify our algorithm for RSU chains to reduce the memory requirement. In the full paper 
we motivate and treat the following lin­tuned algorithm, which we christen Algorithm RSUS (for Random 
Site Updating Sampler), and which is baaed on the observation for the ti)c algorithm that one can reconstmct 
a trajectory segment (X., ..., X.) = (Xt ~, ..., X: r) and build the corresponding wgment of ~ horn knowledge 
of just Xt ., the corresponding generator seed at that time, and % .. Algorithm RSUS differs from the 
basic, algorithm only in the way that the ith iteration (with t = 2 1) is carried out (i= 1,2,.. .). 
For Algorithm RSUS, this is done by calling COupledReverae(i 1, b} initialaeed, i). The procedure Ckmpledleverae(h, 
~, startaeed, y), listed b­low, takes as input the binary logarithm h of an interval length 2h, an initial 
configuration xo and uniform random number generator seed startaeed for a forward trajectory (X), and 
an initial co-ation y for an appropriately cou­ pled reverse trajectory (Y). It returns the tinal configura­tion 
in the ~-trajed.ory. The procedure ForwardStep(x, seed) is essumed to take an initial configuration 
x and a given seed, use first the generator to produce a U-value and then the transition rule ~ of (4.2), 
and return the pair (~(x, U), coreapondingly updated seed). The procedure CoupledReverseStep(xo, startseed, 
y) is assumed to carry out CoupledReverse(O, XO,startseed, y) correctly we do not present the details 
of CoupledRevera­eStep, but note for future reference that it involves a single call to the procedure 
ForwardStep. CoupledReverse(h, XO,startseed, y): if h=O return COupledReverseStep(xO, startaeed, y) else 
x+~ seed + Startaeed for g 4-1 to 2h 1 (x, seed) t Forwardstep(x,seed) y-COupledlleve=(h -1,x, seed, 
y) return CoupledReverae(h 1, ~, startaeed, y) 8.2 Performanceof AlgorithmRSUS The following theorem 
briefly summarizes the time and space requirements of Algorithm RSUS and is proved in Sec­tion 10.2 of 
the full paper. Theorem 8.1 nmning time of Algorithm RS.VS The ezpectaii9 O(T1 1) lOgT~l)), and the ezpected 
space requirement for dy­ namic me-is O(n log r~l)). Here T1 1) is the mting time pamrneter uen by (1.4) 
for the mndorn site update chain p = n-l ~P.. f 9 Compiwison of algorithms 9.1 Mixing tim~ reversibility,scheme6 
andotherupdating The Propp-Wilson algorithm [29] uses monotone P while the algorithm introduced in thw 
extended abstract assumes monotone time reversal ~. In comparing the algorithms, then, it makes sense 
to assume that the monotone t.m. M taken as P in Algorithm PW is taken as * in the new algG rithm, and 
we shall do so without further comment. Even without assuming any monotonicity, it is clear from the 
definition (1.3) of sap(t) that its value does not chauge under time reversal. In order to compare the 
performance of the algorithms, therefore, we need to compare the varia­ tion threshold ~1 of (1 .2) with 
the separation threshold Til) :fJp4~r I)ds is easy in the case of reversible chains (e.g., [3], Lemma 
9.1 For ang finite-state eryodic reversible Markou chai~ TI~Tl (1) < _ 4TI. The tirat inequality holds 
also for nonreversible chains, but there is no universal constant bound on T~l) /rI, even for monotone 
chains, as discussed in the full paper. It is reasonable to focus attention on reversible chains, since 
two of the mmt common methods for simulating a Markov chain with a desired stationary distribution r 
are the Metropolis algorithm and the Gibbs sampler with ran­dom site updating, both of which give reversibility. 
It is even more common in practice to use the Gibbs sampler Pssu = P., P., . . . Pum with systematic 
site updating, where VI,. ... V. is some tixed ordering of the sites. Since Fssu = PvmP. _, . . . P.l 
, reversibilityy is lost, but (1) it is easy to implement and, in terms of t-fl), to analyze fine-tuned 
versions of our user­impatience unbked algorithm for this and other altern­ativeupdating schem~, and 
(2) absent analytical informa­tion about the respective mixing time values, there seems to be no particular 
reason to prefer Pssu over either its multiplicative (PSSUPSSU) or additive [~ (Pssu + FwJ)] revemiblization. 
For balance, we develop a nontrivial nonrevemible examp­le in a companion paper [15]. 9.2 Comparisonof 
Propp-Whcmandthenewalgorithm Let S be a partially ordered state space p-ing a unique minimum (respectively, 
maximum) element O (reap., ~). Let M be a monotone t.m. on S to be used se P for the Algorithm PW of 
Section 5 and es ~ for our algorithm in Section 6.2. ~n particular, P = P = M if M is reversible.] Let 
~1 and ~1 1) be the variation and separation thresholdsfor M given by (1.2) and (1.4), respectively. 
We now give a point-by-point comparison of the two algorithms. Underlying ideas: Backward coupling for 
P~ acceptance rejection, or strong stationary times and duality, for ours. Applicability: PW requires 
the existence of a monotone transition rule (recall Definition 4.2) for M (and this is a somewhat stronger 
requirement than monotonicity of M; recall Remark 4.5); ours doesn t, but requires the ability to generate 
transitions from each KX,Y(X , .), where (see Sec­tion 6.1) Kx,y (for x s y) is an upward kernel for 
M(x,.) and M(y, .). Ours additionally requires the ability to gener­ ate transitions from each M(x, .); 
in the nonreversible case, PW doeen t. Genemlizabikty: Ideas initiated by Kendall [24] lead to a modification 
of PW for anti-monotone chains, including repulsh-e spin systems; see Hi&#38;ztrom and Nelander [22] 
for definitiona and further development. Aa for monotone chains, the algorithm maintains only two states. 
Our algo­rithm can be similarly modified. The PW algorithm also poeamae s the noteworthy fea­ture of 
allowing for omnithermal sampling of attractive spin systems, in effect simultaneously generating one 
obser­vation for every possible temperature. See Section 3.1 and the remarkable Figure 2 in [29]. Our 
algorithm similarly can allow for on-mithermal sampling. There exist varhnta of both algorithms for non-monotone 
chains, although neither is very useful for generic chains with large state space, in view of the comment 
at the outset of Section 4. See [29] for PW we plan to discuss the variant of our algorithm in future 
work. There are other schemes to handle general chainx see [34] [27] [4] . Both algorithms are also easily 
generalkmd to allow time inhomogeneous chains, although the performance analyzes are greatly complicated 
in doing m. Performance: Unlike PW, our algorithm is not subject to user-impatience bi~ that is a major 
theme of the present abstract. The expected number of Markov transition for PW is O(T1 log 1), where 
1 is the length of the longeat chain in S; the corresponding guarantee for ours is O(~\l)). If M is reversible, 
our bound is smaller; otherwise, our running time can be worse: see Section 9.1. Further, a count of 
for­ward transitions does not tell the full running time story. In [15] we present a nonreversible example 
for which transi­ tions horn M (required for our algorithm but not for PW) take time of larger order 
of magnitude than thca from M. Similarly, generating tlom the upward kernels might take longer than from 
M. From now on we restrict attention to attractive spin sys­tems on n sites. We will consider only the 
performance of RSU chains, es in Definition 3.1; similar analysis is possible for other updating schemee. 
We write r indifferently for T1 or TI 1) . See Sections 6.2, 10.2, and 10.3 of the fdl paper for supporting 
detaila. (a) Suppose first that truly random bits are used. Ezpected run time: Our guaranteeis smaller, 
O(T) vs. O(T logn) for PW. Ezpded space: For read/write memory, the guarantee is O(7 log n+ n) for both 
algorithms. PW requires an addi­tional O(T(log n)2) of read-only memory. In fairness, we emphasize that 
the above summary con­cerns only bounds. At least for some examples (e.g., see [15]), the general bound 
ET = O(T log 1) for PW can be sharp­ened to ET = O(T). If this sharpened bound holds for an RSU chain, 
then the expected run time bounda for the two algorithms become equal in magnitude, and PW requires less 
read/write memory. (b) Now suppoee. that a seeded pxmdorandom number generator, as described at the end 
of Section 6.2 in the full paper, is used. From a probabilistic viewpoint, our analysis treats the numbers 
generated as if truly random. Aa dis­cussed at the end of Section 6.2 of the full paper, we may asarne 
that T = ~(n=) for some a < co. Ezpected ma time: Our guarantee is O(T log r), of same order se PW S 
O(7 log n). Ezpected space: Our guarantee is O(n log ~) = O(rLl~ n), which is logarithmically huger than 
PW S O(n + (log7) ) = O(n). Acknowtedgmenta The author thanks David Aldous, Lenore Gwen, Keith Crank, 
Motoya Machida, Jim Propp, and David Wilson for helpiil discussions and also thanks anonymous committee 
members and referees of the full paper for their suggestions which improved the exposition in this extended 
abstract. Refarencea <RefA>[1] Aldous, D. and Discords, P. (1986). Shutliing cards and stopping times. Amer. 
Math. Monthly 93333-348. [2] Aldous, D. and Diaconis, P. (1987). Strong uniform times and finite random 
walka. Advances in Appl. Math. 869-97. [3] Aldous, D. and Fill, J. A. (1996). Reversibk Markov Chains 
and Random Walks on Gnaphs. Book in preparation. First draft of manuscript available via http: Ilww. 
stat .berkeley. aduhaeralaldoua. [4] Aamuseen, S., Glynn, P. W., and Thorisson, H. (1992). Stationary 
detection in the initial transient problem. ACM lbans. Mcdelling and Computer Stm. 2130-157. [5] Beaag, 
J. E. (1986). On the statistical analysis of dirty pictures. J. l?o~al Statist. Sot. B 48259-302. [6] 
Jkag, J. E. and Clifford, P. (1989). Generalized Monte Carlo significance tests. Biometti 76633-642. 
[7] 13esag, J. E. and ClitTord, P. (1991). Sequential Monte Carlo pvalues. Biometrika 78301-304. [8] 
Besag, J., Green, P., Higdon, D., and Mengeraen, K. (1995). Bayesirm computation and stochastic systems. 
Statistical Science 103-66. [9] Borovkov, A. A. and Foss, S. G. (1992). Stochastically recursive sequences 
and their generaEzationa. Sibetian Adv. Math. 216-81. [10] Borovkov, A. A. and Foss, S. G. (1994). Two 
ergodic­ity criteria for stochaatically recursive sequences. Acts Applic. Math. S4 125-134. [11] Diaconis, 
P. (1988). Grvup Repwentations in Probabd­ity and Statistics. Institute of Mathematical Statistics, Hayward, 
California. [12] Diaconis, P. and Fill, J. A. (1990). Stnmg stationary times via a new form of duality. 
Ann. Robab. 181483­1522. [13] Diaconis, P. and Saloff-Coate, L. (1995). What do we know about the Metropolis 
algorithm? In S~posium on the T* of Computing, 112 129. [14] Diaconis, P. and Saloff-Coate, L. (1995). 
Geometry and randomness. Unpublished lecture notes. 115] Fill, J. A. (1996). The move-t&#38;lont rule: 
a case sutdy for two exact sampling algorithms. Technical Re­port #566, Department of Mathematical Sciences, 
The Johns Hopkins University. [16] Fill, J. A. and Machida, M. (1996). Stochastic ordering on posets. 
Unpublished notes. [17] Fill, J. A. and Machida, M. (1996). Duahty relations for Markov chains on partially 
ordered state spaces. Un­published notes. [18] Foaa, S. G. (1983). On ergodicity conditions in multi-Server 
queuea. Siberian Math. J. 24168-175. [19] Foss, S., Tweedie, R. L., and Cormran J. (1997). Sim­ulating 
the invariant measures of Markov chains using backward coupling at regeneration times. Preprint. [20] 
Geman, S. and Geman, D. (1984). Stochastic relax­ation, Gibbs distributiona, and the Bayesian restoration 
of images. IEEE Thmsactcons on Pattern Ana@ia and Machine Intelligence, PAMI-6(6). [21] Haggatr5m, O., 
van Lieshout, M. N. M., and M@er, J. (1996). Characterisation results and Markov chain Monte Carlo algorithms 
including exact simulation for some spatial point processes. Preprint. [22] Hi@gstr6m, O. and Nelander, 
K. (1997). Exact sam­pling km anti-monotone systems. Preprint. [23] Kamae, T., Krengel, U., and O Brien, 
G. L. (1977). Stochastic inequalities on partially ordered state spaces. Ann. Pm6ab. 5899-912. [24] Kendall, 
W. S. (1996). Perfect simulation for the arew interaction point process. In Proceedings of the S~po­sium 
on Prubabilitg towards the Year 2000 (eds.: L. Ac­cardi and C. C. Heyde), Springer, to appear. [25] Kendall, 
W. S. (1996). On some weighted Boolean mod­els. Preprint 295, Department of Statistics, Warwick University. 
[26] Liggett, T. (1985). Jntemcting Particle Systems. Springer-Verlag, New York. [27] Lov&#38;az, L. 
and Winkler, P. (1995). Exact mixing in an unknown Markov chain. Electnmic J. Combinatorics 2 #R15. [28] 
Lund, R. B., Wilson, D. B., Foss, S., and Tweedie, R. L. (1997). Exact and approximate simulation of 
the invari­ant measures of Markov chains. Preprint. [29] Propp, J. G. and Wllaon, D. B. (1996). Exact 
sampling with coupled Markov chains and applications to statis­ tical mechanics. Random Structures and 
Algorithms 9 223-252. [30] Rcea, S. (1994). A First Course in Pmbabdity, 4th ed. Macmillan, New York. 
[31] Sinclair, A. (1993). Algorithms for Random Gensnztion and Counting: A Markov Chain Approach. Birkh&#38;uaer, 
Boaton.  [32] Stanley, R. P. (1986). Enumemtiue Combinatorics, vol­ume 1. Wadsworth &#38; Brooks/Cole, 
Monterey, Califor­ [33] %&#38;wen, V. (1965). The existence of probability mea­sures with given marginala. 
Ann. Math. Statiat. 36423­ 439. [34] Wilson, D. B. and Propp, J. G. (1997). How to get a perfectly random 
sample from a generic Markov chain and generate a random spanning tree of a directed graph. Journal of 
Algorithms, to appear. [35] Wilson, D. B. (1995). Personal communication.  </RefA>
			
