
 Proceedings of the 1996 Winter Simulation Conference ed. J. M. Charnes, D. J. Morrice, D. T. Brunner, 
and J. J. Swa n AN INTRODUCTION TO SIMULATION MODELING Martha A. Centeno Department of Industrial&#38; 
Systems Engineering College of Engineering and Design Florida International University Miami, Florida 
33199, U.S.A. ABSTRACT This paper offers an introductory overview of discrete simulation, with emphasis 
on the simulation modeling process rather than on any specific simulation package. Examples are used 
to demonstrate the application of the methodology at each step of the process. An extensive list of additional 
readings is given for the reader who wishes to deepen hMher knowledge in a specific area. 1 SIMULATION 
MODELING The word simulation means different things depending on the domain in which it is being applied. 
In this tutorial, simulation should be understood as the process of designing a model of a real system 
and conducting experiments with this model for the purpose of understanding the behavior of the system 
or of evaluating various strategies for the operation of the system (Shannon, 1975). In other words, 
simulation modeling is an experimental technique and applied methodology which seeks / to describe the 
behavior of systems, < to construct theories or hypotheses that account for the observed behavior, and 
. ~ to use these theories to predict future behavior or the effect produced by changes in the operational 
input set. 1.1 Types of Simulation Simulation is classified based on the type of system under study. 
Thus, simulation can be either continuous or discrete. Our emphasis in this tutorial will be on discrete 
simulation. There are two approaches for dkcrete simulation: event-driven and process driven. Under event 
driven discrete simulation, the modeler has to think in terms of the events that may change the status 
of the system to describe the model. The status of the systems is defined by the set of variables (measures 
of performance) being observed (e.g. number in queue, status of server, number of servers). On the other 
hand, under the process driven approach, the modeler thinks in terms of the processes that the dynamic 
entity will experience as it moves through the system. 1.2 Some Terminology Every simulation model represents 
a system of some form. The system may be a manufacturing cell, an assembly line, a computer network, 
a service facility, or a health care facility, just to name a few. Although these systems seems to be 
completely different, they are not really that different if we expressed them in terms of their components. 
In general the components of a system are dynamic entity (ies) and resource(s). Dynamic entities are 
the objects moving through the system that request one of the services provided by the system resources. 
Entities have attributes which describe a characteristic of it. Entities may {experience events which 
is an instantaneous occurrence that (may) change(s) the state of the system. An endogenous event is an 
event that occurs within the system, whereas an exogenous event is an event that occurs cutside the system. 
Resources are the static entities that provide a service to an entity. Resources are further classified 
based on the type of service they provide; e.g. servers (machines or persons), free path transporters, 
guided transporters, conveyors, and so forth. Resources engage in activities which is a time period of 
specified length. The state of the system is a collection of variables needed to describe the system 
s performance. Simulation will model the random behavior of a system, over time, by utilizing an internal 
simulation clock and by sampling from a stream of random numbers. A random number generator is a computational 
algorithm that enables the creation of a 15 new number every time the function is invoked. The clearly 
understanding and assessing management needs sequence of these numbers is known as a random and expectations, 
the modeler must determine whether number stream. A true random number cannot be or not simulation is 
indeed an adequate tool for the generated by a computer. Computers can only generate analysis of the 
system under scrutiny. In some instance, pseudo-random numbers. However, these numbers are an analytical 
technique may suftlce to obtain adequate statistically random; thus, their usage in simulation solutions. 
Analytical tools should be preferred over modeling is valid. simulation whenever possible. The modeler 
must establish a set of assumptions under which a technique, 1.3 The Simulation Modeling Process or a 
combination of techniques, is applicable, feasible and sufficient. The simulation modeling methodology 
has many If simulation modeling is the technique, or it is part stages including: definition of the project 
and its goals, of a combination of techniques, the modeler proceeds to abstraction of a model, digital 
representation of the gather data and performs proper statistical analysis to model, experimenting with 
the model, and producing support models of the system. The needed data may be complete documentation 
of the project. It tends to be an available in many different places and/or in different iterative process 
in which a model is designed, a formats. For example, data may reside on paper, or it scenario defined, 
the experiment run, results analyzed, may reside within a database of a computerized another scenario 
chosen, another experiment was run, information system. In either case, statistical tests must and so 
forth. However, advances in computer hardware, be performed without altering or destroying the original 
software engineering, artificial intelligence (AI), and raw data. When there is no data available, the 
modeler databases are exerting a major influence on the must define the inputs to the model about the 
system simulation modeling process (SMP) and the using rules of thumb and/or personal experience. development 
philosophy of support tools. If we look at A conceptual model of a system must be devised and the SMP 
(Figure 1), it is clear that simulation modeling converted into a digital model. The modeler resorts 
to is a knowledge and data intensive process. Notice that tools that will make the transition less difficult 
and less the flow through the SMP is not a sequential one; time consuming such as model generator front 
ends, rather, it is a highly iterative one as discussed in the simulation packages and so on. However, 
converting a following paragraphs. conceptual model into a digital one is by itself meaningless, unless 
such a digital model is thoroughly verified and validated. The reliability of the digital I r model is 
directly affected by the quality of the ,:Fj.::d~ verification and validation processes. Verification 
entails assuring that the digital code of the model OwdipmjaiplanJ performs as expected and intended, 
and validation seeksI t I to show that the model behavior represents that of the L ,. -..Lreal-world 
system being modeled. With a reliable and accurate digital model, the Wi&#38;I,~cdhrsonj no modeler proceeds 
to the experimentation phase. iStatistical experiments are designed to meet the ..­  +Ml ~k+ objectives 
of the study. Observing a model under one set of experimental conditions usually provides little or 
incomplete information. Thus, a set of experimentalVelaied 1 conditions must be analyzed within the framework 
of%+yes multiple experimental conditions. no no \ Implemtatkm The capstone of the SMP is the preparation 
of a set of Vdidatal recommendations into a formal management report. This report includes implementation 
and operations Figure 1: The Simulation Modeling Process guidelines. yes A study of a system starts 
when there is a problem 1.4 Advantagesll)isadvantages of Using Simulation with an existing system, or 
when it is not possible to experiment with the real system, or when the system is Simulation modeling 
is a highly flexible technique under design, i.e. the system does not exist yet. After because its models 
do not require the many simplifying assumptions needed by most analytical techniques. An Introduction 
to Simulation Modeling Furthermore, simulation tends to be easier to apply (once the programming side 
is overcome) than analytic methods. In addition, simulation data is usually less costly than data collected 
using a real system. However, despite its flexibility, simulation modeling is not the magic wand that 
solves all the problems. Constructing simulation models may be costly, particularly because they need 
to be thoroughly verified and validated. Additionally, the cost of the experiment may increase as the 
computational time increases. The statistical nature of simulation requires that many runs of the same 
model be done to achieve reliable and accurate results. Despite its disadvantages, simulation remains 
a valuable tool to address a variety of engineering problems, at the design, planning, and operations 
levels. In each of this areas, simulation can be used to provide information for decision making, or 
it may actually provide a solution (Pritsker, 1992). 2 STATISTICAL ASPECTS 2.1 Statistical Tools It is 
not uncommon for a new comer to the simulation modeling methodology to feel hesitant about it because 
of its intense use of statistics. Fortunately, there are a variety of support tools to overcome this 
hesitation. Simulation packages such as SIMANIARENA (Banks, et al., 1994), GPSWH (Henriksen, 1989), and 
SLAMSYSTEM (0 Reilly, 1994) provide some support for both the analysis of data for inputs as well as 
for the analysis of output. In addition, there are several packages that has been designed to support 
the statistical analysis needed in simulation. For example, ExpertFit (Law and Vincent, 1995) enables 
the input data modeling for up to twenty seven probabilistic models; a variety of statistical tests and 
measures of accuracy are implemented in this p~kage. Another example is SIMSTAT (Blaisdell and Haddock, 
1993) which is an interactive program that allows the analysis of both input and output data. Both packages 
are Windows-Based, and they both allow for the user to save their outputs in various formats. In the 
following paragraphs, a discussion of some of the issues and techniques needed are discussed. 2.2 Analysis 
of Inputs A simulation model requires data andJor data models for to come alive. Without input data models, 
the simulation model itself is incapable of generating any data about the behavior of the system it representa. 
A simulation practitioner may be confronted with one of three possible scenarios at this stage of the 
SMP: El There seems to be an immense amount of data El There is no data at all ~ There is a few amount 
of data On the onset, the first situation may appear to be ideal: the more data, the merrier. But, caution 
must be exercise as the data available may be irrelevant for the purposes of the study. Even if the data 
presents itself as relevant to the study, traditional common sense practices must be done before using 
the data 10 develop models for simulation. Is the data reliable? H[ow was it collected? Are there any 
circumstances that occurred during the data collection process that may lead to skewed or bias data models? 
Once sufficient information about the data and the data collection process has been compiled, classical 
statistical techniques should be used to develop data models. Some of these techniques are correlation 
analysis, point and interval estimation, linear and non-linear regression, and curve fitting in general. 
Assume that there is a sample in the available data set that represent the number of customers that arrived 
at a bank in a 15-minute time interval.. Further, assume that these data was collected over the course 
of two weeks, between the hours of 9:00 AM to 2:00 PM and 5:00 PM to 6:00 PM. Correlation analysis will 
help answer questions such as is the customer arrival rate constant through the day? throughout the week? 
If it is not, how does it vary? Could the arrival rate be modeled differently for each type of service 
the bank provide? If yes, do the data lend themselves jbr proper breakdown ? The use of graphical techniques 
such as line graphs and scatter plots will also help in establishing how to cluster the data set. Figure, 
for instance, reveals that there are changes in the rate of arrival throughout the day. Further, it seems 
that there is a variation of the rate of arrival depending not only on the time, but also on the day 
of the week. Correlation analysis should be used to confirm the visual hypothesis.  , ~r... .- . . . 
l l - - - - --  --{Y : : l 1 ------  ---  ---- --: Figure 2: Line Graph of Sample Data Set 
It is important that these previous questions be may come from the people who operate the system. In 
answer by analyzing the data because if it is assume that some cases the estimates given by the operators 
may just the entire sample of 1000 observations comes from the be an average or mean value. Depending 
on the same population, a single data model may be built for it actual system, the modeler may use such 
value as a which will not reflect the true arrival rate behavior. constant or as the mean value of a 
distribution. To In our example, it is possible to construct three decide on the distribution, the modeler 
should use different probability data models to account for the knowledge about the areas of application 
of the change in the arrival rate. Goodness of fit tests, such as distributions. Table 1 give a summary 
of some classical the X2 test and the Kolmogorov-Smirnov test need to be distributions and what they 
are capable of modeling. done to test the hypothesized distribution. In our The third situation requires 
some of the efforts of the example, we could formulate that first one (assessing quality of data, data 
collection process and so forth). Usually, there is a small sample HO= arrival rate follows a uniform 
distribution from which one has to develop data input models. between 9:00 AM and 11:00 AM Statistical 
methods based on the t-student distribution are utilized. If the sample size is large enough , then After 
using point estimators for the lower and the techniques based on the Normal distribution may be upper 
bounds of the uniform distribution, we can test Ho used. using the X2 test if the number of observations 
is adequate and if the expected number of observations in 2.3 Analysis of Outputs each and every interval 
is at least five. The second situation is clearly the worst case The actual analysis of the data provided 
by the scenario because the simulation practitioner has to rely simulation model will depend on the initial 
objectives of on his/her experience and knowledge about the system the study and on the type of system 
being modeled to establish appropriate input data models. In this case, (Sadowski, 1993). There are two 
basic types of systems: .. the modeler has to quantify his/her educated guesses terminating and non-terminating. 
based on any estimated values available. Such estimates Distribution Name: Binomiul Poisson Definition 
of Variable: X = Number of successes among n X = Number of events during one unit of Bernoulli trials 
measure (time, volume, length,..) Some Assumptions: It can be used in cases where experiment Binomial 
converges to a Poisson (n + co consists of a sequence of n trials and n is and n -) O). fixed. It provides 
probabilities of how many Trials are dichotomous &#38; identical events will occur over a period of time. 
(Bernoulli trials). Events occur at some average rate. Rate Trials are independent and have same of events 
remains constant over the probability of success. duration of a unit of time. No two events Commonly 
used to model quality control can occur simultaneously. and reliability data models. Commonly used in 
queueing analysis and to model rate of arrivals/ rate of service. Distribution Name: Normal Exponential 
Definition of Variable: X = depends on the system under study X = time or distance between two consecutive 
events Some Assumptions: It can be applied to model physical, It is a special case of the Gamma model 
chemical properties. It is the best know (r=l). and most widely used distribution. It is memory-less 
when modeling time It can be used to model both discrete and In a Poisson process, the rate of arrival 
/ continuous variables, but with caution service is Poisson and the time between because its domain is 
real and expands arrivals / services is Exponential. from -= to +00 ... .. ---. .. . 1ame 1: Summary 
or some Umtntmtlons An Introduction to Terminating systems are systems that have a clear point in time 
when they start operations and a clear point in time when the end operations. For these type of systems, 
it is required to established the sample size and the simulation length. The latter is usually established 
by the context of the problem. For a bank facility, it may be the entire day, or just the rush hours 
during Friday afternoon. The sample size is established, based on the accuracy, reliability, and variation 
desired for the study, using the equation .. n = 2;/20 d2 where d is the accuracy expressed in the same 
units as those of the measure of performance (e.g. within 5 minutes), z is the critical value from the 
standard normal table at a given reliability level, 1-tx, (e.g. 95 %0 reliability leads to an u = 0.05), 
and o is the standard deviation desired. The value of n is the minimum number of replications (not runs) 
needed to have statistically valid results. It is very common for the novice to confuse a replication 
worth a simulation run. A run is what happens from the moment the user clicks on the run option of the 
main menu, to the moment in which the software finishes outputting data and comes back to the main menu. 
A replication, on the other hand, is what happens from the simulated start time to the closing simulation 
time. A simulation run of this type of systems has n replications. The summary report from replication 
to replication is different, but the summary reports from run to run are exactly the same, unless the 
random number stream is changed between runs. Non terminating systems are systems that have no clear 
beginning time when they start operations, nor do they have a clear point in time when they stop operations. 
For this kind of systems, it is necessary first to bring the simulation model to steady state before 
the model generated data is used in analysis. All the data generated before the model reaches steady 
state should be thrown away. Upon reaching steady state, it is necessary to decide the length of the 
single replication that is to be run. Usually, the method of batching is used to analyze this data. Batching 
refers to the breaking the highly correlated, sequential observations generated by the model, into groups 
or batches. These batches would then be treated in the same fashion as the replication in the case of 
terminating systems. A batch is fortned based on the level of correlation between observations separated 
by a given lag k. Statistical theory tells us that the farther apart two Simulation Modeling correlated 
observations are, the smaller the correlation. So what one needs to do is to compute the correlation 
factor for various values of the lag k (20-500), graph the correlation factor, and identify the lag value 
at which the correlation actor p is approximately O. From that process, the number of observations in 
the batch is established taking into account that this is a random process, so a safety factor needs 
to be added. Once the batches are formed, each batch is treated as an independent replication, and similar 
analysis to that for a terminating system should be done. Regardless of the type of system, the modeler 
must keep in mind that reporting point estimates of the measure of performance are not that helpful. 
Confidence intervals on critical measures of performance should be built to add credibility and robustness 
to the study. 3 CODING THE MODEL This the stage that, at first, seems to be the most time consuming. 
However, without proper planning and proper analysis, the effort at this stage is useless. It does not 
matter how beautiful the model IIooks like (animation), or how fancy (full of details) the model is. 
If it does not addressed the original problem, it is useless. The modeler must be knowledgeable about 
programming and/or a simulation package. Although simulation models can be built using general purpose 
languages such as C/C++ and FORTRAN, nowadays there are a significant number of packages that have proven 
themselves as versatile and robust. Some of these packages are domain specific, while other are more 
general purpose. These packages include GPSS/HTM, GPSS/WorldTM, SIMAN/ARENA@, SLAMSYSTEM@, WITNESS, SIMFACTORY, 
ProModel, AutoMod, AIM, and Taylor (Banks, 1995). 4 VERIFICATION&#38; VALIDATION Verification is the 
process of determining that the model operates as intended. In other words, it is the process of debugging 
the model. All the verification activities are closely related to the moclel. An empirical way to check 
if the model is behaving as the modeler intended is to put constant values for all the random processes 
in the model, and to calculate the outputs the model is supposed to give. This process is by no means 
sufficient or enough to declare a,model as verified, but it helps to identify subtle errors. In fact, 
determining that a model is absolutely verified maybe impossible to attain. During the verification stage, 
the modeler must test each major component of the model. These can be done by doing static testing (correctness 
proofs, structured walk through) or by doing dynamic testing (execute the model under various conditions) 
(Sargent, 1984 and 1994) Validation is the process of ascertaining that a model is an acceptable representation 
of the real world system. The validation process is concerned with establishing the confidence that the 
end user will have on the model. Some critical questions to ask during this stage are does the model 
adequately represents the relationships of the real system?, is the model generated output typical of 
the real system?. Validation requires that the model be tested for reasonableness (continuity, consistency, 
and degeneracy). A point to start the validation process empirically is to question the structural assumptions 
of the model as well as the data assumptions made early in the SMP. A more sophisticated way to validate 
a model may require the use of some analytical tools such as Queueing Theory, but for it additional data 
may be needed (Sargent, 1994). In summary, verification and validation can be informal (audits, face 
validations, Turing test, walk through), Static (consistency checking, data flow analysis), Dynamic (Black-box 
testing, regression testing), Symbolic (cause-effect diagrams, path analysis), Constraint (assertion 
checking, inductive assertions), and Formal (Logical deduction, Predicate calculus, proof of correctness). 
For more details in any of these test, see Balci (1995 and 1996). 5 ENSURING SUCCESS Simulation modeling 
is very susceptible to the ability of the project to leader to organize the study. It is paramount to 
clearly define the objectives of the study; otherwise, there will be no clear guidelines as to what type 
of experimentation should be done. Further, establishing which assumptions are acceptable depends on 
what the objectives are. A modeling strategy needs to be developed early in the process. The complexity 
of the system may be too much to include in the model. In fact, such level of complexity may not be desirable. 
A model can be simplified by omission, aggregation, or substitution. Omission refers to leaving out details 
that are negligible; for example, sojourn time over a two-foot distance by human being. Aggregation refers 
to the lumping of details / activities; for example, it may not be possible to model the time it takes 
to move a box from one table to another, when the tables are next to each other, but it may be possible 
to measure the time it takes from the moment the server seizes the box, Centeno opens it, performs whatever 
activity is supposed to perform, and places it on a cart. Substitution refers to replacing an object 
in the system for another one with similar, not equal, characteristics; for example, assuming that two 
cashiers at a fast food place work at the same speed, when indeed they do not. It is very typical for 
novice simulation practitioners to resist omission. They want to build an exact replica of the real world 
system. This situation may lead to costly and delayed simulation studies. Similarly, a very experienced 
modeler may fall I in the trap of simplifying a bit too much. The impact of the simplifications made 
on the model generated data must be taken into consideration before implementing the simplifications. 
Again, the. impacts are assessed in light of the objectives of the study. It is very important that the 
modeler, or someone in the team, be properly trained in both simulation modeling and statistical analysis. 
A common pitfall of simulation studies is poor analysis of both the input data (to formulate data models) 
and the model generated data. A simulation study is not a simple task. Instead of setting an absolute 
delivery date, plan on having intermediate progress reports. This approach will help you and the end 
user of the model to verify, validate and accept the recommendations of the study. It is very likely 
that as you make a progress report, the owner of the system points out that you have not quite understood 
a portion of the operations of the system. In summary, keep in mind the maxims outlined by Musselman 
(1994), and transcribed below: Define the problem to be studied, including a written statement of the 
problem-solving objective Work on the right problem; fuzzy objectives lead to unclear success. Listen 
to the customer; do not look for a solution without firsts listening to the problem. Communicate; keep 
people informed, for the journey is more valuable than the solution. Only by knowing where you started 
can you judge how far you have come. Direct the model; advance the model by formulating it backwards. 
Manage expectations; it is easier to correct an expectation now, than to change a belief later. Do not 
take data for granted. Focus on the problem more than the model. Add complexity; do not start with it. 
Do not let the model become so sophisticated that it compensates for a bad design, or so complex that 
it goes beyond your ability to implement. Verbal agreements are not worth the paper they are printed 
on. An Introduction to Simulation Modeling # Customer perceptions require attention. # Report successes 
early and often. # If it does not make sense, check it out. Y People decide; models do not. < fiow when 
to stop;ultimatetruthis not affordable. ~ present a choice; people do not resist their own discoveries. 
< Document, Document, Document! 6 CONCLUDING REMARKS This tutorial has been intended as an introduction 
to this powerful technique. In-depth study of other sources is strongly recommended before engaging in 
a simulation study. Sources for simulation modeling include Nelson (1995), Banks and Carson (1984), Law 
and Kelton (1991), Sadowski (1993), Pidd 9 1994). For statistical analysis, recommended source include 
Nelson (1992), Law and Kelton (1991), and Alexopoulos (1995). For software selection, Banks (1995) is 
a good starting point. For the methodology in general, excellent sources include Pegden, Shannon, and 
Sadowski 1995), Shannon (1975), Banks and Carson (1991), and Law and Kelton (1991). REFERENCES <RefA>Alexopoulos, 
C. 1995. Advanced Methods for Simulation Output Analysis. In Proceedings of the 1995 Winter Simulation 
Conference, Eds. C. Alexopoulos, K. Kang, W. R. Lilegdon, and D. Goldsman. 101-109. Balci, O. 1995. Principles 
and Techniques of Simulation Validation, Verification, and Testing. In Proceedings of the 1995 Winter 
Simulation Conference, Eds. C. Alexopoulos, K. Kang, W. R. Lilegdon, and D. Goldsman. Balci, O. 1996. 
Principles of Simulation Model Validation, Verification, and Testing. International Journal in Computer 
Simulation, to appear. Banks, J. 1995. Software Simulation. In Proceedings of the 1995 Winter Simulation 
Conference, Eds. C . Alexopoulos, K. Kang, W. R. Lilegdon, and D. Goldsman. 32-38 Banks, J., B. Burnette, 
H. Kozloski, and J. Rose. 1994. Introduction to SIA4AN V and CINEMA. New York: John Wiley &#38; Sons 
USA. Banks, J. and J. S. Carson. 1984. Discrete-Event System Simulation. Englewood Cliffs, New Jersey, 
Prentice Hall. Blaisdell, W. E. and J. Haddock. 1993. Simulation Analysis Using SIMSTAT 2.0. In Proceedings 
of the 1993 Winter Simulation Conference, Eds. G. W. Evans, M. Mollaghasemi, E. C. Russell, W. E. Biles. 
213-217. Henriksen, J. O. and R. C. Crain. 1989. GPSS/H Reference Manual. Annandale, Va. Wolverine Software 
Corporation. Law, A. and W. D. Kelton. 1991. Simulation Modeling &#38; Analysis. 2nd edition, New York, 
McGraw-Hill, Inc. USA. Law, A. M. and S. Vincent. 1995. ExpertFitr~ User s Guide, Averill M. Law &#38; 
Associates, IP.O. Box 40996, Tucson, Arizona 85717. Musselman, K. J. 1994. Guidelines for Simulation 
Project Success. In Proceedings of lLhe 1994 Winter Simulation Conference, Eds. J. D. Tew, S. Manivannan, 
D. A. Sadowski, and A. F. Seila. 88-95 Nelson, B. L. 1992. Designing Efficient Experiments. In Proceedings 
of the 1992 Winter Simulation Conference, ed. J. J, Swain, D. Goldsman, R. C. Crain, and J. R. Wilson, 
126-132. Nelson, B. L. 1995. Stochastic Modeling: Analysis &#38; Simulation. McGraw-Hill, Inc. USA. O 
Reilly, J. J. 1994. Introduction to SLAM II and SLAMSYSTEM. In Proceedings of lhe 1994 Winter Simulation 
Conference, Eds. J. D, Tew, S. Manivannan, D. A. Sadowski, and A. F. Seila. 415-419. Pegden, C. D., R. 
E. Shannon, and R. P. Sadowski. 1995. Introduction to Simulation Using SIMAN. 2nd Edition. New York, 
McGraw Hill USA. Pidd, M. 1994. An Introduction to Computer Simulation. In Proceedings of the 1994 Winter 
Simulation Conference, Eds. J. D. Tew, S. Manivannan, D. A. Sadowski, and A. F. Seila. 7­ 14. Pritsker, 
A.A. B. 1992. Simulation: The Premier Technique of Industrial Engineering. Industrial Engineering, 24(7) 
:25-26. Sadowski, R. 1993. Selling Simulation and Simulation Results. In Proceedings of the 1993 Winter 
Simulation Conference. ed. G. W. Evans, M. Mollaghasetni, E. C. Russell, W. E. Biles, 65-68. Sargent, 
R. G. 1984. Simulation Model Validation. Simulation and Model-Based Methodologies: An Integrative View, 
Eds. Oren, et al. Springer-Verlag. Sargent, R. 1994. Verification and Validation of Simulation Models. 
In Proceedings of the 1994 Winter Simulation Conference, Eds. J. D, Tew, S. Manivannan, D. A. Sadowski, 
and A. F. Seila. 77-87. Shannon, R. E. 1975. Systems Simulation: The Art and the Science, New Jersey: 
Prentice-Hall, Inc. Systems Modeling Corporation. 1994. SIMAN V Reference Guide. Sewickley, Pennsylvania. </RefA>
AUTHOR BIOGRAPHY MARTHA A. CENTENO is an assistant professor in the Department of Industrial and Systems 
Engineering at Florida International University. She received a B.S. in Chemical Engineering from ITESO 
University (Guadalajara, Jalisco, Mexico), a M.S. in Industrial Engineering from Louisiana State University, 
and a Ph. D. in Industrial Engineering from Texas A&#38;M University. Dr. Centeno s current research 
interest include the utilization of artificial intelligence and database technologies to develop comprehensive 
and smart simulation modeling environments. Dr. Centeno is a member of ASA, Alpha Pi Mu, Tau Beta Pi, 
IIE, INFORMS, and SCS.  
			
