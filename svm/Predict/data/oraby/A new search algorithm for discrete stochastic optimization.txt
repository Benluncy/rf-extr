
 Proceedings of the 1995 Winter simulation Conference ed. C. Alexopoulos, h . Kang, W. R. Lilegdon, and 
D, Goldsman A NEW SEARCH ALGORITHM FOR Mahmoud H. Alrefaei Department of Industrial Engineering University 
of Wisconsin Madison 1513 University Avenue Madison, WI 53706, U.S.A. ABSTRACT We present a new method 
for finding a global optimal solution to a discrete stochastic optimization prob­lem. This method resembles 
the simulated annealing method for discrete deterministic optimization. How­ever, in our method the annealing 
schedule (the cool­ing temperature) is kept fixed, and the mechanism for estimating the optimal solution 
is different from that used in the original simulated annealing method. We state a convergence result 
that shows that our method converges almost surely to a global optimal solution under mild conditions. 
We also present empirical re­sults that illustrate the performance of the proposed approach on a simple 
example. INTRODUCTION Consider the problem of optimizing an objective func­tion over a discrete feasible 
set of parameters in sit­uations where the objective function does not have a closed form expression, 
so that its values have to be estimated or simulated. In mathematical notation, this problem can be represented 
as (1) where S is a discrete set and t : S + %! is a deter­ministic function whose evaluations all include 
some noise. Often ~ is the expected performance of a com­plex stochastic system, so that for all ~ ~ 
S, f(z) = E[h(z, Y.)], (2) where Yz is some random variable that depends on the parameter z and h is 
a deterministic function. In the deterministic case, when the values of the function j can be evaluated 
easily, then one can use a discrete deterministic optimization technique such as the branch-and-bound 
method or the simulated annealing method to solve the optimization problem DISCRETE STOCHASTIC OPTIMIZATION 
Sigrim Andradhttir School of Industrial and Systems Engineering Georgia Institute of Technology Atlanta, 
GA 30332, U.S.A. (l). But when the function evaluations are difficult to come by and include noise, deterministic 
optimiza­tion techniques can not be used to locate the optimal solution. Instead a specialized method 
should be used to deal with functions with noisy evaluations. For objective functions of the form given 
in equa­tion (2), when independent and identically dis­tributed observations YZ(l), Y$(2), . . . YC(n) 
of the random variable YC can be generated for all z ~ S, and when S is finite, one could think of replacing 
the original optimization problem (1) by an approximate optimization problem (3) where j~($) = ~ z~=l 
h(z, Y.(i)), for all ~ E S, and then use a deterministic optimization technique to solve this approximation 
of the original optimization problem. But in order to guarantee convergence, the sample size n may have 
to be very large, which implies that it may require too much computer time to get a good estimate of 
the solution. In addition, it can be difficult to determine how large n should be for (3) to be a good 
approximation of the original optimization problem (1) (2). The approach outlined above (using equation 
(3) to approximate the original optimization problem (1) -(2)) would be more convenient if the number 
of alternatives were small, say less than twenty. In such situations, methods for selecting the best 
sys­tem can be used to solve the discrete stochastic op­timization problem (1) (2). Goldsman, Nelson 
and Schmeiser (1991) present a brief overview of three methods for selecting the best system: interactive 
analysis, ranking and selection, and multiple compar­isons. For more details on ranking and selection 
and multiple comparison procedures, see Goldsman and Nelson (1994). Other related work has appeared in 
the literatures on the multi-armed bandit problem and on learning automata, see for example Lai and Robbins 
(1985), Devroye (1976), and Yakowitz and 236 Lugosi (1990). More recently, Yan and Mukai (1992), Gong, 
Ho, and Zhai (1993), and Andrad6ttir (1995, 1996) have proposed new methods for discrete stochastic opti­mization. 
These methods all generate a Markov chain on the feasible set S of the optimization problem (1). However, 
the specifics of this Markov chain, as well as the approach used to estimate the solution, differ between 
the methods. Both Yan and Mukai (1992) and also Gong, Ho, and Zhai (1993) show that under certain conditions, 
their methods converge in proba­bility to a global solution of the underlying optimiza­tion problem. 
On the other hand, Andrad6ttir proves that under certain conditions, the method proposed in Andrad6ttir 
(1995) converges almost surely to a local optimizer of the objective function, whereas the method proposed 
in Andrad6ttir (1996) converges al­most surely to a global optimizer. In this paper we introduce a new 
method for dis­crete stochastic optimization that resembles the sim­ulated annealing method for discrete 
deterministic optimization. In particular, the proposed approach generates a Markov chain on the state 
space S of the underlying optimization problem (1) that strongly re­sembles the Markov chain generated 
by the simulated annealing algorithm. However, the proposed algo­rithm differs from the simulated annealing 
algorithm in that it uses a constant, rather than decreasing, cooling temperature (see the discussion 
in Sections 2 and 3). Also, our new method employs the mech­anism proposed by Andrad6ttir (1995, 1996) 
to esti­mate the optimal solution, which is different from the mechanism used by the original simulated 
annealing approach. This paper is organized as follows. In Section 2 we give a brief description of the 
simulated annealing algorithm for discrete deterministic optimization. In Section 3 we present the proposed 
discrete stochas­tic optimization algorithm and state conditions under which this algorithm is guaranteed 
to converge almost surely to a global optimal solution of the optimization problem (1) (2). Section 
4 contains empirical re­sults for the proposed method, and some concluding remarks are given in Section 
5. 2 THE SIMULATED ANNEALING ALGO-RITHM Simulated annealing is a random search algorithm that is designed 
to find a global optimizer of a given deterministic function j over a finite set S in situa­ tions where 
the objective function f may have many local minima. Before stating the details of the algo­ rithm, we 
need the following definitions and assump­tions: Definition 1 For each x E S, there exists a subset 
N(z) of S \ {x}, which is called the set of neighbors Ofx. Assumption 1 For any x,x c S, z is reachable 
from x; i.e., there exists a finite sequence, {ni}~=o for some 1, such that xnO = X,xml = X , xn,+l E 
N(xm, ), i = 0,1,2,...,1 1. Definition 2 Let R : S x S -+ [0, 1] be a nonnegative function that satwjies 
1. 12(x,x ) >0 &#38; x E N(x), and 2. x./E~ R(x, x ) = 1.  Then R(x, x ) M called the probability of 
generating X1 from x. Assumption 2 The neighbor system {N(r) : x G S} and the transition pro babzltty 
functton R are symmet­ ric, i. e., 1.x cN(x) @xcN(x ), and 2. R(x, X ) = f?(X , X). Now we state the 
original simulated annealing al­gorithm. Note that {T~ } is a sequence of positive ~calars, and that 
for all Z-6!J?, [x]+= zwhenx~0 and [x]+ = O otherwise. Algorithm 1 Step O: Select a starting point X~ 
G S. Step 1: Gwen Xm = x choose a candidate Zm ~ N(x) with probability distribution P[Zm = zlXm = z]=R(z, 
z), where N(r) and R(x, z) are defined in Defini­tions 1 and 2. Step 2: Given Zm = z, generate Um w 
UIO, 1], and set if Um <pm, xm+~ = 2 otherw~e x7{ where  -[f(~) -f(x)]+ pm =exp [T. 1 Step 3: Let 
m=m+1.GotoStep 1. 238 Alrefaei and Andradc%tir Note that the simulated annealing algorithm al­lows hill-climbing 
moves (to go from z to d with ~(~) < ~(z?)) in order to avoid local minima. Also, the higher the cooling 
temperature T~, the more likely it is that a hill-climbing move will be made. The initial temperature 
and the rate of decrease of the temperature are important parameters that affect the speed of convergence 
of the simulated annealing algorithm and the quality of the final configuration. Let be the set of global 
solutions to the optimization prob­lem (1). To show that Algorithm 1 converges in prob­ability to an 
element of S, consider the undirected graph with the states in S forming the nodes and the neighborhood 
structure {iV(Z) : z E S} forming the edges; i.e., if z c N(z), then the edge (z, z ) belongs to this 
undirected graph. The distance d(z, x ) be­tween two nodes x and x is defined to be the length (number 
of edges) of the minimum path from z to z . Let Sm = {X ES: f(y) < f(z) for ally E ~(x)} be the set of 
all the points that are local maxima for the cost function. Define the radius of the graph r = min maxct(x, 
x ), x@\sm X/Es and let The following result follows directly from Theorems 4.2 and 5.1 and Propositions 
3.2 and 5.1 in Mitral Romeo, and Sangiovanni-Vincentelli (1986). Theorem 1 Under Assumptions 1 and 2, 
tf the se­quence {Tm } satisfies 7 T. = , m=0,1, 2,..., log(rn + m(l + 1) where m. is any parameter 
satwfying 1 ~ m. < c-o and y ~ rL, then Iim P{X~ ES*} = 1. m-+co 3 THE PROPOSED ALGORITHM FOR NOISY FUNCTIONS 
The original simulated annealing algorithm (Algo­rithm 1) is not designed to solve optimization prob-Iems 
that are stochastic in the sense that the evalu­ations of the objective function ~ (see equations (1) 
and (2)) involve noise. Gong, Ho and Zhai (1993) mention that in order for the original simulated an­nealing 
algorithm to be applied to solve such discrete stochastic optimization problems, one needs to ob­t ain 
accurate estimates of the function values, and that this will cost too much computer time. Haddock and 
Mittenthal (1992) implemented this basic idea. However, in order to reduce the required computer time, 
they employed a more rapid temperature de­creasing (i.e., heuristic) annealing schedule (so that standard 
convergence results such as Theorem 1 do not apply). We propose another algorithm which does not re­quire 
accurate estimates of the function values at ev­ery iteration. This algorithm strongly resembles the 
original simulated annealing approach, and in partic­ular, it has the hill-climbing feature which allows 
it to escape from local minima. However, our method uses the criterion of Andrad6ttir (1995, 1996) in 
de­termining the estimate of the optimal solution. In particular, the state that the algorithm has visited 
most often at any given time will be the estimate of the optimal solution. We will need the following 
as­sumption: Assumption 3 The temperature T is a positive (constant) reai number. In addition, {Km} is 
a se­quence of positive integers satisfying lim~+m Km = co. Now we state the proposed simulated annealing 
al­gorithm for noisy functions. Note that after m iter­ations, X~ is the current state of the Markov 
chain generated by the algorithm, for all x E s, V~ (z) is the number of times the Markov chain {Xn } 
has vis­ ited state ~ in the first m iterations, and X~ is the state that the Markov chain {Xn } has 
visited most often in the first m iterations. Algorithm 2 Step O: Select a starting point X. ~ S. Let 
VO(XO) = 11 and VO(S) = O, for all x ~ S, x#Xo. Letm=Oand X&#38;= Xo. Step 1: Gwen X~ = x, choose a candidate 
Zm ~ N(x) with probabdity distribution P[zm = Zlxm = x] = R(3, z), where N(x) and R(x, z) are defined 
in Defini­tions 1 and 2, Step 2: Given Zm = z, generate independent ob­servations Y= (l), YZ(2), .... 
YZ(K~) of YZ and Yc(l), Y$(2), . . .. YZ(K~). of YZ (see equation . (2)). Evaluate ~m(z) and fro(z), 
where fro(s)= * ~~~ h(~, K(i)) fors = z, z. Step 3: Given Z~ = .z, generate U~ N UIO, 1], and set ifUm 
<pm, X~+l = z otherw~se, {x where m=exp[-[m~m]+l  Step 4: Let m = m+ l, Vm(Xm) = Vm-~(Xm) + 1, and Vm(z) 
= Vm l(x), for all x c S, x # Xm. If V~(X~) > V~(X~_l), then let X&#38; = -%; otherwise let X; = X~_l. 
GO to Step 1. We now state a convergence result for the proposed algorithm. This theorem is proved in 
Alrefaei and Andrad6ttir (1995). Theorem 2 Under Assumptions 1, 2, and 3, the se­ quence{x&#38;} generated 
by Algorithm 2 converges ai­ most surely to an element of S (in the sense that there exists a set A such 
that P(A) = 1 and for ail u ~ A, there ex~sts Mw > 0 such that X;(w) ~ S* for all m ~ Mu). 4 APPLICATION 
OF THE PROPOSED ALGORITHM Now we apply the proposed algorithm to solve a simple discrete stochastic optimization 
prob­ lem. In equation (l), let S = {1,...,10}, and let ~(z) = E[YX] for all z E S, where Y. is a uniform 
random variable on the interval p(z) + 0.5, for all z E S and p(l), . . .. P(10) are 0.3,0.7,0.9,0.5,1.0, 
1.4,0.7,0.8,0.0, and 0.6, respec­tively. We will apply Algorithm 2 to solve this opti­mization problem 
with a number of different choices of the parameters T, {Km}, {N(x) : x E S}, and {R($, z?) : z 6 S and 
x E N(z)}. In particu­lar, we use two different values of the temperature T: T = 0.1 and T = 1. We also 
use two choices for the sequence {Km}. In the first one we let Km = [2 log(m + 3)] for all m, where [z] 
denotes the integer part of z for all z E 3?. Hence, this se­ quence {Km } increases very slowly in m. 
The second choice is Km = 1 + lm/ 10] for all m, so this sequence increases more rapidly in m than the 
first choice. Also, we use two different neighborhood structures {N(x) : z E S}. The first neighborhood 
structure is N(z) = {z+ 1 (mod 10), z + 2 (mod 10)} (4) for all z E S. In this case, we let R(z, z ) 
= 1/4 for all z E S and x c N(x). On the other hand, the second neighborhood structure is given by N(z) 
= {z+ 1 (mod 10)} (5) for all $ E S. In this case, we let R($, d) = 1/2 for all z E S and x E N(z). 
Note that in the first neigh­borhood structure (4), we have one local minimum at z = 4 and one global 
minimum at x = 9. On the other hand, in the second neighborhood structure (5) we have three local minima 
at z = 1, 4, and 7 and one global minimum at z = 9. Since the second neighbor­hood structure has more 
local minima, we expect that Algorithm 2 will converge more slowly in this setting than when the first 
neighborhood structure is used. Tables 1 through 4 show the results obtained by applying Algorithm 2 
to solve this optimization prob­lem with the choices of parameters described above. In particular, the 
tables show how many of one hun­dred replications have converged to the true global optimizer as a function 
of the number of iterations of Algorithm 2 that have been completed. The tables also give,for each choice 
of parameters, the average number of observations (computed from the one hun­ dred replications) that 
were needed before the algo­ rithm converged. Table 1: The performance of the proposed method when Km 
= 12 log(m + 3)] for all m and the neigh­ borhood structure is given in equation (4) Iteration T= 0.1 
T=l 100 93 59 200 100 72 500 100 89 1,000 100 98 2,000 100 100 3,000 100 100 Average number of observations 
310 6,590 From the results given in Tables 1 through 4, we conclude that in this example it is better 
to have larger neighborhoods iV(Z), where z 6 S, and smaller temperatures T (the results for the neighborhood 
structure (4) are better than those for the neighbor­ hood structure (5), and the results for T = 0.1 
are better than those for T = 1). In addition, we find that the number of iterations needed for the algorithm 
to converge to a global minimizer does not seem to de­ pend heavily on the rate of increase of the sequence 
{Km }, but when the sequence {Km} increases very rapidly (e.g., when Km = 1 + lm/10J for all m), the 
Alrefaei and Andrad6t tir Table 2: The performance of the proposed method Table 4: The performance of 
the proposed method when Km = 1 + [m/10] for all m and the neighbor-when Km = 1 + [rn/10j for all m and 
the neighbor­hood structure is given in equation (4) hood structure is given in equation (5) Iteration 
T= 0.1 T=l Iteration T=O.1 T=l 100 56 100 79 53 200 I::0 63 200 85 59 500 97 72 1,000 99 88 2,000 100 
98 3,000 100 98  BaE13!d 4,000 100 100 Average number of observations 163 23,572 Average number of 
observations 5,822 96,314 Table 3: The performance of the proposed method when Km = [2 log(m + 3)] for 
all m and the neigh-small number of observations per iteration). How­borhood structure is given in equation 
(5) ever, more research on how the parameters of the proposed method should be selected in different 
situ­ n Iteration IT= O.l]T=l n ations is needed. 100 72 40 200 76 56 ACKNOWLEDGMENTS 500 98 70 1,000 
99 84 The research of the first author was supported by the Jordan University of Science and Technology. 
The -1 3:000 100 98 research of the second author was supported by the 4,000 100 100 National Science 
Foundation under Grant No. DDM­ 1J 9210679. Average number of observations 2,580 15,402 REFERENCES <RefA>Alrefaei, 
M. H., and S. Andrad6ttir. 1995. Sim­ algorithm usually (but not always) spends more com­ulated annealing 
for discrete stochastic optimiza­ puter time in generating the observations. tion. Working paper. Andrad6ttir, 
S. 1995. A method for discrete stochas­5 CONCLUSION tic optimization. To appear in Management Sci­ ence, 
1995. We have presented a new method for solving discrete Andrad6ttir, S. 1996. A global search method 
for stochastic optimization problems that resembles the discrete stochastic optimization. To appear in 
the simulated annealing method for discrete deterministic SIAM Journal on Optimization, 1996. optimization. 
This method converges almost sureiy Devroye, L. 1976. On the convergence of statistical to a global solution 
of the underlying optimization search. IEEE Transactions on Systems, Man and problem. Its performance 
depends on the choice of Cybernetics 6:46-56. a number of parameters, including the temperature, Goldsman, 
D., B. L. Nelson, and B. Schmeiser. 1991. the neighborhood structure, and the number of ob-Methods for 
selecting the best system. In Proceed­servations obtained in the different iterations. C)ur ings of the 
1991 Winter Simulation Conference, preliminary numerical experience indicates that small eds. B. L. Nelson, 
W. D. Kelton, and C. M. Clark, temperatures and large neighborhood structures seem 177 186. Institute 
of Electrical and Electronics En­to result in better performance. on the other hand, gineers, Piscataway, 
New Jersey. the performance of the algorithm seems less sensitive Goldsman, D., and B. L. Nelson. 1994. 
Ranking, se­to how many observations are drawn in each iteration lection and multiple comparisons in 
computer sim­(although it appears to be better to draw a relatively ulation. In Proceedings of the 1994 
Winter Simula­tion Conference, eds. J. D. Tew, S. Manivannan, D. A. Sadowski, and A. F. Seila, 192-199. 
Institute of Electrical and Electronics Engineers, Piscataway, New Jersey. Gong, W. B., Y. C. Ho, and 
W. Zhai. 1993. A stochastic comparison algorithm for discrete opti­mization with estimation. Preprint. 
Haddock, J., and J. Mittenthal. 1992. Simulation optimization using simulated annealing. Comput­ers and 
Industrial Engineering 22:387 395. Lai, T. L., and H. Robbins. 1985. Asymptotically efficient adaptive 
allocation rules. Advances in Ap­plied Mathematics 6:4-22. Mitra, D., F. Romeo, and A. Sangiovanni-Vincentelli. 
1986. Convergence and finite-time behavior of sim­ulated annealing. Advances in Applied Probability, 
18:747-771. Yakowitz, S. J., and E. Lugosi. 1990. Random search in the presence of noise, with applications 
to ma­chine learning. SIAM Journal on Scientific and Statistical Computing 11:702-712. Yan, D., and H. 
Mukai. 1992. Stochastic discrete optimization. SIAM Journal on Control and Opti­mization 30:594 612. </RefA>
AUTHOR BIOGRAPHIES MAHMOUD HASAN ALREFAEI is pursuing a joint Ph.D. degree in Mathematics and Industrial 
En­gineering at the University of Wisconsin Madison. He received his B.S. and M.S. degrees in Mathematics 
from Yarmouk University in Jordan. His interests in­clude discrete stochastic optimization and simulated 
annealing. He is presently a member of INFORMS and AMS. SIGRfiN ANDRADOTTIR is an Associate Pro­fessor 
of Industrial and Systems Engineering at the Georgia Institute of Technology, on leave from the University 
of Wisconsin Madison where she has held a faculty position since 1990. She received a B.S. in Mathematics 
from the University of Iceland in 1986, an M.S. in Statistics from Stanford Univer­sity in 1989, and 
a Ph.D. in Operations Research from Stanford University in 1990. Her research inter­ests include stochastic 
optimization, simulation and stochastic processes. She presently serves as Asso­ciate Editor for HE Transactions 
and Stochastic Mod­ els. She is a member of INFORMS. 
			
