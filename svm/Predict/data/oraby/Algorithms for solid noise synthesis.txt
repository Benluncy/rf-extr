
 ¢ Computer Graphics, Volume 23, Number 3, July 1989 Algorithms for Solid Noise Synthesis J. P. Lewis 
 Computer Graphics Laboratory New York Institute of Technology ABSTRACT A solid noise is a function 
that defines a random value at each point in space. Solid noises have immediate and powerful applications 
in surface texturing, stochastic modeling, and the animation of natural phenomena. Existing solid noise 
synthesis algorithms are surveyed and two new algorithms are presented. The first uses Wiener interpolation 
to interpolate random values on a discrete lattice. The second is an efficient sparse convolution algorithm. 
Both algorithms are developed for model-directed synthesis, in which sampling and construction of the 
noise occur only at points where the noise value is required, rather than over a regularly sampled region 
of space. The paper attempts to present the rationale for the selection of these particular algorithms. 
The new algorithms have advantages of efficiency, improved control over the noise power spectrum, and 
the absence of arti- facts. The convolution algorithm additionally allows quality to be traded for efficiency 
without introducing obvious deterministic effects. The algorithms are particularly suitable for applications 
where high-quality solid noises are required. Several sample ap- plications in stochastic modeling and 
solid texturing are shown. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image 
Generation; 1.3.7 [Computer Graph- ics]: Three-Dimensional Graphics and Realism -color, shading, shadowing, 
and texture. General Terms: Algorithms, Graphics. Additional Key Words and Phrases: Solid noise, texture, 
stochastic modeling, simulation of natural phenomena, texture syn- thesis, fractals. INTRODUCTION A 
solid noise is a random-valued function f : R 3 ~ R. "Noise" is used to denote a random function with 
some known statistical properties. Solid noises are a subset of the concept of solid textures introduced 
in computer graphics by Perlin [17,18] and Peachy [161). Solid noises have been used for texturing three-dimensional 
ob- jects by assigning the color at a visible point on the surface as a function of the noise value at 
that point in space. In this role, solid textures have several advantages over conventional texture mapping: 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. Surfaces with 
Gaussian curvature can be textured homo- geneously, without distortions such as poles that occur in texture 
mapping. The spatial nature of the noise correlation makes possible certain effects which would be difficult 
with texture map- ping, for example, the "carved out of" effect [18] which uses the fact that noise features 
(e.g. veins in simulated rock) can cross overhangs in the object (Fig. 7). Solid noises also have many 
potential applications in describ- ing complex/irregular forms or movement; a few possibilities are shown 
in Section 5 of this paper. 2 SOLID NOISE ALGORITHMS In all applications, it is desirable that a solid 
noise algorithm be controllable and free of artifacts. Consistent with recent work [ 18,9,11 ], the noise 
power spectrum is considered as a reasonably powerful and intuitive framework for developing control 
over the noise. When the noise is used for surface texturing, efficiency is a major consideration, since 
the three-dimensional variants of even simple computations such as linear interpolation are fairly expen- 
sive when the computation is required at each pixel. It is desirable that the noise synthesis algorithm 
allow quality to be traded for ef- ficiency where appropriate, e.g. for previewing or for background 
objects which do not need a high-quality noise. For most applica- tions it is probably preferable to 
trade some control for efficiency rather than adopting an efficient method that has intrinsic artifacts. 
For animation applications the solid noise should also be ban- dlimited. Although the aliasing of an 
improperly sampled noise function will often not be objectionable in a still picture (due to the same 
principle evident in stochastic sampling [5] -objectionable Moire patterns result from the structured 
sampling of a structured signal), the same aliased noise used in an animation will typi- cally produce 
characteristic "shimmering" or "bubbling" aliasing effects. While a large variety of particular three-dimensional 
random- valued functions are conceivable, most can be decomposed into a basic noise source and some functional 
or procedural transfor- mation of this noise. As argued by Perlin [18], the noise source should be a 
controllable "primitive" that allows the user to de- fine various ad hoc solid noise functions in terms 
of this noise primitive. This paper presents two algorithms for the synthesis of high- quality solid 
noises with control of the noise power spectrum and (optionally) distribution functions. Considerations 
that lead to the selection of these particular algorithms are also described. @1989 ACM-0-89791-312-4/89/007/0263 
$00.75 '89, Boston, 31 July-4 August, 1989 IIII I #define RANTABLEN /* something prime */ float Rantab[RANTABLEN] 
; int Indx [ILEN] , Indy [ILEN] , Indz [ILEN] ; float hash3(float x,y,z) (  int i = HASH( Indx[LOWBITS(x)], 
Indy[LOWBITS(y)], Indz[LOWBITS(z)] ); return( Kantab[i 7. KANTABLEN] ); }  Fig. 1 : Pseudocode for the 
lattice white noise function. 2.1 MODEL-DIRECTED SYNTHESIS Although the linear filtering algorithms for 
obtaining noises having desired power spectra are well understood [13], these algorithms are not ideally 
suited to the requirements of computer graphic modeling and rendering. In particular, in place of the 
regular and ordered sampling that is fundamental to digital signal processing we require a model-directed 
synthesis, in which the noise function is constructed only at particular points determined by the object 
model, and in an order that may depend on the model or the viewpoint. In a texturing application, these 
points are the points on the object's surface that project without occlusion to pixels in a perspective 
projection of the object. Similarly, in a modeling application the noise may be constructed at a limited 
and irregular set of points, e.g., the vertices of a polygonal model. Digital filters assume regular 
sampling and spatial or temporal ordering (causality) of the input signal and consequently cannot meaningfully 
operate at isolated points in space. The direct ap- plication of a digital filtering approach for solid 
noise synthesis would thus result in a solid region of filtered noise enclosing the points of interest. 
This is very costly in terms of storage, since the storage size of a solid noise varies with the cube 
of the reso- lution. The direct FFT or digital filter synthesis of a medium- or high-resolution solid 
noise is usually impractical in this respect. Also it would seem inefficient to construct the noise over 
a solid region when it is only needed at isolated points, though this may depend on the number of points 
required and on the respective algorithms. A third drawback of digital filtering approaches is that since 
the noise is sampled it needs to be interpolated from the sampling lattice to the locations of interest. 
Model-directed synthesis can be achieved by constructing the input noise signal as needed at synthesis 
time, and by employ- ing an acausal and metaphorically continuous rather than sampled filtering approach. 
Since the spatial ordering of the synthesis is unknown, particular regions may be visited multiple times. 
The input noise construction must be internally consistent (in the ter- minology of [8]): independent 
constructions of a particular point must produce the same value. While model-directed synthesis ap- proaches 
are suited for many computer graphics problems, it is evident that they cannot easily use the coherence 
provided by reg- ular sampling and consequently will be more costly than standard filtering approaches 
for constructing regularly sampled noises. 2.2 LATTICE WHITE NOISE A consistent uncorrelated ("white") 
noise can be generated using a hash-like pseudo-random function of the mantissa bits of the lo- cation 
coordinates z, y, z. One such function was described in [4]. A variation of this function uses the low-order 
bits of each coordi- nate (scaled suitably) to index a corresponding randomly permuted 'indirection table' 
of indices into a second table of uncorrelated random values with the desired probability density. The 
three re- sulting indexes are hashed to form an index into the prime-length random value table (Fig. 
1). The HASH3 function generates an uncorrelated periodic noise, with the period determined by the number 
of coordinate bits which are retained. The function takes on new values only on the lattice defined by 
the low bits of the coordinate mantissas, thus "lattice noise". For most purposes it will be necessary 
to interpolate or filter the noise values on the lattice to obtain a continuous and correlated solid 
noise. 2.3 PERLIN ALGORITHM Perlin [17,18] outlined a model-directed solid noise algorithm based on 
interpolating a location hashing function such as I-IASH3. The resulting noise is employed as a spectral 
basis function, with a desired noise ~ being approximated by a weighted sum of basis noises r/k at different 
scales: (1) The characteristics of the resulting noise are determined by the selected interpolation 
approach. The cubic polynomial interpola- tion suggested in [18] has certain disadvantages. Interpolation 
in several dimensions using the separable tensor product of a one-dimensional interpolation scheme results 
in preferred direc- tions along the coordinate system axes; this artifact can only be avoided by using 
an intrinsically multi-dimensional interpolation approach. Cubic polynomial interpolation in three dimensions 
is also quite expensive. The direct tensor product scheme for cubic spline interpolation requires a support 
of 43 = 64 points as well as 16(z) + 4(y) + l(z) = 21 spline evaluations [2]. The inter- polation must 
be repeated for each basis function in the spectral summation (1). One popular implementation of Perlin's 
approach employs Her- mite interpolation, using the lattice noise to define gradients at the (eight) 
nearest-neighbor points on the lattice [10]. These val- ues are separably interpolated using a cosine-like 
function. While this approach is considerably more efficient than a cubic spline interpolation, it has 
stronger directional artifacts (Fig. 2). An-other drawback is that the noise value and second-derivative 
are both zero at the lattice points. The directional trends and regu- larly spaced zeros are visible 
(e.g. see Fig. 3), though it may be possible to disguise them through application of the summation (1). 
In order to be approximately orthogonal, candidate spectral ba- sis functions should be zero beyond a 
particular range of frequen- cies ("bandpass"). Approaches which use standard (meaning non- oscillatory, 
energy minimizing, spline-like) interpolation methods to interpolate an uncorrelated noise lattice produce 
a low-pass rather than a band-pass random function, however, since they do not remove or attenuate the 
low frequency portion of the origi- nal noise power spectrum (which has equal expected power at all frequencies) 
(Fig, 4,) This can be seen in part by considering the zero frequency: interpolation will not remove the 
mean. From a signal-processing viewpoint, standard interpolation methods have ~ Fig. 4: Computed amplitude 
spectrum (zero frequency at left) of a long one-dimensional section of the noise shown in Fig. 2. The 
spectrum is not bandpass. the effect of attenuating high frequencies [19] (also see problem 26 in [3]). 
One misinterpretation of the summation (1) is that, by anal- ogy with Fourier summation, a bandpass noise 
might be produced using a lowpass noise primitive by subtracting a more bandlim- ited noise from a given 
noise, in the hope of removing the low- frequency portion of the spectrum. Power spectra of mutually 
uncorrelated noises cannot be meaningfully subtracted however: S(ql -~) = S(~1 ) -2C(nl, 7~ ) + S(~)where 
C(~/,, ~2 ) = 0 is the covariance between the noises. Eq. (1) is a spectral summation but not a Fourier 
summation. The high-frequency (amplitude) spectrum of the Perlin basis noise using cubic interpolation 
falls off as A-4 since the amplitude spectral envelope of a C~ function is A-~-2 [3]. This also is not 
ideally bandlimited. We conclude that polynomially interpolated noise does not provide an ideal spectral 
basis. The various disadvantages of polynomial interpolation for a spectral synthesis approach are avoided 
in the Wiener interpo- lation algorithm presented in section 3 below. 2.4 GARDNER AND PEACHY ALGORITHMS 
Gardner [9] developed a naturalistic texturing function based on a modified Fourier series. This approach 
is unusual in its use of a conceptually deterministic function to simulate irregular texture. 3 The function 
appears as a product of two one-dimensional series in z and y (as described it is two-dimensional but 
an equivalent three-dimensional function can be formulated). A separable func-tion f(u,v) = f~(u)fv(v) 
has strong directional artifacts that make it unsuitable for simulating a naturalistic texture even if 
the component functions f~, f~ are characteristic sections of the desired texture. Gardner overcame this 
'checkerboard effect' by coupling the phases of each term in the u-series to v, and con- versely. The 
resulting texture is not separable and is sufficiently complex that it mimics a random texture when applied 
carefully. The spectrum of the Gardner function has not been analyzed but is not (as might be supposed) 
directly defined by the Fourier series coefficients. This can be seen by considering the kth term of 
the u-series evaluated along a diagonal profile with u and v varying: fk(u) = ak sin(~ku + [sin(wk_av)) 
 This is a form of frequency modulation. From [1] sin(0 --F I sin/3) = Jo(±) ~in 0 + ~.~ J.([) {si,~(O 
+ k~) + (-~)~ ~in(O -- k~) } k=i I while the computer implementation of any random process is necessarily 
deter- ministic, there is a practical as well as a conceptual difference, in that the period of an n-term 
Fourier series is 2n samples whereas the period of a simulated random process is usually considerably 
larger, as determined by the period of the pseudo-random number function.  Computer Graphics, Volume 
23, Number 3, July 1989 so although the Gardner texturing function has a line spectrum, it is more complex 
than suggested by its Fourier series resemblance (also it is evident that it is not strictly bandlimited). 
Peachy [ 16] proposed solid function generation by the composi- tion (e.g. sum or product) of several 
lower-dimensional functions. If the functions are random the result is a solid noise. As in the Gardner 
algorithm, the composition function can be designed to eliminate separability but the absence of an intrinsically 
three- dimensional correlation structure may be visually evident. 3 WIENER INTERPOLATION ALGORITHM Wiener 
interpolation differs from other interpolation approaches in that it is based on the expected correlation 
of the interpolated function. Since the autocorrelation or autocovariance function is equivalent information 
to the power spectrum, Wiener interpo- lation is particularly suited for noise synthesis where control 
of the noise correlation and spectrum is required. Control of the noise spectrum is intrinsic to Wiener 
interpolation, so problems with band-limiting and the expensive spectral summation (1) are avoided. Wiener 
interpolation has many other potential applications in computer graphics (e.g., as the basis for an improved 
stochastic subdivision method [11], or possibly as an approach to resam-pling stochastically sampled 
images for display). Some additional characteristics and advantages of Wiener interpolation are: -The 
data can be arbitrarily spaced. -The algorithm applies without modification to multi-dimensional data. 
- Wiener interpolation of discrete data is simple, requiring only the solution of a linear equation. 
- In an estimation application the algorithm provides an er- ror or confidence level associated with 
each point on the interpolated surface. - The algorithm is optimal by a particular criterion (see be- 
low) which may or may not be relevant. - The interpolation can be made local or global to the ex- tent 
desired. This is achieved by adjusting the covariance function so that points beyond a desired distance 
have a negligible correlation. - The interpolation can be as smooth as desired, for example, an analytic 
covariance function will result in an analytic interpolated curve or surface. - The interpolation need 
not be "smooth", for example, the correlation can be negative at certain distances, oscillatory, or (in 
several dimensions) have directional preferences.  (The last three properties result from the direct 
spectral control provided by Wiener interpolation.) There are a number of formulations and variations 
of Wiener interpolation [20,7]. A simple probabilistic formulation suitable for solid noise interpolation 
will be used here. The description requires two concepts from probability: - The correlation of two random 
variables is the expectation of their product, E[xy]. The autocorrelation or autocovari- ance function 
of a random process (noise) is the correlation of pairs of points from the process: C(tl, t2) = E [q(t1)77(t2)] 
For homogeneous noise, this expectation is a function only of the distance between the two points: C(t,t 
+ r) =   ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 C(r) = E[z/(t)nn(t + 7")]. The variance is 
the value of the autocovariance function at zero. (Auto)covariance refers to the correlation of a process 
whose mean is removed and (usually) whose variance is normalized to be one. - Expectation behaves as 
a linear operator, so any factor or term which is known can be moved "outside" the expec- tation. For 
example, assuming a and b are known, E {ann + b} = aE[nn] + b Also, the order of differentiation and 
expectation can be interchanged, etc. Wiener interpolation estimates the value ~ of the process nn at 
a particular location as a weighted sum of the values nn~ observed at some number of other locations: 
= ~ a~ ~, (2) The weights aj are chosen to minimize the expected squared dif- ference or error between 
the estimate and the value of the "real" process at the same location: E { (nn -~)2 } (3) The reference 
to the "real" process in (3) seems troublesome be- cause the real process may be unknowable at the particular 
loca- tion, but since it is the expected error which is minimized, this reference disappears in the solution. 
Wiener interpolation is optimal among linear interpolation schemes in that it minimizes the expected 
squared error (3). When the data have jointly Gaussian probability distributions (and thus are indistinguishable 
from a realization of a Gaussian stochastic process), Wiener interpolation is also optimal among nonlinear 
interpolation schemes. 3.I DERIVATION By the orthogonality principle [21,14], the squared error of a 
linear estimator is minimum when the error is orthogonal in expectation to all of the known data, with 
"orthogonal" meaning that the ex- pectation of the product of the data and the error is zero: E{(nn--~)nnk} 
=0 for all k Substituting ~ from (2), E {(nn - E a,~3)r/k} = 0 (4) E {nnnk - Z %nn,,k} : 0 The expectation 
of nn~k is the correlation C(i -ik), and likewise for nn3~k, so: c(t -t~) = ~ %c(t, -t~) or Ca = e (5) 
 This equation can be solved for the coefficients %. The coeffi- cients depend on the positions of the 
data nn3 through the covari- ance function, but not on the actual data values; the values appear in the 
interpolation (2) though. Also, (5) does not directly involve the dimensionality of the data. The only 
difference for multi- dimensional data is that the covariance is a function of several arguments: E[pq] 
= C(xp --xq, yp --yq, Zp --Zq,...). 3.2 COST From (5) and (2), the coefficients aj are a = C-~e, and 
the estimate is it = nntC-lc. The vector c changes from point to point, but nntC-a is constant for given 
data, so the interpolation cost is a dot product =< nntc-~, e > (6) of two vectors whose size is the 
number of data points. 3.3 EVALUATION The spectral definition possible in Wiener interpolation is propor- 
tional to the number of data points considered in the interpolation. For simple spectra requiring a small 
neighborhood of points (e.g. 33 or 43 points), the computation (6) appears to be considerably more efficient 
than polynomial spline interpolation. A fair degree of spectral control can be achieved if larger neighborhoods 
are used, for example, oscillatory (bandpass) noises are possible. The expensive spectral summation (1) 
is also avoided The disadvantage of this algorithm is intrinsic to the approach of interpolating an uncorrelated 
noise lattice: the three-dimensional covariance function, centered at a noise lattice point, should strictly 
be zero when sampled at any other lattice point, since these points are not correlated. For an isotropic 
covariance, this requires that CI(T ) z 0 at distances r = 6~i 2 + j2 + k 2 for all lattice offsets i 
+ j + k >= 1 (6 is the lattice spacing). The co- variance structure is thus artificially constrained. 
If the specified covariance does not satisfy this constraint, the interpolation error (confidence measure) 
will be non-zero and the realized covariance will be somewhat different than that specified. 4 SPARSE 
CONVOLUTION ALGORITHM A second algorithm avoids the covariance function constraints of the noise lattice 
interpolation approach but retains the direct spec- tral control of the Wiener interpolation approach. 
In addition, it has the advantage of conceptual simplicity. In this algorithm a three-dimensional noise 
is synthesized by the convolution of a three-dimensional kernel h(p) with a Poisson noise process 7 ~(P) 
= f~3 ~(o-)h(p -o-)do-(7) The Poisson process consists of impulses of uncorrelated intensity distributed 
at uncorrelated locations in space: 7(P) = ~ ak~(p-- Pk) (Pk is the location of the kth impulse). This 
is a 'sparse' form of white noise, hence "sparse convolution". The power spectrum S v at the output of 
a linear time-invariant filter (expressible as a convolution) is related to the input spectrum S~ by 
[21] sy(~) = s~(~)I~q(j~)l 2 where H is the Fourier transform of the filter impulse response or kernel 
h. Since 7 is uncorrelated its transform is a constant, so the spectrum of a noise synthesized by sparse 
convolution is simply the (deterministic) spectrum of the kernel, scaled by a constant. 4.1 EFFICIENCY 
Sparse convolution has several advantages for digital computation. Because of the impulsive nature of 
the noise, the convolution integral (7) reduces to a summation over the impulses: rl(p) = Z akh(p Pk) 
(8)  ~ Computer Graphics, Volume 23, Number 3, July 1989 Thus, the synthesis is reduced naturally to 
a computationally real- izable form without requiring sampling (and subsequent interpo- lation) of the 
noise. The quality of the noise can be varied as required for the ap- plication by varying the density 
of the Poisson noise. This is an important property, since e.g. background objects or interac- tive previewing 
applications may not require full quality noise. A density of less than one impulse per kernel volume 
produces a "lumpy" noise with little spectral definition. Typical applications require a density of several 
impulses per kernel volume, and noises produced with a density of 10 or more points per kernel are usu- 
ally not distinguishable from those produced by convolving with a uniformly sampled (non-sparse) white 
noise, though the sparse convolution is considerably more efficient. For an isotropic noise the kernel 
h is also isotropic and (as- suming it is non-zero over a finite radius) can be approximately evaluated 
by a one-dimensional table lookup. In this case the sum- mation (8) can be restricted to only those impulses 
7e within the kernel radius of the location /9. The problem then is to identify these points efficiently, 
in particular, without requiring examina- tion of all points and an expensive distance computation requiring 
a square-root. This can be accomplished with an appropriate construction of the Poisson process 7. A 
simple construction is to define a large but finite sampling lattice over the noise domain and approximate 
the Poisson process by choosing N Poisson-distributed impulses in each voxel. The voxels can then be 
numbered, and the voxel number serves as a random number generator seed for generating the impulses within 
that voxel. The lattice spacing and kernel ra- dius are conveniently set to one (with space scaled accordingly). 
Then the impulses lying within a unit radius of a particular lo- cation p are those in the voxel containing 
p and in the adjacent voxels. The summation (8) is modified accordingly. Square roots are entirely removed 
by using the squared distance IP - Pkl 2 to index a prewarped kernel table h(7) = h(vr~). The author's 
implementation of sparse convolution uses stan- dard tricks such as fixed-point computation. In addition, 
the noise impulses Pk are stored in a cache array as they are computed, and are reused if the next location 
falls within the same voxel. With these optimizations, the algorithm using one impulse per voxel is slightly 
slower than the previously described Hermite implemen- tation of Perlin's algorithm, but does not have 
visible artifacts and provides some control over the spectrum. The upper-left panel in Fig. 5 shows a 
planar section of a sample texture generated with the sparse convolution algorithm using a smooth cosine 
kernel 1/2 + 1/2cos(rr), 17-[ < 1.The texture does not reveal the synthesis coordinate system or display 
other artifacts. APPLICATIONS A solid noise algorithm is most useful as a primitive in a lan- guage 
that allows one to easily define functional or procedural transformations of the noise. An important 
characteristic of this language is that it should allow functions to be dynamically de- fined at modeling/rendering/animation 
time -the "user" should have the freedom to define an ad hoc function in the model, rather than requiring 
the original programmer of the graphics system to anticipate and implement libraries of special-purpose 
functions. This requires either an interpreted language or user-compiled func- tions that are dynamically 
linked with the graphics system. An interpreted language was described in [18], while the shade-trees 
approach [6] appears to use compiled functions that are dynami- cally linked to an interpreted expression 
evaluator. In the language approach adopted by the author, a small and portable public-domain Lisp language 
interpreter was adapted to Fig. 8: Porous object model defined by the iso-density surface of a solid 
noise. allow compiled C language functions to be dynamically linked and called from Lisp. This approach 
avoids the definition and implementation of a new special-purpose language, and permits functions to 
be implemented in either Lisp or C or some combi- nation of these. Typically a function is developed 
in Lisp, and if needed the inner loops are reimplemented in C and dynamically "glued" together with Lisp. 
Stepping back from the full power of procedural manipulation of the noise, we note that the special case 
of a functional transfor- mation is useful from an analysis-resynthesis viewpoint, since a desired probability 
density (a commonly measured random texture characteristic) can be obtained by functional transformation 
[12]. 5.1 SOLID TEXTURE Although spectral synthesis adequately simulates most homoge- neous random textures, 
many textures have some structural fea- tures that cannot be simulated using this approach. Such textures 
can often be simulated using a procedural transform of a homo- geneous texture. An example is the marble 
texture described in [18]. Another example of a procedural transform is the solid wood texture shown 
in (Figs. 6, 7). The structure of concentric rings parallel to the tree trunk is produced using a periodic 
or (prefer- ably) quasi-periodic function xtab of the radial distance from the z axis. This function 
describes the color variation across a ra- dial section of a typical ring. Natural irregularity is introduced 
by perturbing the radial distance by a solid noise: ~,ood(p) = ~,tb[~/p.T ~ + p.y2 + ~(p)] (where p.x 
denotes the x-component of p). Various refinements are possible, for example, the radial distance can 
be replaced by a random monotonic function of this distance, thereby creating radial regions of densely 
or sparsely separated rings to simulate periods of slow or fast growth. Fig. 6 shows planar sections 
of several solid wood simulations, where the perturbation noise 7/ and the ring cross section function 
stab are altered to simulate different woods. Fig. 7 shows a figure, model with a solid wood texture. 
This surface/texture combination would be difficult to achieve using texture mapping.  5.2 STOCHASTIC 
MODELING An interesting stochastic modeling approach utilizing solid noise is to define objects as the 
equal-density surface of a solid noise. The overall shape of the object can be controlled by multiplying 
 SIGGFIAPH '89, Boston, 31 July-4 August, 1989 "\ ktD;'c! LI,~I Fig. 12: Trajectories of a number of 
particles forced by a vector solid noise. the noise by an analytic density function that tapers to zero 
outside of the desired object shape. This approach can produce porous and highly irregular shapes such 
as the coral-like form in Fig. 8. 5.3 STOCHASTIC DEFORMATION This is a powerful stochastic modeling technique 
which uses a vector-valued solid noise (vector field) v : R 3 ~ R 3 to perturb an existing object model. 
Three independent scalar solid noises form the components of the vector field. Stochastic deformation 
is particularly efficient for polygonal boundary-represented models, since only the vertices are perturbed. 
Stochastic deformation can be used to simulate the individuality of natural objects by slightly deforming 
a prototype object model (Figs. 9, 11). The noise can be varied to produce either realistic or caricatural 
individuality. Large-amplitude or iterated deformation can produce self-intersecting or twisted forms 
which do not resemble the original object (Fig. 10). A deformation can be animated by offsetting the 
object location by a continuously changing vector before perturb- ing, effectively moving the object 
through the noise. 5.4 CORRELATED FLOW Solid noises may be employed as a correlated random environmen- 
tal factor for many physically motivated simulations. For exam- ple, a solid noise can be used as a force 
field to produce turbulent trajectories or flow. Fig. 12 shows the trajectories of a number of particles 
obeying a simple dynamics equation ~ = 7/(p). The resulting collection of trajectories displays bifurcations 
and resem- bles animal fur and other natural structures. Fig. 13 is a frame from a brief animation in 
which the trajectories are animated by the previously mentioned technique of moving the model through 
the noise. The trajectories are rendered to produce the effect of an "organic fireball". 6 CONCLUSION 
In addition to their demonstrated use in solid texturing, solid noises have direct applications in stochastic 
modeling. In both model- ing and texturing it is desirable that the solid noise synthesis be controllable, 
efficient, and free of artifacts. Spectral synthesis pro- vides a framework for assessing the control 
and quality of various synthesis approaches. Existing solid noise algorithms were sur-veyed from this 
viewpoint. 268 Two new algorithms were described and evaluated. Both al- gorithms provide improved spectral 
control and efficiency. The sparse convolution algorithm is attractive in that it allows a trade- off 
between quality and efficiency as required by the application, without introducing gross artifacts. Several 
solid texturing and stochastic modeling examples visually illustrate the control and quality achievable 
with this algorithm. Symbols S(A) power spectrum C(r) autocovariance function h filter kernel 7 uncorrelated 
noise 7/ correlated synthesized noise p, o" locations in space )% a2 frequency, angular frequency Acknowledgements 
The figure model in Fig. 7 was developed by Dick Lundin and Susan VanBaerle. The head model used in Fig. 
9 was developed by Fred Parke [15] with additions by Rebecca Allen, Steve Di- Paola and Robert McDermott. 
Thanks to Paul Heckbert and Lance Williams for discussions. References <RefA>[1] Abramowitz, M. and Stegun, 
I., Handbook of Mathematical Functions. Dover, New York, 1965. [21 Bohm, W., Farin, G. and Kahmann, J., 
A Survey of Curve and Surface Methods in CAGD. Computer Aided Geometric Design 1, 1 (1984), 1-60. [3] 
Bracewell, R., The Fourier Transform and Its Applications. McGraw-Hill, New York, 1965. [4] Carpenter, 
L., Computer Rendering of Fractal Curves and Surfaces. Supplement to Proceedings of SIGGRAPH '80 (Seattle, 
July 1980). In Computer Graphics 14, 3 (July 1980), 180. [5] Cook, R., Stochastic Sampling in Computer 
Graphics. ACM Transactions on Graphics 5, 1 (January 1986), 51-72. [6] Cook, R., Shade Trees. Proceedings 
of SIGGRAPH '84 (Minneapolis, July 23-27 1984). In Computer Graphics 18, 3 (July 1984), 223-231. [7] 
Deutsch, R., Estimation Theory. Prentice-Hall, New Jersey, 1965. [8] Foumier, A., Fussell, D., and Carpenter, 
L., Computer Ren- dering of Stochastic Models. Communications ACM 25, 6 (June 1982), 371-384. [9] Gardner, 
G., Simulation of Natural Scenes Using Textured Quadric Surfaces. Proceedings of SIGGRAPH '84 (Min-neapolis, 
July 23-27 1984). In Computer Graphics 18, 3 (July 1984), 11-20. [10] Heckbert, P., Personal communication, 
[1 l] Lewis, J.P., Generalized Stochastic Subdivision. ACM Trans- actions on Graphics 6, 3 (July 1987), 
167-190. [121 Lewis, J.P., Methods for Stochastic Spectral Synthesis. In Proceedings of Graphics Interface 
86 (Vancouver, May 1986), 173-179.</RefA>     
			
