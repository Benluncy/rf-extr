
 Algorithms for Loading Parallel Grid Files * Jianzhong Lit Doron Rotem$ Jaideep Srivastava$ Information 
and Computing Science Division Lawrence Berkeley Laboratory, Berkeley, CA 94720 Abstract The paper describes 
three fast loading algorithms for grid files on a parallel shared nothing architec­ture. The algorithms 
use dynamic programming g and sampling to effectively partition the data file among the processors to 
achieve maximum parallelism in answering range queries. Each proceezor then con­ structs in parallel 
its own portion of the grid file. Analytical results and simulations are given for the three algorithms. 
 1 Introduction In this paper we study efficient multiprocessor algo­rithms for initial loading of large 
existing data files into a spatial data structure. This work is motivated by scientific and GIS applications 
such as climate modeling, seismic studies and physics experiments, where large data files are generated 
by simulation programs or by collecting recorded measurements of a large number of sensors. Various subsets 
of this large volume of multidimensional data, which often residea on robotic tape libraries, must be 
loaded into an appropriate disk based spatial structure for the purpose of analysis, querying and visualization. 
In such applications, loading of a new subset is per­ Suppcrted by the U.S. Department of Energy under 
Con­tract DEAC03-7SSFO(WBS. tG l-W ~m HdoI@q University, P. R. ChiUA t ~ ~jth ~~t of ME s-J-state ~vaty 
$Is with the Computer Science Department, Univemity of Minneeota at Minneapolis. Permission to copv 
without fee all or part of this matarial is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and tha title of the publication and its data 
appaar, and notice ie given that copying is by parmiesion of the Aaaociation for Computing Machinary. 
To copy otharwise, or to rapublish, requires a fea and/or specific permission. SIGMOD 151931Washirtgton, 
DC, USA 01993 ACM 0-89791 -592-519310005 /0347 . ..$1 .50 formed frequently as users shift their focus 
of atten­ tion to different regiona of intereat within the original file. Additional cases where fast 
loading is important include:  Recovery -Reconstruction of a spatial structure afler recovery fkom a 
disk failure may involve loading of large files from backup tapes or disks.  Reorganization -Dynamic 
spatial data structures may suffer from deterioration of storage utilization over time due to large directory 
and sparsely filled data pages. The algorithms described here can be used to restore the storage utilization 
to an accept­able level while reloading the fle.  There are quite a few papera in the literature deal­ing 
with efficient retrieval of spatial data structures on parallel architectures [LSR92,GAK90,FKK91]. The 
objective of these research worka is to find meth­ods for distributing the data among processors irt 
or­der to balance the work involved in computing the answer to a query. However, to the best of our knowledge, 
very little research work has been done on the initial loading of the spatial data structure which may 
become a serious bottleneck in the above mentioned applications. In the case of one dimen­sional data, 
there has been some work on fast loading of B-trees [ROS81] and many commercial database systems have 
bulk loading utilities which allow fast construction of index structures while loading the database. 
Many dynamic spatial data structures are baaed on some partitioning of the space into regions with the 
property that the data that belongs to one region fits on a single disk page. The partitioning points 
along each dimension and the assignment of disk pages to regions are maintained in some type of directory 
con­sisting of one or more levels. Growing a spatial data structure dynamically by inserting individual 
records one at a time may be a relatively slow process as each disk page overflow may require updating 
the directory, as well M mov­ing some data from the overflowed page into a newly created one. Furthermore, 
in some data structures, a single insert ion may cause several disk 1/0 s due to a chain of page splits. 
In this paper we show that in case the data already exists in some format, a much faster bulk loading 
process is poseible. The idea behind our algorithms is to perform some precomputation on the input file 
and use the results to determine optimal or close to optimal partition­ing points along each dimension 
such that the file to be loaded can then be partitioned among the proces­sors. This phase is called logical 
partitioning and its main goal is to achieve a balanced work load among the processors for computation 
of answers to range and partial match queries. The second phase, called physical partitioning, is performed 
in parallel by all processors. Each of the processors performs some precomputation on the subfile assigned 
to it in the previous phase. The results of this precomputation are then used in constructing their subdirectories 
and loading their portion of the data. In this paper we are concerned mainly with effi­cient parallel 
loading of grid files. However, similar techniques can be used to parallelize the loading of other director 
y based spatial data structures. The paper is organtied as follows. In Section 2 some background and 
terminology are introduced. In Section 3 we describe the parallel grid file structure. In Section 4 three 
parallel loading algorithms are de­scribed. In Section 5 we analyze the overflow gen­erated by the sampling 
procedure. In Section 6, we present simulation results and comparisons between the algorithms. Finally, 
in Section 7 some conclusions and directions for future research are given. Proofs for the lemmas and 
theorems are provided in the Ap­pendix.  2 Terminology and Background 2.1 Parallel Computing Architecture 
For ease of presentation in this paper, we assume a shared nothing multiprocessor architecture, where 
each processor has one dedicated disk [STC)86]. The processor interconnection is a hypercube which is 
one of the most versatile and efficient networks yet dis­covered for parallel computation. It is well 
suited for both special-purpose and general-purpose tasks, and it can efficiently simulate any other 
network of the same size. It can solve arbitrary message-routing problems in 0(log22V) steps where N 
is the number of processors. A processor with its associated pri­ vate memory and dedicated disk is called 
a processing node. We assume that the file to be loaded is initially stored at a processing node, called 
the coordinator. 2.2 Multidimensional Database Files Let Di (1 < i < d)beanordered set. A d­dimensionai 
jile scheme on Dl, . . . . Dd consists of d attributes Al, A2, .... Ad where Di is defined to be the 
domain of attribute Ai. An instance of a d­dimensionaljile scheme is a non-empty set of records, where 
a record is an ordered d-tuple (rl, ra, .... rd) ~ D1 X D2 X ... x Dd and ri is the value of the record 
on attribute Ai. In the rest of the paper we simply call both a d-dimensional file scheme aa well as 
its instance a d-dimensional jile or file. For simplicity, we assume that all files are subsets of the 
unit space S = [0, l)d. However, one should note that the al­gorithms in this paper are not limited to 
the space s.  2.3 Grid File Structure A grid file is a multi-dimensional file structure [NIE84] in which 
records of a d-dimensional file are represented aa points in a d-dimensional space. The space is divided 
into a set of hyper-rectangles called grid blocks, each of which is assigned to a disk page. Several 
grid blocks forming a hyperrectangle may be assigned to the same disk page. A grid file consists of a 
grid directory and a space partitioned by a grid partition scheme. A grid partition scheme can be obtained 
by impos­ing intervals on each axis and partitioning the space into blocks. The grid partitioning scheme 
ia com­posed of d one-dimensional arraya called linear scales, each of which defines a division of a 
dimension of the space. During the operation of a grid file sys­tem the underlying partition of the space 
may need to be modified in response to splitting an interval or merging of two adjacent intervala. The 
task of the grid directory is to assign grid blocks to disk pages. A grid directory consists of a dynamic 
d-dimensional array whose elements (point­ers to data pages) are in one to one correspondence with the 
grid blocks of the partition. When the as­signment of grid blocks to pagea changes, an update of the 
directory is needed. In the grid file structure, an exact-match query needs only two page accesses: 
the first access to the directory and the second to the correct data page. The grid file can process 
range queries with respect to all attributes efficiently because it can preserve the order defined on 
each attribute domain so that records being near in the domain of any attribute are likely to be on the 
same page. Partial match queries, which are a special case of range queries, are efE­ciently supported 
as well. 2.4 Multidimensional Data Decluster­ing for Grid Files Multidimensional declustering is a partitioning 
scheme which determines which part of the data will reside on each processing node. As the size of an 
answer to a range query may be very large, the ob­jective of multidimensional declustering is to achieve 
balance among the processors in computing the re­ sults of such queries. s Parallel Grid File Structure 
A parallel grid file system is a two level structure. One is a logical parallel grid jile structure and 
the other is a physical pamllel gm d jile structure. Most of the concepts in this section were first 
introduced and proved in [LSR92], in order to make this paper self contained we discuss here briefly 
the main results of that work, 3.1 Logical Parallel Grid File Struc­ture Given a d-dimensional file F, 
this structure deacribea the logical grid partition of F and the assignment of the logical grand blocks 
resulting from the partition to proceaaing nodes. The capacity of a logical grid block is not necessarily 
equal to the size of a disk page. It is determined by the expected area of a range query as explained 
in [LSR92]. In general, if range queries typically cover a small area compared to the space covered by 
the grid file, smaller logical blocks are needed to guarautee maximum parallelism. 3.1.1 Logical Grid 
Partitioning Given a d-dimensional file F and capacity C of a log­ical grid block, the primary objective 
of the logical grid partitioning is to partition F into grid blocks by dividing ali Di s into intervals 
such that the data skew among blocks is minimized. In this paper, the metric used to measure the logical 
data skew of a partition­ing scheme is simply the total absolute deviation of all partition blocks from 
C, the logical capacity of a grid block. This measure assigns an equal penalty for overflow and underflow. 
As we typically do not allow overflow in grid files, we use total overflow as the metric for measuring 
physical data skew. (See next section for a formal definition). The algorithms can be adapted to minimize 
objective functions bssed on other metrics such as worst case deviation. A simple method of declustering 
F is to divide each dimension into equally spaced intervals. How­ever, if F is not uniformly distributed, 
this may lead to a large imbalance between the number of points in ~each block. Our strategy is to partition 
S into ~i=l ni logical grid blocks where ni s are determined by partitioning algorithms which are sensitive 
to the distribution of F. These partitioning algorithms will be discussed in detail later. Here we only 
provide an overview of the logical grid partitioning. The partitioning of F is represented by d vec­tors, 
called partition vectors. The $*h partition vec­tor describes the partition of the ith domain Di, which 
is defined as Vi = (Pi, P2, . . . . p~i-1)~ where o<pl<p2 <... < pni-l< 1 are the points that partition 
Di into ni intervals [0, PI), h, P2), ... . bn,-1, 1), forl~i~d. The intervale on each dimension are 
numbered from O to ni 1. The kth interval of Di is denoted by likl for O ~ k ~ ni 1. We define the 
coonlinate of the interua/ Iik to be k. Hereafter, we use [~ki, hki) to represent interval Iki. Consider 
two inter~ Iikl and ~ik2. If kl < k~, then every point in interval ~ikl is leaa than every point in interval 
&#38;k,. After logical grid partitioning, F is divided into ~~=1 ni logical grid blocks, where a logical 
grid block is the cross product of d intervals, i.e., [zl~, , hlkl) x [~2k,, ~2ka) x . . . x [hk,, hikt), 
where, O~ kj ~ nj 1, 1~ j ~ d. We define the coordinate of the logical grr d block above to be (kl, k2, 
.... kd). The logical grid block with coordi­nate (kl, ka, .... kd) is represented by Rkl, k=, .... k,. 
In the rest of the paper, we use capital letters X, Y, ... to represent the coordinates of regiona in 
S and % Y) .,, to represent the coordinates of the records in F, i.e. points in space S.  3.2 Assignment 
of Logical Grid Blocks First, .we define an allocation function, called Coordi­nate Modulo Declustering 
(CiWD), which determines the processing node to which a logical block is as­signed, It is defined as: 
C~D(Xl, X2, .... Xd) = (XI +X2+... + Xd) ~o~ ~. The region (Xl, X2, . . . . Xd) iS assigned tO prOCeSS@ 
node CMD(XI, X2, . . . . Xd), where the ~ process­ ing nodes are numbered O, 1, .... N 1. After the 
logical grid partitioning and the alloca­tion of the logical grid blocks to processing nodes, we have 
a logical parallel grid jile structure for the file F, denoted by (F, (VI, .... Vd), CkfD) where K is 
a (ni -1)-dimensional partition vector, for 1 s i ~ d.  3.3 Physical Parallel Grid File Struc­ture Given 
a d-dimensional file F and its logical parallel grid file structure, the physical parallel grid file 
struc­ture describes the organization of the subfilea of F on processing nodes, In the following, let 
Fi and Si rep resent the subfile of F and the subset of S allocated to processing node i for O ~ i ~ 
N -1. In general, any uniprocesaor spatial data structure can be used in conjunction with the logical 
parallel grid file to implement a complete parallel file struc­ture. In this paper, we use the uniproceasor 
grid file structure to organize Fi on processing node i. The regions in S which are assigned to Fi lie 
along paral­lel diagonala in the logical parallel file structure, and form a highly non-uniform subspace. 
It ie therefore not efficient to organize Fi by directly using a grid file structure. To solve the non-uniformity 
problem, we define a coordinate transformation function on Si to map Si into a d-dimensional rectangle 
and map Fi into a uniformly distributed file in this rectangle. In the 2-dimensional case, the transformation 
we define amounts to collecting from each column only those regions which are assigned to processing 
node i col­lapsing all the other regions. 4 Parallel Loading Algorithms In this section, we develop three 
parallel algorithms for loading parallel grid files. The algorithms ditTer by the coat of precomputation 
they perform on the initial file. Given a d-dimensional file F, the foIlowing three tasks need to be 
performed by a loading algorithm 1. Create the logical parallel grid file structure for F; 2. Create 
the physical parallel grid file structure for each F; 3. Load the data of F into the parallel grid file 
resulting from steps 1 and 2.  In order to guarantee load balancing on procem­ing nodes and high parallelism 
and low 1/0 cost for query processing, the objective of the algorithms is to minimize the total data 
ouerj?ow of the physical grid blocks and the total data skew of the logical grid blocks. The total data 
ouetj?ow of the physical grid blocks is defined as ~=1 MAX(O, Ci -c), where P is the number of disk pages, 
Ci is the size in bytes of the t%h physical grid block and c is the capacity of disk page. The total 
data skew of the logical grid blocks is defined M ~i=l p I LC i -C 1, where LP is the number of logical 
grid blocks, LCi is the size in bytes of the irh logical grid block, and C is the capacity of a logical 
grid block. 4.1 Two Phase Optimal Algorithm In this section, we present a two phase optimal al­gorithm, 
called TOPLOADING. The algorithm per­forms logical and physical partitioning of file F in two phases. 
In the logical partitioning phase, it par­titions F into h x u logical grid blocks, where h and u are 
fixed and depend on the properties of the queries on F. Baaed on a theorem proven in [LSR92], it is beneficial 
to have at leaet one of them be of the form kN for some integer k so that the data distribution among 
processing nodes will be balanced. After the logical partitioning phaae, the logical grid blocks are 
allocated to processing nodes according to the CMD function, and the partition Fi of F is sent to pro­cessing 
node i, for O ~ i ~ N 1. In the physical partitioning phase, all the processing nodes perform the physical 
partitioning of Fi s in parallel and create the grid files for all Fi s. Finally, the parallel grid file 
is built from F and the data is loaded into it. 4.1.1 Multidimensional Partitioning of F The goal of 
this subsection is to present a dynamic programming formulation for the optimal solution of the logical 
and physical partitioning problems. For expository purposes, we present the model for the two dimensional 
case where each attribute has the same number of values. The model can be generalized to any number .of 
dimensions and an arbitrary number of possible values per attribute. In the following dis­cussion, we 
use the term block to denote physical or logical grid block. Let ~ =< vil,via) .... vin > be the sorted 
set of vaiues in Di, the domain of attribute Ai, for i = 1, 2. For any pair of values vli and v2j, there 
maybe more than one record in F whose values on Al and Aa are vli and v2j respectively, Let FM be a n 
x n matrix, called frequency matriz, whose elements fij S am the count of the records with values vli 
and vzj. Thus, fij = Il{r I r GF, r[A~]= vli and r[4 = v~j}ll l~i,j~n, where r[Ai] denotes the value 
of record r on attribute Ai. In order to partition F into K blocks, we only need to partition the matrix 
FM. FM has to be par­titioned by horizontal and vertical lines into K blocks such that some cost function 
is minimized. The par­titioning of FM induces a similar partitioning on the records of F. Given a pair 
of integers nl and nz, they are called permissible factors of K if nl x nz = K and ni s n for i = 1, 
2. We partition the matrix FM into K blocks by partitioning the rows into nl segments and the columns 
into n2 segments. This is done by placing nl -1 horizontal lines between the rows and nz 1 vertical 
lines bet ween the columns. Let FM(r, s) be the n x (s -r + 1) submatrix of FM which includes the elements 
fij for 1 ~ i s n and r s j ~ s, and T be a tied partitioning of the rows of FM into nl segments. We 
denote by OSr(i, j) the total data skew or total data overflow from the partitioning of FM(i, j) into 
nl blocks by horizontal lines in r only, i.e., no vertical lines are placed anywhere between columns 
i and j. We consider possible partitions of the submatrix FM(1, j) by placing vertical lines and without 
chang­ing the position of the horizontal lines in r. Let Z OST(j, 1) be the total cost incurred by optimal 
par­titioning of FM(1, j) using I -1 vertical Iinea into 1x nl blocks given the fixed partitioning fi. 
Based on the principle of optimalit y [HOR78], we can give the following recursive equation: ToS.(j, 
/) = MINi=/-l,...l{To sm(i,(i, 1 1)+ OSm(i+ l,j)}for 1<1 ~ j TOSW(j, 1) = OSX(l, j) for j ~ 1. The 
first term in the first equation is obtained by optimally partitioning the first i columns (1 -1 ~ i~j 
1) into 1 -1 segments and placing a verti­cal line after column i, and the second part consists of columns 
i + 1 up to j, which are all placed in a single segment. The equation stat-that the optimal partitioning 
is obtained by a value of i which mini­mizes the sum of coats from these two parts. Thus, the optimal 
solution for the factors nl and nz under the fixed horizontal partitioning r is TOSm(n, n~). 4.2 Model 
of Logical Partitioning In the logical partitioning phase of the TOPLOAD-ING algorithm, F is partitioned 
into h x v logical M and replacing OS and grid blocks. Letting C = ~Xv TOS with LSKEW and LTSKE W (for 
logical skew parameters) in the recursive equation above, we get the mathematical model of the skew of 
the logical partitioning as follows. LTSKEWX(j, 1) = MIiVi=l_l,...,l{ LTSKEW~(i,i, 1 1)+ LSKEWr(i + 
1, j)} (1 <1 <j) LTSKEW*(j, 1) = LSKEW,(l, j) for j z 1 LSKEWm(i,j) = ~ I ck -cl, k=l  where, c1 = ~~=i 
z% ~SYI Ch = ~~=i ~&#38;-1+1 fSY~ Ck = ~~=i %=p_I+l f~~ or2~ k~h-lJad pl, .... ph-1are t e positions 
of the h -1 horizontal lines in x. The optimal solution of partitioning F for h and v, under a Iixed 
horizontal partitioning % is LTSKEW, (n, u). 4.2.1 Model of Physical Partitioning Let Fh-fk be the local 
frequency matrix of Fk for O s k s N 1. The physical grid partitioning uses processing node k to partition 
Fhfk such that the to­tal overflow of the physical grid blocks of Fk is mini­mized for O S k S N -1. 
Replacing 0S7 and TOS~ by OVERF~ and TOVERF~ in the recursive equa­tion in subsection 4.1.1, we get the 
model of physical grid partitioning of Fk as follows for O ~ k ~ N 1. TOVERF~(j, 1) = MINi=l-l,.,j-l{ 
TOVERF$i, 1 _ 1)+ OVERF~(i+ l,j)) (1< 1 ~ j) TOVERF~(j, 1) = OVERF#(l, j) for j ~ 1 OVERF$(i, j) = ~ 
MAX(O, C~ -c), k=l where, Cl = x~si ~~~1 f~y! Ctll = ~~=i ZLpm,.l+l f~y! ck = ~~=i ~?z ,.1+1 fk39 for2~k~nl 
l, f&#38;is a element of Ftik, and pl, .... pnl _l are the positions of the nl 1 horizontal lines in 
T. The optimal solu­tion of partitioning Fk for a pair of factors, z and y, under a fixed horizontal 
partitioning T is TOVERF~ (n, y) for O~k~N -1.   4.3 Performance Analysis of the TOPLOADING Algorithm 
The response time of an algorithm is the elapsed time from the start to the end of the algorithm s execu­tion. 
Theorem 4.1.1 gives the response time of the TOPLOADING algorithm. Theorem 4.1.1. the response time of 
the TOP LOADING algorithm is 3P ~++) +% (% : + ti/.(2P + ~ + Nc () 2*(7ap)l.5 +[FI ~+ N+h+v)+ N twmn(nz 
+ 310gzN + : () +(h + )N +q~ -;)). log2N 4.4 Random-Optimal Two Phase Al­gorithm In this section we 
develop a more efficient random algorithm. It can give optimal or near optimal solu­tions for the data 
loading problem with high proba­bility. It requires much lesser CPU, communication and 1/0 times than 
the algorithm in section 4.1. This is also a two phase algorithm. In the first phase, it uses random 
sampling to create the logical grid file structure for given file F and allocates the data of F to processing 
nodes according to the CMD function. In the second phase, it creates the physical grid file structure 
for F and loads F to the parallel grid file, using dynamic programming. The logical partitioning in the 
first phase randomly selects samples from F, sorts them on each dimen­sion, and determines psxtitioning 
points on each di­mension using the sample quantiles as in [SSN92]. In the second phase, the physical 
partitioning is performed by using processing node i to solve a dy­namic program on the subfile Fi, for 
O ~ i < N -1. The mathematical model of the physical partitioning is the same as in section 4.1.3. 4.5 
Performance Analysis of the ROTLADING Algorithm Assuming that each sample needs one disk page ac­cess, 
Theorem 4.2,1 gives the response time of the ROTLOADING algorithm. In the following, SN is the sample 
size used in logical partitioning. Theorem 4.2.1. The response time of the ROT-LOADING algorithm is h+v 
ti/O(SN + P + y+ $+*)+ t .Omm(li(l -~N)+ logzN) + 2*(rap)l 5 IF I + 2SN/og@N -t h+ u+ CPU( N N). 4.6 
Fully Random Two Phase Algo­ rithm For further reducing CPU cost, we propose a fully random algorithm. 
This algorithm sk has two phases. in the first phase, it uses random sampling method to do the logical 
grid partitioning, creates the logical parallel grid file structure for a given file F, and allocatea 
the logical grid blocks to processing nodes according to the ClkfD method. In the sec­ond phase, it uses 
processing node i to perform the physical partitioning of subfile Fi of F allocated to processing node 
i also by random sampling method, creates grid file structure for Fi, and loads Fi into the grid file 
for O~i~N L Since this algorithm uses random sampling in both phases, we call it the fully random algorithm, 
denoted by FRLOADING. 4.7 Performance LOADING Al Analysis gorithm of the FR- Theorems LOADING Theorem 
LOADING 4.3.1 gives algorithm. 4.3.1. algorithm the The is response response time time of of the the 
FIL FR­ tilO(SN1 + P + ;+ ;(1 + ~)+SN2 + +)+ tepu(2(SN210g2SN2 + SN110g2SN1) + t .Omm(l?(l -~N)+ log2N), 
 where, SN1 and SN2 are the sample sizes used in logical and physical partitionings. 5 Effect of Sample 
Size on Data Overflow In all sampling baaed methods there is always a non­zero probability that the number 
of records assigned to a block will exceed page capacity and cause a page overflow. It ia quite easy 
to deal with such overflows by creating a general overflow area or using separate chaining for each overflowed 
page. However, grid files do not allow data page overflows in order to guarantee at moat two 1/0 s for 
exact match queries. In this section we will derive a general bound on the probability that a block of 
the partitioning over­flows. This can be used by the designer in determin­ing proper values for s, the 
sample size, and a the storage utilization factor. The idea is to use known bounda for a d 1 di­mensional 
file to derive a bound for a d dimensional file. We derive it here only for d = 2. For ease of presentation 
we will use the term column to de­note all blocks between a pair of successive vertical partitionings. 
Let X = {ZI, Z2, .... ZM} be a collec­tion of M keys. Let 13X(s, a, k, M) be a bound on the probability 
that in partitioning X into k parts based on a sample of size ks (using sample quan­tizes), one part 
contains more than ~ keys. Let XY = {(zl, yl), (z2, y2), ,.,, (z~, y~)} be a set of M two dimensional 
keys. We partition XY by taking a sample of size us of the z values of each key and determine u 1 partitioning 
pointa along z-axis and then take a sample of size hs from the v valuea of each key. Let BXY(S, a, u, 
h) be a bound on the proba­bility that a block of this partitioning has more than * elements of XY. Theorem 
5.1. BXY(8, a,u, h) < v x [BX(s, a,u, M) +(1 l?X(s, a, u, M)) x h x BX(s, a,h, :)1. Proof (Sketch): 
The first term in the angular brackets represents the fact that in case one column of the partitioning 
overflows at least one block in that column will also overflow. The second term repre­sents a bound on 
the probability of the event that a column does not overtlow (i.e. has at most aM/v keys but at leaat 
one block in that column still over­flows. The above formula is general for any known one dimensional 
bound. In particular we use the best known bound given in [SSN92,SES92] k -a - l?X(8, a,k, M) = a ~ 
(-)  to derive: h-a -s 1 m h () Figure 1 shows the quality of this bound for a be­tween 1.5and 1.8and 
h= u= 50. 6 Simulation and Comparisons In this section, we examine the performance of the proposed algorithms 
by simulation. We investigate the effect of sample size on the total data skew of logical or physical 
grid blocks resulting from sampling partitioning methods. We also compare the response time of the algorithms 
using the analytical results in section 4. The system parameters used in our simu­lation are as follows: 
\ 0.06 . 0.0s . 0.44 . 0.03 0.02 . 0.01 . ( ! 1.5s 1.6 1.6s 1.7 1.7s 1.8 Figure 1: Bounds on the probability 
of at least one block overflowing. I Number of processing I N = 64. I nodes: CPU processing rate: 20MIPS. 
1/0 bandwidth: !5Mbytes/second. Effective corninunication 10Mbytes/second. channel bandwidth: Capacity 
of disk page: 4k bytes. These parameters are comparable with that in [OM192] and ~UA90]. 6.1 Effect 
of Sample Size on Data Skew of Logical Partitioning We ran the algorithm on 4 randomly generated files 
with different size each. The sizes of the files are 50000,100000, 150000 and 200000 records. The block 
size is 100 records. Fig. 2 shows the results. In the legend of the figure, 50, 100, 150 and 200 are 
in units of 1000. From Fig. 2, we can see that the sampling partition method works well for a large range 
of files. When the sample size b greater than zi~o, the data skew is less than 4% and the method is almost 
in­dependent of file size. 6.2 Effect of Sample Size on Data Overflow of Physical Partitioning To examine 
the effect of sample size on total overflow of physical grid blocks, we implemented the physi­cal sampling 
partition method in the FRLOADING algorithm. We ran the program on a file of 1000000 randomly generated 
records for grid block sizes of 400 ...... ...... ......... ........ .. ............. 14 12 -o . ------; 
-------. . ------------; ----.-----; h h 10. .. -----. -:-------. --~----------; . ------.-.: . .. 
......................... ........... % g -8. --­ . . ............... .. . .......... 4 ........ ..>... 
.................. . ......... . 2 0# 123 45 Figure 2: Effect of sample size on data skew for dif­fer;nt 
file sizer Figure 3: Table 3. Comparisons of A.O. and N.O between dynamic programming g and Sam­pling 
algorithms. records with system page capacity 400. The domain size of each attribute of the file is 1000000. 
We also implemented the dynamic programming physical partitioning algorithm. We ran the sam­pling and 
dynamic algorithms on a file of 10000 ran­domly generated records with system page capacity 100. The 
domain size of each attribute of the file is 15. In Table 3, we compare A.O. and N,O. between the dynamic 
progr amrning algorithm and the sam­pling algorithm for various values of SY. The sample size is 3% of 
the total file size. As we can see from this table sampling provides a reasonable estimation as compared 
with the optimal solution. 6.3 Comparison of Response Time Fixing n, the size of domains of all attributes, 
to 65, we first compare the response time of the algorithms for increasing file size using the analytical 
results of section 4. For comparison, we assume that record 2.N 4.1* 4.*. *. 1,7 ,. Z,* a.u 4.S* 6.1** 
a.1, L J Figure 4: Comparison of response time for varying file size. size ia 200 bytes, h = v = 64, 
and sample size is 5000. Fig, 4 shows the comparison of response times for files with sizes varying from 
10s bytes to 10g bytes. In the two figures, the time unit is seconds. It is obvi­ous that all the algorithms 
are very efficient for a large range of file sizes. In these figures, i.e. for n = 65, the TOPLOADING 
algorithm is always slower than the other two because of the high cost of dynamic programming. However, 
this algorithm can provide an optimal solution and can work very efficiently for small n. Fig. 4 also 
shows that the ROTLOADING algorithm is fsster than the FRLOADING algorithm for files with size less than 
10s bytes. The resaon is that the response time in this case is dominated by the 1/0 time for acceasing 
samplea and the FRLOAD-ING algorithm needs more time to read the samplea in the physical partition phase 
than the ROTLOAD-ING algorithm. In the following discussion, we fix the file size to 10s bytes, We assume 
that record size is 200 bytes, h = v = 64, and sample size ia 5000. 100 . 2s0 . 200 . 150 .  100 50 
I 100 200 300 400 543 Figure 5: Comparison of response time of the ROT-LOADING and FRLOADING algorithms 
for varying size of attribute domains Fig. 5 shows the comparison of the response time of the ROTLOADING 
and FRLOADING algorithms when n variea from 10 to 500. This figure shows that the ROTLOADING algorithm 
is more aemitive to n than the FRLOADING algorithm due to the dynamic programming in the physical partitioning. 
When n is less than 150, the ROTLOADING algorithm ia more efficient than the FRLOADING algorithm. The 
rea­son ia that the 1/0 time for accessing samplea is the main part of the response time in this case 
and the FRLOADING algorithm needa more 1/0 time to read the samples in the physical partition phase than 
the ROTLOADING algorithm. 7 Conclusions and Future Re­search Three algorithms for loading parallel grid 
files, namely TOPLOADING, ROTLOADING and FIV LOADING, have been proposed in this paper. The TOPLOADING 
algorithm ia based on dynamic pro­gr amming. It givea optimal solutions for the logi­cal and physical 
partitioning problems. However it ia only efficient for small n, the number of different values in domains 
of attributes of a given file. The ROTLOADING algorithm ia bzsed on the combina­tion of the dynamic progr 
amming and estimation of population quantilea using sampling. It givea a near optimal solution for the 
logical partitioning problem by sampling and optimal solution for physical par­titioning problem by dynamic 
progr amming. It is [NIC92] less sensitive to n and much more efficient than the TOP LOADING algorithm. 
However, it will be in­efficient when n is very large. The FRLODING al­gorithm is the most efficient 
algorithm. It gives near optimal solutions for logical and physical partitioning [NIE84]problems by sampling. 
The theoretical and simula­tion results show that this algorithm can efficiently work for any n and give 
very near optimal solutions with small number of samples. [OM192] Our ongoing research is addressing 
the following issues: 1. Analysis and experimentation of our algorithms for different data distributions 
including correlations between attribute values on the two dimensions.  2. Developing algorithms for 
loading other data structures such as Quad tree, R-tree, etc. [ROS81] 3. Developing loading algorithm 
for other parallel computing architectures.  [ROT88] References <RefA>[GAK90] Abdel Ghaffar K. and El Abbadi 
A. On the Optimality of disk allocation for cartesian [sEs92] product files. In proceedings of A CM Sym­posium 
on Principles of Database Systems, (April 1990), 258-264. [FKK91] Fujwara T., Ito M, Kasarni t., Katakoa 
M. [SSN92] and Okui J., Performance analysis of disk allocation method using error-correcting codes. 
IEEE Transactions on Information Theory 37, 2(1991),379-384 [HUA90] Kien A. Hua and Chiang Lee, An Adap-[ST086] 
tive Data Placement Scheme for Parallel Database Computer Systems, in Proc. of Inter. Con~ on Very LaVe 
Data Bases (VLDB), Australia, 1990. [HOR78] T.H. Horowitz and S. Sahni, Fundamentals of Computer Algorithms, 
Computer Sci­ence Press, 1978. [LSR92] Jianzhong Li, Jaideep Srivastava and Doron Rotem, CMD: An Multidimensional 
Declustering Method for Parallel Database Systems, in Proc. of Inter. Conf. on Very Large Data Bases 
(VLDB), Canada, Aug. 1992. 356 T. M. Niccum, J. Sri­vastava, and Jianzhong Li, A Haah Based Parallel 
Join for Relations with Coordinate Modulo Declustering (CMD) Storage, Sub­mitted for publication, 1992. 
J. Neievergelt, H. Hinterberger and K.C. Sevcik, The Grid File: An Adaptable, Sym­metric Multikey File 
Structure, E. Omiecinaki and E. T. Lin, The AdaptiveHash Join Algorithm for a Hy­percube Multicomputer, 
IEEE Tmns. on Parallel and Distributed Systems, Vol.3, No.3, May, 1992. ACM Truns. on Database Systems, 
Vol. 9, No. 1, 1984. Arnold L. Rosenberg and Lawrence Sny­der, Time-and Space-Optimality in B-Tree, ACM 
Transaction on Database Sys­tems, VO1.6, No.1, March 1981. Doron Rotem and Arie Segev, Algorithms for 
Multidimensional Partitioning of Static Files, IEEE tin. on Soflware Engineer­ing, Vol. 14, No. 11, Nov. 
1988. S. Seshadri, Probabilistic Methods in Query Processing, Ph.D. thesis, Depart­ment of Computer Science, 
University of Wisconzin-Madiaon, 1992. S. Seshadri and J. F. Naughton, Sampling Issues in Parallel Database 
systems, in Pro­ceedings of the 9rd International Confer ence on Extending Database Technology, Vienna, 
Austria, March 1992. M. Stonebraker, The Case for Shared Noth­ing, Database Engineering, 9(l), 1986.</RefA> 
   
			
