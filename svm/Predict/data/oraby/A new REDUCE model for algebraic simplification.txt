
 A New Reduce Model for Algebraic Simplification* Anthony C. Hearn University of Utah Abstract This 
paper shows how the general concepts of mode analysis can play a useful role in the design and implementation 
of programs for algebraic sim- plification. We utilize these ideas in presenting a new model for simplification 
which will be incorporated into REDUCE in the near future. i. Introduction This paper shows how the 
concepts of mode or type analysis can play a useful role in the design and implementation of programs 
for the simplifica- tion of algebraic expressions. The result is more flexible and more easily maintainable 
algebraic manipulation programs, clearly goals of utmost importance in such a rapidly developing field. 
Such goals can also be achieved without any loss of egficiency; in fact in essentially all cases more 
efficient programs result. As a consequence of this study we shall also present a new model for expression 
simplification which will be incorporated into REDUCE in the near future. There are two main aspects 
to the question of algebraic simplification. The first relates to the problem of designing algorithms 
for the canonical evaluation of as large a class of expressions as possible. This is a question of much 
theoretical and practical importance, but not one we are considering here. The second relates to the 
actual design of programs to incorporate such theoretical advances. This is also a problem of great practical 
importance to users of algebra systems, because if the inclusion of new theoretical results in an existing 
program requires major reprogramming, then it will be many months (or maybe never!) before such users 
see the effect of these results on their calcu- lations. The resolution of this problem in REDUCE was 
in fact one of the reasons this study was begun. In particular, the desirability of utilizing the results 
of Brown and Hall's (i, 2) study of algorithms for factored forms as a general facility in REDUCE was 
a major inducement. However, since incorporating this representation into the current system would have 
required con- siderable changes to the source program, it was *Work supported in part by the National 
Science Foundation under Grant No. GJ-32181. decided to reexamine the whole basis for the model so that 
when other theoretical improvements come later (as surely they will!) they can be incorpor- ated with 
the minimum of effort. Another motivation for this study was the obvious need for a general model of 
simplification which was more easily explainable to users than the current one. Several recent applications 
of REDUCE have required this level of explanation (3) and it was therefore decided to attempt a descrip- 
tion in terms of the mode concepts which are currently being introduced into REDUCE. This analysis revealed 
in fact many inefficiencies in the current implementation. Our experience in this regard is probably 
little different from other designers of large systems; as users have discovered special cases for which 
the available program did a poor job of simplifying or required some special facility for their particular 
problems, local patches were made to take care of this. How-ever ~hese patches sometimes repeated work 
done by another section of the program so that ineffi-ciencies arose, Several such examples were re- 
vealed by our study and resolved in the new model presented here. Because the ideas of mode analysis 
may be new to some readers, we shall summarize in Section 2 the salient features necessary for this study. 
In Section 3 we shall present a description of the new simplification moael. We shall then show in Section 
4 how the mode ideas provide for a natural imple- mentation of the simplification model and at the same 
time provide the flexibility necessary to make future maintenance of the program much easier. 2. Mode 
Analysis Since the ideas of mode analysis are impor- tant in our study of simplification, we shall repeat 
in this section a brief description of the process as it is being implemented in a new version of REDUCE 
(4). These ideas are not new, and the choices made in the implementation have been influenced by a study 
of the features found in ELI (5), ALGOL 68 (6) and PASCAL (7). We associate the term mode8 with the various 
data-structures considered by REDUCE. Currently the built-in modes include integer (i.e., arbitrary precision 
inte- gers), real and algebraic. The meaning of the latter mode will be explained later. A mode literal 
is also defined for a literal atom, and an  Proceedings of the 1976 ACM Symposium on Symbolic and Algebraic 
Computation 46 atom itself (i.e., a literal or a number) is of The second statement will be parsed as 
 mode atom. In addition to its value, every literal in REDUCE has such a mode associated with it. This 
mode may be provided by the user by means of a DECLARE statement or defaults to a standard type otherwise 
(usually algebraic). Each expression built up from the basic literals and constants also has a mode 
associated with it, determined by a semantic analysis of the expression. This analysis, performed by 
a function MEVAL, is just one step in the complete evaluation of an expression. Each command is in fact 
processed in four separate stages; a parse, a mode analysis, an (optional) compilation and an evaluation. 
However, the mode analyzer is also available (as a REDUCE procedure) for use during evaluation, and'this 
use will prove important to our discussion here. In the parse step, each command is converted into an 
equivalent LISP expression using standard LISP names for the infix arithmetic operators. For example, 
the REDUCE expression (X+A) * (Y+B) becomes (TIMES (PLUS X A) (PLUS Y B)). Following a suggestion of 
M. Nordstrom, this conversion attempts to preserve as closely as possible the structure of the input 
expression, and is there- fore a fairly faithful representation of the parse tree for the expression. 
In the current version of REDUCE, however, the parser also applies some semantic transformations to the 
data. For example, FOR statements are converted into blocks. This complicates the parser by introducing 
material more concerned with semantics than syntax and makes compilation harder by throwing away control 
information too early. The parser in the new version is essentially context and semantic free and is 
based on one described and implemented by Nordstrom (8). The design of the mode evaluator is similar 
to that of any LISP evaluator. It takes an expression as argument, modifies it according to the semantic 
analysis and returns a dotted pair of the modified expression and its mode. The analysis proceeds roughly 
as follows. If the argument is an atom, it is either a constant (for example, a number) or a literal; 
in either case its mode is known. Otherwise the expression is assumed to be of the form f(argl ....,argn), 
or (f argl ... argn) in LISP notation. A check is first made to see if f is a special Â£orm as far as 
the mode evaluator is concerned. If it is, a specific mode analyzing function is used. In the usual case, 
however, MEVAL will begin by per- forming a mode analysis of the arguments of the function, determining 
in the process their mode. It will then attempt to assign a meaning to f with arguments of this mode 
by an inspection of a table on the property list of f. If a meaning can be assigned, the appropriate 
internal function to use in that case will be determined, otherwise an error results. This process may 
involve coercion (or conversion), in other words a transformation  from one mode to another. A simple 
numerical example illustrates this. Consider the program segment DECLARE A)B:INTEGER; A+B; (PLUS A B). 
An inspection of the semantic prop- erties of the generic function PLUS will reveal that the addition 
of two integers has meaning, and that the internal function associated with this process is, say, IPLUS 
whose value has the mode integer. MEVAL will therefore return the expres- sion ((IPLUS A B) . INTEGER). 
However, suppose instead that we had said: DECLARE A:INTEGER,B:REAL; A+B; The parse of the last statement 
will still be the same, but the mode analyzer will now find that no routine exists for the addition of 
an integer and a real number. It will find however, that it is possible to convert an integer into a 
real number and that addition of two real numbers using, say, RPLUS is possible. If the function for 
doing this conversion is FLOATF, then MEVAL will return in this case ((RPLUS (FLOATF A) B) . REAL). Further 
details on the use of this facility are given in Ref. (4) and (9). With these ideas in mind we can now 
turn to the particular problem under consideration, namely the design and implementation of a simplification 
model for algebraic expressions. 3. The Simplification Model One word guaranteed to produce sharp reac- 
tions and controversy among those concerned with symbolic computation is simplification and so it will 
be necessary to attach our own meaning to the term. We agree with Moses (I0) and Brown (i) that simplification 
changes only the form or represen- tation of an expression. However, we also require that the transformed 
expression be idempotent, namely that if the simplification algorithm is immediately applied again to 
the simplified expression its form will not change. We shall call this idempotent expression the value 
of the original expression, and to avoid further contro- versy on the meaning of simplification, shall 
call the transformation to this value the evaluation of the expression. Because an idempotent expression 
is semantically different from the original class of expressions we began with, it is reasonable to associate 
a new mode idempotent with this class. So the value of an expression of idempotent mode is itself. The 
simplification algorithm exploits this fact to avoid any further computation when it meets an expression 
so tagged. (This is reminiscent of the"already simplified" flag of FORMAC (ii).) In the current version 
of REDUCE, such idempotency is not recognized consistently, so that some such expressions are reevaluated 
by the full algorithm. Although such reevaluation is usually on small expressions so that the additional 
cost is not high, it is an overhead nonetheless which is eliminated in the new model. It is of course 
necessary to recognize that the idempotency of such expressions may be destroyed later by some operation, 
such as the assignment of a value to one of the literals in an expression. However, such a possibility 
is easily handled. In the worst case one could change the mode of all such expressions whenever a new 
sub-  stitution is defined. This naturally is to inef- ficient to consider in practice and so one tries 
to keep the class of expressions whose mode is changed as small as possible by keeping track of the literals 
and operators on which the idempotent expressions depend. Another important question to resolve in designing 
an algebraic simplification program is the appropriate interface between the user and the system. In 
other words, should the system try to leave an expression as close as possible to the form in which the 
user entered it or immediately transform it into an internal representation which can be manipulated 
with greater ease by the pro- gram? Our current feeling is that if algebra systems wish to attract casual 
users who do not care to learn the intricacies of the internal representations, then one must choose 
a program- ming interface which is as near as possible to the user's input, and an easy choice is the 
parsed form of the user's expressions. + + X A Y B Figure 1. Parse tree for expression (X+A) * (Y+B) 
 It has proved quite easy to explain to users that the oxpression (X+A) * (Y+B) is parsed by the program 
into the form equivalent to Fig. i, (more precisely, the LISP form given earlier), and therefore concepts 
like leading operator, ,, lead- ing term, (X+A), and so on are quickly apparent. On the other hand, trying 
to explain to a casual user that the leading term of (X+A) * (Y+B) is A * B, which might be true if an 
internal repre- sentation for polynomials in expanded form is used, even if the expression is displayed 
as above, can only lead to confusion and frustration. This is not to say that a more expert user should 
not be allowed direct access to such an internal form; on the contrary. However, such a user should be 
forced to do something, such as make some addi- tional declarations, in order to get that access. In 
a sense, we are reinforcing the point also made by Moses (12) that users like to see their output in 
terms of the same functions as their input. Moses was talking about integration, but the point is clearly 
more general. In this spirit we believe that users also like to think about manipulating expressions 
in terms of the struc- tures they see before them on a terminal or printed output, not in terms of some 
internal represen- tation possibly bearing little relationship to the output. It is with this parsed 
form for expressions that we associate the mode algebraic. To keep expressions in the most "natural" 
form from the user's point of view, it is reasonable to consider expression evaluation by means of pattern 
matching on the parsed expressions. For this purpose the model provides a general purpose pattern matching 
facility which transforms such expressions by a Markov algorithm similar to that used by SCRATCHPAD 
(13). In our model, a pattern considered by this facility consists of three parts; a template, which 
is an expression to be matched against, a boolean expression defining conditions on free parameters in 
the template, and a value for the original expression if the template matches and the boolean expression 
is true. Such patterns are introduced by the LET command in REDUCE. Its syntax is <optional boolean 
expression> LET <expression> = <expression>,... Arbitrary (free) parameters in the boolean expres- sion 
are simply tagged as such and not included in the pattern boolean expression. Otherwise the optional 
boolean expression becomes the boolean expression in the pattern (which will be true if no boolean expression 
is present in the LET state- ment), the left hand side of the substitution is the template, and the right 
hand side the value. For example, the statement LET COS(O) = 1 would result in the pattern (COS(0),TRUE,i). 
 Each operator and literal has associated with it a pattern list to which new patterns are added when 
defined. This list is organized as a stack in that the last pattern is entered at the head of the list. 
Since this list is searched from the top when pattern matching is attempted the latest pattern entered 
takes precedence over any previous pattern since the pattern marcher stops as soon as it has a successful 
match. When a new pattern is added to a pattern list, the system checks to see if the same template and 
boolean condition already appear on the list, in which case the old pattern is deleted. However, it is 
important to note that no other check is made for the compatibility of a new pattern with any previously 
declared patterns, and so a user is not protected against declaring inconsistent patterns by mistake. 
However, at least the last entry is seen first! Evaluation of an algebraic expression now proceeds as 
follows. Such an expression is either an atom or a structure of the form f[argl,...,argn). If the expression 
is an atom, it is either a number or a literal. In the former case, a flag is checked to see what global 
number mode is active, i.e. floating or fixed, and an appropriate conversion takes place if the number 
 is in the wrong mode. In the latter case, the literal pattern list is checked for a true boolean expression 
and if one is found the algorithm is reapplied to the pattern value until an idempotent expression results. 
Otherwise the literal is returned unchanged. On the other hand, if the expression has structure, we 
begin by evaluating the arguments recursively by the process we are describing. The operator is then 
checked for anypatterns associ- ated with it. If any are found, a check is made to see if any match 
the expression. If so, the algorithm is reapplied to the pattern value with any free parameters of course 
replaced by their relevant values; otherwise the form f(argl* .....argn*) is returned, where the asterisks 
denote the evaluated arguments, The actual expression matching algorithm is also straightforward. Suppose 
that we are trying to match the template f(ul, .... Um) against the expression f(vl,...,Vn). If f is 
neither commu- tative nor associative then we require that m = n and then match u I against Vl, u 2 against 
v 2 and so on as follows. If a given u i happens to be an atom, then if it is tagged as free a match 
has occurred and the free parameter is paired with the expression v i in a table. If u i is not free 
it must equal v$ for a match to occur. On the other hand, if u i is not an atom then v i must also be 
a structure with the same leading operator and the algorithm is then applied recursively to u i and 
v i. If the whole expression matches in this manner, the appropriate values for the free parameters 
are substituted into the boolean form, which, if true on evaluation, means that a complete match has 
 occurred. If f is either commutative or associative (or bothl) then the matching process has to take 
into account all possible pairings of arguments allowed by these properties. It is clear that this process 
could be quite time consuming in the worst case. In the current REDUCE there are, as a result, restrictions 
on the way that the associ- ativity property of +, for example, is applied in order to make the matching 
process more efficient. In fact the matching process is only applied to a right binary grouping of the 
expression plus the permutations allowed by the commutativity rule. We plan to investigate in the new 
implementation the cost of making the process more general, and if possible remove the restrictions existing 
in the current system. If this were the complete model for REDUCE evaluation, then there would be no 
difficulty in explaining precisely to every user how expresslons are evaluated. However, a scheme based 
solely on pattern matching does not provide for the effi- ciency inherent in more canonical schemes, 
or for a natural interface to algorithms based on canonical representations such as factorization. To 
proved for such internal representations, how- ever, is a fairly simple modification to our model. One 
associates with a certain class of operators, usually the standard arithmetic oper- ators, +, *, etc. 
an internal property and further assumes that the mode of the value of an expression (i.e. idempotent) 
is a union of two modes; kernel and internal. The former is an idempotent sub-class of the class of algebraic 
expressions, whereas the latter can have a repre- sentation entirely different. However, we assume the 
existence of a transformation between internal forms and kernels and vice versa, as well as a run time 
check for each sub-mode (since idempotent is now a union mode). Therefore, if we are dealing with a non-internal 
operator for which the above pattern matching model still applies, we must first check to see if each 
argument after the evaluation is of kernel mode and convert it if not. Likewise, the functions for the 
evaluation of expressions involving top level internal operators must also allow for the existence of 
the union mode. In most cases, however, the function definition will specify the required mode for its 
arguments so that the mode evaluator will insert the appropriate conversion function automatically as 
in our numerical example in Section 2. For simplicity, we also assume that the value of an expression 
with a top level internal operator is of internal mode. An obvious choice for such internal represen- 
tations is to make them canonical in some sense but again to avoid controversy we need not insist on 
this in our description. However, the standard internal representation currently used in REDUCE (14, 
15) is a rational form with numerator and denominator in expanded form, which is canonical if the kernels 
which act as indeterminates in this representation are independent, and the expression has been reduced 
to lowest terms. Rules for substitutions for expressions involving top level canonical operators are 
also handled quite differently from the previous model. In order to perform the evaluation of such expres- 
sions in an optimal manner, the system applies its own set of evaluation rules and those introduced by 
a user in an arbitrary order. In particular, most user substitutions are only applied when a conver- 
 sion from internal to kernel takes place. For this method to work, it is necessary that any top level 
expression of internal mode be converted to kernel mode in order that an expression be always returned 
 in idempotent form. As a compromise for reasons of efficiency, however, we can often avoid this conve~ 
 alan by'applying the subst~tution-tD ~he expression which will return another internal form and tagging 
 this as a "substituted internal form". Of course, if a user wishes to display such an expression and 
 get at parts of it as seen on the display, the full conversion has to be done. Let me repeat however, 
that such substitutions for internal operators are applied only once to the whole expression. This has 
usually proved a more efficient practice than applying the substitution rules every time an internal 
operator is encoun- tered, and also seems to lead to more compact expressions in some cases. For example, 
given that I*'2 = -i, the expression (I**2-1)/(I+l) will have the value I-i by this method, whereas it 
would be -2/(I+i) if the substitution was applied as soon as the exponentiation operator was encountered. 
An exception to this rule is made for any power of an indeterminate whose value is 0. This is immediately 
substituted in order to avoid unneces- sary computation with zero valued expressions. For those interested, 
the order in which such substitutions are applied in the current REDUCE is first rules for powers with 
true boolean expres- sions and no free parameters, then rules for other powers and finally rules for 
products. Rules for top level sums and quotients are not allowed in the current system. It is clear that 
we want to remove this restriction in an efficient manner in the new system. One method being investigated 
is the possibility of generating an ideal from the set of substitutions and then reducing a given  polynomial 
or rational function to a unique repre- sentative in the appropriate equivalence class (16). Such a 
method would again apply the rules in an arbitrary order, but since the method checks for the self-consistency 
of the rules, the results will be independent of their order of application. This method, however, cannot 
currently incorporate substitutions with free parameters or boolean con- ditions. This then is the complete 
model. We see that canonical evaluation and pattern matching each play a complementary role and that 
the mode of the value of an expression can either be ~er~el (i.e. an idempotent algebraic expression) 
or intez~nal. This differs from the current REDUCE system (14, 15), where all values are of internal 
mode, so that a certain amount of overhead is involved in writing kernels as internal expressions and 
then extracting the kernel again when needed. The new model could also allow for an idempotent value 
mode which was a union of several different modes corresponding to different internal repre- sentations 
for different operators. Little would need to be changed if this later proves desirable. We can allow 
also for users to specify that their rules for internal operators take precedence over the system rules 
by first using the pattern matching program on such operators before applying the system rules. Such 
a possibility does in fact exist in the current REDUCE and was used by Stoutemyer (17) to postpone such 
operations as the collection of like powers and like terms, the distribution of powers over factors and 
the associative laws of addition and multiplication until after his set of rules had been applied. However, 
this facility was added in a rather ad hoc manner, whereas in the current model it is an integral part 
of the algorithm. Another possibil- ity is to allow a user to remove all internal properties on operators 
and work solely in a pattern matching context for a while so that only his rules are applied. 4. Implementation 
of the Model So far, we have described a model for expres- sion evaluation in which the language of 
mode analysis proved of some help in the description. However, we have not yet faced the problem of implementing 
this model in a manner which allows for the easy change from one internal form to another; for example 
to replace an expanded repre- sentation for the class of internal operators with say a factored representation. 
There are in fact three tasks to be considered, namely: i. writing the routines for arithmetic operations 
and substitutions on the new structures, 2. writing the routines for transforming between an algebraic 
expression (our interface) and this new mode,  3. writing the routines for transforming between the 
internal mode and the user interface and printing expres- sions in this form.  The first problem is 
considered in Refs. (4) and (9). In fact Griss (9) shows how the data- structures appropriate to the 
internal represen- tations may also be defined using standard data- defining tools. This method also 
provides the user with an appropriate set of selectors and con- structors for use in writing the routines 
for operations on these structures, and the mode analyzer then checks to ensure that such opera- tions 
are always applied to the correct data- structures. However, as this point is considered in some detail 
in the cited references we shall not repeat the discussion here. Once such data-defining tools are available, 
even the task of defining an algebraic expression becomes much easier. Such a mode could be defined as 
follows: MODE ALGEBRAIC = UNION(ATOM, ALGSTRUCT), ALGSTRUCT = STRUCT(LOP:LITERAL,ARGLIST), ARGLIST = 
LIST OF ALGEBRAIC; Here atom and literal are the predefined system modes mentioned earlier, UNION constructs 
a new mode which because its first argument, ATOM, is self-identifying does not need an additional run- 
 time tag, and STRUCT builds a structure with two fields, the first of which is selected by LOP and the 
second by ARGS. The mode of the second field, ARGLIST, is further defined as a list of alge- braics, 
so that the standard list selectors HEAD and TAIL can access parts of that list. For example, given a 
(non atomic) algebraic expression defined in this manner, LOP will select its lead- ing operator and 
HEAD ARGS the first argument of that operator. One might wish to go one step further and limit the literals 
allowed to be LOPs to a class so tagged, but this presents no diffi- culties. At first sight, it looked 
as though the second task on our list would involve extensive programming. However, in looking at the 
structure of the existing REDUCE simplifier an interesting fact emerged. Like most LISP-based simplification 
programs, the top level function in this program has the name SIMP which then calls other functions with 
names like SIMPPLUS, SIMPTIMES, etc. on expressions with particular top-level operators. However, as 
these routines transform their argu- ments from one form to another, most of the analy- sis performed 
is semantic in nature. Since in the mode analyzing model such analysis is also per- formed by MEVAL, 
it became obvious that the main part of the work done by SIMP could be replaced by MEVAL and a few small 
auxiliary functions. In fact, in the new model an acceptable definition for SIMP of an expression is 
simply EVAL of MEVAL of the expression! Since a call to SIMP is often needed dynamically, the need to 
have MEVAL also available for dynamic use is therefore apparent. This definition of SIMP has the advantage 
that the current body of code associated with SIMP and its auxiliary functions can be removed in favor 
of the more general mode analyzer. The task of adding an interface to a new internal form is therefore 
reduced to writing a straightforward function for converting a kernel to this form plus a few auxiliary 
functions concerned with the handling of such things as unusual exponents. Some straight- forward changes 
to the mode tables of the relevant operators can now make this new internal form the system default. 
 Another immediate advantage of this technique is that because the mode analyzer can be (prefer- entially) 
used statically as well as dynamically, we have the possibility of optimizing calculations further by 
doing as much of the semantic analysis as possible statically. Consider for example the following program 
to compute the first eight terms in the famous f and g series: DEPS :: -SIG*(MU+2*EPS); DMU := -3*MU*SIG; 
DSIG := EPS-2*SIG**2; F1 :: i; G1 := 0; FOR I := 1:8 DO BEGIN F2 := -MU*GI + DEPS*DF(FI,EPS) + DMU*DF(Fi,MU) 
 + DSIG*DF(Fi,SIG); G2 := F1 + DEPS*DF(Gi,EPS) + DMU*DF(Gi,MU) +DSIG*DF(Gi,SIG); F1 := F2; G1 := G2 
END; Within the loop it is fairly easy for the mode evaluator to determine that EPS, MU, SIG, DEPS, 
DMU and DSIG are invariants. Furthermore, it knows from analysis prior to the loop that EPS, MU and SIG 
have (idempotent) mode kernel, and that the other literals have a value whose mode is internal, in this 
case an internal form for poly- nomials (since no division occurs). Finally since Fi, F2, G1 and G2 are 
assigned within the ~oop to expressions with top level internal operators, they too are of mode internal. 
So a term like MU*Gi can be replaced by the form MULTKF(MU,Gi), where MULTKF is a function for multiplying 
a kernel by an internal form. If such a function does not exist, coercion would transform the kernel 
to an internal form, giving say MULTF(K2F(MU),Gi). Finally, the analyzer can recognize that K2F(MU) has 
a constant value and therefore put that value in directly. One can similarly analyze each expression 
in the loop and so produce an optimized form for the loop before it is evaluated. Another way to optimize 
such a calculation would be to declare EPS, MU and SIG as kernels and the remaining literals as polynomials 
by saying DECLARE EPS,SIG,MU:KERNEL, DEPS,DSIG,DMU,Fi,F2,Gi,G2:POLYNOMIAL; Given that polynomial was 
the mode of the internal form for polynomials such a declaration would cause all expressions involving 
these literals to be treated in such a mode, and incidentally give a more expert user the direct access 
to that internal mode we mentioned earlier as desirable in some cases. This would clearly be the most 
efficient way in general of treating such problems, but it is interesting to note in this case, that 
even with no declarations at all, the system was able to do statically all the necessary optimization 
itself. Compiler experts will recognize that such optimizations are little different in nature from 
those one might apply to any program, and this is probably no accident since our ideas have clearly been 
influenced by some recent work on designing a portable compiler for the REDUCE embedding lan- guage LISP 
(18). Eventually we hope to use the general analysis provided by the mode analyzer as a means of improving 
the compilation process still further, but this remains for the future. The last task to be faced in 
introducing a new internal mode is perhaps the messiest, namely the conversion of an internal form to 
an algebraic expression, or printing it directly in such a form. The mode evaluator cannot help here 
because the syntax of the internal representation is unlikely to be of a form understood by MEVAL. So 
these routines must be written directly. However, this turns out to require only a page or two of code 
in most cases and the task is again eased by using the appropriately named selectors and constructors 
introduced in defining the different data-sturc- tures. The most important thing, of course, is that 
our analysis has localized in a fairly modular way the necessary additional code to be written when introducing 
a new mode. One can therefore intro- duce a new representation confident that no sur- prises will occur 
when the internal form is used. 5. Conclusion We have described in this paper a new model for simplification 
in REDUCE which allows for far more flexibility and ease of description than previously. At the same 
time, the use of general mode analyzing concepts has not only helped with this description but also allowed 
for an implemen- tation with such obviously desirable properties as greater robustness and efficiency, 
and more ease of maintenance by the modular localization of internal representations. The result should 
be a system with far greater user appeal than the current version, which, in addition to providing users 
with a well defined natural interface, will also allow them easy access to the internal representations 
if they so desire. 6. Acknowledgment The author is grateful to the Centre de Physique Th~orique, CNRS, 
Marseilles, France, for its hospitality during the period when this paper was written.  7. References 
<RefA>(is) GRISS, M.L., and HEARN, A.C., A Portable (I) BROWN, W.S., On Computing with Factored Rational Expressions, 
SIGSAM Bulletin, ACM, New York, 8 (1974) 27-34. (2) HALL, A.D., Factored Rational Expressions in ALTRAN, 
SIGSAM Bulletin, ACM, New York, 8 (1974) 35-45. (3) HOROWITZ, E. and MUSSER, D.R., The Synthesis and 
Use of Algebraic Specifications of Data-Structures, USC Preprint 1975.  (4) HEARN, A.C., A Mode Analyzing 
Algebraic Simplification Progr~n, Proc. ACM 74,   ACM, New York (1974) 722-724. (S) WEGBREIT, B., 
Comm. ACM 17 (1974) 2Si-264. (6) LINDSEY, C.H., and Van der MEULEN, S.G., Informal Introduction to ALGOL 
68, North-Holland (1973).  (7) WIRTH, N., Acta Informatica I (1971) 35-63. HOARE, C.A.R., Notes on 
Data Structuring in Structured Progran~ning, Academic Press (1972). (8) NORDSTROM, M., A Parsing Technique, 
Univ. of Utah Comp. Phys. Operating Note No. 12 (1973).  (9) GRISS, M.L., The Definition and Use of 
Data- Structures in REDUCE, Proceedings of SYMSAC 76, ACM, New York (1976)q  (I0) MOSES, J., Comm. ACM 
14 (1971) 527-537 (li) TOBEY, R.G., BOBROW, R.J. and ZILLES, S.N., Automatic Simplification in FORMAC, 
Proc. AFIPS 1965 Fall Joint Comput. Conf., Pt. 1, (1965) 37-52.  (12) MOSES, J., Comm. ACM 14 (1971) 
548-560.  (13) JENKS, R.D., The SCRATCHPAD Language, SIGPLAN Notices, ACM, New York, 9 (1974) i01-iii. 
 (14) HEARN, A.C., The Problem of Substitution, Proc. IBM Summer Institute on Symbolic Math. by Computer, 
IBM Prog. Lab. Rep. No. FSC-69-0312 (1969) 3-19.  (is) HEARN, A.C. The REDUCE Program for Computer Algebra, 
Proc. 3rd Colloq. on Advanced Comp. Methods in Theor. Phys., C.N.R.S., Marseilles, (1973). (16) SHTOKHAMER, 
R., Simple Ideal Theory, Some Applications to Algebraic Simplifi- cation~ Univ. of Utah Comp. Phys. Report 
No. UCP-36 (197S).  (17) STOUTEMYER, D., Automatic Error Analysis Using the Computer Symbolic Language 
REDUCE, Trans. Math. Software (to be published).   LISP Compiler, Univ. of Utah Comp. Phys. Report 
No. UCP-47 (1976) (to be published). </RefA>52  
			
