
 A New Approach to Teaching a First Course zn Compiler Construction Henry D. Shapiro and M. Dennis 
Mickunas Department of Computer Science University of Illinois at Urbana-Champaign Abstract A new approach 
to teaching a first course in compiler construction is presented, in which the traditional term project 
is replaced by several smaller, independent, progrsmmming assignments. Each assignment is a compiler 
for a simple lan- guage using a different parsing technique. A means is described to augment the progrsm~ning 
assign- ments, so that a greater variety of experiences is provided students. A short review of the litera- 
ture is included. I. Introduction The purpose of this paper is to evaluate the traditional approach 
to teaching a first course in compiler construction, in light of the current body of knowledge in this 
field, and then to pre- sent, in some detail, a new instructional approach that is more in line with 
accepted educational goals. While compiler construction remained in its infancy and was largely an ad 
boa process, the traditional approach was indeed appropriate. How- ever, with the development of increased 
formaliza- tion and more sophisticated techniques, this original approach now fails to provide a suffi- 
cientlywide range of ex}eriences. In this course, as traditionally taught, the main focus has been the 
completion of an individual or small group term project [6,9]--a compiler for a substantial language. 
This assignment is based on the prevailing attitude that compiler construc- tion is best learned by "doing" 
[9]. Thus, the source language to be compiled must be sufficently complex so that, in addition to the 
"basics", the student encounters several topics selected from among multi-dimensional array handling, 
scope of variable names, run-time storageallocation, syntactic error recovery, procedure handling, etc. 
Class time is spent either in careful examination of a sample compiler, which the students enmlate, or 
in a very detailed discussion of the algorithms to be employed. In addition to the massiveness of the 
project itsel~ the situation is further aggravated by the fact that the project cannot actually be started 
in a meaningful way until well into the term, not before lectures on an overview of compiling and a discussion 
of parsing have been given. Thus, the bulk of the project is deferred until the end of the term, when 
student time is consumed with exs~ninations in other courses and turnaround time is long [4]. II. Some 
Perspectives on the Traditional Approach The students who enroll in a compiler construc- tion course 
tend to be advanced undergraduates or beginning graduate students. At the University of Illinois, the 
course is optional in each curricu- lum. Compiler construction seems to have an almost magnetic attraction 
for students, and often the students are not as well prepared as the instructor might assume. Many of 
the students have never had to write a truly long and complex program before, and, lacking experience, 
they are not accomplished structured progrsm~ners. Most of them probably have never done a serious group 
project either. This lack of organizational experience is a serious handicap when it comes to programming 
the term project. Also, the students frequently have not taken courses in the theory of formal languages 
and automata (ACM Curriculum '68 course A1 [6] ), and, in general, are not interested in these abstractions. 
The need for remediation delays completion of the discussion of parsing. On the positive side students 
almost always know a higher level language of the ALGOL / PL/I type and manip- ulate data structures 
with facility (course I1). These entering behaviors help provide some guide- posts for judging the appropriateness 
of a course in compiler construction. Two basic assumptions regarding learning also underlie our evaluation 
of approaches to compiler construction: (1) No single course the student takes should consume inordinately 
more time than any other, and (2) Real learning is building a framework into which the student can fit 
his experiences and knowledge, and is not merely a collection of tricks and facts that apply in only 
one case.  As has been noted by others [4,5], the tradi- tional approach runs directly counter to this 
first assumption. Students often report that compiler construction was the most time consuming course 
in their entire graduate program. Similarly, the learning process expressed in assumption two becomes 
completely corrupted. The students become 158 pressured as the majority of the work on the term project 
becomes concentrated into a short period at the end of the term, conscious of the fact that their course 
grade depends heavily on this single assignment. Thus, the students tend to become so engrossed in the 
problems of their particular com- piler that topics presented in class which do not directly relate to 
producing their specific com- piler are often completely "tuned out". Hence, students often remain cqmpleZelyunaware 
of prob- lems (and appropriate solutions) only slightly different from those they have actually encoun- 
tered [5]. In addition, good programming practices are usually abandoned in the rush, ingraining bad 
habits more deeply, and questions regarding soft- ware reliability and the correctness of the com- piler 
are ignored. Discussions with students who have been through the traditional approach indicate little 
or no knowledge of aspects and techniques of compiler construction that they did not personally implement. 
The knowledge which was acquired was not well integrated. Awareness of these shortcomings of the tradi- 
tional approach caused us to try a different instructional teehnique--a technique in which the term project 
is replaced by several independent programming assignments. At the University of lllinois, initial experimentation 
with this new technique, discussed in detail in succeeding sections, has proven to be more consonant 
with the entering behaviors of the students and our two basic pedagogical assumptions. III. The New 
Approach: Basic Course Structure The modern compiler can best be understood by knowing the method it 
uses to parse programs. Almost all other activities in which the compiler engages fit quite naturally 
into the parsing scheme and are subordinate to it, or else are totally independent of the parsing algorithm 
used. For this reason, and because of the highly varied nature of currently employed parsing techniques, 
we feel the student can build a solid understand- ing of compiler construction only if he is famil- iar 
with several methods of parsing. To develop this understanding, durin G the course of the term the student 
is expected to write several compilers, all for the same, rÂ£fxbt~u~u S/mol~, lan~ua~e~ but each using 
a different parsing ~echnique. Of the many techniques available, the formal, table-driven, techniques 
appear to be the best suited for this course. There are several reasons for this, both technical pedagogical. 
 (i) When operating in a formal environment, many parts of one compiler can be reused in the next, with 
little or no modification. The reus- ability of program modules makes the value of structured programming 
clearer to the student in a practical way. Moreover, the savings of time realized helps to cut down on 
the total hours spent by the student.  (2) Since the construction of a suitable grammar and the associated 
parse tables is inde- pendent of the coding, the instructor is provided with a natural checkpoint at 
which to monitor the progress of students. The independent nature of  the two tasks also stresses the 
advantage of break- ing large jobs into logically distinct and manage- able sub-units, really the issue 
behind structured programming. Furthermore, since the greater part of the work is the construction of 
the parse tables, a paper and pencil task, student progress is impeded somewhat less by the fluctuating 
demand on computer time throughout the semester. (3) Software reliability cannot be guaranteed for ad 
hoc methods. This is of growing importance in the real world, and is certain to lead to the extensive 
use of formal methods in actual practice. In line with this, it can be noted that compiler writing systems 
employ formal methods in their parser generation routines. While the main function of the programming 
assignments is to give the students an in-depth look at parsing methods, and to require students to acquire 
facility with them, these tasks alone do not provide a sufficiently wide range of experiences. To increase 
the students' under- standing of the parsing techniques involved, and to reveal their limitations and 
strengths, a major aspect of the course is supplemental written assignments. These can often be in the 
form of mini-languages, which isolate interesting problems not found in the simple language for which 
the students actually build their compilers. The students are to construct an appropriate grammar and 
build the parse tables (as a check), while making sure the necessary semantic actions can be fitted in. 
This aspect of the course will be elaborated further in section five. Many important aspects of compiler 
construction are not covered in lectures about abstract parsing techniques, nor will they appear in the 
programming assignments because of the necessarily simple nature of the source language to be compiled. 
A first course which did not discuss these issues would be incomplete. The instructor will find that 
once the course gains momentum (i.e., after a careful discussion of all aspects of the first compiler, 
which should be done in reasonable detail), a complete presentation of additional parsing techniques 
will take less time than it takes the students to write the compilers. This provides time for the discussion 
of topics critical in the construction of campilers for more complex la~ruages, but not needed in the 
progrsm~ning pro- jects for this course. In particular, serious symbol table management, run-time storage 
alloca- tion, parameter handling in subroutines, and if time permits, error recovery, code optimization 
and code generation can be taught. Gries [9] is an excellent source for this kind of material. Figure 
1 is a proposed course timetable for a 15-week semester. The topics in italics are those not needed for 
the programming assignments, but are important in compilers for more complex languages. As mentioned 
above, they can be in- serted between lectures on different parsing methods. Since the students' progrmmming 
assign- ments are not particularly large, the motivation for their "tuning out" these discussions seems 
greatly diminished. One additional advantage envisioned for this new approach to teaching compiler construction 
is Topic Lecture Hours Allotted Overview of compiling; Context free languages and grammars; Introduction 
to parsing Target machine architecture and associated machine language (programming assignment specific) 
 Pushdown automata as acceptors of context free languages; Deterministic pushdown automata LL(1) parsing 
 Conversion of grammars into equivalent LL(1) grammars Semantic considerations in the compiling process; 
Syntax directed translation (Semantic activity only as needed for prograrmning assignments) Discussion 
of sample compiler; Review Symbol table management: Hash table techniques; scope of va~ables and block 
st~ucta~ing Introduction to error recovery 1 Bottom up parsing overview; Shift-reduce model Precedence 
Techniques: Simple precedence; Weak precedence; Simple mixed strategy precedence Bottom up semantic 
processing (Semantic activity only as needed for progrsmmaing assignments) Run-time storage allocation; 
Ma~ti-dimensional a~ay handling; Possible forms of intermediate code SLR(1) parsing Procedure handling: 
Recursionl parameter passing 4 Total 41 + 4 hours for review and examinations Figure 1. Course Outline 
for 15-week Semester its flexibility. Schools on the quarter system (1) What language should the compilers 
be could make this a two quarter sequence and expand written in? on the additional (italicized) topics 
presented. Similarly, instructors who feel that some addition- (2) What parsing techniques should be 
 al topics are critical in a first course need employed? discuss only two parsing techniques and could 
use the time saved to present these other topics. (3) What should the source language be? Such a practice 
may be necessary in schools with no second, more advanced, course on this subject. (4) What should the 
target language be? The lack of a term project permits greater free- dom, by not forcing the instructor 
into a situation In response to the first question, any higher level where he has no option in topic 
selection. language of the ALGOL type is perfectly adequate. Usually this choice will be dictated by 
the avail- IV. The Progra~uing Assignments ability of compilers at the computer center. There are four 
important questions which need Concerning the second question, we recommend to be asked about the progrsrmuing 
assignments: that the students write campilers based on LL(1), simple ~_ixed strategy precedence (SMSP) 
and and with cogent examples; formal treatment of the SLR(1) techniques. Not only do these methods general 
LL(k) or LR(k) theory serves no purpose at embody the most important parsing techniques, but this level, 
and will only bore and lose the stu- the manual construction of their parser tables is dents. It is also 
suggested that precedence quite straightforward, and of reasonable length techniques be treated as the 
first of the two for our suggested syntax (Figure 2). Furthermore, bottom-up techniques. In addition 
to historical the use of these techniques allows presentation of perspective, precedence techniques appear 
to fit both top-down and bottom-up methods. The order of in more naturally with the general shift-reduce 
presentation, as suggested in the course outline model, in that once the right end of the handle is of 
Figure i, is motivated by the feeling that the located, some search for the left end and which LL(1) 
technique, being top-down, is more intuitive production to reduce by must be made. and fits in naturally 
with the way in which any context free language can be shown to be accepted The third question is the 
most important one by some (nondeterministic) pushdown automaton. The and is central to the determination 
of the success LL(1) restriction is easily seen to be sufficient of this course. Achievement of correct 
balance to force the machine to behave deterministically. between too easy and too complex a source language 
At this point, it should be noted that these is critical. Failure to find this balance can turn parsing 
techniques should be presented intuitively the course into a disaster. Figure 2 presents a grsrmuar 
we feel is a good choice. <program> : :: <declaration-statement> <statement-list> . <declaration-statementb 
::= DECLARE <declarations> ; IA <declarations> ::= <declarations> , <declare-item> I <declare-it em~ 
 <declare-item~ : := identifier I identifier (number) <statement-list> ::= <statement-list> ; <statement> 
I <statement> <statement> ::= : <label> : <statement> I <unlabeled- statement> <unlabeled-statement> 
::= BEGIN <statement-list> END I GOT0 <label> I READ <inlist> I WRITE <outlist> I IF <relationai-expression> 
THE~ <unlabeled-statement> I <variable> ~ <expression> <inlist> ::= <inlist> , <variable> I <variable> 
 <outlist> ::= <outlist> , <out-item~ I <out-item~ <out-item~ ::= E0L I <expression> <relational-expression~ 
: := <expression> <relational-operator> <expression> <expression> : := <expression> <add-operator> <term> 
I <term> <tenu> : := <term> <multiply-operator> <factor> I <factor> <factor> : : = -<unit> I <unit> 
 Figure E. Typical Source Language for Programming Assignments 161 <unit> ::= <variable> I ( <expression> 
) I number <variable> ::= identifier I identifier ( <expression> ) <label> ::= identifier ~el~ional-operator> 
::= < I< I = m/ <add-operator> ::= + I <multiply-operator> ::= / I Special semantics: (1) All scalar 
variables must be declared. (2) Names for labels, scalar variables, and subscripted variables must all 
be distinct.  (3) Identifier is AIB I...IZ (i.e., names for variables and labels are restricted to a 
single letter).  (4) Number is an integer in the range zero to scme convenient maximum.  Figure 2. 
Typical Source Lsm~uage for Programming Assignments (continued) Some elements of the language which 
make it On the other hand, interesting character is easy to compile are: added by such devices as (1) 
The limitation of variable names to one (i) GOTO <label> and IF <relational- letter and the global scope 
of all expression> T}KEN <unlabeled-statement>, which variables and labels eliminates serious cause the 
need to save enough information to deal symbol table management. with unresolved forward references at 
a later time. (As a practical consideration we recommend (2) The required declaration of all vari- that 
the generated code be stored in a large array, ables, and the use of only one dimen- in some encoded 
form. This array can be viewed as sional arrays, permits easy semantic the memory of the target machine 
and the encoding type checks, as an identifier is either as the machine language representation of the 
a label, scalar, or one dimensional object code produced. The necessary corrections array. to the code 
are then easy to make. In handling the GOTO, the necessary information can be stored (3) The use of one 
dimensional arrays with by means of a linked list starting in the symbol compile time specified bounds 
eliminates table and winding through the array of object run-time storage allocation and greatly code. 
) simplifies code generation for sub- scripted references. (2) The presentation of the grammar in a form 
which is syntactically unusable for the parsing (4) By use of syntactic sugar, labels are techniques 
to be employed. The resulting necessary readily distinguished from variables that manipulation of the 
grammar can be very instruc- begin assignment statements. tive. The natural looking grsmmar presented 
in Figure 2 is in just such a form. (5) Keywords (capitalized in Figure 2) are reserved. Caution should 
be exercised in incorporating any extensions. The addition of seemingly innoc- (6) Input/0utput is rudimentary. 
uous language features can very easily complicate the assignment. (See, for example, the mini- language 
example in the next section, where the 162 syntactic device mentioned in (4) above is elimi- nated.) 
Indeed, the inclusion of certain "desirable" features, like string manipulation, run-time error detection 
or recursion can suddenly turn a simple assignment into a semester project. In line with this policy, 
it is reasonable to halt compilation upon detection of the first error. Error recovery and correction 
is better left to a more advanced course. The choice of a zero address (stack) machine for the architecture 
of the target computer helps keep the programming assignments simple. With this architecture the need 
to be explicitly concerned with temporary variables is eliminated. One possible architecture and instruction 
set is exhibited in Figures 3 and 4. We have attempted z/o de-vices to provide a target machine and 
instruction set which is limited enough to be presentable in a single lecture, but which is rich enough 
to support our language and to permit some minor optimization by ambitious students. It is possible that 
an instructor, especially in a two-quarter course, might expand the target machine and instruction set 
to include varying length instructions, index registers, more flexible I/O instructions, etc. Alternatively, 
other forms of architecture can be examined through the use of the mini-language problems mentioned earlier. 
(For the sake of brevity, important hardware functions, such as checking for stack under/overflow, addressing 
errors, etc., have not been included in the instruction descriptions in Figure 4.) [ L I L I CPU [ [ 
Instruction register Stacktop Program counter i K L I I , \ word 0 ~ord M memory word N stack word 0 
 Figure 3. Simplified Architecture of Target Machine Instruction Data Field Cc~ments JMP COMPSKPT 
POP LOAD LOADI STORE READ WRITE FETCH ADD SUB MUL DIV NEG STOP address relop addre s s address 
 number type Figure 4. PC ~ address begin if stack (staektop-l) relop stack (stacktop) then PC ~ PC+2 
else PC ~ PC+l; stacktop ~ staektop-2 end (relop is 0,1,2,3,4,5 representing <, ~, >, ~ =, ~) after 
cempleting all other instructions PC ~ PC+I is performed begin memory (address) ~ stack (stacktop); 
stacktop ~ stacktop-i end begin stacktop ~ stacktop+l; stack (stacktop) ~ memory (address) end begin 
staektop ~ stacktop+l; stack (staektop) ~ number end begin memory (stack(stacktop-l)) ~ stack (stacktop); 
stacktop ~ stacktop-2 end begin stacktop Ã·- stacktop+l; stack (stacktop) . value from reader end if 
type = 0 then begin value to printer * stack (stacktop); stacktop ~ stacktop-1 end else value to printer 
~ carriage return (type is 0 or i) stack (stacktop) ~ memory (stack(staektop)) begin li 1 stack(stacktop-1) 
* stack(stacktop-1) stack(stacktop stacktop ~ stacktop-1 end stack (stacktop) ~ -stack (stacktop) Instruction 
Set for Target Machine Even with the simplified language described above writing the first compiler 
is a formidable task. To ease the sheer burden of progrannming, we suggest that a lexical analyzer be 
provided to the students. This is normally a messy task and one that is not particularly instructive. 
If a care- fully coded lexical analyzer is provided, the students can study it as a good example of struc- 
tured programming. Recent experience in teaching this course has shown that it pays to make the first 
compiler (LL(1)) easier by providing a detailed model. A complete compiler for the sub-language consisting 
 of a single assignment statement using only scalar variables was handed out to the students prior to 
the first programming assignment. In this way students, who may have had no previous experience with 
formal automata, can see how a formal parsing scheme is encoded as a simulated machine driven by parsing 
tables. Constructing the first compiler, therefore, reduces to reworking the grammar into LL(1) form 
and adding appropriate semantic actions (including semantic error detection) where appropriate. (Notice 
that the course outline devotes a lecture to the discussion of this sample cempiler.) Since the first 
compiler cannot be formally assigned until after the fifth week, there is time for a tutorial assignment 
for those students unfa- miliar with the higher level language chosen for the course. A good choice would 
be to program a simulator for the target machine. In this way, the students not only learn the higher 
level language in which they must program, but gain a better under- standing of the functioning of the 
target machine. Another possible program choice is one which pro- duces some form of mnemonic translation 
when passed the compiler's symbol table and array of generated code. For grading purposes, it is probably 
wise to have the students run their eempilers against a standard test program. For a nice final touch, 
the students can have their generated code run by passing their array of object code to an instruc- tor 
provided simulator. This provides the students the satisfaction of having actually done a "compile and 
go", and also, provides a rapid and reasonable check of the compiler's accuracy. The Sieve of Eratosthenes 
has been used for this purpose. V. An Example of a Mini-Ia~guage Problem As mentioned in earlier sections, 
the mini- language problems are an essential aspect of the course, in that they provide the instructor 
with a means of considerably broadening the students' experiences. It is hoped that through careful selection 
of these problems, the students will be able to analyze and handle new situations that they may encounter 
in more advanced work. Example: Exercise in compiling multiple assign- ments in languages which also 
allow multiple labels (e.g., nul: m2: l>-q~r+s). Construct a translator with underlying LL(1) parser 
for the language generated by <statement> ::= id : <statement> I ~content> <content> ::= id ~ <content> 
I i"&#38;~ <expression> <expression> : := <expression> + id li_ After some work, the students may 
obtain the LL(1) grammar <statement> ::= id <statement-or-content-trail> <statement-or-content-trail>::= 
: <statement> I ~ id<content-or-expression-trail> <content-or-expression-trail> ::= id <content-or-expression-trail> 
I <e~ression-trail> <expression-tail> ::= + id <e~ression-trail> IA-- However, if the students attempt 
to append code generation to this grammar (as the names of  semantic routines embedded in the production 
rules) they find a problem with id's. For example sc~e- where in <statement-or-content-trail> ::= : 
<statement>  the routine enterid should appear so that the previously encountered id can be entered 
in the symbol table as a label. If we attempt to maintain the discipline that only the lexical analyzer 
should have access to the input stream, then that id must be transmitted via a semantic stack, and is 
en--tered there by the routine s~c~d in <statement> ::= id stackid id <statement-or-content-trail> Since 
at the time that <statement>is expanded as above, id is the current input symbol, the parser has the 
i--nformation needed to generate s~a~d id as part of the expansion. However, such informa- tion is not 
available in the rule <expansion-trail> ::= + id <expression-trail>, since + will be the current input 
symbol. One possible grammar (with embedded semantics) is: <statement> ::= id stackgd id <statement-or-content-trail> 
 <statement-or-content-trail> ::= eag~d : <statement> I ~ <content-or-expression-trail*> store <content-or-expression-trail> 
::= <content-or-expression-trail*> store* I op~and <expression-trail> <content-or-expression-trail*> 
::= id stated id <content-or-expression-trail> <expression-trail> ::= + <expression-trai~> IA <expression-trail*> 
: := id stackid id operand gene~ateadd <expres si on-trail>  where stackid causes the next item on 
the syntax stack (/d--the name of the id) to be stacked on the semantic stack. e~t~d causes the name 
on the top of the semantic stack to be entered in the symbol table as a label. operand generates a LOAD 
address, where address is the address of the variable on top of the semantic stack. generateadd generates 
ADD. store generates a POP address, where address is the address of the variable on top of the semantic 
stack. 165 generates a POP address, LOAD address, where address is the address of the variable on top 
of the semantic stack.  store* The same problem might be used later, only with the minor alteration 
of "underlying SLR(1) parser". As is easily seen, these mini-language problems provide the instructor 
with a tool which allows him to provide students with a great variety of experiences. VI. Text Materials 
 Unfortunately it is impossible to recommend any single textbook for this proposed course. Aho and Ullman 
[3] give a thorough treatment of parsing techniques, but much of their material is far too formal and 
abstract for this course, and thus, it can be suggested for use only as a refer- ence. However, many 
good examples, worked out in complete detail, can be excerpted from it for use in this course. It is 
the best single source on parsing techniques. There are also numerous journal articles which describe 
various parsing methods. A few are listed in the references [1,2,7,8,10,12]. The material in some will 
be readily accessible to the student, especially Aho  and Johnson [2], which is highly recommended. 
 Others will require elucidation by the instructor. Suitable references must be provided for the additional 
course topics. Gries [9] has an excellent treatment of non-syntax related concepts, especially symbol 
table management and run-time storage allocation. Morris [16] presents a good survey of hashing. Knuth 
[15] treats this topic in great detail. Hopgood Ill] briefly treats hashing as well as many other topics, 
including elementary optimization, register management, and storage allocation. If call-by-name is to 
be taught, the instructor will find Ingerman [13] useful. Kanner, et al [14] present a smattering of 
problems encountered in an early ALGOL compiler, and can be used as a motivating device. This paper is 
reprinted in Rosen [17], along with some other interesting material. References <RefA>[i] Aho, A. V, P. J. 
Denning, and J D. Ul3_man, '~Weak and mixed strategy precedence parsing, " JACM 19 (1972), pp. 225-243. 
[2] Aho, A. V and S. C. Johnson, "LR parsing, " Com~mlting Surve[s 6 (1974), pp. 99-124. [3] Aho, A. 
V. and J. D. Ullman, The Theory of Parsing/ Translation, and Compiling, Vol. 1 (1972) and Vol. 2 (1973) 
, Prentice-Hail, Inc., Englewood Cliffs, NJ.  [4] Barnard, A. C. L., "Planning and experience with a 
one-quarter course on compiler writing using Gries' book and structured programming, " SIGCSE Bull. 7, 
No. 2 (June, 1975), pP. 27-29. [5] Chanon, R. N., "Compiler construction in an undergraduate course: 
some difficulties, " SIGCSE Bull. 7, No. 2 (June, 1975), PP. 30-32.  [6] [7] [8] [9] [ io] [ii] 
 [13]  [z4] [15] [16] [17] Curriculum 68, CACM ii (1968), pp. 151-197. DeRemer, F. L., "Simple 
LR(k) grammars," CACM 14 (1971), pp. 453-460. Feldman, J. A. and D. Gries, "Translator writing systems, 
" CACM Ii (1968), pp. 77-113. Gries, D., Compiler Construction for Digital Computers, John Wiley and 
Sons, Inc., NY (1971). Griffiths, M., "LL(1) gram/nars and analyzers," in Compiler Construction an 
advanced course, edited by F. L Bauer and J. Eickel, Vol. 21 of Lecture Notes in Computer Science, edited 
by G. Goos and J. Hartmanis, Springer-Verlag, Berlin (1974) Hopgood, F. R. A., Compiling Techniques, 
American Elsevier, NY (1969). Ichbiah, J. D. and S. P. Morse, '~ technique for generating almost optimal 
Floyd-Evans productions for precedence grammars," CACM 13 (1970), pp. 501-508. Ingerman, P. Z., "Thunks, 
" CACM 4 (1961), PP. 55-58. Kanner, H., P. Kosinski and C. L. Robinson, "The structure of yet another 
Algol compiler, " CACM 8 (1965), pp. 427-438. Knuth, D., The Art of Computer Programming, Addison-Wesley 
Publishing Company, Reading, MA (1973), Vol. 3, Sorting and Searching. Morris, R., "Scatter storage 
techniques, " CACM ii (1968), pp. 35-44. Rosen, S., Progrsmm~ng Systems and Languages, McGraw-Hill, 
NY (1967).  </RefA>166  
			
