
 A Framework for Program Verification in the Context of Linked Structures and Pointer Variables Tom Whaley 
Department of Computer Science Washington and Lee University Lexington, VA 24450 Intemec whaley.t.p@p9955.wlu.edu 
1. Introduction. The question of the appropriate role of program correcmess proofs in the undergraduate 
curriculum is current and even controversial ([2] and responses). The issue is somewhat analogous to 
the question of when to introduce &#38; limit proofs in the mathematics curriculum. For many of us who 
came to computer science via mathematics there was a major difference, however. We came to the calculus 
issue with years of coursework in real analysis and abstract mathematics. We had a basis for our opkions, 
a confidence in our experimentation, and an assurance that we could pinpoint precisely the source of 
fuzzy thinking on the part of our students-. We could get formal and rigorous when we deemed it appropriate. 
When I began teaching programming, it was not with the same degree of confidence or competence. I was 
comfortable with syntax, structured programming, stepwise refinement, modularity and testing. However, 
I had no tools for formal examination or explanation of code. The best I could do to convince students 
that a loop worked was to step through a few iterations, hoping that the pattern of execution would become 
obvious . Fortumtely, we had David Gries and others to chide us, present workshops for us, and write 
books ([3]) for us. I was especially fortunate to take a short course from David in the IFRICS program 
at Clarkson University. This helped. I could now deal with weakest precondition semantics for assignment 
statements (both for simple variables and arrays), conditional statements, and compound statements. Loop 
invariants provided a sufficient tool for working with loop statements. By­products of this approach 
were clarity of specifications and documentation, tools for program development, and a methodology for 
program or algorithm presentation. This goes along way toward enabling us to get formal and Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy othsrwise, or to rspublish, requires a fee and/of specific permission. @ 1991 ACM 
0-89791-377-9/91/0002-01 19... $1.50 rigorous when we deem it appropriate. But not far enough. I wanted 
a clear understanding of formal techniques for data structures, especially pointer variable implementations 
of such. Students often find this a difficult and confusing topic; therefote the need for clarity of 
carefully presented semantics. Having little luck in finding a satisfactory presentation of pointer variable 
semantics ([4] was of some help), I attempted my own development. Eventually, I found that a careful 
look at cursor implementations of linked structures could be extended nicely to provide a semantic theory 
of pointer variables adequate for my needs. Recent mseareh articles ([1,5,61) make use of a closely related, 
if not equivalent approach. In this paper we outline this approach by showing first how formal methods 
can be applied to specify and verify programs dealing with linked structures within arrays. As our example 
we deal with ordered linked lists (a sequel is planned which will treat more complicated structures). 
Then we show how to extend this model to incorporate pointer variable implementations. We do not give 
detailed verifications of the code segments presented here, but rather show how to formulate the requirements 
so that basic techniques as presented in [3] can be applied to complete the verification. Our goal is 
to provide a model whose formality an instructor can adjust as appropriate. 2. Summary of weakest precondition 
semantics. This section is included for the benefit of those readers who are unfamiliar with the subject. 
We give here some of the essential definitions (applied to Pascal) and notation from Part II of [3]. 
Since the purpose of this paper is to provide an outline mther than actual correcmess proofs, readers 
new to this subject should be able to get the general picture by reading this section and the rest of 
the paper. They are then encouraged to turn to [3] for a more complete presentation of these topics. 
If Q and R are predicates and S is a program statement, then the notation {Q] S (R} asserts that if Q 
is true before execution of S, then execution of S terminates with R true. The semantics of most basic 
statements can be defined in terms of the weakest precondition operator, wp. If S is a statement and 
R is a prcdicatc, then wp(SJl) denotes a predicate with the property that {Q] S {R} holds if and only 
if Q=wp(S,R). In defining the semantics of various elementary statements in terms of wp, we must include 
domain conjuncts to assure that constituent expressions can be evaluated. For simplicity, we choose to 
ignore this complication and omit these conjuncts. With these understandings, for the assignment to a 
simple variable, we have WP( X:= e ~) = R: whete e is an expression of the same type as x and Rx denotes 
the predicate obtained by textually substittttin~ e for x in the predicate R. For the if-statement we 
have wp( if b then S ,R) = (not b and R) or (b and wp(S,R)) ad wp( if b then S else U , R) = (b and WP(S,R)) 
or (not b and wp(U,R)). The weakest precondition for the while-statement is somewhat more complicated, 
and we omit its formal definition. In practice we usually make use of loop invariattts to verify while-statements. 
The idea hem is that in order to establish {Q) while b do S {R} it is enough to establish termination 
(the use of bound functions is covered in [3]), and to find a predicate P, the invariant, such that l) 
Q-P (P initially true) 2) (b and P) a wp(S,P) (P invariant under execution of loop body} 3)(not bandP) 
= R (termination gives postcondition). Here P a wp( whiie b do S ,R). To deal formally with arrays, it 
is best to view the array as a function from the subscript type into the component type. Then an assignment 
to an array element can be defined as an assignment to the function itself. Thus we have wp( b[e] := 
f JZ) = R(b.~: ~, where e is a valid subscript expression, f is an expression compatible with the component 
type, and Additional convenient notation for dealing with arrays is to use b[i:j] to denote the subarray 
of b restricted to the interval from i to j, inclusive, and to interpret relations such as b[i:j]>t as 
universally quantified over the interval. Finally, compound statements arc handled by WP( S ~;S2 J?) 
= WP(S ~,WP(S2R)). In theory this enables us tQ provide a verification of a program (Q) S (R) by repeatedly 
applying the wp operator, working from the postcondition R to obtain wp(S,R), and then showing that the 
resulting predicate is implied by Q. 3. Array implementation of ordered linked lists. If we are to deal 
formally or mathematically with data structures, it is mandatory that we have careful definitions of 
the structures themselves. It is also important to note that the use of non-program variables, so-called 
thought variables , in program veritlcation often provides clarity in presentation. For us a M of elements 
of type T is a finite sequence, S, of elements of type T; i.e., for some non­ negative integer n, S is 
a function from ii into T where ii denotes the set of non-negative integers less than n. If n=O, the 
list is empty. If we choose to implement the list elements as components (not necessarily consecutive) 
of an array, K: array [I] of T, we need a position function indicating where S(i) is located in the 
array, i.e., we need a one-to­ one function, P, from ii into I with S=KOP where o denotes function composition. 
The usual notion of a linked implementation is obtained by considering the next function , N=P o SUCCOP-l; 
SONOP= PO SUCC, and N&#38;(i)) = P(i+l). Now the domain of N is (P(i) :0< i < n-1), and N@(i))= I@+l(P(0)). 
we usually extend the domain of N to include n-1 by defining N(n-1) = X @ I. For example, if I is the 
subrange type O..m, we might take Ito be-1. So one way to implement the list would be to start with K 
and P and define N and S as thought variables as indicated above, However, if we have p a variable of 
type Iu{L} and N is a function from I to Iu{h} so that IW(p)=k for some n20, we can define a position 
function, P, by P(i) = IV(p). This is, in fact, our usual approac~ we implement K and N either as parallel 
arrays or as an array of records and use S and P as thought variables. Note that when our list implementation 
uses consecutive array components with S(i) stored in K[i], P becomes the identity function, and N is 
simply the successor function (implicitly). If T is an ordered type, we say the list S is ordered provided 
S(i)<S(j) whenever O<iejen (treating T as a record type with ordered key field requires only a slight 
modification in notation, of course). In terms of K, N and p, this requirement becomes Kmi[p]] < Kmj[p]] 
whenever (Kicjen. Thus to claim that we have an ordered list, our proof obligation is to show LI : I@[p] 
= L for some n20 {we have a list), and L2: KIJ@[p]] < Kmj[p]] for O<i<j<n (the list is ordered]. As an 
example, we now outline a verification of the standard linked list insertion. To avoid a digression on 
procedure call semantics, we choose to use iteration rather than recursion. Our precondition is that 
(K,N,p) implements an ordered list (LI and L2) and t is a value of type T. Informally, we wish to extend 
the list, maintaining order and adding t to the bag of list values. First we present the usual search 
codez i.e. the code to locate the first element of the list, if any , whose value is at least t and 
also locate the predecessor of this node, if any. Using q and r as variables of type Iu{l} and making 
use of thought variable S, we are able to state succinctly the postcondition for our search loop as Q: 
(3i: O<iSn: QI and Q2 and Q3 and Q4) Whele QI: q=~[pl {q gives a subscript of a list element or is1) 
Q2: SIOi-l]<t (any preceding list element (or all elements if q=l) have values less than t), Q3: SIO:n-l]2t 
{unless q=l, elements from S[i] on are at least t in value), and Q4: ((PI) and (i=O)) or r=Ni-l [p]) 
{the list is empty and r=l=q, or r=k and q gives the first element, or q=k and r gives the last element 
of the list, or q gives an element other than the fwst and r gives its predecessor). The usual search 
code is something similar to c: C=k, q:=~ Done=q=k while not Done d o if K[q]>=t then Done= true else 
 begin r=q q=N[ql; Dom.q.k end; An adequate loop invariant is given by Q: (Done and Q) or (not Done and 
(3i: (Ki<n: QI and QZ and Q4)) which is obtained by a fairly standard weakening of the postcondition. 
It is straightfonvard to verify this invariant and to check that (LI and L2) C {Q]. For the actual insertion, 
we take as given that v is in I-PIO:n-1]. (To implement and verify a NewNode operation, say as a stack 
of free nodes, would make an excellent student project.) So the existence of v together with L1 and L2 
and Q becomes the precondition for the insertion code. The postcondition could be smted in terms of bags 
of values, etc., but a cleaner presentation is obtained by taking a stronger predicate which gives the 
exact composition of the resulting sequence. To this end, with O<Kn and t in T, we define the sequence 
[S;i:t] by S(j) if O<j<i [S;i:t]@= t if j=i { S(j-1) if i<j<n. Letting SO and PO denote fixed functions, 
the precondition for the insertion becomes V: L1 and Lz and Q and S=SO and P=PO. The postcondition can 
be taken simply as W: S=[So;i:t] and P=[po;i:vl. From P=[Po;i:v] it follows that NII+l [p]=p[n+l]=pO[n] 
=h; so LI holds. Also, that L2 holds for [So;i:t] is clear from Qz and Q3. And the desired bag of values 
is apparent from the definition of [SO;iX]. Again, application of the weakest precondition operator to 
the code K[v]:=G N[v]:=q if r=k then p.v else N[r]:=v; leads to the verification. More detail of the 
veritlcation is given in the next section. 4. Extending array semantics to pointer variables. The innovation 
needed to obtain a satisfactory semantic model for dealing with lists linked by pointer variables is 
the use of thought variables in the semantic definitions. The ideas are motivated by the array implementation 
of Section 3. To be specific, let us assume the following type definitions: type NodcPtr = Nodcz Node 
= record Key: KeyTypq (some ordered type) Next: NodePtr end; Associated with these types, we assume a 
set CL (the address space for type Node), an element nil@ Cl., an array X with subscript type Cl and 
component type KeyType, and an array Tt with subscript type 0-and component type Cl u {nil). Again, thought 
variables 9( and T-could be replaced by a single army of ~cords. For p an initialized variable of type 
NodePtr, the value of p is in CLu{nil), @.Key is interpreted as 9( [p], and pA.Next as T. [p]. With this 
interpretation, reference through a nil pointer corresponds to an array subscript out of bounds. The 
semantics for assignment statements involving simple pointer variables is the same as beforq i.e. wp( 
p:=e ,R) = R:. To see how to handle derived pointer variables, let s consider, as an example, wp( ~.NextA.Next:= 
qA.Next Jl). Now @.NextA.Next transforms to ~2[p] and qA.Next to 71 [q]. Thus in terms of the thought 
variables, the assignment is T-U-UP]] := --l-WI], and we would have ~m[m[p]] := IUql ifV =R&#38;;m[pl:n[ql) 
However, for this to make sense, R also must be expressed in terms of the thought variables. Thus, the 
approach we adopt is to replace pointer references in the predicates by corresponding expressions in 
the thought variables and compute wp using the array semantics. The resulting predicate can then be translated 
back to pointer notation, if this is preferred. As an exanmle. wp(''p`.Next=q;.Next'',p`.NextA.Next`.Key=r`.Key) 
s ~~[pl:= ~[q] ,~[~[~m]]]=x[rl) = (K[(Tt2xT-[ql)[(Tl;#ll[ql)@lll=9Qrl) = (K[(~;p$fl[ql)[( TUqlll=X[rl) 
= (((p= n[ql)~d ( K[~[qll=X[rl) or ((p#TUql) and (XITUTUqlll=K[rl))) = (@q .Next) and (qA.NextA.Key=r 
.Key)) or ((p~A.Next) and (qA.NextA.Next=r .Key)). Recall that we are assuming that all given expressions 
can be evaluati, otherwise, the array semantics would include domain constmints which would yield conditional 
conjuncts assuring that q, qA.Next, etc. are initialized and non-nil. To motivate our treatment of the 
procedure m, assume that Avail is a non-program variable of type NodePtr. We picture Avail as pointing 
to a list of unused addresses. At any point, Avail is initialized, s#Avail for all termss other than 
Avail itself, and Avail .Next and AvailA.Key are not initialize@ so comparisons with them fail. Execution 
of new(t) results in t getting the current value of Avail and Avail getting a new value with the above 
restrictions. Thus our method for computing wp( new(t) ,R) is as follows: 1. Express R in terms of the 
thought variables, giving R . 2. Express t in terms of the thought variables, giving 3. Co~pute wp( 
t :=Avail J) ). 4. Use the restrictions on Avail to remove all occurrences of Avail.  5. Convert occurrences 
of the thought variables to pointer notation.  The following example illustrates this technique. wp( 
new(@.Next) Next=qAqNext)t) . ~q_l[p]:=Avti,~ [r]=~[q]) = ((TL;pAvail)[r]=(Tl,;pAvail)[q]) = (p=r=q 
and Avail=Avail) or (p=r and pq and Avail= TL[q]) or (p#r and p=q and Tl [r]=Avail) or (p#r and pq and 
ll[r]= ll[ql) = @r== or(p#randp#qand TUrl=TUql) = (p=r=q) or @#r and p#q and r .Next=qA.Next) As for 
the pointer variable implementation of ordered linked lists, the defining conditions LI and L2 of Section 
3 apply in terms of the thought variables 9( and ~. Now the insertion code becomes s: new(v); v .Key=C 
vA.Next-~, if r=nil then p:=v else rAoNex~=v with precondition V and postcondition W, the obvious translations 
from Section 3. We conclude by outlining the verification for the case r=lll-l [p]#nifi the other cases 
are actually simpler. Complete verification of some of the steps in the outline would require induction 
and exploitation of the properties of Avail. It is convenient to express the postcondition W in terms 
of 9( and ~ using the facts that S(i)=9( [Tli[p]] and P(i)=lli-l [p]. Using PO as the precondition value 
of p and letting Tl~ denote the formula l-l:[Pol if O<jci v if j=i nJo?po] if i<j<n+l{ and X: the formula 
xo[Tt;[Poll if O<j<i t ifj=i , ~O[~J~[pOll if i<j<n{ we have W=(W and W ) whe~ W=(llJ[p] = Il. ~ ) and 
W=(Wm~[pOll=X~). Since the code !S does not alter r or q, we can use r=TL -1 [pO] and q=Tl [pO] throughout. 
In the case under consideration, = wp( if r=nil then p:=v else r .Nexti=v , W) 1 = wp(rA.Nexc=v ,W) 
= (CM@[pl= TL~ ) and W . Then W2 = wp( vA.Nexc=q ,W1) = (((~;v@@iP]= ~: ) and W . Continuing, W3 = wp( 
v .Key:=,W2 )W2) = (((Tl;v@J+[Pl= n: ) and ((?(;v:t)[~ ~[po]]=~;); so WP(5,W) = wp( new(v) ,W3) = (((n;&#38;ail:q);nAvailip]= 
Ttj[Pol if O<j<i Avail if j=i TOol[po] if iej<n+l { and (X;Avail:t)[T@pJ]= 9(:). Now the precondition 
V gives ll=T1-O, X=XO, and P=PO; so the prwmWm implies that ((ll;Avail@;cAvail~[p] = ((~&#38;AVaikq);CAVailj[POl 
T$j[pol if O<j<i = ((ll&#38;AVail:q);CAVail)[Tt i~[POll ifj=i { (( TIO;Avail:q);~Avail~-i+l[Tti~[pO]] 
if i<j<n+l l-l~[pol if O<j<i = ((T, ~; Avail: q);r:Avail)[r] if j=i { (( TIO;Avail:q);~ Avail)j-i+l[r] 
if icj<n+l njho] if O<jci = Avail if j=i ((710; Avaikq);r:Avail~ -i-[Avail] if iej<n+l { l-t; [pol if 
OSj<i = Avail if j=i nj~-l[ql if i<j<n+l { n~[pol if OSj<i = Avail if j=i l-LJol[po] if i<j<n+l. { Thus 
V implies the first conjunct of wp(!S,~, and the second conjunct follows in a similar way. References. 
<RefA>[1] A. Bijlsma, Calculating with pointers, Sci Comp Prog 12(1989) 191-205. [2] E. W. Dijkstra, On the 
cruelty of really teaching computer science, Comm ACM 32(Dec. 1989), 1398-1404. [31 D, Gries, The Science 
of Programming, Springer-Verlag, New York, 1981. [4] C. A. R. Hoare and N. Wirth, An axiomatic definition 
of the programming language PASCAL, Acts Inform. 2(1973), 335-355. [51 J. M. Morris, A general axiom 
of assignment, in: Theoretical Foundations of Programming Methodology (Lecture Notes International Summer 
School, Marktoberdorf, 1981) NATO Adv. Study Inst. Ser. C Math. Phys. Sci. 91 (Reidel, Dordrecht, Netherlands, 
1982) 25-34. [6] J. M. Morris, Assignment and linked data structures, in: Theoretical Foundations of 
Programming Methodology (Lecture Notes International Summer School, Marktoberdorf, 1981) NATO Adv, Study 
Inst. Ser. C Math. Phys. Sci. 91 (Reidel, Dordr@ht, Netherlands, 1982) 35-41.</RefA>
			
