
 Allocating Bandwidth for Bursty Connections Jon Kleinberg Yuval Rabanit l%a Tardos: Cornell University 
Technion Come]] University IBM Almaden Abstract In this paper, we undertake the first study of statistical 
mul­tiplexing from the perspective of approximation algorithms. The basic issue underlying statistical 
multiplexing is the fol­lowing: in high-speed networks, individual connections (i.e. communication sessions) 
are very bw-sty, with transmission rates that vary greatly over time. As such, the problem of packing 
multiple connections together on a link becomes more subtle than in the case when each connection is 
as­sumed to have a fixed demand. We consider one of the most commonly studied models in this domain: 
that of two communicating nodes connected by a set of parallel edges, where the rate of each connection 
be­tween them is a random variable. We consider three related problems: (1) stochastic load balancing, 
(2) stochastic bin­packing, and (3) stochastic knapsack. In the first problem the number of links is 
given and we want to minimize the expected value of the maximum load. In the other two prob­lem the link 
capacity and art atlowed over@w probability p are given, and the objective is to assign connections to 
links, so that the probability that the load exceeds the link capacity is at most p. For the stochastic 
load balancing problem we give an O(l) -approximation algorithm for arbitrary random vari­ables. For 
the other two problems we have algorithms re­stricted to on-off sources (the most common special case 
studied in the statistical multiplexing literature), with a Research for this paper was supportedin part 
by NSF throughgrant DMS 9505155. Email: kleinber@almaden. ibm. com klost of this workwas done while visiting 
Cornell University. Support at Cornell wasprovidedby ONR throughgrant NOO014-%-I -0050. tlis work was 
stso supportedby grantsfrom the fund forthepromotionof spon­sored researchand thefundfor thepromotionof 
researchatlheTechnion, and by a David and RuthMoskowitz Academic Lectureshipaward. Email: rabani@cs. 
tecbnion. ac. il keseamh supportedin part by an NSF PYI award DMI-9157199, by NSFthroughgrantDMS 9505155, 
andbyONR throughgrantNOOO14-96­1-0050. Emai[: eva@cs. cornel 1. edu somewhat weaker range of performance 
guarantees. A standardapproach that has emerged for dealing with probabilistic resource requirements 
is the notion of @ective bandwidth this is a means of associating a fixed demand with a bunsty connection 
that represents its distribution as closely as possible. Our approximation algorithms make use of the 
standard definition of effective bandwidth and also a new one that we introducq the performance guarantees 
are based on new results showing that a combination of these measures can be used to provide bounds on 
the optimal so­lution. 1 Introduction Motivationand previous work. The issues of ad­mission control and 
routing in high-speed networks have in­spired recent analyticd workon networkrouting and band­width allocation 
problems in several communities (e.g. [10, 1, 5]). One line of work has been directed towards the de­velopment 
of approximation algorithms and competitive on­line algorithms for admission control and virtual cimuit 
rout­ing problems (see the survey by Plotkin [16]). The network model in this line of work represents 
the links of the net­work as edges of fixed capacity, and connections as pairs of vertices with a fixed 
bandwidth demand between them. The algorithms and their analysis are motivated by this network flow perspective. 
In fact, however, traffic in high-speed networks based on ATM and related technologies tends to be extremely 
hursty. ltte transmission rate of a single connection can vary greatly over timq there can be infrequent 
periods of very high peak rate, while the average rate is much lower. One can try to avoid this issue 
by assigning each connec­tion a demand equal to its maximum possible rate. The use of such a conservative 
approximation will ensure that edge capacities are never violated. But much of the stmmgth of ATM comes 
from the advantage of statistical multiplexing the packing of uncorrelated, bursty connections on the 
same link. In particular, suppose one is willing to tolerate a low rate of packet loss due to occasional 
violations of the link capacity. As the peak states of different connections coin­cide only very rarely, 
one can pack many more connections than is possible via the above worst-case approach, and still maintain 
a very low rate of packet loss due to overtlow. Queueing theorists recently have devoted a great deal 
of study to the analysis of statistical multiplexing (see the book edited by Kelly, Zachary, and Zeidins 
[13]). Typically, this work models a single connection either as a discrete random variable X, with Pr[X 
= s] indicating the fraction of the time that the connection transmits at rates, or as a finite-state 
Markov chain with a fixed transmission rate for each state. (A much-discussed case is when X is an on-off 
source. In our context, such a connection is equivalent to a weighted Bernoulli trial.) This line of 
work has concentrated primar­ily on the case of point-to-point transmission across a set of parallel 
links; this allows one to study the packing and load balancing issues that arise without the added complication 
of path-selection in a large network. One of the main concepts that has emerged from this work has been 
the development of a notion of e~ective bandwidth for bursty connections. This is based on the following 
natu­ral idea Suppose one is willing to tolerate a rate p of over­flow on each link. One first assigns 
a number ~p(X) to each connection (i.e. random variable) X, indicating the effec­tive amount of bandwidth 
required by this connection. One then uses a standard packing or load balancing algorithm to assign connections 
to links, using the single number/3P(X) as the demand of the connection X. This notion of effective bandwidth 
is indeed what underlies the modeling of routing problems as network flow questions. Consensus has more 
or less been reached (see Kelly [12]) on a specific formula for 8P, first studied by Hui [10]: a scaled 
logarithm of the moments-generating function of X. One of its attractions is that packing according to 
~P (X) al­ways provides a relatively conservative estimate in the fol­lowing sense: If the sum of the 
effective bandwidths of a set of independent connections does not exceed the link capac­ity, then the 
probability y that the sum of their transmission rates exceeds twice the capacity at any instant is at 
most p. Problems studied in this paper. In this paper, we un­dertake the first study of the issues inherent 
in statistical mul­tiplexing from the perspective of approximation algorithms. We are motivated primarily 
by the following fact: the queue­ing theoretical work dkcussed above does not attempt to prove that its 
methods, based on effective bandwidth, pro­vide solutions that are near-optimal on all (or even on typ­ical) 
instances. Indeed, researchers have recognized that claims about the power of the effective bandwidth 
approach depend critically on a number of fundamental assumptions about the nature of the underlying 
traffic (e.g. de Veciana and Walrand [18]). Thus an analysis of statistical multiplex­ing problems in 
the framework of approximation algorithms can provide tools for understanding the performance guar­antees 
that can be attained in this domain. We mentioned above that the model studied in this area concentrates 
primarily on the case of two communicating nodes connected by a set of parallel edges. Thus, the prob­lem 
of assigning bursty connections to edges is equivalent to that of assigning (bursty) items to bins. As 
a result, we have a direct connection between the standard questions ad­dressed in statistical multiplexing, 
and stochastic versions of some of the classical resource allocation problems in combi­natorial optimization. 
We design and analyze approximation algorithms for the following fundamental problems: Stochastic load 
balancing. An item is a discrete random variable. We are given items Xl, . . . . Xn. We want to assign 
each item to one of the bins 1, . . . . m so as to minimize the expected maximum weight in any bin. That 
is, we want to minimize where Bi is the set of items assigned to bin i. Stochastic bin-packing. We are 
given items as above, and we define the oveflow probability of a subset of these items to be the probability 
that their sum exceeds 1. We are also given a number p > 0, We want to determine the minimum number of 
bins (of capacity 1) that we need in order to pack all the items, so that the overflow probability of 
the items in each bin is at most p. Stochastic knapsack. We are given p~ O and asetof items Xl,..., X~, 
with item Xi having a value vi. We want to find a subset of the items of maximum value, subject to the 
constraint that its overflow probability is at most p. Thus, the above problems provide us with a very 
con­crete setting in which to try assessing the power of various approaches to the statistical multiplexing 
of bursty cmmec­tions. These problems are also the natural stochastic ana­logues of some of the central 
problems in the area of approx­imation algorithms; and hence we feel that their approxima­bility is of 
basic interest. Of course, each of these problems is NP-hard, since the versions in which each item Xi 
is deterministic (i.e. takes a single value with probabilityy 1) correspond to the min­imum nrakespan, 
bin-packing, and knapsack problems re­spective y. However, the stochastic versions introduce con­siderable 
additional complications, For example, we show that even given a set of items, determining its overflow 
prob­ability is #P-complete (see Section 2). Moreover, we also show that simple approaches such as (i) 
applying Hui s definition of effective bandwidth [10] to the items, and then (ii) running a standard 
algorithm for the case of deterministic weights (e.g. Graham s Lowest-Fit makespan algorithm or First-Fit 
for bin paeking), can lead to results that are very far from optimal. Indeed, we show in Section 2 that 
in a certain praise sense there is no direct use of effective bandwidth that can provide approximation 
results as strong as those we obtain. 1.1 Our Results This paper provides the first approximation algorithms 
for these load balancing and packing problems with stochastic items. Our algorithms make use of effective 
bandwidth, and their analysis is based on new results showing, roughly, that it is possible to define 
a notion of eflective bandwidth that can be used to obtain bounds on the value of the optimum. However, 
the relationships between the effective band­width and the optimum are quite subtle. In particular, while 
Hui s definition is a useful ingredient in our algorithm for the case of load balancing, we show in the 
cases of bin-packing and knapsack that it is necessary to use a definition of effec­tive bandwidth that 
is different from the standard one. Our new effective bandwidth function @ has a number of addi­tional 
properties that make its analysis particularly tractable. In particular, it was through@ that we were 
able to establish our basic relations between the function ~ and the value of the optimum for the case 
of load balancing. Load Balancing. Perhaps our strongest result is for the load balancing problem: we 
provide a constant-factor approximation algorithm for the optimum load, for arbitrary random variables. 
With a somewhat larger constant, we can modify our algorithm to work in an on-line setting, in which 
items arrive in sequence and must be assigned to bins imme­diate y. Let us give some indication of the 
techniques underlying this zdgorithm. First, we mentioned above that the standard effective bandwidth 
&#38; comes with an upper hound guaran­tee: if the sum of the effective bandwidths of a set of items 
is bounded by 1, then the probability that the total load of these items exceeds 2 is at most p. (This 
fact is due origi­nally to Hui [10], and has been extended and generalized by Kelly [11], Elwalid and 
Mitra [4], and others.) Our proof of the constant approximation ratio uses of a new lower hound guarantee 
for effective bandwidth. Sup­pose we have a set of random variables Xl,. . . . Xn, so that each Xi is 
a weighted Bernoulli trial taking on the values O and 2-*, for an integer O < i ~ loglogp-l. We show 
that there is an absolute constant C < 7 so that if the sum of the effective bandwidths of the Xi~s at 
least C, then the probability that their sum exceeds 1 is at least p. A number of issues must be resolved 
in order to use these bounds in the design and analysis of our algorithm. First, the upper bound guarantee 
holds only under some restric­ting assumptions on the item sizes, which are not necessarily valid for 
our input. Therefore, we have to handle excep­tional items separately. Secondly, our lower bound concerns 
overtlow probabilities, whereas our objective function is the expected maximum load in any bin. Finally, 
we have to use this lower bound in the setting of arbitrary random variables, despite the fact that the 
concrete result itself applies only to a restricted type of random variable. Bin-packing and Knapsack. 
In the case of the the bin-packing and knapsack problems we consider primarily on-off sources. In our 
context, such a connection is equiv­alent to a weighted Bernoulli trial. Our emphasis on on-off sources 
is in keeping with the focus of much of the litera­ture (see e.g. the book [13] ). With somewhat weaker 
perfor­mance guarantees, we can also handle the more general case of high-low sources: connections whose 
rates are al ways one of two positive values. For the bin-packing problem with on-off items we give an 
algorithm that finds a solution with at most o (~-) B* + O(logp-l) bins, where B is the minimum possible 
number of bins. For the knapsack prob­lem we provide an O(logp-l )-approximation algorithm. We rdso provide 
constant-factor approximation algorithms for both problems, when one is allowed to relax either the size 
of the bin or the overflow probability by an arbitrary constant e > 0. Our algorithm for bin-packing 
can be mod­ified to work in an on-line setting, in which items arrive in sequence and must be assigned 
to bins immediately. Our algorithms are based on a notion of effective band­width, but not the standard 
one in the literature. In particu­lar, the guarantee provided by the standard definition is not strong 
enough for the bin-packing and knapsack problems: it says that if the sum of the effective bandwidths 
of a set of items is bounded by 1, then the probability that the total load of these items exceeds 2 
is at most p. While such a guarantee is strong enough for the load-balancing problem a load of 2 is 
within a constant factor of a load of 1 it is inadequate for the bin-packing and knapsack problems, 
which fix hard limits on the size of each bin. Stronger guar­antees without exceeding the link capacity 
were provided by Hui [10], Kelly [11] and Elwalid and Mitra [4] using large overfiow buffers. We provide 
such stronger guarantee with­out resorting to overflow buffers. In particular, for items of large peak 
rate (the most difficult case for the standard defi­nition @, we make use of our new effective bandwidth 
/? to provide the desired performance guarantee.  1.2 Connections with Stochastic Scheduling Although 
we have so far expressed things in the context of bursty traffic in a network, our result on load balancing 
also resolves a natural problem in the area of stochastic schedul­ing. There is a large literature on 
scheduling with stochastic re­quirements; the recent book on scheduling theory by Pinedo [15] gives an 
overview of the important results known in this area. In a stochastic scheduling problem, the job processing 
times are represented by random variables; typical assump­tions are that these processing times are independent 
and identically distributed, and that the distribution is Poisson or exponential. For some of these cases, 
algorithms have been developed that guarantee an asymptotically optimal sched­ule with high probability 
(e.g. Weiss [19, 20]). We can naturatly view our load balancing problem as a scheduling problem on m 
identical machines (the bins), with a set of n stochastic jobs (the items). Since the problem con­tains 
the NP-hard deterministic version as a special case, we cannot expect to find an optimal solution. What 
our load balancing result provides is a constant approximation for the minimum makespan problem on m 
identical machines, when the processing time of each job can have an arbitrary distribution. One distinction 
that arises in these scheduling problems is the following: must all the jobs be loaded onto their as­signed 
machines immediately, or can we perform an assign­ment adaptively, learning the processing times of earlier 
jobs as they finish? Our model, since it is motivated by a circuit­routing application, takes the first 
approach. This is also the approach taken by e.g. Lehtonen [14], who considers the special case of exponentially 
distributed processing times; that work left the case of general distributions which we handle here 
 as an open problem.   Preliminary Results and Examples For much of the paper, we will be discussing 
random vari­ables that are Bernoulli trials. We say that a random variable X is a Bernoulli trial oftype 
(g,s) if X takes the values with probability q and the value Owith probability 1 g. The load bahncing, 
bin-packing, and knapsack problems are all NP-complete even when al 1 items are deterministic (i.e. they 
assume a single value with probability 1). As men­tioned above, the introduction of stochastic items 
leads to new sources of intractability. Theorem 2.1 Given Bernoulli trials Xl, . . . . Xn, where Xi is 
of type (p;, s; ), it is #P-complete to compute Pr[~ X; > 1]. The use of effective bandwidth is a major 
component in the design of our approximation algorithms. We now give some examples to show that no direct 
use of effective bandwidth will suffice in order to obtain the approximation guarantees presented in 
later sections. These examples also provide intuition for some of the issues that arise in dealing with 
stochastic items. First we consider the load balancing problem. A natural approximation method one might 
consider here is Graham s Lowest-Fit algorithm applied to the expected values of the items. However, 
this fails to achieve a constant-factor ap­proximation. This is a consequence of the following much more 
general fact. Let -y be any function from random vari­ables to the non-negative real numbers. If Xl,,.., 
Xn are random variables, and # is an assignment of them tom bins, we say that ~ is ~-optimal if it minimizes 
the maximum sum of the ~-values of the items in any one bin. Theorem 2.2 For every function y as above, 
there exist xl,. ..,Xn and a -y-optimal assignment 4 of Xl, . . ., X­to m bins such that the load of@ 
is Q(log m/ log log m) times the optimum load. We now discuss a similar phenomenon in the case of bin­ 
packing. Let us say that a packing of items into bins is incompressible if merging any two of its bins 
results in an infeasible packing. For the problem of packing determinis­ tic items, a basic fact is that 
any incompressible packing is within a factor of 2 of optimal. In contrast, we can show the existence 
of a set of stochastic items that can be packed in only two bins, but for which there is an incompressible 
packing using Q(p-* ) bins. A consequence of this example is that no algorithm which simply looks at 
a single effective bandwidth number for each item can provide an approxi­mation ratio better than C?(p-~ 
). The Effective Bandwidth We Use. As discussed in the introduction, we will use both the standard definition 
of effective bandwidth /?P, and a new modified effective band­width @P that turns out to be necessary 
in the case of bin­packing, and is also used in proving our lower bounds on optimality for the load 
balancing problem. For a random variable X, one defines [10, 12] %(x) = log E~-x] ]Ogp-l  (1) For a 
Bernoulli trial X of type (q, s), we define its modified flective bandwidth by ~ p(X) = min{s, Sgp- }. 
(2) For a set of random variables R, we will use the notation /%(%) = ~x~z%(x)~ and~ ,(~) = &#38;~PJX). 
We first give an inequality relating our modified effective bandwidth to the standard one. The proof 
follows from ele­mentary calculus, Proposition 23 For a Bernoulli trial X, ~P(X) < ~ P(X). 3 Stochastic 
Load Balancing Letxl, x2,,.., X. be mutually independent random vari­ables taking non-negative real values. 
We shall refer to them as items. Let4 : {l,... jn} + {1,..., m}bea function assigning each item Xi to 
one of m bins. We define the load of the assignment ~, denoted ~(~), to be the expected maximum load 
on any bin; that is, C(4) = E [mu ~jE~_,(i) Xj ] . We are interested in designing ap­ proximation algorithms 
for the problem of minimizing L(4) over all possible assignments #. Note that the maximum of the expectations 
would be easy to approximate by simply load balancing the expwtations. 3.1 The Algorithm for On-Off Items 
In this subsection we present an 0(1)-approximation algo­rithm for the case of weighted Bernoulli trials; 
we then ex­tend this to handle arbitrary distributions in the following subsection. For a Bernoulli trial 
of type (p, s), we can fur­ther assume thats is a power of two by reducing all item sizes to the nearest 
power of two we lose on] y a factor of two in the approximation ratio. Our load-balancing algorithm is 
on-line. It proceeds through iterations; in each iteration it maintains a current es­timate of the optimum 
load, which will always be correct to within a constant factor. An iteration can end in one of two ways: 
the input can come to an end, or the iteration can ~ail. In the latter case, the estimate of the optimum 
is doubled, anda new iterationbegins. For ease of notation, the algorithm re-scales all modified sizes 
that it sees so that the estimate in the current iteration is always equal to 1. An item Xi of type (pi, 
Si) is said to be eweprimud if Si >1, and normal otherwise. Throughout the algorithm, we define p = m-1 
(recall that m is the num­ber of bins) and C to be an absolute constant. (C = 18 is sufficient.) One 
iteration proceeds as follows; suppose that item X; has just been presented. (1)For each bin ~, let Bj 
denote the set of all non­exceptional items from this iteration that have been as­signed to j. (2) If 
Xi is normal, then we assign it to the bin j with the smallest value of ~P (l?j ). If this would cause 
BP(13j ) to exceed C, then the iteration fails. (3) Suppose Xi is exceptional. If the total expected 
size of all exceptional items seen in this iteration (including Xi) exceeds 1, then the iteration fails. 
Otherwise, Xi is assigned to an arbitrary bin.  To prove that this algorithm provides a constant-factor 
ap­proximation, we show that (i) if an iteration does not fail, then the load of the resulting assignment 
is within a constant factor of the estimate for that iteration; and (ii) if iteration fails, then the 
load of any assignment must be at least a con­stant times the estimate for that iteration. We start with 
(ii). Lower Bounding the Optimal Solution. First we prove a lower bound on the optimal solution to the 
load bal­ancing problem. This lower bound is the main new technical contribution of this part, and will 
be used also in analyz­ing the bin-packing and knapsack algorithm in the next two sections. In this subsection 
we state and prove the lower bound for the special case of weighted Bernoulli trials. (In section 3.2 
we show how the general case follows from the special case.) Assume that Xl, X2, . . . . X~ are independent 
Bernoulli trials such that Xi is of type (pi, sa). We will sometimes say that itern Xi is on to refer 
to the event that xi = s~. We use the following basic claim repeatedly. Claim 3.1 Let 61 . . . . . &#38;k 
be independent events, with Pr[&#38;$] = pi. Let t? be the event that at least one of these events occurs. 
Let q <1 be a number such that ~i pi ~ q. Then Pr[&#38; ] ~ #q. Our key technical lower bound is in the 
following lemma, Hem p . [1),1] is a target probability (in this section we use p = m-l). Lemma 3.2 Let 
Xl,. ... Xn be Bernoulli trials of types (Pi, sl), . . ., (Pn, sn ), respectively, such that log-1 p-1 
~ Si < 1for each t, and each Si is an inverse power of 2. If z, ~ p(xi) > T,then Pr[~i Xi ~ 1]~ p. Proof 
Our goal is to modify the given set of Bernoulli trials so as to obtain a new problem in which (i) the 
probability of the sum exceeding 1 is no greater than originally, and (ii) the probability of the sum 
exceeding 1 is at least p. If there is any Xi for which @ P(Xi) = Si, we lower pi until pi = p s. This 
preserves the assumption that x,P p(xi)27. Let a be an inverse power of two, and consider the set w( 
) of items Xi for which Si = s. We partition W( ) into sets . . . . W( ) such that fordlj = 1,2, . . 
..r. W~s), ~, 1, 2P S ~~lx,~w~sj Ps < 3ps, and ~. ,Ix,ewj:) pi < 2P . This canbe done because pi < p 
for all Xi E W( ). We define a set V( ) of Bernoulli trials Y[ ),.. ., Y/~?l, each of VP (P , s). Intuitively, 
each ~( ) approximates well the ~­havior of ~x,E ~(.) xi. In particular, we show that the for­mer is 
stochasticd 1 y dominated by the latter. We will prove the following: (A) Pr[~, ~j ~ ) > 1] < Pr[~ixi 
z l]. (B)@p(u,V( )) >1. (C) Pr[z, ~j ~ G) > _ 112P The claim clearly follows from (A) and (C). To prove 
(A), we show that Pr ~xi~wf.) xi ~ s 2 [ 1 d)> s The expression on the left-hand side p =pr[~ -1 is 
simply the probability that any of the items in W~s) is on; by Claim 3.1, the fact that ~ x.Ewj~J Pi 
Z 2P , andthe fact that p < ~, this probability is at least p , and (A) follows. To prove (B), notice 
that ~ p( W~~)) < ZP SP- = % and for 1 s j < r,, ~ p(W~ )) s 3p sp- = 3s. On the other hand, @P(Y} )) 
= p sp- = s. Thus P P(V( )) ~ ~(E p(W( )) 2s). Hence    = @ p(t w-:~s >1, 8 s where the last inequality 
follows from the fact that ~, P ,(H +)) >7, and ~as ~ 2 because s only takes on the values of inverse 
powers of two. To prove (C), recall that for all j,s, @P(~(S)) = p Sp s = s. Now, let V denote a subset 
of Us V(s) con­sisting of items whose sizes sum to 1. That such a set ex­ists follows from (B) and the 
fact that all sizes are inverse powers of 2. Let {Y:, . . . . Y/} denote the items in V, and lets~, . 
. . ,s; denote their sizes, respectively, Note that the probability that Y/ is on is equal to p :. The 
probability of the event ~, ~j Y; ) z 1 is at least as large as the probability that all items in V are 
on. But this latter probability is equal to ~~=1 p ; = p. . The lower bound for exceptional items follows 
by an ar­gument using Claim 3.1. Lemma 3.3 Let X1, . . .. X~besuch that L~sl~. ~ sn and xi p~s; z L. 
Then for all ~, we have L(4) ~ ~L. Proofi Without loss of generality, we may assume xi pis~ = L. ~t 
qi = ~j >i pj. Gt t; denote the event that at least one item among {Xj }j>i is on, and let qj = Pr[Sa]. 
Note that because ~i pisi = L andSi~ Lforalli, wehave ~ipi <1 and hence qi ~ 1 for all i. Thus by Claim 
3.1, q: > +4;. Write so = Oand !L+l = O Observe that ~i pisi = xi qi(si si. ~), because each si is counted 
with a multiplier of pi on the right-hand side. Since Pr[Xi is on and not &#38;+l] ~ q: q~+l, we have 
E[max{Xl,. ... ~}12~ a(d-9\+l)=~ 9~(si si-1). i i Thus for any assignment ~ we have Our main lower bound 
for the load balancing problem is the following Lemma 3.4 Suppose that for all i, si is an inverse non­negative 
integral power of 2 (so si < 1).Further suppose that ~i/3 m_* (Xi) ~ 17rn. Then, for all ~, L(+) = Q(l). 
Proof Let#be anarbitraryassignmentof theitemsto bins. Let Bl, ..., Bm denote the sets of items assigned 
to bins 1,. ... m, respectively. Apply the following construction: as long as some set B: contains a 
subset S with ~ m-, (S) ~ 8, we put aside a minimal subset S with this property. Note that ~ m., (S) 
~ 9 as the bandwidth of a single item of size at most 1 never exceeds 1. When we can no longer find such 
a subset, then the set of remaining items R has P ~-1 (R) S fJm. Thus, this construction produces at 
least m subsets, such that each is assigned to a single bin by @. We denote the first m of these subsets 
by WI, . . . . Wm. Call a Bernoulli trial X of type (q,s) small if s < 1/ logp-1. Using the fact that 
small items have p-- ~ 2 we can see that the effective bandwidth @ P(X) of a small item is at most twice 
its expectation J3[X] = qs. Catl a set W~ dense if the set of small items S i ~ Wi has /? m_, (S1) ~ 
1. If there exists a dense set Wi, then the expected size of Wi is at least ~. Since t(~) is at least 
as large as the expected size of Wi, t(~) ~ ~ and the lemma follows. Thus, we consider the case in which 
no Wi is dense. Let W; ~ W~ denote the set of items in Wi which are not smatl. Since Wi is not dense, 
/3 m., (W:) >7. By Lemma 3.2, the probability that size of W; exceeds i is at least m-1. Hence the probability 
that some W/ exceeds 1 is at least 1 (1 -1 ~ >1 e-l Since L(4) z E[rnwc{lVl, . . . . w~}l> :e ,:mR 
follows-. Recall that the atgorithm maintains a current estimate. The iteration fails if the total effective 
bandwidth of the smatl and normal items in a bin would exceed a constant C (we use C = 18), or if the 
total expected size of all exceptional items seen in this iteration exceeds 1. Each of these cases implies 
a lower bound on the optimum: In the former case we use Lemma 3.4 and the fact that an item s size, and 
therefore its effective bandwidth, cannot exceed 1; in the latter case we use Lemma 3.3, Theorem 3.5 
L@ W denote the set of items presented to the algorithm in an iteration that fails. For any assignment 
4 of W to a set of m bins we have 1(4) = fl(l), where 1 is the estimate for the iteration. Upper Bounding 
the Solution Obtained. The fol­lowing proposition is essentially due to Hui [10] who stated itwitha = 
2and b= 1. We give a short proof for the sake of completeness. Proposition 3.6 (Hui) Let XI,.. .,X. be 
independent ran­dom variables, and X = ~i Xi. L.@a > b. ff~i ~ (Xi) < b,then Pr[X ~ a] < pa-b. proof 
Erst,if xi ~~(Xi) s b, then ~ log Ek-x ] S logp-b and hence Hi E~-xO] < p-b. l%us we have Pr[X > a]= 
Pr~-x z p- ] < p E~-x] = p ~i E~-x*] < p;-b, where the first inequality fol­lows from Markov s inequality, 
the equation from the inde­pendence of the Xi, and the last inequality from inequality above, . Lemma 
3.7 Consider the assignment produced by any iter­ation of the algorithm. The load of this assignment 
is 0(1). (Recall that sizes are scaled so that 1is the estimate for that iteration. ) Proof The expected 
size of the sum of exceptional items placed in this iteration is at most 1, so they only add at most 
1 to the expected maximum load. IA Sj = ~~,e~j Xi. Letz > 0. As ~P(13j) ~ C, Pr[Sj > z + C] ~ m-z by 
Proposition 3.6. Let S* = max{Sl, ..., Sin}. We have Pr[S* ~ y] s ~j Pr[Sj ~ y]. Hence m E[S] = ~mPr[5 
~ z]dz < C + 1+ Pr[5 ~ z]dz/ n-l-l n --, ­ cm = C+l+ Pr[S* ~ z + C]dz / 1 m < C+l+ m ~m- dz /1 = C +l+mA. 
C+o(l). from which the lemma follows. . Since the estimates increase geometrically, a consequence of 
Lemma 3.7 is Theorem 3.S Let $A be the assignment produced by the al­gorithm. Then C(4A ) = 0(1), where 
item sizes are scaled so that 1 is the estimate for the$nal iteration. Combining Theorem 3.8 and 3.5, 
we get our main result Theorem 3.9 The algorithm provides a constant-factor ap­proximation to the minimum 
load. 3.2 Extension to Arbitrary Distributions We may assume that the only values taken on by our ran­dom 
variables are powers of two. If not, other values are rounded down to a power of two. As in the previous 
section, this increases our approximation guarantee by a factor of 2 at most. Call a random variable 
that only takes values that are powers of 2 geometric. By the following claim we can reduce the problem 
for geometric items to the problem for Bernoulli trial items, which we have already solved. Lemma 3.10 
Let X be a geometric random variable. Then there exists a set of independent Bernoulli trials Y1, . . 
. . yk, with Y = ~a Yi,such that Pr[X = s] = Pr[s < Y < 2s]. The algorithm is essentially the same as 
before. It uses the standard definition of effective bandwidth (Equation 1), which applies to any distribution. 
The only change arises from the fact that we must define what we mean by excep­tional in this case. Each 
item Xi is now divided into an exceptional part Xi . I{x, > ~~ and a non-exceptional part Xi Iix,< 1}. 
When the expected total value of all excep­tional part: exceeds 1, the iteration fails; before this, 
excep­tional parts are (necessarily) just packed together with their non-exceptional parts. Theorem 3.11 
The algorithm provides a constant-factor approximation to the minimum load. Proof Recall that in the 
case of Bernoulli trials excep­tional items could be packed in any bin. The upper bound argument follows 
as before, using Proposition 3.6 for the non-exceptional parts of the items. The lower bound argument 
requires the approximation of each item by a sum of Bernoulli trials using Lemma 3.10. We replace each 
item Xi of a geometric random variable by the corresponding independent Bernoulli trials, and apply the 
lower bound of the previous subsection to the resulting set of Bernoulli trials. .  4 Bin Packing with 
Stochastic On-Off Items In this section we consider the bin packing problem with in­dependent weighted 
Bernoulli trials, which we will refer to as items . In addition we are given an allowed probability of 
overt-low p. The problem is to pack the items into as few bins of size 1 each as possible, so that in 
each bin the proba­bility that the total size of the items in the bin exceeds 1 is at most p. We assume 
throughout that p < ~; this is consistent with routing applications, where p is much smaller than this 
[4]. We develop approximation algorithms parametrized by a number t, O < 6 < ~. Our results show that 
a solu­tion whose value is within a factor of O(c 1) to optimal can be obtained if we relax either the 
bin size or the over­flow probability. That is, we compare the performance of our algorithm to the optimum 
for a slightly smaller bin size or overflow probability. Using these results we then give an approximation 
algorithm without relaxing either the bin-size or the ovetiow probability. Our algorithms will be on-line, 
as before. The basic outline of the method is as follows. As in the load balancing atgorithm, we will 
classify items according to their sizes. For the case with relaxed sizes and/or prob­abilities, an item 
will be small if si < 1/logs p-1, large if $i ~ ~e for the parameter c, and normal otherwise. We pack 
using the expectation for small items, using the effective bandwidth ~P (X) for normal items, and we 
develop tech­niques for paeking large items basect on our version of the effective bandwidth /.? P(X). 
It can in fact be shown that the standard definition of effective bandwidth is not adequate for obtaining 
a strong enough approximation ratio. For a large item of type (pi, Si), we effectively discretize its 
size, and work with its eflective size Sa; this is the recipro­cal of the minimum number of copies of 
weight si that will overtlow a bin of size 1: ii~l = min{j : j~i > 1}, Notice that iii < s; for all i, 
 An algorithm with relaxed bin-size and probability. We start by describing a simpler version of the 
algorithm in which we relax both the bin-size and the overRow prob­ability. Each bin will contain items 
only of the same type (smatl, normal, or large). Each item is assigned a weight, according to which it 
is packed. Bins of each type can be packed according to any on-line bin-packing heuristic, ap­plied to 
the weights; to be concrete, we will assume that the First Fit heuristic is being used. Small items are 
given a weight equal to their expectation. A bin with small items will be packed so that its total weight 
does not exceed ~. Each normal item X is assigned a weight of flP (x). A bin of ncnmal items will be 
packed so that its total weight does not exceed c. The set of large items can have at most J2c-11 different 
effective sizes. They are classified into groups by the follow­ing two criteria. (i) Each bin will only 
contain items of the same effective size. (ii) We say that a large item X; of type (pi, s;) and effec­tive 
size z has large probability if p; > p~ and normal probability otherwise. No bin will con~ln items of 
both large and normal probabilities.  We pack large probability items in bins so that fewer than ~ 
are in any bin. We pack normal probability items so that the sum of the probabilities of items in a bin 
does not exceed pg/Se where e % 2.7.. is the base of the naturat logarithm. We now argue that the algorithm 
yields a feasible packing in bins of size 1 +6. First we consider large items. If a bin contains items 
of effective size 3 = ~, then it will overflow if and only if at least k items are on. This implies that 
bins with large prob­ability items do not overfiow even if all items are on. Large items with normal 
probability are handled by the following lemma, which involves an analysis of our modified effective 
bandwidth. Lemma4.1 Let Xl, ..., Xn be independent Bernoulli tri­als, of types {(pi, si )}, and assume 
that the effective size ~i = 5and pi ~ pyfor all i. Let X = ~i Xi and assume that ~i pi < pJ/Se. Then 
Pr[X ~ 1] ~ p. Proofi We get overflow in a bin if and only if at least k items are on, where k = ~. LetZ 
denote the set of all items. For a set of items S ~ Z of size k, the probability that all items inS are 
on is ~i~s pi. Thus the probability of overtlow is at most (3) z np SgJ,lSld iES We claim that this 
formula is maximized, for a given sum of probabilities ~i pi, if all probabilities pi are all the same. 
To see this, suppose that we have two items Xi, Xj with dif­ferent probabilities, and consider modified 
items with prob­abilities p; = p; = ~ (pi +pj ). We now observe that the sum of probabilities has remained 
the same, but the probability of overflow is larger: the terms of Equation (3) that contain Oor 1 of 
the values pi, pj contribute in total the same as before, and terms containing both are each increased. 
Assume now that all items have the same probability g. The sum of the probabilities of items is at most 
pr/Se, hence the number of these items is at most p3/3qe. Now the prob­ability that k items are on is 
bounded by the inequality follows from the estimate ~) < (~)k. . The feasibility for smatl items follows 
easily from Cher­noff bounds. For the normal items, we apply Proposition 3.6 witha=l+candb=c. Theorem 
4.2 The on-line algorithmjinds a packing of items in bins with the property that for each bin, the probability 
that the total size of the items in that bin exceeds 1 + t is at most p. Note that large and small items 
are atso feasible with bin size 1; it is only the normal items that require the relaxed bin size. To 
prove the approximation ratio, we need to lower-bound the optimum. For small items, Chemoff bounds are 
suffi­ciency for normal items and large items of a given effective size we make use of a more careful 
analog of Lemma 3.2. Theorem 4.3 For a parameter e ~ ,og,lP_r, the above on­line algorithm$nds a packing 
of items in bins of size 1+ e such that the number of bim used is at most O (c-1) times the minimum possible 
number of bins in any packing with bin size 1 and overjiow probability at most pl+3 .  Algorithms with 
either relaxed bin-size or probability. In fact, we can obtain the same approximation ratios (up to a 
constant factor) by only relaxing either the bin size or the overflow probability, but not both. Since 
the relaxed guaran­tees were only needed for normal items, the idea is to slightly inflate or deflate 
the size of the normal items that we present to the above algorithm, and argue that we still do not lose 
too much in comparison to the optimum. The details are similar to those of the preceding algorithm, and 
we omit them in this version.  An algorithm without relaxing bin size or probability. In this section 
we use the results above to obtain an approx­imation algorithm without relaxing either the bin size or 
the capacity. In fact, our algorithm will simply be the on-line al­gorithm from the previous section, 
with c = ~. Thus, there will be no items classified as normal only small and large. One can give a weak 
analysis of this algorithm as follows: since the relaxed probabilities and sizes were only required for 
normal items, this algorithm produces a packing that is with O(e-l) = O(logp-l) times the optimum with 
bin size 1 and overflow probability p. Our goal in this section will to be give a more involved anal 
ysis of the same algorithm, showing that its performance is actually much better than this: it produces 
a packing with )13 + O(logp-l ) bins, where B* is the op­ o(~= timum number of bins required (with size 
1 and overflow probability p). The main step of the analysis is the following extension of Lemma 3.2. 
Lemma 4.4 Let e= $ ~. Ifxl, ....xk are inde­ r pendent Bernoulli trials of types (pl, 51), . . .. (pk, 
sk), e ~ si ~ 10g21p.f, and X$ @p(Xi) ~ 76 1, then Pr[~a X; > 1]> p. The proof relies heavily on our 
modified effective band­width, with a grouping scheme as in the proof of Lemma 3.2. However, we cannot 
afford to analyze the groups in each ef­fective size separately; thus we require a combinatorial ar­gument 
which analyzes the antichain of minimal collections of groups that would cause the bin to overflow. This 
lemma allows us to give a stronger analysis of our algorithm: although the algorithm only recognizes 
small and large items, our analysis further partitions the large items depending on whether their sizes 
are smaller or larger than For large items with sizes below t, we =$­apply Lemma 4.4. Theorem 4.5 The 
above algorithm finds a packing of items in bins of size 1 with oveflow probability p such that the number 
of bins used is at most 0( J-)B* + O(log p-l), where B* is the minimum possible number of bins. It is 
natural to ask whether this analysis can be further tightened to show that the same algorithm is in fact 
produc­ing a packing with O(B* ) + O(log p 1, bins. In fact this is not possible; this is contained in 
the following theorem. Theorem 4.6 There exist instances in which B* is arbi­trarily large, and the above 
algorithm uses more than B* . O(log log log logp-l) bins. The form of the final bound suggest that it 
is possible our analysis could be tightened further, albeit not to provide a constant ratio.  The Knapsack 
Problem Finally, we consider the knapsack problem. First we con­sider a simple version of the Knapsack 
problem with items Xl, Xz, ., ., Xn that are independent Bernoulli trials. Each item has a value vi, 
and we are given a knapsack size, say 1, and an allowed probability of overflow p. The problem is to 
find a set of items of maximum value such that the probabil­ity that the total size of the set exceeds 
1 is at most p. The lower bounds and techniques developed in the previ­ous section yield similar results 
also for the knapsack prob­lem. We distinguish items by their sizes (small, normal, and large), we group 
large items by their effective size, and we distinguish large and small probability items just as in 
the previous section. The solution we construct for the knap­sack problem only contains one type of item 
(either small, normal, or large with a given effective bandwidth). We will look for a near-optimal solution 
in each of these groups, and select the best alternative. Thus, we can show the following. Theorem 5.1 
Let Xl ,. ... Xn be independent Bernoulli tri­als. . There is a polynomial time algorithm that finds 
a solu­tion to the knapsack problem with items Xl, . . . . X~ of value at least an O(log p-1) fraction 
of the optimum. . For any c > t), there is a polynomial time algorithm that iinds a solution to the 
knatnack vroblem, usirw knau­sack size 1 + e and oveflow probability p, of value at least an O(c-1) fraction 
of the maximum possible with a knapsack of size 1 and overjlow probability p. . For any e > 0, there 
is a polynomial time algorithm that jinds a solution to the knapsack problem, using knapsack size 1 and 
overjiow probability p, of value at least an O(e-1) fraction of the maximum possible with a knapsack 
of size 1 and oveflow probability p~~c.  We can extend this theorem to the more general class of high-low 
items: Y is a high-low item if has the form a + X, where a is a non-negative real number and X is a weighted 
Bernoulli trial. By a greedy set-cover argument, this also gives us a (weaker) approximation for bin-packing 
with high-low items. 6 Extensions to General Networks The model we have been considering two nodes 
com­municating over a set of parallel links is a common one in the study of bursty traffic. However, 
it is interesting to consider the extent to which one can carry over the results developed here to the 
problem of routing bursty connections in a general network. The model for a general network fol­lows 
directly from the discussion in the introduction: we are given a graph G = (V, E) with capacities {cc} 
on the edges, and source-sink pairs (s*, ti)indicating connection requests in the network, For each source-sink 
pair, we are given a ran­dom variable Xi corresponding to the demand of that con­nection; a routing is 
a choice of a path Pi in G for each connection (Si, ti ). There are several options in how one might 
want to model the capacity constraints for a problem of this typq we de­fine two main possibilities here. 
Suppose we are given an allowed overtlow probability y p, (i) The link-based overjlow constraint requires 
that for each edge e, we have Pr[~i:e~p, Xi > c.] < P. (ii) The connection-based over@w constraint requires 
that for each connection (si, t$), we have  i:eEPt One can argue that from the perspective of providing 
guaranteed quality of service to users in a network, the connection-based oveflow constraint is more 
natural. In this section we use this model. Now suppose we are in a high-capacity setting in which the 
capacity of every edge exceeds the peak bandwidth rate of every connection Xi by a factor of c log(p-1Ill]) 
for an appropriate constant c. Let us define the value of aset of connections to be the sum of their 
expectation we consider the problem of accepting a set of connections of maximum value. We run the on-line 
algorithm of Awerbuch, Azar, and Plotkin [2], using E[X~] as the demand for connection (si, h) A *c. 
as the capacityof edgee. Theorem 6.1 The set of connections accepted by the above algorithm satisfies 
the connection-based overjZow con­straints, and the total value of the connections accepted is within 
an O(log lE\ ) factor of the off-line optimum on the graph G. Proof Whhout loss of generalit y, we may 
assume that the minimum edge capacity in the network is 1.Recall our as­sumption that the peak rate of 
any connection X is at most l/(c log(p-1IEI)); thus for each connection X, the effective bandwidth /3P111-I 
(X), with respect to probability A, is at most 2E[XJ Now Proposition 3.6 implies that our routing satisfies 
the link-based overflow constraint with probability fi, and hence the connection-based overtlow constraints 
with probability p. To compare our performance to that of the optimum, we argue as follows. Letting k 
denote the total value of con­nections accepted by our algorithm, the analysis of [2] can be used to 
show that there is a constant C for which the fol­lowing holds: in any routing of a set of connections 
of value at least C(log lEl)k, there is some edge e carrying a total expected vah.te greater than 8c~. 
Now, we give up a constant factor in the approximation ratio and use Lemma 3.10 to model each connection 
as a set of independent Bemoul Ii trials whose peak rates are inverse powers of two, as in Section 3.2. 
Using Chemoff bounds we can show that such a routing violates the link-baaed overtlow constraint on edge 
e, and hence any path through the edge e violates the connection-baaed overflow constraint. It follows 
that our routing is within O(log IEI) of optimal. . We note that the anatysis of [2] also allows us to 
provide performance guarantees in terms of more general notions of value.  References <RefA>[1] J. Aspnes, 
Y. Azar, A. Fiat, S. Plotkin and O. Waarta, On-line load Balancing with applications to machine scheduling 
and virtual circuit routing Proc. 25th ACM STOC, 1993. [2] B. Awerbuch, Y. Azar, S. Plotkin, Thnmghput<ompetitive 
online routing, Proc. 34th IEEE FOCS, 1993, pp. 32-40. [3] Y. Bartal, A. Fiat, H. Karloff, and R. Vorha. 
New Algorithms for an Ancient Scheduling Problem. Proc. 24th ACM STOC, 1992. [4] A. Elwalid and D. Mitra. 
Effective bandwidth of general Markovian traffic sources and admission control of high speed networks. 
IEEE Trans. Networking, 1(3):329-343, 1993. [5] R. Gawlick, C. Kalmanek, K.G. Ramakrishnan, On-line rout­ing 
for permanent virtual circuits: Proc. INFOCOM, 1995. [6] R. Gibbens, P. Hunt, Effective bandwidths for 
the multi-type UAS channel: Queueing Systems, 9(1991). [7] R.L. Graham. Bounds for certain multiprocessing 
anomalies. Bell System Tech. J., 45:1563-1581,1966. [8] R.L. Graham. Bounds on multiprocessing anomalies. 
SIAMJ. Appl. Math., 17(2):41ti29, 1969. [9] D.S. Hochbaum and D.B. Shmoys. Using dual approximation algorithms 
for scheduling problems: theoretical and practical results. J. Assoc. Comput. Mach., 34(1):144-162, 1987. 
[IO] J.Y. Hui, Resource allocation for broadband networlm IEEE J. Selected AreasinComm.,6(1988). [11] 
F.P. Kelly, Effective bandwidths at multi-class queues: Queueing Systems, 9(1991). [12] F,P.Kelly, Notes 
on effective bandwidths; in [13]. [13] F.P.Kelly, S. Zachary, LB. Zeidins, eds., Stochastic Networks: 
Theory and Applications, Oxford University Press, 1996. [14] T. Lehtonen. Scheduling jobs with exponential 
processing times on parallel machines. J. App. Prob., 25(1988), 752-762. [15] M. F inedo, Scheduling: 
Theo~, Algorithms and Systems. PrenticeHall, 1995. [16] S. Plotkin. Competitive Routing in ATM networks. 
IEEE J. Selected Areas in Communications, 1128-1136,1995. [17] P. Raghavan, C.D. Thompson, Randomized 
rounding: a technique for provably good algorithms and algorithmic proofs: Combinatorics, 7(1987), pp. 
365-374. [18] G. de Veciana and J. Walrand. Effective bandwidths: Call admission, traffic policing and 
filtering for ATM networks. Queueing Systems, 20:37-39,1995. [19] G. Weiss, Approximation results in 
parallel machines stochastic scheduling , Annals of Opemtions Research, 26(1990), Pp. 195-242. [201 G. 
Weiss, A Tutorial in Stochastic Scheduling: in Schedul­-ing Theory and Its Applications, P. Chretienne, 
E.G. Cofftnan, J.K. Lenstra, Z. Liu, eds., Wiley, 1995.</RefA>  
			
