
 (Almost) Optimal Coordination Mechanisms for Unrelated Machine Scheduling Yossi Azar * Kamal Jain Vahab 
Mirrokni Abstract We investigate the in.uence of di.erent algorithmic choices on the approximation ratio 
in sel.sh scheduling. Our goal is to design local policies that minimize the ine.ciency of resulting 
equilibria. In particular, we design optimal coordination mechanisms for unrelated machine scheduling, 
and improve the known approximation ratio from T(m)to T(log m), where m is the number of machines. A 
local policy for each machine orders the set of jobs assigned to it only based on parameters of those 
jobs. A strongly local policy only uses the processing time of jobs on the the same machine. We prove 
that the approximation ra­tio of any set of strongly local ordering policies in equilibria is at least 
O(m). In particular, it implies that the approxi­mation ratio of a greedy shortest-.rst algorithm for 
machine scheduling is at least O(m). This closes the gap between the known lower and upper bounds for 
this problem, and an­swers an open question raised by Ibarra and Kim [16], and Davis and Ja.e [10]. We 
then design a local ordering policy with the approximation ratio of T(log m) in equilibria, and prove 
that this policy is optimal among all local ordering policies. This policy orders the jobs in the non-decreasing 
order of their ine.ciency, i.e, the ratio between the pro­cessing time on that machine over the minimum 
processing time. Finally, we show that best responses of players for the ine.ciency-based policy may 
not converge to a pure Nash equilibrium, and present a T(log2 m) policy for which we can prove fast convergence 
of best responses to pure Nash equilibria. 1 Introduction In order to study the in.uence of algorithmic 
choices in the presence of sel.sh users, we need to study the ine.ciency of equilibrium points. The approximation 
ratio of a decentralized algorithm in lack of coordina­tion can be captured by the the worst case performance 
of a Nash equilibrium over a global social optimum, i.e., the price of anarchy [19]. A natural question 
is to design decentralized algorithms to reduce the price of anarchy for sel.sh users. In these algorithms, 
a central author­ity can only design protocols and de.ne rewarding rules and hope that the independent 
and sel.sh choices of the users -given the rules of the protocols-result in a socially * azar@tau.ac.il. 
Microsoft Research, Redmond and Tel-Aviv University, Tel-Aviv, 69978, Israel. Research supported in part 
by the Israel Science Foundation and by the German-Israeli Foundation. kamalj@microsoft.com. Microsoft 
Research, Redmond. mirrokni@microsoft.com. Microsoft Research, Redmond. desired outcome. To this end, 
di.erent approaches have been proposed such as imposing economic incentives in the form of monetary payments 
[5, 8, 13], and using the Stackelberg strategy [4, 18, 22, 25] which is enforcing strategies upon a fraction 
of users. The main disadvan­tage of these two strategies is that they assume global knowledge of the 
system and thus have high communi­cation complexity. In many settings, it is important to be able to 
compute mechanisms locally. A di.erent ap­proach, which is the focus of our paper, is called coordi­nation 
mechanisms, .rst introduced by Christodoulou, Koutsoupias and Nanavati [7]. A coordination mecha­nism 
is a local policy that assigns a cost to each strat­egy s,where thecost of s is a function of the users 
who have chosen s. Consider, for example, the sel.sh scheduling game in which there are n jobs owned 
by independent users, m machines and a processing time pij for job i on machine j. We concentrate on 
pure strategies case where each user selects one machine to assign his job. Each user is aware of the 
decisions made by other users and behaves sel.shly. Speci.cally, it wishes to minimize its completion 
time by assigning its job to the machine at which its job would complete .rst. The global objective however, 
is to minimize the make span -maximum completion time. A coordination mechanism [7] for this game is 
a set of local policies, one for each machine, that determines how to schedule jobs assigned to that 
machine. A machine s policy is a function only of the jobs assigned to that machine. This allows the 
policy to be implemented in a completely distributed and local fashion. We mainly study ordering policies. 
Ordering poli­cies characterize all deterministic non-preemptive poli­cies that satisfy the independence 
of irrelevant alterna­tives or IIA property1.We consider strongly local poli­cies in which the ordering 
of jobs on machine j only depends on the processing time of the set Sj of jobs on machine j,and local 
policies in which the ordering for machine j depends on all parameters of jobs in Sj .Two 1For the de.nition 
of non-preemptive policies and the IIA property, see Section 2.  examples of the strongly local ordering 
policies are the ShortestFirst and LongestFirst policies in which we order the jobs in non-decreasing 
and non-increasing order of their processing times, respectively. Several local policies have been studied 
for machine scheduling problems, both in the context of greedy or local search algorithms for machine 
scheduling [16, 12, 23, 10, 1, 3, 6, 26], and also in the context of coordination mechanisms [19, 9, 
7, 17]. Ibarra and Kim [16] present a greedy shortest-.rst algorithm and proved an upper bound of m for 
its approximation factor. It has been shown that the output of this greedy algorithm is equivalent to 
the pure Nash equilibria of the ShortestFirst policy in sel.sh scheduling [17]. An O(log m) lower bound 
has been proved for the approximation factor of this algorithm [10]. Our Results. In Section 3, we show 
that any set of strongly local ordering policies results in the price of anarchy of O(m). This result 
implies that the ShortestFirst policy has the price of anarchy of T(m). Moreover, this bound closes the 
gap between the known lower and upper bounds of the approximation ratio of the shortest-.rst greedy algorithm 
(i.e., Algorithm D by Ibarra and Kim [16]) and answers an open question originally raised in 1977 [16, 
10, 17]. In Section 4, we design a local ordering policy for which the price of anarchy is T(log m). 
Speci.cally, on each machine, we order the jobs by in the non­decreasing order of their ine.ciency, i.e., 
the ratio of the job s processing time on this machine to its fastest processing time. Also we show that 
any deterministic non-preemptive set of local policies satisfying the IIA property results in the price 
of anarchy of O(log m). In particular, it shows that the ine.ciency-based policy is almost optimal among 
local ordering policies. In Section 6, we study existence of pure Nash equilibria for ordering policies 
and prove convergence to pure Nash equilibria for some special cases. The main result of this section 
is that pure Nash equilibria may not exist for the ine.ciency-based policy and the best responses of 
players may not converge to it. Finally, in Section 7, we design a local policy for which the best­response 
dynamics of players converges to a pure Nash equilibrium in polynomial time and the price of anarchy 
is T(log2 m). Related work. Coordination mechanisms are re­lated to local search algorithms. Starting 
from a so­lution, a local search algorithm iteratively moves to a neighbor solution which improves the 
global objective. This is based on a neighborhood relation that is de­.ned on the set of solutions. The 
local improvement moves in the local search algorithm correspond to the best-response moves of users 
in the game de.ned by the coordination mechanism. The speed of convergence and the approximation factor 
of local search algorithms for scheduling problems have been studied in several pa­pers [10, 11, 12, 
16, 23, 24, 26, 1, 3]. Vredeveld sur­veyed some of the results on local search algorithms for scheduling 
problems in his thesis [26]. Here, we note that the invariant that we use in the proof of the O(log m) 
upper bound for the unrelated machines seems similar to the invariant proved in [3] for the online al­gorithm 
for the restricted assignment model. However, for the unrelated machine we cannot use volume preser­vation 
as in the restricted assignment model (i.e., the total size jobs on machines depends on the assignment). 
Moreover, in the restricted assignment model the e.­ciency of all jobs are 1 where in the unrelated machines 
model they vary. Interestingly, the proof of the online algorithm for unrelated machines [1] is based 
on a dif­ferent technique (and not on this type of invariant). Ibarra and Kim [16] analyzed several greedy 
algo­rithms for unrelated machine scheduling. In particular, they proved that the shortest-.rst greedy 
algorithm is an m-approximation for the maximum completion time. Davis and Ja.e [10] showed that the 
approximation fac­tor of this greedy algorithm is at least log m.The best known approximation factor 
is given by a central 2­approximation algorithm due to Lenstra, Shmoys and Tardos [20]. A widely studied 
scheduling policy is the Makespan policy in which we process all jobs on the same machine in parallel 
so that the completion time of a job on machine j is the makespan of machine j. The price of anarchy 
of this policy is unbounded even for two machines. Tight price of anarchy results for (mixed) Nash equilibria 
are known for this policy for special cases of the unrelated scheduling problem [9, 2, 14, 19]. Coordination 
mechanism design was introduced by Christodoulou, Koutsoupias and Nanavati [7]. In their paper, they 
analyzed the LongestFirst policy for P||Cmax and also studied a sel.sh routing game. Immorlica, Li, Mirrokni, 
and Schulz [17] study four coordination mech­anisms for four types of machine scheduling problems and 
survey the results for these problems. They further study the speed of convergence to equilibria and 
exis­tence of pure Nash equilibria for the ShortestFirst and LongestFirst policies. 2 Preliminaries The 
unrelated machine scheduling problem or R||Cmax is de.ned as follows: there are m machines and n users, 
where user i(i=1,...,n) has a job that can be assigned to any machine. Job ifor i=1,...,nis associated 
with an m-vector p.i,where pij indicates the processing time of job i if assigned to machine j.  Given 
an instance of the R||Cmax problem, we de.ne the global optimum (denote it by OPT)to be the assignment 
of jobs to machines that minimizes the makespan, i.e., the maximum completion time. We slightly abuse 
the notation and use OPT to denote also the value of the optimal solution. The goal is to .nd a schedule 
which minimizes the total makespan. In sel.sh scheduling, eachjob is ownedbyaninde­pendent user whose 
goal is to minimize the completion time of his job. In order to make the sel.sh users to take globally 
near-optimal actions, we can de.ne the follow­ing notion of coordination mechanism [7]. A coordina­tion 
mechanism is a set of local scheduling policies,one for each machine. A scheduling policy Pj for a machine 
j maps any set S of jobs on machine j to a schedule of all jobs in S. The policy is run locally at a 
machine, and so does not have access to information regarding the global state of the system, for example 
the set of jobs scheduled on other machines. As a result, for any policy Pj and a set of jobs S for machine 
j, each job i. S is mapped to a completion time Pj (S,i). A scheduling policy Pj is strongly local if 
it only looks at the processing time of jobs in Sj on machine j and assign each job i. Sj a completion 
time. A strongly local policy Pj may have an arbitrary tie-breaking rule for jobs of the same processing 
time. In order to formally de.ne the tie-breaking rules, we assume that each job has a unique ID and 
a local policy s tie breaking rule is a function of the set of IDs of jobs. A local policy looks at all 
parameters of jobs assigned to machine j and assigns each job i . Sj a completion time . Note that a 
local policy that is not strongly local may use the processing times of the jobs of Sj on other machines, 
but it does not have any information about other jobs that are not assigned to this machine. A policy 
is a non-preemptive policy if it processes each job in an un-interrupted fashion without any delay. A 
policy is a preemptive policy if it can interrupt jobs during the scheduling and can put some delay on 
the machine. We say that a policy satis.es the independence of irrelevant alternatives or IIA property 
if for any set S of jobs and any two jobs i,if . S,if i has a smaller completion time than if in S,then 
i should have a smaller completion time than if in any set S .{k}.In other words, whether i or if is 
preferred should not be changed by the availability of a job k. The IIA property appears as an axiom 
in voting theory, bargaining theory, and logic [27]. A scheduling policy is an ordering policy if for 
each instance of the scheduling problem, it orders the jobs non-preemptively based on a global ordering. 
It is not hard to show that any deterministic non-preemptive policy that satis.es the IIA property is 
an ordering policy. The ShortestFirst and LongestFirst policies are ordering policies in which we order 
the jobs in non­decreasing and non-increasing order of their processing times, respectively. Note that 
the ShortestFirst and LongestFirst may have arbitrary tie-breaking rules based on the IDs of jobs. A 
special class of the R||Cmax problem is the ma­chine scheduling for restricted assignment (B||Cmax)in 
whicheachjob i can be scheduled on a subset Ti of ma­chines, i.e., pij is equal to pi if j . Ti and is 
equal to 8 otherwise. 3 A Lower Bound for Strongly Local Policies In this section, we show that the approximation 
ratio of any set of strongly local ordering policies is O(m). In the next section, we present a local 
ordering policy that achieves the factor O(log m) and will prove a matching lower bound for local policies. 
Theorem 3.1. The price of anarchy for any set of de­terministic non-preemptive strongly local policies 
satis­fying the IIA property is at least O(m). Proof. We observe that any deterministic non­preemptive 
policy satisfying the IIA property is an ordering policy. As a result, we show that for any strongly 
local ordering policy, the price of anarchy is 2(m-1)! at least O(m). Let nj = for 1 = j = m and (j-1)! 
m n= j=1 nj . Consider the set of m machines and a set P1,...,Pm of strongly local ordering policies 
on these m machines. Given this set of policies, we construct an instance of n jobs for which the price 
of anarchy is O(m). Since the policy Pj is a strongly local ordering policy, it only looks at the processing 
time of jobs on machine j and their IDs. As a result, if the processing (j-1)! time of all jobs on machine 
j is equal to , Pj (m-1)! orders the jobs based on a global ordering of IDs. Let sj be this ordering 
on the IDs of jobs. We construct an instance in which all jobs that can be scheduled (j-1)! on machine 
j has the same processing time . (m-1)! We de.ne a family of subsets S1,...,Sm such that |Sj | = nj for 
1 = j = m.Jobs in Sj can be scheduled only on machines j and j +1 for 1 = j = m (jobs in Sm can only 
go to machine m). The processing time of (j-1)! 2 all jobs on machine j is =. (m-1)! nj In order to de.ne 
Sj s, we use the following nota­tion. Given any ordering s on the IDs of n jobs, a set T .{1,...,n} of 
IDs of jobs, and a number k,let sk(T) be the set of .rst k IDs in ordering s that are in set T. In particular, 
sk({1,2,...,n})is the setof.rst k IDs in .j an ordering s.Also, for 1 = j = m,let wj = nt. t=1 Now, we 
are ready to de.ne Sj s as a function of all job orderings sl by all machines 1 = l = m as follows: Let 
 Mm+1 := {1,2,...,n}. Then, for each j (m= j = 1), we have wj-1 Mj := sj (Mj+1), and Sj := Mj+1\Mj. 
We claim that the price of anarchy of this instance is m . An optimal solution of this instance schedules 
jobs of set Sj on machine j for 1 = j = m.The makespan 2 of this schedule is nj = 2. We prove the following 
nj Lemma on this instance. Lemma 3.1. In any pure Nash equilibrium of this in­stance, the makespan of 
machine j is equal to j for any j from 1 to m. In particular, half of the jobs of Sj are scheduled on 
machine j and half of them are scheduled on machine j+1 for any j from 1 to m- 1. Proof. By the construction 
of Sj (1 = j = m), policy Pj puts all jobs of Sj after all jobs of Sj-1 on machine j, since all jobs 
of Mj go before all jobs of Sj on machine j and Sj-1 . Mj . We prove the lemma by induction on j. For 
the base of the induction, de.ne S0 as an empty set and machine 0 as a dummy machine. For the induction 
hypothesis, assume that for k = j- 1, in any pure Nash equilibrium, half of the jobs of Sk are scheduled 
on machine k and half of them are scheduled on machine k + 1. As a result, the load of machine k for 
k = j - 1isexactly k, and the load of machine j nj-1 2 from jobs in Sj-1 is 2 nj = j - 1. We prove that 
in any pure Nash equilibrium, half of jobs of Sj go to machine j and half of them go to machine j +1. 
We prove the induction step by contradiction. If in a pure Nash equilibrium, less than half of the jobs 
in Sj are at machine j+1, then the completion time of the last job q 2 of Sj on machine j is strictly 
more than j-1+ n2 j nj = j, since all jobs of Sj-1 will be scheduled before all jobs of Sj on machine 
j. Since only jobs in Sj and Sj+1 can be scheduled on machine j+1 and q . Sj will be scheduled before 
any job Sj+1,if q moves to machine j +1, its nj 2 completion time is at most = j. Therefore, q 2 nj+1 
has incentive to switch to machine j+ 1. In addition, if in a pure Nash equilibrium, more than half of 
the jobs in Sj are scheduled on machine j+ 1, then the completion time of the last job is more than j 
on machine j +1 and this job can move to machine j and improve its completion time. This proves the induction 
step. The above lemma proves that in any pure Nash equilib­rium the makespan of machine m is m, and therefore, 
the price of anarchy for this instance is at least m .This 2 completes the proof of the theorem. Since 
the ShortestFirst policy is a strongly local pol­icy, the above theorem implies that the price of anar­ 
m chy of the ShortestFirst policy is at least . Immorlica 2 et.al. [17] observed that the set of pure 
Nash equilib­ria of the ShortestFirst policy is equivalent to the out­put of the shortest-.rst greedy 
algorithm of Ibarra and Kim [16]. Therefore, the above lower bound implies m the lower bound of for the 
shortest-.rst greedy algo­ 2 rithm, and answers an open question raised by Ibarra and Kim [16], and Davis 
and Ja.e [10]. As a result, we have the following theorem: Theorem 3.2. The price of anarchy of the m 
ShortestFirst policy is at least .In particular, it 2 implies that the approximation factor of m proved 
by Ibarra and Kim [16] for the shortest-.rst greedy algorithm is almost tight. It is worth mentioning 
that the proof of Theorem 3.1 uses jobs of the same size and argue about tie breaking rules. For the 
ShortestFirst policy, we can actually perturb the example such that all jobs have di.erent sizes, and 
hence the shortest-.rst algorithm is uniquely de.ne. A proof of Theorem 3.2 without jobs of the same 
size is given in the appendix. 4 A Logarithmic Upper Bound In this section, we give a deterministic non-preemptive 
local policy with the IIA property for which the price of anarchy is T(log m). Recall that in the unrelated 
links model, a job i is associated with an m-vector pi =(pi1,...,pim) specifying its processing time 
on each machine. Denote by pi =minj pij which is the fastest processing time of that job on any of the 
machines. The ine.ciency of job i on machine j is eij = pij /pi.By de.nition eij = 1 for all iand j.The 
min-weight of a set S of jobs is equal to i.S pi. Also, let W = pi. 1=i=n The ine.ciency-based policy 
for machine j orders the jobs assigned to it in the non-decreasing order of their ine.ciency eij . Theorem 
4.1. The price of anarchy for R||Cmax for the ine.ciency-based policy is at most 2log m+4. Proof. Given 
this ordering strategy for each machine and a pure Nash equilibrium, we partition the assign­ment into 
layers. For any k = 0, we denote by Mkj all jobs (and parts of jobs) that are processed on ma­chine j 
after time 2kOPT.Let Mk be the union over all machines j of Mkj , i.e., Mk = .1=j=mMkj . Let Rkj denote 
the min-weight of jobs in Mkj , i.e., Rkj = pi. Speci.cally if job i is partially i.Mkj processed on 
machine j for x units of time after time  2kOPT, then its contribution to Rkj is x/eij = xpi/pij. Let 
Rk = Rkj which is the min-weight of 1=j=m jobs processed after time 2kOPT.Note that R0 = W since it is 
the total min-weight of all jobs. Our main lemma is the following: Lemma 4.1. For all k = 1, Rk = 1 · 
Rk-1. 2 Proof. Let Oj be the set of jobs processed on machine j by OPT .Let Okj be the intersection of 
Oj and Mk. Let fkj be the minimum ine.ciency of all jobs in Okj in the equilibrium assignment. Each job 
in Okj could switch to machine j.If Okj is not empty, then in the equilibrium assignment, machine j is 
processing jobs of ine.ciency of at most of fkj up to time (2k - 1)OPT otherwise the job with the minimum 
ine.ciency in Okj would move to machine j and complete by time (2k - 1)OPT + OPT =2kOPT. Hence, machine 
j processes jobs of ine.ciency at most fkj between times (2k - 2)OPT and (2k - 1)OPT which implies that 
Rk-1,j - Rkj = OPT/fkj . On the other hand, all jobs in Okj are processed by OPT on machine j with ine.ciency 
of at least fkj and hence their total min-weight is at most OPT/fkj.By combining the last two inequalities, 
we conclude that Rk-1,j - Rkj is at least the min-weight of jobs in Okj . Summing up over all j,we get 
that Rk-1 - Rk = Rk, since Mk is the union of Okj over all machines j.We conclude that Rk-1 = 2Rk as 
required. We are now ready to complete the proof of the Theorem. By applying the main lemma, b = plog 
ml times we get that 1 W Rb =· R0 = = OPT . mm In particular, this implies that the total processing 
time of jobs of ine.ciency 1 in Mb is at most OPT. Hence each such job ends by time (2b)OPT + OPT =(2b 
+ 1)OPT. Consider a job that has not been completed by time 2bOPT. Such job has an option to run on a 
machine of ine.ciency of 1. In that case it would start no later than (2b +1)OPT and would .nish no later 
than (2b+1)OPT +OPT =(2b+2)OPT (since its min­weight is at most OPT ). Since the assignment is a Nash 
equilibrium, we conclude that the maximum completion of any job is at most (2b +2)OPT = (2 log m +4)OPT 
as needed. Remark 1. The above proof can be extended to bound the price of anarchy for mixed Nash equilibria 
of the ine.ciency-based policy. We can prove a lemma for mixed strategies similar to Theorem 4.1 with 
the bound of O(log m). Then using the Hoe.ding inequality and the framework developed by Czumaj and Vocking 
[9] (and also used by Awerbuch et. al. [2]), we can prove that the price of anarchy for mixed Nash equilibria 
for this policy is T(log m). 5 A Lower Bound for Local Policies In Section 3, we proved that the price 
of anarchy for any strongly local ordering set of policies is at least O(m). Here, we show that the price 
of anarchy for any set of local ordering policies is at least O(log m). As a warm­up example, we show 
that our analysis is almost tight for the ine.ciency-based policy. Theorem 5.1. The price of anarchy 
for R||Cmax when the ordering strategy is by non-decreasing ine.ciency is at least log m. Proof. We use 
a standard example to show that even for the restricted assignment model (B||Cmax) the price of anarchy 
of this strategy is at least log m. Not that for B||Cmax the ine.ciency of every job is precisely 1 on 
any legal machine for that job. Hence the algorithm may order the jobs on each machine in any order. 
In this proof, we assume a global tie breaking rule on the order of all jobs. Without loss of generality 
a job with a lower index has a higher priority (otherwise we can rename the jobs). In the example, there 
are m =2q machines and m - 1 jobs. All jobs have unit size. Each job can be assigned to two machines. 
The jobs are partitioned into log m groups. For 1 = k = q,there are m/2k jobs in group k.Job l of group 
k for 1 = l = m/2k can be assigned to machines l and m/2k + l.The optimal algorithm can assign that job 
to machine m/2k + l and get a makespan of 1. We claim that if this job is assigned to machine l, it is 
a Nash equilibrium and results in a makespan of log m (machine 1 has log m completion time). It is easy 
to verify that all jobs in group k have a completion time of k and if they would move to the other option 
they would still have a completion time of k. Hence this assignment is a Nash Equilibrium which completes 
the proof. Now, we use the structure of the standard example in Theorem 5.1 to prove the following general 
lower bound: Theorem 5.2. The price of anarchy for all determinis­tic non-preemptive local policies satisfying 
the IIA prop­erty for R||Cmax is at least O(log m). Proof. Without loss of generality, we assume that 
m = 2q. We recall that deterministic non-preemptive local policies satisfying the IIA property correspond 
to order­ing the jobs in a certain order according to all parame­ters of the jobs assigned to that machine. 
That means that the order depends on the IDs of jobs and their full vector of processing times on all 
machines. Given a set of local ordering policies, we construct an instance sim­ilar to the example used 
in Theorem 5.1. We start with  m -m 2jobs from which exactly m - 1jobs are used in 2 the .nal instance. 
In particular, all jobs are of unit size and can be assigned to precisely two machines. More­over, the 
ID of a possible job that can be assigned to machine j and machine jf is unique (say it is mj + jf). 
If we restrict ourselves only to these types of jobs, then there are at most m-1 jobs that can be assigned 
to each machine j. Speci.cally, these jobs can be described as (j, jf) for all j = jf, since all remaining 
parameters (i.e. ID and the full load vector) are exact functions of the pair (j, jf). A local policy 
of each machine j for any 1 = j = m corresponds to an ordering of these jobs to be processed on machine 
j.Let sj be this ordering. Let A0 = {1,...,m} and J0 = Ø.For k from 1 to log m,we construct Ak and Jk 
from Ak-1 as follows: .rst, let Ak = Ø,and Jk = Ø. Weperform thefollowing m process times: Choose an 
arbitrary machine j from 2k Ak-1 . Find the job of the highest priority to run on machine j among all 
jobs (j, jf)where jf . Ak-1,and denote its ID by (j, mk(j)), i.e., (j, mk(j)) is the .rst job in sj among 
jobs (j, jf) . Ak-1 × Ak-1 . Then, let Ak = Ak .{j} and Jk = Jk .{(j, mk(j))}. Also, let Ak-1 = Ak-1\{j, 
mk(j)}. At the end of the process, mm Ak-1 becomes empty, Ak has indices, and Jk has 2k 2k jobs. The 
set of jobs for the .nal instance is the union of the jobs Jk for 1 = k = log m, i.e., .1=k=log mJk . 
Hencewehave m-1 jobs in the resulting instance. The following solution of makespan 1 is the optimal solution: 
assign job (j, mk(j)) . Jk to machine mk(j). Consider an assignment A in which each job (j, mk(j)) . 
Jk is assigned to machine j. We prove that this assignment is a pure Nash equilibrium. Using induction 
on k, we prove that for each k from 1to log m, in assignment A, each job (j, mk(j)) . Jk is completed 
exactly at time k on machine j.Moreover, if it switches to machine mk(j), its completion time is not 
less than k. For the base of induction, job (j, m1(j)) . J1 has more priority than all jobs (j, mk' (j)) 
. Jk' for 2 = kf = log m, and hence, its completion time is 1. Also, this job would not want to switch 
to machine m1(j). The proof of the induction step is similar to the base case and follow from the fact 
that by the construction of Jk, each job (j, mk(j)) . Jk has more Jk' kf priority than job (j, mk' (j)) 
. for any k< . This inductive argument proves that assignment A is Table 1: An example without pure Nash 
equilibria: The processing time of four jobs on four machines. 1 2 3 4 A 20 8 8 8 B 2 12 8 1.98 C 4 24 
25 3.95 D 5 28 8 4.9 a pure Nash equilibrium, and its makespan is log m. . Alog m Speci.cally, machine 
j* has makespan log m, since one job from each of J1,J2,...,Jlog m is scheduled on this machine. This 
instance shows that for any set of local ordering policies, there is an instance for which the price 
of anarchy is at least O(log m). 6 Existence of Pure Nash Equilibria Pure Nash equilibria may not exist 
for some strategic games, and even if they exist, a sequence of best re­sponses of players may not converge 
to them. Poten­tial games are games for which we can .nd a potential function that maps any state (or 
any set of strategies) in the game to a number (or a vector) such that after any best response of any 
player the value of the func­tion strictly decreases (or lexicographically decreases). Potential games 
possess pure Nash equilibria and any random sequence of best responses of players converge to pure Nash 
equilibria with probability one. We can prove the corresponding game of any or­dering policy for B||Cmax 
is a potential game and thus, possess pure Nash equilibria, but this is not the case for R||Cmax even 
for two machines. Moreover, we can prove that the game corresponding to the ine.ciency-based policy for 
two machines always possess pure Nash equi­libria, but this is not true for any number of machines. Here, 
we only prove the main result of this section, and leave the rest of them to the appendix. Theorem 6.1. 
The corresponding game to ine.ciency-based policy for R||Cmax may not pos­sess any pure Nash equilibrium. 
Proof. Consider an instance of R||Cmax with 4 machines and 5 jobs A, B, C, D, and T .Job T can only be 
scheduled on machine 4 and its processing time is 50. The ordering on machine 4 is T, B, C, D, A.The 
processing times of jobs A, B, C, D on machines 1, 2, 3, 4 are depicted in Table 1. As a result, the 
ordering of jobs in the ine.ciency­based policy for machine 1 is (A, B, C, D, T ), and for machine 2 
is (D, B, C, A, T ), and for machine 3 is (C,A,B,D,T). We claim that no pure Nash equilib­ria exist for 
this example. We have found this ex­ample by solving a mathematical program that cap­tures the inequalities 
required to prove that no pure Nash equilibrium exists. Here, we give a brief de­scription of why this 
instance does not have any pure Nash equilibrium. Job T is always scheduled on ma­chine 4 and no other 
job wants to go to machine 4. We can show a schedule on four machines as a se­quence of subsets of jobs 
in each machine, for exam­ple, if jobs A,B, and C are on machine 1, job D is on machine 2, and job T 
is on machine 4, the corre­sponding sequence is (ABC,D, ,T). From this sched­ule, job C has incentive 
to switch to machine 3, and the resulting schedule is (AB,D,C,T). This move is shown brie.y by (ABC,D, 
,T) . (AB,D,C,T). Similarly, (ABD, ,C,T) . (ABD,C, ,T) . (AD,BC, ,T) . (ACD,B, ,T) . (AD,DB, ,T) . (ABC,D, 
,T) . (AB,D,C,T) . (ABD, ,C,T). Also (AD,B,C,T) . (ACD,B, ,T). Checking that no other pure Nash equi­librium 
exists is straightforward.  This theorem indicates the need for a coordination mechanism with small 
price of anarchy for which we can prove convergence to pure Nash equilibria. 7 A Polylogarithmic Upper 
Bound with Fast Convergence In Section 4, we designed a scheduling policy for each machine that has a 
low price of anarchy. However, in Section 6, we proved there may be no (pure) Nash Equilibrium for the 
jobs and the system may not con­verge. In this section, we show that we can in­crease slightly the price 
of anarchy from O(log m)to O(log2 m), but guarantee existence of Nash Equilibria as well as convergence 
to pure Nash equilibria. The algorithm is as follows. Each machine simulates b = plog ml sub-machines. 
Sub-machine l for 0 = l = b-1 of machine j runs only jobs of ine.ciency of at least 2l andless than2l+1 
. Machine j allocates continuously the same time for each of its sub-machines even if jobs to mb sub-machines 
as follows: if in the original instance job i has processing time pij ,then it would have processing 
time bpij on sub-machines lj of machine j where lj = leij J given that eij <m. On all other sub­machines 
of j (in case eij = m on all sub-machines of j) the processing time is in.nite. We start with the following 
lemma Lemma 7.1. Given an instance to the R||Cmax problem and its corresponding instance on mb sub-machines. 
1. Given an assignment for the original instance on the m machines, we can get an assignment for the 
corresponding instance on the mb sub-machines while increasing the makespan by a factor of at most 2b. 
In particular, the optimal makespan increases by a factor of at most 2b. 2. Given an assignment for 
the corresponding instance on the mb sub-machines, we can get an assignment for the original instance 
where the completion time of each job remains the same (and in particular the makespan does not increase). 
 Proof. The second part of the lemma is easy. Each machine simulates the b sub-machines continuously 
and provides 1/b of the time for each. Since the processing time of each job in the corresponding instance 
is btimes its original processing time then the completion time of each job remains the same as needed. 
Next, we prove the .rst part of the lemma. Given the an assignment to the original instance we create 
a feasible assignment to the new instance with increase in makespan by factor of at most 2b.We do it 
in two steps. In the .rst step we create a new assignment for the original instance where no job i runs 
on machine j with eij = m. This will (at most) double double the makespan. We do it by simply moving 
each job i that runs on machine j with eij = m to the best machine for that job, i.e., to machine jf 
where eij' =1. Let I be the set of such jobs. Clearly the makespan has increased additively by at most 
i.I pi (even if all these jobs were to go on the same machine). However i.I pij =i.I mpi. Hence the original 
makespan was at least there are no jobs to process on some sub-machines (this requires preemption and 
idle time). A job assigned to machine j will run on sub-machine l of machine j where l = <m.If = m,the 
job 1 leij J given that pij = 1 mmpi = eij eij pi will be delayed for ever on machine j. To complete 
the m i.Ii.Ii.I description of the processing strategy, we need to de.ne the order in which each sub-machine 
processes its jobs. If it is an arbitrary order, we call the family of strategies Split &#38; Any. If 
it is ordered according to ShortestFirst we call it Split &#38; Shortest. Given an instance of the R||Cmax 
problem on m machines, we create a corresponding instance of those which means that the makespan at most 
doubled. In the second step, we create from the modi.ed assignment an assignment for the sub-machines 
instance by increasing the makespan by a multiplicative factor of b. This is easily done by assigning 
job i that is assigned to machine j to the sub-machine l = leij J of machine j which is feasible and 
always exists since eij <m. The load of each sub-machine of machine j does not increase since the jobs 
were split among the sub-machines. However, since the processing time is multiplied by b, the completion 
time is scaled up by afactorof b. Hence, after applying the two steps the makespan for the corresponding 
instance is increased by at most 2b as required.   Now, we can easily prove the following: Theorem 
7.1. The price of anarchy for R||Cmax using Split &#38; Any is O(log2 m). In particular, the price of 
anarchy for unrelated machines using Split &#38; Shortest is O(log2 m). Proof. We can view Split &#38; 
Any for the original instance as processing the jobs on the corresponding instance in almost non-decreasing 
order of the ine.ciency. All jobs on each sub-machine have almost the same (i.e. up to factor of 2) ine.ciency. 
If we change the size of jobs to have precisely the same ine.ciency then by using Theorem 5.1 the price 
of anarchy is at most O(log m) with respect to the optimal assignment for the corre­sponding instance 
(with the original size we lose only additional factor of 2). Nevertheless, the makespan of the optimal 
assignment for the corresponding instance is at most O(log m) times the the makespan of the optimal assignment 
of the original instance. Hence the price of anarchy of Split &#38; Any is O(log2 m) with respect to 
its optimum. Since, Split &#38; Shortest belongs to the family of Split &#38; Any its price of anarchy 
is not larger. Now, we show that our analysis is tight. Theorem 7.2. The price of anarchy for R||Cmax 
using Split &#38; Shortest is at least log2 m. Proof. We use again a variation on the standard ex­ample 
from Theorem 5.1 to show that even for the re­stricted assignment model (B||Cmax) the price of anar­chyof 
this strategyis at least log2 m. Note again that for B||Cmax, the ine.ciency of every job is precisely 
1 on any legal machine for that job. Hence, only the .rst sub­machine of each machine is doing any work. 
We use the example from Theorem 5.1 but we slightly perturb the job sizes. All jobs are of processing 
time slightly smaller than 1 where all jobs in class k are slightly shorter than all jobs in class k 
+ 1. Hence the algorithm may order the jobs on each machine (on the .rst sub-machine) ac­cording to classes 
and hence we get a similar (up to a small perturbation) example as in Theorem 5.1. Since only one sub-machine 
is active, the makespan of the example described is multiplied by log m and becomes log2 m where the 
optimum remains the same i.e., 1. Finally, we show that this policy converges to a Nash equilibrium very 
fast. Theorem 7.3. The corresponding game for the Split &#38; Shortest policy is a potential game. Moreover, 
any sequence of best responses of players consisting of n rounds of all players converges to a pure Nash 
equilibrium. Proof. The completion time of each job in Split &#38; Shortest is precisely equal to the 
completion time of each job in the corresponding instance on the mb sub­machines. That instance is ShortestFirst 
on each sub­machine. Hence, any sequential improvement process converges to a Nash equilibrium [11, 17]. 
A potential function for the ShortestFirst policy is the vector of the completion time (sorted in non-decreasing 
order) of all jobs which decreases lexicographically after each best response. Also it is proved in [17] 
that at most n rounds of best responses of players converges to pure Nash equilibria in this game. 8Open 
Problems In this paper, we proved that the best achievable price of anarchy by strongly local and local 
ordering policies are T(m)and T(log m). Ordering policies character­ize all deterministic non-preemptive 
policies satisfying the IIA property. An interesting open problem is to de­sign preemptive or randomized 
policies with a constant price of anarchy, or to prove that this is not possible. Another interesting 
open problem is the speed of con­  vergence to approximate solutions for the ine.ciency­based policy 
[21]. Finally, since pure Nash equilibria for the ine.ciency-based policy do not necessarily exist, it 
would be interesting to bound the approximation ratio of the sink equilibria [15]. Acknowledgements. 
We thank Allan Borodin for interesting discussions about related work. References <RefA>[1] Aspnes, Y. Azar, 
A. Fiat, S. Plotkin, and Waarts. On­line routing of virtual circuits with applications to load balancing 
and machine scheduling. J. ACM 44, 3:486 504, 1997. [2] B. Awerbuch, Y. Azar, Y. Richter, and Dekel Tsur. 
Tradeo.s in worst-case equilibria. In WAOA, 2003. [3] Y. Azar, J. Naor, and R. Rom. The competitiveness 
of on-line assignments. Journal of Algorithms, 18:221 237, 1995. [4] A. Bagchi. Stackelberg di.erential 
games in economic models. Springer-Verlag, 1984. [5] M. Beckman, C. B. McGuire, and C. B. Winsten. Studies 
in the Economics of Transportation. Yale University Press, 1956.  [6] A. Borodin, M. Nielsen, and C. 
Racko.. (incremental) priority algorithms. In SODA, pages 752 761, 2002. [7] G. Christodoulou, E. Koutsoupias, 
and A. Nanavati. Coordination mechanisms. In ICALP, pages 345 357, Turku, Finland, 12 16 July 2004. [8] 
R. Cole, Y. Dodis, and T. Roughgarden. How much can taxes help sel.sh routing? In EC, pages 98 107, 2003. 
[9] A. Czumaj and B. Vocking. Tight bounds for worst­case equilibria. In SODA, pages 413 420, 2002. [10] 
E. Davis and J.M. Ja.e. Algorithms for scheduling tasks on unrelated processors. J. ACM, 28(4):721 736, 
1981. [11] E. Even-dar, A. Kesselman, and Y. Mansour. Conver­gence time to nash equilibria. In ICALP, 
pages 502 513, 2003. [12] G. Finn and E. Horowitz. A linear time approximation algorithm for multiprocessor 
scheduling. BIT, 19:312 320, 1979. [13] L. Fleischer, K. Jain, and M. Mahdian. Tolls for het­erogeneous 
sel.sh users in multicommodity networks and generalized congestion games. In FOCS, pages 277 285, 2004. 
[14] M. Gairing, T. Lucking, M. Mavronicolas, and B. Monien. Computing nash equilibria for scheduling 
on restricted parallel links. In STOC, pages 613 622, 2004. [15] M.X. Goemans, V.S. Mirrokni, and A. 
Vetta. Sink equilibria and convergence. In Proceedings of the 46th Annual IEEE Symposium on Foundations 
of Computer Science(FOCS), pages 142 154, 2005. [16] O.H. Ibarra and C.E. Kim. Heuristic algorithms for 
scheduling independent tasks on nonidentical proces­sors. J. ACM, 24(2):280 289, 1977. [17] N. Immorlica, 
L. Li, V. Mirrokni, and A. Schulz. Coordination mechanisms for sel.sh scheduling. In Workshop of Internet 
and Economics, 2005. [18] Y.A. Korilis, A.A. Lazar, and A. Orda. Achieving network optima using Stackelberg 
routing strategies. IEEE/ACM Transactions on Networking, 5(1):161 173, 1997. [19] E. Koutsoupias and 
C. Papadimitriou. Worst-case equilibria. In STACS, pages 404 413, 1999. ´ algorithms for scheduling unrelated 
parallel machines. Mathematical Programming, 46:259 271, 1990. [20] J. Lenstra, D. Shmoys, and E. Tardos. 
Approximation [21] V.S. Mirrokni and A. Vetta. Convergence issues in competitive games. In APPROX, pages 
183 194, 2004. [22] T. Roughgarden. Stackelberg scheduling strategies. In STOC, pages 104 113, 2001. 
[23] S. Sahni and Y. Cho. Bounds for list schedules on uniform processors. Siam J. of Computing, 9:91 
103, 1980. [24] P. Schuurman and T. Vredeveld. Performance guaran­tees of local search for multiprocessor 
scheduling. In IPCO, pages 370 382, 2001. [25] H. von Stackelberg. Marktform und Gleichgewicht. Springer-Verlag, 
1934. English translation entitled The Theory of the Market Economy. [26] T. Vredeveld. Combinatorial 
approximation algo­rithms. Guaranteed versus experimental performance. 2002. Ph.D. thesis. [27] Wikipedia. 
http://en.wikipedia.org/wiki/ Indepen­dence of irrelevant alternatives</RefA>. Appendix A Proof of Theorem 
3.2 Proof. In order not to deal with the issue of breaking ties (which plays a major role in the general 
lower bound), we would make all jobs of di.erent size. We construct the following instance. There are 
m- 1types j =2 (m-1)! of jobs. For j=1 to m- 1, there are njobs (j-1)! of type j.Job kfor 1 = k= nj of 
type jhas processing 2(j-1)! time (1 + ekj)= (1+ ekj) on machine j and nj (m-1)! 2jj! (1 + ekj)= (1+ 
ekj) on machine j+1 and nj (m-1)! in.nite (or large enough) on all other machines. We choose 0 <ekj <efor 
some small enough ej+1 where ekj <ek+1,j for all kand j and enj ,j <e1,j+1. The optimal solution may 
use the following assign­ment. Assign all nj jobs of type j on machine j.This assignment results in completion 
time of at most 2(1+e) for each machine (except the m th one which remains empty). Consider the following 
assignment. Half of the jobs of type jare assigned to machine jand half to machine j+1 (we later specify 
which half). Then Machine j+1 for j=1to m-2 would have a load of slightly more than (nj/2)(2j/nj)= j 
of jobs of type j and slightly more than (nj/2)(2/nj)= 1 of jobs of type j+ 1. Machine 1 has a load of 
slightly more than 1 (type 1 jobs) and machine m a load of slightly more than m- 1(type m- 1jobs). Note 
that all jobs on each machine have approxi­mately thesamesize. Sincewe set ekj <ek',j+1 for all jand 
k,kf this implies that jobs of type jare processed before jobs of type j+ 1 (on machine j+1). Finally, 
we have to specify which set of jobs are actually assigned to each machine. This assignment de.nes the 
order of jobs on each machine. Assume for amomentthat ekj would have been 0. This would de.ne a set of 
completion times for all jobs of type j on machines j and j + 1. Assign the jobs of type j to the two 
machines (j and j+ 1) in non-decreasing order of the ID kaccording to the non-decreasing order of completion 
time of that jobs. We claim that this assignment is a Nash Equilibrium. Moreover the price of anarchy 
is about m/2. Immorlica et.al. [17] observed that the set of pure Nash equilibria of the ShortestFirst 
policy is equivalent to the output of the shortest-.rst greedy algorithm of Ibarra and Kim [16]. Therefore, 
the above lower   m bound implies the lower bound of for the shortest­ 2 .rst greedy algorithm. B 
Pure Nash equilibria for Special Cases In this section, we investigate the existence of pure Nash equilibria 
for general ordering policies and for some special cases. In particular, we prove the following theorems. 
Theorem B.1. The corresponding game of any order­ing policy is a potential game for B||Cmax.Thus, it 
has pure Nash equilibria for B||Cmax.Also, if the global ordering for all machines is the same, then 
pure Nash equilibria exist for the corresponding game of the R||Cmax. However, for R||Cmax, there are 
ordering poli­cies without any pure Nash equilibria even for two ma­chines. Proof. Let w(i,j) be the 
position or rank of job i in the global ordering of machine j, i.e., job i is at the w(i,j)s position 
in the global ordering of machine j.Given a schedule S of jobs on all machines, let mi be the machine 
of job i and Ti be the starting time of job i.In order to de.ne the potential function for S, we add 
a dummy job dj of length 8 to the end of each machine j.The rank of the dummy job dj on machine j is 
n+ 1, i.e., w(dj ,j)= n +1, and mdj = j. After adding these dummy jobs, we .nd the potential function 
for schedule S as follows: sort the jobs in the non-decreasing order of their starting time, and if there 
are ties between the starting times, sort them in the non-decreasing order of their ranks w(i,mi). Since 
we added a dummy job for each machine, the length of the vector of the potential function is n+ m. Let 
the vector of jobs in this order be (1,2,...,n+ m). Therefore, by de.nition, T1 = T2 = ...= Tn+m and 
if Tl = Tl+1,then w(l,ml) = w(l+1,ml+1). The potential function for this schedule S is (w(1,m1),w(2,m2),...,w(n+ 
m,mn+m)). If job k f plays his best response and goes to machine minstead k of machine mk, the starting 
time of job k decreases (since for B||Cmax when a job improves its completion time, it improves its starting 
time as well). As a result, job k occupies an earlier position in the corresponding vector of the new 
schedule. Job k cannot be the last job f on machine m, since each machine has a dummy job k who is the 
last. Let job kf be the job after k on machine f mafter k moves (note that kf might be a dummy job). 
k The rank of job k is less than the rank of job kf on f machine mk. This proves that the potential function 
decreases lexicographically. Therefore, the game is a potential game. It is not hard to prove that if 
the global ordering for all machines is the same, then pure Nash equilibria exist for the corresponding 
game of the R||Cmax and the game is a potential game. If the global ordering on all machines is (1,2,...,n) 
and the completion time of job i in schedule S is Ci(S), then the potential function in this case for 
schedule S is (C1(S),C2(S),...,Cn(S)). Finally, for R||Cmax, there are examples even for two machines 
for which the corresponding game does not have any pure Nash equilibrium. Consider an example with two 
machines 1 and 2, and three jobs A,B,C. The global ordering for machine 1 is (A,B,C) and the global ordering 
for machine 2 is (C,A,B). The processing time of jobs on machines are pA1 = 12, pB1 = 16, pC1 =2, pA2 
= 10, pB2 = 10, pC2 = 16. It is not hard to check that no set of strategies of players is a pure Nash 
equilibrium in this game. The above theorem shows that an arbitrary set of ordering policies may not 
have pure Nash equilibria even for two machines. We showed that the corresponding game of the ine.ciency-based 
policy may not possess pure Nash equilibria. The following theorem shows that the ine.ciency-based policy 
always have pure Nash equilibria for two machines. Theorem B.2. The ine.ciency-based mechanism al­ways 
possess pure Nash equilibria for two machines. Proof. The proof is by induction. The base of induction 
is for one job for which the proof is trivial. Consider the most ine.cient job on both machines and call 
it A.We do not let A go on the machine for which it is less e.cient, say machine 1. The induction is 
on the number of pairs of jobs and machines (i,j) such that job i can be scheduled on machine j. For 
the instance for which job A cannot be scheduled on machine 1, we .nd a pure Nash equilibrium S by induction. 
For the induction step, we would like to change this equilibrium S to an equilibrium for the original 
instance. The only possibility is that job Ain S wants toswitch tomachine 1. Ifwelet A move to machine 
1, no other job from machine 2 wants to move to machine 1. We claim that jobs from machine 1 do not want 
to switch to machine 2 either. Note that job A is larger on machine 1 than on machine 2 and hence machine 
1 ends in schedule S (without job A) before job A starts on machine 2, otherwise A would not like to 
move from machine 2. Hence no jobs from machine 1 want to move to machine 2 (although job A left machine 
2), since they would .nish later if they move.   
			
