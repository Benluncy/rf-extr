
 A lower bound for integer multiplication with read-once branching programs Stephen Ponzio MIT Laboratory 
for Computer Science Abstract 1 Introduction and background Recent developments in the field of digital 
de- It is well known that many functions, some sign and verification have found great use for of them 
very simple, cannot be computed byrestricted forms of branching programs. In par­ read-once branching 
programs of polynomialticular, oblivious read-once branching programs size [32, 35, 14, 31, 3, 19, 22]. 
Interest in wheth­(also called OBDD S ) are now commonly used er integer multiplication can be so computedin 
circuit verification. This restricted class of has been created by recent developments in the branching 
programs is useful because these pro­field of digital design and verification. grams are easily manipulated 
and tested for equivalence. However, their practical utility is A central problem of verification is 
to check limited because they cannot compute in poly­ whether a combinational hardware circuit has nomial 
size several simple functions most no­ been correctly designed. One approach to ver­tably, integer multiplication. 
This limitation ification often employed today is to indepen­has prompted the consideration of alternative 
dently convert both the circuit description and models, usually types of branching programs, the function 
specification to a common inter­in the hope of finding one with greater compu­ mediate representation 
and then test whether tational power but also easily manipulated and the two representations are equivalent 
(e.g., [34]). tested for equivalence, The use of oblivious read-once branching pro­ grams, also known 
as ordered binary deci­Read-once (non-oblivious) branching programs sion diagrams (OBDD s), for the intermediate 
can to some degree be manipulated and tested representation has made this approach feasi­ for equivalence, 
but it has been an open ques­ble and very popular several software pack­ tion whether they can compute 
integer multi­ages are available for implementing this very plication in polynomial size. This paper 
proves strategy [25, 10]. that they cannot multiplication requires size 2Q(fi). Most of the computational 
models considered Permission to copy without fee all or part of this material is as candidates for the 
intermediate represen­granted provided that the copies are not made or distributed for tation are restricted 
classes of branching pro­ direct commercial advantage, the ACM copyri ht notice and the Me of the publication 
and Its date appear, an3 notice is given grams. A branching program is a directed a­ hat cPPYk#is by 
permission of theAssociationof Computing cyclic graph with a distinguished root node Machinery. o cop 
otherwise, or to republish, requires {and two sink nodes. The sink nodes are la­ a fee andior specl ICpermission. 
STOC 95, Las Vegas, Nevada, USA @ 1995 ACM 0-89791 -718-9/95/0005..$3.50 beled 1 and O and each non-sink 
node is la­ beled with an input variable x, and has two outgoing edges, labeled O and 1. A branch­ ing 
program computes a Boolean function ~ : {O, 1} --+ {O, 1} in the natural manner: each assignment of Boolean 
values to the variables $, defines a unique path through the graph from the root to one of the sinks; 
the label of that sink defines the value of the function on that input. The size of a branching pro­gram 
is its number of nodes. An OBDD is a branching program in which the input vari­ ables appear at most 
once on each path from the root and also in the same order on each path. In other words, an OBDD S reading 
of the inputs is oblivious. OBDD S serve well in this application because they are easily manip­ulated: 
Given two OBDD S obeying the same ordering of the variables and computing func­tions f and g, 1. It is 
easy to construct an OBDD to compute fAg, fVg, orlf. Tf is trivially constructed by interchanging the 
accepting and rejecting nodes; f A g and f V g are obtained by a simple product construction as for finite 
automata. (The latter is is not true if the two OBDD S do not obey the same ordering see below. ) 2. 
It is easy to determine whether f = g. Equivalence is easily determined by testing the satisfiability 
of an OBDD for f 6 g. An OBDD can be checked for satisfiability by simple checking whether there exists 
a path from the start node to an accepting node.  The synthesis operations of (1) are neces­sary for 
the typical algorithm that constructs the OBDD from the circuit description. The circuits under consideration 
are ordinary com­binational circuits, built up from a standard basis of boolean functions such as {A, 
V, 7}. A common algorithm is to work bottom-up through the circuit, from the inputs to the out­put, combining 
the representations appropri­ately at each gate. Thus, the algorithm need only compute a representation 
for f A g, f V g, and lj, given representations for f and g. This strategy for verification has two short­comings 
that are immediately apparent. Re­ call that unrestricted polynomial-size branch­ing programs compute 
exactly those functions in non-uniform logspace. Therefore, if our tar­get representation is a restricted 
form of branch­ing program, we clearly cannot hope for a gen­eral algorithm to compute a polynomial-size 
representation (polynomial in the size of the original circuit) unless L = P. This problem has largely 
been accepted as inherent and not critical, since functions computed at level of hardware are not generally 
complex and are in fact in L anyway. A second observation is that efficient algorithms for the synthesis 
oper­ations do not imply that the resulting bottom­up algorithm for computing a representation is efficient-squaring 
the size of the represen­tation at each gate, for example, results in a final representation that is 
exponential in the size of the original circuit. Despite this prob­lem, researchers have been content 
with the bottom-up algorithm as long as each synthe­ sis operation can be performed efficiently. Integer 
multiplication. By integer multz­ plzcahon, we will refer to the Boolean function MULT : {O, 1}2 --+ 
{O, 1} that computes the middle bit in the product of two n-bit inte­ gers. That is, MU LT(Z, y) = zn_l 
where x = Xn l . . . Z(), g=yn.. -l Yo, and z2~_1 . . .Zo = z = Zy is the product of the integerc repre­sented 
in binary by J and y. The middle bit is the hardest bit, in the sense that if it can be computed by read-once 
branching pro­grams (or any computational model) of size f(n), then any other bit can be computed with 
size at most ~(2n). Although OBDD S can efficiently compute many of the functions of importance to the 
verifica­ tion community (integer addition, symmetric boolean functions, and many of their bench­ mark 
functions [8] ), some simple functions are known to require exponential size. Most im­ portantly, it 
was proved by Bryant [9] that exponential size is required to M ULT. This was an important setback to 
the viability of OBDD S, since the hardware to be tested typi­tally contains circuits that perform multiplica­tion. 
Today, the largest multipliers that can be checked using this method have 12-bit inputs; ideally, circuit 
designers would like to check multipliers of 32 or even 64 bits. Other models. As a result, various 
alterna­tives to OBDD S have been proposed with the goal of finding a representation that is likewise 
manipulated but with greater computational power [28, 29, e.g.]. For example, the various extensions 
that have been considered include k-BDD s , where each path reads the variables in the same order k times 
consecutively [5, 7, 23]; k-IBDD s , which are the same as k-BDD s except that the k vari­able orderings 
may be different [18, 12]; read­k-times branching programs [7, 6, 20]; and other types of oblivious branching 
programs [2]. The natural extensions of allowing vari­ous kinds of non-deterministic branching (V­nodes, 
A-nodes, ~-nodes) have been studied in [27, 28, 16, and others]. Recently proposed al­ternative models 
include graph-driven BDD s [29] and binary moment diagrams [11]. From Bryant s proof it follows by a 
simple commu­nication complexity argument that multiplica­tion cannot be computed in polynomial-size 
by k-BDD s [23, 5] or the various non-determini­stic OBDD S [16]. Incorporating results from [1], a similar 
lower bound is shown for arbi­trary linear-length oblivious programs [16]. Read-once programs. Another 
candidate representation for this verification technique is read-once branching programs, which have 
been widely studied by the theory community. In a read-once program, the input variables appear at most 
once each on each path from the root, but not necessarily in the same order on each path. The possibility 
of using read-once pro­grams in this application has been tentatively explored by several researchers 
in the verifica­tion community [17]. Read-once programs do not enjoy quite the same degree of manipula­bility. 
It is j ust as easy to test a read-once pro­gram for satisfiability, but there exist functions f and 
g that each have polynomial-size read­once programs but whose conjunction f A g requires exponential-size 
read-once programs. For example, the function PERM, indicating whether a O, l-matrix is a permutation 
matrix, requires exponential-size read-once programs [23, 24] whereas the (necessary and together sufficient) 
row-wise and column-wise criteria are each computable with small OBDD S. For determining the equivalence 
of two read­once programs, the best algorithm known is a CO-RP algorithm due to Blum, Chandra, and Wegman 
[4]. It relies on randomly assigning values from a finite field to the literals and then computing the 
value of the polynomial corre­sponding to the function. There is also a deterministic algorithm to test 
the equivalence of an OBDD and a read-once program [15]. The read-once restriction is strong enough that 
there has been great success in proving lower bounds on size (see [26, 14, 35, 31, 30]). In particular, 
it was proved in [35] (see also [31]) that the function Clique-0 nlyn12, which deter­mines whether a 
graph on n nodes contains an n/2-clique and nothing more, requires size 2Q(nJ. (For comparison, there 
is a simple read­twice program of size 0(n3 ). ) [3] proves an asymptotically optimal lower bound of 
2°1 2 J for computing the parity of the number of tri­angles in a graph on n nodes. In light of the many 
proposed extensions to OBDD S, it was an interesting open question for the verification community whether 
polynomial­size read-once programs could compute MU LT. This paper proves they cannot. This is the first 
superpolynomial lower bound for multi­plication on non-oblivious branching programs. By known problem 
reductions, it follows that several other arithmetic functions, including squaring and division, also 
obey this bound. This result demonstrates that relaxing the or­dering restriction of OBDD S is insufficient 
to gain the desired computational power, and thus further strengthening of the model is needed. The decision 
problem DMU LT. Although it is not directly related to the issue of verifica­tion, another Boolean function 
that has been considered is the decision problem DMULT of recognizing the graph of multiplication. That 
is, DMULT(Z, y, z) = 1 if xy = z. Note that it is not readily apparent which problem is harder , MULT 
or DMULT. On the one hand, DMULT seems to require practically computing all the bits of .ry; however, 
an algorithm for DM U LT has the advantage of inspecting all the bits of z, the putative product (see 
[13]). A simple argument [34] shows that computing DM U LT with read-once programs is as hard as factoring. 
To factor an integer n, instantiate it for the bits of z in the read-once program, and then construct 
a nontrivial factor z one bit at a time by testing the program for satisfiabil­ity each time x is extended 
by one bit. So a polynomial-size read-once program for D M U LT gives a polynomial-time algorithm for 
factor­ ing, Julma [21] proves a lower bound of exp(fi/k2~ ) for DM ULT on non-deterministic read-k-times 
branching programs. His lower bound follows the framework of [6], and gives a simple reduc­tion of DMULT 
to the problem of recognizing codewords of a linear code, for which a lower bound of exp(@/k2~) is proved 
in [20].  The lower bound Simon and Szegedy [30] give a basic lemma for proving lower bounds on the 
size of read-once branching programs. The lemma uses Neci­poruli s method of counting the subfunctions 
that are possible when some subset of input bits is fixed. This technique appears implicitly in the read-once 
lower bounds of [32, 35] and explicitly in those of [19, 22, 14]; the general­ization in [30] enables 
an easier proof of the lower bound of [3] and others [31, 14, 19]. Let ~ be a Boolean function, ~ : {O, 
l}n + {O, 1}, and let X = {Zo, ... ,Zn l } be its n binary in­put variables, Let 7 be a filter on X. 
(That is, 3 c 2X and F is closed upward if S < F, then all supersets of S are in X.) A subset 1? C X 
is said to be in the boundary of .T if 1? $? .F but (I3 UZZ) 6 .7_ for some x,. By set­ting the values 
of ~ = X \ l?, we naturally induce a function on l?. The lemma is stated below in the form we will need 
it; it appears in [30] in slightly more generalized form. Lemma 1 (Simon and Szegedy) If for any B in 
the boundary of3, at most 21B1/L settzngs to B induce the same subfunction on B, then any read-once branching 
program computing f has we at least L. The idea of this lemma is as follows. We may associate with each 
edge of the program the set of variables appearing in the subprogram rooted there. Because the program 
is read­once, these variables do not appear on any path from the root to the edge. Say an edge has variables 
V c X in its subprogram. The in­puts z ~ {O, l}n that reach this edge are char­acterized exactly by their 
settings to V. Each setting to ~ that reaches this edge clearly in­duces the same subfunction on V, as 
defined by the subprogram rooted there. We may identify in the program a frontier of edges closest to 
the root whose set of variables is not in the fil­ter 3, and associate with each frontier edge a se~B 
C X in the boundary of%. Since at most 21B1/L settings to ~ give the same subfunction on B, at most (21B1/L)21Bl 
= 2n/.L inputs in {O, 1} may reach such an edge. Since every in­put reaches some frontier edge, there 
must be at least L such edges. Having fan-out 2 and only one root, the program also has at least L nodes. 
For ease of presentation, we will first prove a lower bound of 2af $@, and then explain how the proof 
can be extended to achieve 2Q(fiJ. Theorem 1 Any read-once branching program that computes M ULT has 
size at least 2 *14. Let m = fi/4 and let X and Y denote the sets of variables X = {XO, . . . , xn 1} 
and Y = {Ye,. ~~ , ?h 1 }. Define the filter [Vn X/>n m, and,3={ VC(XUY): ,vny, >n_m ~ Roughly speaking, 
this filter marks the frontier of the program where at most m bits of X and at most m bits of Y have 
been read. We will show ~hat for any B in the boundary of ~, at most 21B1 ~ settings to ~ give the same 
subfunction on 13. By Lemma 1, this gives the desired lower bound of 2rn. Fix any B in the boundary of 
7 and let S = ~. Think of S as being the variables already read by the branch­ing program. Since B is 
in the boundary of%, either ISnXl = m or ISnYI = m. We will show that there is a subset S c S of size 
at least m such that if two settings to S differ on S then they induce different subfunctions on ~ = 
B. Thus at most 21sl ~ settings to S = ~ induce the same subfunction on ~ = B, as desired. We will show 
that the subfunctions are different by explicitly demonstrating a sin­gle setting to the bits of ~ where 
the induced subfunctions of MULT differ. Suppose lSnXl = m (and IS nYl s m). Let iG{o, . . ..n 1} be 
the least index such that yi @S. Let S == {ye,...,Yi_l} u (Sn {Zo,... ,Z~_l_z}). Note that because {go, 
. . . , Vi l} Q S and lSn X] = m, we have IS I 2 m. Let Q,/3 be two settings to S (i.e., functions from 
S to {O, 1}) that differ on some bit in S . For a setting cr to W ~ X U Y, let x. denote the integer 
that is represented in binary by setting the bits of X n W as in a and the bits of Xn@ to O. Define y. 
similarly. For a single variable z c (XU Y) \ W, let a+ z denote the setting to W U {z} that also sets 
z = 1. Let (z), denote the ith bit in the binary representation of integer x. Thus our goal is to find 
a setting -r to the bits of S so that (z~u~y~u7 )~ l # (~@JrV~uT)n -l, where {a U -r denotes the setting 
equal to Q on S and to r on ~. We proceed in two stages, according to Lemmas 2 and 3. First we ensure, 
by setting (if necessary) to 1 a single variable z of ~ so that the two products xa+zya+~ and Ze+zyo+z 
differ in a high-order bit a bit po­sition in the range [n m 3, n 1]. (We call these bits high-order 
even though they re in the middle because we don t care about the bits above position n 1.) In the second 
stage, we set to 1 a pair of variables of ~, one in X and one in Y, so that the resulting product differs 
in a higher bit position. We iterate this second stage, repeatedly setting a pair of vari­ables until 
the resulting products differ in bit position n 1. It follows that a and ,8 induce different subfunctions 
on ~ the subfunctions differ when ~ has z and the pairs above all set to 1 and the remaining bits of 
~ set to O. Lemma2 If for allie [n m 3, n 1] we have (z@y@)i = (zPyP)i, then there is a single variable 
z c (X U Y) \ S such that forsome biti E[n-m-3, n-1]. Lemma 3 Let T c X UY and Qand ~ betwo settings 
to T. Let d be the greatest tndex m [0, n -2] such that (Z~y~)d # (ZpyD)d. ~f d Z n m 3 andmax(lT flXl, 
lTn Yl) = t < 3nt, then there are two variables, XU E X n ~ and yv E Y n~, such that (wYa )d+l #  (~/3 
Y/3 )d+l Theorem 1 follows from these lemmas as out­lined above. Notice that Lemma 3 is first applied 
with t < m + 1, and since we must ap­ply Lemma 3 at most m + 3 times, each time setting one more variable 
of X and Y, we main­tain t < 2m + 4< 3m as needed. 0 We now give the proofs of Lemmas 2 and 3. Proof 
of Lemma 2: The settings Q and ,B differ on S ~ S; suppose they differ in a bit of S n X (the case when 
they differ in a bit of S n Y is similar). The proof is most easily explained by pictur­ing the integers 
modulo 2n on a circle. Parti­tion the circle into 2~+3 equal-sized segments according to the values of 
the m + 3 highest bits, so each segment contains 2n-m 3 consec­utive integers. The hypothesis of the 
lemma is that xay~ and zpyp fall into the same seg­ment. If we set bit y~ c ~ (7Y to 1, we obtain = Xaya 
+ xQ2k and xp+Yhyp+yk = Q+yk Yff+$%xpyp + xp2k. The product xa+y~ya+g~ is ob­tained by a translation 
of 2KZa along the circle from Xaya, and x~+gk YB+Y, is obtained by a translation of 2~xp from xpyp. 
If, modulo 2 , 2~ (x@ X6) is at least 2n-~-l, or four segments long, and at most 2n 2n-m-2, or negative 
two segments long, then it is clear that the tranSkk Za+yk Yff+yk and o+7Jk Y@ +Yk fall into different 
segments. It follows that they differ in a high-order bit position. It only remains to show how to choose 
yk ~ ~ nY so that 2n-m-l < 2k(x. X6) < 2n zn m 2 1modulo 2 . Let z= x. Zp. It is useful now to think 
in terms of the table gen­erated by the usual grade-school algorithm for multiplying z by y, as depicted 
below. Since a and 1? differ in a bit of S (1 X, the differ­ence z has a 1 somewhere in the range of 
bit positions [0, n 1 Z]. Let j be the position of the least significant 1 in Z, so that either there 
is a O in position j 1, or j = O. Choose any variable of ~ n Y with index k in the range [(n-1 )-j-m, 
(n-1)-j]. /% /% ;% Oe+ .7 *** .. 1000000:5 find k@S This range contains a variable y~ ~ ~ n Y be­cause 
ifj <n m 1,the range hasatleast m+l elements but [Sn Yl < m; ifj ~ n m, we may choose k= i, which isat 
most (n 1) j (since j < n -i -1 and by definition y, @ S). This ensures that 2% has a 1 in position 
j + k anda Oinposition j+k l, where n l m< j + k < n 1. It follows that 2% is at least 2n n l and at 
most 2n 1 2n ~ 2 (the latter attained if all bits except bit j + k 1 are 1 s andj+k=n 1 m). This completes 
the proof. Proof of Lemma 3: Consider all pairs of variables (xU, yv) such that u + v = d. Clearly, (%Y.+2 
),+1 # (x,YD+2 )d+l since (~~Y~)~+l = (XpYp)~+l by the definition of d. Also, we have Xaf yml = ($a+2u)(y@ 
+2 ) Xaya + 2d )( + 2 xa + 2 ya) , ( Xpf ypl = (x@ +2 )(yp +2 )  Xpyp +2d + 2 xp +2 y~) . )( ( In each 
case above, we think of the right-hand side as the addition of the two integers as paren­thesized. We 
will choose u and v so that in each case, the second integer has O s in bit positions d and d + 1 and 
furthermore, in the addition of the two integers, there is no carry bit into position d. Since the addition 
of 2vx~ + 2 y~ to Xaya + 2ddoes not affect bits dor d+ 1of x~uo + 2d (and similarly for Ll). we then 
have (~~,y~~)d+~ # (~~ly@)d+~. ruled out is thus at most Ch.me u .md v so these hits are all 0 s. **lllo. 
..=LTm y~ n ld , To accomplish this, we first find the largest bit position i less than d where Zaya 
has a O (so positions i + 1 through d 1 are all l s). We will choose u and v so that 2Vxa and 2 yQ each 
has O s in positions i 1 through d + 1. It follows that their sum then has O s in positions i through 
d + 1,and so, when added to z~y~ + 2d, causes no carry into position d. We will choose u and v so that 
the same conditions hold for ~ as well. A simple counting argument now shows that there exist u and v 
as desired. First, we claim that X=ga (and Z@y@) has 1 s in at most t2bit positions. In general, if the 
binary representa­tions of integers p and q have w(p) and w(q) 1 s in them respectively, then clearly 
p + q has at most w(p) + w(q) 1 s in it. Recall a sets at most t bits in X or Y. We may therefore view 
Xmym as the addition of at most t shifts of XQ, and the claim follows. We require (2 xa)j = (2 xp)j = 
O in at most t2+ 4 positions j: j = d, d + 1,the positions of the t21 s to the right of position d, and 
the next two positions after those. There are at most t bit positions in which either Xa or xp has a 
1, and for each such 1, there are at most t2+ 4 bad values of v 6 [0, n 1] that shift the 1 to a position 
we require to be O. Thus, Za and Z. rule out at most t(t2 + 4) values of v. Furthermore, there are up 
to t variables of Y that are in T, making a total of t(t2+ 4) + t values of v that we may not choose. 
Similarly, a total of at most t(t2+ 4) + t values of u are ruled out by UQ, yp, and T. The number of 
pairs (xU, YV) in which either ZU or y. has been 2(t3+5t) <2 (27m3 + 15rn) <2 (~+% since t s 3m and m 
= fi/4. There are at least d+ 1~n m 2pairs (xU,yv) such that u + v = d. Thus we retain at least n-~ 
2 ~n+~fi = Q(n) >0 ) ( good pairs satisfying the desired requirements for x. and y.. 2.1 Tuning the 
lower bound We can improve the lower bound to 2°tfiJ by analyzing more closely how we iterate Lemma 3 
in the proof of the theorem. We begin with the observation that we needed m = 0(W) because in Lemma 3, 
we used t2 = O(m2) as an upper bound on the number of consecutive 1 s to the right of position d in Xaya 
or zpyp. We then required O s in these 0(m2) positions in the cross terms 2 xa + 2Uya and 2vxp +2Uyp. 
Since each of the t1 s in Xa may rule out O(m2) values of v, we needed O(tm2) = 0(m3) < n in order to 
have some values left over, In order to allow m = O(@), we will reduce to O(m) the number of positions 
in which we require O s in the cross terms. For example, if we knew that Xoy. and xpyp Xaya=. .. p... 
looked likel , then we would xpyp=. ..~o. . . need to require O s in tie cross terms in only three positions: 
d+ 1, d, and d 1. This is sufficient to ensure that the addition of cross term 2 x. + 2Uy. to Zayo + 
2d does not gener­ate a carry into position d and does not affect bits d or d+ 1 of Xoya + 2d. The same 
holds for 9 and we get (xot ya~ )d+l # (xpf yp~ )d+l. With 1Here and henceforth, . denotes an arbitrary 
string of O s and l s; thus zmy~ = 10 has a 1 in bit d, aOin bit d 1,and may have ajy values in other 
bit positions. only these three positions required to be O s, the total number of v s ruled out by Zp 
and Xm is only O(t) = O(m). Similarly, the cases ~aya=. ..l l... Zaya=. ..l l... a d and Xpyp=. ..(j 
o... qjyp=. ..p. can be handyed with only a few constraints. In fact, there is really only one case 
in which we need to require (2 z6 + 2Uyp) or (2 x@ + 2UyQ) to have many O s: Definition 1 Let d be the 
greatest index less than n an whzch (x~y~)d # (ZpY~)d. we say that xay~ and xpyp are k-bad tf they look 
like Xaya = ...~o ...... Xpyp = . ..())... k or vzce-versa (exchanging a and ~). L Inthiscase, sayz~yO=. 
..~lll 11. ... we must require 2 xp + 2Uyp to be O in at least these k positions in order to prevent 
a carry into position d when we add it to Xbyp. In order to allow m = O(A), we will ensure that the products 
are not k-bad for k > 4m. We will first show that we may begin with products that differ in a high-order 
bit but are not (m+ 5)-bad, and then prove a version of Lemma 3 in which each application allows the 
badness to grow by at most 2. Building on Lemma 2, we prove Lemma 4 Let m = @/5. For any Q and ~, there 
are three (or fewer) variables ZU, y,,, z E (XUY)\S such that ford = Q+xU+yV+z and ~ = P +X. + Y. + Z, 
the products Xa,ya, and XpIybI dtffer tn a high-order bit and moreover, are not (m + 5)-bad. And a version 
of Lemma 3 holds with the ad­ ditional property that the badness grow= by at most 2: Lemma 5 Let m = 
&#38;/5 and let T, a, ,8,d andtbeasinLemma 3,with t~2m+5and the additional property that Xaya and xpyp 
are not k-bad, for some k ~ 3m + 9. Then there are two vartables, XU, y,, $?T, such that (%Yd )d+l # 
(wY/3 )d+l forcJ=~+xu +yvand/? =P+xu+yu, and moreover XaIyaI and XPIy61 are not (k+ 2)-bad. Because of 
space limitations, we omit the proofs of Lemma 4 and Lemma 5. We now have Theorem 2 Any read-once branchang 
program that computes MULT has stze at least 2@15. Proof: We start with products that differ in a high-order 
bit but are not (m+ 5)-bad, as pro­vided by Lemma 4. The number of variables in X or Y set in these products 
is at most m +2. We obtain a difference in bit n 1 by iterat­ing Lemma 5 at most m + 2 times, each time 
setting at most one variable in X and in Y. This maintains t< (m+2)+(m+2)and k < (m+ 5) + 2(m + 2) as 
needed.  2.2 Implications for other arithmetic functions There are strong ( projection ) reductions 
from other arithmetic functions to multiplication [33]. In particular, these reductions imply that if 
each bit of such a function is computable with read-once programs of size f(n), then MU LT is computable 
with read-once programs of size ~(cn) (for some constant c). Corollary 1 Any read-once branching program 
for computtng the square of an Integer has size at least 2Qifi). Corollary 2 Any read-once branching 
program for computing l/x has size at least 2°tfiJ. In Corollary 21 x is an n-bit number and the problem 
is to compute the n most significant bits of l/z.  Acknowledgments Thanks to Mikael Goldmann for pointing 
out the reductions in [33], to Mauricio Karchmer and Ravi Sundaram for discussions, and to Al­lan Borodin 
for bringing this problem to my attention. References <RefA>[I.] N. Alon and W. Maass. Meanders and their 
applications in lower bounds argu­ments. Journal of Computer and System Sci­ences, 37, 1988, pp. 118 
129. [2] P. Ashar, A. Ghosh, and S. Devadas. Boolean satisfiability and equivalence check­ing using general 
binary decision diagrams. Proc. Int 1. Conference on Computer Design, 1991, pp. 259-264. [3] L. Babai, 
N. Nisan, E. Szemeredi, and G. Turan. A lower bound for read-once branch­ing programs. Journal of Computer 
and Sys­tem Sciences, No. 37 (1988), pp. 153 162. [4] M. Blum, A. Chandra, and M. Wegman. Equivalence 
of free boolean graphs can be decided probabilistically in polynomial time. Information Processing Letters, 
Vol. 10, No. 2, March 1980, pp. 80-82. [5] B. Bollig, M. Sauerhoff, D. Sieling, and I. Wegener. Read-k-times 
ordered binary de­cision diagrams efficient algorithms in the presence of null chains. Technical Report 
474, Univ. Dortmund, 1993. [6] A. Borodin, A. Razborov, and R. Smolen­sky. On lower bounds for read-k-times 
branching programs. Computational Com ­piezity, 3, 1993, pp. 1-18. [7] Y. Breitbart, H. B. Hunt III and 
D. Rosen­krantz. The size of binary decision diagrams representing boolean functions. Theoretical Computer 
Science, to appear. [8] F. Brglez and H. Fujiwara. A neutral netlist of 10 combinational circuits. Proc. 
1985 IEEE Int 1. Symposium on Circuits and Sys­tems. [9] R. Bryant. On the complexity of VLSI im­plementations 
and graph representations of boolean functions with applications to in­teger multiplication. IEEE Transactions 
on Computers, Vol. 40, No. 2, February 1991. pp. 205-213. [10] R. Bryant. Symbolic boolean manipula­tion 
with ordered binary decision diagrams. ACM Computing Surveys, Vol. 24, No. 3, September 1992. pp. 293-318. 
[11] Randal Bryant and Yirng-An Chen. Veri­fication of arithmetic functions with binary moment diagrams. 
Technical Report CMU­CS-94-1601 Carnegie Mellon University, May 31, 1994. [12] B. Bollig, M. Sauerhoff, 
D. Sieling, and I. Wegener. On the power of different types of restricted branching programs. Submitted 
to Theoretical Computer Science. [13] S. Buss. The graph of multiplication is equivalent to counting. 
Information Process­ing Letters, 41 (18 March 1992), pp. 199 201. [14] P. E. Dunne. Lower bounds on 
the com­plexity of l-time only branching programs. Proceedings of the FC T, Springer-Verlag LNCS No. 
199 (1985), pp. 90-99. [15] S. Fortune, J. Hopcroft, and E. M. Schmidt. The complexity of equivalence 
and containment for free single variable pro­gram schemes. Springer-Verlag LNCS No. 62, 1978, pp. 227-240. 
[16] J. Gergov. Time-space tradeoffs for inte­ger multiplication on various types of input­oblivious 
sequential machines. Information Processing Letters, 51 (1994), pp. 265-269. [17] J. Gergov and C. Meinel. 
Efficient boolean manipulations with OBDD S can be extended to FBDD s. IEEE Transactions on Computers, 
Vol. 43, No. 10, (October 1994), pp. 1197-1209. [18] J. Jain, M. Abadir, J. Bitner, D. Fussell, and J. 
Abraham. IBDD s: An efficient functional rep­resentation for digital circuits. European Design Automation 
Conference (1992), pp. 440-446. [19] S. Jukna. Entropy of contact circuits and lower bounds on their 
complexity. Theoretical Com­puter Sczence, 47:2 (1988), pp. 113-129. [20] S. Jukna. A note on read-k-times 
branch­ing programs. Technical report 448, Universitat Dortmund, 1992. Submitted to RAIRO Theoret­ical 
Computer Science. [21] S. Jukna. The graph of multiplication is hard for read-k-times networks. Manuscript, 
April 1994. [22] M. Krause. Exponential lower bounds on the complexity of real time and local branching 
pro­grams. Journal of Information Processing and Cybernetics (EIK), 24:3 (1988), pp. 99-110. [23] M. 
Krause. Lower bounds for depth-restricted branching programs. Information and Computa­tion, Vol. 91, 
1991. pp. 1-14. [24] M. Krause, C. Meinel, and S. Waack. Separat­ing the eraser Turing machine classes 
L~, NLC, CO-NL,, and P.. Theoretical Computer Sczence, 86 (1991), pp. 267-275. [2.5] S. Krischer. FANCY 
new version (1.1). The­orynet-A announcement from krischer@ tl .uni-trier. de, U. Trier, Germany, Nov. 
17, 1994. [26] W. Masek. A Fast Algordhm for the String-Edztmg Problem and Dects~on Graph Complex­ity.SM 
Thesis, MIT, 1976. [27] C. Meinel. Modzfied Branchzng Programs and Thetr Computational Power. Springer-Verlag 
LNCS No. 370, 1989. [28] A. Shen, S. Devadas, and A. Ghosh. Proba­bilistic manipulation of boolean functions 
using free boolean diagrams. Manuscript, MIT, 1994. [29] D. Sieling and I. Wegener. Graph driven BDD 
s a new data structure for boolean func­tions. Theoret~cal Compute? Science 143 (1995), to appear [30] 
J. Simon and M. Szegedy. A new lower bound theorem for read-only-once branching programs and its applications. 
Advances in Computational ComplexZt y Theory (Jin-Yi Cai, editor), DI-MACS Series, Vol. 13, AMS (1993) 
pp. 183-193. [31] I. Wegener. The Complexity of Boolean Func­tions. Wiley-Teubner Series in Computer 
Sci­ence. New York/Stuggart, 1987. [32] 1. Wegener. On the complexity of branching programs and decision 
trees for clique functions. Journal of the ACM, 35(2) (1988), pp. 461-471. [33] I. Wegener. Optimal lower 
bounds on the depth of polynomial-size threshold circuits for some arithmetic functions. Information 
Process­ing Letters, Vol. 46, No. 2, pp. 85 87, May 17, 1993. [34] I. Wegener. Efficient data structures 
for boolean functions. Dwcrete Mathematics, 136, (1994), pp. 347-372. [35] S. Zak. An exponential lower 
bound for one­time-only branching programs. Proceedings of the llth MFCT, Springer-Verlag LNCS No. 176 
(1984), pp. 562-566.</RefA>  
			
