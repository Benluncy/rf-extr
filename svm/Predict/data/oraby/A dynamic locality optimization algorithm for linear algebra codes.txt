
 A Dynamic Locality Optimization Algorithm for Linear Algebra Codes Some text in this electronic article 
is rendered in Type 3 or bitmapped fonts, and may display poorly on screen in Adobe Acrobat v. 4.0 and 
later. However, printouts of this file are unaffected by this problem. We recommend that you print the 
file for best legibility. Mahmut Kandemir Microsystems Design Laboratory Pennsylvania State University 
University Park, PA 16802, USA kandemir@cse.psu.edu ABSTRACT Compiler-directedoptimizationtechniquesareefectivein 
reducingthenumberofcyclesspentinof-chipmemoryac­ cesses.Recently,methodshavebeendevelopedthattrans­ formmemorylayoutsofdatastructuresatcompile-time 
toimprovespatiallocalityofnestedloopsbeyondcurrent control-centric(loopnest-based)optimizations.Mostofthese 
data-centrictransformationsuseasinglestatic(program­ wide)memorylayoutforeacharray.Adisadvantageof thesestaticlayout-basedlocalityenhancementstrategiesis 
thattheymightfailtooptimizecodesthatmanipulatear­ rayswhichdemanddiferentlayouts(fromadatalocality perspective)indiferentpartsofthecode. 
Inthispaper,wepresentanewapproachwhichextends currentstaticlayoutoptimizationtechniquestoselectdy­ namicallychangingmemorylayoutstofurtherimprovethe 
localityofdataaccesses.Weshowthatthepossibilityof dynamicallychangingmemorylayoutsduringthecourseof executionaddsanewdimensiontothedatalocalityop­ 
timizationproblem.Ourstrategyemploysastaticlayout optimizermoduleasabuildingblockandbyrepeatedlyin­ vokingitfordiferentpartsofthecode,itcheckswhether 
runtimelayoutmodifcationsbringadditionalbeneftsbe­ yondstaticoptimizer.  Keywords OptimizingCompilers,MemoryLayouts,DynamicOpti-mizations,CacheLocality,DataReuse. 
 1. INTRODUCTION Datalocalityiscriticaltoachievinghighperformanceon bothuniprocessorandmultiprocessorarchitectures.Inpar­ticular,compiler-directedprogramtransformationstoim­provecacheperformancecanleadtolargesavingsinexe­cutiontimes.Optimizingcacheperformanceisparticularly 
importantforalargeclassofcodesfromlinearmatrixalge- Permission to make digital or hard copies of part 
or all of this work or personal or classroom use is granted without fee provided that copies are Permission 
to make digital or hard copies of all or part of this work for not made or distributed for profit or 
commercial advantage and that copies personal or classroom use is granted without fee provided that copies 
are bear this notice and the full citation on the first page. To copy otherwise, to not made or distributed 
for pro.t or commercial advantage and that copies republish, to post on servers, or to redistribute 
to lists, requires prior bear this notice and the full citation on the .rst page. To copy otherwise, 
to republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or 
a fee. specific permission and/or a fee. SAC 2001, Las Vegas, NV SAC 2001, Las Vegas, NV &#38;#169; 
2001 ACM 1-58113-287-5/01/02 $5.00 Copyright 2001 ACM 1-58113-324-3/01/02 ...$5.00 brathatmanipulatemulti-dimensionalarraysusingmulti­levelnestedloops. 
Mostofthepreviouscompiler-basedapproachestodata localityfocusonloop-centrictransformations.Iterationspace 
tiling[7,12](anddata-consciousversionofit[6]),linearloop transformationslikeloopinterchangeandreversal[13,12], 
andinstructionschedulingforlocalityhaveextensivelybeen usedbycompilersfromacademiaandindustry. Alternatively,data-centrictransformationsmodifymem­orylayoutsinanattempttomakethemmoresuitablefor 
thedominantaccesspattern.Thesetransformationsare,in general,restrictedtooptimizingspatiallocality[8,4]and 
demandamoreglobalperspectiveasanarraycanbeac­cessedindiferentplaces(i.e.,notnecessarilyinasingle nest)inagivencode. 
Severalresearchgroups[3,1]havealsotargetedtheirre­searchefortstodevelopintegratedtechniquesthatuseloop­centricanddata-centrictransformationsinaunifedframe­work.Maybethesinglemostimportantproblemthatthese 
integratedtechniquesfaceistofnd(inareasonableamount oftime)themostsuitablecombinationofloopanddata transformationsfromadatalocalityperspectiveforagiven 
application. Manydata-centricapproachestodatalocalityinthedo­mainofregularlinearalgebracodesarelimitedinthesense 
thatthelayoutsdeterminedbythesealgorithmsarestatic, thatis,theyaredeterminedatcompiletimeandvalidthrough­outtheentireexecution.Adisadvantageofthestaticlayout­basedlocalityenhancementstrategyisthatitfailstoop­timizecodesthatmanipulatearraysthatdemanddiferent 
layouts(fromthedatalocalityperspective)indiferentparts ofthecode. Inthispaper,wepresentanewapproachwhichextends 
thestaticlayoutoptimizationtechniquestoselectdynam­icallychanginglayoutstofurtherimprovethelocalityof 
accesses.Werefertothistechniqueasdynamiclayoutop­timization.Ourapproachinthispaperbuildsuponour previousworkonstaticlayoutoptimizationschemes,and 
employsthetechniquedevelopedin[5]asacomponent(i.e., buildingblock).However,thedynamicoptimizationap­proachpresentedinthispaperisfexibleandcanork 
wwith almostanystaticlocalityoptimizerthatusessomeformof layouttransformation. Ourapproachtolayoutoptimizationdividesthejobbe­tweencompile-timeandrun-time.Morespecifcally,thelay­outsofarraysatdiferentpartsofthecodearedetermined 
atcompile-time(alongwiththeaccompanyinglooptrans­formations),andthebookkeepingcodethatisnecessaryto dynamicallytransformthelayoutsofarraysbetweendif­ferentprogramsegmentsisinsertedinthecode(againat 
compiletime).However,thesebookkeepingcodesareex­ecutedatrun-time.Inotherwords,thememorylayouts aretransformedduringthecourseofexecution.Whilethe 
successofthisstrategyislimitedbythecompile-timeana­lyzabilityofthecode(whichisnotmuchofaproblemfor regulararray-basedcodes),ithastheadvantageofoptimiz­ingthebookkeepingcodesatcompile-time.Forinstance, 
ifthecompilerdetectsthattwoarraysofthesamedimen­sionalityandsizeneedtobetransformedatthesamepoint inthecode,itcantransformthemusingonlyasinglenest 
insteadoftwoseparatenests,oneperarray.  2. BACKGROUND Wemainlyfocusonself-temporalandself-spatialreuses; 
however,ourapproachcanbeextendedtohandlegroup reuses(thatis,thereusesbetweendiferentarrayreferences tothesamearray)[12]aswell.Whenareferenceinaloop 
nestaccessesthesamedataindiferentiterationswesaythat temporalreuseoccurs.Similarly,ifareferenceaccessesdata 
residingonthesamecachelineindiferentiterations,we saythatspatialreuseoccurs.Itshouldbeemphasizedthat 
themostimportantreuses(whethertemporalorspatial)are theonesexhibitedbytheinnermostloop.Iftheinnermost 
loopexhibitstemporalreuseforagivenreference,thenthe elementaccessedbythatreferencecanbekeptinaregister 
throughouttheexecutionoftheinnermostloopprovided thatthereisnoaliasing.Similarly,spatialreuseismost benefcialwhenitoccursintheinnermostloop;because,in 
thatcaseitmayenableunit-strideaccesses[8]. Datastructuresintheprogramarerestrictedtobemulti­dimensionalarraysandcontrolstructuresarelimitedtose-quencingandnestedloops.Loopnestboundsandarray 
subscriptfunctionsarea.nefunctionsofenclosingloopin­dicesandconstantparameters.Undertheseassumptions, 
anoptimizingcompilercandetectthepotentialtemporal andspatialreusesinthecodeandconvertthesereusesinto 
locality(i.e.,itcanmodifythecodetoexploitthesereuses atrun-time). Theapplicationofalooptransformationrepresentedby 
asquarenon-singularmatrixcanbeaccomplishedintwo steps:(i)re-writingtheloopbodyand(ii)re-writingthe loopbounds[13].Ontheotherhand,adatatransformation 
(again,thatcanberepresentedusingasquarenon-singular matrix)isappliedbytransformingthedimensions(subscript 
expressions)ofthearrayreferenceandthedeclarationofthe associatedarray[4]. Forasinglereference,determiningbothaloopandadata 
transformationmatrixsimultaneouslyisingeneraladi.cult problem,andisequivalenttosolvinganon-linearsystem 
withsomeadditionalconstraints.Thestaticlocalityopti­mizationapproachpresentedin[5]solvesthisproblemby 
frstdeterminingthelooptransformationmatrix,andthen determiningthedatatransformationmatrix. 3. FRAMEWORK 
3.1 Static Layout Optimization Thestaticlayoutoptimizationframeworkutilizedinthis workisbasedonacombinationofloopanddatatransfor­mations.Observingthatdatatransformationsmaydirectly 
afectspatiallocalityonly(asthefactthatthesameelement ofanarrayisnotaccessedbydiferentiterationscannotbe 
changedbymodifyingthememorylayoutofthearrayin question)whereaslooptransformationsafecttemporalas wellasspatiallocality,thestaticapproachin[5]frstuses 
looptransformationstooptimizeasmuchtemporallocality aspossible(limitedbytheinherenttemporalreuseinthe 
code);then,forthereferencesthatdonotexhibittemporal locality(afterlooptransformation),itusesdatatransfor­mationstoimprovetheirspatiallocality.Asfarasthepos­sibletransformationsspaceisconcerned,theapproachuses 
unimodularloopanddatatransformations.Sinceunimod­ulartransformationsareknowntopreservethevolumeof thetransformediterationordataspace[13],thisapproach 
tendstoincurreducedloopoverhead(forlooptransforma­tions),andminimizestheextramemoryneeded(fordata transformations).Unimodularlooptransformations[2,13] 
includeloopinterchange,loopreversal,andloopskewing. Unimodulardatatransformationsincludedimensionpermu­tation(e.g.,convertingamemorylayoutfromrow-majorto 
column-major)andskewedlayoutssuchasdiagonallayouts (thatmightbeveryusefulinsomebandedmatrixapplica­tions[3]). 
Inordertohandlemultiplenests(procedure-wideopti­mization),thetechniquein[5]propagatesmemorylayouts acrossloopnests.Toaccomplishthis,itfrstordersthenest 
usinganimportancecriterion(alsocalledcostcriterion). Thefrst(themostimportantorthemostcritical)nestis 
thenoptimizedusingthestrategyexplainedintheprevious paragraph.Afterthis,thememorylayoutsforasubset(pos­siblyall)ofthearraysaccessedinthisnestaredetermined. 
Next,thealgorithmmovestothenextmostimportantnest. Itusesthesameapproach(asinthemostimportantnest) tooptimizethisnest.Theonlydiferenceisthat,inse­lectingthemostsuitablelooptransformation,italsotakes 
thememorylayoutsthathavebeendeterminedsofarinto account.Inotherwords,theobjectiveofthislooptransfor­mationisnownotjustoptimizing(maximizing)temporal 
localitybutalsosatisfyingasmanymemorylayouts(deter­minedsofar)aspossible.Aconfictresolutionschemeis adoptedifitisnotpossibletoachieveboththeobjectives. 
Afteroptimizingthisnest,agroupofnewlayoutsisadded tothe`setofdeterminedlayouts',andtheapproachmoves tothenext(third)importantnest,andoptimizesthisnest 
takingintoaccountallthelayoutsfoundsofar(fromthe mostimportantnestandthesecondmostimportantnest), andsoon.If,atsomepointduringtheoptimizationprocess, 
allthelayoutsaredetermined,theremainingnests(ifany) areoptimizedusingonlylooptransformations.If,onthe 
otherhand,afterthelastnestisoptimized,therearestill arrayswhoselayoutsareyettobedetermined,theselay­outsareselectedsoastooptimizethespatiallocalityacross 
outerloopiterations. Oncethelayoutsaredeterminedandtheaccompanying looptransformationsarefound,thecompilermodifesthe 
sourcecodetoobtainanoptimizedsourcewhichcanthen becompiledusingthenativecompileronthemachine.The processofcodegenerationaftertransformationsisquiteme­chanical;thedetailsarebeyondthescopeofthispaper,and 
canbefoundin[4,8,11].Acompletediscussionofthe staticoptimizeraswellasperformancenumbersshowingits efectivenesscanbefoundin[5]. 
 3.2 Cost Estimation Inthisstudy,weusecachethemissestimationtechnique discussedin[10].Theoriginalalgorithmin[10]isdeveloped 
undertheassumptionthatallarrayshaveafxedcolumn­majormemorylayout.Actually,thisassumptionafects onlythereferencecostcalculations.Inourframework,we 
allowdiferentarraystohavediferentmemorylayouts;con­sequently,weneedtorelaxthisfxeduniformlayoutrequire­ment.Thisiseasyas,givenalayoutandanaccesspattern, 
wecanalwayscalculatethereferencecost. 3.3 Dynamic Layout Optimization Themostimportantpartofourapproachisdetermining 
thelayoutsofarraysatdiferentprogrampoints(i.e.,in diferentnests).Beforestartingtodescribethealgorithm 
however,weshouldmakeitclearthatourapproachem­ploysastaticlocalityoptimizationscheme[5]andacache missestimationscheme[10]asmentionedearlier.Thecache 
missestimationschemeisusedtoobtainamissestimatefor agivencodeandmemorylayoutcombination.However, thedynamicoptimizationalgorithm,itself,isindependent 
ofanyspecifcstaticoptimizationtechniqueorcachemiss estimationscheme.Ifdesired,itcanbemadetoworkwith diferentstaticoptimizationtechniques(e.g.,[3])andcache 
missestimationschemes.Inparticular,moreaccuratecache estimationtechniquesthattakeconfictmissestimations 
intoaccountcanleadtobetterexposedmissestimations and,eventually,tobetterlayoutsdependingonthecode beingoptimized. 
Ourtechniquemakesuseofaniterativeapproachtode­terminethebestdynamiclayouts(fromadatalocalityper­spective).Aninformaldescriptionofthetechniquefollows. 
Inthispaper,wefocusonasimplecasewherewehavea numberofconsecutiveloopnestswithnoconditionalstate­mentsbetweenthemandnotiming!convergencetestloops. 
Asketchofsuchacodeanditsgraphrepresentationare showninFigures1(a)and(b),respectively.Thegraphrep­resentationofacodehasanodeforeachnestedloopin 
thecode.Thereisadirectededgebetweentwonodesif oneofthemimmediatelyfollowstheother.Theweightof thisedgerepresentstheestimatednumberofmisseswhen 
onlythetwonests(correspondingtothesetwonodes)are considered. Ourdynamicoptimizationapproachproceedsasfollows. 
First,itusesthestaticlocalityoptimizertooptimizenest v0throughnestv4(i.e.,theentirecode).Thisoptimiza­tionreturnsapotentiallymodifedcodewithoptimizednests 
(throughlooptransformations),andassignsasuitablemem­orylayouttoeacharray.Thisisnormallythecodethat wouldbereturnedbythestaticapproachdescribedin[5]. 
Thedynamicapproachestimatesthenumberofmissesfor thisoptimizedcode,andrecordsit.Insteadofmodifying theoriginalcodedirectly(aswouldbedonebythestatic 
optimizer),itjustrecordstheloopanddatatransforma­tionsfoundalongwiththenumberofestimatedmisses(call thisnumbercost04).1Next,itchecksalltheedgeweights 
1Thenotationcostij referstothenumberofestimated missesfortheprogramfragmentstartingwithviandend­ingwithvj(includingbothviandvj).Ontheotherhand, 
overheadijdenotesthenumberofestimatedmissesthat wouldoccurduringdynamicallytransformingthememory layouts(whenevernecessary)betweenthepartitionthat 
endswithviandthepartitionthatstartswithvj. Nest V4 (a) (b) (c) (d) (e) (f) Figure1:(a)Anexamplecodesketch;(b-f)Difer­entlogicalpartitionings. 
andselectstheedgewiththehighestweightasthecutpoint. Withoutlossofgenerality,letusassumethatinourexample 
thecutpointis(v2;v3),thatis,theedgebetweenv2andv3. Thiscutpointdividesthecodeintotwologicalpartitions: 
theonethatcontainsthenestsv0,v1,andv2andtheother onethatcontainsv3andv4(seeFigure1(c)). Afterthat,thedynamicapproachrunsthestaticopti­mizationalgorithmforeachpartitionseparately,andobtains 
thenumberofmissesforeachofthem(callthesenumbers cost02andcost34).Italsorecordsthepreferablelayouts andaccompanyinglooptransformationsforeachpartition. 
Notethatsincethesetwopartitionsmayaccesssomecom­monarrays,itispossiblethatthestaticoptimizercanse­lectdiferentlayoutsforthesamearrayineachpartition. 
Iftherearesucharrays(withdiferentlayoutsindifer­entlogicalpartitions),thedynamicapproachalsocalculates 
overhead23,theestimatednumberofmissesthatwouldoc­curduringdynamicallytransformingthelayoutsofsuchar­raysbetweentwopartitions.Theapproachthencompares 
cost04andcost02+cost34+overhead23.Iftheformertermis smallerthanorequaltothelatter,theapproachstops,and 
returnstheresultsofthestaticoptimizer(whentheinput istheentirecode)astheoptimizedcode(indicatingthat 
thestaticlayoutoptimizedversionisthebestalternative forthiscode).Ifnot,thismeansthattransformingmemory 
layoutsacrosspartitions(thatis,dynamiclayouttransfor­mation)mightbebenefcialforthecodeinquestion(under 
ourmissestimationmodel).Inthiscase,thealgorithmre­cursivelyappliesthisstrategybydividingthetwopartitions 
inFigure1(c)intofurthersubpartitions.Ateachstepof therecursion,thealgorithmre-computesthetotalnumberof 
misses(consideringtheentirecode)andcomparesthisfgure withthecasebeforetherecursion,andstopstherecursionif 
andonlyiffurtherpartitioningthecoderesultsinahigher costthanthecurrentminimum,orthereisnopossibilityof 
partitioningthecodefurther(notethatourapproachworks onanestgranularity).Duringtheoptimizationprocess,it 
alsokeepstrackofthecurrentminimum. Returningtoourcurrentexample,supposingthatafter thefrstpartitioningstep,cost02+cost34+overhead23< 
cost04,thealgorithmrecordscost02+cost34+overhead23as thecurrentminimum,andfurtherpartitionsthecode.As­sumingthatinthefrstpartition,(v1;v2)isthecutpoint, 
thenthedynamicoptimizationapproachappliesthestatic optimizertotwosubpartitions:onecontainingthenestsv0 
andv1andtheothercontainingonlythenestv2(seeFig­ure1(d)).Thenewtotal(procedure-wide)costiscomputed ascost01+cost22+overhead12+cost34+overhead0 
and 23,iscomparedtothecurrentminimum.Onepointshould benoted.Ingeneral,overhead0 mighbediferent 23tfrom 
overhead23asthestaticoptimizercanreturnadiferent layoutsforsomearraysinv2dependingonwhetheritis workingonv0,v1,andv2(asasinglepartition),oronlyon 
v2.Continuingwiththeexample,assumingthatcost01+ cost22+overhead12+cost34+overhead0 issmallerthan 23 thecurrentminimum,thedynamicapproachselectsthisas 
thecurrentminimum,andthistime,itcheckstheproftabil­ityofsplittingthepartitionthatcontainsthenestsrepre­sentedbyv3andv4.Assumingthatthispartitioningand 
anyfurtherpartitioningofthesubpartitionthatcontains thenestsv0andv1donotbringanybeneft,theapproach stopsandreturnsthethreepartitions(theiroptimizedver­sions)asshowninFigure1(d).Figures1(e)and(f),onthe 
otherhand,showwhatwouldbethecaseiffurtherparti­tioningswerebenefcial.Figure1(e)wouldbethecasehad thedynamicapproachdecidedthatitwouldbebenefcial 
todividethepartitionthatcontainsv3andv4intofurther subpartitions.AsdepictedinFigure1(f),intheextreme 
case,eachnestedloopisplacedintoitsownpartition.  4. CONCLUSIONS Thispaperpresentsadynamiclayoutoptimizationstrat­egytominimizethenumberofcyclesspentinmemoryac­cesses.Inthisstrategy,agivenmulti-dimensionalarrayis 
allowedtohavediferentmemorylayoutsindiferentpartsof theapplicationifdoingsoimprovesdatalocalitybeyondthe 
staticapproachesthatfxmemorylayoutstospecifcforms atcompile-time.Inthisdynamicstrategy,diferentlayouts 
thatagivenarraywillassumeatrun-timearedeterminedat compile-time,howeverthelayoutmodifcations,themselves, 
occurdynamicallyduringthecourseofexecution. 5. REFERENCES <RefA>[1]J.Anderson,S.Amarasinghe,andM.Lam.Dataand 
computationtransformationsformultiprocessors.In Proc.5thACMSIGPLANSymposiumonPrinciples andPracticeofParallelProgramming,July1995. 
[2]U.Banerjee.Unimodulartransformationsofdouble loops.InAdvancesinLanguagesandCompilersfor ParallelProcessing,editedbyA.Nicolauetal.,MIT 
Press,1991. [3]M.CierniakandW.Li.Unifyingdataandcontrol transformationsfordistributedsharedmemory machines.InProc.SIGPLAN'95Conferenceon 
ProgrammingLanguageDesignandImplementation, June1995. [4]M.Kandemir,A.Choudhary,N.Shenoy,P.Banerjee, 
andJ.Ramanujam.Ahyperplanebasedapproachfor optimizingspatiallocalityinloopnests.InProc.1998 ACMInternationalConferenceonSupercomputing, 
July1998. [5]M.Kandemir,A.Choudhary,J.Ramanujam,andP. Banerjee.Improvinglocalityusingloopanddata transformationsinanintegratedframework.InProc. 
InternationalSymposiumonMicroarchitecture,Dallas, TX,December1998,pp.285.296. [6]I.Kodukula,N.Ahmed,andK.Pingali.Data-centric 
multi-levelblocking.InProc.SIGPLAN Conf.ProgrammingLanguageDesignand Implementation,June1997. [7]M.Lam,E.Rothberg,andM.Wolf.Thecache 
performanceofblockedalgorithms.InProc.4th InternationalConferenceonArchitecturalSupportfor ProgrammingLanguagesandOperatingSystems,April 
1991. [8]S.-T.LeungandJ.Zahorjan.Optimizingdatalocality byarrayrestructuring.TechnicalReportTR95-09-01, 
DepartmentofComputerScienceandEngineering, UniversityofWashington,Sept.1995. [9]W.Li.CompilingforNUMAParallelMachines.Ph.D. 
Thesis,ComputerScienceDepartment,Cornell University,Ithaca,NY,1993. [10]K.McKinley,S.Carr,andC.W.Tseng.Improving 
datalocalitywithlooptransformations.ACM TransactionsonProgrammingLanguagesand Systems,1996. [11]M.O'BoyleandP.Knijnenburg.Non-singulardata 
transformations:Defnition,validity,applications.In Proc.6thWorkshoponCompilersforParallel Computers,pages287.297,Aachen,Germany,1996. 
[12]M.WolfandM.Lam.Adatalocalityoptimizing algorithm.InProc.ACMSIGPLAN91Conf. ProgrammingLanguageDesignandImplementation, 
pages30.44,June1991. [13]M.Wolfe.HighPerformanceCompilersforParallel Computing,Addison-WesleyPublishingCompany, 
1996.  </RefA>
			
