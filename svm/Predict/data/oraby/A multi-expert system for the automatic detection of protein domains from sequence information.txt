
 A Multi-Expert System for the Automatic Detection of Protein Domains from Sequence Information Niranjan 
Nagarajan and Golan Yona* Department of Computer Science Cornell University * Corresponding author: golan@cs.cornell.edu 
 ABSTRACT We describe a novel method for detecting the domain struc­ture of a protein from sequence information 
alone. The method is based on analyzing multiple sequence alignments that are derived from a database 
search. Multiple measures are de.ned to quantify the domain information content of each position along 
the sequence, and are combined into a single predictor using a neural network. The output is further 
smoothed and post-processed using a probabilistic model to predict the most likely transition or boundary 
posi­tions between domains. The method was assessed using the domain de.nitions in SCOP for proteins 
of known structures and was compared to several other existing methods. Our method improves signi.cantly 
over the best method avail­able, the semi-manual PFam domain database, while being fully automatic. Our 
method can also be used to verify do­main partitions based on structural data. Few examples of predicted 
domain de.nitions and alternative partitions, as suggested by our method, are also discussed. Categories 
&#38; Subject Descriptors: I.5 Pattern Recog­nition, I.2.6 Learning, H.1.1 Systems and Information The­ory, 
J.3 Life and Medical Sciences Biology and genetics. General Terms: Algorithms, Theory. Keywords: protein 
domains, domain prediction, SCOP, domain boundaries 1. INTRODUCTION One of the .rst steps in analysing 
proteins is to detect the constituent domains or the domain structure of the protein. A domain is considered 
as the fundamental unit of protein structure, folding, function, evolution and design [1, 2, 3]. It combines 
several secondary structure elements and motifs, not necessarily contiguous, which are packed in a compact 
globular structure. It is commonly believed that a domain can fold independently into a stable three 
dimen­sional structure and it has a speci.c function. A protein may be comprised of a single domain or 
several di.erent domains, or several copies of the same domain. It is the do- Permission to make digital 
or hard copies of all or part of this work for personal or classroom use is granted without fee provided 
that copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice 
and the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute 
to lists, requires prior speci.c permission and/or a fee. RECOMB 03, April 10 13, 2003, Berlin, Germany. 
Copyright 2003 ACM 1-58113-635-8/03/0004 ...$5.00. main structure of a protein that determines its function, 
the biological pathways in which it is involved and the molecules it interacts with. Detecting the domain 
structure of a protein is a challeng­ing problem. Given the protein sequence there are no signals or 
signs that indicate when one domain ends and another begins. Structural information can help in detecting 
the do­main structure of a protein. Domain delineation based on structure is currently best done manually 
by experts. The SCOP domain classi.cation [4], which is based on extensive expert knowledge, is an excellent 
example. However, struc­tural information is available for only a small portion of the protein space. 
Therefore, there is a strong interest in de­tecting the domain structure of a protein directly from the 
sequence. In our study we de.ne a domain to be a continuous se­quence that corresponds to an elemental 
building block of protein folds -a subsequence that is likely to be stable as an independent folding 
unit. As such we believe that this build­ing block was .rst formed as an independent protein with a speci.c 
acquired function. In the course of evolution, the do­main might have been combined with additional domains 
to perform other, possibly more complex functions. However, if the domain indeed existed at some point 
as an indepen­dent unit, then it is likely that traces of the autonomous unit might exist in other database 
sequences, possibly in lower organisms. Thus a database search can sometimes provide us with ample information 
on the domain structure of a protein. For example, the histogram and pro.le of sequence matches one can 
obtain from a database search may help to detect domain boundaries [5, 6, 7]. However, one should be 
cautious in analysing database matches in search for such signals. One possible di.culty arises from 
the fact that pairs of sequence domains may appear in many related se­quences, thus hindering the ability 
to discern the two apart. Furthermore, mutations, insertions and deletions blur do­main boundaries and 
make it hard to distinguish a signal from background noise. 1.1 Related studies Previous methods for 
sequence-based domain detection could be roughly classi.ed into four categories: (i) Methods based on 
the use of similarity searches and knowledge of se­quence termini to delineate domain boundaries using 
heuris­tics. Methods like MKDOM [8], Domainer [9], DIVCLUS [10] and DOMO [11] fall in this category. 
These methods were designed to partition all the proteins in a database into domains but they are in 
general less accurate due to their heuristic nature. (ii) Methods that rely on expert knowl­edge of protein 
families to construct models like HMMs to identify other members of the family. PFam A [12, 13], TigrFam 
[14] and SMART [15] fall in this category. These methods are considerably more accurate but are restricted 
by their ability to make predictions only for well studied families. (iii) Methods that try to infer 
domain boundaries by using sequence information to predict tertiary structure .rst. SnapDragon [16] and 
Rigden s covariance analysis [17] are examples of this approach. These methods use novel sources of information 
but are computationally expensive. (iv) Methods that use multiple alignments to predict do­main boundaries 
such as PASS [6] and Domination [7]. (v) Other methods, that do not fall into any of the previous categories 
(clustering sequence alignments [18] and domain guess by size [19]). There is no .xed, universally accepted 
set of rules for par­titioning a protein into its constituent domains. Therefore it is hard to assess 
the quality of domain predictions by any of the above algorithms.In the absence of a common framework 
for analyzing the quality of domain predictions, the various works that we have mentioned above have 
relied on a variety of qualitative and quantitative evaluation criteria, external resources and manual 
analysis to verify domain boundaries and study the capabilities of their systems. For example, the quality 
of domain predictions in DOMO is analyzed by taking domain annotations in PIR [20] and SwissProt [21] 
as being the standards of truth, and comparing the predictions to ProDom predictions. However, their 
analysis is based only on a few selected examples.Others, such as Domina­tion and Rigden s covariance 
analysis, run a more extensive evaluation based on comparisons with structure-based do­main de.nitions 
as in SCOP [22] but they did not evaluate the capabilities of other methods with this setup. The diversity 
of evaluation criteria has made it impossible to objectively compare the various methods for domain pre­diction. 
Here we propose and use a common framework to evaluate the various methods. This framework is based on 
using de.nitions from the SCOP database as the standard of truth. In addition we devise scores that can 
be used in a uniform and unbiased fashion to evaluate the accuracy and coverage of the various methods. 
Despite the large number of studies, the task of construct­ing an accurate and e.cient general-purpose 
domain detec­tion system that works solely on sequence information is still an open problem. While methods 
like SMART and Tigr-Fam are accurate, they require careful manual inspection and provide predictions 
for a small subset of the sequence database. On the other side of the spectrum, methods like DOMO and 
ProDom are fully automatic and give predic­tions for nearly all proteins in the sequence database, but 
are not su.ciently accurate. In this paper we suggest a novel approach that incorporates many of the 
salient features of earlier systems into a probabilistic framework that is exten­sible and is based on 
rigorous analysis of information sources in order to predict domain boundaries with high accuracy and 
coverage. The paper is organized as follows. We .rst describe the data set, scores and our learning methodology 
in detail. We then present the results of testing our method on a large collection of proteins with known 
structures and compare our predictions to structure based domain de.nitions as well as to other sequence 
based domain partitioning methods. We conclude with a few examples.  2. METHODS Given a query sequence, 
our algorithm starts by searching a large sequence database and generating a multiple align­ment of all 
signi.cant hits. The columns of the multiple alignment are analyzed using a variety of sources, to de.ne 
scores that re.ect the domain-information-content of align­ment columns. Information theory based principles 
are em­ployed to maximize the information content. These scores are then combined using a neural network 
to label single columns as core-domain or boundary positions with high accuracy. The output of the arti.cial 
neural network is then post-processed to smooth and re.ne predictions while con­sidering local information 
from multiple columns. Finally, we introduce the domain-generator model that uses global information 
about the distribution of domain sizes and se­quence divergence to test multiple hypotheses, .lter out 
po­sitions that are incorrectly predicted as boundary positions and output the most likely partition. 
An overview of our method is depicted in Fig. 1. We now turn to describe our method in detail.  Figure 
1: (a) Overview of the domain prediction system. 2.1 The data sets 2.1.1 The query data set In the absence 
of general rules or principles that de.ne domain boundaries, one must rely on existing knowledge of protein 
domains, to devise a reliable and accurate methods for automatic domain detection. One of the most extensive 
collections of protein domains is the one provided by the SCOP classi.cation of protein structures [22]. 
The domains in this database are de.ned from PDB records [23]. To train and test our method we selected 
complete pro­tein chains from PDB, searched the database and generated multiple alignments. About half 
of these alignments with their corresponding domain structure as de.ned by SCOP were used for training. 
The other half was used for testing. Our initial dataset was the set of protein sequences in the PDB 
database as of May 2002 with 35,184 protein chains, and 11,969 non-identical sequence entries. All sequences 
shorter than 40 amino acids and fragments of longer se­quences were eliminated and of all sequences that 
are more than 95% identical only a single representative was retained, yielding a total of 4,810 valid 
queries. 2.1.2 Alignments Each one of the 4810 queries was searched against a com­posite non-redundant 
database that contains 933,075 unique sequence entries. The database is composed from 97 di.er­ent databases 
among which are SwissProt, TrEMBL, PIR, PDB, SCOP, DBJ, GenBank, REF, PATAA, PRF and the complete genomes 
of 78 organisms. All entries that are documented as fragments (according to at least one source database) 
were eliminated, leaving a total of 693,912 non­fragmented entries. The alignment was created in two 
phases. First, the query was searched against the non-redundant database using BLAST [24] and the related 
sequences were compiled into a database (a di.erent database for each query sequence). In the second 
phase, the query was searched against this smaller database, using PSI-BLAST [24] until convergence. 
Of these alignments, fragmented queries were eliminated and only alignments with more than 20 hits were 
kept. Finally, the query sequences were grouped into clus­ters (using the ProtoMap clustering algorithm 
[25] with a conservative e-value threshold) and from each group only one representative was selected 
(the one with the maximal number of database aligned sequences). The .nal set of queries consisted of 
3,140 PDB sequences, with their cor­responding alignments. Alignments are represented as a se­quence 
of alignment columns with each one being associated with one position in the seed sequence (insertions 
respective to the seed sequence are processed as described in section 2.2.3). 2.1.3 Domain de.nitions 
The domain de.nitions are retrieved from the SCOP database, version 1.57 as of May 2002. Of the 3,140 
PDB queries, 3,039 were documented in this list, with the number of domains ranging from 1 to 7. In a 
.nal pruning step, protein chains that are less than 90% covered by SCOP domains are elimi­nated. In 
the .nal data set we retained all the multi-domain proteins (605) and one-fourth of the single domain 
proteins (576) to ensure an equal representation of both. For eachprotein chainwe de.nedthe domain positions 
to be the positions that are at least x residues apart from a domain boundary. Domain boundaries are 
obtained from SCOP de.nitions where for a SCOP de.nition of the form (start1,end1)..(startn,endn) the 
domain boundaries are taken to be (endi + starti+1)/2. All positions that are within x residues from 
domain boundaries are considered boundary positions. This process allows us to classify all the posi­tions 
in the proteins being considered as domain or bound­ary positions.  2.2 The domain-information-content 
of an align­ment column To quantify the likelihood that a sequence position is part of a domain, or at 
the boundary of a domain we de.ned several measures based on the multiple alignment that we believe re.ect 
structural properties of proteins and would therefore be informative of the domain structure of the seed 
protein. 2.2.1 Conservation measures Amino acid entropy: Multiple alignments of protein families can 
expose the core positions along the backbone that are crucial to stabilize the protein structure, or 
play an important functional role (as in the active site or in an interaction site). These positions 
tend to be more conserved than others and strongly favor amino acids with similar and very speci.c physio-chemical 
properties, because of struc­tural and functional constraints. One possible measure of the conservation 
of an alignment column is given by the entropy of the corresponding distribution. For a given prob­ability 
distribution P over the set A of the 20 amino acids P =(p1,p2, ..., p20)t, the entropy is de.ned as 20 
. Ea(P)= - pi log2 pi i=1 For a given alignment column, the probability distribution P is de.ned from 
the empirical counts, after adding pseudo counts as described in [26]. Class entropy: Quite frequently 
one may observe posi­tions in protein families that have a preference to a class of amino acids, all 
of which have similar physio-chemical properties. The amino acid entropy measure is not e.ec­tive in 
such cases since it ignores amino acid similarities. An entropy measure based on suitably de.ned classes 
may capture positions with subtle preferences towards classes of amino acids. The classes we use are 
sulphur (CM), sim­ple aliphatic (AL), side-chain restrictive aliphatic (IV), aro­matic (FWY), hydroxyl 
(ST), amide (NQ), acidic (ED), Ba­sic (KRH), proline (P) and glycine (G). This classi.cation (Linda Nicholson, 
personal communication) worked better than other classi.cations that we found in the literature [27, 
28]. Given the set C of amino acid classes and the empirical probabilities (with pseudo counts) P the 
class entropy is de.ned in a similar way to the amino acid entropy . Ec(P)= - pi log2 pi i.C Evolutionary 
pressure: The class entropy is one possi­ble solution to the aforementioned problem, however, it does 
not utilize all the prior information we have about amino acid similarities. A better entropy measure 
would consider the mutual information (similarity) of the amino acids. To the best of our knowledge, 
this problem has never been ad­dressed directly before. A possible extension may generalize upon the 
results of [29]. Alternatively, we suggest a measure that estimates the evolutionary pressure in an alignment 
col­umn by calculating the evolutionary span, approximated by the sum of pairwise similarities of amino 
acids in a column. Speci.cally, if the number of sequences participating in an alignment column k is 
n then the span of this column is de.ned as .. 2 n Span(k)= s(aik,ajk) n(n - 1) i=1 j<i where aik is 
the amino acid in position k of sequence i and s(a, b) is the similarity score of amino acids a and b 
according to a scoring matrix such as BLOSUM50 [30]. 2.2.2 Consistency and correlation measures Since 
protein domains are believed to be stable building blocks of protein folds, it is reasonable to assume 
that all ap­pearances of a domain in database sequences will maintain the domain s integrity. Integrating 
the information from multiple sequences can generate a strong signal, indicative of domain boundaries 
by detecting changes in sequence partic­ipation and evolutionary divergence. Several di.erent mea­sures 
are tested. These measures quantify the correlation and consistency of neighboring columns in an alignment. 
Consistency: This simple coarse-grained measure is based on sequence counts. The measure is de.ned as 
the di.erence in sequence counts of a column and the average of the sur­rounding columns in a window 
of size w.If ck is the sequence count in position k then 1 . Consistency(k)= |ck - ci| 2w i =k,|i-k|=w 
Asymmetric correlation: This is a more re.ned mea­sure that considers the consistency of individual sequences 
and sums their contributions. To measure the correlation of two columns we .rst transform each alignment 
column into a binary vector of dimension n (the number of sequences in the alignment) with 1 s signifying 
aligned residues and 0 s for gaps. Given two binary vectors iu and iv their asymmetric correlation (bitwise 
AND) is de.ned as n . Corra(iu,iv)=<iu,iv>= ui ·vi i=1 High correlation values re.ect consistent sequence 
partici­pation while low correlation values signal a region of ambigu­ous sequence participation and 
possible domain boundaries. Symmetric correlation: the asymmetric correlation does not reward for sequences 
that are missing from both posi­tions. However, these may reinforce a weak signal based only on participating 
sequences. The symmetric correlation corrects this by using bitwise XNOR when comparing two alignment 
columns, i.e. n . Corrs(iu,iv)= d(ui,vi) i=1 where d is the delta function d(x, y)=1 .. x = y To enhance 
the signal and smooth random .uctuations the contributions of all positions in a local neighborhood around 
a sequence position are added, and all correlation measures for an alignment column are calculated as 
the average cor­relation over a window of size w centered at the column (the parameter w is optimized, 
as described in section 2.4). Sequence termination: sequence termination is a strong signal of a domain 
boundary. However, in a multiple align­ment it is not necessarily indicative of a true sequence ter­mination. 
Although we eliminated all sequences that are documented as fragments from our database, the sequence 
may still be a fragment of a longer sequence without be­ing documented as such. Moreover, the termination 
may be premature, as end loops are often loosely constrained and tend to diverge more than core domain 
positions. These di­verged subsequences may be omitted from the alignment if they decrease the overall 
similarity score. Therefore the se­quence termination signal may be misleading if used simple­mindedly. 
To reduce the sensitivity to sparse signals due to the aforementioned problems with sequence termination, 
we consider all participating sequences in a position with their evalues (that indirectly indicate alignment 
s reliability). For every position we calculate right and left termination scores, based on sequences 
that terminate and originate from that position respectively, by taking the sum of the log of the corresponding 
evalues. For example if an alignment position has n sequences, of which c terminate at that position 
and the e-values of the corresponding alignments are e1,e2, ..., ec then the left termination score is 
de.ned as Eleft termination =log(e1 ·e2 ·····ec) The left and right termination scores are .rst smoothed 
over a window and then multiplied for each position to get the sequence termination score. 2.2.3 Measures 
of structural .exibility Indel entropy: In multiple alignment of related sequences positions with indels 
with respect to the seed sequence indi­cate regions where there is a certain level of structural .ex­ibility. 
The larger the number of insertions and the more prominent the variability in the indel length at a position 
the more .exible we would expect the structure to be in that region. Such structural variability is more 
likely to oc­cur near a domain boundary where the structure is usually exposed and less constrained. 
To quantify the structural variability or vulnerability of a position we de.ne the indel entropy based 
on the distribution of indel lengths as . Eg(P)= - pi log2 pi i where the pi are the various indel lengths 
seen at a position. Correlated mutations: Another source of information about the structural .exibility 
of a position can be obtained from the pro.le of predicted contacts in a protein. For each sequence position 
we count the number of pairwise contacts between residues that reside on opposite sides of that po­sition 
(see also [17]). Minimas in the pro.le correspond to regions where fewer interactions occur across these 
se­quence positions, implying relatively higher structural .ex­ibility and suggesting a domain boundary. 
Contacts between residues in a protein are usually pre­dicted based on correlated mutations. The correlated 
muta­tion score between two columns is de.ned as in [31]. Specif­ically, the correlation coe.cient for 
two positions k and l is de.ned as Corrm(k, l)= .. 1 nn(s(aik,ajk)-<sk >)(s(ail,ajl)-<sl >) n2 sk ·sl 
i=1 j=1 where aik is the amino acid in position k of sequence i and s(a, b) is the similarity score of 
amino acids a and b according to the scoring matrix. The term <sk > is the average similarity in position 
k and sk is the standard deviation. n is the number of sequences that participate in both columns. To 
predict a contact based on a correlated mutation score one needs a reliable statistical signi.cance measure 
to dis­cern true correlations from random coincidental regularities. To assess the statistical signi.cance 
of correlated mutations we calculated the correlation score for a large collection of random alignment 
columns. Based on the distribution of the random scores we associate a z -score with each correlated 
mutation score1 . We used the correlated mutation information to design two types of scores. In the .rst 
case we considered correlated mutation values that were larger than those in the random distribution 
as indicating contacts. The number of contacts across every position is then normalized by the total 
number of possible contacts to generate a contact pro.le. The other score was based on considering all 
the values as contacts but weighting them by the z-score to get a weighted pro.le. 2.2.4 Residue type 
based measures Physio-Chemical properties of proteins may also help in predicting domain boundaries since 
they tend to have dif­ferent characteristics around domain transition points than in domain core positions. 
For example, hydrophobic residues tend to cluster inside domain cores with hydrophillic residues occupying 
more exposed locations in a protein structure and therefore more likely to be in inter-domain regions. 
Simi­larly, certain amino acids such as cystines and prolines are crucial in de.ning protein structure 
and therefore tend to oc­cur in di.erent frequencies in core domain and inter-domain regions of a protein. 
In order to exploit these sources of information we de.ned several measures; for hydrophobic­ity, molecular 
weight and for the amino acids cystine, va­line, proline and glycine, all believed to be instrumental 
in de.ning protein structure. In addition we also used the Rasmol classi.cation of amino-acids to create 
a set of non­redundant classes that we use as measures (acyclic [ARND-CEQGILKMSTV], aliphatic [AGILV], 
aromatic [HFWY], buried [ACILMFWV], hydrophobic [AGILMFPWYV], large [REQHILKMFWY], negative [DE], positive 
[RHK], small [AGS]). For each measure, the score of an alignment column is de.ned as the average of all 
residue scores, where residue scores are de.ned in the range of 0-1 (hydrophobicity and molecular weight 
are adopted from [32] and class scores are simply de.ned by the relative frequency of the residues in 
the class). 2.2.5 Predicted secondary structure information Protein structure is often studied at the 
level of secondary structure. Most inter-domain regions are composed of loops while beta strands tend 
to form sheets that constitute the core of protein domains. Alpha helices and beta sheets in proteins 
are relatively rigid units and therefore domain boundaries rarely split these secondary structure elements. 
Indeed, in the study by [33] a domain delineation algorithm was developed that was based on the clustering 
of secondary structure units. This algorithm was applied to proteins of known structure, and used the 
available structural informa­tion to de.ne the secondary structure elements. However, useful information 
regarding the secondary structure of a protein can be obtained even when the structure is unknown. We 
used the neural network based program PSIPRED [34] to predict the secondary structure of the seed protein. 
The neural network con.dence values in the range 0-1 were then used as alpha helix (alpha), beta strand 
(beta) and coiled region (coil) measures. 1Random columns are generated by choosing a root residue at 
random and mutating it according to transition probabil­ities, derived from the BLOSUM50 matrix, to generate 
the other residues in the column. 2.2.6 Intron-exon data It is well known that the alternative splicing 
mechanism is used extensively in higher organisms to generate multiple mRNA and protein products from 
the same DNA strand. This mechanism raises an interesting combinatorial prob­lem. By sampling (and sometimes 
shu.ing) the set of ex­ons encoded in a DNA sequence, the cell generates di.erent proteins that share 
di.erent numbers of exons. Intron-exon data at the DNA level is believed to be corre­lated with domain 
boundaries [35, 36]. As building blocks, domains are believed to have evolved independently. There­fore 
it is likely that each domain has a well de.ned set of exons associated with it. If the product protein 
is a multi­domain protein we expect exon boundaries to coincide with domain boundaries. The Intron-exon 
data was derived from the EID database [37]. Only genes that were experimentally determined (based on 
the header information) were included in our analysis (a total of 25,130 sequences, and 21,042 entries 
after eliminat­ing redundancy). Each seed sequence was compared with all the EID sequences, and all signi.cant 
ungapped matches were recorded. To quantify the likelihood of an exon bound­ary we use a similar equation 
as in sequence termination. Speci.cally, if an alignment position has n sequences, of which c coincide 
with exon boundaries and the e-values of the corresponding alignments are e1,e2, ..., ec then the exon 
termination score is de.ned as Eexon =log(e1 ·e2 ·····ec)  2.3 Score re.nement and normalization Two 
additional steps are executed before the measures are fed into the neural network. First, they are smoothed 
to eliminate random local .uctuations and improve the dis­crimination power of the measure. The scores 
are smoothed by calculating the average over a window of size w (the smoothing factor). This parameter 
is optimized to max­imize the separation between the two types of positions, as described in the next 
section. Second they are normalized to a single scale. To scale all measures to the same units we transformed 
every score to a z-score based on the distribution of scores along all align­ment positions. The normalization 
is invoked separately for each alignment. The z-score does not only serve as a uni­versal scale but also 
provides a measure of statistical signif­icance for each position in the alignment, helping to locate 
extreme a-typical positions. 2.4 Maximizing the information content of scores To improve domain recognition, 
the distributions of do­main positions and boundary positions (according to each of the domain-information-content 
measures suggested above) must be well separated. However, it is hardly ever the case that the two distributions 
are completely disjoint, and the parameters introduced before (the boundary window size x and the smoothing 
factor w) may greatly a.ect the separa­tion of these distributions. To de.ne the best set of parameters 
we measured the sta­tistical similarity of the two probability distributions for dif­ferent sets of parameters, 
and selected the one that maxi­mized separation. To measure statistical similarity we used the Jensen-Shannon 
(JS) divergence between probability dis­tributions [38]. This is a variation over the KL divergence measure 
[39], that is both symmetric and bounded (unlike the KL divergence). Formally, given two (empirical) 
proba­bility distributions p and q, for every 0 = . = 1, the .-JS divergence is de.ned as JSKLKL D[p||q]= 
.D[p||r]+(1 - .)D[q||r] . where r = .p+(1-.)q canbe consideredas the most likely common source distribution 
of both distributions p and q, with . as a prior weight. In our case, the priors for in-domain positions 
p and boundary positions q di.er markedly, and . is set to the prior probability of in-domain positions. 
We call the corresponding measure the divergence score. Distribution of sequence termination scores 0.8 
0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Z-score Distribution of aliphatic residue scores 0.25 0.2 0.15 0.1 0.05 
0 Z-score Figure 2: Distributions of sequence termination scores (a) and aliphatic residue scores (b) 
Two examples of score distributions are given in Fig. 2. Even measures with identical distributions may 
be infor­mative in a mutli-variate model, where higher level corre­lations can generate an e.ective boundary 
surface. How­ever, to simplify the .nal model, only measures that in­duce di.erent distributions of scores 
for domain positions and boundary positions are considered for further analysis. The optimal complex 
decision boundary is learned by train­ing a neural network as described next. The measures that are used 
to train the network and their Jensen-Shannon di­vergence are given in Table 1. Although better separation 
was obtained with individual boundary windows, the .nal boundary window was uniformly set to x =10 (experiments 
with smaller window sizes decreased .nal prediction accu­racy) and the smoothing window w was set individually 
for each score based on the optimization of the Jensen-Shannon divergence. Probability Probability 
Score Smoothing Jensen-Shannon window divergence Alpha 4 0.008 8 0.008  Acyclic 7 0.010 Indel Entropy 
10 0.010 Consistency 8 0.010 Small 10 0.015 Glycine 10 0.020 Introns Class Entropy 10 0.024 8 0.034 
 Weighted Mutation Pro.le 10 0.048 Proline 10 0.095 Symmetric Correlation Sequence Termination 7 0.542 
Table 1: Jensen-Shannon divergence for di.erent scores. The JS divergence for identical distributions 
is 0. 2.5 The learning model Each one of the measures we described in section 2.2 cap­tures some aspects 
or properties of domain transition sig­nals. To .nd the optimal combination we trained a neu­ral network 
over the domain information content scores. A neural network is capable of learning complex non-linear 
de­cision boundaries between categories, and therefore seems to be most suited for this task (an alternative 
model to try would be SVMs). The inputs used were the individual scores in a position, and the output 
learnt is a number between 0 and 1, where 0 corresponds to a transition point and 1 to a domain. The 
network was trained using the Matlab neural nets toolbox, on a set of 484 proteins with a valida­tion 
set of 237 proteins and a test set of 460 proteins. The neural network is a feed-forward network trained 
using the back propagation algorithm with tangent sigmoid activation function. The best network takes 
in 12 inputs and has two hidden layers with 10 and 15 neurons respectively. It accu­rately predicts 94% 
of the core-domain positions and 88% of the transition points in the test set. Since a domain transition 
point is not singular we also tried to learn more complex networks that map multiple in­puts (several 
positions along the sequence) to multiple out­puts. However, performance-wise, the basic network (map­ping 
a single sequence position to a single output) performed the best. This might change as more data becomes 
available.  3. HYPOTHESIS EVALUATION The neural network does not take into account the infor­mation 
from neighboring positions while making a decision (attempts to learn local neighborhoods in the input 
space to local neighborhoods in the output space failed to improve the performance). Thus, despite the 
high rate of accurate predictions for single positions, the .nal predictions may overly fragment proteins 
into domains. We experiment with two post-processing setups. 3.1 The simple model In the simple model, 
to re.ne the putative predictions of the neural-net the following two steps are employed. First, a position 
is predicted as transition point only if a signi.­cant fraction of the positions in a window centered 
around it are predicted as putative transition points by the neural-net (the threshold can be altered 
to give di.erent levels of ac­curacy and sensitivity). Second, transition points are listed in decreasing 
order of reliability (as measured by the depth of the corresponding minima in the smoothed curve) and 
all minima that are within a window of 30 amino acids from predicted transitions are rejected. 3.2 The 
domain-generator model Given multiple hypotheses, i.e. putative partitions of the query sequence into 
domains we would like to .nd the most likely one. The domain-generator model assumes a random generator 
that moves repeatedly between a domain state and a linker state and emits one domain or transition at 
a time according to di.erent source probability distributions. Thus the probability of a sequence of 
domains is given by the product of domain-emission probabilities and the transition probabilities Formally, 
we are given a protein sequence S (a multiple alignment) of length L and a possible partition D of S 
into n domains D = D1,D2, .., Dn of lengths l1,l2, ..., ln (as sug­gested by the output of the neural-net). 
Our goal is to .nd the most likely model, i.e. the partition that maximizes the posterior probability 
of the model given the data P (D/S) We calculate the posterior probability by relying on esti­mating 
the likelihood of the data given the partition P (S/D) from the precalculated measures described in section 
2.2 and then applying Bayes formula: P (S/D)P (D)P (D/S)= P (S) The denominator is .xed for all hypotheses, 
thus we are looking for the partition that will maximize the product of the likelihood P (S/D)and the 
prior P (D) To calculate the prior P (D) wehave toestimatethe prob­ability that an arbitrary protein 
sequence of length L will consist of d domains of the speci.c lengths l1,l2, ..., ln.What we need to 
calculate then is P (D)= P ((D1,l1)(D2,l2)...(Dn,ln) s.t.l1 +l2 +..+ln = L) This can be estimated from 
the data by considering known domain partitions of proteins of length L. However, the amount of data 
available is not enough to accurately esti­mate these probabilities for all possible partitions. We ap­proximate 
this probability by using a simpli.ed model; given the length of the protein, the generator selects the 
number of domains .rst and then selects the length of one domain at a time, considering the domains that 
were already gen­erated. For a partition into n domains there are n! possible orderings of the domains, 
therefore the prior probability of the partition is approximated by P (D) Prob(n/L) · n-2 .. P0(l1/L)P0(l2/L 
-l1)...P0(ln-1/L - li) p(l1,l2,..,ln)1 where Prob(n/L) is the prior probability that a sequence of length 
L constitutes of n domains and P0(li/L) is the prior probability to emit a domain of length li given 
a sequence of length L.The term p(l1,l2, .., ln) denotes all possible permutations of l1,l2, .., ln. 
The prior probabilities P0(li/L) are approximated by P0(li), normalized to the relevant range [0..L], 
and are estimated from the distribution of domain lengths in the SCOP database2 . 2Ideally, we would 
like to use P0(li/L). However, the SCOP data set is very noisy and the resulting distributions are heavily 
biased towards the domain de.nitions in SCOP. We are currently working on improving these estimates. 
The second term, Prob(n/L)is given by Prob(n/L)= Prob(n, L)/P (L)where Prob(n, L)is estimated by the 
(n - 1)th order sum LLL ... Prob(n, L)= P0(x1) P0(x2)... P0(xn-1) · 11 1 ·P0(L -x1 -x2 -... -xn-1) and 
P (L) is simply given by the complete probability for­mula L . P (L)= Prob(i, L) i=i To calculate the 
likelihood of the data given the model P (S/D) we use the probabilities of the observed scores given 
the domain structure as predicted by the neural-net. We consider the individual domains and the transitions 
between domains (the linkers) as two di.erent sources. Each source induces a unique probability distribution 
over the domain­information content scores (see section 2.2). Speci.cally, given the model D that partitions 
the sequence S into n do­mains and n -1 transitions D1,T1,D2,T2, ..Tn-1,Dn that correspond to the subsequences 
s1,t1,s2,t2, ...tn-1,sn we es­timate the likelihood by P (S/D)= P (S/D1,T1,D2, ..Tn-1,Dn) = P (s1/D1)P 
(t1/T1)P (s2/D2) · ·P (t2/T2)...P (tn-1/Tn-1)P (sn/Dn) where we already employed the assumption that 
the do­mains are independent of each other. Each one of the terms P (si/Di)and P (tj/Tj ) is a product 
over the probabilities of the individual positions. The probability on an individual position j in domain 
i is estimated by the joint probability distribution of the 12 features that are used in our system P 
(sij /Di)= P (f1,f2, ...f12 /Di) However, estimating this probability is impractical given the amount 
of data we have. On the other hand, given the cor­relation between scores (see section 4.1) the independence 
assumption for the individual scores does not hold. There­fore we adopt an intermediate approach. We 
start by writing the exact formulation of the joint probability distribution of k random variables X1,X2, 
.., Xk using the expansion P (X1,X2, .., Xk)= P (X1)P (X2/X1)P (X3/X1,X2) ··· ···P (Xk/X1,X2, .., Xk-1) 
where the random variables can be ordered in an arbitrary order. To derive a sensible approximation of 
these prob­abilities we use .rst-order dependencies3 and employ the following heuristic. For each pair 
of random variables X, Y we calculate the distance between the joint probability dis­tribution and the 
product of the marginal probability dis­tributions DEP EN(X, Y ) =Dist(PXY ,PX PY ) This distance (measured 
either using the l1 norm or the JS divergence measure) is a measure of the dependency between the two 
variables. The larger it is, the more dependent are 3Pair statistics can be calculated quite reliably 
from our data set, but the data is too sparse to derive reliable esti­mates of higher order statistics 
the variables (one might also consider using the mutual in­formation measure instead). We sort all pairs 
based on their distance and pick the most dependent one .rst (denoted by Y1 and Y2) to start the expansion 
P (X1,X2, .., Xk)= P (Y1)P (Y2/Y1)....... The next terms are selected based on their strongest depen­dency 
with variables that are already used in the expansion. Thus Y3 =arg max{max{DEP EN(Y, Y1), DEP EN(Y, 
Y2)}} Y Denote by Z = P ILLAR(Y ) the random variable that Y is most dependent on (of the random variables 
that are already in the expansion), then of all possible dependencies involving Y3 we pick P (Y3/P ILLAR(Y3)) 
and add it to the expansion P (X1,X2, .., Xk)= P (Y1)P (Y2/Y1)P (Y3/P ILLAR(Y3))..... The procedure continues 
until all variables are accounted for. This heuristic attempts to minimize the errors that are intro­duced 
by relaxing the dependency assumption to a .rst or­der dependency by maximizing the support for each 
random variable we introduce in the expansion. Thus, highly corre­lated variables a.ect the total probability 
only marginally, while under the independence assumption they might in­troduce a substantial error (other, 
alternative methods for approximating the joint probability distribution from the marginal distributions 
are described in [41] and [42] and we are currently testing their e.ect on our estimates). Note that 
the expansion for domain regions can be di.erent from the expansion for linker regions, as the source 
distributions di.er. However, once the two expansions (for domains and linkers) are de.ned based on the 
pair statistics, the same expansions are used for all domains and all linkers. Finally, given a set of 
N putative transition points (as described in section 3), our algorithm enumerates all pos­sible combinations 
of transition points to form 2N possible partitions (hypotheses). For each partition we calculate the 
posterior probability and eventually output the most likely one. The whole calculation is very fast. 
For example, for a protein of length L = 300 and set of N = 10 possible tran­sition points, the algorithm 
will output the most probable hypothesis in a matter of minutes.  4. RESULTS To test our approach we 
run our system on a subset of 460 proteins that were excluded from the training set. For each of these 
proteins the prediction was compared to that of SMART [15], Pfam [12, 13], ProDom [9] and Tigr [14], 
based on the information provided by InterPro [43] as well as predictions from DOMO [11] obtained by 
running BLAST searches against the DOMO database. Since the predictions obtained from other systems are 
often incomplete for the seed proteins in our test set, we needed to design an evaluation procedure that 
would have di.erent scores for accuracy and coverage. In addition, the predictions may disagree with 
SCOP on the number of do­mains in the seed protein. Therefore one needs to de.ne an algorithm for associating 
predicted transition points with their most probable SCOP counterparts and vice versa. The simplest choice 
is to assign every transition point that is be­ing considered to the closest reference transition point. 
Here we adopt this model4 and de.ne the following four measures. Distance accuracy. This measure evaluates 
predictions by using SCOP transition points as reference. For each seed protein we calculate the average 
distance of the predicted transitions from their associated SCOP transition points. The .nal value that 
is reported is the average distance over all proteins in the test set. Distance sensitivity. This measure 
assesses the sen­sitivity in detecting true domain boundaries by using the predicted transitions as reference. 
The average distance of SCOP transitions from the associated predicted transitions is calculated for 
each protein, with the value reported being the average of this distance over all proteins in the test 
set. Selectivity. For this measure we consider predictions that are within x = 10 residues of a SCOP 
transition as being correct with the .nal value reported being the per­centage of predictions that are 
considered correct for the entire set. Coverage. Analogous to accuracy, SCOP transitions that are associated 
with a predicted transition point within x = 10 residues are considered successfully predicted. The percentage 
of correctly predicted SCOP transitions for the entire set is reported. The results of our tests are 
summarized in Table 2. To assess the impact of the di.erent components of our model two di.erent sets 
of numbers are given; for the simple model and for the domain-generator model as described in section 
3. Note that our method outperformed other methods in terms of the de.ned measures, even the manually 
calibrated Pfam, while being fully automatic5 . Number of Accuracy/Sensitivity Selectivity/Coverage predictions 
(in residues) (percentages) simple model 460 26/7 66/82 domain-generator 460 27/6 63/83 HMMPfam 441 29/14 
43/65 BlastDomo 252 17/70 22/12 HMMSmart 172 12/73 27/17 BlastProDom 123 8/90 30/6 HMMTigr 51 2/96 33/1 
 Table 2: Performance evaluation results. . It is important to note that although the domain-generator 
model does not improve over the simple model, as measured by the four performance indices described above, 
it is a bet­ter model overall. Speci.cally, the domain-generator model provides us with a critical statistical 
framework for assessing alternative, competing hypotheses. The model can be used to assign a con.dence 
value to each hypothesis, and by com­paring these con.dence values (between the best hypothesis and the 
next best hypothesis or the set of all other hypothe­ses) one can de.ne a signi.cance measure and associate 
it with the output hypothesis. In cases where the di.erences between competing hypotheses are insigni.cant, 
one might want to consider also alternative hypotheses. 4We are currently working on developing a more 
sophisti­cated association scheme. 5Pfam is actually using the SCOP de.nitions (when avail­able) to determine 
their domain de.nitions. Their perfor­mance therefore may not be as good over an independent data set. 
4.1 Examples The overall performance of our method shows that the model is capable of learning even subtle 
signals that indicate domain boundaries. Our .rst example is a four domain pro­tein that was predicted 
accurately for all its domains. This is the PDB protein 2gep, 497 residues long. The protein is partitioned 
by SCOP into four domains that correspond to positions 8-72, 73-272, 273-352 and 353-497. Our pre­diction 
suggests transition points at positions 75, 270 and 352 (see Fig. 3) within 3 residues from SCOP de.nitions. 
These positions are correlated with strong sequence termi­nation and correlated mutations signals. It 
should be noted that the sequence termination measure is quite noisy in this case because of a complex 
alignment, and there are incor­rect signals at positions 160, 240, 300, 420, 440 and 460. However, our 
system successfully rejected these transitions. For comparison, PFam predicts three domains between po­sitions 
1-67, 273-345 and 356-425 (nitrite/sul.de reductase ferrodoxin-like half domain at 1-67 and 273-345, 
and nitrite and sul.te reductase at 356-425). DOMO predicts a single domain (positions 1-481). No predictions 
are available from ProDom, SMART or Tigr. Figure 3: (a) Domain de.nitions for 2gep. Our method predicts 
four domains. The transition points are marked by their residue number (note that positions are o.set 
by 81 since the .rst residue in the PDB .le is numbered as residue 81). Another example where our method 
correctly predicted all the domain transition points is for the protein 1a8y. How­ever, in this case 
none of the other sequence-based predic­tions (including Pfam) were able to partition the protein correctly. 
This protein is 367 amino acids long, and accord­ing to SCOP it consists of three independent domains, 
be­tween positions 3-126, 127-228 and 229-347 (see Fig. 4). No clear distinction is made in SCOP regarding 
their di.erent functional role. Our prediction locates domain boundaries at positions 125 and 225, within 
4 residues from the SCOP de.nition. According to Pfam, the main domain (Calsequestrin) is lo­cated between 
positions 1 and 362, transcending the struc­tural domain boundaries. Domo predicts one domain be­tween 
positions 1 and 335. No predictions are available from ProDom, SMART or Tigr. Detailed analysis of our 
system in this case reveals sequence termination signals at positions 30, 120, 130, 210, 230, 270 and 
280 (with signals at 230, 280 and 120 being dominant), three major entropy peaks at 70, 120 and 210 and 
a proline rich region between positions 210 and 240 (that corresponds to a sharp turn in the structure). 
Major correlation troughs are also detected at positions 40, 120-140 and 260 (data is not presented graphically 
because of limited space). Figure 4: (a) Domain de.nitions for 1a8y. In this case a mosaic of signals 
(sequence termination, en­tropy, correlation and residue type) is integrated by our system into three 
precise predictions that are in perfect agreement with structural de.nitions. 4.2 Suggested novel partitions 
The list of proteins on which our method failed to cor­rectly predict domain boundaries as de.ned by 
SCOP re­vealed interesting cases. Many of them raise serious ques­tions about the validity of the SCOP 
de.nitions. For exam­ple, PDB protein 1acc (735 amino acids long) is de.ned as a single domain in SCOP. 
Our analysis suggests three do­mains, at positions 1-167, 168-586 and 587-735 (see Fig. 5). As the .gure 
illustrates, this partition seems to better satisfy the de.nition of a domain as a compact, independent 
fold­able unit. Moreover, given the distribution of domain sizes in proteins (see section 3.2), it is 
not very likely to have pro­tein domains that are longer than 700 amino acids, further supporting our 
hypothesis. For comparison, Pfam detects one domain at positions 103-544 (PF03495 Clostridial Bi­nary 
exotoxin B) and Domo predicts two domains at posi­tions 1-647 and 648-735. No predictions are available 
from ProDom, SMART or Tigr. Figure 5: (a) Domain de.nitions for 1acc. SCOP de.nes this protein as a 
single domain. Our analysis suggests three compact units. In this case we get clean and strong sequence 
termination signals at positions 150, 170, 590 and 610 and a remark­ably consistent alignment between 
positions 170 and 580. This signal is reinforced by other measures: the hydrophobic curve has three major 
troughs at 170, 290 and 570, insertion entropy has major peaks at 180, 310 and 560 and correlation is 
pretty low around 200, 280 and 590.  5. DISCUSSION In this paper we presented a novel method for detecting 
the domain structure of a protein from sequence information alone, by utilizing the information in sequence 
databases. The query sequence is compared with all the sequences in the database and the resulting alignment 
is processed fully automatically in search for domain transition signals. There are several novel elements 
in out method. First, our method uses multiple scores. Some of the scores we designed are vari­ations 
on measures that were suggested in earlier studies (e.g sequence participation and correlation scores 
were used in DOMO, ProDom and PASS and correlated mutations were used in Rigden s work). However, we 
introduce many novel scores based on analysis of basic sequence properties or pre­dicted properties, 
scores that are calculated from multiple alignments, and scores that are extracted from external re­sources 
such as intron-exon data. Second, information the­ory principles are used to optimize the scores and 
select the subset that maximizes the domain information content. Third, a neural network is trained to 
learn a non-linear map­ping from the original scores to a single output6 . Finally, a probabilistic domain-generator 
model is developed to as­sess multiple hypotheses and predict the most likely one. This multi-stage system 
is not only robust to alignment in­accuracies, but it can also tolerate partial information. It can be 
extended and generalized to include other types of scores. Most importantly, our method suggests for 
the .rst time a rigorous model that can test all possible hypotheses and output the one that is most 
consistent with the data. We also developed an evaluation framework that hopefully will provide a clearer 
understanding of the strengths and weaknesses of the algorithms that have been designed so far and thus 
aid in the design of better algorithms. More­over, our domain-generator model can associate a statistical 
signi.cance score for every hypothesis, thus enabling us to compare di.erent hypotheses by the same method 
or even di.erent hypotheses by several di.erent methods. We trained and tested our method on what is 
considered to be the gold standard in protein structure classi.cation, the SCOP database of protein domains. 
Our method was better than the best manual methods currently available while being fully automatic. One 
should keep in mind that SCOP is a man-made classi.cation, and the de.nitions of domains do not necessarily 
conform with nature s de.ni­tions . Indeed many of our supposedly errors seem to make sense when inspected 
visually. We are already considering several variations to the model described here. Although our algorithm 
is not overly sensi­tive to alignment accuracy, obviously better multiple align­ment algorithms are expected 
to improve the performance. Another possible improvement is the integration of a weight­ing scheme into 
the multiple alignment. Currently all se­quences are weighted equally. However, due to the biased representation 
of protein families in sequence databases and 6Early attempts to use a linear system failed to provide 
satisfactory performance. the nature of sequence comparison algorithms, diverged se­quences that might 
provide us with crucial information about domain boundaries are usually underrepresented in these alignments. 
To eliminate this bias one should decrease the weight of highly similar sequences and increase the weight 
of highly diverged sequences. This modi.cation in currently underway. Hopefully these variations will 
improve perfor­mance even more. 6. ACKNOWLEDGMENTS This work is supported by the National Science Founda­tion 
under Grant No. 0133311 to Golan Yona. 7. REFERENCES <RefA>[1] Rose, G. D. (1979). Hierarchic organization 
of domains in globular proteins. J. Mol. Biol. 134, 447-470. [2] Lesk, A. M. &#38; Rose, G. D. (1981). 
Folding units in globular proteins. Proc. Natl. Acad. Sci. USA 78, 4304-4308. [3] Holm, L. &#38; Sander, 
C. (1994). Parser for protein folding units. Proteins 19, 256-268. [4] Murzin, A. G., Brenner, S. E., 
Hubbard, T. &#38; Chothia, C. (1995). SCOP: a structural classi.cation of proteins database for the investigation 
of sequences and structures. J. Mol. Biol. 247, 536-540. [5] Yona, G. &#38; Levitt, M. (2000). Towards 
a complete map of the protein space based on a uni.ed sequence and structure analysis of all known proteins. 
In the proceedings of ISMB 2000, 395-406, AAAI press, Menlo Park. [6] Kuroda, Y., Tani, K., Matsuo, Y. 
&#38; Yokoyama, S. (2000). Automated search of natively folded protein fragments for high-throughput 
structure determination in structural genomics. Protein Sci. 9, 2313-2321. [7] George, R. A. &#38; Heringa, 
J. (2002). Protein domain identi.cation and improved sequence similarity searching using PSI-BLAST. Proteins 
48, 672-681. [8] Gouzy, J., Corpet, F. &#38; Kahn, D. (1999). Whole genome protein domain analysis using 
a new method for domain clustering. Comput Chem. 23, 333-340. [9] Sonnhammer, E. L. L. &#38; Kahn, D. 
(1994). Modular arrangement of proteins as inferred from analysis of homology. Protein Sci. 3, 482-492. 
 [10] Park, J. &#38; Teicmann, S. A. (1998). DIVCLUS: an automatic method in the GEANFAMMER package that 
.nds homologous domains in single-and multi-domain proteins. Bioinformatics 14:2, 144-150. [11] Gracy, 
J. &#38; Argos, P. (1998). Automated protein sequence database classi.cation. I. Integration of copositional 
similarity search, local similarity search and multiple sequence alignment. II. Delineation of domain 
boundries from sequence similarity. Bioinformatics 14:2, 164-187. [12] Sonnhammer, E. L., Eddy, S. R., 
Durbin, R. (1997). Pfam: a comprehensive database of protein domain families based on seed alignments. 
Proteins 28, 405-420. [13] Bateman, A., Birney, E., Durbin, R., Eddy, S. R., Finn R. D., &#38; Sonnhammer 
E. L. (1999). Pfam 3.1: 1313 multiple alignments and pro.le HMMs match the majority of proteins. Nucl. 
Acids Res. 27, 260-262. [14] Haft,D.H., Loftus,B. J., Richardson,D.L., Yang, F., Eisen, J. A., Paulsen, 
I. T. &#38; White, O. (2001). TIGRFAMs: a protein family resource for the functional identi.cation of 
proteins. Nucl. Acids Res. 29, 41-43. [15] Ponting, C. P., Schultz, J., Milpetz, F. &#38; Bork, P. (1999). 
SMART: identi.cation and annotation of domains from signalling and extracellular protein sequences. Nucl. 
Acids Res. 27, 229-232. [16] George, R. A. &#38; Heringa, J. (2002). SnapDRAGON: a method to delineate 
protein structural domains from sequence data. J. Mol. Biol. 316, 839-851. [17] Rigden, D. J. (2002). 
Use of covariance analysis for the prediction of structural domain boundaries from multiple protein sequence 
alignments. Protein Eng. 15, 65-77. [18] Guan, X. &#38; Du, L. (1998). Domain identi.cation by clustering 
sequence alignments. Bioinformatics 14, 783-788. [19] Wheelan, S. J., Marchler-Bauer, A. &#38; Bryant, 
S. H. (2000). Domain size distributions can predict domain boundaries. Bioinformatics 16, 613-618. [20] 
George, D.G., Barker,W.C., Mewes, H. W.,Pfei.er, F. &#38; Tsugita, A. (1996). The PIR-International protein 
sequence database. Nucl. Acids. Res. 24, 17-20. [21] Bairoch, A. &#38; Apweiler, R. (1999). The SWISS-PROT 
protein sequence data bank and its supplement TrEMBL in 1999. Nucl. Acids Res. 27 49-54. [22] Hubbard, 
T. J., Ailey, B., Brenner, S. E., Murzin, A. G. &#38; Chothia, C. (1999). SCOP: a Structural Classi.cation 
of Proteins database. Nucl. Acids Res. 27, 254-256. [23] Westbrook, J., Feng, Z., Jain, S. et al. (2002). 
The Protein Data Bank: unifying the archive. Nucl. Acids. Res. 30, 245-248 [24] Altschul, S. F., Madden, 
T. L., Scha.er, A. A., Zhang, J., Zhang, Z., Miller, W. &#38; Lipman, D.J. (1997). Gapped BLAST and PSI-BLAST: 
a new generation of protein database search programs. Nucl. Acids Res. 25, 3389-3402. [25] Yona, G., 
Linial, N. &#38; Linial, M. (1999). ProtoMap: Automatic classi.cation of protein sequences, a hierarchy 
of protein families, and local maps of the protein space. Proteins, 37, 360-378. [26] Heniko., J. G. 
&#38; Heniko., S. (1996). Using substitution probabilities to improve position-speci.c scoring matrices. 
Comp. App. Biosci. 12:2, 135-143. [27] Hobohm, U. &#38; Sander, C. (1995). A sequence property approach 
to searching protein database. J. Mol. Biol. 251, 390-399. [28] Ferran, E. A., P.ugfelder, B. &#38; Ferrara 
P. (1994). Self-Organized Neural Maps of Human Protein Sequences. Protein Sci. 3, 507-521. [29] Csiszr, 
I. Information Theoretic Methods in Probability and Statistics. From citeseer.nj.nec.com [30] Heniko., 
S. &#38; Heniko., J. G. (1992). Amino acid substitution matrices from protein blocks. Proc. Natl Acad. 
Sci. USA 89, 10915-10919. [31] Pazos, F., Helmer-Citterich, M., Ausiello, G. &#38; Valencia, A. (1997). 
Correlated mutations contain information about protein-protein interaction. J. Mol. Biol. 271, 511-523. 
[32] Black, S.D. &#38; Mould, D.R. (1991). Development of Hydrophobicity Parameters to Analyze Proteins 
Which Bear Post or Cotranslational Modi.cations. Anal. Biochem. 193, 72-82. [33] Sowdhamini, R. &#38; 
Blundell, T. L. (1995). An automatic method involving cluster analysis of secondary structures for the 
identi.cation of domains in proteins. Protein Sci. 4, 506-520. [34] McGu.n, L. J. , Bryson, K. &#38; 
Jones, D. T. (2000). The PSIPRED protein structure prediction server. Bioinformatics 16, 404-405. [35] 
Gilbert, W. &#38; Glynias, M. (1993). On the ancient nature of introns. Gene 135, 137-144. [36] Gilbert, 
W., de Souza, S. J. &#38; Long, M. (1997). Origin of genes. Proc. Natl Acad. Sci. USA 94, 7698-7703. 
[37] Saxonov, S. , Daizadeh, I. , Fedorov, A. &#38; Gilbert, W. (2000). EID: the Exon-Intron Database-an 
exhaustive database of protein-coding intron-containing genes. Nucl. Acids Res. 28, 185-190. [38] Lin, 
J. (1991). Divergence measures based on the Shannon entropy. IEEE Trans. Info. Theory 37:1, 145-151. 
[39] Kullback, S. (1959). Information theory and statistics . John Wiley and Sons, New York. [40] El-Yaniv, 
R., Fine, S. &#38; Tishby, N. (1997). Agnostic classi.cation of markovian sequences. Advances in Neural 
Information Processing Systems 10, 465-471. [41] Ireland, C. T. &#38; Kullback, S. (1968). Contingency 
tables with given marginals. Biometrika 55, 179-189. [42] Pearl, J. (1997). Probabilistic Reasoning in 
Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers Inc., San Mateo, California. 
[43] Apweiler, R., Attwood, T. K., Bairoch, A., Bateman, A., Birney, E., Biswas, M., Bucher, P., Cerutti, 
L., Corpet, F., Croning, M. D., Durbin, R., Falquet, L., Fleischmann, W., Gouzy, J., Hermjakob, H., Hulo, 
N., Jonassen, I., Kahn, D., Kanapin, A., Karavidopoulou, Y.,Lopez,R., Marx,B., Mulder,N.J., Oinn, T. 
M., Pagni, M., Servant, F., Sigrist, C. J. &#38; Zdobnov, E. M. (2001). The InterPro database, an integrated 
documentation resource for protein families, domains and functional sites. Nucl. Acids Res. 29, 37-40.</RefA> 
  
			
