
 3D-VISUALIZATION OF TOMOGRAPHIC VOLUME DATA USING THE GENERALIZED VOXEL-MODEL HShne, K.H.; Bomans, M.; 
Pommert, A.; Riemer, M.; Schiers, C.; Tiede~ U.; Wiebecke~ G. Institute of Mathematics and Computer 
Science in Medicine University Hospital Eppendorf, Hamburg, F.R.G. ABSTRACT Multi-slice images obtained 
from computer tomog- raphy and magnetic resonance imaging represent a three-dimensional image volume. 
For its visu- alization we use a ray-casting algorithm working on a gray scMe voxel data model. This 
model is extended by additional attributes such as mem-bership to an organ or a second imaging modal- 
ity ("generalized voxel model"). It is shown that the combination of different surface rendering al- 
gorithms together with cutting and transparent display allow a realistic visualization of human anatomy. 
INTRODUCTION An ever-increasing number of medical diagnostic images are obtained from X-ray Computed 
Tomog- raphy (CT), Magnetic Resonance Imaging (MRI), and Positron Emission Tomography (PET), which produce 
sequences of two-dimensional (2D) cross- sectional slices. The current predominant method of analyzing 
these images is by sequential observa- tion of individual 2D slices and the viewer's subse- quent 'mental 
reconstruction' of three-dimensional (3D) relationships. Computerized reconstructions of CT scans have 
produced 3D perspective display of bony anatomy that have proved clinically useful in craniofacial surgery 
and orthopedics [Hemmy et al. 83; Templeton et al. 84; Vannier et al. 84; Yasuda et al. 84; Boecker et 
al. 85; Chen et al. 85; Herman et al. 85; Witte et al. 86]. The pro- cedures used in these applications 
are limited by the fact that only predefined surfaces (mostly bone) can be visualized and that all other 
information is not used or lost during processing. A few recent in- vestigations have dealt with the 
software and hard- ware problems of displaying 3D tomographic vol- umes that preserve the entire original 
gray scale data and thus allow a detailed exploration of the volume [Goldwasser et al. 85; Jackel 85; 
Lenz et al. 86; Kaufman 86; HShne et al. 87]. On the basis of data from computer tomography and MRI we 
have developed, investigated and compared a vari- ety of methods for visualizing gray level volumes. 
This paper is a condensed version of an article to appear e]sewhere [HShne et al. 89]. METHOD AND RESULTS 
 Data structure The raw data is a spatial sequence of image matri- ces of 2563 or 5123 pixels. To save 
storage space the gray level data of the original volume is com- pressed to a dynamic range of 256 gray 
values. To achieve cubic volume elements a linear interpola- tion of the intensity values between the 
original slices is performed. The thus obtained 3D array ("voxel-model") is the basic data structure 
for most of the described algorithms. As an extension each voxel may not only contain a gray value but 
also further attributes such as membership to an or-gan or an intensity value delivered by an additional 
imaging modality ("generalized voxel-model"). In the present implementation each voxel can be de- scribed 
by up to 16 bits. CH Volume Visualization Workshop 51 Projection strategy When scanning the volume we 
basically have the choice between two classes of strategies: One class consists of the object space oriented 
methods that scan along lines or columns of the 3D-array and project a chosen aspect onto an image plane 
in the direction of view. These are known as back-to-front (BTF) or front-to-back (FTB) methods. They 
have proved to be reasonably fast when a pure surface display of a single object is required. When, how- 
ever, volumetric properties such as translucency are to be visualized, image space oriented methods that 
scan the image volume along the viewing direction are unavoidable. The computing overhead of this algorithm 
referred to as ray casting is larger, espe- cially when the whole data volume does not fit into the main 
memory of the hardware. Therefore we use in our project a front-to-back algorithm for the visualization 
of pure surfaces. For all other projec- tions we rotate the whole volume such that scan-ning for a desired 
viewing direction can be done along the lines of the array. Thus the time consum- ing coordinate transformation 
has to be performed only once per viewing direction. The gray level as- signment in the rotated volume 
is done by tri-linear interpolation. Optionally, the volume can be dis- torted such that a central projection 
is achieved. All pictures in this article have been produced this way. Surface rendering The classical 
approach of visualizing a volume is the display of surfaces contained in it (see e.g. [Pizer and Fuchs 
87]). The easiest way of determining the voxels that represent a surface (segmentation) is in- tensity 
thresholding. This works quite well for the outer skin in MR and CT and also for bone in CT. As well 
known a raw image of the thus determined surface can be produced by imaging the negative distance to 
the observer (Z-buffer (Z-) shading, see fig. la). For realistic images, of course, the sur-face normal 
vectors have to be determined. A still not too time consuming method is the estimation of the surface 
normals from the Z-buffer [Chen et al. 85] in our project further referred to as Z-buffer gradient (ZG-) 
shading. We have implemented a modified version of this algorithm [Tiede et al. 87]. This algorithm delivers 
fairly realistic images, but it suffers from the fact that the dynamic range of surface angles is low 
(fig. lb). This is because they are computed on the basis of the position of sur- face voxels in a 3x3 
neighbourhood, which does not allow a large number of choices. 52 ¢H Volume Visualization Workshop Much 
better results can be obtained if the gray scale data are utilized for the determination of the surface 
normals. As a consequence of the tomo-graphic data acquisition technique the gray values in the neighbourhood 
of a surface voxel reflect the relative average of the various (usually two) tissue types (air/skin, 
soft tissue/bone) in the voxels im- mediately adjacent to the voxel in question. These relative volumes 
are related to the surface inclina- tion. Thus the gray level gradient can be consid- ered as a measure 
for surface inclination. This idea of gray level gradient (GG-) shading has been de- scribed by [Barillot 
et al. 85] and independently by [H6hne and Bernstein 86; Tiede et al. 87 and 88]. The algorithm published 
by [Lorensen et al. 87] is working on the same basis. Our procedure is as follows: Given the gray level 
of a surface voxel at a location i,j,k the gray level gradient is computed as: Gx --g(i+l,j,k) --g(i-l,j,k) 
Gy = g(i,j+l,k) --g(i,j-l,k) Gz = g(i,j,k+l) -g(i,j,~-l) The components of the surface normals are normal- 
ized as el$ Nu ----~ u ~ x~y~z 2 + + (az) The gradients are typically computed either from 6 central 
neighbours in the 3x3x3 neighbourhood or from all 26 neighbours. In the latter case the algorithm is 
identical to the Zucker-Hummel oper- ator for edge detection [Zucker and Hummel 79]. The images of this 
paper have been computed with 26 neighbors. Using the normal vectors the object can be shaded according 
to any shading model such as Phong shading which has been used throughout this paper. Due to the high 
dynamic range of the gray levels a continuous shading is now possible that leads to a more realistic 
impression of the objects. Small details not visible with the Z-buffer gradient shad- ing such as the 
suture of a skull now become rec-ognizable (fig. lc). In addition, aliasing effects present in ZG-shading, 
especially during rotation, do not occur. In the case of small objects, how- ever, such as a thin bone 
in the orbita or the nasal septum, this method leads to artefacts. This is due to the fact that in this 
case the gray level is no longer governed by the membership to an ob-ject class but by the thickness 
of the object. As  Improvement through extended object descriptions So far the definition of the objects 
displayed has been made by thresholding the intensity profile while traversing the volume. A more detailed 
object definition cannot be achieved through the analysis of the intensity along the ray since we need 
a larger 3D-neighbourhood for the decision on whether a voxel belongs to a surface. Another possibility 
is to gain this information from an ad-ditional source. In the following subsections we de- scribe two 
kinds of extended descriptions, organ la- bels gained through segmentatiorL and the addition of a second 
imaging modality. Segmentation. For the determination of ob- ject surfaces other than bone and skin segmenta- 
tion algorithms are necessary that take larger voxel neighbourhoods into account than is possible in 
the 1D-ray casting case. In order to find the intensity changes that represent surfaces we applied a 
3D-extension of the Marr-Hildreth operator [Marr and Hildreth 80], which is defined by I'(x, y, z) = 
V2(I(x, y, z) * G(x, y, z, a)) where V is the Laplace operator, I the image vol- ume, and G the Ganssian 
function. The zero cross- ings of I' are considered as surfaces. These are by definition closed which 
is important for 3D-display. In our implementation the Marr-Hildreth operator was approximated by a difference 
of Gaussians [Bo- roans et al. 87 and 89]. We have applied this method to MRI data of the head. After 
binariz- ing the filtered volume I' the obtained regions are labeled according to their correspondence 
to dif-ferent constituents (skin, bone, brain etc.). In our current procedure this is done interactively 
for each slice. The regions found do not always correspond to anatomical structures. Errors had to be 
cor-rected by removing wrong connections or by insert- ing new surface elements. For the segmentation 
of the brain cortex, for example, we correct typi-cally ten 2D-contours. For the 3D-contour of the cortex 
we apply in addition a 3D-dilation with a subsequent erosion. This procedure destroys small details of 
the contour. If we use, however, the thus obtained 3D-contour as a baseline for a semi- transparent display 
-here just an integration over 6 pixels ("integral shading") -we obtain images as shown in fig. 8. Here 
skin, bone and ventricle were rendered using GG-shading. For brain and carotid artery "integral shading" 
was used. 54 CH Volume Visualization Workshop Multiple imaging modalities. A 3D-image if generated from 
a single imaging modality shows only special aspects of the reality. Improved in- formation can be obtained 
by combining data of different modalities such as CT, MtU or PET. This way, e.g. bone structures may 
be described better by CT while soft tissue properties are better repre- sented by MRI. Generally the 
different data sets do not match geometrically. It is therefore necessary to register the volumes to 
each other. As a basic tool we have developed a 3D-specifier: correspond- ing landmarks specified on 
surface images of MR. or CT volumes serve for the computation of polynomi- Ms performing the required 
3D-distortion [Schiers et al. 89]. Preliminary experience shows that this kind of specification needs 
a well trained user and sometimes more than one attempt to arrive at a satisfying match. Fig. 9 shows 
a thus obtained im- age with the combined properties of M1H and CT. IMPLEMENTATION ASPECTS The described 
algorithms are implemented within the program system VOXEL-MAN on a VAX 11/780 (24 mbytes of main memory) 
and VAX-station II/GPX (16 mbytes of main memory). The rotation of a volume of 2563 voxels takes between 
15 and 30 minutes. The described projections take be- tween 10 and 60 seconds. Such times are certainly 
not sufficient for clinical work but can be tolerated in a research environment. In the meantime a sub- 
set of the algorithms has been implemented on a processor manufactured by the KONTRON Corpo- ration. 
Here a view from any direction shaded with gray level gradient shading takes between 5 and 10 seconds. 
If we take into account the fast progress in hardware development, computing speed will not be a major 
issue in the future. The main problem to be solved for a broad applica- tion is the design of an appropriate 
user interface. Presently VOXEL-MAN has two interfaces: One is a language interface that allows the specification 
of the desired action through a string of parame- ters. It has full flexibility, but it needs an expert 
to choose the right combination from a choice of more than 30 parameters. The other interface is a menn 
interface that is certainly suitable for the beginner. However, not all specifications can be ex- pressed 
suitably in this form (see fig. 3). APPLICATIONS 3D-imaging, especially of bone, has for several years 
proved to be useful in craniofacial surgery  ACKNOWLEDGEMENTS The authors would like to thank ProL 
Dr. Dr. Wolf-Joachim HSltje (Dept. of Craniofacial Surgery), Prof. Dr. Wolfgang Schulze (Dept. of Anatomy), 
Dr. Jiirgen Wening (Dept. of Trauma- tology), and Dr. Gerd Witte (Dept. of Radiology) for many discussions. 
We also thank Ellen Vaske and Rainer Schubert for their help. We are grate- ful to Siemens (Erlangen) 
for providing the original MRI-volume data from which the perspective views have been produced. The images 
of the mummy were produced in collaboration with the Institute of Anthropology and the Department of 
Neurora- diology, University of Tfihingen. The tomograms of the cadaver have kindly been provided by 
the Dept. of Neuroanatomy, Medical University ttan- nover. The investigations were supported in part 
by the Deutsche Forschungsgemeinschaft and the Werner- Otto-Foundation Hamburg. REFERENCES <RefA><SinRef><author>Barillot 
C, </author><author>Gibaud B</author>,<author> Luo LM</author>, <author>Scarabin IM </author>[<date>1985</date>] <title>3-D Representation of anatomic structures from ct examinations</title>. 
<booktitle>Biostereometrics '85, Proc. SPIE </booktitle><volume>602</volume>:pp<pages>307-314</pages></SinRef><SinRef> <author>Boecker FRP</author>,<author> Tiede U</author>, and <author>HShne KH </author>[<date>1985</date>] <title>Com- bined use 
of different algorithms for interactive sur- gical planning</title>. In: <booktitle>Lemke U (ed) Computer as- sisted radiology</booktitle>. 
<publisher>Springer</publisher>, <location>Berlin New York Tokyo</location>, pp<pages>572-577 </pages></SinRef><SinRef><author>Bomans M</author>, <author>Riemer M</author>, <author>Tiede U</author>,<author> HShne KH </author>[<date>1987</date>] <title>3-D Segmentation 
yon Kernspintomogrammen. 9. DAGM-Tagung Braunschweig</title>. In: <booktitle>Informatik Fachberichte </booktitle><volume>149</volume>, <publisher>Springer</publisher>, <location>Berlin</location>, 
pp<pages>231-235</pages> </SinRef><SinRef><author>Bomans M</author>, <author>HShne KH</author>, <author>Riemer M</author>, <author>Tiede U </author>[<date>1989</date>] <title>3D-segmentation of MR-images of the head for 3D- 
display</title>, <journal>IEEE Trans. Med. Imaging</journal>, <publisher>im press </publisher></SinRef><SinRef><author>Chen LS</author>, <author>Herman GT</author>, <author>Reynolds RA</author>, <author>Udupa JK </author>[<date>1985</date>] <title>Surface 
shading in the cuberUle environment</title>.<journal> Computer Graphics and Applications</journal> <volume>5</volume>, pp<pages>33-43 </pages></SinRef><SinRef><author>Goldwasser SM</author>, <author>Reynolds 
RA</author>, <author>Bapty T</author>, <author>Baxaff D</author>, <author>Summers J</author>, <author>Talton DA</author>, and <author>Walsh E </author>[<date>1985</date>] <title>Physicians workstation with real time 
performance</title>. <journal>Computer Graphics and Applications </journal><volume>5</volume>, pp<pages>44-57 </pages></SinRef><SinRef><author>Hemmy DC</author>, <author>David D J</author>, <author>Herman GT</author> [<date>1983</date>] <title>Three- 
dimensional reconstruction of craniofacial defor-mity using computed tomography</title>. <journal>Neurosurgery</journal> <volume>13</volume>, pp<pages>534-541 </pages></SinRef>
56 ¢H Volume Visualization Workshop<SinRef> <author>Herman GT</author>, <author>Vose WF</author>, <author>Gomori JM</author>, <author>Gefter WB </author>[<date>1985</date>] <title>Stereoscopic computed 
threedimensional surface displays</title>. <journal>Radio Graphics </journal><volume>5</volume>, pp<pages>825-852 </pages></SinRef><SinRef><author>HShne KH</author>, <author>Bomans M</author>, <author>Pommert A</author>, <author>Riemer 
M</author>, <author>Tiede U</author>, <author>Wiebecke G </author>[<date>1989</date>] <title>3D-visualization of to- mographic volume data using the generalized voxel- 
model</title>.<journal> Visual Computer </journal><volume>5,3 </volume>(<publisher>in press</publisher>) </SinRef><SinRef><author>HShne KH</author>, <author>Bomans M</author>, <author>Tiede U</author>, <author>Riemer M </author>[<date>1988</date>] <title>Display of multiple 
3D-objects using the general- ized voxel-model</title>.<booktitle> Proceedings SPIE 914</booktitle>: pp<pages>850- 854 </pages></SinRef><SinRef><author>HShne KH</author>, <author>DeLaPaz RL</author>, 
<author>Bernstein R</author>, <author>Taylor RC </author>[<date>1987</date>] <title>Combined surface display and reformatting for the 3D-analysis of tomographic 
data</title>. <journal>Investiga- tive Radiology</journal> <volume>22</volume>:pp<pages>658-664 </pages></SinRef><SinRef><author>HShne KH</author>, <author>Bernstein 1~ </author>[<date>1986</date>] <title>Shading 3D images from CT 
using gray level gradients</title>, <journal>IEEE Transac- tions on Medical Imaging</journal> <volume>5</volume>:pp<pages>45-47 </pages></SinRef><SinRef><author>Jackel D </author>[<date>1985</date>] <title>The graphics 
PARCUM system: A 3D memory based computer .architecture for pro- cessing and display of solid objects</title>. 
<journal>Computer Graphics Forum </journal><volume>4</volume>:pp<pages>21-32 </pages></SinRef><SinRef><author>Kaufman A </author>[<date>1986</date>] <title>Voxel based architectures for three-dimensional graphics</title>. 
<booktitle>Proc, IFIP'86</booktitle>:pp<pages>361- 366 </pages></SinRef><SinRef><author>Lenz l~, </author><author>Danielsson PE</author>, <author>CronstrSm S</author>,<author> Gudmundson B</author> [<date>1986</date>] <title>Interactive display 
of 3D medical objects</title>. In: <editor>HShne KH </editor>(ed) <booktitle>Pictorial information systems in medicine, Springer</booktitle>, <location>Berlin 
New York Tokyo</location>, pp<pages>449- 468 </pages></SinRef><SinRef><author>Levoy M </author>[<date>1988</date>] <title>Display of surface from volume data</title>. <journal>IEEE Computer Graphics 
g~ Applications </journal><volume>8</volume>:pp<pages>29-37 </pages></SinRef><SinRef><author>Lorensen WE</author>, <author>Cline HE </author>[<date>1987</date>] <title>Marching Cubes: A high resolution 3D surface construction 
algorithm</title>. <journal>Computer Graphics </journal><volume>21</volume>:pp<pages>163-169 </pages></SinRef><SinRef><author>Mart D, Hildreth EC </author>[<date>1980</date>] <title>Theroy of edge detec- tion</title>. <booktitle>Proc. 
It. Soc. Lond. B </booktitle><volume>207</volume>:pp<pages>187-217</pages></SinRef> <SinRef><author>Pizer SM</author>, <author>Fuchs H </author>[<date>1987</date>] <title>Three Dimensional Image Presentation Techniques 
in Medical Imaging</title>. In: <editor>Lemke HU </editor><editor>et al. </editor>(eds), <booktitle>Computer Assisted Radiol- ogy (Proc. CAR '87), </booktitle><publisher>Springer</publisher>, 
<location>Berlin</location>, pp<pages>589-597</pages></SinRef> <SinRef><author>Pommert A</author>, <author>Bomans M</author>, <author>Tiede U, HShne KH </author>[<date>1989a</date>] <title>Investigations on image quality for 
3D- display techniques</title>. In: <editor>Lemke HU </editor><editor>et al. </editor>(eds), <booktitle>Computer Assisted Radiology (Proc. CAR '89), </booktitle><publisher>Springer</publisher>, 
<location>Berlin</location>, in press</SinRef> <SinRef><author>Pommert A</author>, <author>Bomans M</author>, <author>Tiede U, H5hne KH </author>[<date>1989b</date>] <title>Simulation studies for quality assurance 
of 3D-images from computed tomograms</title>. In: <editor>Todd- Pokropek A</editor>, <editor>Viergever MA</editor> (eds): <booktitle>The Forma-tion, Handling 
and Evaluation of Medical Images. NATO ASI Series F, Computer and Systems Sci- ences</booktitle>, <publisher>Springer</publisher>, <location>Berlin</location>, 
in press</SinRef> <SinRef><author>Schiers C</author>, <author>Tiede U</author>, <author>HShne KH </author>[<date>1989</date>] <title>Interactive 3D-registration of image volumes from different 
sources</title>. In: <editor>Lemke HU </editor>et al. (eds), <booktitle>Computer Assisted Radiology (Proc. CAR '89), </booktitle><publisher>Springer</publisher>, <location>Berlin</location>, in 
press </SinRef><SinRef><author>Templeton AW</author>,<author> Johnson JA</author>, <author>Anderson WH </author>[<date>1985</date>] <title>Computer graphics for digitally formatted images</title>. 
Radiology <volume>152</volume>, pp<pages>527-528</pages> </SinRef><SinRef><author>Tiede U</author>, <author>HShne KH</author>, <author>Riemer M </author>[<date>1987</date>] <title>Comparison of surface rendering techniques 
for 3D tomographic objects</title>. In:<booktitle> Lemke U (ed) Computer Assisted Ra- diology</booktitle>, <publisher>Springer</publisher>, <location>Berlin New York 
Tokyo</location>, pp<pages>599- 610 </pages></SinRef><SinRef><author>Tiede U</author>, <author>Pdemer M</author>,<author> Bomans M</author>,<author> H6hne KH </author>[<date>1988</date>] <title>Display Techniques for 3D-Tomographic 
Volume Data</title>. In <booktitle>Proc. NCGA '88</booktitle>, Vol. <volume>IlI</volume>, Anaheim, pp188-197 </SinRef><SinRef><author>Vannier MW</author>, <author>Marsh JL</author>, <author>Warren J </author>[<date>1984</date>]<title> Three- 
dimensional CT reconstruction images for craniofa- cial surgical plannning</title>, <journal>l~adiology </journal><volume>150</volume>, pp<pages>179-184</pages></SinRef> 
<SinRef><author>Witte G</author>, <author>HSltje W</author>, <author>Tiede U</author>, <author>Riemer M </author>[<date>1986</date>] <title>Die dreidimensionale Darstellung computertomo- graphischer 
Untersuchungen kraniofacialer Anoma- lien</title>. <booktitle>Fortschr. RSntgenstr</booktitle>.<volume> 144,4</volume>, pp<pages>24-29</pages></SinRef> <SinRef><author>Yasuda T</author>,<author> Toriwaki J</author>, 
<author>Yokoi S</author>, <author>Katada K </author>[<date>1984</date>] <title>Threedimensional display system of CT images for surgical planning</title>. <booktitle>Int. Symposium 
on Medical Im- ages and Icons</booktitle>. <location>Silver Spring MD</location>: <publisher>IEEE Computer Society</publisher>, pp<pages>322-327</pages></SinRef> <SinRef><author>Zucker SW</author>, <author>Hummel RA 
</author>[<date>1979</date>] <title>An optimal three- dimensional edge operator</title>. <institution>McGi]l University,</institution> Re- port, pp<pages>79-10</pages> CH Volume Visualization 
Workshop</SinRef></RefA> 57    
			
