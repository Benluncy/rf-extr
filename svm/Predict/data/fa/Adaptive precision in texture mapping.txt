
 Adaptive Precision in Texture Mapping Andrew Glassner Department of Computer Science The University 
of North Carolina at Chapel Hill Chapel Hill, North Carolina 27514 Abstract We introduce an adaptive, 
iterative technique for ob- taining texture saxaples of arbitrary precision when synthe- sizing a computer-generated 
image. The technique is an improvement on the sum table texturing method. To mo- tivate the technique 
we analyze the error properties of the sum-table method. Based on that analysis we propose us- ing a 
combination of tables independently or together to obtain a better estimate, and analyze the error properties 
of such methods. We then propose a new technique for obtaining texture samples whose accuracy is a function 
of the texture and the image. As part of this technique we propose the use of an auxiliary table which 
contains local estimates of the texture variance. We show how the iter- ation of a given sample may be 
controlled by values from this table. We then analyze the error in this method, and present images which 
demonstrate the improvement. General Terms: Algorithms, Graphics Keywords: Textures, Sum Tables, Iteration, 
Adaptive Re- finement, Variance CR Categories: 1.3.3 Picture/Image Generation; 1.3.7 Three-Dimensional 
Graphics and Realism Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1986 ACM0-89791-196-2/86/008/0297 $00.75 1.0 Introduction Synthetic texturing 
was first introduced by Catmull [Catm75]. Since that time there has been considerable in- terest in the 
correct and efficient application of texture to surfaces. A popular use of texturing has been to apply 
color de- tail to surfaces. In this sense, textures have been used to simulate painted images [Blin76]. 
Another use of textures has been to simulate shape detail that would be inefficient or difficult to model 
directly, either through normal pertur- bation [Blin78], or displacement mapping [Cook84]. Some techniques 
for generating textures that have been discussed in the literature are stored look-up tables [Blin76], 
procedural routines [Gard84], and multi-dimensional meth- ods [Peal85]. Texture has also been incorporated 
into syn- thesized images as a post-process, either to enhance the understanding of shapes [Schw83], 
or to generate special effects [Perl85]. Many image synthesis systems build an image by ren- dering pieces 
of surface (such as a polygon) one at a time. The pieces may be combined with previous pieces as they 
are rendered in a Z-buffer [Suth74] or an A-buffer [Carp84]. Alternatively, entire images may be merged 
after rendering [Port84], [Duff85]. In all of these schemes, the texturing process is usually one of 
inverse mapping [FeibS0]. The problem of texturing may be expressed in many ways, with varying degrees 
of theoretical and practical con- siderations. A popular model which is theoretically incom- plete but 
often visually acceptable is to assign a texture value to a pixel based on the average value of the texture 
within the surface region seen by that pixel. This is the model we use in this paper. In general, a pixel 
may be considered to be a small window looki/lg onto a surface. When texture is applied to that surface, 
the inverse viewing transform is invoked to find the projection of the pixel onto the surface (in practice, 
we usually project only the four corners of the rectangular pixel). We now want to know where those surface 
points sit in the texture. Often, the axes of two-dimensional textures are referred to as (u,v). These 
four (u,v) pairs (one for each pixel corner) then describe a quadrilateral in that table. If we are rendering 
a very warped surface, it is possible that this quadrilateral will not be convex; in such a case we usually 
use the convex hull for the rest of the process. We then find an average texture value inside that quadrilateral. 
This average value is returned to the renderer as the average particular property of that surface seen 
from that pixel. In [Will83] Williams described the mip map, which pre- computed averages of square 
regions of texture at a variety of different resolutions. In [Crow84] Crow described the sum table, which 
can provide the average value in any rect- angle oriented parallel to the texture axes. The sum table 
is usually used to find the average texture value in the small- est oriented rectangle enclosing the 
mapped pixel. The tex- ture value returned by a sum table is usually more accurate than that from a mip 
map, due to its ability to sample a region that more tightly encloses the texture-space image of the 
pixel. Sum tables have been studied in the field of probability theory as joint cumulative probability 
distribu- tion functions on two variables [Ross76]. Both mip maps and sum tables provide a great speedup 
over direct averaging for every pixel, especially when the texture area covered by the pixel is large. 
Although sum tables are superior to mip maps, they can still present arti- facts. In particular, texture 
outside the pixel but within the enclosing rectangle is included in the average. It is possi- ble that 
the area inside the pixel is very small compared to its bounding rectangle; thus texture from outside 
the pixel may dominate the final average. If this extraneous texture contributes substantially to the 
final average, the texture value applied to a pixel may be substantially wrong. The texture-sampling 
problem can be expressed math- ematically by writing the average value g as a nonlinear convolution of 
a filter kernel h with a texture function f [Andr77]. If we knew the correct filter to apply to the texture 
for a given sample, we could simply convolve the texture and the filter to obtain: g~gion = //h(x--~,y 
-~) f(~,rl) d~ drl The assumption behind sum tables is that the filter h can be approximated by a unit-height 
filter which is 1 inside the bounding box of the texture-space image of the pixel, and 0 outside of that 
box (see Figure la). (a) The filter used in rectangular sum tables has unit height over the bounding 
box of the pixers texture-space image. (b) We suggest a better filter would have unit height only over 
the texture-space pixel itself.  Figure 1 In this paper we present an improvement on the sum table 
technique which allows us to compensate for errors that arise from the inclusion of texture which lies 
outside the pixel. We will give methods to construct a filter which is 1 only inside the transformed 
pixel, and 0 everywhere else (see Figure lb). Our conjecture is that this filter will pro- vide superior 
results over the standard sum table bounding box filter. We present methods for obtaining this improved 
filter to different degrees of precision. Our technique is also iterative and adaptive, allowing us to 
perform only as much extra work as the image requires. 2.0 Terminology When we refer to texture space, 
we mean that co-ordinates are to be interpreted as positions in the texture function. If the function 
is two dimensional, we call the axes u and v. When we transform a screen pixel into a cor- responding 
quadrilateral in texture space, we call the new quadrilateral the pixel's texture-space image. The convex 
hull of this quadrilateral we will call the inverse-mapped pixel, or for convenience simply the mapped 
pixel. The four points that comprise a mapped pixel may form a quadrilat- eral, triangle, line, or single 
point. For simplicity, we will call the shape formed by a mapped pixel a general quadri- lateral. For 
a given region R in texture space, we will designate its area by Ra, the sum of all its values (its integral) 
by Rg, and its average value RE/Ra as Rv. We will sometimes illustrate texture operations by de- termining 
a color for a pixel~ but the texture may actually be supplying any surface parameter. When we do speak 
of color from textures, we imply that three texture tables are accessed simultaneously (holding the red, 
green, and blue components of the texture color). 3.0 Fixed Polygon Approximation When we build a sum 
table, each entry receives the summation of all the values in the original texture within some fixed 
region, oriented with reference to that entry. The traditional region used in a sum table is a rectangle. 
In a rectangular sum table each table entry contains the sum of the texture values between its corresponding 
posi- tion in the texture and the texture origin. We may ex-tend the utility of the sum table by integrating 
under other shapes. The sum table is valuable because of its ability to provide the average value under 
a fixed region of variable size and position. However, the orientation and shape of the region must remain 
fixed throughout the table. Thus, we may quickly find the average value within any fixed re- gion with 
a sum table, but each change in the desired shape or orientation of the region will require a new table. 
We will call the integration region provided by a sum table that table's fundamental region. Note that 
the region we inte- grate under to build a sum table is of the same shape as the fundamental region provided 
by the table. The values returned by a sum table may be composed with one another to create an average 
value for a region with a shape other than the table's fundamental region. This may be achieved with 
simple linear combinations of the values returned by the table and the areas of the queried regions. 
Figure 2 shows an example of finding the average value in the region bounded by a letter E in a sum table 
with a rectangular fundamental region. The desired region is E, the enclosing rectangle is R, and the 
extra spaces are A, B, and C. We can express E~,, the average value in E, as E~ RE -AE -- BE -- C~ Ea 
Ra Aa Ba Ca which may be generalized as R~-~ (region~)~ Ev : i=1 Ra --~ (regioni)a i=l  Dallas, August 
18-22 We will investigate a variety of techniques for finding the average value in regions other than 
a table's fundamen- tal region. To compare these techniques it is helpful to have a measure of how much 
error may exist in the final value. To compare these different techniques we use the relative error measure: 
I desired value - obtained value [ erela~ive = desired value It is a bit more difficult to decide what 
we ought to measure. It would be nice to include the texture data itself in our comparison of texture 
estimation schemes. However, the only aspect of the different techniques that remains un- changed over 
different textures is the area averaged by that technique for a given mapped pixel. Thus, our measured 
values will be the area we want in our final region (whose contents are averaged to obtain a final value), 
and the area of the region we actually get from each technique. Let us first analyze the area errors 
from the rectangu- lar sum table. Figure 3a shows a screen plxel which has mapped into a diamond in texture 
space. The bounding box encloses twice as much area as the interior of the dia- mond. Let us call the 
side of the bounding box L. Then the length of one side of the diamond is L~/~/2, so the di- amond's 
total area is L2/2. The relative area error in this case is L2/2-- L ~ ~rectangle--table "~-L2/2 = 1 
One solution to this problem is to augment the rectangular sum table with a diamond sum table. This is 
simply a rectangular sum table built at a 45 ° angle relative to the standard rectangular sum table. 
When this combination is presented with a mapped pixel, based on the geometry of the pixel we determine 
which of the two tables to use for the texture estimate. Consider this combination of sum tables applied 
to Figure 3b, which shows a rectangle canted at a 22.5 ° angle to the table sides. We want the area inside 
the rectangle; this is the area of the bounding box minus the four outer triangles: desiredarea=L2-4121-(43-L) 
x 41-L] =~-L2 I (5/8)L 2 - n 2 3 ediarn°nd--~able : (5~ --5 We can easily combine elements from a sum 
table to find the average of a shape other than the table's fundamental region. Figure 2  Volume 20, 
Number 4, 1986 For comparison with the other techniques analyzed in this paper, let us find the relative 
error of the worst cases for these tables. Figure 3c shows the worst case for the rectangular table (a 
thin quadrilateral at 45°), and Figure 3d shows the worst case for the combined tables (a thin quadrilateral 
at 22.5°). Under the combined tables, if the mapped pixel's bounding box is not square, we call the shorter 
side L and the longer side nL. The respective errors are: I nL nL 2 £rectangle-or-diarnond = nL I = 
I1 -L[ ! Note that the errors in the worst case are the same, so the addition of the diamond table hasn't 
really earned us anything in general. We have just seen one approach to improving estimates provided 
by a rectangular sum table: maintain a table with a different fundamental region and use it where the 
rect- angular table's estimates would be at their worst. Another way to improve a texture estimate is 
to remove regions of texture we don't want included in our sample. We are not limited to a rectangular 
fundamental region for these subtracted regions. If we maintain a second table with a different shape, 
we may find it easier to remove unwanted areas.  < L > 45~ (a) A bad case for rectangular sum tables. 
22.5 (b) A bad case for combined ##i111iiiiiiii~iiil.iiiiilgi~tilili®~i rectangular and diamond tables. 
 :::::::::::::::::::::::::::::::::::::::::::::: ....... 45 (c) A worst case for rectangular sum tables: 
a degenerate quadrilateral at 45 degrees. (d) A worst case for combined rectangular and diamond tables: 
a degenerate quadrilateral at 22.5 degrees. Figure 3 Let us choose triangles as the fundamental region 
for such an auxiliary sum table. Recalling the above state- ments on sum tables, we may pick any fixed 
shape of trian- gle we like, but we may only have one such shape per table. Let's choose 45 ° right triangles, 
with the sides adjacent to the right angle lined up parallel to the sides of the sum ta- ble. It may 
appear that we need four sum tables, one for each orientation of the right angle. However, we can get 
by with just two triangle tables and the rectangle table. The trick is that when we want a triangle we 
don't have we can find its bounding box and subtract the triangle we do have. The ability to remove these 
triangular regions allows us to draw a generalized octagon around a mapped pixel, and obtain the average 
within this octagon, as shown in Figure 4a. The worst case for the rectangle-plus-triangles scheme is 
when the sides of the mapped pixel make 22.5 ° angles with the sides of the bounding box. Figure 4b demonstrates 
the degenerate form of this worst case, whose error may be expressed as: I nL-(rrL2-2(½L2)) 1 etriangte 
: ~ = -21-L (a) A general case. (b) A worst case: all triangles are 45-45-90. Mapped pixels approximated 
by 45 degree octagons. Figure 4 This error is still linear in L, but grows half as quickly as for the 
combined rectangle-or-diamond table error. We might want to improve our texture estimate further by iteratively 
removing more triangles of smaller size from the unwanted region. However, we would need to know whert 
to stop. We would also like to be able to stop as soon as practical; that is, remove no more regions 
than the image and the texture require to provide acceptable results. In the following section we examine 
a method to provide a stopping point for such an iteration. We should also mention that one can interpolate 
to sub-table values in the sum table, using techniques such as bilinear interpolation. Indeed, this interpolation 
is required to generate alias-free images. It does not save us from the kinds of oversampling errors 
mentioned above, however, un- less carried to an extreme (as briefly discussed in Section 5). 4.0 Estimation 
of Local Texture Complexity We have seen that we can improve the texture esti-mate (or at least the area 
sampled) by iteratively removing extraneous regions from the first approximation made with the bounding 
box. However, we noted that a stopping point is required that will enable us to stop iterating when the 
sampled value is sufficiently accurate for that pixel. To achieve this goal we create a new table: the 
vari-ance table. The variance table contains a local estimate of the variance of the texture at each 
texture position in the table. For a color texture, we can estimate local variance by looking at the 
3 × 3 neighborhood around each texture entry, finding the mean color (~, ~, b), and computing: + 2] 
£=1 est. variance = 8 To use the variance table, first convert it into a rectan- gular sum table. When 
a pixel is mapped into image space, we estimate the variance in that pixel before computing the texture 
value. We estimate the average variance by finding the total variance inside the bounding box of the 
mapped pixel and dividing by the area of the bounding box. Using this technique, we can find an estimate 
of the average amount of high-frequency information inside the mapped pixel, and use that information 
to control how much work we need to do to get a good texture estimate. Figure 5 shows a sample texture 
(before conversion into a rectangular sum table), along with some sample mapped pixels. Note that mapped 
pixel A is in a region with no local variance; the average value inside the bounding box is exactly the 
same as the average value inside the mapped pixel. In this case we should do no more work than that in- 
volved in looking up the bounding box. However, mapped pixel B is in a very busy area. We would like 
a very careful estimate of the area inside the mapped pixel in this case. In the next section we will 
show how to use the es-timated variance to control the accuracy of the sampled pixel. We can approximate 
A coarsely, but we will want a very careful estimate for B. Figure 5 5.0 Adaptive :Polygon Approximation 
In the texturing operation we desire an estimate of the average value within a general quadrilateral. 
One way to derive this estimate is to approximate a non-rectangular shape with rectangles. There are 
at least two ways to do this: additive and subtractive synthesis. We will briefly discuss additive synthesis, 
and then focus on subtractive synthesis for the remainder of this paper. Dallas, August 18-22 The image 
of the pixel in texture space is usually some form of quadrilateral. This quadrilateral could be scan-converted 
in texture space, creating a set of spans defined by one constant co-ordinate and a pair of the other 
co-ordinates defining the endpoints. Each such "scanline" can be looked up in the sum table. This would 
require one sum table access for as many lines as one cares to generate. If the quadrilateral is enclosed 
in a box with height L, this would require L table lookups. Alternatively, one may ap- proximate the 
actual region with a set of smaller rectangles. Let us use K rectangles and apply them to the worst case 
(Figure 4c). Each rectangle would be L/K high by nL/K wide. Thus, the error would be ~additive--ayntheais 
= ~'-~ = --~ (1) Let us now look at subtractive synthesis. We will call the area within the quadrilateral 
representing a mapped pixel the internal region, while the total area outside the quadrilateral but within 
the bounding box is the external region. We may obtain an estimate of the average value in a general 
quadrilateral by first estimating the average value in its bounding box, and then removing rectangles 
from the exterior region. We call each removed rectangle a bite. To maximize the benefit of removing 
bites from the exterior region we should insure that we remove the largest possible bite remaining at 
each step. We must also be able to identify this largest bite quickly and efficiently, since it is an 
operation we may perform many times for every pixel. Bite identification is a two-step process. The first 
step partitions the exterior region into a set of geometric primi- tives, or fragments. The second step 
finds the largest avail- able rectangular region and removes it from the set. The first step is performed 
once per pixel, while the second step is executed once each time we want to refine our texture estimate 
for a given pixel. We chose rectangles and right-angled, table-aligned tri- angles for the fragments. 
These shapes are attractive be- cause the area of their largest bite is easy to compute, and their extents 
require the storage of only four co-ordinates. The largest bite in a rectangle is the entire rectangle, 
and it may be stored by just its two diagonal corner points. The largest bite in a triangle is the rectangle 
with one corner at the right angle and the other at the midpoint of the hy- potenuse~ and it may be stored 
by its right-angle vertex and two side lengths. When a rectangle is removed it is simply deleted from 
the set. When a triangle is removed it is deleted from the set, and the two smaller remaining triangles 
are added, as shown in Figure 6. When we take a bite out of a triangle, we remove the largest rectangle 
it encloses. Two smaller triangles remain. Figure 6 Volume 20, Number 4, 1986 We have developed an iterative 
technique that parti- tions the exterior region into rectangles and triangles. At several points in this 
approach we need to find the orien- tation of a point with respect to a line. We can find which side 
of the line the given point is on by examining the sign of the line equation when solved for the point. 
We can com- pute this efficiently for a point A and a line from P0 to P1 by finding the sign of d = (P 
l= - P0=)(Ay - P0~) + (Plu -P0u)(P0= -A=) We first tag each point of the quadrilateral with a bit field 
indicating whether it lies on each of the four edges or its bounding box (points on a corner are marked 
by both edges). We look for three special cases before proceeding farther. Special case 1 holds if no 
points are corner points; then we must have the ease illustrated in Figure 7. Special case 2 holds if 
all points are corner points; thert the quadri- lateral is a rectangle or a single point~ and we have 
one of the two cases illustrated in Figure 8 (either way there is no exterior region to be partitioned). 
Special case 3 holds if we only have corners on a diagonal, and the other points lie along this line. 
We check for this case by first looking at all the corners; if we only have diagonally opposite corners 
we then find the sign of the distance of the other two points from that line. If the sign of both distances 
is 0, then they all lie along a line, and the partitioning is as illustrated in Figure 9. If all 4 comers 
of the mapped pixel are on the edges of the bounding box, then the pixel must have this form: a right 
triangle in each comer of the bounding box. Figure 7 If all four comers of the pixel are on the comers 
of the bounding box, there are only these two situations: (a) when the mapped pixel is a rectangle with 
non-zero area.  (b) holds when the mapped pixel degenerates into a single texture point.  Figure 8 
When the mapped pixel is a degenerate line across the diagonal of its bounding box we partition the bounding 
box into two triangular regions of equal size, indicated A and B. Figure 9 third -span poin~.___.~ 
 bounding rated box ent  If the 2-span forms a diagonal of the bounding If the 2-span travels from edge 
to edge, then it box we examine a third point (A); if possible this must cut off a comer. We can deduce 
from the point is chosen to lie off the line formed by the rules that created the 2-span that the rest 
of the 2-span. Based on the direction of the 2-span polygon must lie away from that comer. We thus and 
the postition of A, we can tell which triangle create the fragment triangle between the comer to create 
as a fragment. and the 2-span. (a) Figure 10 (b) sl = sign of distance from (E,T) to A UL/E~ UR s2 = 
sign of distance from (T,G) to A s3 = sign of distance from (UL, LR) to T LL G/LRif (s3 > 0) then if 
((sl = 0) AND (s2 = 0)) then else if ((sl <= 0) AND (s2 <= 0)) then else else if (( sl = 0) AND (s2 
= 0) AND (s3 != 0)) then else if ((sl > 0) AND (s2 > 0)) then if (s3 != 0) then else ",'.',', ,...;. 
 ~!,'i'-~ ~ I , An asterisk indicates this partition is else complete at this step and no further spans 
should be processed When we process a 3-span, we need a variety of values to help us create the fragments. 
We compute the sign of the distance from the middle point of the 3-span (denoted T) to each of the two 
corners not included in the 3-span. We also want to know if the fourth point A is on the same side of 
both segments of the 3-span. To this end we compute the distance from A to each of the two line segments. 
We then process the 3-span as shown above. The same process is followed for 3-spans on the other diagonal, 
with appropriate re-labelling. On each partitioning diagram we show the location of the fourth point 
A, determined by the algorithm, to show how the convex hull is automatically determined as we process 
the span. Figure 11 Dallas, August 18-22 If none of these special cases holds, we partition the region 
with an iterative procedure. We start with a corner point and fix a direction to pick up the remaining 
points (clockwise around the original pixel works fine). We then look at the edge information for next 
point around the quadrilateral. If this second point is on an edge, we call this pair of points a e-span. 
We pick one of the other two points as an auxiliary point and call it point .~ ; if possible, we pick 
.~I to lie off the line formed by the 2-span. We then find the sign of the distance from this point to 
the llne formed by the 2-span. If both points of the 2-span are corner points, then we create partitions 
as shown in Figure 10a, otherwise we create partitions as shown in Figure 10b. If this second point is 
not on an edge, then we examine the next point in turn. If this third point is on an edge, we call the 
trio a 9-span, and A is assigned the remaining point. If the first and last points of the 3--span are 
corners we create partitions as shown in Figure 11, otherwise we re-label the points as shown in Figure 
12 and then create the partitions shown in Figure 11. If this third point is not on an edge, we then 
take the fourth point and call the quartet a $-span, and partition it as shown in Figure 13. E EL G E 
G If the endpoints of a 3-span are not comers, then we label them according to these conven- tions and 
use the algorithm of Figure 11. Figure 12 A 4-span necessarily spans opposite diagonals of the bounding 
box. If both of the other points are on the same side of the diagonal we parti- tion the box into these 
6 fragments. If the two non-corner points in a 4-span are not on the same side of the diagonal, then 
we derive the convex hull and partition the regions outside it into 6 fragments using this scheme. Figure 
13 Volume 20, Number 4, 1986 If the point at the end of the most recently classified span is not the 
same point we started with, we use last that point as the start of a new span and continue walking around 
the points of the quadrilateral. When we return to our starting point, we will have walked around the 
en- tire outside of the mapped pixel, partitioning the region between its convex hull and its bounding 
box into triangles and rectangles. The partitioning algorithm is summarized in the Appendix. We are then 
prepared to remove bites from the external region, as guided by this partitioning. The process is reca- 
pitulated in Figure 14. Figure 14a shows a mapped pixel~ 14b shows its decomposition into triangles and 
rectangles, 14c shows the removal of the first bite, and 14d shows the removal of the first six bites. 
/V (a) the mapped pixel (b) the fragments (c) the largest bite (d) the first six bites  Figure 14 It 
is informative to compute the area error left after each step in the refinement of the estimate. A worst-case 
general quadrilateral consists of a line from one corner of its bounding box to its diagonal opposite. 
Let us label the shorter side (if there is one) as L, and the longer side as nL. Both regions around 
L have equal area; let us take the largest bite out of one of them. The area left after this bite iS 
now desired = nL 2 -x -- Thus the relative error is .L-(3.L=/4)[ 1-- Gone--bite = ~ = 43-L Similar 
reasoning for other numbers of bites leads us to a piecewise-linear approximation to the curve 2 -~, 
with exact matches where n is an integer. We thus arrive at the general formula for the error after k 
bites: (3(2[1og2 k]) _ k -1) L ~adaptive(k) 1 (2) -\ 4Ltog= ~ This formula gives us a relationship (albeit 
a little complex) between the number of rectangular bites taken from the area and the resulting relative 
area error. Since this anal- ysis was carried out for the worst case, if we take enough bites to meet 
this error for any situation we are guaranteed a maximum bound on the relative error. The variance table 
and the results of Equation 2 are used to determine a maximum bound on the number of bites we need to 
take from a sample. We simply use a linear relationship between the range of variance and the range of 
error, adjusted to err on the side of over-refining.  Dallas, August 18-22 7.0 Discussion and Future 
Work The use of the variance map to determine how many bites to take in an estimate seems to be a good 
approxima- tion, but it's not ideal; in fact it can lead to estimates which are much higher than they 
ought to be. A better way to determine which bite to take would be to take the Fourier transform of all 
the possible bites at each step, and choose the bite with the maximum energy under its transform. The 
drawback to this scheme is clearly the high computa- tional cost involved in taking the transforms and 
evaluating their energy. It would be interesting to examine techniques to get a quick estimate on these 
values. It would be nice if we could remove bites from the con- cave portions of concave mapped pixels, 
rather than work with their convex hulls. It would be interesting to look for other fragment shapes that 
had the storage and simplicity characteristics of oriented rectangles and oriented right tri- angles, 
but could also give us a handle on approximating concave mapped pixels. It should be noted that there 
is an inherent limit on the theoretical precision of this technique. As mentioned in Section 1.0, we 
are not performing an ideal filtering of the texture when we derive our estimate. Our first ma-jor assumption 
was to use rectangular, abutting "Fourier windows" to control our examined texture region. Our sec- ond 
assumption was to effectively sample the texture with a delta function, instead of a proper filter. These 
assump- tions usually produce good results in synthesized images. However, after a certain point further 
refinement of the texture estimate by the techniques presented here will not come closer to a theoretical 
value. This theoretical draw- back does not seem to detract from the general usefulness of the technique. 
It is true that the complexity measure described in this paper is best for textures with large homogeneous 
ar-eas (such as checkerboards!). Complex textures will have very high values throughout the variance 
map. This isn't too bad, since we will usually will want very accurate esti- mates of complex textures. 
But this is another reason that a better complexity estimator than the variance would be valuable. We 
have investigated another way to determine the partitions of a mapped pixel and its bounding box. We 
have found that there are 25 types of box-bounded convex quadrilaterals. If we can quickly determine 
to which of the 25 types a given mapped pixel corresponds, we can have the entire partitioning immediately. 
We hope to follow this line of thought farther. The techniques described in this paper can be extended 
in a straightforward way to sum tables of 3 or more dimen- sions. In the 3d case we would remove right 
pyramids and right parallelpipeds from our bounding right parallelpiped to refine the texture estimate. 
The fragmentation code would be considerably more complex. 8.0 Acknowledgements Several of the ideas 
in this paper were considered in- dependently by Ken Perlin [Perl86]. Specifically, he inves- tigated 
three-dimensional tables for the triangular tables discussed in Section 3, using two axes for u and v 
and the third for the free angle. Volume 20, Number 4, 1986 Thanks go to my advisor Henry Fuchs for 
his enthusi- astic support. Thanks also go to my fellow students in the UNC-CH Computer Graphics Lab, 
whose expertise and in- sight contributed greatly to this work. Many of the ideas and results in this 
paper grew out of conversations with Greg Abram, Phil Amburn, Larry Bergman, John Gauch, Eric Grant, 
Jeff Hultquist, Marc Levoy, Chuck Mosher, and Lee Westover. Comments on this paper were offered by sev- 
eral of the above and Bobette Eckland. Special thanks go to Jeff and Mary Hultquist, who vol- unteered 
to assist me in the final production of this paper. The excellent layout and pasteup are entirely due 
to their talents and friendship. 9.0 References <RefA>[Andr77] <SinRef><author>Andrews, H.C., </author>and <author>Hunt, B.R., </author>"<title>Digital Image 
Restoration</title>," <publisher>Prentice-Hall</publisher>, Inc. (<date>1977</date>) </SinRef>[Bish82] <SinRef><author>Bishop, G., </author>"<title>Gary's Ikonas Assembler Version 2</title>," <journal>UNC-CH 
Computer Science </journal><title>Department Technical Report</title>, <date>June, 1982 </date></SinRef>[Blirt76] <SinRef><author>Blinn, J., </author>and <author>Newell M.E., </author>"<title>Texture 
and Re- flection in Computer Generated Images,</title>" CACM 19, 10 (Oct 1976) </SinRef>[SlinT8] <SinRef><author>Blinn, J., </author>"<title>Simulation 
of Wrinkled Surfaces</title>," <journal>Computer Graphics</journal>, <volume>eel. 12, no. 3, </volume><date>August 1978 </date></SinRef>[Catm75] <SinRef><author>Catmull, E., </author>"<title>Computer 
Display of Curved Sur- faces</title>," <booktitle>Prec. [EEE Conference on Computer Graphics, Pattern Recognition, and Data 
Struc- ture</booktitle>, <date>May 1975</date></SinRef>. [Carp84] <SinRef><author>Carpenter, L., </author>"<title>The A-buffer, an Antialiased Hidden Surface Method</title>," 
<journal>Computer Graphics</journal>, <volume>eel. 18, no. 3</volume>, <date>July 1984 </date></SinRef>[Cook84] <SinRef><author>Cook, R., </author>"<title>Shade Trees</title>," <journal>Computer Graphics</journal>,<volume> vol. 
18, no. 3, </volume><date>July 1984 </date></SinRef>[Crow84] <SinRef><author>Crow, F., </author>"<title>Summed-Area Tables for Texture Mapping</title>," <journal>Computer Graphics</journal>, 
<volume>eel. 18, no. 3, </volume><date>July 1984 </date></SinRef>[DuffS5] <SinRef><author>Duff, T., </author>"<title>Compositing 3-D Rendered Images</title>," <journal>Computer Graphics</journal>, <volume>eel. 
19, no. 3</volume>, <date>July 1985</date></SinRef> [Feib84] <SinRef><author>Feibush</author>, <author>Levoy, M., </author><author>Cook, R., </author>"<title>Synthetic Tex- turing Using Digital Filters</title>," 
<journal>Computer Graph- ics</journal>, <volume>eel. 14, no. 3 </volume><date>July 1980 </date></SinRef>[Gard84] <SinRef><author>Gardner G., </author>"<title>Simulation of Natural Scenes Using 
Textured Quadric Surfaces</title>," <journal>Computer Graphics</journal>, <volume>eel. 18, no. 3, </volume><date>July 1984</date></SinRef> [Peal85] <SinRef><author>Peachey D., </author>"<title>Solid 
Texturing of Complex Sur- faces</title>," <journal>Computer Graphics</journal>, <volume>eel. 19, no. 3</volume>, <date>July 1985 </date></SinRef>[Per[85] <SinRef><author>Perlin, K</author>., "<title>An 
Image Synthesizer</title>," <journal>Computer Graphics</journal>, <volume>eel. 19, no. 3, </volume><date>July 1985 </date></SinRef>[Perl86] <SinRef><author>Perlin, K</author>.,<title> private communication</title>. </SinRef>
[Port84] <SinRef><author>Porter, T., </author>and<author> Duff, T., </author>"<title>Compositing Digi- tal Images</title>," <journal>Computer Graphics</journal>, <volume>eel. 19, no. 3, </volume>
<date>July 1985</date> </SinRef>[Ross76] <SinRef><author>Ross S., </author>"<title>A First Course in Probability</title>," <publisher>MacMillan Publishing Co</publisher>, Inc. (<date>1976</date>) </SinRef>[Schw831 
<SinRef><author>Schweitzer D., </author>"<title>Artificial Texturing: An Aid to Surface Visualization</title>," <journal>Computer Graphics</journal>, <volume>eel. 18, no. 
3</volume>,<date> July 1984 </date></SinRef>[Suth74] <SinRef><author>Sutherland, I., </author><author>Sproull, R., </author><author>Schumaker, R., </author>"<title>A Characterization of Ten Hidden-Surface 
Al- gorithms</title>," <journal>Computing Surveys</journal>, <volume>eel. 6, no. 1, </volume><date>March 1974</date></SinRef> [WillS3] <SinRef><author>Williams L., </author>"<title>Pyramidal Parametrics</title>," 
<journal>Com-puter Graphics</journal>, <volume>eel. 18, no. 3, </volume><date>July 1984 </date>~. <journal>S I G G R A P H </journal><volume>'86</volume></SinRef></RefA>  Appendix: derivation of the partitioning 
algorithm The figure below shows the possible spans that may arise in a mapped pixel. When we consider 
edge information some spans become unrealizable; these are marked X. For example, the fifth span on the 
first row must have the given partitioning; if the quadri- lateral had any points inside the shaded triangle 
the endpoints of the span would be cor- ners. Sometimes we need another point of the polygon to decide 
which side of the span to partition. This point is chosen to lie off the line(s) formed by the span, 
if possible, and is marked ~ in this diagram. ...... 2-spans J2 -> N ~.~ ~.:.:~ :...:':..:'... 4-spans 
  
			
